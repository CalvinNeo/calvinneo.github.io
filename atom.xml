<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Calvin&#39;s Marbles</title>
  
  
  <link href="http://www.calvinneo.com/atom.xml" rel="self"/>
  
  <link href="http://www.calvinneo.com/"/>
  <updated>2024-11-06T04:15:16.150Z</updated>
  <id>http://www.calvinneo.com/</id>
  
  <author>
    <name>Calvin Neo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Database paper part 2</title>
    <link href="http://www.calvinneo.com/2024/11/01/database-paper-2/"/>
    <id>http://www.calvinneo.com/2024/11/01/database-paper-2/</id>
    <published>2024-11-01T13:33:22.000Z</published>
    <updated>2024-11-06T04:15:16.150Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章中，包含 Greenplum、Aurora、Dynamo、WiscKey。</p><a id="more"></a><h1 id="Greenplum"><a href="#Greenplum" class="headerlink" title="Greenplum"></a>Greenplum</h1><p>Greenplum: A Hybrid Database for Transactional and Analytical Workloads</p><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>Greenplum 类似于 Redshift、AnalyticDB、BigQuery 这样的 PB 级别的数据仓库。相比之下，像 CRDB、Amazon RDS 这种关系型数据库主要还是在 TB 阶段。</p><p>Client 和 coordinator 交互，coordinator 将任务下发到各个 segment 上。各个 segment 并行处理，并且可能会 shuffle 一些 tuple。</p><p>DML 可以在 worker segment 上被用来修改数据。</p><p>原子性通过 2PC 保证。</p><p>并发事务通过分布式快照保证。</p><p>Greenplum 支持 append-optimized column-oriented 表。支持多种压缩算法。这些表适合用来做 bulk read 和 buld write，也就是典型的 OLAP 负载。</p><p><img src="/img/dbpaper/gp/1.png"></p><p>后面就自然演化出 HTAP 的需求，要求点查的响应要快，也要有 scalable 的 AP 能力。</p><p>GP 主要是三点：</p><ol><li>并行的 data loading，且 ACID</li><li>减少点查的响应时间</li><li>Resource Group，隔离用户在不同类型的 workload 的资源</li></ol><p>GP 以 OLAP 为第一等公民。特别是对于小事务来说，2PC 是一个巨大的惩罚。Coordinator 会被施加很重的锁，以避免 distributed deadlock，这个设计限制性太大了。</p><p>下面这张图的意思是对于一个 10s 的查询，在锁上面占用的时间的比例。随着并发度的提高，这个时间越来越不可接受。</p><p><img src="/img/dbpaper/gp/2.png"></p><p>GP 的贡献：</p><ol><li>如何从 OLAP 转换成为 HTAP</li><li>global deadlock detector<br> 作用是减少了锁的开销，优化了 TP 的响应时间。同时不牺牲 AP。</li><li>对于一个 segment 上的事务只做 1PC</li><li>前面提到的 resource control</li></ol><p>在 Relate work 中主要介绍了两种 HTAP 方案。第一种是从 OLTP 演进的，包含 Oracle Exadata、Aurora。另一种是从 NewSQL 演进的，例如 Spanner、CRDB、TiDB 和 F1。</p><h2 id="MPP-架构"><a href="#MPP-架构" class="headerlink" title="MPP 架构"></a>MPP 架构</h2><p>在整个数据库中，只有一个 coordinator segment。</p><p>一些 segment 会被作为 mirror 或者 standby（特指对 coordinator）存在，但不会参与到计算中。它们接受 WAL，并且回放。</p><p>GP 是 shared-nothing 的。使用各自的内存和 data directory，只通过 network 访问。</p><h3 id="Distributed-Plan-and-Distributed-Executor"><a href="#Distributed-Plan-and-Distributed-Executor" class="headerlink" title="Distributed Plan and Distributed Executor"></a>Distributed Plan and Distributed Executor</h3><p>作为 shared-nothing 架构，在 join 的时候就需要在 segments 之间移动 tuples。</p><p>GP 引入了 Motion plan。Motion 将 plan 切分为更小的块，称为 slice，我理解就是子计划。每个 slice 被一个 process group 执行，这一 process group 称为 gang。</p><p>With the proposed Motion plan node and gang mentioned above, Greenplum’s query plan and the executor both becomes distributed. The plan will be dispatched to each process, and based on its local context and state, each process executes its own slice of the plan to finish the query execution. The described execution is the Single Program Multiple Data technique: we dispatch the same plan to groups of processes across the cluster and different processes spawned by different segments have their own local context, states, and data.</p><p>下图的上面部分是一个分布式查询计划，下面部分是这个计划的执行流程。在例子中有两个 segment。<br>The top slice is executed by a single process on the coordinator, and other slices are executed on segments. One slice scans the table and then sends the tuples out using redistributed motion. Another slice that performs hash join will receive tuples from the motion node, scan the student table, build a hash table, compute the hash join, and finally send tuples out to the top slice.<br><img src="/img/dbpaper/gp/4.png"></p><h3 id="Distributed-Transaction-Management"><a href="#Distributed-Transaction-Management" class="headerlink" title="Distributed Transaction Management"></a>Distributed Transaction Management</h3><p>GP 中，每个 segment 实际上是一个 PostgreSQL 实例。</p><p>为了保障 ACID 特性，GP 用了 2PC 和分布式快照。</p><h3 id="Hybrid-Storage-and-Optimizer"><a href="#Hybrid-Storage-and-Optimizer" class="headerlink" title="Hybrid Storage and Optimizer"></a>Hybrid Storage and Optimizer</h3><p>GP 支持 PSQL 原生的 heap table。这个 table 是一个行存，包含固定大小的 block，以及被多个 query 共享的 cache。</p><p>GP 自己添加了两种新表：AO-row 和 AO-column。AO 表示 append-optimized。AO 的访问模式更有利于 bulk IO，也就是 AP 的工作负载。</p><p>GP 的分区是在 root table 下新建更低层级的表来做的，这里就类似于 TiDB 的方案。不同的 partition 可以存在不同的表类型中，特别地，还支持一些外部存储，比如 HDFS、S3 等。</p><h2 id="OBJECT-LOCK-OPTIMIZATION"><a href="#OBJECT-LOCK-OPTIMIZATION" class="headerlink" title="OBJECT LOCK OPTIMIZATION"></a>OBJECT LOCK OPTIMIZATION</h2><p>这是 GP 的关键。核心是通过一个算法解决分布式环境下的 global deadlock 问题。</p><p>GP 会举例子来讲解。例子中有两个 int column c1 和 c2，c1 是 distributed ke。数据分布在三个 segments 上。</p><h3 id="Locks-in-Greenplum"><a href="#Locks-in-Greenplum" class="headerlink" title="Locks in Greenplum"></a>Locks in Greenplum</h3><p>三种类型的锁：spin lock，LWLock，Object lock。</p><p>前两者是为了保护读写共享内存的，我理解实际上叫 latch 吧。主要还是聚焦 Object 锁。</p><p>和 PSQL 一样，lock mode 分为 8 个级别。</p><p><img src="/img/dbpaper/gp/t1.png"></p><p>但是 MPP 数据库和 PSQL 的锁算法是有区别的，PSQL 锁逻辑不能发现或者解决 global deadlock。更具体来说，需要增加 DML 操作的 local level，保证事务是 serially 执行的。</p><p>在 GP 的早期版本是基于 PSQL 的，在事务比较多的时候，性能很差，因为只有一个事务能够对同一个 relation 进行 update 或者 delete。</p><h3 id="Global-Deadlock-Issue"><a href="#Global-Deadlock-Issue" class="headerlink" title="Global Deadlock Issue"></a>Global Deadlock Issue</h3><p>在诸如 GP 这样的分布式系统中，DML 语句的行为如下：</p><ol><li>在 parse-analyze 阶段， the transaction locks the target relation in some mode.</li><li>在执行阶段，事务在 tuple 中写入自己的 id。This is just a way of locking tuple using the transaction lock.</li></ol><p>在 PSQL 这样的单机数据库中，第一阶段一般是 RowExclusive 锁。所以它们是能够并发的，除非它们要写的是同一个 tuple，才会有等待。</p><p>这些 lock dependencies 会被存在每个 segment 的内存中，如果死锁发生了，就可以通过内存中的信息去解决。</p><p>但是 PSQL 的 lock deadlock handler 是不够的。如下图所示</p><p><img src="/img/dbpaper/gp/6.png"></p><p>简单来说，是下面的时序关系：</p><ol><li>A 要写 segment 0 里面的一个 tuple (2, 2)，持有的是 segment 0 的锁。B 要写 segment 1 里面的一个 tuple (1, 1)，持有的是 segment 1 的锁。</li><li>B 需要写刚才 A 写的那个 tuple，因为 A 还没有 commit 或者 abort，所以 B 得等。</li><li>同理，A 要写 B 刚才写的 tuple，A 也得等。</li></ol><p>于是，segment 0 上的 B 在等 segment 1 上的 A。segment 1 上是类似的情况。无论是 segment 0 还是 1，它本地的 deadlock handler 都检测不到有 deadlock，这也就是一直在说的 global deadlock。</p><p>后面还举了一个更复杂的例子，我也不想看了。</p><p>在 GP 5 以及之前的版本，同一个 relation 上面的事务是串行执行的。并发度很差了，虽然肯定没有死锁。</p><h3 id="Global-Deadlock-Detection-Algorithm"><a href="#Global-Deadlock-Detection-Algorithm" class="headerlink" title="Global Deadlock Detection Algorithm"></a>Global Deadlock Detection Algorithm</h3><p>GDD 要点：</p><ol><li>在 coordinator segment 上启动一个 daemon</li><li>daemon 定时收集每个 segment 上的 wait-for 图</li><li>daemon 确定是否有 global deadlock 发生</li><li>daemon 使用预定义的策略解决死锁</li></ol><p>wait-for 图中，点表示事务，有向边 a -&gt; b 表示 a 在等 b。这里会引入 deg(G)(V) 和 deg(i)(V) 分别表示 V 的 global out-degree 以及 i 的 local out-degree。</p><p>从不同 segment 收到的 wait-for 信息是异步的。</p><p>GDD 算法的核心是贪心，它会尝试 remove 掉可能在后续能执行的边，那么剩下来的边上可能就会发生 global deadlock。当然，这是不够的，算法的 recall 和 accuracy 都得是 1 才行。</p><p>这个时候，算法就需要在 coordinator 上面 lock 所有的 process，然后检查剩余的 edge 是否是 valid 的。如果这个时候一些事务已经结束了，GDD 就会 abort 掉这一轮的所有信息，sleep 一段时间，然后开启下一轮。</p><p>在 global wait-for 图中，有两种边：</p><ol><li>实线边<br> 表示这个 waiting 只会在持有锁的事务结束后才会消失。<br> 比如说 when a relation lock on the target table in UPDATE 或者 DELETE 语句。<br> Such an edge can be removed only when the holding transaction is not blocked everywhere because based on the greedy rule we can suppose the hold transaction will be over and release all locks it holds.<br> 例如 Xid lock、Relation lock closed with NO_LOCK。</li><li>虚线边<br> 表示可以在事务还没结束的时候，这个锁就可能被 release 了。<br> For example, a <strong>tuple lock</strong> that is held just before modifying the content of a tuple during the execution of a low level delete or update operation. Such an edge can be removed only when the holding transaction is not blocked by others in the specific segment. This is based on the greedy rule we can suppose the hold transaction will release the locks that blocks the waiting transaction without committing or aborting.</li></ol><p>GDD 算法如下。<br>首先移除掉所有出度为 0 的 V。<br>然后扫描每个 local wait-for 图，删除掉所有指向出度为 0 的 V 的<strong>虚线</strong>边。</p><p><img src="/img/dbpaper/gp/a1.png"></p><h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h3><p>在下面的例子中，在前三步 B 会被 segment 0 上的 A 和 segment 1 上的 C 阻塞。在第四步，A 有试图 lock segment 1 上的 tuple，然后被 B 阻塞。</p><p>【Q】这里应该同时也会被 C 阻塞？</p><p>注意，这里的 A -&gt; B 是一个虚线。【Q】Why？我理解可能是事务上的第一个锁是 xid 锁，后面的是 tuple 锁。</p><p><img src="/img/dbpaper/gp/8.png"></p><p>下面是 GDD 算法：</p><ol><li>首先，C 的 global 出度是 0。因为 C 没有在等任何的事务。因此在移除掉 C 之后，得到 (b) 这张图。</li><li>发现 B 在 seg 1 上的出度是 0，所以可以移除所有指向 B 的虚线边，从而得到 (c) 这张图。</li><li>发现 A 的 global 出度是 0，移除掉 A 之后，可以得到 (d) 这张图。</li><li>GDD 报告没有死锁。</li></ol><p><img src="/img/dbpaper/gp/9.png"></p><h2 id="DISTRIBUTED-TRANSACTION-MANAGEMENT"><a href="#DISTRIBUTED-TRANSACTION-MANAGEMENT" class="headerlink" title="DISTRIBUTED TRANSACTION MANAGEMENT"></a>DISTRIBUTED TRANSACTION MANAGEMENT</h2><h1 id="Aurora"><a href="#Aurora" class="headerlink" title="Aurora"></a>Aurora</h1><p>Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases</p><h2 id="Intro-1"><a href="#Intro-1" class="headerlink" title="Intro"></a>Intro</h2><p>认为随着扩容，IO 瓶颈变成了网络。特别是在存算分离下，变成了计算层和存储层之间的网络。因为计算节点通常是并行发送请求，所以网络问题还存在木桶效应。</p><p>有一些操作是同步的，比如如果 cache miss，读线程就会等待。checkpoint 以及 dirty page write 技术能够缓解，但也会引入 stall、context switch 以及 resource contention 问题。</p><p>另外，事务提交也是另一个问题。特别是在分布式环境下的 2PC 会更加有挑战性。</p><p>Aurora 的思想是更加激进地使用 redo log。它从一个 virtualized segmented redo log 抽象上构造的 </p><blockquote><p>We use a novel service-oriented architecture with a multi-tenant scale-out storage service that abstracts a virtualized segmented redo log and is loosely coupled to a fleet of database instances. Although each instance still includes most of the components of a traditional kernel (query processor, transactions, locking, buffer cache, access methods and undo management) several functions (redo logging, durable storage, crash recovery, and backup/restore) are off-loaded to the storage service.</p></blockquote><p>三点优势：</p><ol><li>由存储服务来负责容错以及自愈，数据库就可免受存储层的影响<br> 他们说 failure in durability 可以被看做长期的 availablity 问题，一个 availablity 问题可以被看做长期的性能问题。</li><li>因为往存储写的是 redo log，所以能够大幅度减少 IOPS</li><li>将一些复杂但是重要的工作，比如 backup and redo recovery 从一次性的昂贵操作转变为连续的异步操作，并且这些操作分布在多个机器上的<br> 这实际上让 crash recovery 变得非常快，并且这还不需要依赖 checkpoint 技术，也不会影响前台的处理。</li></ol><h2 id="DURABILITY-AT-SCALE"><a href="#DURABILITY-AT-SCALE" class="headerlink" title="DURABILITY AT SCALE"></a>DURABILITY AT SCALE</h2><h3 id="Replication-and-Correlated-Failures"><a href="#Replication-and-Correlated-Failures" class="headerlink" title="Replication and Correlated Failures"></a>Replication and Correlated Failures</h3><p>这里说的 instance 应该可以理解为计算层。Aurora 说这两个的生命周期不是一致的，计算层随着上下线，扩缩容，变化更大。</p><p>假如有 V 个副本，令读操作需要 Vr 票，写操作需要 Vw 票，那么：</p><ol><li>Vr + Vw &gt; V<br> 也就是至少有一个读节点能看到最近的写入。</li><li>Vw &gt; V / 2<br> 这是在写入的时候，要避免冲突，形成多数。</li></ol><p>所以，为了容忍单个节点的故障，可以选择 V 为 3，Vr 为 2，Vw 为 2。这个类似于 Dynamo，在 <a href="/2017/09/20/distributed-system-consistency-and-consensus/">分布式一致性和分布式共识协议</a> 中也讲解了为什么 Vr + Vw &gt; V 并不足以能保证线性一致。</p><p>但是 Aurora 认为这是不够的，主要是如果一个 AZ 挂了，就会损失两个副本，这样就没有办法确认第三个副本是不是最新的了。Aurora 需要实现的是：</p><ol><li>丢失一个 AZ 不影响写入能力</li><li>丢失一个 AZ 以及一个额外节点而不影响数据恢复能力</li></ol><p>因此，它们使用了 V=6，Vr = 3，Vw=4 的模型。</p><h3 id="Segmented-Storage"><a href="#Segmented-Storage" class="headerlink" title="Segmented Storage"></a>Segmented Storage</h3><p>通过缩短 MTTR 去减少可能出现 double fault 的窗口。</p><p>主要就是将数据库氛围 10GB 的 Segment，每个 Segment 按照六副本复制，会被复制到 3 个 AZ 中，每个 AZ 两个副本。目前 Aurora 支持最大 64TB 的数据库。</p><p>10 GB 的 segment 可以在 10s 内被修复，基于一个 10Gbps 的网络。</p><h3 id="Operational-Advantages-of-Resilience"><a href="#Operational-Advantages-of-Resilience" class="headerlink" title="Operational Advantages of Resilience"></a>Operational Advantages of Resilience</h3><h2 id="THE-LOG-IS-THE-DATABASE"><a href="#THE-LOG-IS-THE-DATABASE" class="headerlink" title="THE LOG IS THE DATABASE"></a>THE LOG IS THE DATABASE</h2><h3 id="The-Burden-of-Amplified-Writes"><a href="#The-Burden-of-Amplified-Writes" class="headerlink" title="The Burden of Amplified Writes"></a>The Burden of Amplified Writes</h3><p>主要是为了维持多副本，IO 就会显著变高。IO 变高会导致系统中的同步阻塞点变多。这里提到，Chain replication 能够减少网络开销，但是链式复制引入了更多的同步。</p><p>在传统数据库中，数据被写入到 data page 中，也被写到 redo log 中。每个 redo log 包含了前像和后像之间的 diff。</p><p>下图是如果要维护一个传统的 MySQL 镜像需要进行的 replication 的数据规模。</p><p>这里 double write 指的是 MySQL 在刷脏页的时候，如果中途发生宕机，可能有一个页面只写了一般，从而丢失数据的情况。因为 redo log 记录的是 diff 而不是 page 本身的数据，所以无法通过 redo log 恢复。double write 机制是先把这些页面<strong>顺序</strong>地写到磁盘上<strong>连续</strong>的一些页中（128页 * 16K=2MB），然后再刷到实际的位置中。这样可以从第一次写的地方恢复最近一次刷脏的页面。<br><img src="/img/dbpaper/aurora/1.png"></p><p>从分布式系统角度看，这个模型是一个 4/4 write quorum，对 failure 和离群点性能更敏感。</p><h3 id="Offloading-Redo-Processing-to-Storage"><a href="#Offloading-Redo-Processing-to-Storage" class="headerlink" title="Offloading Redo Processing to Storage"></a>Offloading Redo Processing to Storage</h3><p>传统数据库中惠使用 log applicator 去将 redo log 应用到前像上从而产生后像，事务提交至少需要 redo log 被持久化。Aurora 在数据库层面，没有后台写、checkpoint、cache evection。log applicator 会被下推到存储层，从而可以后台地、异步地去生成 database page。</p><p>当然，从头开始生成的代价是昂贵的，所以我们会在后台持续物化 database page，来避免每次都重新生成。当然，这个物化是完全可选的，因为 the log is the database。</p><p>Note also that, unlike checkpointing, only pages with a long chain of modifications need to be rematerialized. Checkpointing is governed by the length of the entire redo log chain. Aurora page materialization is governed by the length of the chain for a given page.<br><img src="/img/dbpaper/aurora/3.png"></p><p>下面是一个显著的性能对比。</p><p><img src="/img/dbpaper/aurora/t1.png"></p><p>在存储层进行日志复制的工作实际上能减少 crash recovery 时间，并且消除 checkpoint、后台 data page 写入、backup 导致的 jitter。因此，提高了可用性。</p><p>原因如下。在传统数据库中，在一次 crash 之后，系统必须从最近的 checkpoint 开始回放 redo log。In Aurora, durable redo record application happens at the storage tier, continuously, asynchronously, and distributed across the fleet. Any read request for a data page may require some redo records to be applied if the page is not current. As a result, the process of crash recovery is spread across all normal foreground processing. 在数据库重启的时候，无需进行任何的操作，也没有额外的等待。</p><h3 id="Storage-Service-Design-Points"><a href="#Storage-Service-Design-Points" class="headerlink" title="Storage Service Design Points"></a>Storage Service Design Points</h3><p>Aurora 设计的信条是减少前台写入的延迟。因此，它将大部分的 storage processing 移动到了后台。</p><p>Given the natural variability between peak to average foreground requests from the storage tier, we have ample time to perform these tasks outside the foreground path. We also have the opportunity to trade CPU for disk.</p><p>例如，在存储节点忙于前台写入任务的时候，就没有必要进行 GC，除非磁盘要爆了。</p><p>在 Aurora 中，后台处理和前台处理是负相关的。而传统数据库中，后台写 page 以及 checkpoint 的操作，和前台负载是正相关的。如果引入 backlog 机制，就需要限制前台的活动，从而避免队列越积压越长。相反地，在 Aurora 中，如果一个节点积压卡死了，可以通过 4/6 Quorum 模型来轻松处理：这个节点会被标注为一个慢节点，但是不影响整个系统运行。</p><p>Let’s examine the various activities on the storage node in more detail. As seen in Figure 4, it involves the following steps: </p><ul><li>(1) receive log record and add to an in-memory queue</li><li>(2) persist record on disk and acknowledge</li><li>(3) organize records and identify gaps in the log since some batches may be lost</li><li>(4) gossip with peers to fill in gaps, (5) coalesce log records into new data pages, (6) periodically stage log and new pages to S3</li><li>(7) periodically garbage collect old versions</li><li>(8) periodically validate CRC codes on pages. </li></ul><p>注意，上述的每一步都是异步的。只有 1 和 2 属于前台写入路径中，从而可能影响到性能。</p><h2 id="THE-LOG-MARCHES-FORWARD"><a href="#THE-LOG-MARCHES-FORWARD" class="headerlink" title="THE LOG MARCHES FORWARD"></a>THE LOG MARCHES FORWARD</h2><h3 id="Solution-sketch-Asynchronous-Processing"><a href="#Solution-sketch-Asynchronous-Processing" class="headerlink" title="Solution sketch: Asynchronous Processing"></a>Solution sketch: Asynchronous Processing</h3><p>每个 log record 都有一个对应的 LSN，它是单调递增的。通过它可以避免 2PC，which is chatty and intolerant of failures。</p><p>因为每个存储节点可能缺少一些 log record，所以它们会和 PG 中的其他成员 gossip，尝试 fill the holes。</p><p>下面这个不知道具体指的是什么</p><blockquote><p>The runtime state maintained by the database lets us use single segment reads rather than quorum reads except on recovery when the state is lost and has to be rebuilt. </p></blockquote><p>The database may have multiple outstanding isolated transactions, which can complete (reach a finished and durable state) in a different order than initiated. Supposing the database crashes or reboots, the determination of whether to roll back is separate for each of these individual transactions. The logic for tracking partially completed transactions and undoing them is kept in the database engine, just as if it were writing to simple disks.<br>但是在重启后，在数据库能够访问存储前，存储服务能够执行自己的 restore 逻辑。在恢复的时候，并不是关注事务，而是关注数据库能够看到一致性的存储视图。</p><p>存储服务应决定一个最大的 LSN，称为 VCL(Volume Complete LSN)。在存储恢复过程中，所有 LSN 大于 VCL 的日志都需要被截断。数据库可以进一步标记一个 CPL(Consistency Point LSNs)从而进一步截断日志。我们定义 VDL(Volumn Durable LSN)为所有副本中最大的 CPL，并且要小于等于 VCL。然后截断 LSN 大于 VDL 的所有日志。比如，即使我们有一份完整的直到 LSN 1007 的数据，但是数据库定义了 CPL 分别是 900/1000/1100，这样的话必须 truncate 到 1000。也就是 we are complete to 1007, but only durable to 1000.</p><p>因此，完整性和持久性是不同的，CPL 可以被看做一种必须被按序 accept 的存储层事务。如果客户端不关注这些区别，就可以将所有日志标志为 CPL。在实际应用时，数据库和存储服务的交互如下：</p><ol><li>数据库层的事务被分为多个 MTR，这些 MTR 是有序的，并且必须要原子地被执行</li><li>所有的 MTR 由多个连续的 Log Record 组成</li><li>MTR 的最终的 Log Record 是一个 CPL</li></ol><p>在恢复的时候，数据库询问每个 PG 的 durable point，并用它来构造 VDL。</p><h3 id="Normal-Operation"><a href="#Normal-Operation" class="headerlink" title="Normal Operation"></a>Normal Operation</h3><h4 id="Writes"><a href="#Writes" class="headerlink" title="Writes"></a>Writes</h4><p>In the normal/forward path, as the database receives acknowledgements to establish the write quorum for each batch of log records, it advances the current VDL.</p><p>分配 LSN 的规则是不能分配比 <code>VDL+LAL</code> 还大的 LSN。VDL 就是目前的 VDL，LAL 是一个常数，称为 LSN Aoolocation Limit，目前等于 10m。这个限制让数据库不会比存储系统超前太多。这样避免当存储或者网络跟不上的时候，后台压力过大导致写入阻塞。</p><p>注意，每个 Segment 只会看到对应 PG 的一个 log record 的子集。每个 log record 会附有一个后向指针，指向这个 PG 的前一条 log record。</p><p>These backlinks can be used to track the point of completeness of the log records that have reached each segment to establish a Segment Complete LSN(SCL) that identifies the greatest LSN below which all log records of the PG have been received. The SCL is used by the storage nodes when they gossip with each other in order to find and exchange log records that they are missing. </p><h4 id="Commits"><a href="#Commits" class="headerlink" title="Commits"></a>Commits</h4><p>当客户端提交一个事务的时候，线程会记录一个 commit LSN，然后将它放到事务提交等待队列中，然后就继续其他工作。这等价于 WAL 协议：当且仅当最新的 VDL 大于等于 commit LSN 的时候，事务就提交完成了。</p><p>随着 VDL 的推进，数据库识别出这些已经提交完成了的事务，通过单独的线程将提交确认返回给正在等待的客户端。而之前说的工作线程依旧不会做这样的事情，它只是不停地 pull 其他的请求，然后处理。</p><h4 id="Reads"><a href="#Reads" class="headerlink" title="Reads"></a>Reads</h4><p>Aurora 中也有一个 buffer cache。在传统数据库中，从 buffer cache 中 evict page，如果此 page 是个脏页，那么就会先 flush，然后再在 buffer cache 中替换这个页面。Aurora 并没有这种 evect 机制，但是也保证 cache 中的数据页一定是最新的版本。Aurora 的保证是只有在 page LSN 大于等于 VDL 的时候，才会去 evict 这个 page。其中 page LSN 表示最新一次对这个 page 修改的 log record 的 LSN。这个 protocal 保证了：</p><ol><li>所有对这个 page 的修改都被持久化了</li><li>在 cache miss 的时候，只需要通过当前的 VDL 请求当前 page 的 version，就可以获得最新的 durable version</li></ol><p>大部分时候的读取都不需要 read quorum。从磁盘读取时，构造一个 read-point，表示读取时候的 VDL。The database can then select a storage node that is complete with respect to the read point, knowing that it will therefore receive an up to date version. A page that is returned by the storage node must be consistent with the expected semantics of a mini-transaction (MTR) in the database. Since the database directly manages feeding log records to storage nodes and tracking progress (i.e., the SCL of each segment), it normally knows which segment is capable of satisfying a read (the segments whose SCL is greater than the read-point)，所以可以向一个有足够数据的 segment 发送读请求。</p><p>假设数据库知道所有的 outstanding reads，他就计算任意时间点每个 PG 上的 Minimum Read Point LSN。If there are read replicas the writer gossips with them to establish the per-PG Minimum Read Point LSN across all nodes. 这些值称为 Protection Group Min Read Point LSN(PGMRPL)，代表了一个 low watermark，这个 PG 上低于这个 mark 的所有 log record 都是不必要的了。换句话说，没有 read-point 低于 PGMRPL 的 read page 请求了。因此，数据库可以 advance the materialized pages on disk by coalescing the older log records and then 安全地 GC 掉它们。</p><p>实际的并发控制协议是在数据库中执行的，就好像在使用本地存储一样。</p><h4 id="Replicas"><a href="#Replicas" class="headerlink" title="Replicas"></a>Replicas</h4><p>一个共享存储卷上可以挂一个写节点以及15个读节点。【Q】不是很清楚只能挂在一个写节点是怎么做到 Vw = 4 的。</p><p>为了减少 lag，日志流在送给存储节点的同时，也会送给所有的 read replica。【Q】这个 read replica 是啥？是不是指的一种特殊类型的只读节点？</p><p>在 reader 中，数据库会消费 log 流，如果这个 log record 指向了 buffer cache 中的一个 page，就使用 log applicator 去 apply 这个特定的 redo 操作到 cache 中。否则（也就是如果不指向的话），就丢掉这个 log record。</p><p>注意，从 writer 的角度来看 replicas 是异步地消费这些 log record 的。而 writer 在处理用户的事务提交的时候，也是不管 replica 的。因此，就需要引入两条 replica 的规则：</p><ol><li>只有 LSN 小于等于 VDL 的日志才能被 apply</li><li>属于同一个 single mini-transaction 的 log record 要被原子的 apply<br> 这样才能看到一个一致的视图</li></ol><p>在实践中，每个 replica 落后 writer 只有 20ms 左右。</p><h3 id="Recovery"><a href="#Recovery" class="headerlink" title="Recovery"></a>Recovery</h3><p>A great simplifying principle of a traditional database is that the same redo log applicator is used in the forward processing path as well as on recovery where it operates synchronously and in the foreground while the database is offline. We rely on the same principle in Aurora as well, except that the redo log applicator is decoupled from the database and operates on storage nodes, in parallel, and all the time in the background. Once the database starts up it performs volume recovery in collaboration with the storage service and as a result, an Aurora database can recover very quickly (generally under 10 seconds) even if it crashed while processing over 100,000 write statements per second.</p><h1 id="Dynamo"><a href="#Dynamo" class="headerlink" title="Dynamo"></a>Dynamo</h1><p><a href="https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf" target="_blank" rel="noopener">https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf</a></p><h2 id="Intro-2"><a href="#Intro-2" class="headerlink" title="Intro"></a>Intro</h2><p>In this environment there is a particular need for storage technologies that are always available. AWS 对可用性的要求很高。</p><blockquote><p>treats failure handling as the normal case without impacting availability or performance. </p></blockquote><p>Dynamo is used to manage the state of services that have very high reliability requirements and need tight control over the tradeoffs between availability, consistency, cost-effectiveness and performance.</p><p>Dynamo 用了一些经典的技术达到高可用性和可扩展性：</p><ol><li>一致性哈希</li><li>object versioning 实现一致性<br> 给的论文是 Lamport clock</li><li>quorum-like technique 保证一致性，以及 decentralized replica synchronization protocol</li><li>基于 gossip 的分布式 failure 检测和 membership protocol</li></ol><p>它的一个贡献是介绍如何评估不同的技术对于搭建一个高可用性的最终一致的 KV 存储的作用，以及这个系统最终的适用性。</p><h2 id="BACKGROUND"><a href="#BACKGROUND" class="headerlink" title="BACKGROUND"></a>BACKGROUND</h2><p>对关系型数据库的评论：</p><ol><li>很多需要持久化状态的服务只需要主键，不需要 rdbms 的复杂功能</li><li>rdbms 的 replication 性能有限，牺牲 availbility 换 consistency。在 scale-out 和 smart partitioning 这一款不是很好</li></ol><h3 id="System-Assumptions-and-Requirements"><a href="#System-Assumptions-and-Requirements" class="headerlink" title="System Assumptions and Requirements"></a>System Assumptions and Requirements</h3><p>查询模型：简单的主键读写。1MB 左右的 blob。没有操作跨越多个 data items。</p><p>ACID 性质：不提供任何 I 的保证，只允许 single key updates。</p><p>Efficiency：满足 SLA。</p><h3 id="Service-Level-Agreements-SLA"><a href="#Service-Level-Agreements-SLA" class="headerlink" title="Service Level Agreements (SLA)"></a>Service Level Agreements (SLA)</h3><p>To guarantee that the application can deliver its functionality in a bounded time, each and every dependency in the platform needs to deliver its functionality with even tighter bounds.</p><p>客户和提供商会签 SLA 契约，里面包含了客户期望某个 API 的 request rate distribution，以及这些条件下的 service latency。比如，某个 API 在多少 QPS 下，99.9% 的请求的耗时都在 300ms 内。</p><p>下面讲述了为什么选择 P99.9 作为 SLA 的指标，就不翻译了。这个做法是基于一个 cost-benefit analysis 得到的。</p><blockquote><p>A common approach in the industry for forming a performance oriented SLA is to describe it using average, median and expected variance. At Amazon we have found that these metrics are not good enough if the goal is to build a system where all customers have a good experience, rather than just the majority. For example if extensive personalization techniques are used then customers with longer histories require more processing which impacts performance at the high-end of the distribution. An SLA stated in terms of mean or median response times will not address the performance of this important customer segment. To address this issue, at Amazon, SLAs are expressed and measured at the 99.9th percentile of the distribution. </p></blockquote><p>Dynamo 的一个主要的设计考虑是让用户来控制系统的特性比如 consistency 和 durability，并且让服务自己去在 functionality、performance 和 const-effectiveness 之间权衡。</p><h3 id="Design-Considerations"><a href="#Design-Considerations" class="headerlink" title="Design Considerations"></a>Design Considerations</h3><p>首先提了下 CAP 理论。那么对于容易发生机器和网络故障的系统来说，可用性可以通过 optimistic replication 技术提高。这种技术需要发现并且 resolve conflict changes。这个过程包含两部分：</p><ol><li>when to resolve them</li><li>who resolves them</li></ol><h4 id="when"><a href="#when" class="headerlink" title="when"></a>when</h4><p>很多关系型数据库在写入阶段处理，这样 read 的复杂度更低。这种情况下，如果写入不能到达所有或者大多数 replica 时，会被拒绝。</p><p>另一方面，Dynamo 面向一个 “always writeable” 的 data store。所以，Dynamo 会将 conflict resolution 推到 read 阶段，让 write 不被拒绝。</p><h4 id="who"><a href="#who" class="headerlink" title="who"></a>who</h4><p>如果让 data store 来做，那么选择就很有限。一般来说，只能用诸如 last write wins 这种 simple polocy。</p><p>另一方面，因为应用程序知道 data schema，所以更加适合。比如应用程序维护了客户的购物车，在遇到冲突的时候，可以选择 “merge” 购物车的内容。</p><h4 id="另外的一些-Key-priciples"><a href="#另外的一些-Key-priciples" class="headerlink" title="另外的一些 Key priciples"></a>另外的一些 Key priciples</h4><p>Incremental scalability: Dynamo should be able to scale out one storage host(后面简称为 node) at a time.</p><p>Symmetry: 每个节点的职责应该是相同的。目的是简化系统交付和运维。</p><p>Decentralization: 在过去，集中化控制导致了 outage，我们想避免。这产生了更简单，易于扩展，并且可用性更好的系统。</p><p>Heterogeneity: 系统要能利用基础设施的异构性。比如添加了更牛逼的节点之后，系统能够适配，比如给它更多的活这样。</p><h2 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h2><h3 id="Peer-to-Peer-Systems"><a href="#Peer-to-Peer-Systems" class="headerlink" title="Peer to Peer Systems"></a>Peer to Peer Systems</h3><h3 id="Distributed-File-Systems-and-Databases"><a href="#Distributed-File-Systems-and-Databases" class="headerlink" title="Distributed File Systems and Databases"></a>Distributed File Systems and Databases</h3><h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p>Dynamo differs from the aforementioned decentralized storage systems in terms of its target requirements. </p><ol><li>First, Dynamo is targeted mainly at applications that need an “always writeable” data store where no updates are rejected due to failures or concurrent writes. This is a crucial requirement for many Amazon applications.</li><li>Second, as noted earlier, Dynamo is built for an infrastructure within a single administrative domain where all nodes are assumed to be trusted. </li><li>Third, applications that use Dynamo do not require support for hierarchical namespaces (a norm in many file systems) or complex relational schema (supported by traditional databases). </li><li>Fourth, Dynamo is built for latency sensitive applications that require at least 99.9% of read and write operations to be performed within a few hundred milliseconds. To meet these stringent latency requirements, it was imperative for us to avoid routing requests through multiple nodes (which is the typical design adopted by several distributed hash table systems such as Chord and Pastry). This is because multihop routing increases variability in response times, thereby increasing the latency at higher percentiles. Dynamo can be characterized as a zero-hop DHT, where each node maintains enough routing information locally to route a request to the appropriate node directly.</li></ol><h2 id="SYSTEM-ARCHITECTURE"><a href="#SYSTEM-ARCHITECTURE" class="headerlink" title="SYSTEM ARCHITECTURE"></a>SYSTEM ARCHITECTURE</h2><p><img src="/img/dbpaper/dynamo/t1.png"></p><h3 id="System-Interface"><a href="#System-Interface" class="headerlink" title="System Interface"></a>System Interface</h3><ol><li>get(key)<br> 返回一个对象。如果有冲突版本，就返回一个对象列表。还会返回 context，从后文来看，无论返回的是对象还是对象列表，都会返回一个 context 实例。</li><li>put(key, context, object)<br> context 对调用者透明，包含了系统元数据比如 version。</li></ol><h3 id="Partitioning-Algorithm"><a href="#Partitioning-Algorithm" class="headerlink" title="Partitioning Algorithm"></a>Partitioning Algorithm</h3><p>优化了基础的一致性哈希：每个 Dynamo 节点映射到环上的多个点。</p><p>原因是存储的硬件是异构的，厉害的人可以做更多的事情。所以 Dynamo 引入了 virtual node。一个 dynamo node 可以管理多个 virtual node。</p><p>虚拟节点的好处：</p><ol><li>If a node becomes unavailable (due to failures or routine maintenance), the load handled by this node is evenly dispersed across the remaining available nodes.</li><li>When a node becomes available again, or a new node is added to the system, the newly available node accepts a roughly equivalent amount of load from each of the other vailable nodes.</li><li>The number of virtual nodes that a node is responsible can decided based on its capacity, accounting for heterogeneity in the physical infrastructure.</li></ol><h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>每个 key k 会被分配到一个 coordinator node 上。coordinator 不仅会自己存储 key，而且会将它们复制到顺时方向的后 N-1 的 node 上。所以，每个 node 实际要存储 N 个 node 上的数据。比如下图中的 node D 需要存储 (A, D] 上的数据。</p><p><img src="/img/dbpaper/dynamo/rep.png"></p><p>对于每一个 key，它被存储在多个 node 上，这些 node 形成一个 preference list。Section 4.8 会讲到如何维护这个表，现在需要知道的是为了处理 node failure 的情况，这个列表里面可能存放超过 N 个 node。</p><p>另外，使用 virtual node 的时候，可能根本没有 N 个 dynamo node 存储这 N 个 virtual node。比如一个 dynamo node 上存了几个 virtual node。【Q】我觉得也太扯了，一个 key 在同一个机器上存几份，即使是集群比较早期的状态，意义何在？Dynamo 也意识到了这个问题。为了避免这个问题，preference list 在选择节点的时候会跳过一些位置，确保 list 里面的节点在不同的物理节点上。</p><h3 id="Data-Versioning"><a href="#Data-Versioning" class="headerlink" title="Data Versioning"></a>Data Versioning</h3><p>一个 put() 可能在被 apply 到所有 node 之前就返回给 caller 了。这会导致后续的 get() 操作返回一个比较旧的 object。 如果没有网络问题，那么传递更新的耗时是有个上限的，但如果服务器宕机了，或者网络分区，那么更新就不能够及时到达所有的 replica。</p><p>很多应用程序是能够容忍这个 inconsistency 的。比如对于 shopping cart 来说，如果最新的版本没有拿到，并且客户又是基于一个旧版本进行的修改，那么这个修改依旧是有意义的，并且要被保留。当然这种保留并不是去覆盖，而更可能是 merge。注意，无论是添加到购物车，还是从购物车删除，对于 Dynamo 而言都是 put 操作。</p><p>Dynamo 将所有修改视为一个新的 immutable 的版本。也就是说允许一个对象在同一时间有多个版本。一般情况下，新版本跟随旧版本，此时系统能够知道谁是 authoritative version，我们称之为 syntactic reconciliation。但是 version branching 可能发生，比如 concurrent update 的时候出现了 failure。在这种情况下，系统不能处理，client 需要 reconcile，从而将多个 branch 坍缩回单个 version，称为 semantic reconciliation。比如 merge 购物车这样。当然，</p><p>Dynamo 使用向量时钟。一个向量时钟是一个 (node, counter) 列表。一个向量时钟和每个 object 的每个版本相关联。可以通过向量时钟判断两个 version 之间的因果性。如果在第一个 object 上的 vector clock 都不大于第二个 clock，那么第一个就是第二个的祖先。否则，就是冲突状态，需要 reconciliation。 这样 “add to cart” 操作就永远不会被丢掉，但是 deleted items can resurface.</p><p>It is important to understand that certain failure modes can potentially result in the system having not just two but several versions of the same data. Updates in the presence of network partitions and node failures can potentially result in an object having distinct version sub-histories, which the system will need to reconcile in the future. This requires us to design applications that explicitly acknowledge the possibility of multiple versions of the same data (in order to never lose any updates).  </p><p>Dynamo 中，如果 client 需要更新一个 object，就需要指定基于哪个 version 更新。这是通过从上一次 read 时候获得的 context 得到的。在处理一个 read 请求时，如果 Dynamo 可以访问多个 branch，并且不能 syntactically reconciled，就会返回所有叶子节点上的对象，以及对应的 version information。使用这个 context 的 update 会被认为是已经 reconcil 了 divergent 的 version，并且所有的 branch 都坍缩回到一个单一的 version。</p><p>下面是一个 demo。Sx、Sy、Sz 都是节点。</p><ol><li>Sx 处理写入，会自增自己的 seq，然后用它来创建数据的 vector clock，因此系统中有了对象 D1 以及关联的时钟 [(Sx, 1)]</li><li>现在 client 又更新了对象，假如说又是 Sx 来处理了，那么系统中就有了 D2 和它的关联时钟 [(Sx, 2)]<br> 注意，D2 “decendant” 了 D1，所以 overwrite 了 D1，当然有的 replica 可能认为 D1 还在，也就是没见到 D2。</li><li>不如假设此时 client 又更新了，这时候 Sy 来处理了。此时得到 D3 和 [(Sx, 2), (Sy, 1)]<br> 显然这里 Sy 知道了 D2 的存在。</li><li>假设后续<strong>另一个</strong> client 读到了 D2，然后进行了更新，由 Sz 来处理。得到了 D4 和 [(Sx, 2), (Sz, 1)]。</li></ol><p>此时，一个能看到 D1 和 D2 的 node，在收到 D4 和它的时钟之后，可以发现 D1 和 D2 是可以被覆盖的。但是如果一个节点只看到了 D3，在收到 D4 之后会发现 D3 和 D4 之间没有因果关系。这个时候，两个数据都要保留，然后给 client 在下一次读的时候做 semantic reconciliation。</p><p>假设某个 client 同时读到了 D3 和 D4，此时 context 是 [(Sx, 2), (Sy, 1), (Sz, 1)]。如果这个 client 执行了 reconciliation，并且 Sx coordinate 了这个 write（也就是 client 处理完是 Sx 负责的写入），Sx 就会更新自己的 seq，所以新的 D5 的 clock 就是 [(Sx, 3), (Sy, 1), (Sz, 1)].</p><p><img src="/img/dbpaper/dynamo/3.png"></p><p>Vector clock 的一个问题是它可能会变大，特别是有很多 server 对同一个 object 操作的时候。但是在实践中并不经常发生，因为写入通常是由 preference list 里面的 top N nodes 中的某一个处理的。在网络分区的时候，可能是某个不在 top N nodes 里面的节点处理，从而导致 vector clock 列表变长。在这种情况下，Dynamo 有一个 truncation scheme: 对于每个 (node, counter) 对，记录一个 Timestamp，表示上一次这个 node 更新的时间。当这个 vector clock 中的 (node, pair) 对的数量超过一个阈值，比如 10 的时候，最老的 pair 就会被移动出去。</p><p>当然这个会导致 reconciliation 的时候的一些不便利的情况，比如 decendant relationship 就不能被准确推断出来。但反正生产环境也没发现有这个问题。</p><h3 id="Execution-of-get-and-put-operations"><a href="#Execution-of-get-and-put-operations" class="headerlink" title="Execution of get () and put () operations"></a>Execution of get () and put () operations</h3><p>Dynamo 的任何 storage 节点都可以接受 client 的 get 和 put 请求。有两种选择 node 的方式：</p><ol><li>通过一个通用的 load balancer</li><li>如果 client 知道 partition 的信息，就可以直接请求 coordinator node</li></ol><p>第一种方式不需要了解 Dynamo 的实现，第二种可以避免额外一次的转发。</p><p>处理读写操作的节点是 coordinator。通常是 preference list 里面 top N nodes 的第一个。</p><p>读和写会涉及 preference list 中的前 N 个健康的 node。如果有 node 处于 failure 或者网络分区状态，那么 preference list 上更低 rank 的 node 就会被访问。</p><p>Dynamo 使用 RWN 协议来管理一致性。</p><h3 id="Handling-Failures-Hinted-Handoff"><a href="#Handling-Failures-Hinted-Handoff" class="headerlink" title="Handling Failures: Hinted Handoff"></a>Handling Failures: Hinted Handoff</h3><p>介绍了 Sloppy Quorum 的方案。虽然所有的读写都需要在使用 preference list 上的 top N 健康 nodes。但是它们并不一定是顺着一致性哈希那个环来的 N 个。</p><p>Consider the example of Dynamo configuration given in Figure 2 with N=3. In this example, if node A is temporarily down or unreachable during a write operation then a replica that would normally have lived on A will now be sent to node D. This is done to maintain the desired availability and durability guarantees. The replica sent to D will have a hint in its metadata that suggests which node was the intended recipient of the replica (in this case A). Nodes that receive hinted replicas will keep them in a separate local database that is scanned periodically. Upon detecting that A has recovered, D will attempt to deliver the replica to A. Once the transfer succeeds, D may delete the object from its local store without decreasing the total number of replicas in the system. </p><p>Dynamo 通过 Hinted Handoff 摆正即使有节点临时故障，读写请求也不会 fail。</p><h3 id="Handling-permanent-failures-Replica-synchronization"><a href="#Handling-permanent-failures-Replica-synchronization" class="headerlink" title="Handling permanent failures: Replica synchronization"></a>Handling permanent failures: Replica synchronization</h3><p>一些场景中，当 hinted 副本移交回原 node 之前，这个副本就不可用了，这影响持久性。Dynamo 使用一个 anti-entropy 的 replica synchronization protocol 去做到这一点。</p><p>Dynamo 使用 Merkle tree 去发现不一致。这棵树是有关哈希值的，叶子节点是每个 key 的哈希值。上层的节点是它们各自孩子的哈希值。Merkle 树可以独立检查每个分支，而不需要下载整棵树下来。</p><p>Merkle 树还能帮助减少传递的数据量。这是因为它的性质，比如如果两个树的 root 上存的 hash 是相等的，那么两棵树就是相等的。因此，就不需要传输这些数据了。如果不相等，就继续往下比较，看看是哪里的问题。</p><p>Dynamo 对 Merkle 树的具体用法是，每个 node 上为每一段 key-range（对于一个 virtual node 的范围）维护一棵独立的树。因此，node 之间是可以比较 key range 的。</p><p>当有成员变更的时候，有些 key-range 可能会变，因此对应的 Merkle tree 要重新计算。</p><h3 id="Membership-and-Failure-Detection"><a href="#Membership-and-Failure-Detection" class="headerlink" title="Membership and Failure Detection"></a>Membership and Failure Detection</h3><h4 id="Ring-Membership"><a href="#Ring-Membership" class="headerlink" title="Ring Membership"></a>Ring Membership</h4><p>管理员通过命令行或者 Web UI 的方式发起一个 membership change 命令。这个命令也会被写入 Dymano 的存储。所有的成员变动会形成历史记录。Dynamo 使用 gossip 算法来 propagate 成员变动消息，维护一份最终一致视图。</p><p>当一个 node 启动时，它会扫描一致性哈希空间中的 virtual nodes 称为 token，它会选出一些，然后 maps nodes to their respective token sets.</p><p>这个 mapping 信息是存在磁盘上的，一开始只有本地的节点，以及 token set。节点和 token set 的映射是在和 membeiship change 一起 reconcil 的。因此，partitioning 和 placement 信息也会被 propagate，让每个 storage node 都了解 token range 信息。因此，每个 node 都能把读写请求 forward 到正确的节点集合中。</p><h4 id="External-Discovery"><a href="#External-Discovery" class="headerlink" title="External Discovery"></a>External Discovery</h4><p>上述的机制可能导致暂时的逻辑分裂。</p><p>比如管理员先添加了 node A，然后立即添加了 node B，这个时候 A 和 B 都是哈希环的成员，但是却不能立即感知到对方。</p><p>因此 Dynamo 加入了种子节点，这些节点是通过外部的机制直接指定的，对所有的节点都是可知的。因为最终所有的 node 都会和种子节点通信，因此逻辑分裂是不太可能的。</p><p>种子节点可以通过静态文件，或者配置服务来获得。</p><h4 id="Failure-Detection"><a href="#Failure-Detection" class="headerlink" title="Failure Detection"></a>Failure Detection</h4><p>如果用户的请求是持续发过来的，node A 就能够快速发现 node B 不能响应了，当 B 开始无法回复一个 message 的时候。</p><p>In the absence of client requests to drive traffic between two nodes, neither node really needs to know whether the other is reachable and responsive.</p><p>Dynamo 早期有一个 decentralized failure detector 去维护一个 globally consistent view of failure state。但后面发现，explicit node join and leave 方案下，就不再需要这个 global view 了。这是因为通过这个机制，node 就能知道哪些 node 永久上线或者下线了。对于临时的 node failure，当哪个节点连不上的时候，就会独自发现了。</p><h3 id="Adding-Removing-Storage-Nodes"><a href="#Adding-Removing-Storage-Nodes" class="headerlink" title="Adding/Removing Storage Nodes"></a>Adding/Removing Storage Nodes</h3><p>当一个新的 node 比如 X 被加入到系统之后，它被分配一系列 token。这些 token 在 ring 上是散落分布的。此时，对于每个 token，有小于等于 N 个 node 已经在管理这 token 对应的 key-range 了。这些 node 中有一些就不会再管理了，要把 key-range 转给 X。</p><p>比如，X 加入 A 和 B 中间，这样 X 就会处理 (F, G], (G, A] 和 (A, X] 之间的 key 了。结果 B、C、D 节点就不需要负责对应的 range 了。Therefore, nodes B, C, and D will offer to and upon confirmation from X transfer the appropriate set of keys. When a node is removed from the system, the reallocation of keys happens in a reverse process.<br><img src="/img/dbpaper/dynamo/rep.png"></p><p>通过在 source 和 destination 之间增加一个  confirmation round，可以避免 destination node 不会收到 duplicate transfers。</p><h2 id="IMPLEMENTATION"><a href="#IMPLEMENTATION" class="headerlink" title="IMPLEMENTATION"></a>IMPLEMENTATION</h2><p>前面略。主要介绍下 write coordination。</p><p>如前面所说，write 请求会被某个 top N nodes 来 coordinate。尽管我们希望去选择 first node，从而将所有的 write 都写到同一个地方，但这会导致不平衡的 load distribution。因为请求本身就不一定是均匀分布的。因此，preference list 中 top N 的任意节点都是可以被返回的。特别地，因为每个 write 请求通常是在一个 read 请求之后的，所以 write 的 coordinator 通常会选择上一次 read 中回复最快的那个 node。</p><p>这样的优化还能使得下一次读取的时候，这个节点更容易被选中，提高了 read-your-writes 一致性的概率。</p><h2 id="EXPERIENCES-amp-LESSONS-LEARNED"><a href="#EXPERIENCES-amp-LESSONS-LEARNED" class="headerlink" title="EXPERIENCES &amp; LESSONS LEARNED"></a>EXPERIENCES &amp; LESSONS LEARNED</h2><p>Dynamo 的最大优势是客户可以通过调节 N、R、W 来达到期望的性能、可用性和持久性等级。</p><p>AWS 最常用的 Dynamo 集群是 (3, 2, 2) 的。</p><h3 id="Balancing-Performance-and-Durability"><a href="#Balancing-Performance-and-Durability" class="headerlink" title="Balancing Performance and Durability"></a>Balancing Performance and Durability</h3><p>Since Dynamo is run on standard commodity hardware components that have far less I/O throughput than high-end enterprise servers, providing consistently high performance for read and write operations is a non-trivial task. The involvement of multiple storage nodes in read and write operations makes it even more challenging, since the performance of these operations is limited by the slowest of the R or W replicas.</p><p>在一些场景下，用户愿意牺牲持久性去换取更高的性能。此时，每个 storage node 可以维护一个 object buffer。每个操作会先存在 buffer 中，然后通过一个 writer 线程去写入到 storage 里面。这个优化可以将峰值流量期间的 P99.9 下降到原来的 1/5，并且只需要一个存放 1000 个对象的缓存即可。从图中还能看到，write buffering 能够对 P99.9 进行平滑。</p><p>当然，这种情况下，只需要一个节点挂掉，那么对应缓存里面的没有落盘的数据就消失了。To reduce the durability risk, the write operation is refined to have the coordinator choose one out of the N replicas to perform a “durable write”. Since the coordinator waits only for W responses, the performance of the write operation is not affected by the performance of the durable write operation performed by a single replica. </p><p><img src="/img/dbpaper/dynamo/5.png"></p><p>【Q】这里的意思我理解照样是写 W 个结果就返回了，写盘的那个节点很慢，但是我们不一定需要它成为那 W 个中的一个，我理解是这样。</p><h3 id="Ensuring-Uniform-Load-distribution"><a href="#Ensuring-Uniform-Load-distribution" class="headerlink" title="Ensuring Uniform Load distribution"></a>Ensuring Uniform Load distribution</h3><h3 id="Divergent-Versions-When-and-How-Many"><a href="#Divergent-Versions-When-and-How-Many" class="headerlink" title="Divergent Versions: When and How Many?"></a>Divergent Versions: When and How Many?</h3><p>从实验上来看，导致版本分叉增多的原因并不是故障，而是并发写数量的增加。</p><h3 id="Client-driven-or-Server-driven-Coordination"><a href="#Client-driven-or-Server-driven-Coordination" class="headerlink" title="Client-driven or Server-driven Coordination"></a>Client-driven or Server-driven Coordination</h3><p>每个 Dynamo 节点都可以充当 read coordinator，但是只有 preference list 中的 node 才能当 write coordinator。这是因为这些 node 可以生成一个 version stamp，从而 causally subsumes the version that has been updated by the write request. 特别地，如果 Dynamo 的 versioning scheme 是基于物理时钟的，那么任何的节点都可以 coordinate 一个写入请求了。当然我个人理解就需要要原子钟那一套了。</p><p>另一种 request coordination 的方式是将 state machine 移动到 client node 上。客户端阶段性请求一个 Dynamo 节点，获取 membership 状态。这样的好处是能减少一跳。另一个重要的优势是，不再需要一个 load balancer 去均匀分发客户的负载了。</p><p>这个方案的劣势是 membership 不一定是最新鲜的。</p><h3 id="Balancing-background-vs-foreground-tasks"><a href="#Balancing-background-vs-foreground-tasks" class="headerlink" title="Balancing background vs. foreground tasks"></a>Balancing background vs. foreground tasks</h3><p>To this end, the background tasks were integrated with an <strong>admission control mechanism</strong>. Each of the background tasks uses this controller to reserve runtime slices of the resource (e.g. database), shared across all background tasks. A feedback mechanism based on the monitored performance of the foreground tasks is employed to change the number of slices that are available to the background tasks.</p><p>The admission controller constantly monitors the behavior of resource accesses while executing a “foreground” put/get operation. Monitored aspects include latencies for disk operations, failed database accesses due to lock-contention and transaction timeouts, and request queue wait times. This information is used to check whether the percentiles of latencies (or failures) in a given trailing time window are close to a desired threshold. For example, the background controller checks to see how close the 99th percentile database read latency (over the last 60 seconds) is to a preset threshold (say 50ms). The controller uses such comparisons to assess the resource availability for the foreground operations. Subsequently, it decides on how many time slices will be available to background tasks, thereby using the feedback loop to limit the intrusiveness of the background activities. Note that a similar problem of managing background tasks has been studied in [4]. </p><h1 id="Wisckey"><a href="#Wisckey" class="headerlink" title="Wisckey"></a>Wisckey</h1><p><a href="https://dl.acm.org/doi/pdf/10.1145/3033273" target="_blank" rel="noopener">https://dl.acm.org/doi/pdf/10.1145/3033273</a></p><h2 id="Intro-3"><a href="#Intro-3" class="headerlink" title="Intro"></a>Intro</h2><p>LSM 相对于其他索引结构的优点是它为写操作提供了顺序访问。B 树上的更新可能包含很多随机写入，在 HDD 和 SDD 上的效率都不高。</p><p>为了支持有效率的查询，LSM 需要在后台进行 compaction，让 key-value 对们是 sorted 的。因此这带来了 50x 甚至更高的写放大。</p><p>在 HDD 上，随机 IO 比顺序 IO 慢了 100 倍，因此 performing additional sequential reads and writes to continually sort keys and enable efficient lookups represents an excellent tradeoff.</p><p>SSD 和 HDD 存在不同：</p><ol><li>SDD 上顺序写和随机写的差异不如 HDD 那么大<br> 因此，执行大量的顺序 IO，从而避免后续的随机 IO，可能会浪费不少带宽</li><li>SSD 的 internal parallelism 很高</li><li>SSD 会因为反复写入磨损，LSM 的写放大会降低寿命</li></ol><p>WiscKey 被设计来解决 SSD 上的这些问题。WiscKey 是键值分离的，键在 LSM 树上保持有序，Value 单独存在一个 log 中。换句话说，WiscKey 解耦了 key sorting 和 GC，而 LevelDB 将它们打包在了一起。这减少了在 sort 的时候移动 value 的写放大。特别地，这也减少了 LSM 树的大小，减少了 device read 的数量，也能让 lookup 的时候 cache 的效果更好。</p><p>这存在一些挑战：</p><ol><li>range query 的性能会收到影响，因为 value 不再是有序存储的了<br> 在 <a href="https://docs.pingcap.com/zh/tidb/stable/titan-overview" target="_blank" rel="noopener">Titan</a> 的评测中，可以从 scan100 和 scan1000 中明显看到这一点。特别是小行宽、扫描行数多的情况下，Titan 劣势明显。<br> WiscKey 的方案是利用了 SSD 的冗余的 internal parallellism。</li><li>WiscKey 需要 GC 去回收 invalid 的 value<br> 它提出了一个轻量级的 online GC。它只需要顺序的 IO，对前台影响很有限。</li><li>Key value 分离让 crash consistency 更有挑战性<br> WiscKey 利用了现代文件存储中的一个特性，也就是 append 操作永远不会在崩溃的时候产生垃圾数据。</li></ol><h2 id="BACKGROUND-AND-MOTIVATION"><a href="#BACKGROUND-AND-MOTIVATION" class="headerlink" title="BACKGROUND AND MOTIVATION"></a>BACKGROUND AND MOTIVATION</h2><h3 id="LSM"><a href="#LSM" class="headerlink" title="LSM"></a>LSM</h3><h3 id="LevelDB"><a href="#LevelDB" class="headerlink" title="LevelDB"></a>LevelDB</h3><h3 id="Write-and-Read-Amplification"><a href="#Write-and-Read-Amplification" class="headerlink" title="Write and Read Amplification"></a>Write and Read Amplification</h3><p>Write (read) amplification is defined as the ratio between the amount of data written to (read from) the underlying storage device and the amount of data requested by the user.</p><p>LSM 写放大高的原因是从 Li-1 层合并到 Li 层的时候，LevelDB 最坏情况下要读取 Li 层的全部 10 个文件，并在排序后重新写回 Li 层，从而产生 10 倍的写放大。</p><p>LSM 中存在两种读放大：</p><ol><li>读一个 KV 的时候，LSM 可能要查询多个层级<br> Tier 层的 8 个文件加上 Leveled 层每一级的一个文件，总共可以是 14 个 SST 文件最多</li><li>在 SST 中查找 KV，要读取多个元数据块<br> 包含 index block + bloom-filter block + data block。<br> 例如，查找 1KB 的键值对，要读 16KB 的 index block，4KB 的 bloomfilter 和 4KB 的 data block，总共 24KB。</li></ol><p>两个开销加起来，读放大能到 336。更小的 KV 会产生更高的读放大。</p><p>如下图所示：</p><ol><li>写放大随着数据库大小增加的原因是从低 level 到高 level 压缩会多次写入。因为高 level 被 compact 了，文件平均数通常小于最坏情况的 10 个，因此没有达到最劣的情况</li><li>对于大数据来说，如果读取涉及到多个 SST 文件，而内存又不够存储所有的 SST 文件的 index block 和 bloom-filter，那么每次读取都会造成开销。</li></ol><p><img src="/img/dbpaper/wisckey/1.png"></p><p>It should be noted that the high write and read amplifications are a justified tradeoff for hard drives. As an example, for a given hard drive with a 10ms seek latency and a 100MB/s throughput, the approximate time required to access a random 1K of data is 10ms, while that for the next sequential block is about 10μs—the ratio between random and sequential latency is 1,000:1. Hence, compared to alternative data structures such as B-trees that require random write accesses, a sequential-write-only scheme with write amplification less than 1,000 will be faster on a hard drive. On the other hand, the read amplification for LSM-trees is still comparable to B-trees. For example, considering a B-tree with a height of five and a block size of 4KB, a random lookup for a 1KB key-value pair would require accessing six blocks, resulting in a read amplification of 24. </p><h3 id="Fast-Storage-Hardware"><a href="#Fast-Storage-Hardware" class="headerlink" title="Fast Storage Hardware"></a>Fast Storage Hardware</h3><p>不同于 HDD，相比于顺序读取，随机读取性能在 SSD 上的表现更好。特别是如果随机读取是并发被执行的话，对于某些 workload 来说，总的 throughput 甚至能接近顺序存储。<br><img src="/img/dbpaper/wisckey/5.png"></p><h2 id="WISCKEY"><a href="#WISCKEY" class="headerlink" title="WISCKEY"></a>WISCKEY</h2><p>复读了一遍 intro。</p><h3 id="Design-Goals"><a href="#Design-Goals" class="headerlink" title="Design Goals"></a>Design Goals</h3><p>WiscKey 是一个单机的 persistent KV Store，从 LevelDB derive 出来。提供了类似 LevelDB 的 Put、Get、Delete 和 Scan 接口。</p><p>设计的主要目标：</p><ol><li>Low write amplification<br> 避免浪费带宽、减少寿命。</li><li>Low read amplification<br> 避免降低吞吐、低效缓存。</li><li>SSD optimized</li><li>Feature-rich API</li><li>Realistic key-value sizes</li></ol><h3 id="Key-Value-Separation"><a href="#Key-Value-Separation" class="headerlink" title="Key-Value Separation"></a>Key-Value Separation</h3><p>对于一个有 16Bytes 大小的 key，1KB 大小的 value，key 写放大 10，value 写放大 1 的 WiscKey 来说，总的写放大是 <code>(10 * 16 + 1024) / (16 + 1024) = 1.14</code>。</p><p>WiscKey 较小的读放大能提高性能。虽然需要一次额外的 IO 去取 value，但是因为 WiscKey 上的 LSM 要更小，所以一次查询可能只会搜更少的 SST 文件。进一步的，LSM 的一部分甚至可以被缓存在内存里面，因此一次查询可能只需要一个随机读用来取回 value。</p><p>WiscKey 的架构如下所示。<br><img src="/img/dbpaper/wisckey/6.png"></p><p>当用户写入 KV 的时候，value 首先被写入 vLog，然后 key 被加入 LSM，附带上 value 在 vLog 上的信息 <code>&lt;vLog-offset, value-size&gt;</code>。删除一个 key 只需要在 LSM 上删除就行了。在 vLog 中的 value 会在稍后被 GC 掉。</p><p>在读取时，首先读取 LSM 的地址，然后到 vLog 里面找 value。</p><h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h3><h4 id="Parallel-Range-Query"><a href="#Parallel-Range-Query" class="headerlink" title="Parallel Range Query"></a>Parallel Range Query</h4><p>为了使 scan 更高效，WiscKey 需要利用 SSD 的并行 IO 特性去 prefetch vLog 中的 value。</p><p>如果 user 请求一个 range 查询，Scan 会返回一个迭代器。WiscKey 会跟踪这个 range query 的 access pattern。一旦它开始请求一个 contiguous sequence of KV pairs，WiscKey 会开始顺序地从 LSM 读取一系列 key。因此，对应的 value 地址会被添加到队列里面，多个线程会从 vLog 中并行地获取这些 value。</p><h4 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h4><p>在 LSM 的 compaction 中，WiscKey 不会同时回收 value。</p><p>一个简单的从 vLog 回收的方式是，首先扫描 LSM 拿到所有有效的 value 地址，然后 vLog 中没有被 LSM 引用的 value 就会被回收掉。显然这个方式很重，最关键的是，它只能适用于 offline 的场景。</p><p>WiscKey 的方案需要引入一个小的 data layout 变动。在存储 value 的时候，同时也要存储对应的 key。也就是 <code>&lt;key size, value size, key, value&gt;</code>。</p><p>WiscKey 的思路是让 valid 的值在 vLog 中处于一个连续的区段内。在这个区段的一端，也就是 head 的位置，是新的 value 被 append 的地方。在这个 range 的另一端，也就是 tail 的位置，是 GC 开始释放空间的位置。只有在 head 和 tail 之间包含了 valid 的 value 的部分，才可能在查询中被访问。<br><img src="/img/dbpaper/wisckey/7.png"></p><p>在 GC 时，WiscKey 首先会从 tail 读取一个 chunk，比如几个 MB 的 KV 对，然后会查询 LSM 树，看这些 key 是否被删除了。然后 WiscKey 会将 valid 的 key 添加回 head 位置。最后，它更新 tail 的位置，并释放空间。</p><p>为了避免 GC 过程中丢失数据，WiscKey 需要保证新 append 的 valid 的 value 和新的 tail 首先被 persist，然后才能真的去 free 掉 space。WiscKey 的方案是：</p><ol><li>在 appending the valid values to the vLog 之后，GC 会调用一次 fsync</li><li>将这些新的 value 的地址和当前的 tail 同步地写入 LSM 中<br> tail 在 LSM 中存放的格式是 <code>&lt;tail-marker, tail-vLog-offset&gt;</code>。</li><li>最后，在 vLog 中回收空间</li></ol><h4 id="Crash-Consistency"><a href="#Crash-Consistency" class="headerlink" title="Crash Consistency"></a>Crash Consistency</h4><p>WiscKey 保证了和 LSM 树同样的 crash guarantee，原因是利用了现代文件系统的一个特性。考虑一个文件包含了 <code>b1 b2 b3 ... bn</code> 这样的序列，然后后续 append 了 <code>bn+1 bn+2 bn+3 ... bn+m</code> 这些序列。如果发生了 crash，恢复后，会看到 <code>b1 b2 b3 ... bn bn+1 bn+2 bn+3 ... bn+x</code> 这样的序列，并且 x 是小于 m 的。也就是说，实际被添加的只可能是前缀，不可能是某个随机字节，或者多出来添加某些序列。进一步又可以推论，如果 X 在 vLog 中因为 crash 丢失了，那么所有在 X 之后被添加的也会丢失。</p><p>如果 key 在系统 crash 的时候丢失了，如果是 LSM 里面找不到的情况，会按照 LSM 的模式来处理。即使 value 已经被写进去了 vLog，它也可以在随后被 GC 掉。但是如果 LSM 中能找到key，就需要额外步骤。首先 WiscKey 会查询 value 的地址是否在 vLog 的有效范围，也就是 head 到 tail 这个区间内。如果不在，就说明 value 在系统崩溃中丢失了，从 LSM 中删除 key，并且通知用户 key 不存在。</p><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><h4 id="Value-log-Write-Buffer"><a href="#Value-log-Write-Buffer" class="headerlink" title="Value-log Write Buffer"></a>Value-log Write Buffer</h4><h4 id="Optimizing-the-LSM-Tree-Log"><a href="#Optimizing-the-LSM-Tree-Log" class="headerlink" title="Optimizing the LSM-Tree Log"></a>Optimizing the LSM-Tree Log</h4><p>LSM 的 log 中存放了 key 和 value。WiscKey 中 LSM 的 log 只存 key 和 value 的地址。进一步地，vLog 也会记录被插入了的 key，从而更好支持 GC。</p><p>如果在 key 在被持久化到 LSM 之前 crash 了，它们可以从 vLog 中被扫描从而恢复。但简便的做法需要扫描全部的 vLog 才能会的结果。为了减少这一点开销，WiscKey 会定期在 LSM 中记录 vLog 的 head：<code>&lt;head-marker, head-vLog-offset&gt;</code>。【Q】这里可以对比看下记录 head 和 tail 的不同原因。当一个数据库被打开之后，WiscKey 会从最新的 head 开始扫描 vLog，直到 tail。因为 head 被存储在了 LSM 树里面，所以 LSM 就 inherently 能够保证被插入 LSM 的 key 可以按照插入的顺序恢复，从而满足 crash consistency。</p><p>因此，从 WiscKey 中移除 LSM 的 WAL 是一个安全的优化。</p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><h4 id="空间放大"><a href="#空间放大" class="headerlink" title="空间放大"></a>空间放大</h4><p><img src="/img/dbpaper/wisckey/19.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;这篇文章中，包含 Greenplum、Aurora、Dynamo、WiscKey。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>2024 挪威冰岛西班牙</title>
    <link href="http://www.calvinneo.com/2024/10/11/2024_norway_iceland_spain/"/>
    <id>http://www.calvinneo.com/2024/10/11/2024_norway_iceland_spain/</id>
    <published>2024-10-11T01:23:25.000Z</published>
    <updated>2024-11-05T05:43:55.378Z</updated>
    
    <content type="html"><![CDATA[<p>OSLO -&gt; BERGEN -&gt; ICELAND -&gt; BACELONA</p><a id="more"></a><h1 id="挪威"><a href="#挪威" class="headerlink" title="挪威"></a>挪威</h1><h2 id="D0-奥斯陆"><a href="#D0-奥斯陆" class="headerlink" title="D0 奥斯陆"></a>D0 奥斯陆</h2><p>到了奥斯陆，看了下 vy 发现末班车只有不到一个小时了，而现在行李还没拿，以为要来不及了。没想到这里贼方便，行李转盘5分钟就取到了，然后出门就是火车站。我们甚至在倒数第二辆 vy 发车之后一分钟买到了它的票。担心没赶上这车就不能坐了，于是问了个路人小姐姐。路人说她虽然没有试验过，但这是列车公司的错误，导致我们买到了已经出发的列车，因此他们不应该因为这个事情去为难我们。后面我们又问了旁边 flytoget 站台上的工作人员，她和我说只要在某个时间区间范围内乘坐就行了，我们只需要赶上末班车就行。<br>于是上了个厕所就早早下到了站台上。</p><p>宾馆就在车站对面。这个时候路上只有不多的行人了，火车站广场边有一群滑板男孩。这边人过马路是真的不看红绿灯，红灯会亮两盏都拦不住他们。</p><p>我们只需要出示 passport 就可以入住了。这个酒店没有 self service 的 laundry 了。这个房间特别奇葩，一进门右转就是一段下楼的阶梯，上面的玄关连我的大箱子都放不下。<br>这里床是两个小窗拼成的双人床，被子也是一个人一个。窗户对着街道，被用白色塑料布全封住了，但这样还是有不少的噪音。</p><p>这里的水一股苦杏仁味，所以我们没怎么喝。卫生间的墙上贴着告示，说要我们刷牙的时候关水龙头，可以节约多少多少水。</p><h2 id="D1-奥斯陆"><a href="#D1-奥斯陆" class="headerlink" title="D1 奥斯陆"></a>D1 奥斯陆</h2><p>今天在奥斯陆 city walk，顺便逛逛各个场馆。<br>我们的餐厅是有早饭的，并且品种相当丰富，我觉得应该是在西班牙前最丰富的了，取餐区也特别大。</p><p>吃完早饭，打算先逛大教堂，但是大教堂没开门，于是就先买点东西吧。我们买了点巧克力和鱼子酱，完了发现旁边的药妆店还没开门。Anyway，最后我们买了点护肤品，但是很遗憾忘了要退税票了。然后我们就跑去喝 oslo 那边有名的咖啡，我点了个 flat white，我对象点了个那边有特色的咖啡。结果我的 flat white 平平无奇，我对象的咖啡挺好喝的，不过冰块占了很大一部分。我们还点了两个甜点，甜甜圈一样的里面有蛋液，挺香的，另外一个肉桂卷也很好吃，但是太甜了。吃完了刚好可以逛大教堂，这个教堂不是很大，我们很快就出来了。接下来去市政厅，中间路过了奥斯陆的中央公园，以及挪威的皇宫。奥斯陆市政厅在海边，那边游客是比较多的，我们需要排队过一个安检通道才能进去。这边是很多挪威人结婚来的地方，我们遇到了先前在马路上的一对穿着似乎是民族传统服饰结婚的一对情侣，进去之后，在大台阶上，还有另一对情侣也在拍照片。市政厅里面主要是壁画很好看，另外还能看到奥斯陆市议会的房间。</p><p>看完之后，就往奥斯陆美术馆走了，但中途对象发现太阳帽丢了，这可是她赖以生存的宝贝，于是就去市政厅找。结果刚过了安检通道就出来了，看来人家安检员早就在等她了，一眼认出，还和她 say goodbye 了。</p><p>奥斯陆美术馆需要将包和外套都存放在地下室里面的 locker 里面。奥斯陆美术馆会给一个简易的导览地图，上面列出了一些很奇怪的作品。美术馆包含三层楼，很多个房间。这些房间是通过一个两位数阿拉伯数字来标号的，没有一个特别好的一笔画线路，所以瞎逛是 OK 的。</p><p>美术馆有个露台是很值得打卡的地方，景色优美，但是风吹有点冷。露台旁边有一个青砖小屋，好像什么当地野人住的一样。</p><p>从美术馆出来，沿着海边走，打算去吃大众点评上排名第一的餐馆。挪威是真的不爱挂自己的国旗，一路上看到了各种旗子，单单没看到挪威的。餐馆需要排队，但是如果愿意坐在外面，就可以少排队很久。那为啥不坐在外面享受太阳呢？我们点了生蚝、牛舌、鱼汤以及 fish &amp; chips，总的来讲都挺好吃的。生蚝比较小，比较腥，但是它的那个酸溜溜的调味汁很爽口，我们渴了一天，所以很喜欢。鱼汤里面还有其他海鲜，鱼肉好像是大块的三文鱼，吃起来很鲜嫩，但是不是很腥。汤是奶油汤，但不是很腻。fish &amp; chips 意外得很好吃，鱼比较大，也很嫩，外面炸的不是特别腻。总的来说这边菜还是比较清淡新鲜爽口的。</p><p>吃完饭，就走路去奥斯陆歌剧院和蒙克美术馆了，它们都在海滨。我们穿过 oslo 火车站就能走到。拍歌剧院最好的角度是在海湾的对面，需要小走一段路。我惊讶地发现居然这个天气还有人下海游泳。</p><p>尽管奥斯陆歌剧院的内部除了大厅是不给上的，但是它的屋顶是可以上的，我觉得是一个玩滑板的好地方，但是我去的时候没有人在玩。据说奥斯陆专门立法规定在屋顶上玩滑板出了事情的话是责任自负的。在歌剧院屋顶上可以看到海湾，以及奥斯陆城区的建筑，包括大教堂。近处是一些比较现代的建筑，例如德勤的楼。尽管如此，因为屋顶不是特别的高，所以更好的角度是蒙克美术馆，尽管美术馆会隔着一层玻璃反光。</p><p>奥斯陆歌剧院是个很好的地方，因为它不仅有厕所，里面的 cafe 还能提供免费水。相比之下，蒙克美术馆里面的免费水在我们想去打的时候，人家就说他们关门了，打不到。进入蒙克美术馆同样是需要存东西的，然后会乘坐扶梯直接上到4楼。蒙克的呐喊有三张在这里，每个半小时展出一张。更高的楼层上有陈列蒙克的超大画幅的画作，蒙克的版画等。在版画馆中，我们还可以尝试亲手拓印一些蒙克的画作。再往上的楼层就很抽象了，有一层在播放很神秘的音乐，还有一层在展示北欧的现代艺术。有个蒙克实验室，但是目前还不开门，很遗憾。在顶层，我们可以看到夕阳西下的风景，并俯瞰整个奥斯陆的湾区。</p><h2 id="D2-奥斯陆-弗洛姆"><a href="#D2-奥斯陆-弗洛姆" class="headerlink" title="D2 奥斯陆 - 弗洛姆"></a>D2 奥斯陆 - 弗洛姆</h2><p>早上起来发现昨天买的巧克力放在暖气片上都化掉了。加上发圈也掉了，于是紧急到旁边的 24 小时超市重新买了点。那些化掉的巧克力后面发现状况并不是那么严重，并且我们自己也吃了不少。</p><p>前往 oslo 火车站开启挪威缩影。我们乘坐的火车是前往明天的目的地 Bergen 的，但我们需要在中间站 Myrdal 下车，乘坐 Flam 的高山小火车去 Flam，然后第二天再在 Flam 乘船。事实证明这一段路程是很艰苦的，并且很缺水。我中途去买了一瓶水，居然花了不到五十块钱，这也太贵了。火车会从 oslo 往南先开到 dremen，然后往西北绕回去开到 honefoss，最后到达 Myrdal。这趟火车推荐坐在左侧，虽然在一开始会在右侧看到一片大湖，但在从 Finse 开始，左边会看到雪山和大湖，其实更漂亮。当然，想拍照片的话就比较难，因为路上会经过很多隧道。</p><p>我们的火车是晚点的，但实际上 Flam 的火车会等一会。我们提前了一会就在车门口边等待，被旁边的女士叫住说不要挡到厕所里面的人出来。然后我们就聊开了，这个人也去过中国，然后她就说中国火车站很挤，大家不得不在下车前就挤在出口 blabla，大家看来都不太喜欢这一点。</p><p>攻略上会建议 Flam 小火车坐在 7 还是 8 号车厢，但这是不必要的，因为经过那个瀑布的时候火车会停下来让我们下车看几分钟。而关键的是坐到靠窗的位置，因为从 Myrdal 到 Flam 的下坡路，能够在很短时间内看到深切的峡谷，以及下面的河流或者草地。并且即使坐靠窗，我们还是得站起来，才能从窗户打开的小缝中看到风景。火车玻璃太脏了。</p><p>不知道是不是枯水季的缘故，那个瀑布看起来着实不怎么样。比较有意思的是，瀑布上还有个人在放着音乐跳舞。</p><p>相比于瀑布，我们身边的那个外国小姐姐似乎更想要看到 black church，在一上车就往我们这边的方向凑，希望能找到它。我们的小火车最终要达到 Flam 的时候，她兴奋地喊叫，说看到了这个教堂，我们顺着她手指的方向也看到了。它被一圈墓碑包裹着。</p><p>Flam 面对一个小海湾，这个海湾中停了一艘特别大的游轮，游轮的烟囱还一直在冒烟。第二天走的时候，游轮还在，我怀疑它是不是一直搁浅在这里当做酒店用的。</p><p>在弗洛姆的酒店我觉得是非常好看的，无论是从外立面，还是里面的装饰而言。吸引我的是它靠门的一个斗柜，看着特别有年代感。然后是它的窗户，正好对着 Flam 的海湾，特别好看。卫生间是上个世纪的风格，浴缸，镀金的莲蓬头，温度需要手动调节 Cool 和 Hot 的比例。马桶圈也是木头的，和小时候的类似，上面还顶了个水箱。甚至在我们 check in 的时候，它居然有 laundry room，但进去之后发现它只有一台烘干机和两台洗衣机，我果断放弃了洗衣服的念头。</p><p>我们放完行李，就准备出去走走。到了游客中心，发现有一个比较好的项目是一个观景台，可以看到峡湾。很遗憾的是，三点半和四点半的车票都各自只剩下一张了。我们在前台咨询，他们建议我去 el-tour.no 这个网站上看看，说这是另外一家公司，也许它还有票。但是我试了下，发现它好像也是 sold out 状态，我甚至看不到出发时间。剩下来的方式，就是去租一个 e-car 开过去，我们考虑是山路，就放弃了这个想法。最终决定去 Flam culture park 看看。</p><p>走到最后也没看到 culture park 是什么样子，因此决定还是去 black church 吧。实际上这段路也很好走，路上没有什么特别波澜壮阔的风景，这里特指 hiking 指南上列出的一些瀑布都不是很壮观。这边的气候很舒服，适合徒步。下午的阳光不是很刺眼，照在近处的青山和远处的雪山上呈现不同的色彩。草地很绿，很多牛、马，但主要还是羊在吃草。路上是各种羊屎，我对象基本上都能准确命中。走到 black church 还是挺远的，但是路上风景还是不错的，也能看到附近村民的生活。比如回去的路上看到有人就下班开车到家了，隔壁的老爷爷摘了个树上的苹果，还分给邻居吃。</p><p>酒店前台，我们问了路书上推荐的那家餐厅，酒店说只有餐厅自己对应的酒店才能预定，因此我们只能自己去排队了。点了两个啤酒，我的那个好像叫 honey 啥的，比较酸。我对象的颜色深一点，比较类似于黑啤。这个餐厅让我想到那种小酒馆，一楼除了吧台之外就是一张张桌子，大家端着酒在聊天。中间有一个圆形的坑，在边缘安装了座椅，坑的中央放了个火炉，这样大家可以围着火炉坐着聊天。招待我们的是一个非常 E 的老外，长得好像那种披发下来的骑士，当然肯定是没穿戴甲胄的。他和我们说要排 40min 多，然后就在本子的第二行写下了 LUO。我们很快发现这是一个比较尴尬的事情，因为他说等他大声喊（然后我不得不在一片嘈杂声中大声喊出我的姓的正确读法）到的时候，我们就跟着他上二楼。</p><p>只点了几个菜，因为据说这家店分量很大。有一个品酒套餐挺好的，因为我们已经喝过酒了，所以可以去掉酒，还便宜点。里面包含了好几样小菜，包含我想尝试的鹿肉。</p><p>吃完饭出来，天还没有完全黑。走出来路过纪念商店也没有关门，这商店牌子上居然还有中文。</p><h2 id="D3-弗诺姆-卑尔根"><a href="#D3-弗诺姆-卑尔根" class="headerlink" title="D3 弗诺姆 - 卑尔根"></a>D3 弗诺姆 - 卑尔根</h2><p>早上不到七点就下到二楼吃早饭了。从四楼到二楼走的是一个木质的台阶，我觉得非常有感觉。二楼有几张座位是靠着酒店的玻璃屋顶的，于是一边吃就可以一边看远处的晨光越来越亮。他们家有不少奶酪，我都尝了下还不错。我对象觉得都很腥。我还尝了下羊奶，感觉没啥感觉。倒是那个长得像山楂水的还挺好喝的。这边的 porriage 也挺好吃。</p><p>这一路上遇到了不少人，昨天看到的不少人，比如一个台湾的大叔。我们也遇到了不少人后面也见到了，比如上船的时候唯一排在我们前面的深圳过来的三姐妹，她们在前面说要怎么怎么坐，我们就在后面偷听，然后跟着她们学。我们选择的是船尾的那几个沙发，但是进门的时候需要放行李，所以我放的时候，另一个人就得去把位置占了。确实视野是比较好的，但松恩峡湾最好的还是站在船前进的那一面看，而这就需要出去吹冷风了。</p><p>船舱里看到一个阿姨，在凑着拍，于是我邀请她坐在我位置上拍。结果她说自己也是中国人过来的，好像是找了个当地的导游。她说这边的很多瀑布是有水的，但是最近好像是枯水季，就都不是很壮观。然后她又用英语和她的同伴介绍中国三峡，说这边让她想到了三峡。她还说她的向导的哥哥就是这峡湾半边山的主人，因为挪威这边很多东西是私有的，并且只传给男性长子，所以他哥哥就得继承。但这却不是件好事，因为政府会强制所有者投入资金去保护这些地方，而对应的，这些山又不是很赚钱。他哥哥说已经赔了三百万克朗进去了，现在特别想换职业去打渔，那才挣钱。</p><p>我们船的客舱在底层，内饰相当的舒服，有很软和深的沙发。中间还有个小吧台，这是十分必要的。从前进方向可以出去直面寒风，然后从船舷的两侧可以走到船尾一个更高的平台上，然后从这个平台又可以往前进方向走，最终走到客舱的屋顶上。太冷了，对象买了杯热可可，发现那边居然是自助结账。</p><p>船开了一个半小时，我看左边好像是一个水湾这个时候船开始往右边停靠，难道已经到终点了么？转念一想，这水堆积在那里怎么流出来呢？果然，那边是一个很小的村子，几个人从船上下来，大家朝他们挥手致意，然后船就往那个水湾开了过去，然后水湾就慢慢朝远处延伸，我们仍有一段路要走。</p><p>这时候我们就走在了雪山之间，两侧的岩壁很陡峭，可以看到植被很明显的分层现象，直到最终的雪顶。</p><p>卑尔根真的是很小的城。我们先去吃了鱼饼，那感觉是一个非常重要的路口，因为后面我们去各种地方都会看到这个鱼饼店。这个鱼饼感觉就和老家的鱼圆一个感觉，但不是市面上买的那种比较清淡的鱼圆，而是我外婆烧的那种味道浓厚一点的。然后就去吃了热狗，热狗店就在卑尔根的缆车旁边，所以我们就去买了缆车票。但随后我们发现还没到五点，而卑尔根可能要七点多才日落，所以就打算先出去晃下。</p><p>我急着上厕所，就去人字屋旁边有个城堡那边上免费厕所。看起来那是卑尔根大公住过的城堡，并且是可以进去的，我们计划明天也许能过来看看。后面我们在人字屋那边花了很长时间拍照，然后重新赶到了缆车那边。这个时候人就比较多了，我们前面有两组四五个人没有选择进入即将出发的缆车，而是希望能够等到下一趟。这样可以坐到最下面的车厢的最前面，从而看到最好的风景。我们也就跟着等，当然下一趟列车第一排的位置也是轮不到我们的。于是我就突发奇想问前面的貌似是印度来的小哥我坐到台阶上会不会影响到他们。他们说请不要坐在这，然后又热情地把我招呼下来，说那是个玩笑。</p><p>到了山顶，接近六点了。我们赶快找那个商店买卑尔根的冰箱贴，结果到了发现门打不开。绕到侧面发现里面灯亮着，又绕到正门，发现里面有两个人在收拾东西，顿感不妙。招呼了下，她们打开门，果然下班了。气氛突然变得比较难受，因为我对象认为只有这个商店才有可移动的缆车的冰箱贴，但我坚持认为这种工业制品不至于只有一个地方有。在随后的五分钟，我们贴着窗玻璃左右走动来回观察，但即使这样，也没看到店里那里有我们想要的冰箱贴。我觉得这种工业化的制品不可能只在山顶一个地方有，但是我对象不相信，很沮丧。</p><p>无论如何，只能在山顶逛逛，等日落了。这个山顶还是比较大的，上面有好几家餐厅，有一个餐厅位于高处，外面是一个瞭望台。从瞭望台往缆车方向走有一个信标，上面特地用乌克兰国旗标注了基辅的方位和距离。瞭望台的另一个方向往前走就是很多山羊放养的地方，这些山羊都被打了特殊的标记用来识别。山羊都很懒，趴在地上不怎么运动，它们似乎已经习惯了游客和它们合照了。</p><p>从山顶下来我们就没有特地选择缆车的位置，但天也确实比较晚了。下来之后，发现大部分商铺都关门了，我们可能明天才能找哪些店有冰箱贴了。</p><h2 id="D4-卑尔根-雷克雅未克"><a href="#D4-卑尔根-雷克雅未克" class="headerlink" title="D4 卑尔根 - 雷克雅未克"></a>D4 卑尔根 - 雷克雅未克</h2><p>卑尔根机场十分小，进去之后就一个厅，从一头到另一头估计两三分钟就能走到。我们的冰岛航空似乎是严格按照 2h 提前值机的，所以虽然队已经排有点长了，但柜台一个工作人员都没有。我们在最左边的一号柜台站着，成为靓丽的风景线。</p><p>我的箱子重 21.9 KG，感觉很快就要爆了，这还是我已经把羽绒服啥的穿上的情况，看来去冰岛要抓紧时间吃点东西了。</p><p>卑尔根机场的巧克力最后还有一包了。</p><h1 id="冰岛"><a href="#冰岛" class="headerlink" title="冰岛"></a>冰岛</h1><h2 id="D0-雷克雅未克"><a href="#D0-雷克雅未克" class="headerlink" title="D0 雷克雅未克"></a>D0 雷克雅未克</h2><p>从卑尔根飞雷克雅未克的飞机依旧是很满的，感觉这边上客率真的很牛。到了 KEF 发现机场是一团阴湿的雾气，要我说就像伏地魔来了的感觉。我们还必须要坐摆渡车才能到机场，非常折腾。到了机场发现它似乎很乱，排队上飞机的人把我们到达的走廊挤得只剩一半的宽度了。我们走了比较远才遇到一个厕所，但里面的设施是非常干净整洁的，也是北欧一直给我的印象。</p><p>我们需要出机场，才能走到专门去租车公司那里的摆渡车乘坐点。我们的 Alamo 公司是在摆渡车的最后一站，进去之后发现他们生意有点好啊，里面已经有了不少人在等待了。我们需要取号，排在我们前面的是四个中国留子，有一个人看起来英文比较好，并且也来过一次冰岛，所以他在讲解什么是 pre paid fuel，大概就是先付一箱油的钱，这样回来的时候就可以不用加满油了，然后租车公司会给你一个折扣。然后大家就开始算至少油表要干到多少才不赔钱。不一会，他们就被一个很健谈的大叔叫过去了，大叔非常热情，讲解了大概有十分钟至少，我们很希望他能帮我们办租车，这样驾照问题应该能被 cover 住。但显然他们花了很长时间，所以不一会一个小姐姐上任并叫到了我们的号。</p><p>租车的过程异常顺利，我们担心的不少东西基本没有发生。租车公司只是检查了下驾照复印件就同意加上了 secondary driver，但是她也强调，只是对他们是 OK 的，但是警察不一定。她祝愿我们好好开车，不要被警察抓到。租车公司是非常贴心的，他们会给你一个小册子，里面记录了很多关键的内容，包括汽车加什么油。一般来说，都是汽油车，加绿色的 95 号汽油。她还建议我们下一个 safe travel 软件，因为只有它是及时更新路况的。</p><p>开回来的路上，发现 google 地图的驾驶导航功能没有很明显的超速提醒，也没有摄像头提醒，于是我对象找了半天，下了另外一个叫 weez 的软件。不过它也好不到哪里去，至少在离开冰岛的时候我还没有根据它的提示去判断超速。另外，我们汽车的仪表盘倒是很智能，会告诉你当前路段的限速是多少。</p><p>一路开过去，一路上基本没有任何红绿灯，有交叉口的地方都是用的环岛来替代的。但虽然说是环岛，基本另一条道路都是很窄的，去往某个村庄，或者人迹罕至的某个地方的路，很少有车会去那里。</p><p>我们大概五点一刻出发的，当时是多云微雨。我感觉我在开往世界末日。旁边都是黄草，远处是很低的乌云，仿佛笼罩着什么山，我想肯定是某个火山吧。开了一段，公路会经过海边，这个时候我第一次看到了城镇，我想那可能就是雷克雅维克了。后面的路感觉起伏更大一点，我感觉在上坡和下坡。再往前开，环岛变多了。后面开始有小型的立交桥，路也从单车道变成双车道，再变成高速公路那样子。这里立交桥还是挺有意思的，下了高速，就是一个上坡，坡上一个红绿灯，很多车都在那边等开到别的路上。最后，我们似乎到了这一条高速的尽头，需要在一个由红绿灯管控的路口左转，这是我第一次看到红绿灯。</p><p>开到了希尔顿，它的停车场已经快停满了，我们好不容易才找到一个车位。</p><h2 id="D1-斯奈山半岛"><a href="#D1-斯奈山半岛" class="headerlink" title="D1 斯奈山半岛"></a>D1 斯奈山半岛</h2><p>早上从雷克雅未克的希尔顿出发，就往草帽山走。</p><p>这边开车给我造成了相当的困扰。首先是路比较窄，在离开雷克雅维克不久，所谓的一号公路就变回了双向两车道了。我的车又比较大，我总觉得我不是太靠左就是太靠右。野外的限速是 90，但会车的时候感觉一股气流从身边掀过，如果遇上了大车，那可能方向盘都吃劲。于是我总是躲着靠右边开，但总容易开到路肩上，轮胎声音都不一样了。天气也是一个原因，比如在某个地方，我甚至看到远处有个像龙卷风一样的东西，我很担心自己是不是要走那边走。但真的开到那边时，发现只是一团雾气了。所幸有素质的司机占了绝大部分，我只遇到一个开着脏兮兮面包车的司机在超我车之后迅速并线，感觉就是擦着我的车过去的。在这个事件过去不久，就遇到了传说中冰岛个位数数量的测速摄像头之一，我当时正在控制车速，突然发现前面有一个灰色箱子，并且正在朝我迅速靠近。测速摄像头！我赶快一脚刹车下去，速度瞬间往 40 走了。但我距离摄像头太近了，不知道有没有拍到。</p><p>海豹沙滩是此行的最东边了，下车的时候风非常冷，还带点小雨星。我们要先走到收费亭那边交费，然后再往下走到沙滩上。这个沙滩特别地脏和腥臭，上面堆满了海带或者鱿鱼带子一类的东西。海豹是不会上岸的，它们会在离岸边十几米左右的地方露着一个头泡着水，或者一个猛子扎进去游泳。</p><p>这个小镇中似乎只有一个酒店，一个餐厅，还有几家咖啡馆。这个小镇是邻着海湾和悬崖的，也算是一个景点了。我们的酒店只有一排房子，显得非常小，穿过门厅就是餐厅，过了餐厅就是客房。这边没有房卡只有钥匙。给我们准备了一盘巧克力。</p><p>晚上出门打算寻找极光，发现餐厅和门厅里面一个人都没有，门厅里面的猫也不知所踪，这场景不得不说有点害怕，加上四周又很安静，我觉得很有恐怖片的感觉。推开大门，外面风特别大和冷，还下着雨，看来今天晚上是没有极光了。</p><h2 id="D2-黄金圈"><a href="#D2-黄金圈" class="headerlink" title="D2 黄金圈"></a>D2 黄金圈</h2><p>早上从海德纳尔弗斯的酒店起来时候天还没亮。这家餐厅是有早餐的，种类相比挪威的要少一点，毕竟它的备餐桌也很小。这边的煮鸡蛋是冷的，让人很遗憾。</p><p>出门的时候还是要死人的天气，走到一半阴雨绵绵。我们到一家 N1 加油站加油，里面一个人都没有。</p><p>但不知何时起，太阳就当空高照，冰岛瞬间就不一样了。在路上，我甚至能拍到几十公里外雷克雅未克的大教堂。</p><p>我们的第一站是辛格韦德利国家公园，但风景在离开一号公路走到 36 号公路的时候就开始了。当时还下了一点小雨，我们以为又到了之前那种阴森的环境中。但不一会，之前一直见到的黄草、绿苔藓的景色就消失了，现在眼前多了很多红色以及绿色的植物，就连草也变成了更加明亮的黄色。它们组合在一起，就形成了三原色，让这片区域生机勃勃。再过了一会，就看到了一片大湖，可能就是辛格韦德利湖了。我们要绕半圈这个湖，到它的另一侧，也就是国家公园，沿途有几个观景点，都是用来看湖的，我们没有过多停留。</p><p>到了国家公园，映入眼帘的是很现代化的游客中心，以及冰岛国旗。相比挪威，冰岛人更喜欢悬挂自己的国旗。后面了解到，这个公园比较大，有很多个停车场，游客中心所在的停车场是在一片高地上，旁边就是一个观景台，可以看到后面我们要游览的大部分地方。站在观景台上往下看，根本不知道这些是啥，感觉就像一片湿地或者滩涂，往右边延伸就是辛格韦德利湖了，不恰当的很像千岛菜花。在这片滩涂中，有很多行人在 hiking，我们很疑惑这边有啥好走的？高地的两边都可以往下走，我们看到左边是有人上来，右边也就是靠着观景台的那一边大部分人在往下走，于是觉得这是一个环状线，跟着往右下去了。实际上这个公园非常乱，最后要走不少回头路。</p><p>往下走两侧是峡谷，峡谷两侧的岩壁非常不同。左边高大陡峭，整体很光滑，但是岩面也很多，在一些缝隙之中长了不少草。右边就低并且平缓很多，岩面有更多的向外的凸出，上面长满了青苔。听说这公园和裂缝有关，难道这一边是美洲的，一边是欧洲的？右边还有一些小路，可以往里走一小段，看的是之前看过的滩涂的风景，没有什么意思。回归到大路上往下走，坡度比较大。到达前方，是一面冰岛国旗，后来才知道，这里是冰岛唯一一个文化遗产，因为世界上第一个国会阿尔廷就是在这里形成的。再往下走，就到了滩涂上了。我们对它并不是很感兴趣，就继续沿着路往前走，这时候会路过第二个停车场和厕所。</p><p>住的 selfoss 的酒店相比昨天的显得特别现代感，也有好几层楼，并且它就靠着 1 号公路。可惜它的后院停车位比较少，我们应该是抢到了最后一个停车位。我们向酒店询问极光叫醒服务，她秒懂并指着桌上的一个本子，上面已经密密麻麻登记了很多房号。她说如果有极光的话，在酒店的后院就能看到。我们的房间在三楼，望北，但可惜路对面还是有建筑和树木遮挡，并不能直接看到海。</p><p>小猪超市在 selfoss 的另一端，但是酒店旁边有个 K 记超市，所以我们去逛了下。 冰岛的物价并不是很离谱，树莓和蓝莓都不是很贵，我们还买了一些薯片和酸奶。</p><p>夜里又是定了闹钟起来。走下楼发现前台值班换成了一个光头男，他在电脑前面点一堆表格一样的东西。我们问他极光的事情，他说这个谁也不知道，至少酒店外面是看不到的。我们从后院出门，在小镇四周绕了一圈，也没有看到，就会宾馆准备睡觉。这个时候遇到一车人，他们似乎是刚追完极光回来。里面一个妹子说他们追到了，并给我们看了照片。她说是在 selfoss 南边的荒地里面追到的，但现在可能不一定有了。但我们决定一试，把车开出酒店，发现路边都停满了车，万一我们没追到极光回来又丢了车位，那就可太惨了。</p><p>我们开了十分钟来到南边的田地里，找了个“停车场”（实际那不是停车场，只是丁字路口方便转弯多修的一块路肩）停下。车子的左侧应该是西方，是万里晴空，可以看到除了猎户之外的其他很多星星，以及银河。车子的右侧也是什么都没有，只能看到一团雾气包裹着白色。我们花了几分钟才意识到这可能就是极光，在群里一问才知道，极光不强的时候就是白色的，用手机拍是绿色的。这里我尝试用了 iPhone 的长曝光 3s，发现确实是绿色的，边缘还带点黄。但肉眼看，最多只有淡绿色。如果不开长曝光，拍出来就是一团黑。在半夜两点左右的时候，我们迎来了一波比较强烈的极光，尽管颜色还不是呈现绿色，但它们有了形状。在 20 分钟之后，这些形状又消散，变回了一团雾气。我们等到三点不到就回去了。</p><p>到了宾馆，只剩下了残疾人车位和电动车车位，不过宾馆说电动车车位也是可以停的。</p><h2 id="D3-维克"><a href="#D3-维克" class="headerlink" title="D3 维克"></a>D3 维克</h2><p>selfoss 酒店的早餐比前一天丰盛很多，取餐区也能围成一个圈了。他们家的土豆胡萝卜豇豆大乱炖、洋葱炒啥的，以及臭鱼烂虾挺好吃的。</p><p>第一站塞里雅兰瀑布开了一个小时就到了，但太阳还是非常晒。</p><p>从黑沙滩回来还有一阵，我们打算先去 Orkan 加油，顺便去旁边的 K 记超市买点东西。我们把车停在 K 超市东边的停产场上，一下车，这海上刮来的风就把车门咵地扯开了。很是后怕，因为租车保险是不赔车门被挂飞了的。相比下，这个超市就很 nice 了，它是 ice wear 和 K 记的结合体。我赶快去上了个厕所，黑沙滩可把我憋坏了。在 ice wear 店里面我看到了小红书里面讲的廉价版火山石冰块，它看起来一点不像火山石，而更像大理石地砖给切开得到的东西。外面的木头盒子也特别廉价，我就没有买。</p><p>check in 的时候说他们的 hot tap 坏了，我们以为是没有热水，后来才发现他说的可能是那个桑拿房坏掉了，我们洗澡是有热水的。这个酒店的钥匙特别古怪，非常的大。我们住的九号房间离 reception 不是很远。</p><p>到酒店坐了一阵觉得没啥意思，就打算出发去 yoda 洞。</p><p>晚上九点半起来去宾馆门口看了下，发现风特别大，还有点小雨，觉得又没戏了，就回去睡觉。晚上十点半再起来，发现地图上居然又橙色区域了，而维克碰巧在云区的边缘。我对象就像开车往 selfoss 方向走，比如开到塞里雅兰可能也就一个小时。十点五十左右，我在小红书上找到一个塞里雅兰瀑布附近看到极光的妹子，她说那边刚才确实是大爆发，但是现在已经没了。</p><p>一路上我在用手机追踪极光，在某个方向上，确实可以看到一团云雾一样的极光，但是不成形状。我们大概开到斯科加瀑布那里拐进去停在路边，发现那边也有一些追极光的人。</p><p>开车回来路上发现一直在松的左眼镜片掉下来了，吓我一跳。最终发现原来是某个螺丝掉了。于是我打算用晾衣绳系一下。没想到后面在放杯子的地方重新找到了这个螺丝，也是运气好。</p><p>路过维克镇已经过了12点了，路上居然遇到了警察在查酒驾。果然要求出示驾照，我们只好说晚上出来追极光，in a hurry，驾照忘在酒店了，但是有电子驾照。警察说 it’s OK with me，但是法律要求要随身带驾照的，然后就做了酒驾测试。结尾我对象还问了句你们这么晚还要出来工作么，他说是的。</p><h2 id="D4-冰川徒步、冰河湖游船"><a href="#D4-冰川徒步、冰河湖游船" class="headerlink" title="D4 冰川徒步、冰河湖游船"></a>D4 冰川徒步、冰河湖游船</h2><p>今天起得特别早，但我们还是混到了大概六点五十，于是决定不如就去简单吃点早饭。这个宾馆的早饭还是不错的，特别是它的臭鱼烂虾，有一种味精超标的鲜，以及一溜溜酸味。但是既不腥也不臭。</p><p>据说是昨天的风沙太大了，所以昨天的冰川徒步改到了今天上午十点，也就是我们的场子。结果上来看，我们是一个大团队坐了一辆大巴车，然后被分成三个小团队，一个小团队有十来个人这样，估计体验上会比较差。实际上体验还好，可能是我们攀爬的冰川本来就是比较简单的，因此没有人出现什么状况。此外，向导会有很多时间讲解，并且也会让我们排队拍照，所以冰川上不是特别乱。</p><p>我们早早就到了，这个时候，9.30 的人还在排队上厕所准备入场。这个厕所比较简陋，里面没有卫生纸。因为人很多，厕所只有两个，所以要排非常长的队。所以，它实际上对徒步完之后的游客不是很友好，我们最后是到冰河湖上的厕所。冰川徒步必须穿 boots，其他的什么鞋子都不行，包括我的护踝也不管用。</p><p>大巴车只能停在距离冰川很远的地方，我们需要走一段不到半个小时的有苔藓覆盖的路，然后走到一片湖前面。再往前就是一片煤灰一样的地，然后是陡峭的和煤灰一样的坡，以及坡上面的白色冰川。我的鞋带中间还开了，进了不少沙子，特别难受。在这里大团队被分成了三个小组，我们的领队是一个妹子。在这里我们停留了许久，学习如何穿戴冰爪。首先她带领我们一步步穿上右边的脚，然后我们就自己把左脚给穿上，最后一个个给她检查。我们大概花了至少二十分钟在上面，直到导游脱下了她的防寒服放到包里，我暗叫不好，估计穿多了。</p><p>在真正看到蓝冰洞和白色冰川前，我们要爬一个陡峭的像煤灰一样的坡，向导说其实这个已经是冰川了。我用爪子挠了下地面，发现“煤灰”下面是灰黑色的冰块。因为人特别多，所以我们在蓝冰洞门口要排队，这个时候赶紧脱掉衣服了。今天是晴天，方才在集合点的时候，太阳还没晒到，因此特别冷，我穿了两条单裤和一条棉毛裤，上面是羊毛衫和羽绒冲锋衣。而实际上冰川上太阳一直晒着，就会特别热，我把羊毛衫脱掉了。相比之下腿晒不到，还是可以忍受的。</p><p>我们的第一站就是蓝冰洞，这是一个特别小的蓝冰洞，一两分钟就可以穿过去了。但是里面的冰是特别的蓝，还能看到气泡。冰洞是先往下的，然后陡然向上。旁边有锁链供我们搀扶。</p><p>出了蓝冰洞，就到了肉眼可见的冰川上了，到处是白白的一片，在强大的阳光的照耀下，非常刺眼，我的墨镜起到了非常大的作用。</p><p>从冰河湖游船上下来，就疯狂往羽毛大峡谷赶路。因为纬度比较高，羽毛大峡谷那里日落比冰河湖要晚个几分钟，但我们依旧是在日落之后一刻钟才到达羽毛大峡谷，距离 last light 只有半个多小时了。所幸最后还是赶上了，然后就是往坡上冲刺。但令人宽慰的是这个时候还有不少人在往上面走。因为我们是十月份去的，这个时候草基本已经枯黄了，水位也不是很足，所以感觉上没有图片看到的那么惊艳。但羽毛大峡谷比斯科加瀑布上游的河流要崎岖狭窄很多，两侧的崖壁的形态也更加夸张。还有很多嶙峋的石柱在河道中间升起，像是被侵蚀出来的一样。</p><p>尽管羽毛大峡谷的正经停车场那条路封了，我们实际上是往左走岔道下到的另一个停车场，但这也不影响要交费。好在大峡谷上坡的地方修了个厕所，旁边就有个交费的亭子，不然用那个 parka 软件就非常麻烦了。回程的路上，我们甚至可以看到一队青年男女刚刚上山，我们怀疑是专门露营看极光的。不过我可不敢在这种地方露营，因为开回 1 号公路的时候，我相信我看到了一头狼在旁边的旷野上走路。</p><p>晚上住在黑沙滩酒店，它离黑沙滩贼近，风也贼大，我们黑漆马虎地开了好一段没灯的路才到那里。它的规模很大，散落在黑沙滩上有很多个小房子，我们被分在 46 号。理论上是可以直接开车到房间门口的，但因为车位满了，所以只能拖着大箱子走了很远。<br>房间的门很简陋，看起来像卫生间的门一样，但进去发现是非常豪华。首先它居然有一套厨房，并且厨房里面的餐具、微波炉、冰箱、咖啡机都是全的，虽然唯独缺了烧水壶。然后它有一个露台，在露台上就可以看极光。<br>我们很快就看到的极光，大家都很开心。对面的小房子里面的学生们开心地吼了出来，我对象也开心地撞到了玻璃门。这比我们在 selfoss 看到的极光要强很多了，它横跨整个天空，并且有了很明显的绿色。在十点左右，它甚至有一部分在缓慢地动。因为今天的 KP 是 7，所以我们期望后续有极光盛宴，但实际上十点半左右极光就消散了，并且维克出现在了 Aurora 软件的绿带之外。<br>晚上定了无数个闹钟，醒来很多次，发现基本都是这个卵样了。后续发现今天的绿带非常地小，感觉完全配不上 KP 7。感觉刚才我们看到的极光也就是在北面的，后面极光带往北再移动维克就彻底看不到了。甚至早上看到在加拿大时候的极光带也是特别小，看来果然 max possible KP 不等于实际的 KP。</p><h2 id="D5-雷克雅未克"><a href="#D5-雷克雅未克" class="headerlink" title="D5 雷克雅未克"></a>D5 雷克雅未克</h2><p>我们大概十点半出点头就到了雷克雅未克的大教堂，这次我们停在了靠近正面的停车场，很不幸，后来发现这里似乎要交费。更加不幸的是，当我们想要登塔的时候，门被拦住了，里面准备做弥撒于是就不让进了。我们后面还有观鲸，于是只能退而求其次，去 city walk。吃了个叫 braud 的面包，旁边的 reykjavik roasters 点了两杯咖啡，然后我们就往湖那边走。白天的托宁湖确实不是那么阴间了，白天鹅和鸭子还是在打架或者抢食。</p><p>大概十二点一刻左右，我们就到了观鲸那边的停车场，然后走到那个红房子里面取票。剩下来的时间就是在码头上等待，我们是第二组到的。</p><p>趁着他们争论的间隙，我问了向导几个问题，顺便缓解尴尬。我问这些鲸鱼都是有名字的么，向导说 humpback whale 是有的，但是 minke whale 太多太小了，所以就没有。那是如何认出来的呢？向导给我看了下她的照片，原来是可以从尾部的花纹认出来。另外它们的背鳍也不太一样。所以看鲸鱼真的要带大炮过去，不然很难拍清楚鲸鱼长什么样子。</p><p>看完鲸鱼立马往教堂赶。最后居然赶上了。</p><p>我们很早就从雷克往 KEF 开了，目的是抓紧时间赶紧洗完车，还完车，然后出去看极光，顺便可能可以在 KEF 镇上看看日落。实际上当我们开到 KEF 镇上那个自称为 self host 的 N1 加油站时，发现它的洗车关门了。墙上写了一行字，说是搬到了某个别的地方。于是只能去小红书上搜了下，说有个两个 b 打头字母的地方可以自助洗车，但首先要去 olis 加油站买洗车币。我们开到了附近一个 ob，但是它关门了。看起来不得不去更远的那个 olis 了。但路上我们决定先经过那个很两个 b 打头的地方看看是怎么回事。谢天谢地那里还是开着的，并且有四个库房可以洗车，有两个黑哥哥似乎在洗出租车，我上去问了下。他们说就是在那个两个 roundabout 之外的 ob 有洗车币卖，我们只要买 20 分钟就行了。我们看了下隔壁的库房，里面一个枪头还在滴水，看起来也可以白嫖一下？无论如何，还是多一事不如少一事去那家店买了。看起来这个 olis 和 ob 两个牌子似乎是一家的，我进去买了 2 个十分钟的洗车币，居然要 120 rmb 这样，也太贵了，有点后悔。</p><p>重新回到那里，天已经黑了。我担心别的可能是坏的，所以开到黑哥哥原来用的库房，下来投币，发现这个洗车贼高端。它有四个旋钮，1 会从喷枪里面喷出汽油一样的东西，用来去污垢，2 会从高压水枪里面喷出肥皂水清洁，3 是会从一个拖把里面喷水，可以刷脚垫啥的，4 是清水或者可以打蜡。这一套流程下来，10分钟确实不够用。</p><p>又回去 N1 加油，把汽油滴到了我的衣服上，这个味道好冲，我不禁有点担心明天安检能不能过了。</p><h2 id="D6-KEF"><a href="#D6-KEF" class="headerlink" title="D6 KEF"></a>D6 KEF</h2><p>KEF 机场真的是离谱。</p><p>排到二楼才能看到刷登机牌的地方。我们通过时发现几个人没法刷登机牌再走人工通道，等到转过弯排队安检时又遇到了他们。他们正在和一个貌似是台湾人争论，他们说他们的飞机很早就 last call 了，希望能去 front desk 去问问。但是台湾人认为是在插队，很严厉地拒绝。在经过我的时候，我让他们从我前面进入队列，并且和对向的白人小姐姐沟通，让他们绕过围栏插了过去。后续这帮人往前走，激起了另一组白人以及原来台湾人的讨伐。</p><p>过安检，果然我们的包又被分到了要人工检查的那一边了。安检人员拿着我的 ipad 仔细瞧了瞧，贴了下爆炸物检测纸就放我走了。我担心的没有发生。过了安检就是免税店，那里没有我要的火山石冰块。问了工作人员，他们非常热心，还给我出来指方向。但是他们的口音确实比较重，我模糊中只能听到是 “something rocks” 这家店。所以只能跟着小红书上面的印象，往 C 口走。</p><h1 id="西班牙"><a href="#西班牙" class="headerlink" title="西班牙"></a>西班牙</h1><h2 id="D0"><a href="#D0" class="headerlink" title="D0"></a>D0</h2><p>巴塞罗那的天气比我想象中还要热。</p><h2 id="D1-巴塞罗那"><a href="#D1-巴塞罗那" class="headerlink" title="D1 巴塞罗那"></a>D1 巴塞罗那</h2><p>我的那个酒看着像巧克力或者中药，喝起来是酸甜的，但是也带着一股药草味。</p><h2 id="D2-巴塞罗那"><a href="#D2-巴塞罗那" class="headerlink" title="D2 巴塞罗那"></a>D2 巴塞罗那</h2><h2 id="D3-巴塞罗那"><a href="#D3-巴塞罗那" class="headerlink" title="D3 巴塞罗那"></a>D3 巴塞罗那</h2><p>巴塞罗那机场的退税要方便一些了。只需要在一台机器上扫描一个退税单，就可以登记所有的退税单了。然后就可以去旁边的柜台办理。有两个选择，一个是获得一个 coupon，但是只能在机场免税店里面购买，另一个是直接获得欧元现金。我选择了现金，这个还是比较合理的，因为后面发现免税店里面其实没有什么可以买的。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;OSLO -&amp;gt; BERGEN -&amp;gt; ICELAND -&amp;gt; BACELONA&lt;/p&gt;</summary>
    
    
    
    
    <category term="游记" scheme="http://www.calvinneo.com/tags/游记/"/>
    
  </entry>
  
  <entry>
    <title>C++ 内存监控方案</title>
    <link href="http://www.calvinneo.com/2024/08/23/monitor-alloc-in-C++/"/>
    <id>http://www.calvinneo.com/2024/08/23/monitor-alloc-in-C++/</id>
    <published>2024-08-23T01:23:25.000Z</published>
    <updated>2024-08-23T10:15:55.982Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 C++ 上的内存监控方案。</p><p>默认使用 jemalloc。</p><a id="more"></a><h1 id="MemoryTracker"><a href="#MemoryTracker" class="headerlink" title="MemoryTracker"></a>MemoryTracker</h1><p>原理是每次分配内存的时候，manually 去向⼀个 MemoryTracker 注册。下层级的 Tracker 和上层级的 Tracker ⼀起组成树状结构。</p><h1 id="Jemalloc-allocatedptr"><a href="#Jemalloc-allocatedptr" class="headerlink" title="Jemalloc allocatedptr"></a>Jemalloc allocatedptr</h1><p>这个方案要求感知线程的创建和销毁，在对应的时候，通过 <code>thread.allocatedp</code> 和 <code>thread.deallocatedp</code> 来注册。这样就可以知道每个线程分配或者释放了多少内存。<br>该⽅案能够很好看到内存分配和释放的速率和增量，例如如果观察到 allocated 斜率⼤幅增加，则说明该线程最近在⾼速分配内存。但难以判断某个线程到底 own 了多少内存，原因是：</p><ol><li>⼀个线程可能释放另⼀个线程分配的内存。例如同一个模块中线程 bg-1 分配的内存可能被另⼀个线程 bg-2 释放。</li><li>Rust 的 move 语义和协程机制会加剧这个问题。</li></ol><h1 id="Jemalloc-Arena"><a href="#Jemalloc-Arena" class="headerlink" title="Jemalloc Arena"></a>Jemalloc Arena</h1><p>该⽅案可以看做是对 allocatedptr 的补充。通过 thread.arena 绑定⼀个线程到某个 arena，则可以通过该 arena 获知该线程 own 了多少内存，所以这是看存量的⼯具。<br>但线程 own 多少内存，并不等于某个模块占⽤了多少内存。原因：</p><ol><li>内存的 ownership 会在平⾏的模块之间转移。例如 P 模块分配出来的内存，可能会被转移给 S 模块。所以即便能够看到 S 线程池对应的 arena 的占⽤上升，也难以判断是 S 模块的原因，还是 P 转移过来的内存。</li><li>上级模块从同线程中调⽤下级模块，⽆法区分出上级和下级分别消耗了多少内存。</li></ol><p>这个⽅案有下述的缺点：</p><ol><li>我们更需要找内存增⻓的根因，知道内存都在哪些 arena ⾥⾯未必是⾜够的。</li><li>一些使用线程池的模块中的内存分配⼤致满⾜“⾃⼰⽤⾃⼰弃”的 pattern，因此可以通过减法来算出存量。因此，“Jemalloc Arena” 相⽐ “Jemalloc allocatedptr” 的⽅案的作⽤不是很⼤</li></ol><h1 id="thread-local-memory-tracker"><a href="#thread-local-memory-tracker" class="headerlink" title="thread_local memory tracker"></a>thread_local memory tracker</h1><p>来⾃ Doris 的 Memtracker ⽅案。<br>该⽅案可以作为 “Jemalloc allocatedptr” ⽅案的补充。对于“上级模块从同线程中调⽤下级模块”的情况，可以使⽤⼀个 thread_local 变量记录栈中的⼀部分的内存开销。如下所⽰ kvs_page_mem 这个 thread_local 变量记录了 thread 1 中从 KVStore 调⽤到 PageStorage ⼀部分的开销。因此再结合 “Jemalloc allocatedptr” ⽅案本⾝的数据，就可以区分开来 PageStorage 产⽣<br>的内存（如新建⽴的 PageDirectoy）和调⽤链路上其他的内存，如 KVStore 和 PageStorage 中缓存的其他内容。<br>thread_local 的信息会被定时地上报给全局的 tracker，并由 tracker 做聚合后上报给 Prometheus。<br>也可以直接复⽤当前的逻辑，由 tracker 直接做聚合，但这样就需要⼀个全局的 hook 去线程启动的事件。</p><p><img src="/img/monitor-memory/11.png"></p><p>缺点：</p><ol><li>只能根据调⽤链路细化，不能追踪某个组件占据了多少内存。</li></ol><h1 id="Jemalloc-mallocx"><a href="#Jemalloc-mallocx" class="headerlink" title="Jemalloc mallocx"></a>Jemalloc mallocx</h1><p>通过 MALLOCX_ARENA flag，可以在 mallocx 的时候指定从某个 arena 分配。因此对于模块 A 可以替换它的所有 malloc 为 mallocx，从⽽实现追踪该模块的内存分配。<br>C++ 中内存管理层级和⽅式都很多，不能通过简单替换 mallocx 才能做到按组件统计。</p><h1 id="C-的堆内存管理层级"><a href="#C-的堆内存管理层级" class="headerlink" title="C++ 的堆内存管理层级"></a>C++ 的堆内存管理层级</h1><p><img src="/img/monitor-memory/heap-hire.png"></p><h1 id="C-Custom-Allocator"><a href="#C-Custom-Allocator" class="headerlink" title="C++ Custom Allocator"></a>C++ Custom Allocator</h1><p>对于 stl 中的 container 类型提供，指⽰如何构造 <code>Container&lt;T, CustomAllocator&lt;T&gt;&gt;</code> 。因为⼤部分内存的占⽤都是通过 C++ 的容器对⼀些基本类型组合产⽣的，因此通过指定⾃⼰的 allocator 可以达到较⾼的覆盖率。<br>缺点：</p><ol><li>只对 stl 起作⽤，custom class 需要⾃⼰适配，并且会传染。</li><li>Stl 的接⼝也不同，诸如 std::map、std::vector 需要提供⼀个额外的参数。⽽ std::make_shared<br>需要被 std::allocated_shared 代替。修改成本⽐较⼤。</li><li>Allocator 是有类型的，所以不同 allocator 的容器之间不能简单实现互操作，除⾮使⽤ pmr。</li></ol><h2 id="pmr"><a href="#pmr" class="headerlink" title="pmr"></a>pmr</h2><p>需要⽤ std::pmr 下⾯的容器，同样具有传染性。</p><h1 id="C-Custom-global-operator-new"><a href="#C-Custom-global-operator-new" class="headerlink" title="C++ Custom global operator new"></a>C++ Custom global operator new</h1><p>可以通过下⾯实现⼀些类似 “thread_local memory tracker” 的功能，避免掉⼿动埋点。</p><ol><li>在 new 或者 delete 中调⽤ backtrace 获得前⼀帧，判断组件来源</li><li>设法 inline 这些 operator，然后给需要监控的 <code>__FUNCTION__</code> 加上特定的前缀</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> __attribute__((always_inline)) <span class="function"><span class="keyword">void</span> *<span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="keyword">size_t</span> size)</span></span></span><br><span class="line"><span class="function"><span class="title">noexcept</span><span class="params">(<span class="literal">false</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> wrap_malloc(size, __FILE__, __LINE__, __FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">inline</span> __attribute__((always_inline)) <span class="keyword">void</span> *<span class="keyword">operator</span> <span class="keyword">new</span>[](<span class="keyword">size_t</span> size)</span><br><span class="line"><span class="keyword">noexcept</span>(<span class="literal">false</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> wrap_malloc(size, __FILE__, __LINE__, __FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">inline</span> __attribute__((always_inline)) <span class="function"><span class="keyword">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="keyword">void</span> *ptr)</span> <span class="keyword">noexcept</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    wrap_free(ptr, __FILE__, __LINE__, __FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">inline</span> __attribute__((always_inline)) <span class="keyword">void</span> <span class="keyword">operator</span> <span class="keyword">delete</span>[](<span class="keyword">void</span> *ptr)</span><br><span class="line"><span class="keyword">noexcept</span> &#123;</span><br><span class="line">    wrap_free(ptr, __FILE__, __LINE__, __FUNCTION__);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>缺点：</p><ol><li>在 critical path 上，打击范围太⼴。C++ 实践中不太推荐这么做。</li></ol><h1 id="C-Custom-class-operator-new"><a href="#C-Custom-class-operator-new" class="headerlink" title="C++ Custom class operator new"></a>C++ Custom class operator new</h1><p>相⽐ global operator new 的⽅案，class operator new 的时候已经知道了对象的类型，所以打击范围不⼴。我们可以仅仅针对某些对象统计。<br>缺点：</p><ol><li>只能追踪通过 new 分配的内存。栈内存⼀般较⼩，所以这⼀点不是问题。</li><li>在对象内部再通过 new 分配的动态内存⽆法被追踪。也就意味着</li></ol><p>std::vector::push_back 、 std::make_shared 和 new T[] 这样的主⼒内存分配点⽆法被跟踪。<br>因此，基于这样的⽅案，需要在某个 T 提供⼀个 size() ⽅法，然后 hook 住 T 的 operator new，从⽽给到关于 T 的总内存占⽤的统计。例如对 Block 和 VersionedPageEntries 提供统计。<br>缺点：</p><ol><li>std::make_shared 直接调⽤ ::new，因此对此没有作⽤</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍 C++ 上的内存监控方案。&lt;/p&gt;
&lt;p&gt;默认使用 jemalloc。&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
    <category term="内存管理" scheme="http://www.calvinneo.com/tags/内存管理/"/>
    
  </entry>
  
  <entry>
    <title>系列拼装模型攻略</title>
    <link href="http://www.calvinneo.com/2024/06/17/ugears-rockr-etc/"/>
    <id>http://www.calvinneo.com/2024/06/17/ugears-rockr-etc/</id>
    <published>2024-06-17T03:57:20.000Z</published>
    <updated>2024-11-04T16:40:24.735Z</updated>
    
    <content type="html"><![CDATA[<p>记录 rokr、ugears 等拼装模型的过程和经验。</p><a id="more"></a><h1 id="Rokr-视界地球仪"><a href="#Rokr-视界地球仪" class="headerlink" title="Rokr 视界地球仪"></a>Rokr 视界地球仪</h1><h1 id="Rokr-夜城"><a href="#Rokr-夜城" class="headerlink" title="Rokr 夜城"></a>Rokr 夜城</h1><p>感觉是买到了劣等品，插轴套的时候非常困难，好几个轴套甚至都被我弄崩开了。</p><h1 id="Rokr-留声机"><a href="#Rokr-留声机" class="headerlink" title="Rokr 留声机"></a>Rokr 留声机</h1><p>留声机的大叶片的贴合很困难。官方视频都无法做到完全贴合。</p><h1 id="Rokr-蒸汽火车头"><a href="#Rokr-蒸汽火车头" class="headerlink" title="Rokr 蒸汽火车头"></a>Rokr 蒸汽火车头</h1><h1 id="盗版-Ugears-首饰盒"><a href="#盗版-Ugears-首饰盒" class="headerlink" title="盗版 Ugears 首饰盒"></a>盗版 Ugears 首饰盒</h1><p>零件公差太大，无法实现自动开合。</p><h1 id="盗版-Ugears-风琴"><a href="#盗版-Ugears-风琴" class="headerlink" title="盗版 Ugears 风琴"></a>盗版 Ugears 风琴</h1><p>零件公差太大，无法实现按压回弹。</p><h1 id="Rokr-放映机"><a href="#Rokr-放映机" class="headerlink" title="Rokr 放映机"></a>Rokr 放映机</h1><h1 id="Rokr-时之恒摆钟"><a href="#Rokr-时之恒摆钟" class="headerlink" title="Rokr 时之恒摆钟"></a>Rokr 时之恒摆钟</h1><p>部分轴的冗余不是很高，容易脱落。<br>打蜡和打磨一定要充分，不然很难拧得动最下层的动力齿轮。我觉得它的齿轮组有点太多了。</p><h1 id="Rokr-星辰之恋"><a href="#Rokr-星辰之恋" class="headerlink" title="Rokr 星辰之恋"></a>Rokr 星辰之恋</h1><h1 id="Rokr-转转杯"><a href="#Rokr-转转杯" class="headerlink" title="Rokr 转转杯"></a>Rokr 转转杯</h1><p>那几个柱子要注意，很容易短。而且也很容易组装错。</p><h1 id="Rokr-望远镜"><a href="#Rokr-望远镜" class="headerlink" title="Rokr 望远镜"></a>Rokr 望远镜</h1><h1 id="Rokr-摩托车"><a href="#Rokr-摩托车" class="headerlink" title="Rokr 摩托车"></a>Rokr 摩托车</h1><p>零件非常多，但是拼装起来很有意思。</p><h1 id="Rokr-小吉他"><a href="#Rokr-小吉他" class="headerlink" title="Rokr 小吉他"></a>Rokr 小吉他</h1><h1 id="Rokr-露营车"><a href="#Rokr-露营车" class="headerlink" title="Rokr 露营车"></a>Rokr 露营车</h1><h1 id="Roke-维多利亚台灯"><a href="#Roke-维多利亚台灯" class="headerlink" title="Roke 维多利亚台灯"></a>Roke 维多利亚台灯</h1><h1 id="Rokr-时间胶囊"><a href="#Rokr-时间胶囊" class="headerlink" title="Rokr 时间胶囊"></a>Rokr 时间胶囊</h1><p>胶水很拉胯，可以考虑双面胶。<br>另外亚克力零件比较脆。</p><h1 id="乐放-天空之城"><a href="#乐放-天空之城" class="headerlink" title="乐放 天空之城"></a>乐放 天空之城</h1><h1 id="Rokr-钢琴"><a href="#Rokr-钢琴" class="headerlink" title="Rokr 钢琴"></a>Rokr 钢琴</h1><h1 id="Rokr-印画工坊"><a href="#Rokr-印画工坊" class="headerlink" title="Rokr 印画工坊"></a>Rokr 印画工坊</h1><p>注意把手安装时的角度，以及方向。特别是红圈处的零件只能有一个，如果有三个说明装反了。这样就按压不了，而是往上抬了。<br><img src="/img/modules-wood/yhgf.jpg"></p><h1 id="Rokr-大提琴"><a href="#Rokr-大提琴" class="headerlink" title="Rokr 大提琴"></a>Rokr 大提琴</h1><h1 id="Rokr-逐梦之翼"><a href="#Rokr-逐梦之翼" class="headerlink" title="Rokr 逐梦之翼"></a>Rokr 逐梦之翼</h1><p>注意飞机的前后上下。</p><h1 id="Rokr-猫头鹰钟"><a href="#Rokr-猫头鹰钟" class="headerlink" title="Rokr 猫头鹰钟"></a>Rokr 猫头鹰钟</h1><p>和时之恒钟摆一样，转发条得用大力，所以齿轮间的磨合要充分打磨和上蜡。<br>定时组件的发条最好预置比较紧，这样每次上发条不要转很久。上发条出现咔咔声是正常的。<br>部分轴套较短。</p><h1 id="Rokr-降落伞"><a href="#Rokr-降落伞" class="headerlink" title="Rokr 降落伞"></a>Rokr 降落伞</h1><h1 id="Rokr-小猫头鹰"><a href="#Rokr-小猫头鹰" class="headerlink" title="Rokr 小猫头鹰"></a>Rokr 小猫头鹰</h1><h1 id="Rokr-电动恐龙"><a href="#Rokr-电动恐龙" class="headerlink" title="Rokr 电动恐龙"></a>Rokr 电动恐龙</h1><h1 id="Rokr-飞艇"><a href="#Rokr-飞艇" class="headerlink" title="Rokr 飞艇"></a>Rokr 飞艇</h1><h1 id="Rolife-摩天轮"><a href="#Rolife-摩天轮" class="headerlink" title="Rolife 摩天轮"></a>Rolife 摩天轮</h1><p>注意摩天轮有几个扇形。<br>注意摩天轮外部轴套的安装顺序。老版本会很松动。</p><h1 id="Rokr-挂钟"><a href="#Rokr-挂钟" class="headerlink" title="Rokr 挂钟"></a>Rokr 挂钟</h1><p>安装四个齿轮组的时候需要特别比对。对轴两端各插什么东西需要注意。</p><h1 id="Rolife-假日花房"><a href="#Rolife-假日花房" class="headerlink" title="Rolife 假日花房"></a>Rolife 假日花房</h1><p>要大量用到胶水，体验比较差。</p><h1 id="Ugears-钢片琴键"><a href="#Ugears-钢片琴键" class="headerlink" title="Ugears 钢片琴键"></a>Ugears 钢片琴键</h1><p>安装编谱器的时候需要注意，两侧的木轴套的内径是不一样的。不要强行按压。</p><p>在安装键盘 CDEFGAB 以及它下面的支架时，需要辨别方向。否则会导致后面的皮筋勾不住。</p><h1 id="Ugears-曲率仪"><a href="#Ugears-曲率仪" class="headerlink" title="Ugears 曲率仪"></a>Ugears 曲率仪</h1><h1 id="Rokr-基地"><a href="#Rokr-基地" class="headerlink" title="Rokr 基地"></a>Rokr 基地</h1><h1 id="Ugears-三球仪"><a href="#Ugears-三球仪" class="headerlink" title="Ugears 三球仪"></a>Ugears 三球仪</h1><p>c3 组件是地球公转系统的重要组成部分，这个组件很容易出现卡壳。这种情况下，无论如何上蜡和打磨，最好的结果也是组装完成后可以逆时针（朝自己）摇动把手，但公转不会起作用，且间歇性咔咔作响。此外，顺时针转动把手，或者世界逆时针转动 c3 都会卡壳。因此对 c3 组件需要充分调试：</p><ol><li>顺时针转动 c1，则 c3 可以流畅运行。</li><li>将 c6 和 c5 组装完成后，手动顺时针转动 c1，系统可以流畅运行。</li><li>将公转系统安装上去之后转动把手，可以流畅运行。<br> 如下所示可以单独拆出公转部分<br> <img src="/img/modules-wood/solar-system.png"><br> 以及地月系统<br> <img src="/img/modules-wood/the-earth.png"></li></ol><p>这里的关键在于 50 这个偏心组件必须牢牢被安装在轴上。如果它松动了，则 c3 的齿轮会倾斜，从而导致系统无法工作。因此建议用 502 胶水涂抹 50 内侧，让它变紧。或者必要时直接粘上去。</p><h1 id="Ugears-魁地奇球场"><a href="#Ugears-魁地奇球场" class="headerlink" title="Ugears 魁地奇球场"></a>Ugears 魁地奇球场</h1><p>计分器有问题，不知道怎么回事。<br>另外，球在掉下去之后，下方的轨道会被上面的板挡到。</p><h1 id="Rokr-巧克力工厂"><a href="#Rokr-巧克力工厂" class="headerlink" title="Rokr 巧克力工厂"></a>Rokr 巧克力工厂</h1><p>上面攒球的地方容易卡住。</p><h1 id="Rokr-空中飞椅"><a href="#Rokr-空中飞椅" class="headerlink" title="Rokr 空中飞椅"></a>Rokr 空中飞椅</h1><p>C 开头的很多插销很啰嗦，尽量别装错。</p><h1 id="Rokr-史密斯-M60"><a href="#Rokr-史密斯-M60" class="headerlink" title="Rokr 史密斯 M60"></a>Rokr 史密斯 M60</h1>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录 rokr、ugears 等拼装模型的过程和经验。&lt;/p&gt;</summary>
    
    
    
    
    <category term="游戏" scheme="http://www.calvinneo.com/tags/游戏/"/>
    
    <category term="拼装模型" scheme="http://www.calvinneo.com/tags/拼装模型/"/>
    
  </entry>
  
  <entry>
    <title>C++ 的 allocator 机制</title>
    <link href="http://www.calvinneo.com/2024/05/30/C++-allocator/"/>
    <id>http://www.calvinneo.com/2024/05/30/C++-allocator/</id>
    <published>2024-05-30T14:34:20.000Z</published>
    <updated>2024-05-30T17:45:59.929Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 C++ 的 allocator 机制</p><a id="more"></a><h1 id="allocator-的实现"><a href="#allocator-的实现" class="headerlink" title="allocator 的实现"></a>allocator 的实现</h1><p>默认的 allocator 的实现如下所示。可以发现这是基于 malloc 的。</p><p>因此，诸如 jemalloc 的内存管理机制对 C++ 同样是有作用的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdlib&gt; // for std::malloc and std::free</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;new&gt;     // for std::bad_alloc</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">allocator</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">using</span> value_type = T;</span><br><span class="line"></span><br><span class="line">    allocator() <span class="keyword">noexcept</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> U&gt;</span><br><span class="line">    allocator(<span class="keyword">const</span> allocator&lt;U&gt;&amp;) <span class="keyword">noexcept</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">T* <span class="title">allocate</span><span class="params">(<span class="built_in">std</span>::<span class="keyword">size_t</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (n &gt; <span class="built_in">std</span>::<span class="keyword">size_t</span>(<span class="number">-1</span>) / <span class="keyword">sizeof</span>(T))</span><br><span class="line">            <span class="keyword">throw</span> <span class="built_in">std</span>::bad_alloc();</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">auto</span> p = <span class="keyword">static_cast</span>&lt;T*&gt;(<span class="built_in">std</span>::<span class="built_in">malloc</span>(n * <span class="keyword">sizeof</span>(T))))</span><br><span class="line">            <span class="keyword">return</span> p;</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">std</span>::bad_alloc();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">deallocate</span><span class="params">(T* p, <span class="built_in">std</span>::<span class="keyword">size_t</span>)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">free</span>(p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span><br><span class="line"><span class="keyword">bool</span> <span class="keyword">operator</span>==(<span class="keyword">const</span> allocator&lt;T&gt;&amp;, <span class="keyword">const</span> allocator&lt;U&gt;&amp;) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span><br><span class="line"><span class="keyword">bool</span> <span class="keyword">operator</span>!=(<span class="keyword">const</span> allocator&lt;T&gt;&amp;, <span class="keyword">const</span> allocator&lt;U&gt;&amp;) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125; <span class="comment">// namespace std</span></span><br></pre></td></tr></table></figure><h1 id="std-pmr"><a href="#std-pmr" class="headerlink" title="std::pmr"></a>std::pmr</h1><p>Polymorphic Memory Resources 解决了什么问题？</p><ol><li>简化 custom allocator 的实现<br> 主要提供了 std::pmr::memory_resource 和 std::pmr::polymorphic_allocator。</li><li>动态类型<br> std::pmr::polymorphic_allocator 允许动态修改 allocator 的策略，而不需要修改 container 的代码。</li><li>提供了一些预定义的策略<br> std::pmr::monotonic_buffer_resource 是最简单的分配器。<br> std::pmr::unsynchronized_pool_resource 是基于 pool 的分配器。</li><li>可以跨多个 container 和 components 统一管理内存分配方案</li></ol><p>如下所示，需要用 <code>std::pmr</code> 下面的 container</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory_resource&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Create a buffer for monotonic_buffer_resource</span></span><br><span class="line">    <span class="keyword">char</span> buffer[<span class="number">1024</span>];</span><br><span class="line">    <span class="built_in">std</span>::pmr::monotonic_buffer_resource pool&#123;buffer, <span class="keyword">sizeof</span>(buffer)&#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Create a vector using the custom memory resource</span></span><br><span class="line">    <span class="built_in">std</span>::pmr::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec&#123;&amp;pool&#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Use the vector as usual</span></span><br><span class="line">    vec.push_back(<span class="number">1</span>);</span><br><span class="line">    vec.push_back(<span class="number">2</span>);</span><br><span class="line">    vec.push_back(<span class="number">3</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Memory-Trace-的讨论"><a href="#Memory-Trace-的讨论" class="headerlink" title="Memory Trace 的讨论"></a>Memory Trace 的讨论</h1><h2 id="operator-new-和自定义-allocator-的区别"><a href="#operator-new-和自定义-allocator-的区别" class="headerlink" title="operator new 和自定义 allocator 的区别"></a>operator new 和自定义 allocator 的区别</h2><p>In C++, both custom allocators and custom operator new play roles in managing memory allocation, but they serve different purposes and operate at different levels of abstraction.</p><p>Custom Allocator:</p><p>A custom allocator typically refers to a class that provides an interface for allocating and deallocating memory.<br>It’s a more general-purpose mechanism that can be used not only for dynamic memory allocation but also for other types of memory management, like managing memory pools or implementing specialized allocation strategies.<br>Custom allocators are often used with standard library containers like std::vector, std::map, etc., allowing you to customize how memory is allocated and deallocated for these containers.<br>Custom allocators are used through allocators traits like std::allocator_traits and can be customized for specific needs.</p><p>Custom operator new:<br>operator new is a language-level function used for dynamic memory allocation in C++. It’s responsible for allocating memory for objects.<br>Customizing operator new typically involves overloading it or providing a replacement function. This allows you to intercept and customize memory allocation behavior for individual types or globally.<br>This approach is more specific and low-level compared to custom allocators. It directly affects how memory is allocated for individual objects.<br>Custom operator new is often used when you need to apply specific allocation strategies or track memory usage at the level of individual objects rather than at the container level.<br>In summary, custom allocators offer a more flexible and higher-level approach to memory management, suitable for container classes and general-purpose memory management, while custom operator new provides a more direct and low-level means of customizing memory allocation behavior for individual objects.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍 C++ 的 allocator 机制&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
    <category term="Linux" scheme="http://www.calvinneo.com/tags/Linux/"/>
    
    <category term="并行计算" scheme="http://www.calvinneo.com/tags/并行计算/"/>
    
    <category term="多线程" scheme="http://www.calvinneo.com/tags/多线程/"/>
    
    <category term="atomic" scheme="http://www.calvinneo.com/tags/atomic/"/>
    
  </entry>
  
  <entry>
    <title>C++ Coroutine 介绍的翻译</title>
    <link href="http://www.calvinneo.com/2024/05/26/C++-coroutine/"/>
    <id>http://www.calvinneo.com/2024/05/26/C++-coroutine/</id>
    <published>2024-05-26T07:46:32.000Z</published>
    <updated>2024-07-15T12:33:46.022Z</updated>
    
    <content type="html"><![CDATA[<p>翻译 <a href="https://lewissbaker.github.io/" target="_blank" rel="noopener">lewissbaker</a> 的三篇文章。</p><a id="more"></a><h1 id="Coroutine-Theory"><a href="#Coroutine-Theory" class="headerlink" title="Coroutine Theory"></a>Coroutine Theory</h1><p>暂略</p><h1 id="Understanding-operator-co-await"><a href="#Understanding-operator-co-await" class="headerlink" title="Understanding operator co_await"></a>Understanding operator co_await</h1><p><a href="https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await" target="_blank" rel="noopener">https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await</a></p><p>有两个接口需要定义，Promise 和 Awaiter。</p><p>Promist 接口定义了 coroutine 自己的行为，例如 coroutine 被调用的时候应该做什么，应该返回什么，并且定义 co_await 或者 co_yield 在 coroutine 中的行为。</p><p>Awaitable 接口定义了 co_await 的语义。当我们 co_await 一个对象时，这个 co_await 会被转化为一系列调用，负责挂起当前的 coroutine，执行一些帮助它后续被重新调度起来的命令，以及一些在 resume 之后生成 co_await 返回值的命令。</p><h2 id="Awaiters-and-Awaitables-Explaining-operator-co-await"><a href="#Awaiters-and-Awaitables-Explaining-operator-co-await" class="headerlink" title="Awaiters and Awaitables: Explaining operator co_await"></a>Awaiters and Awaitables: Explaining operator co_await</h2><h3 id="Awaitable"><a href="#Awaitable" class="headerlink" title="Awaitable"></a>Awaitable</h3><p>如果一个类型支持 <code>co_await &lt;expr&gt;</code>，它就是一个 Awaitable 类型。</p><p>Promise 类型可以通过 await_transform 方法去修改 co_await 的 expr。下面将没有实现 await_transform 的类型称为 Normally Awaitable。将实现了 await_transform 的称为 Contextually Awaitable，此时这个类型只支持在一些特定类型的 coroutine 中被调用。</p><h3 id="Awaiter"><a href="#Awaiter" class="headerlink" title="Awaiter"></a>Awaiter</h3><p>一个 Awaiter 类型需要实现三个方法：await_ready, await_suspend 和 await_resume，它们加在一起组成了 co_await。</p><p>一个类型可以既是 Awaiter 又是 Awaitable。</p><h2 id="获取-Awaiter"><a href="#获取-Awaiter" class="headerlink" title="获取 Awaiter"></a>获取 Awaiter</h2><p>假设这个 awaiting coroutine 的 promise 对象的类型是 P，并且这个 <code>promise</code> 是对当前 coroutine 中的 P 实例的左值引用。</p><p>如果 P 有一个 await_transform 方法，那么 <code>expr</code> 就会被首先传给 <code>promise.await_transform(&lt;expr&gt;)</code>，以获得对应的 Awaitable 对象。否则，<code>expr</code> 的结果就会直接被作为 Awaitable 对象。不妨令为 <code>awaitable</code>。</p><p>Then, if the Awaitable object, awaitable, has an applicable operator co_await() overload then this is called to obtain the Awaiter object. Otherwise the object, awaitable, is used as the awaiter object.<br>然后，如果这个 Awaitable 对象 <code>awaitable</code> 有一个 <code>operator co_await()</code>，那么就可以通过调用它来获得一个 Awaiter 对象。否则就会直接使用 awaitable 作为 Awaiter 对象。</p><p>上面说的内容可以通过下面的代码来理解。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> P, <span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">decltype</span>(<span class="keyword">auto</span>) get_awaitable(P&amp; promise, T&amp;&amp; expr)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(has_any_await_transform_member_v&lt;P&gt;)</span></span></span><br><span class="line">    return promise.await_transform(static_cast&lt;T&amp;&amp;&gt;(expr));</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;T&amp;&amp;&gt;(expr);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Awaitable&gt;</span><br><span class="line"><span class="keyword">decltype</span>(<span class="keyword">auto</span>) get_awaiter(Awaitable&amp;&amp; awaitable)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(has_member_operator_co_await_v&lt;Awaitable&gt;)</span></span></span><br><span class="line">    return static_cast&lt;Awaitable&amp;&amp;&gt;(awaitable).operator co_await();</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> <span class="keyword">constexpr</span> (has_non_member_operator_co_await_v&lt;Awaitable&amp;&amp;&gt;)</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">operator</span> co_await(<span class="keyword">static_cast</span>&lt;Awaitable&amp;&amp;&gt;(awaitable));</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;Awaitable&amp;&amp;&gt;(awaitable);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【Q】为什么要区分 Awaiter 和 Awaitable 呢？</p><h2 id="Awaiting-the-Awaiter"><a href="#Awaiting-the-Awaiter" class="headerlink" title="Awaiting the Awaiter"></a>Awaiting the Awaiter</h2><p><code>co_await &lt;expr&gt;</code> 这个调用可以被转换成如下的形式。</p><p>注意，下面说的 caller 我理解就是 coroutine 的 caller。而 resumer 指的是 coroutine 在被重新调度执行后的“caller”。</p><p>await_suspend 有两个版本：</p><ol><li>返回 void 的版本<br> 在 await_suspend 调用返回后，会无条件将执行权转移给 caller 或者 resumer。</li><li>返回 bool 的版本<br> 允许有条件地立即 resume 这个 coroutine，而不是将执行权转移给 caller 或者 resumer。<br> 一般来说，如果这个 awaiter 需要执行的异步操作在一些情况下可能同步地完成，那么就可以在 await_suspend 中返回 false，让 coroutine 立即 resume 从而执行后面的逻辑。</li></ol><p>在 <code>&lt;suspend-coroutine&gt;</code> 处，编译期会生成一些代码，保存当前 coroutine 的状态以便后续恢复。比如存储 <code>&lt;resume-point&gt;</code> 的位置，以及将当前寄存器的状态保存在内存中等。</p><p>那么在 <code>&lt;suspend-coroutine&gt;</code> 之后就可以认为这个 coroutine 已经被 suspend 了。所以可以在 await_suspend 调用中首先可以观察到被挂起的 coroutine。此后，它可以被 resume 或者被 destroy。</p><p>await_suspend 还需要负责在 coroutine 的异步操作被完成后重新 resume 或者 destroy 掉这个 coroutine。</p><p>如果这个 coroutine 的异步操作是被同步完成的，就可以通过 await_ready 调用避免掉 <code>&lt;suspend-coroutine&gt;</code> 挂起 coroutine 的开销。<br>【Q】那么它和返回 bool 的 await_suspend 的区别是啥呢？感觉前者是给你决定要不要，后者是告诉你实际发生了什么。</p><p>在 <code>&lt;return-to-caller-or-resumer&gt;</code> 处，执行权会被重新转移给 caller 或者 resumer。此时会 popping the local stack frame but keeping the coroutine frame alive。</p><p>【Q】什么是 coroutine frame 呢？从下文可知，coroutine_handle 是一个 coroutine frame 的句柄，用来对它进行操作。可是它本体是啥呢？在<a href="https://lewissbaker.github.io/2017/09/25/coroutine-theory" target="_blank" rel="noopener">前文</a>中有介绍：</p><blockquote><p>The ‘coroutine frame’ holds part of the coroutine’s activation frame that persists while the coroutine is suspended and the ‘stack frame’ part only exists while the coroutine is executing and is freed when the coroutine suspends and transfers execution back to the caller/resumer.</p></blockquote><p>如果被挂起的 coroutine 最终是被 resume 的话，会在 <code>&lt;resume-point&gt;</code> 点被继续执行。</p><p>await_resume 调用的返回值会成为 co_await 的返回值。注意 await_resume 同样可能抛出异常，此时这个异常会被传播到 co_await 之外。</p><p>Note that if an exception propagates out of the await_suspend() call then the coroutine is automatically resumed and the exception propagates out of the co_await expression without calling await_resume().</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">co_await (T expr)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">auto</span>&amp;&amp; value = &lt;expr&gt;;</span><br><span class="line">  <span class="keyword">auto</span>&amp;&amp; awaitable = get_awaitable(promise, <span class="keyword">static_cast</span>&lt;<span class="keyword">decltype</span>(value)&gt;(value));</span><br><span class="line">  <span class="keyword">auto</span>&amp;&amp; awaiter = get_awaiter(<span class="keyword">static_cast</span>&lt;<span class="keyword">decltype</span>(awaitable)&gt;(awaitable));</span><br><span class="line">  <span class="keyword">if</span> (!awaiter.await_ready())</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">handle_t</span> = <span class="built_in">std</span>::experimental::coroutine_handle&lt;P&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">await_suspend_result_t</span> =</span><br><span class="line">      <span class="keyword">decltype</span>(awaiter.await_suspend(<span class="keyword">handle_t</span>::from_promise(p)));</span><br><span class="line"></span><br><span class="line">    &lt;suspend-coroutine&gt;</span><br><span class="line">    <span class="comment">// 此后可以认为该 coroutine 已经被 suspend 了</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// await_suspend 会处理诸如 rescheduling 的事情</span></span><br><span class="line">    <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(<span class="built_in">std</span>::is_void_v&lt;<span class="keyword">await_suspend_result_t</span>&gt;)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      awaiter.await_suspend(<span class="keyword">handle_t</span>::from_promise(p));</span><br><span class="line">      &lt;<span class="keyword">return</span>-to-caller-<span class="keyword">or</span>-resumer&gt;</span><br><span class="line">      <span class="comment">// 此后，执行权交还给 caller 或者 resumer</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">static_assert</span>(</span><br><span class="line">         <span class="built_in">std</span>::is_same_v&lt;<span class="keyword">await_suspend_result_t</span>, <span class="keyword">bool</span>&gt;,</span><br><span class="line">         <span class="string">"await_suspend() must return 'void' or 'bool'."</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (awaiter.await_suspend(<span class="keyword">handle_t</span>::from_promise(p)))</span><br><span class="line">      &#123;</span><br><span class="line">        &lt;<span class="keyword">return</span>-to-caller-<span class="keyword">or</span>-resumer&gt;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &lt;resume-point&gt;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> awaiter.await_resume();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Coroutine-Handles"><a href="#Coroutine-Handles" class="headerlink" title="Coroutine Handles"></a>Coroutine Handles</h2><p>在上文中，一个 <code>coroutine_handle&lt;P&gt;</code> 类型的对象会被传给 await_suspend，作为 await_suspend 的参数。这个类型是对 coroutine frame 的一个非 owning 的句柄。可以通过它来 resume 或者 destroy。同时，还可以用它来访问 coroutine 的 promise 对象。</p><p>coroutine_handle 有类似下面的结构</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>::experimental</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Promise&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_handle</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span>&lt;&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_handle</span>&lt;void&gt;</span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">done</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">resume</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span>* <span class="title">address</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> coroutine_handle <span class="title">from_address</span><span class="params">(<span class="keyword">void</span>* address)</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Promise&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_handle</span> :</span> coroutine_handle&lt;<span class="keyword">void</span>&gt;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="function">Promise&amp; <span class="title">promise</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> coroutine_handle <span class="title">from_promise</span><span class="params">(Promise&amp; promise)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> coroutine_handle <span class="title">from_address</span><span class="params">(<span class="keyword">void</span>* address)</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>resume<br> 当异步动作完成，需要 resume 这个 coroutine 的时候，应该调用 resume 方法。此时会在 <code>&lt;resume-point&gt;</code> 继续执行 coroutine。<br> 对 resume 本身的调用会在 coroutine 下一次碰到 <code>&lt;return-to-caller-or-resumer&gt;</code> 的时候返回。</li><li>destroy<br> 会销毁当前的 coroutine feame。<br> 一般来说不需要调用这个方法，除非是库的作者在实现 promise 类型的时候。<br> 一般来说，coroutine frame 会被调用 coroutine 时返回的 RAII 类型所持有。所以需要避免 double-destruction bug。</li><li>promise<br> 返回 coroutine 的 promise 对象的引用。<br> 对于大多数 Normally Awaitable 类型，应当使用 <code>coroutine_handle&lt;void&gt;</code> 作为 await_suspend 的参数，而不是 <code>coroutine_handle&lt;Promise&gt;</code>。<br> <code>coroutine_handle&lt;P&gt;::from_promise(P&amp; promise)</code> 这个函数可以由 coroutine promise 对象的引用来<strong>重新构造</strong> coroutine_handle。注意必须要保证 P 和 coroutine frame 使用的 concrete promise type 是一致的。也就是说如果创建 <code>coroutine_handle&lt;Base&gt;</code>，但是实际的 promise type 是 Derived 会导致 UB。</li><li>address/from_address<br> 将一个 coroutine handle 和 void* 指针进行互相转化。它的目的主要是和 C 语言的接口交互。<br> 但一般来说，在实现时经常发现还需要打包发送其他上下文，所以一般来说会将 <code>coroutine_handle</code> 放到一个结构中，并返回结构的指针。</li></ol><h2 id="Synchronisation-free-async-code"><a href="#Synchronisation-free-async-code" class="headerlink" title="Synchronisation-free async code"></a>Synchronisation-free async code</h2><p>co_await 的一个作用是可以在 coroutine 被 suspend 之后，和被 caller/resumer 重新获得执行权之前的这段时间中执行代码。</p><p>也就是说，Awaiter 对象会在 coroutine 被 suspend 之后启动一个 async 操作，将 <code>coroutine_handle</code> 传给这个 async 操作，让它能在完成后去 resume 之前的 coroutine。注意这个 coroutine 可能是在另一个线程中被 resume 了。整个过程中并不需要任何的同步开销。</p><p>举个例子，一段代码在线程 A 中执行，使用 coroutine 去做一个异步读，那么 Awaiter 可以在 await_suspend 中启动这个异步读，而这个异步读是在线程 B 中被实际处理的。但线程 A 和线程 B 之间是没有任何同步开销的。比如没有通过条件变量或者 channel 进行等待。如下面所示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Time     Thread A                           Thread B</span><br><span class="line">  |      --------                           --------</span><br><span class="line">  |      ....                               Call OS - Wait for I/O event</span><br><span class="line">  |      Call await_ready()                    |</span><br><span class="line">  |      &lt;supend-point&gt;                        |</span><br><span class="line">  |      Call await_suspend(handle)            |</span><br><span class="line">  |        Store handle in operation           |</span><br><span class="line">  V        Start AsyncFileRead ---+            V</span><br><span class="line">                                  +-----&gt;   &lt;AsyncFileRead Completion Event&gt;</span><br><span class="line">                                            Load coroutine_handle from operation</span><br><span class="line">                                            Call handle.resume()</span><br><span class="line">                                              &lt;resume-point&gt;</span><br><span class="line">                                              Call to await_resume()</span><br><span class="line">                                              execution continues....</span><br><span class="line">           Call to AsyncFileRead returns</span><br><span class="line">         Call to await_suspend() returns</span><br><span class="line">         &lt;return-to-caller/resumer&gt;</span><br></pre></td></tr></table></figure><p>在上面的伪代码中还需要注意：</p><ol><li>如果异步任务把 <code>coroutine_handle</code> 传给了另一个线程，那么这个线程就可能在 await_suspend 返回之前就 resume 这个 coroutine。这样，就会和 await_suspend 方法剩下来的部分竞争。</li><li>当 resume 一个 coroutine 的时候，首先需要调用 await_resume 去获得异步任务的结果。一般与此同时会立即析构掉 Awaiter 对象（可以看看上面的 demo）。因为 Awaiter 对象实际上就是 await_suspend 的 this 指针，所以 coroutine 可能会在 await_suspend 调用之前就 destruct 掉 coroutine 和 promise 对象。</li></ol><p>因此，在 await_suspend 方法中，一旦 coroutine 可以在另一个线程上并发地 resume，就需要保证不会再去访问 this 或者 coroutine 的 promise() 对象了，因为它们可能都被销毁了。实际上，当 coroutine 已经 scheduled for resumption 的时候，唯一能安全访问的只有 await_suspend 中的本地变量了。</p><h2 id="Comparison-to-Stackful-Coroutines"><a href="#Comparison-to-Stackful-Coroutines" class="headerlink" title="Comparison to Stackful Coroutines"></a>Comparison to Stackful Coroutines</h2><p>和诸如 win32 的 fiber 或者 boost::context 这样的有栈协程相比：<br>在很多有栈协程中，suspend 操作通常会伴随着 resume 另一个 coroutine，从而组合成为一个 context-switch 操作。而这个操作会导致没有机会再 suspend 当前 coroutine 之后，以及将执行权转移到另一个 coroutine 之前执行一些逻辑。<br>而这就意味着如果需要实现一个类似的 async-file-read 操作，就需要在 suspend 这个 coroutine 之前就开启这个操作。因此这个操作可能就会在当前 coroutine 被 suspend 之前，就在另一个线程中被执行完了，而当前 coroutine 因此又要被 resume。这就在这两个线程之间引入了 race。而如上所述，C++ 的 coroutine 不需要在线程 A 和线程 B 之间引入同步机制。</p><p>There are probably ways around this by using a trampoline context that can start the operation on behalf of the initiating context after the initiating context has been suspended. However this would require extra infrastructure and an extra context-switch to make it work and it’s possible that the overhead this introduces would be greater than the cost of the synchronisation it’s trying to avoid.</p><h2 id="Avoiding-memory-allocations"><a href="#Avoiding-memory-allocations" class="headerlink" title="Avoiding memory allocations"></a>Avoiding memory allocations</h2><p>async 操作需要分配一些内存。比如在 win32 io 函数接口中，需要分配一个 OVERLAPPED 结构，这个结构需要在操作完成之后才会被释放。因此这样的结构必须要分配在堆上，并且每个 async 操作都需要 allocate 一次。因此在这里可以使用一个对象池来优化。</p><p>但是在 C++ 的 coroutine 中，可以避免堆内存分配，因为 local variable 在 coroutine 被 suspend 的时候会在 coroutine frame 里面，从而肯定是存活的。</p><p>将 per-operation state 存放在 Awaiter 对象中，可以白嫖 coroutine frame，从而延续到至少是 co_await expression 的 lifetime。一旦这个 operation 完成，coroutine 就会 resume，然后 Awaiter 对象就会被销毁。</p><p>当然，coroutine frame 本身还是会在堆上分配的，但是，一旦它被分配，是可以被用来执行很多个 async 操作的。这就好像是一个 arena memory allocator 一样，编译期可以在编译期计算出 local variable 的大小，然后就可以一次性分配出来了。</p><p>【Q】没太明白为啥 coroutine frame 是可以被复用的。我理解应该是指的可以 co_await 很多次。</p><h2 id="An-example-Implementing-a-simple-thread-synchronisation-primitive"><a href="#An-example-Implementing-a-simple-thread-synchronisation-primitive" class="headerlink" title="An example: Implementing a simple thread-synchronisation primitive"></a>An example: Implementing a simple thread-synchronisation primitive</h2><p>下面是一个简单的多生产者-多消费者模型。如果 set 已经被调用过了，那么后续的 consumer 就不会 suspend 了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">T value;</span><br><span class="line">async_manual_reset_event event;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A single call to produce a value</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">producer</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  value = some_long_running_computation();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Publish the value by setting the event.</span></span><br><span class="line">  event.<span class="built_in">set</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Supports multiple concurrent consumers</span></span><br><span class="line">task&lt;&gt; consumer()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// Wait until the event is signalled by call to event.set()</span></span><br><span class="line">  <span class="comment">// in the producer() function.</span></span><br><span class="line">  co_await event;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Now it's safe to consume 'value'</span></span><br><span class="line">  <span class="comment">// This is guaranteed to 'happen after' assignment to 'value'</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; value &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的设计就是用一个 <code>std::atomic&lt;void*&gt;</code> 指针。它要么指向 this，说明已经 set 了；要么指向一个链表的表头，表示正在 suspend 的链表。</p><p>在这里，我们也实现了上面提到的节省内存分配的方案，将链表的 node 分配在 awaiter 对象里面，而 awaiter 对象在 coroutine frame 上面。</p><p>总而言之，代码如下所示。它支持 co_await，所以是个 Awaitable 类型。co_await 操作符返回一个 awaiter 也就是后面要实现的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">async_manual_reset_event</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">  async_manual_reset_event(<span class="keyword">bool</span> initiallySet = <span class="literal">false</span>) <span class="keyword">noexcept</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// No copying/moving</span></span><br><span class="line">  async_manual_reset_event(<span class="keyword">const</span> async_manual_reset_event&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  async_manual_reset_event(async_manual_reset_event&amp;&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  async_manual_reset_event&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> async_manual_reset_event&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  async_manual_reset_event&amp; <span class="keyword">operator</span>=(async_manual_reset_event&amp;&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">is_set</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">awaiter</span>;</span></span><br><span class="line">  <span class="function">awaiter <span class="keyword">operator</span> <span class="title">co_await</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set</span><span class="params">()</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">reset</span><span class="params">()</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"></span><br><span class="line">  <span class="keyword">friend</span> <span class="class"><span class="keyword">struct</span> <span class="title">awaiter</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// - 'this' =&gt; set state</span></span><br><span class="line">  <span class="comment">// - otherwise =&gt; not set, head of linked list of awaiter*.</span></span><br><span class="line">  <span class="keyword">mutable</span> <span class="built_in">std</span>::atomic&lt;<span class="keyword">void</span>*&gt; m_state;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个 awaiter 如下所示:</p><ol><li>首先，它要持有一个 Awaitable 对象的指针，这是因为它要知道自己是要 await 什么东西。</li><li>然后，它还要扮演一个在 awaiter 链表里面的一个节点的角色，所以它应该能访问自己后面的那个 awaiter。</li><li>然后，它还要存储 coroutine_handle 对象，这样当 await_suspend 被调用后，它能知道如何去 resume coroutine。因为我们没 await_transform 啥的，所以这里 coroutine_handle 对象就是 <code>coroutine_handle&lt;void&gt;</code>。</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">async_manual_reset_event</span>:</span>:awaiter</span><br><span class="line">&#123;</span><br><span class="line">  awaiter(<span class="keyword">const</span> async_manual_reset_event&amp; event) <span class="keyword">noexcept</span></span><br><span class="line">  : m_event(event)</span><br><span class="line">  &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt; awaitingCoroutine)</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> async_manual_reset_event&amp; m_event;</span><br><span class="line">  <span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt; m_awaitingCoroutine;</span><br><span class="line">  awaiter* m_next;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>await_ready 要做的就是如果已经 set 了，就不再 suspend。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> async_manual_reset_event::awaiter::await_ready() <span class="keyword">const</span> <span class="keyword">noexcept</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">return</span> m_event.is_set();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>await_suspend 最为重要：</p><ol><li>首先，它要保存 coroutine_handle，从而后续可以调用 <code>coroutine_handle.resume()</code> 方法。</li><li>然后，就要将 awaiter 放到链表里面<br> 将链表头的指针即 m_state 设置为 this。注意，这里的 this 是 awaiter；而 oldValue 是 async_manual_reset_event，即 Awaitable。<br> 如果添加成功，就返回 true，表示不会立即 resume 这个 coroutine。否则，就返回 false，表示可以立即 resume。这也回答了之前的一个【Q】，也就是 await_suspend 和 await_ready 的返回值到底作用有什么不同。</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> async_manual_reset_event::awaiter::await_suspend(</span><br><span class="line">  <span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt; awaitingCoroutine) <span class="keyword">noexcept</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// Special m_state value that indicates the event is in the 'set' state.</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">void</span>* <span class="keyword">const</span> setState = &amp;m_event;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Remember the handle of the awaiting coroutine.</span></span><br><span class="line">  m_awaitingCoroutine = awaitingCoroutine;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Try to atomically push this awaiter onto the front of the list.</span></span><br><span class="line">  <span class="keyword">void</span>* oldValue = m_event.m_state.load(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// Resume immediately if already in 'set' state.</span></span><br><span class="line">    <span class="keyword">if</span> (oldValue == setState) <span class="keyword">return</span> <span class="literal">false</span>; </span><br><span class="line"></span><br><span class="line">    <span class="comment">// Update linked list to point at current head.</span></span><br><span class="line">    m_next = <span class="keyword">static_cast</span>&lt;awaiter*&gt;(oldValue);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Finally, try to swap the old list head, inserting this awaiter</span></span><br><span class="line">    <span class="comment">// as the new list head.</span></span><br><span class="line">  &#125; <span class="keyword">while</span> (!m_event.m_state.compare_exchange_weak(</span><br><span class="line">             oldValue,</span><br><span class="line">             <span class="keyword">this</span>,</span><br><span class="line">             <span class="built_in">std</span>::memory_order_release,</span><br><span class="line">             <span class="built_in">std</span>::memory_order_acquire));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Successfully enqueued. Remain suspended.</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【Q】这里 await_resume 起到了什么作用，为啥它是空的？</p><h2 id="Filling-out-the-rest-of-the-event-class"><a href="#Filling-out-the-rest-of-the-event-class" class="headerlink" title="Filling out the rest of the event class"></a>Filling out the rest of the event class</h2><p>如果是 set 状态，则改为 nullptr。所以 m_state 有三种情况：</p><ol><li>nullptr<br> 没有 set，但是也没有 awaiter 在等</li><li>oldValue<br> set 了</li><li>其他<br> 有 awaiter 在等，并且指向了链表头</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> async_manual_reset_event::reset() <span class="keyword">noexcept</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">void</span>* oldValue = <span class="keyword">this</span>;</span><br><span class="line">  m_state.compare_exchange_strong(oldValue, <span class="literal">nullptr</span>, <span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面是 set 操作。其实有点类似于 CV。实际上的行为就是对所有的 waiter 调用 <code>coroutine_handle.resume()</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> async_manual_reset_event::<span class="built_in">set</span>() <span class="keyword">noexcept</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// Needs to be 'release' so that subsequent 'co_await' has</span></span><br><span class="line">  <span class="comment">// visibility of our prior writes.</span></span><br><span class="line">  <span class="comment">// Needs to be 'acquire' so that we have visibility of prior</span></span><br><span class="line">  <span class="comment">// writes by awaiting coroutines.</span></span><br><span class="line">  <span class="keyword">void</span>* oldValue = m_state.exchange(<span class="keyword">this</span>, <span class="built_in">std</span>::memory_order_acq_rel);</span><br><span class="line">  <span class="keyword">if</span> (oldValue != <span class="keyword">this</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// Wasn't already in 'set' state.</span></span><br><span class="line">    <span class="comment">// Treat old value as head of a linked-list of waiters</span></span><br><span class="line">    <span class="comment">// which we have now acquired and need to resume.</span></span><br><span class="line">    <span class="keyword">auto</span>* waiters = <span class="keyword">static_cast</span>&lt;awaiter*&gt;(oldValue);</span><br><span class="line">    <span class="keyword">while</span> (waiters != <span class="literal">nullptr</span>)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// Read m_next before resuming the coroutine as resuming</span></span><br><span class="line">      <span class="comment">// the coroutine will likely destroy the awaiter object.</span></span><br><span class="line">      <span class="keyword">auto</span>* next = waiters-&gt;m_next;</span><br><span class="line">      waiters-&gt;m_awaitingCoroutine.resume();</span><br><span class="line">      waiters = next;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【Q】这里的 awaiter 都是在什么地方被析构的呢？我理解这里的 awaiter 都是 local variable，生命周期等同于 co_await 的 <code>&lt;expr&gt;</code>。可以看到，co_await 返回的就是这个 awaiter。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">async_manual_reset_event::awaiter</span><br><span class="line">async_manual_reset_event::<span class="function"><span class="keyword">operator</span> <span class="title">co_await</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> awaiter&#123; *<span class="keyword">this</span> &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="https://godbolt.org/g/Ad47tH" target="_blank" rel="noopener">https://godbolt.org/g/Ad47tH</a> 是源码</p><h1 id="Understanding-the-promise-type"><a href="#Understanding-the-promise-type" class="headerlink" title="Understanding the promise type"></a>Understanding the promise type</h1><p><a href="https://lewissbaker.github.io/2018/09/05/understanding-the-promise-type" target="_blank" rel="noopener">https://lewissbaker.github.io/2018/09/05/understanding-the-promise-type</a></p><h2 id="Coroutine-Concepts"><a href="#Coroutine-Concepts" class="headerlink" title="Coroutine Concepts"></a>Coroutine Concepts</h2><p>Promise 接口用来自定义 coroutine 自己的行为，比如它被调用的时候，或者它返回（无论是正常值还是异常）的时候。</p><h2 id="Promise-objects"><a href="#Promise-objects" class="headerlink" title="Promise objects"></a>Promise objects</h2><p>字如其名，Promise 确实有类似 <code>std::promise</code> 的作用，但是它的功能更为衍生，实际上应该将它理解为一个 coroutine state controller。</p><p>比如，写了一个 coroutine function，编译器会转换成下面的形式，其中 <code>&lt;body-statements&gt;</code> 是函数体。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  co_await promise.initial_suspend();</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    &lt;body-statements&gt;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">catch</span> (...)</span><br><span class="line">  &#123;</span><br><span class="line">    promise.unhandled_exception();</span><br><span class="line">  &#125;</span><br><span class="line">FinalSuspend:</span><br><span class="line">  co_await promise.final_suspend();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当 coroutine 被调用的时候，会：</p><ol><li>【可选】用 operator new 分配一个 coroutine frame。<br> 【Q】为什么这里是可选的？见下文。</li><li>将 parameter 拷贝到 coroutine frame 里面。</li><li>调用 P 的构造函数创建 promise 对象。</li><li>调用 <code>promise.get_return_object()</code> 方法会得到一个东西，可以在第一次 suspend 的时候返回给 caller。这个东西被保存为 local variable。<br> 我理解这个东西，也就是后面会看到的 <code>task</code> 就是 “Coroutine 本身”。特别地：<ul><li><code>task</code> 里面会持有一个 std::coroutine_handle 对象。</li><li><code>task</code> 里面会支持 co_await 操作符，也就是说它是一个 Awaitable 对象。</li><li>promise 对象的类型就是 <code>task::promise_type</code>。</li></ul></li><li>调用 <code>promise.initial_suspend()</code>，并 <code>co_await</code> 结果。</li><li>当 co_await <code>promise.initial_suspend()</code> resume（这里同样可能不挂起直接返回），coroutine 开始执行 <code>&lt;body-statements&gt;</code>。</li></ol><p>在 co_return 被执行的时候，会：</p><ol><li>调用 <code>promise.return_void()</code> 或者 <code>promise.return_value(&lt;expr&gt;)</code>。</li><li>销毁所有的自动变量。</li><li>调用 <code>promise.final_suspend()</code>，并且 co_await 结果。</li></ol><p>特别地，如果 <code>&lt;body-statements&gt;</code> 抛出异常，则：</p><ol><li>捕获这个异常，并调用 <code>promise.unhandled_exception()</code>。</li><li>调用 <code>promise.final_suspend()</code>，并且 co_await 结果。</li></ol><p>一旦 execution propagates outside of the coroutine body，那么 coroutine frame 就会被销毁。此时：</p><ol><li>调用 promise 对象的析构函数。</li><li>调用 parameter 的析构函数。</li><li>【可选】调用 operator delete 释放内存。</li><li>将执行权交还给 resumer 或者 caller。</li></ol><p>当第一次执行到 <code>&lt;return-to-caller-or-resumer&gt;</code> 的时候，或者 coroutine 没有执行到这个点就完成了，那么这个 coroutine 要么是 suspend 了，要么是 destroy 了。此时这之前通过调用 <code>promise.get_return_object()</code> 得到的 return-object 会被直接返回给 caller。回顾下，这里的 <code>&lt;return-to-caller-or-resumer&gt;</code> 是在 <code>co_await</code> 中，执行完 <code>await_suspend</code> 之后的点。</p><h2 id="Allocating-a-coroutine-frame"><a href="#Allocating-a-coroutine-frame" class="headerlink" title="Allocating a coroutine frame"></a>Allocating a coroutine frame</h2><p>First, the compiler generates a call to operator new to allocate memory for the coroutine frame.</p><p>If the promise type, P, defines a custom operator new method then that is called, otherwise the global operator new is called.</p><p>要点：</p><ol><li>operator new 分配的大小并不是 sizeof(P)，而是整个 coroutine frame 的大小，这个是由编译器计算的。包含了 parameter，promise 对象，local variables 以及其他的一些用来存储 coroutine state 的结构。我理解之前我们白嫖的也是这一段的空间。</li><li>编译期可以省略这个 operator new，而直接在 caller 的 stack-frame 或者 coroutine-frame 中分配，当：<ul><li>可以断定 coroutine frame 的生命周期是小于 caller 的。</li><li>并且编译期可以在调用的时候就能看到整个 coroutine frame 需要的大小。<br>目前 Coroutine TS 并没有 guarantee 任何的 elision 的情况，所以我们要处理分配 coroutine frame 的时候出现 std::bad_alloc 的情况。这里有一些异常处理相关的问题，一般我们就直接 terminate 掉了。但如果 promise 对象支持静态的 <code>P::get_return_object_on_allocation_failure()</code> 函数，则可以不抛出异常。</li></ul></li></ol><h3 id="Customising-coroutine-frame-memory-allocation"><a href="#Customising-coroutine-frame-memory-allocation" class="headerlink" title="Customising coroutine frame memory allocation"></a>Customising coroutine frame memory allocation</h3><p>Your promise type can define an overload of operator new() that will be called instead of global-scope operator new if the compiler needs to allocate memory for a coroutine frame that uses your promise type.</p><p>For example:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">my_promise_type</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span>* <span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="built_in">std</span>::<span class="keyword">size_t</span> size)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">void</span>* ptr = my_custom_allocate(size);</span><br><span class="line">    <span class="keyword">if</span> (!ptr) <span class="keyword">throw</span> <span class="built_in">std</span>::bad_alloc&#123;&#125;;</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="keyword">void</span>* ptr, <span class="built_in">std</span>::<span class="keyword">size_t</span> size)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    my_custom_free(ptr, size);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>同样，也可以提供一个 custom allocator。如下所示，可以提供一个重载版本的 <code>P::operator new()</code>，它额外接受诸如 allocator 这样的参数，这样就可以在 new 的时候调用 <code>allocator.allocate()</code> 来分配内存了。</p><p>这里有个问题，coroutine frame 中存储的 parameter 在 <code>operator delete</code> 之前就已经被析构了，那如何获得 allocator 呢？所以，为了能在 <code>operator delete</code> 中调用 <code>allocator.deallocate()</code>，我们要将 allocator 存在 <code>allocatorOffset</code> 上面。</p><p>简而言之，就是在创建 my_promise_type 之前分配空间的时候，多分配一部分空间，用来存放对应的 allocator。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> ALLOCATOR&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">my_promise_type</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span>... ARGS&gt;</span><br><span class="line">  <span class="function"><span class="keyword">void</span>* <span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="built_in">std</span>::<span class="keyword">size_t</span> sz, <span class="built_in">std</span>::<span class="keyword">allocator_arg_t</span>, ALLOCATOR&amp; allocator, ARGS&amp;... args)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="comment">// Round up sz to next multiple of ALLOCATOR alignment</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="keyword">size_t</span> allocatorOffset =</span><br><span class="line">      (sz + <span class="keyword">alignof</span>(ALLOCATOR) - <span class="number">1u</span>) &amp; ~(<span class="keyword">alignof</span>(ALLOCATOR) - <span class="number">1u</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Call onto allocator to allocate space for coroutine frame.</span></span><br><span class="line">    <span class="keyword">void</span>* ptr = allocator.allocate(allocatorOffset + <span class="keyword">sizeof</span>(ALLOCATOR));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Take a copy of the allocator (assuming noexcept copy constructor here)</span></span><br><span class="line">    <span class="keyword">new</span> (((<span class="keyword">char</span>*)ptr) + allocatorOffset) ALLOCATOR(allocator);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="keyword">void</span>* ptr, <span class="built_in">std</span>::<span class="keyword">size_t</span> sz)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="keyword">size_t</span> allocatorOffset =</span><br><span class="line">      (sz + <span class="keyword">alignof</span>(ALLOCATOR) - <span class="number">1u</span>) &amp; ~(<span class="keyword">alignof</span>(ALLOCATOR) - <span class="number">1u</span>);</span><br><span class="line"></span><br><span class="line">    ALLOCATOR&amp; allocator = *<span class="keyword">reinterpret_cast</span>&lt;ALLOCATOR*&gt;(</span><br><span class="line">      ((<span class="keyword">char</span>*)ptr) + allocatorOffset);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Move allocator to local variable first so it isn't freeing its</span></span><br><span class="line">    <span class="comment">// own memory from underneath itself.</span></span><br><span class="line">    <span class="comment">// Assuming allocator move-constructor is noexcept here.</span></span><br><span class="line">    ALLOCATOR allocatorCopy = <span class="built_in">std</span>::move(allocator);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// But don't forget to destruct allocator object in coroutine frame</span></span><br><span class="line">    allocator.~ALLOCATOR();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Finally, free the memory using the allocator.</span></span><br><span class="line">    allocatorCopy.deallocate(ptr, allocatorOffset + <span class="keyword">sizeof</span>(ALLOCATOR));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>To hook up the custom <code>my_promise_type</code> to be used for coroutines that pass <code>std::allocator_arg</code> as the first parameter, you need to specialise the <code>coroutine_traits</code> class (see section on coroutine_traits below for more details).</p><p>For example:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>::experimental</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> ALLOCATOR, <span class="keyword">typename</span>... ARGS&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_traits</span>&lt;my_return_type, std::allocator_arg_t, ALLOCATOR, ARGS...&gt;</span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">    <span class="keyword">using</span> promise_type = my_promise_type&lt;ALLOCATOR&gt;;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Note that even if you customise the memory allocation strategy for a coroutine, the compiler is still allowed to elide the call to your memory allocator.</p><h2 id="Copying-parameters-to-the-coroutine-frame"><a href="#Copying-parameters-to-the-coroutine-frame" class="headerlink" title="Copying parameters to the coroutine frame"></a>Copying parameters to the coroutine frame</h2><p>The coroutine needs to copy any parameters passed to the coroutine function by the original caller into the coroutine frame so that they remain valid after the coroutine is suspended.</p><p>复制 parameter 到 coroutine frame 的目的是保证了 coroutine 被 suspend 之后，这些东西都还在。</p><ol><li>如果是 by value 的复制，那么会调用 move-ctor。</li><li>如果是 by reference 的复制，无论是左值还是右值，那么只有引用本身会被复制，指向的对象是不会的。</li></ol><p>对于只有 trivial destructor 的 parameter，编译器可以 elide 掉 copy，如果这个 parameter 在某个可达的 <code>&lt;return-to-caller-or-resumer&gt;</code> 之后就不再被访问了。</p><p>C++ 中用完美转发会比较多，这在 coroutine 中经常会导致 UB。原因就是传入了 reference。</p><p>If any of the parameter copy/move constructors throws an exception then any parameters already constructed are destructed, the coroutine frame is freed and the exception propagates back out to the caller.</p><h2 id="Constructing-the-promise-object"><a href="#Constructing-the-promise-object" class="headerlink" title="Constructing the promise object"></a>Constructing the promise object</h2><p>先复制 parameter 再构造 promise 的原因是允许 promise 对象可以基于复制后的 parameter 构建。</p><p>First, the compiler checks to see if there is an overload of the promise constructor that can accept lvalue references to each of the copied parameters. If the compiler finds such an overload then the compiler generates a call to that constructor overload. If it does not find such an overload then the compiler falls back to generating a call to the promise type’s default constructor.</p><p>这个听起来挺神奇的，好像是既支持“默认”的 aggregate initialization，又支持 default initialization。</p><blockquote><p>Note that the ability for the promise constructor to “peek” at the parameters was a relatively recent change to the Coroutines TS, being adopted in N4723 at the Jacksonville 2018 meeting. See P0914R1 for the proposal. Thus it may not be supported by some older versions of Clang or MSVC.</p></blockquote><p>If the promise constructor throws an exception then the parameter copies are destructed and the coroutine frame freed during stack unwinding before the exception propagates out to the caller.</p><h2 id="Obtaining-the-return-object"><a href="#Obtaining-the-return-object" class="headerlink" title="Obtaining the return object"></a>Obtaining the return object</h2><p>The first thing a coroutine does with the promise object is obtain the return-object by calling promise.get_return_object().</p><p>在 coroutine 被建立后，首先是调用 <code>promise.get_return_object()</code> 获取 return-object。return-object 后续会被返回给 coroutine 的 caller。如前文所说，返回的时间点是第一次 suspend，或者 coroutine 完成了。</p><p>执行大抵如下。注意，在 “Coroutine Handles” 这一节中介绍了，可以通过 from_promise 从 promise 重新构建出 coroutine_handle。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Pretend there's a compiler-generated structure called 'coroutine_frame'</span></span><br><span class="line"><span class="comment">// that holds all of the state needed for the coroutine. It's constructor</span></span><br><span class="line"><span class="comment">// takes a copy of parameters and default-constructs a promise object.</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">coroutine_frame</span> &#123;</span> ... &#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">T <span class="title">some_coroutine</span><span class="params">(P param)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">auto</span>* f = <span class="keyword">new</span> coroutine_frame(<span class="built_in">std</span>::forward&lt;P&gt;(param));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> returnObject = f-&gt;promise.get_return_object();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Start execution of the coroutine body by resuming it.</span></span><br><span class="line">  <span class="comment">// This call will return when:</span></span><br><span class="line">  <span class="comment">// 1. the coroutine gets to the first suspend-point</span></span><br><span class="line">  <span class="comment">// 2. or when the coroutine runs to completion.</span></span><br><span class="line">  coroutine_handle&lt;<span class="keyword">decltype</span>(f-&gt;promise)&gt;::from_promise(f-&gt;promise).resume();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Then the return object is returned to the caller.</span></span><br><span class="line">  <span class="keyword">return</span> returnObject;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，必须要在执行 coroutine body 之前就获取 return-object。这因为 coroutine frame 以及它持有的 promise 对象可能在 <code>coroutine_handle::resume()</code> 返回前就被销毁掉。也就是说，在 resume() 返回前，程序可能处于 suspend 状态的，我理解后续这个 coroutine 就可能被直接销毁掉了。</p><p>销毁未必发生在 caller 的线程上。因此，在开始执行 coroutine body 之后调用 <code>get_return_object()</code> 是不安全的。</p><h2 id="The-initial-suspend-point"><a href="#The-initial-suspend-point" class="headerlink" title="The initial-suspend point"></a>The initial-suspend point</h2><p>The next thing the coroutine executes once the coroutine frame has been initialised and the return object has been obtained is execute the statement <code>co_await promise.initial_suspend()</code>;</p><p>执行 <code>co_await promise.initial_suspend()</code>，实际上允许 <code>promise_type</code> 也就是之前提到的 P 的作者，可以控制 coroutine 到底是立即执行，还是先 suspend 等调度。这有点类似于 std::async 里面相同参数的意思了。</p><p>如果在 initial suspend 点选择 suspend 的话，后续可以被 resume 或者被 destroy。</p><p><code>co_await promise.initial_suspend()</code> 的结果被丢弃，所以实现上可以从 <code>await_resume</code> 返回 void。</p><p>注意1：<code>initial_suspend()</code> 这个调用并没有被 try-catch 块环绕，也就是说这里发生的异常，更准确说是在它的 <code>&lt;return-to-caller-or-resumer&gt;</code> 之前的异常会在销毁 coroutine frame 和 return-object 之后被直接抛给 caller。</p><p>注意2：如果 return-object 中有某个 RAII 语义，能够在它被销毁的时候销毁 coroutine frame，那么就需要保证 <code>co_await promise.initial_suspend()</code> 不会抛出异常，否则会发生 double free 的问题。当然也有提案说要去修改这个行为。</p><p>但实际上因为大部分 coroutine 的 <code>initial_suspend()</code> 只会返回都是 noexcept 的 suspend_never 或者 suspend_always，所以这不是个问题。</p><h2 id="Returning-to-the-caller"><a href="#Returning-to-the-caller" class="headerlink" title="Returning to the caller"></a>Returning to the caller</h2><p>当 coroutine 执行到第一个 <code>&lt;return-to-caller-or-resumer&gt;</code> 点（如果没有这个点就是执行完成）的时候，从 get_return_object 获取的 return-object 会被返回给 caller。</p><p>注意，return-object 的类型不一定是 coroutine function 的 return type。可以进行隐式转换。</p><h2 id="Returning-from-the-coroutine-using-co-return"><a href="#Returning-from-the-coroutine-using-co-return" class="headerlink" title="Returning from the coroutine using co_return"></a>Returning from the coroutine using co_return</h2><p>co_return 会被转化为:</p><ol><li><code>promise.return_void()</code><br><code>co_return &lt;expr&gt; </code></li><li><code>promise.return_value(&lt;expr&gt;)</code><br> 如果 expr 的类型是 void，则 <code>&lt;expr&gt;; promise.return_void();</code>。<br> 如果 expr 的类型不是 void，则 <code>promise.return_value(&lt;expr&gt;);</code></li></ol><p>Note that if execution runs off the end of a coroutine without a co_return statement then this is equivalent to having a co_return; at the end of the function body. In this case, if the promise_type does not have a return_void() method then the behaviour is undefined.</p><p>If either the evaluation of <expr> or the call to promise.return_void() or promise.return_value() throws an exception then the exception still propagates to promise.unhandled_exception().</expr></p><h2 id="Handling-exceptions-that-propagate-out-of-the-coroutine-body"><a href="#Handling-exceptions-that-propagate-out-of-the-coroutine-body" class="headerlink" title="Handling exceptions that propagate out of the coroutine body"></a>Handling exceptions that propagate out of the coroutine body</h2><h2 id="The-final-suspend-point"><a href="#The-final-suspend-point" class="headerlink" title="The final-suspend point"></a>The final-suspend point</h2><p>final_suspend 的调用发生在 <code>return_void()</code>、<code>return_value()</code> 和 <code>unhandled_exception()</code> 之后。也发生在所有的 local variable 都被销毁之后。</p><p>This allows the coroutine to execute some logic, such as publishing a result, signalling completion or resuming a continuation. It also allows the coroutine to optionally suspend immediately before execution of the coroutine runs to completion and the coroutine frame is destroyed.</p><p>在 final_suspend 点 resume 一个 coroutine 是 UB 的，对于这个状态的 coroutine 只可以调用 destroy。</p><p>The rationale for this limitation, according to Gor Nishanov, is that this provides several optimisation opportunities for the compiler due to the reduction in the number of suspend states that need to be represented by the coroutine and a potential reduction in the number of branches required.</p><p>尽管可以在 final_suspend 处不 suspend，但建议是尽量 suspend。因为这可以强迫你在 coroutine 外面调用 destroy（一般是通过某种 RAII 机制）。这样编译器就能够更容易确定 coroutine frame 的 lifetime 是被 caller 的 lifetime 覆盖了的，从而就可以执行之前说的 elide 掉 coroutine frame 内存分配的优化。</p><h2 id="How-the-compiler-chooses-the-promise-type"><a href="#How-the-compiler-chooses-the-promise-type" class="headerlink" title="How the compiler chooses the promise type"></a>How the compiler chooses the promise type</h2><p>编译期可以自动推导 promise_type。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">task&lt;<span class="keyword">float</span>&gt; foo(<span class="built_in">std</span>::<span class="built_in">string</span> x, <span class="keyword">bool</span> flag);</span><br><span class="line">--&gt;</span><br><span class="line"><span class="keyword">typename</span> coroutine_traits&lt;task&lt;<span class="keyword">float</span>&gt;, <span class="built_in">std</span>::<span class="built_in">string</span>, <span class="keyword">bool</span>&gt;::promise_type;</span><br><span class="line"></span><br><span class="line">task&lt;<span class="keyword">void</span>&gt; my_class::method1(<span class="keyword">int</span> x) <span class="keyword">const</span>;</span><br><span class="line">--&gt;</span><br><span class="line"><span class="keyword">typename</span> coroutine_traits&lt;task&lt;<span class="keyword">void</span>&gt;, <span class="keyword">const</span> my_class&amp;, <span class="keyword">int</span>&gt;::promise_type;</span><br><span class="line"></span><br><span class="line">task&lt;foo&gt; my_class::method2() &amp;&amp;;</span><br><span class="line">--&gt;</span><br><span class="line"><span class="keyword">typename</span> coroutine_traits&lt;task&lt;foo&gt;, my_class&amp;&amp;&gt;::promise_type;</span><br></pre></td></tr></table></figure><p>可以自定义 promise_type</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>::experimental</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span>... ARGS&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_traits</span>&lt;std::optional&lt;T&gt;, ARGS...&gt;</span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">    <span class="keyword">using</span> promise_type = optional_promise&lt;T&gt;;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Identifying-a-specific-coroutine-activation-frame"><a href="#Identifying-a-specific-coroutine-activation-frame" class="headerlink" title="Identifying a specific coroutine activation frame"></a>Identifying a specific coroutine activation frame</h2><p>介绍 coroutine_handle 这个类型。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>::experimental</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Promise = <span class="keyword">void</span>&gt;</span><br><span class="line">  struct coroutine_handle;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Type-erased coroutine handle. Can refer to any kind of coroutine.</span></span><br><span class="line">  <span class="comment">// Doesn't allow access to the promise object.</span></span><br><span class="line">  <span class="keyword">template</span>&lt;&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_handle</span>&lt;void&gt;</span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">    <span class="comment">// Constructs to the null handle.</span></span><br><span class="line">    <span class="function"><span class="keyword">constexpr</span> <span class="title">coroutine_handle</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Convert to/from a void* for passing into C-style interop functions.</span></span><br><span class="line">    <span class="function"><span class="keyword">constexpr</span> <span class="keyword">void</span>* <span class="title">address</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">constexpr</span> coroutine_handle <span class="title">from_address</span><span class="params">(<span class="keyword">void</span>* addr)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Query if the handle is non-null.</span></span><br><span class="line">    <span class="function"><span class="keyword">constexpr</span> <span class="keyword">explicit</span> <span class="keyword">operator</span> <span class="title">bool</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Query if the coroutine is suspended at the final_suspend point.</span></span><br><span class="line">    <span class="comment">// Undefined behaviour if coroutine is not currently suspended.</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">done</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Resume/Destroy the suspended coroutine</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">resume</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Coroutine handle for coroutines with a known promise type.</span></span><br><span class="line">  <span class="comment">// Template argument must exactly match coroutine's promise type.</span></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Promise&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_handle</span> :</span> coroutine_handle&lt;&gt;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">using</span> coroutine_handle&lt;&gt;::coroutine_handle;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">constexpr</span> coroutine_handle <span class="title">from_address</span><span class="params">(<span class="keyword">void</span>* addr)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Access to the coroutine's promise object.</span></span><br><span class="line">    <span class="function">Promise&amp; <span class="title">promise</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// You can reconstruct the coroutine handle from the promise object.</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> coroutine_handle <span class="title">from_promise</span><span class="params">(Promise&amp; promise)</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它可以由两个方式获得：</p><ol><li>await_suspend 的参数<br> 这类似于 CPS 的方式。</li><li>通过 promise 从 from_promise 构造</li></ol><p>coroutine_handle 并不是 RAII 的，需要调用 destroy 去释放它。这样设计是为了减少 overhead。</p><p>You should generally try to use higher-level types that provide the RAII semantics for coroutines, such as those provided by cppcoro (shameless plug), or write your own higher-level types that encapsulate the lifetime of the coroutine frame for your coroutine type.</p><h2 id="Customising-the-behaviour-of-co-await"><a href="#Customising-the-behaviour-of-co-await" class="headerlink" title="Customising the behaviour of co_await"></a>Customising the behaviour of co_await</h2><p>promise 类型可以可选地自定义 co_await 表达式的行为。<br>只需要定义这个类型的 <code>await_transform()</code> 方法，编译器就能够将所有的 <code>co_await &lt;expr&gt;</code> 转换为 <code>co_await promise.await_transform(&lt;expr&gt;)</code>。</p><p>为什么要提供这个功能呢？</p><h3 id="原因1"><a href="#原因1" class="headerlink" title="原因1"></a>原因1</h3><p>因为有些类型不是 awaitable 的，所以要提供这个转换。</p><p>For example, a promise type for coroutines with a <code>std::optional&lt;T&gt;</code> return-type might provide an <code>await_transform()</code> overload that takes a <code>std::optional&lt;U&gt;</code> and that returns an awaitable type that either returns a value of type U or suspends the coroutine if the awaited value contains <code>nullopt</code>.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">optional_promise</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> U&gt;</span><br><span class="line">  <span class="function"><span class="keyword">auto</span> <span class="title">await_transform</span><span class="params">(<span class="built_in">std</span>::optional&lt;U&gt;&amp; value)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">awaiter</span></span></span><br><span class="line"><span class="class">    &#123;</span></span><br><span class="line">      <span class="built_in">std</span>::optional&lt;U&gt;&amp; value;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">      explicit awaiter(std::optional&lt;U&gt;&amp; x) noexcept : value(x) &#123;&#125;</span><br><span class="line">      <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> value.has_value(); &#125;</span><br><span class="line">      <span class="function"><span class="keyword">void</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt;)</span> <span class="keyword">noexcept</span> </span>&#123;&#125;</span><br><span class="line">      <span class="function">U&amp; <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> *value; &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">return</span> awaiter&#123; value &#125;;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="原因2"><a href="#原因2" class="headerlink" title="原因2"></a>原因2</h3><p>It lets you disallow awaiting on certain types by declaring <code>await_transform</code> overloads as deleted.</p><p>For example, a promise type for <code>std::generator&lt;T&gt;</code> return-type might declare a deleted <code>await_transform()</code> template member function that accepts any type. This basically disables use of co_await within the coroutine.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">generator_promise</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Disable any use of co_await within this type of coroutine.</span></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> U&gt;</span><br><span class="line">  <span class="built_in">std</span>::experimental::<span class="function">suspend_never <span class="title">await_transform</span><span class="params">(U&amp;&amp;)</span> </span>= <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="原因3"><a href="#原因3" class="headerlink" title="原因3"></a>原因3</h3><p>It lets you adapt and change the behaviour of normally awaitable values.</p><p>For example, you could define a type of coroutine that ensured that the coroutine always resumed from every co_await expression on an associated executor by wrapping the awaitable in a resume_on() operator (see cppcoro::resume_on()).</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> Executor&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">executor_task_promise</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  Executor executor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Awaitable&gt;</span><br><span class="line">  <span class="function"><span class="keyword">auto</span> <span class="title">await_transform</span><span class="params">(Awaitable&amp;&amp; awaitable)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">using</span> cppcoro::resume_on;</span><br><span class="line">    <span class="keyword">return</span> resume_on(<span class="keyword">this</span>-&gt;executor, <span class="built_in">std</span>::forward&lt;Awaitable&gt;(awaitable));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>As a final word on <code>await_transform()</code>, it’s important to note that if the promise type defines any <code>await_transform()</code> members then this triggers the compiler to transform all <code>co_await</code> expressions to call promise.await_transform(). 所以，如果只是希望对某些类型定制 co_await 行为，最好为 <code>await_transform()</code> 提供一个只 forward argument 的重载。</p><h2 id="Customising-the-behaviour-of-co-yield"><a href="#Customising-the-behaviour-of-co-yield" class="headerlink" title="Customising the behaviour of co_yield"></a>Customising the behaviour of co_yield</h2><p>编译器会把 <code>co_yield &lt;expr&gt;</code> 转换为 <code>co_await promise.yield_value(&lt;expr&gt;)</code>。因此 promise 对象可以定制 <code>yield_value</code> 方法。</p><p>如果编译器没有定制这个方法，该方法不会有默认的行为。所以需要显式提供这样的方法，promise 类型才能支持 co_yield。</p><p>如下所示，对一个 generator 类型提供了 yield_value 方法。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">generator_promise</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  T* valuePtr;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::experimental::<span class="function">suspend_always <span class="title">yield_value</span><span class="params">(T&amp; value)</span> <span class="keyword">noexcept</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="comment">// Stash the address of the yielded value and then return an awaitable</span></span><br><span class="line">    <span class="comment">// that will cause the coroutine to suspend at the co_yield expression.</span></span><br><span class="line">    <span class="comment">// Execution will then return from the call to coroutine_handle&lt;&gt;::resume()</span></span><br><span class="line">    <span class="comment">// inside either generator&lt;T&gt;::begin() or generator&lt;T&gt;::iterator::operator++().</span></span><br><span class="line">    valuePtr = <span class="built_in">std</span>::addressof(value);</span><br><span class="line">    <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h1 id="Understanding-Symmetric-Transfer"><a href="#Understanding-Symmetric-Transfer" class="headerlink" title="Understanding Symmetric Transfer"></a>Understanding Symmetric Transfer</h1><p><a href="https://lewissbaker.github.io/2020/05/11/understanding_symmetric_transfer" target="_blank" rel="noopener">https://lewissbaker.github.io/2020/05/11/understanding_symmetric_transfer</a></p><p>在 Coroutine TS 刚开始被提出的时候，有一个限制，会导致轻易的 stack-overflow。为了避免它，就需要在 <code>task&lt;T&gt;</code> 类型中引入额外的同步开销。</p><p>在 2018 年，引入了一个 symmetric transfer 的特性，使得我们可以挂起一个 Coroutine，并 Resume 另一个，但是不会消耗栈空间了。</p><h2 id="First-some-background-on-how-a-task-coroutine-works"><a href="#First-some-background-on-how-a-task-coroutine-works" class="headerlink" title="First some background on how a task coroutine works"></a>First some background on how a task coroutine works</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">task <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  co_return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">task <span class="title">bar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">co_await <span class="title">foo</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不放展开看看 <code>bar()</code> 在 <code>co_await foo()</code> 的时候都发生了什么：</p><ol><li>调用 foo 需要有下面几步<br> 为 coroutine frame 分配寻出空间。<br> 将参数复制到 coroutine frame 里面。在当前 case 里面没有参数，所以就是一个空操作。<br> 在 coroutine frame 里面构造 promise object。<br> 调用 <code>promise.get_return_object()</code> 获得 foo() 的返回值。这个过程中会产生被返回的 task 对象，并使用 std::coroutine_handle 创建它。如前所述，std::coroutine_handle 持有刚创建的 coroutine frame 的引用。<br> 在 initial-suspend point 挂起 coroutine 的执行。<br> 返回 task 对象给到 bar()。</li><li>后面，bar() 会执行 co_await<br> <code>bar()</code> 会被挂起，然后调用由 <code>foo()</code> 返回的 task 对象上的 <code>await_suspend()</code> 方法。会把指向 bar 的 coroutine frame 的 <code>std::coroutine_handle</code> 传给该方法。<br> 在 <code>await_suspend()</code> 中，会存储 bar() 的 <code>std::coroutine_handle</code> 到 foo 的 promise 对象中【A】，然后通过调用 <code>foo</code> 的 <code>std::coroutine_handle</code> 的 resume 方法去 resume foo() 的执行。</li><li>foo() 会同步地执行。</li><li>foo() 会在 final-suspend point 挂起，然后 resume bar。这是根据被存在 promise 对象中的 std::coroutine_handle 来找到的，见【A】步骤。</li><li>bar() 会 resume，继续执行，并最终到达 co_await 语句处，并调用临时 task 对象的析构函数。</li><li>task 对象执行析构。因为这个 task 对象是 foo() 返回的，所以它会调用 foo() 的 coroutine handle 上的 <code>.destroy()</code> 方法，这样就会销毁 coroutine frame，包括 promise 对象和之前复制了的参数之内。</li></ol><h2 id="Outline-of-a-task-implementation"><a href="#Outline-of-a-task-implementation" class="headerlink" title="Outline of a task implementation"></a>Outline of a task implementation</h2><p>下面可以看下如果不支持 symmetric transfer，task 类应该如何被实现。可以看出 task 是一个 Awaitable。</p><p>A task has exclusive ownership of the <code>std::coroutine_handle</code> that corresponds to the coroutine frame created during the invocation of the coroutine. The task object is an RAII object that ensures that <code>.destroy()</code> is called on the <code>std::coroutine_handle</code> when the task object goes out of scope.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">task</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">promise_type</span> &#123;</span> <span class="comment">/* see below */</span> &#125;;</span><br><span class="line"></span><br><span class="line">  task(task&amp;&amp; t) <span class="keyword">noexcept</span></span><br><span class="line">  : coro_(<span class="built_in">std</span>::exchange(t.coro_, &#123;&#125;))</span><br><span class="line">  &#123;&#125;</span><br><span class="line"></span><br><span class="line">  ~task() &#123;</span><br><span class="line">    <span class="keyword">if</span> (coro_)</span><br><span class="line">      coro_.destroy();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">awaiter</span> &#123;</span> <span class="comment">/* see below */</span> &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function">awaiter <span class="keyword">operator</span> <span class="title">co_await</span><span class="params">()</span> &amp;&amp; <span class="keyword">noexcept</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">task</span><span class="params">(<span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; h)</span> <span class="keyword">noexcept</span></span></span><br><span class="line">  : coro_(h)</span><br><span class="line">  &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; coro_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>下面会展开讲解 promise_type 和 awaiter 的实现。</p><h2 id="Implementing-task-promise-type"><a href="#Implementing-task-promise-type" class="headerlink" title="Implementing task::promise_type"></a>Implementing task::promise_type</h2><p>promise_type 会定义在 coroutine frame 中创建的 Promise 对象的类型。</p><p>首先，需要实现 <code>get_return_object()</code> 去构造将来要被返回的 task 对象。这个对象的初始化需要借助于 <code>std::coroutine_handle</code>。</p><p>这里是根据 <code>from_promise</code> 从 Promise 对象中重新构造出了 <code>std::coroutine_handle</code>。这是获得 <code>std::coroutine_handle</code> 的一种方法，另一种方法是 <code>await_suspend</code> 参数，前文中提到过。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">task</span>:</span>:promise_type &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function">task <span class="title">get_return_object</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> task&#123;<span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt;::from_promise(*<span class="keyword">this</span>)&#125;;</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>后面，这个 coroutine 需要在 initial-suspend point 挂起，这样在 task 被 await 的时候，我们可以 resume 它。这样 lazy 的处理有下面几点好处：</p><ol><li>It means that we can attach the continuation’s <code>std::coroutine_handle</code> before starting execution of the coroutine. This means we don’t need to use thread-synchronisation to arbitrate the race between attaching the continuation later and the coroutine running to completion.<br> 我理解这里讲的是和“Comparison to Stackful Coroutines”这一章节中类似的问题。</li><li>It means that the task destructor can unconditionally destroy the coroutine frame - we don’t need to worry about whether the coroutine is potentially executing on another thread since the coroutine will not start executing until we await it, and while it is executing the calling coroutine is suspended and so won’t attempt to call the task destructor until the coroutine finishes executing.<br> 这里说的是 task 的析构函数可以不加判断地直接销毁掉 coroutine frame。也就是说，并不需要担心 coroutine 是否此时还在另一个线程上执行。实际上我们只有在 await 它的时候，coroutine 才会开始执行。而这个时候，调用方 coroutine 已经被挂起了，直到 coroutine 执行完成后，都不会再调用 task 的 destructor 了。<br> 所以这让编译器更容易把分配 coroutine frame 的操作 inline 到 caller 的 frame 里面。我理解就是“Allocating a coroutine frame”里面讲的东西。<br> See P0981R0 to read more about the Heap Allocation eLision Optimisation (HALO).</li><li>It also improves the exception-safety of your coroutine code. If you don’t immediately <code>co_await</code> the returned task and do something else that can throw an exception that causes the stack to unwind and the task destructor to run then we can safely destroy the coroutine since we know it hasn’t started yet. We aren’t left with the difficult choice between detaching, potentially leaving dangling references, blocking in the destructor, terminating or undefined-behaviour.<br> 这也能提高异常安全性。</li></ol><p>为了让 coroutine 能够 initially suspend，需要定义一个返回 <code>suspend_always</code> 的 <code>initial_suspend</code> 方法。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  <span class="built_in">std</span>::<span class="function">suspend_always <span class="title">initial_suspend</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>然后，定义 <code>return_void()</code> 方法。这是在执行 <code>co_return</code> 的时候，或者执行到 coroutine 末尾的时候被调用的。这个方法并不会做什么事情，只是让编译器知道 <code>co_return;</code> 对于当前的 coroutine 类型是合法的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">return_void</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>We also need to add an <code>unhandled_exception()</code> method that is called if an exception escapes the body of the coroutine. For our purposes we can just treat the task coroutine bodies as noexcept and call <code>std::terminate()</code> if this happens.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">unhandled_exception</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::terminate();</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>最后，还需要 coroutine 能在 final-suspend point 被 suspend 住，然后 resume its Continuation。在当前的 case 中 continuation 就是在 awaiting 的 coroutine，在 <code>task::awaiter::await_suspend</code> 的时候被设置的。</p><p>【Q】“resume its Continuation” 中的 Continuation 指的是什么？这里我理解应该就是 loop_synchronously 里面循环的下一次迭代。可以在 Stack 图中看到 continuation 具体指向哪里的。</p><p>因此，需要在 promise 中引入一个成员，去持有 continuation 的 <code>std::coroutine_handle</code>，不然如何调用对应的 <code>.resume()</code> 方法呢？</p><p>还需要定义 <code>final_suspend()</code> 方法来返回一个 awaitable 对象也就是 final_awaiter，让它在当前 coroutine 被挂起后，去 resume 这个 continuation。</p><p>注意，需要再当前 coroutine 被 suspend 之后，才能 resume continuation。这是因为 continuation 可能立即就会调用 task 的析构函数，从而间接调用 coroutine frame 的 <code>.destroy()</code> 方法。<code>.destroy()</code> 方法只对 suspended 的 coroutine 生效。</p><p>The compiler inserts code to evaluate the statement <code>co_await promise.final_suspend();</code> at the closing curly brace.</p><p>需要注意，在调用 <code>final_suspend</code> 的时候，coroutine 还没有进入 suspend 状态。需要等到返回的 awaitable 对象上的 await_suspend() 方法被调用之后，coroutine 才被 suspend。关于这个我觉得可以参考之前讲的 <code>&lt;return-to-caller-or-resumer&gt;</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">final_awaiter</span> &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; h)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">      <span class="comment">// The coroutine is now suspended at the final-suspend point.</span></span><br><span class="line">      <span class="comment">// Lookup its continuation in the promise and resume it.</span></span><br><span class="line">      h.promise().continuation.resume();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;&#125;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function">final_awaiter <span class="title">final_suspend</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>【Q】为啥这里定义一个 <code>final_awaiter</code>，而不是直接用 std::suspend_always。<br>首先，<code>suspend_always</code> 和 <code>suspend_never</code> 的实现上分别定义了<code> await_ready()</code> 方法始终返回 false 或者 true。<code>await_suspend</code> 或者 <code>await_resume</code> 方法都是空实现。而这里是希望 <code>final_awaiter</code> 的 <code>await_suspend</code> 能去 resume continuation。</p><h2 id="Implementing-task-operator-co-await"><a href="#Implementing-task-operator-co-await" class="headerlink" title="Implementing task::operator co_await()"></a>Implementing task::operator co_await()</h2><p>co_await 会返回一个 awaiter 对象，这个对象需要支持 <code>await_ready()</code>、<code>await_suspend()</code> 和 <code>await_resume()</code>。</p><p>下面就是 awaiter 的简单实现。注意，一旦一个 coroutine 被 suspend 了，就需要保存 coroutine handle 到 promise 对象中。这样后续可以调用 std::coroutine_handle 中的 resume() 方法去执行这个 task。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">task</span>:</span>:awaiter &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Store the continuation in the task's promise so that the final_suspend()</span></span><br><span class="line">    <span class="comment">// knows to resume this coroutine when the task completes.</span></span><br><span class="line">    coro_.promise().continuation = continuation;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Then we resume the task's coroutine, which is currently suspended</span></span><br><span class="line">    <span class="comment">// at the initial-suspend-point (ie. at the open curly brace).</span></span><br><span class="line">    coro_.resume();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">awaiter</span><span class="params">(<span class="built_in">std</span>::coroutine_handle&lt;task::promise_type&gt; h)</span> <span class="keyword">noexcept</span></span></span><br><span class="line">  : coro_(h)</span><br><span class="line">  &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::coroutine_handle&lt;task::promise_type&gt; coro_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">task::awaiter task::<span class="function"><span class="keyword">operator</span> <span class="title">co_await</span><span class="params">()</span> &amp;&amp; <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> awaiter&#123;coro_&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>作者给出了一个可编译的 demo 在 <a href="https://godbolt.org/z/-Kw6Nf%E3%80%82" target="_blank" rel="noopener">https://godbolt.org/z/-Kw6Nf。</a></p><h2 id="The-stack-overflow-problem"><a href="#The-stack-overflow-problem" class="headerlink" title="The stack-overflow problem"></a>The stack-overflow problem</h2><p>考虑下面的代码，如果 count 足够大，程序就会爆栈。例如 <a href="https://godbolt.org/z/gy5Q8q" target="_blank" rel="noopener">https://godbolt.org/z/gy5Q8q</a> 中展示了当 count 是 1000000 的时候，程序就爆栈了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">task <span class="title">completes_synchronously</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  co_return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">task <span class="title">loop_synchronously</span><span class="params">(<span class="keyword">int</span> count)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; ++i) &#123;</span><br><span class="line">    <span class="function">co_await <span class="title">completes_synchronously</span><span class="params">()</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是因为当 loop_synchronously() 开始执行时，有一个其他 coroutine 正在 <code>co_await</code> 的自己返回的 task，也就是在 <code>co_await loop_synchronously()</code>。因此，它会 suspend 正在 awating 的 coroutine，然后调用 <code>task::awaiter::await_suspend()</code>。如前文介绍，<code>await_suspend</code> 会负责调用对应 task 的<code> std::coroutine_handle</code> 的 <code>resume()</code> 方法。</p><p>Thus the stack will look something like this when loop_synchronously() starts.</p><p>我理解这里倒数第二底层的 task::awaiter::await_suspend 是由于这个其他 coroutine 在 await 从而产生的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">           Stack                                                   Heap</span><br><span class="line">+------------------------------+  &lt;-- top of stack   +--------------------------+</span><br><span class="line">| loop_synchronously$resume    | active coroutine -&gt; | loop_synchronously frame |</span><br><span class="line">+------------------------------+                     | +----------------------+ |</span><br><span class="line">| coroutine_handle::resume     |                     | | task::promise        | |</span><br><span class="line">+------------------------------+                     | | - continuation --.   | |</span><br><span class="line">| task::awaiter::await_suspend |                     | +------------------|---+ |</span><br><span class="line">+------------------------------+                     | ...                |     |</span><br><span class="line">| awaiting_coroutine$resume    |                     +--------------------|-----+</span><br><span class="line">+------------------------------+                                          V</span><br><span class="line">|  ....                        |                     +--------------------------+</span><br><span class="line">+------------------------------+                     | awaiting_coroutine frame |</span><br><span class="line">                                                     |                          |</span><br><span class="line">                                                     +--------------------------+</span><br></pre></td></tr></table></figure><p>这里的 <code>$resume</code> 后缀用来表示 coroutine 中的用户自定义逻辑。</p><p>然后，当 <code>loop_synchronously()</code> 去 <code>co_await</code> 从 <code>completes_synchronously()</code> 返回的 task 对象时，当前的 coroutine 会被 suspend，然后会调用 <code>task::awaiter::await_suspend()</code>。await_suspend() 方法会调用 <code>completes_synchronously()</code> 的 coroutine handle 上的 <code>.resume()</code> 方法。</p><p>这会 resume <code>completes_synchronously()</code> coroutine。这个 coroutine 会 synchronously 地运行结束，然后在 final-suspend point 被 suspend。然后它会调用 <code>task::promise::final_awaiter::await_suspend()</code>，然后最终调用 <code>loop_synchronously()</code> 这个 coroutine 的 coroutine handle 上的 <code>.resume()</code> 方法。</p><p>如果我们在 <code>loop_synchronously()</code> coroutine 被 resume 之后，它返回的临时的 task 被销毁之前，检查调用栈，就可以看到下面的情况。</p><p>这里的 final_awaiter 也就是 promise 对象的 final_suspend() 方法返回的内容。根据之前的说明，它是在 final-suspend point 之后 resume continuation 的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">           Stack                                                   Heap</span><br><span class="line">+-------------------------------+ &lt;-- top of stack</span><br><span class="line">| loop_synchronously$resume     | active coroutine -.</span><br><span class="line">+-------------------------------+                   |</span><br><span class="line">| coroutine_handle::resume      |            .------&apos;</span><br><span class="line">+-------------------------------+            |</span><br><span class="line">| final_awaiter::await_suspend  |            |</span><br><span class="line">+-------------------------------+            |  +--------------------------+ &lt;-.</span><br><span class="line">| completes_synchronously$resume|            |  | completes_synchronously  |   |</span><br><span class="line">+-------------------------------+            |  | frame                    |   |</span><br><span class="line">| coroutine_handle::resume      |            |  +--------------------------+   |</span><br><span class="line">+-------------------------------+            &apos;---.                             |</span><br><span class="line">| task::awaiter::await_suspend  |                V                             |</span><br><span class="line">+-------------------------------+ &lt;-- prev top  +--------------------------+   |</span><br><span class="line">| loop_synchronously$resume     |     of stack  | loop_synchronously frame |   |</span><br><span class="line">+-------------------------------+               | +----------------------+ |   |</span><br><span class="line">| coroutine_handle::resume      |               | | task::promise        | |   |</span><br><span class="line">+-------------------------------+               | | - continuation --.   | |   |</span><br><span class="line">| task::awaiter::await_suspend  |               | +------------------|---+ |   |</span><br><span class="line">+-------------------------------+               | - task temporary --|---------&apos;</span><br><span class="line">| awaiting_coroutine$resume     |               +--------------------|-----+</span><br><span class="line">+-------------------------------+                                    V</span><br><span class="line">|  ....                         |               +--------------------------+</span><br><span class="line">+-------------------------------+               | awaiting_coroutine frame |</span><br><span class="line">                                                |                          |</span><br><span class="line">                                                +--------------------------+</span><br></pre></td></tr></table></figure><p>然后，就会调用 task 的析构函数，摧毁 <code>completes_synchronously()</code> 的 coroutine frame。然后就会进行新一轮的循环，创建新的 completes_synchronously() 的 coroutine frame，然后 resume。</p><p>最终结果是，<code>loop_synchronously()</code> 和 <code>completes_synchronously()</code> 会递归地互相调用彼此。每次调用都会消耗一点栈空间，直到最后栈爆掉了。</p><p>Writing loops in coroutines built this way makes it very easy to write functions that perform unbounded recursion without looking like they are doing any recursion.</p><p>So, what would the solution look like under the original Coroutines TS design?</p><h2 id="The-Coroutines-TS-solution"><a href="#The-Coroutines-TS-solution" class="headerlink" title="The Coroutines TS solution"></a>The Coroutines TS solution</h2><p>TS 的解决方案是使用返回 bool 的版本的 await_suspend，根据的原理是<br>In the Coroutines TS there is also a version of await_suspend() that returns bool - if it returns true then the coroutine is suspended and execution returns to the caller of resume(), otherwise if it returns false then the coroutine is immediately resumed, but this time without consuming any additional stack-space.</p><p>具体来说，做出下面的修改：</p><ol><li>Inside the <code>task::awaiter::await_suspend()</code> method you can start executing the coroutine by calling <code>.resume()</code>. Then when the call to <code>.resume()</code> returns, check whether the coroutine has run to completion or not. If it has run to completion then we can return false, which indicates the awaiting coroutine should immediately resume, or we can return true, indicating that execution should return to the caller of <code>std::coroutine_handle::resume()</code>.</li><li>Inside <code>task::promise_type::final_awaiter::await_suspend()</code>, which is run when the coroutine runs to completion, we need to check whether the awaiting coroutine has (or will) return true from <code>task::awaiter::await_suspend()</code> and if so then resume it by calling .resume(). Otherwise, we need to avoid resuming the coroutine and notify task::awaiter::await_suspend() that it needs to return false.</li></ol><p>从下面的代码来看，awaiter::await_suspend 和 final_awaiter::await_suspend 中都会尝试设置 promise.ready 为 true。但是：</p><ol><li>在 awaiter::await_suspend 中如果发现 promise.ready 原来是 false，说明还没结束，则要返回 true 去挂起，并且返回给 <code>std::coroutine_handle::resume()</code> 的调用方。如果原来是 true，说明执行完了，就返回 false，则可以立即 resume。</li><li>在 final_awaiter::await_suspend 中如果发现 promise.ready 原来是 true，说明【Q】</li></ol><blockquote><p>There is an added complication, however, in that it’s possible for a coroutine to start executing on the current thread then suspend and later resume and run to completion on a different thread before the call to .resume() returns. Thus, we need to be able to resolve the potential race between part 1 and part 2 above happening concurrently.</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">task</span>:</span>:promise_type &#123;</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation;</span><br><span class="line">  <span class="built_in">std</span>::atomic&lt;<span class="keyword">bool</span>&gt; ready = <span class="literal">false</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">bool</span> task::awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  promise_type&amp; promise = coro_.promise();</span><br><span class="line">  promise.continuation = continuation;</span><br><span class="line">  coro_.resume();</span><br><span class="line">  <span class="keyword">return</span> !promise.ready.exchange(<span class="literal">true</span>, <span class="built_in">std</span>::memory_order_acq_rel);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> task::promise_type::final_awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; h) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  promise_type&amp; promise = h.promise();</span><br><span class="line">  <span class="keyword">if</span> (promise.ready.exchange(<span class="literal">true</span>, <span class="built_in">std</span>::memory_order_acq_rel)) &#123;</span><br><span class="line">    <span class="comment">// The coroutine did not complete synchronously, resume it here.</span></span><br><span class="line">    promise.continuation.resume();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改后的代码在 <a href="https://godbolt.org/z/7fm8Za%E3%80%82" target="_blank" rel="noopener">https://godbolt.org/z/7fm8Za。</a></p><h2 id="The-problems"><a href="#The-problems" class="headerlink" title="The problems"></a>The problems</h2><p>上面的方案依然存在问题：</p><ol><li>依赖原子操作<br> 第一次是在调用者在 suspend awaiting coroutine 的时候。<br> 第二次是在被调用者即将完成执行的时候。</li><li>引入额外的分支操作。</li></ol><p>最后一个最严重的问题是，被挂起的 coroutine 在被 resume 后，被哪个线程执行是不确定的。比如考虑下面的代码</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cppcoro::static_thread_pool tp;</span><br><span class="line"></span><br><span class="line"><span class="function">task <span class="title">foo</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"foo1 "</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">  <span class="comment">// Suspend coroutine and reschedule onto thread-pool thread.</span></span><br><span class="line">  co_await tp.schedule();</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"foo2 "</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">task <span class="title">bar</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"bar1 "</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">  <span class="function">co_await <span class="title">foo</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"bar2"</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在原始的实现中，可能的输出如下。这是因为我们保证在 the code that runs after <code>co_await foo()</code> would run inline on the same thread that foo() completed on.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bar1 1234</span><br><span class="line">foo1 1234</span><br><span class="line">foo2 3456</span><br><span class="line">bar2 3456</span><br></pre></td></tr></table></figure><p>但是因为使用了原子变量，就可能 foo 的 completion 和 bar 的 suspension 之间有 race（我理解就是上面的两个 await_suspend 会竞争地设置 promise.ready 吧）。那么在一些情况下，<code>co_await foo()</code> might run on the original thread that bar() started executing on. 如下所示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bar1 1234</span><br><span class="line">foo1 1234</span><br><span class="line">foo2 3456</span><br><span class="line">bar2 1234</span><br></pre></td></tr></table></figure><p>这对一些场景下是存在问题的。比如 <code>via</code> 这个函数可以指定一个 Scheduler 去运行某个 Awaitable。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Awaitable, <span class="keyword">typename</span> Scheduler&gt;</span><br><span class="line">task&lt;<span class="keyword">await_result_t</span>&lt;Awaitable&gt;&gt; via(Awaitable a, Scheduler s)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">auto</span> result = co_await <span class="built_in">std</span>::move(a);</span><br><span class="line">  co_await s.schedule();</span><br><span class="line">  co_return result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">task&lt;T&gt; get_value();</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">consume</span><span class="params">(<span class="keyword">const</span> T&amp;)</span></span>;</span><br><span class="line"></span><br><span class="line">task&lt;<span class="keyword">void</span>&gt; consumer(static_thread_pool::scheduler s)</span><br><span class="line">&#123;</span><br><span class="line">  T result = co_await via(get_value(), s);</span><br><span class="line">  consume(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但像现在这样的话，<code>consume()</code> 可能在 s 上执行，但也有可能在 whatever thread the consumer() coroutine started execution on 上被执行。</p><h2 id="Enter-“symmetric-transfer”"><a href="#Enter-“symmetric-transfer”" class="headerlink" title="Enter “symmetric transfer”"></a>Enter “symmetric transfer”</h2><p>This paper proposed two key changes:</p><ol><li>Allow returning a <code>std::coroutine_handle&lt;T&gt;</code> from await_suspend() as a way of indicating that execution should be symmetrically transferred to the coroutine identified by the returned handle.</li><li>Add a std::experimental::noop_coroutine() function that returns a special std::coroutine_handle that can be returned from await_suspend() to suspend the current coroutine and return from the call to .resume() instead of transferring execution to another coroutine.</li></ol><p>首先，什么是 symmetric transfer？简单来说，像函数调用，返回那样的就是 asymmetric transfer，因为有明确的调用者和被调用者。具体到 coroutine 场景中，当 A 调用 <code>.resume()</code> 方法去 resume 一个 coroutine 的时候，这个 A 还在 stack 上，尽管 resumed coroutine 正在被执行。当这个 coroutine 后面挂起，并调用 <code>await_suspend</code> 返回 void（无条件 suspend）或者 true（条件 suspend），那么对 <code>.resume()</code> 的调用就返回了。</p><p>每次我们通过 .resume() 方法去 resume 一个 coroutine 的时候，都会创建一个新的 frame。<br>但如果通过 symmetric transfer，我们就只是 suspend 某个 coroutine，resume 另一个 coroutine。这两个 coroutine 之间没有任何的调用者或者被调用者的关系。当一个 coroutine 被 suspend 后，它可以将 execution 给到任意的被 suspend 的coroutine，甚至包括自己，并且在自己被 suspend 之后，也不需要把 execution 还给之前的 coroutine。</p><p>Let’s look at what the compiler lowers a co_await expression to when the awaiter makes use of symmetric-transfer:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="keyword">decltype</span>(<span class="keyword">auto</span>) value = &lt;expr&gt;;</span><br><span class="line">  <span class="keyword">decltype</span>(<span class="keyword">auto</span>) awaitable =</span><br><span class="line">      get_awaitable(promise, <span class="keyword">static_cast</span>&lt;<span class="keyword">decltype</span>(value)&amp;&amp;&gt;(value));</span><br><span class="line">  <span class="keyword">decltype</span>(<span class="keyword">auto</span>) awaiter =</span><br><span class="line">      get_awaiter(<span class="keyword">static_cast</span>&lt;<span class="keyword">decltype</span>(awaitable)&amp;&amp;&gt;(awaitable));</span><br><span class="line">  <span class="keyword">if</span> (!awaiter.await_ready())</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">handle_t</span> = <span class="built_in">std</span>::coroutine_handle&lt;P&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//&lt;suspend-coroutine&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> h = awaiter.await_suspend(<span class="keyword">handle_t</span>::from_promise(p));</span><br><span class="line">    h.resume();</span><br><span class="line">    <span class="comment">//&lt;return-to-caller-or-resumer&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//&lt;resume-point&gt;</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> awaiter.await_resume();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Let’s zoom in on the key part that differs from other co_await forms:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> h = awaiter.await_suspend(<span class="keyword">handle_t</span>::from_promise(p));</span><br><span class="line">h.resume();</span><br><span class="line"><span class="comment">//&lt;return-to-caller-or-resumer&gt;</span></span><br></pre></td></tr></table></figure><p>Once the coroutine state-machine is lowered (a topic for another post), the <code>&lt;return-to-caller-or-resumer&gt;</code> part basically becomes a return; statement which causes the call to .resume() that last resumed the coroutine to return to its caller.</p><p>This means that we have the situation where we have a call to another function with the same signature, <code>std::coroutine_handle::resume()</code>, followed by a return; from the current function which is itself the body of a <code>std::coroutine_handle::resume()</code> call.</p><p>Some compilers, when optimisations are enabled, are able to apply an optimisation that turns calls to other functions the tail-position (ie. just before returning) into tail-calls as long as some conditions are met.</p><p>It just so happens that this kind of tail-call optimisation is exactly the kind of thing we want to be able to do to avoid the stack-overflow problem we were encountering before. But instead of being at the mercy of the optimiser as to whether or not the tail-call transformation is perfromed, we want to be able to guarantee that the tail-call transformation occurs, even when optimisations are not enabled.</p><p>But first let’s dig into what we mean by tail-calls.</p><h2 id="Tail-calls"><a href="#Tail-calls" class="headerlink" title="Tail-calls"></a>Tail-calls</h2><p>Tail-call 指的是当前的 stack frame 被在调用前就被弹出了，然后当前函数的返回地址变为了被调用者的返回地址。比如，被调用者会直接返回给调用者的调用者。</p><p>在 X86 架构上，编译器会首先弹出当前的栈帧，然后用一个 jmp 指令去跳转到被调用的函数的 entry-point。而不是使用一个 call 指令，然后在返回后再弹出当前 stack-frame。</p><p>This optimisation is generally only possible to do in limited circumstances, however. In particular, it requires that:</p><ol><li>the calling convention supports tail-calls and is the same for the caller and callee;</li><li>the return-type is the same;</li><li>there are no non-trivial destructors that need to be run after the call before returning to the caller; and</li><li>the call is not inside a try/catch block.</li></ol><p>The shape of the symmetric-transfer form of co_await has actually been designed specifically to allow coroutines to satisfy all of these requirements. Let’s look at them individually.</p><ol><li><p>Calling convention<br> 当编译器 lowers 一个 coroutine 到机器码的时候，它实际上将 coroutine 分为了两部分。第一部分是 ramp，它会分配并初始化 coroutine 帧。第二部分是 body，它包含了从用户自定义的 coroutine body 生成的状态机。<br> The function signature of the coroutine (and thus any user-specified calling-convention) affects only the ramp part, whereas the body part is under the control of the compiler and is never directly called by any user-code - only by the ramp function and by <code>std::coroutine_handle::resume()</code>.<br> The calling-convention of the coroutine body part is not user-visible and is entirely up to the compiler and thus it can choose an appropriate calling convention that supports tail-calls and that is used by all coroutine bodies.</p></li><li><p>Return type is the same<br> “调用方” coroutine 和“被调用方” coroutine 的 .resume() 方法的返回值都是 void。</p></li><li><p>No non-trivial destructors<br> 在执行 tail-call 时，需要能够在调用目标函数之前就释放当前的 stack frame。而这需要所有在栈上分配的对象的生命周期都在调用前完成。<br> Normally, this would be problematic as soon as there are any objects with non-trivial destructors in-scope as the lifetime of those objects would not yet have ended and those objects would have been allocated on the stack.<br> 但是，当一个 coroutine 被 suspend 之后，它实际上会将需要续命的对象放到 coroutine frame 里面，而不是直接分配在 stack 上。<br> 对于真正的 local variable，也就是那些 lifetime 并不会跨越 suspend-point 的 variable，它们是会被分配在栈上的。但是它们的 lifetime 在 coroutine suspend 之前就已经结束了，并且对应的析构函数也已经被调用了。<br> 所以不会存在有 stack-allocated objects，它们的 non-trivial destructor 需要在 tail-call 返回之后被执行。</p></li><li><p>Call not inside a try/catch block<br> 这里比较 tricky 的一点是每个 coroutine 都会有一个隐式的 try/catch block，来包裹其中的用户自定义的部分。<br> 类似下面这，F 就是用户自定义的部分。</p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  promise_type promise;</span><br><span class="line">  co_await promise.initial_suspend();</span><br><span class="line">  <span class="keyword">try</span> &#123; F; &#125;</span><br><span class="line">  <span class="keyword">catch</span> (...) &#123; promise.unhandled_exception(); &#125;</span><br><span class="line">final_suspend:</span><br><span class="line">  co_await promise.final_suspend();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 所以，每个用户自定义的 co_await 表达式（除了 initial_suspend 和 final_suspend 的）会被 try catch 包裹。<br> However, implementations work around this by actually executing the call to .resume() outside of the context of the try-block.</p></li></ol><p>So we see that coroutines performing a symmetric-transfer generally satisfy all of the requirements for being able to perform a tail-call. The compiler guarantees that this will always be a tail-call, regardless of whether optimisations are enabled or not.</p><p>This means that by using the std::coroutine_handle-returning flavour of await_suspend() we can suspend the current coroutine and transfer execution to another coroutine without consuming extra stack-space.</p><p>This allows us to write coroutines that mutually and recursively resume each other to an arbitrary depth without fear of overflowing the stack.</p><p>This is exactly what we need to fix our task implementation.</p><h2 id="task-revisited"><a href="#task-revisited" class="headerlink" title="task revisited"></a>task revisited</h2><p>So with the new “symmetric transfer” capability under our belt let’s go back and fix our task type implementation.</p><p>To do this we need to make changes to the two await_suspend() methods in our implementation:</p><ol><li>First so that when we await the task that we perform a symmetric-transfer to resume the task’s coroutine.</li><li>Second so that when the task’s coroutine completes that it performs a symmetric transfer to resume the awaiting coroutine.</li></ol><p>To address the await direction we need to change the task::awaiter method from this:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> task::awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  <span class="comment">// Store the continuation in the task's promise so that the final_suspend()</span></span><br><span class="line">  <span class="comment">// knows to resume this coroutine when the task completes.</span></span><br><span class="line">  coro_.promise().continuation = continuation;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Then we resume the task's coroutine, which is currently suspended</span></span><br><span class="line">  <span class="comment">// at the initial-suspend-point (ie. at the open curly brace).</span></span><br><span class="line">  coro_.resume();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会变成</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::coroutine_handle&lt;&gt; task::awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  <span class="comment">// Store the continuation in the task's promise so that the final_suspend()</span></span><br><span class="line">  <span class="comment">// knows to resume this coroutine when the task completes.</span></span><br><span class="line">  coro_.promise().continuation = continuation;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Then we tail-resume the task's coroutine, which is currently suspended</span></span><br><span class="line">  <span class="comment">// at the initial-suspend-point (ie. at the open curly brace), by returning</span></span><br><span class="line">  <span class="comment">// its handle from await_suspend().</span></span><br><span class="line">  <span class="keyword">return</span> coro_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>And to address the return-path we need to update the task::promise_type::final_awaiter method from this:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> task::promise_type::final_awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; h) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  <span class="comment">// The coroutine is now suspended at the final-suspend point.</span></span><br><span class="line">  <span class="comment">// Lookup its continuation in the promise and resume it.</span></span><br><span class="line">  h.promise().continuation.resume();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会变成</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::coroutine_handle&lt;&gt; task::promise_type::final_awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; h) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  <span class="comment">// The coroutine is now suspended at the final-suspend point.</span></span><br><span class="line">  <span class="comment">// Lookup its continuation in the promise and resume it symmetrically.</span></span><br><span class="line">  <span class="keyword">return</span> h.promise().continuation;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>And now we have a task implementation that doesn’t suffer from the stack-overflow problem that the void-returning await_suspend flavour had and that doesn’t have the non-deterministic resumption context problem of the bool-returning await_suspend flavour had.</p><h2 id="Visualising-the-stack"><a href="#Visualising-the-stack" class="headerlink" title="Visualising the stack"></a>Visualising the stack</h2><p>这是之前的例子</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">task <span class="title">completes_synchronously</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  co_return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">task <span class="title">loop_synchronously</span><span class="params">(<span class="keyword">int</span> count)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; ++i) &#123;</span><br><span class="line">    <span class="function">co_await <span class="title">completes_synchronously</span><span class="params">()</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在，在 loop_synchronously() 第一次被执行的时候，可能是因为有些其他的 coroutine 去 co_await 了它。这是通过 symmetric transfer 来实现的，所以栈类似下面。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">           Stack                                                Heap</span><br><span class="line">+---------------------------+  &lt;-- top of stack   +--------------------------+</span><br><span class="line">| loop_synchronously$resume | active coroutine -&gt; | loop_synchronously frame |</span><br><span class="line">+---------------------------+                     | +----------------------+ |</span><br><span class="line">| coroutine_handle::resume  |                     | | task::promise        | |</span><br><span class="line">+---------------------------+                     | | - continuation --.   | |</span><br><span class="line">|     ...                   |                     | +------------------|---+ |</span><br><span class="line">+---------------------------+                     | ...                |     |</span><br><span class="line">                                                  +--------------------|-----+</span><br><span class="line">                                                                       V</span><br><span class="line">                                                  +--------------------------+</span><br><span class="line">                                                  | awaiting_coroutine frame |</span><br><span class="line">                                                  |                          |</span><br><span class="line">                                                  +--------------------------+</span><br></pre></td></tr></table></figure><p>然后，执行 <code>co_await completes_synchronously()</code> 的时候，又会触发一次 symmetric transfer 到 completes_synchronously。</p><p>It does this by:</p><ol><li>调用 <code>task::operator co_await()</code>，获得一个 task::awaiter 对象</li><li>suspend，然后调用 <code>task::awaiter::await_suspend()</code>。它的 symmetric transfer 的版本会返回 <code>coroutine_handle</code> of the <code>completes_synchronously</code> coroutine.</li><li>执行一次 tail-call 或者说 jump 去到 <code>completes_synchronously</code> coroutine。这会弹出 <code>loop_synchronously</code> 的 frame，然后再 activate <code>completes_synchronously</code> 的 frame.</li></ol><p>If we now look at the stack just after <code>completes_synchronously</code> is resumed it will now look like this:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">              Stack                                          Heap</span><br><span class="line">                                            .-&gt; +--------------------------+ &lt;-.</span><br><span class="line">                                            |   | completes_synchronously  |   |</span><br><span class="line">                                            |   | frame                    |   |</span><br><span class="line">                                            |   | +----------------------+ |   |</span><br><span class="line">                                            |   | | task::promise        | |   |</span><br><span class="line">                                            |   | | - continuation --.   | |   |</span><br><span class="line">                                            |   | +------------------|---+ |   |</span><br><span class="line">                                            `-, +--------------------|-----+   |</span><br><span class="line">                                              |                      V         |</span><br><span class="line">+-------------------------------+ &lt;-- top of  | +--------------------------+   |</span><br><span class="line">| completes_synchronously$resume|     stack   | | loop_synchronously frame |   |</span><br><span class="line">+-------------------------------+ active -----&apos; | +----------------------+ |   |</span><br><span class="line">| coroutine_handle::resume      | coroutine     | | task::promise        | |   |</span><br><span class="line">+-------------------------------+               | | - continuation --.   | |   |</span><br><span class="line">|     ...                       |               | +------------------|---+ |   |</span><br><span class="line">+-------------------------------+               | task temporary     |     |   |</span><br><span class="line">                                                | - coro_       -----|---------`</span><br><span class="line">                                                +--------------------|-----+</span><br><span class="line">                                                                     V</span><br><span class="line">                                                +--------------------------+</span><br><span class="line">                                                | awaiting_coroutine frame |</span><br><span class="line">                                                |                          |</span><br><span class="line">                                                +--------------------------+</span><br></pre></td></tr></table></figure><p>注意，stack-frame 的数量没有变多。</p><p>在 completes_synchronously 完成之后，当遇到右花括号的时候，会执行 <code>co_await promise.final_suspend()</code>。</p><p>这会导致 coroutine 被挂起，并且调用 <code>final_awaiter::await_suspend()</code>，从而返回 continuation 的 std::coroutine_handle，实际上就指向的 loop_synchronously。这之后会做一个 symmetric transfer/tail-call 去 resume loop_synchronously。</p><p>If we look at the stack just after loop_synchronously is resumed then it will look something like this:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">           Stack                                                   Heap</span><br><span class="line">                                                   +--------------------------+ &lt;-.</span><br><span class="line">                                                   | completes_synchronously  |   |</span><br><span class="line">                                                   | frame                    |   |</span><br><span class="line">                                                   | +----------------------+ |   |</span><br><span class="line">                                                   | | task::promise        | |   |</span><br><span class="line">                                                   | | - continuation --.   | |   |</span><br><span class="line">                                                   | +------------------|---+ |   |</span><br><span class="line">                                                   +--------------------|-----+   |</span><br><span class="line">                                                                        V         |</span><br><span class="line">+----------------------------+  &lt;-- top of stack   +--------------------------+   |</span><br><span class="line">| loop_synchronously$resume  | active coroutine -&gt; | loop_synchronously frame |   |</span><br><span class="line">+----------------------------+                     | +----------------------+ |   |</span><br><span class="line">| coroutine_handle::resume() |                     | | task::promise        | |   |</span><br><span class="line">+----------------------------+                     | | - continuation --.   | |   |</span><br><span class="line">|     ...                    |                     | +------------------|---+ |   |</span><br><span class="line">+----------------------------+                     | task temporary     |     |   |</span><br><span class="line">                                                   | - coro_       -----|---------`</span><br><span class="line">                                                   +--------------------|-----+</span><br><span class="line">                                                                        V</span><br><span class="line">                                                   +--------------------------+</span><br><span class="line">                                                   | awaiting_coroutine frame |</span><br><span class="line">                                                   |                          |</span><br><span class="line">                                                   +--------------------------+</span><br></pre></td></tr></table></figure><p>loop_synchronously 在 resume 之后要做的第一件事，是调用临时的 task 对象的析构函数。这会销毁 coroutine-frame，释放它的内存，并产生下面：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">           Stack                                                   Heap</span><br><span class="line">+---------------------------+  &lt;-- top of stack   +--------------------------+</span><br><span class="line">| loop_synchronously$resume | active coroutine -&gt; | loop_synchronously frame |</span><br><span class="line">+---------------------------+                     | +----------------------+ |</span><br><span class="line">| coroutine_handle::resume  |                     | | task::promise        | |</span><br><span class="line">+---------------------------+                     | | - continuation --.   | |</span><br><span class="line">|     ...                   |                     | +------------------|---+ |</span><br><span class="line">+---------------------------+                     | ...                |     |</span><br><span class="line">                                                  +--------------------|-----+</span><br><span class="line">                                                                       V</span><br><span class="line">                                                  +--------------------------+</span><br><span class="line">                                                  | awaiting_coroutine frame |</span><br><span class="line">                                                  |                          |</span><br><span class="line">                                                  +--------------------------+</span><br></pre></td></tr></table></figure><p>We are now back to executing the <code>loop_synchronously</code> coroutine and we now have the same number of stack-frames and coroutine-frames as we started, and will do so each time we go around the loop.</p><p>Thus we can perform as many iterations of the loop as we want and will only use a constant amount of storage space.</p><p>For a full example of the symmetric-transfer version of the task type see the following Compiler Explorer link: <a href="https://godbolt.org/z/9baieF" target="_blank" rel="noopener">https://godbolt.org/z/9baieF</a>.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;翻译 &lt;a href=&quot;https://lewissbaker.github.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;lewissbaker&lt;/a&gt; 的三篇文章。&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Rust 的 Borrow Checker</title>
    <link href="http://www.calvinneo.com/2024/04/07/rust-borrow-checker/"/>
    <id>http://www.calvinneo.com/2024/04/07/rust-borrow-checker/</id>
    <published>2024-04-07T07:46:32.000Z</published>
    <updated>2024-07-15T09:44:29.134Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 Rust 的 Borrow Checker 的原理。</p><a id="more"></a><h1 id="前期知识：High-level-Compiler-Architecture"><a href="#前期知识：High-level-Compiler-Architecture" class="headerlink" title="前期知识：High-level Compiler Architecture"></a>前期知识：High-level Compiler Architecture</h1><h2 id="Queries-demand-driven-compilation"><a href="#Queries-demand-driven-compilation" class="headerlink" title="Queries: demand-driven compilation"></a>Queries: demand-driven compilation</h2><p>正在从 pass-based 转变为 demand-driven 模式：</p><blockquote><p>Instead of entirely independent passes (parsing, type-checking, etc.), a set of function-like queries compute information about the input source. For example, there is a query called <code>type_of</code> that, given the <code>DefId</code> of some item, will compute the type of that item and return it to you.</p></blockquote><p>上面的这些 query 是可以被记忆化的，所以在第一次被计算后，剩余的查询就可以从一个 hash table 中被检索出来。这对 Incremental Computation 是非常友好的。</p><p>最终，we want the entire compiler control-flow to be query driven. 也就是对于每个 crate，会运行一个 top-level 的 query 即 <code>compile</code>。这会链式地触发后续的各种计算，比如:</p><ul><li>The compile query might demand to get a list of codegen-units，比如需要被 LLVM 编译的模块列表</li><li>但为了计算这些 codegen-units 就需要使用一个 subquery 计算 Rust 源码中定义的 module 列表</li><li>这个 subquery 就需要触发 HIR 的计算</li><li>This keeps going further and further back until we wind up doing the actual parsing.</li></ul><h3 id="How-the-compiler-executes-a-query"><a href="#How-the-compiler-executes-a-query" class="headerlink" title="How the compiler executes a query"></a>How the compiler executes a query</h3><h3 id="Providers"><a href="#Providers" class="headerlink" title="Providers"></a>Providers</h3><p>If, however, the query is not in the cache, then the compiler will try to find a suitable provider. A provider is a function that has been defined and linked into the compiler somewhere that contains the code to compute the result of the query.</p><h3 id="How-providers-are-setup"><a href="#How-providers-are-setup" class="headerlink" title="How providers are setup"></a>How providers are setup</h3><h2 id="Memory-Management-in-Rustc"><a href="#Memory-Management-in-Rustc" class="headerlink" title="Memory Management in Rustc"></a>Memory Management in Rustc</h2><h1 id="前期知识：Source-Code-Representation"><a href="#前期知识：Source-Code-Representation" class="headerlink" title="前期知识：Source Code Representation"></a>前期知识：Source Code Representation</h1><h2 id="Intermediate-representations-综述"><a href="#Intermediate-representations-综述" class="headerlink" title="Intermediate representations 综述"></a>Intermediate representations 综述</h2><p>Instead most compilers, including rustc, build some sort of IR out of the source code which is easier to analyze. rustc has a few IRs, each optimized for different purposes:</p><ul><li>Token stream: the lexer produces a stream of tokens directly from the source code. This stream of tokens is easier for the parser to deal with than raw text.</li><li>Abstract Syntax Tree (AST): the abstract syntax tree is built from the stream of tokens produced by the lexer. It represents pretty much exactly what the user wrote. It helps to do some syntactic sanity checking (e.g. checking that a type is expected where the user wrote one).</li><li>High-level IR (HIR): This is a sort of desugared AST. It’s still close to what the user wrote syntactically, but it includes some implicit things such as some elided lifetimes, etc. This IR is amenable to type checking.</li><li>Typed HIR (THIR) formerly High-level Abstract IR (HAIR): This is an intermediate between HIR and MIR. It is like the HIR but it is fully typed and a bit more desugared，比如方法调用和隐式解引用都会被显式化. As a result, it is easier to lower to MIR from THIR than from HIR.</li><li>Middle-level IR (MIR): This IR is basically a Control-Flow Graph (CFG). A CFG is a type of diagram that shows the basic blocks of a program and how control flow can go between them. Likewise, MIR also has a bunch of basic blocks with simple typed statements inside them (e.g. assignment, simple computations, etc) and control flow edges to other basic blocks (e.g., calls, dropping values). MIR is used for borrow checking and other important dataflow-based checks, such as checking for uninitialized values. It is also used for a series of optimizations and for constant evaluation (via MIRI). Because MIR is still generic, we can do a lot of analyses here more efficiently than after monomorphization.</li><li>LLVM-IR: This is the standard form of all input to the LLVM compiler. LLVM-IR is a sort of typed assembly language with lots of annotations. It’s a standard format that is used by all compilers that use LLVM (e.g. the clang C compiler also outputs LLVM-IR). LLVM-IR is designed to be easy for other compilers to emit and also rich enough for LLVM to run a bunch of optimizations on it.</li></ul><h2 id="HIR"><a href="#HIR" class="headerlink" title="HIR"></a>HIR</h2><p>HIR – “High-Level Intermediate Representation”，是编译期友好的 AST。只会进行 parse、宏展开和 name resolution 的转化。<br>可以通过第一行的语句得到 HIR 表示，通过第二行的语句得到更为接近原文的 HIR 表示。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cargo rustc -- -Z unpretty=hir-tree</span><br><span class="line">cargo rustc -- -Z unpretty=hir</span><br></pre></td></tr></table></figure><h3 id="HIR-Bodies"><a href="#HIR-Bodies" class="headerlink" title="HIR Bodies"></a>HIR Bodies</h3><p>A <code>rustc_hir::Body</code> represents some kind of executable code, such as the body of a function/closure or the definition of a constant. Bodies are associated with an owner, which is typically some kind of item (e.g. an <code>fn()</code> or <code>const</code>), but could also be a closure expression (e.g. <code>|x, y| x + y</code>). You can use the HIR map to find the body associated with a given def-id (maybe_body_owned_by) or to find the owner of a body (body_owner_def_id).</p><h2 id="THIR"><a href="#THIR" class="headerlink" title="THIR"></a>THIR</h2><p>THIR 也就是 Typed High-Level Intermediate Representation，从前叫 “High-Level Abstract IR。它在 type checking 后生成，被用来构造 MIR，exhaustiveness checking，以及 unsafety checking。</p><p>THIR 在 HIR 更下层。在 type checking 完成后，就能填入所有的 type。HIR 具有下面的特性：</p><ol><li>类似于 MIR，THIR 只表示 “bodies”。其中包含 function bodies，const initializers 等。换句话说，THIR 中没有 struct 或者 trait 的表示。</li><li>THIR 的 body 只是临时被存储，并且在不需要的时候就会被 drop 掉。对应的，HIR 的会存储到编译过程的结束。</li><li>THIR 会有更多的 desugar。比如 automatic references and dereferences 会变得显式。method calls 和 overloaded operators 会转换为 plain function call。Destruction scopes 会显式。<br> 这个我理解是因为 THIR 中已经没有 struct 了。</li><li>Statements、expressions、match arms 会分开存储。</li></ol><p>The THIR lives in <code>rustc_mir_build::thir</code>. To construct a <code>thir::Expr</code>, you can use the <code>thir_body</code> function, passing in the memory arena where the THIR will be allocated. Dropping this arena will result in the THIR being destroyed, which is useful to keep peak memory in check. Having a THIR representation of all bodies of a crate in memory at the same time would be very heavy.</p><p>You can get a debug representation of the THIR by passing the <code>-Zunpretty=thir-tree</code> flag to rustc.</p><p>下面的代码</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> x = <span class="number">1</span> + <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对应的 THIR</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line">Thir &#123;</span><br><span class="line">    // no match arms</span><br><span class="line">    arms: [],</span><br><span class="line">    exprs: [</span><br><span class="line">        // expression 0, a literal with a value of 1</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:13: 2:14 (#0),</span><br><span class="line">            kind: Literal &#123;</span><br><span class="line">                lit: Spanned &#123;</span><br><span class="line">                    node: Int(</span><br><span class="line">                        1,</span><br><span class="line">                        Unsuffixed,</span><br><span class="line">                    ),</span><br><span class="line">                    span: oneplustwo.rs:2:13: 2:14 (#0),</span><br><span class="line">                &#125;,</span><br><span class="line">                neg: false,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 1, scope surrounding literal 1</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:13: 2:14 (#0),</span><br><span class="line">            kind: Scope &#123;</span><br><span class="line">                // reference to expression 0 above</span><br><span class="line">                region_scope: Node(3),</span><br><span class="line">                lint_level: Explicit(</span><br><span class="line">                    HirId &#123;</span><br><span class="line">                        owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                        local_id: 3,</span><br><span class="line">                    &#125;,</span><br><span class="line">                ),</span><br><span class="line">                value: e0,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 2, literal 2</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:17: 2:18 (#0),</span><br><span class="line">            kind: Literal &#123;</span><br><span class="line">                lit: Spanned &#123;</span><br><span class="line">                    node: Int(</span><br><span class="line">                        2,</span><br><span class="line">                        Unsuffixed,</span><br><span class="line">                    ),</span><br><span class="line">                    span: oneplustwo.rs:2:17: 2:18 (#0),</span><br><span class="line">                &#125;,</span><br><span class="line">                neg: false,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 3, scope surrounding literal 2</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:17: 2:18 (#0),</span><br><span class="line">            kind: Scope &#123;</span><br><span class="line">                region_scope: Node(4),</span><br><span class="line">                lint_level: Explicit(</span><br><span class="line">                    HirId &#123;</span><br><span class="line">                        owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                        local_id: 4,</span><br><span class="line">                    &#125;,</span><br><span class="line">                ),</span><br><span class="line">                // reference to expression 2 above</span><br><span class="line">                value: e2,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 4, represents 1 + 2</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:13: 2:18 (#0),</span><br><span class="line">            kind: Binary &#123;</span><br><span class="line">                op: Add,</span><br><span class="line">                // references to scopes surronding literals above</span><br><span class="line">                lhs: e1,</span><br><span class="line">                rhs: e3,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 5, scope surronding expression 4</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:13: 2:18 (#0),</span><br><span class="line">            kind: Scope &#123;</span><br><span class="line">                region_scope: Node(5),</span><br><span class="line">                lint_level: Explicit(</span><br><span class="line">                    HirId &#123;</span><br><span class="line">                        owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                        local_id: 5,</span><br><span class="line">                    &#125;,</span><br><span class="line">                ),</span><br><span class="line">                value: e4,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 6, block around statement</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: (),</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(9),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:1:11: 3:2 (#0),</span><br><span class="line">            kind: Block &#123;</span><br><span class="line">                body: Block &#123;</span><br><span class="line">                    targeted_by_break: false,</span><br><span class="line">                    region_scope: Node(8),</span><br><span class="line">                    opt_destruction_scope: None,</span><br><span class="line">                    span: oneplustwo.rs:1:11: 3:2 (#0),</span><br><span class="line">                    // reference to statement 0 below</span><br><span class="line">                    stmts: [</span><br><span class="line">                        s0,</span><br><span class="line">                    ],</span><br><span class="line">                    expr: None,</span><br><span class="line">                    safety_mode: Safe,</span><br><span class="line">                &#125;,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 7, scope around block in expression 6</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: (),</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(9),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:1:11: 3:2 (#0),</span><br><span class="line">            kind: Scope &#123;</span><br><span class="line">                region_scope: Node(9),</span><br><span class="line">                lint_level: Explicit(</span><br><span class="line">                    HirId &#123;</span><br><span class="line">                        owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                        local_id: 9,</span><br><span class="line">                    &#125;,</span><br><span class="line">                ),</span><br><span class="line">                value: e6,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // destruction scope around expression 7</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: (),</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(9),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:1:11: 3:2 (#0),</span><br><span class="line">            kind: Scope &#123;</span><br><span class="line">                region_scope: Destruction(9),</span><br><span class="line">                lint_level: Inherited,</span><br><span class="line">                value: e7,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    ],</span><br><span class="line">    stmts: [</span><br><span class="line">        // let statement</span><br><span class="line">        Stmt &#123;</span><br><span class="line">            kind: Let &#123;</span><br><span class="line">                remainder_scope: Remainder &#123; block: 8, first_statement_index: 0&#125;,</span><br><span class="line">                init_scope: Node(1),</span><br><span class="line">                pattern: Pat &#123;</span><br><span class="line">                    ty: i32,</span><br><span class="line">                    span: oneplustwo.rs:2:9: 2:10 (#0),</span><br><span class="line">                    kind: Binding &#123;</span><br><span class="line">                        mutability: Not,</span><br><span class="line">                        name: &quot;x&quot;,</span><br><span class="line">                        mode: ByValue,</span><br><span class="line">                        var: LocalVarId(</span><br><span class="line">                            HirId &#123;</span><br><span class="line">                                owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                                local_id: 7,</span><br><span class="line">                            &#125;,</span><br><span class="line">                        ),</span><br><span class="line">                        ty: i32,</span><br><span class="line">                        subpattern: None,</span><br><span class="line">                        is_primary: true,</span><br><span class="line">                    &#125;,</span><br><span class="line">                &#125;,</span><br><span class="line">                initializer: Some(</span><br><span class="line">                    e5,</span><br><span class="line">                ),</span><br><span class="line">                else_block: None,</span><br><span class="line">                lint_level: Explicit(</span><br><span class="line">                    HirId &#123;</span><br><span class="line">                        owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                        local_id: 6,</span><br><span class="line">                    &#125;,</span><br><span class="line">                ),</span><br><span class="line">            &#125;,</span><br><span class="line">            opt_destruction_scope: Some(</span><br><span class="line">                Destruction(1),</span><br><span class="line">            ),</span><br><span class="line">        &#125;,</span><br><span class="line">    ],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Control-flow-Graph-CFG"><a href="#Control-flow-Graph-CFG" class="headerlink" title="Control-flow Graph (CFG)"></a>Control-flow Graph (CFG)</h2><p>A control-flow graph is structured as a set of basic blocks connected by edges. The key idea of a basic block is that it is a set of statements that execute “together” – that is, whenever you branch to a basic block, you start at the first statement and then execute all the remainder. Only at the end of the block is there the possibility of branching to more than one place (in MIR, we call that final statement the terminator):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bb0: &#123;</span><br><span class="line">    statement0;</span><br><span class="line">    statement1;</span><br><span class="line">    statement2;</span><br><span class="line">    ...</span><br><span class="line">    terminator;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>总而言之，basic block 是一个执行的整体。在 block 内部，不会有 branching。可以参考 <a href="/2023/12/17/patmc/">Basic block placement</a> 这个章节。</p><h2 id="MIR"><a href="#MIR" class="headerlink" title="MIR"></a>MIR</h2><p>MIR is Rust’s Mid-level Intermediate Representation. It is constructed from HIR. MIR was introduced in RFC 1211. It is a radically simplified form of Rust that is used for certain flow-sensitive safety checks – notably the borrow checker! – and also for optimization and code generation.</p><h3 id="Key-MIR-vocabulary"><a href="#Key-MIR-vocabulary" class="headerlink" title="Key MIR vocabulary"></a>Key MIR vocabulary</h3><p>This section introduces the key concepts of MIR, summarized here:</p><ul><li>Basic blocks<br>  见上文对 Basic block 的说明。</li><li>Locals<br>  Memory locations allocated on the stack (conceptually, at least), such as function arguments, local variables, and temporaries.<br>  These are identified by an index, written with a leading underscore, like <code>_1</code>. There is also a special “local” (<code>_0</code>) allocated to store the return value.</li><li>Places: expressions that identify a location in memory, like <code>_1</code> or <code>_1.f</code>.</li><li>Rvalues: expressions that produce a value. The “R” stands for the fact that these are the “right-hand side” of an assignment.<ul><li>Operands: the arguments to an rvalue, which can either be a constant (like 22) or a place (like <code>_1</code>).</li></ul></li></ul><p>Some statements like StorageLive are removed in optimization. This happens because the compiler notices the value is never accessed in the code. 可以通过 <code>rustc [filename].rs -Z mir-opt-level=0 --emit mir</code> 显示没有被优化过的 MIR。</p><h3 id="一个样例"><a href="#一个样例" class="headerlink" title="一个样例"></a>一个样例</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> vec = <span class="built_in">Vec</span>::new();</span><br><span class="line">    vec.push(<span class="number">1</span>);</span><br><span class="line">    vec.push(<span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面是 MIR</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">// WARNING: This output format is intended for human consumers only</span><br><span class="line">// and is subject to change without notice. Knock yourself out.</span><br><span class="line">fn main() -&gt; () &#123;</span><br><span class="line">    let mut _0: ();                      // return place in scope 0 at main.rs:1:11: 1:11</span><br><span class="line">    let mut _1: std::vec::Vec&lt;i32&gt;;      // in scope 0 at main.rs:2:9: 2:16</span><br><span class="line">    let _2: ();                          // in scope 0 at main.rs:3:5: 3:16</span><br><span class="line">    let mut _3: &amp;mut std::vec::Vec&lt;i32&gt;; // in scope 0 at main.rs:3:5: 3:16</span><br><span class="line">    let _4: ();                          // in scope 0 at main.rs:4:5: 4:16</span><br><span class="line">    let mut _5: &amp;mut std::vec::Vec&lt;i32&gt;; // in scope 0 at main.rs:4:5: 4:16</span><br><span class="line">    scope 1 &#123;</span><br><span class="line">        debug vec =&gt; _1;                 // in scope 1 at main.rs:2:9: 2:16</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb0: &#123;</span><br><span class="line">        StorageLive(_1);                 // scope 0 at main.rs:2:9: 2:16</span><br><span class="line">        _1 = Vec::&lt;i32&gt;::new() -&gt; bb1;   // scope 0 at main.rs:2:19: 2:29</span><br><span class="line">                                         // mir::Constant</span><br><span class="line">                                         // + span: main.rs:2:19: 2:27</span><br><span class="line">                                         // + user_ty: UserType(0)</span><br><span class="line">                                         // + literal: Const &#123; ty: fn() -&gt; Vec&lt;i32&gt; &#123;Vec::&lt;i32&gt;::new&#125;, val: Value(&lt;ZST&gt;) &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb1: &#123;</span><br><span class="line">        StorageLive(_2);                 // scope 1 at main.rs:3:5: 3:16</span><br><span class="line">        StorageLive(_3);                 // scope 1 at main.rs:3:5: 3:16</span><br><span class="line">        _3 = &amp;mut _1;                    // scope 1 at main.rs:3:5: 3:16</span><br><span class="line">        _2 = Vec::&lt;i32&gt;::push(move _3, const 1_i32) -&gt; [return: bb2, unwind: bb5]; // scope 1 at main.rs:3:5: 3:16</span><br><span class="line">                                         // mir::Constant</span><br><span class="line">                                         // + span: main.rs:3:9: 3:13</span><br><span class="line">                                         // + literal: Const &#123; ty: for&lt;&apos;a&gt; fn(&amp;&apos;a mut Vec&lt;i32&gt;, i32) &#123;Vec::&lt;i32&gt;::push&#125;, val: Value(&lt;ZST&gt;) &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb2: &#123;</span><br><span class="line">        StorageDead(_3);                 // scope 1 at main.rs:3:15: 3:16</span><br><span class="line">        StorageDead(_2);                 // scope 1 at main.rs:3:16: 3:17</span><br><span class="line">        StorageLive(_4);                 // scope 1 at main.rs:4:5: 4:16</span><br><span class="line">        StorageLive(_5);                 // scope 1 at main.rs:4:5: 4:16</span><br><span class="line">        _5 = &amp;mut _1;                    // scope 1 at main.rs:4:5: 4:16</span><br><span class="line">        _4 = Vec::&lt;i32&gt;::push(move _5, const 2_i32) -&gt; [return: bb3, unwind: bb5]; // scope 1 at main.rs:4:5: 4:16</span><br><span class="line">                                         // mir::Constant</span><br><span class="line">                                         // + span: main.rs:4:9: 4:13</span><br><span class="line">                                         // + literal: Const &#123; ty: for&lt;&apos;a&gt; fn(&amp;&apos;a mut Vec&lt;i32&gt;, i32) &#123;Vec::&lt;i32&gt;::push&#125;, val: Value(&lt;ZST&gt;) &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb3: &#123;</span><br><span class="line">        StorageDead(_5);                 // scope 1 at main.rs:4:15: 4:16</span><br><span class="line">        StorageDead(_4);                 // scope 1 at main.rs:4:16: 4:17</span><br><span class="line">        _0 = const ();                   // scope 0 at main.rs:1:11: 5:2</span><br><span class="line">        drop(_1) -&gt; [return: bb4, unwind: bb6]; // scope 0 at main.rs:5:1: 5:2</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb4: &#123;</span><br><span class="line">        StorageDead(_1);                 // scope 0 at main.rs:5:1: 5:2</span><br><span class="line">        return;                          // scope 0 at main.rs:5:2: 5:2</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb5 (cleanup): &#123;</span><br><span class="line">        drop(_1) -&gt; bb6;                 // scope 0 at main.rs:5:1: 5:2</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb6 (cleanup): &#123;</span><br><span class="line">        resume;                          // scope 0 at main.rs:1:1: 5:2</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>debug vec =&gt; _1;</code> 提供了 debug 信息。</p><p><code>StorageLive(_1);</code> 表示 variable <code>_1</code> is “live” 的，也就是稍后还会被使用，直到遇到一个 <code>StorageDead(_1)</code>。这些标记被 LLVM 来分配栈空间。</p><p><code>&lt;Place&gt; = &lt;Rvalue&gt;</code> 这样的是赋值语句。</p><ol><li>A place is an expression like <code>_3</code>, <code>_3.f</code> or <code>*_3</code> – it denotes a location in memory.</li><li>An Rvalue is an expression that creates a value: in this case, the rvalue is a mutable borrow expression, which looks like <code>&amp;mut &lt;Place&gt;</code>. So we can kind of define a grammar for rvalues like so: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;Rvalue&gt;  = &amp; (mut)? &lt;Place&gt;</span><br><span class="line">      | &lt;Operand&gt; + &lt;Operand&gt;</span><br><span class="line">      | &lt;Operand&gt; - &lt;Operand&gt;</span><br><span class="line">      | ...</span><br><span class="line"></span><br><span class="line">&lt;Operand&gt; = Constant</span><br><span class="line">          | copy Place</span><br><span class="line">          | move Place</span><br></pre></td></tr></table></figure></li></ol><p>When you use a place, we indicate whether we are copying it (which requires that the place have a type T where T: Copy) or moving it (which works for a place of any type).</p><h1 id="有关-Rust-的类型系统及其-Analysis"><a href="#有关-Rust-的类型系统及其-Analysis" class="headerlink" title="有关 Rust 的类型系统及其 Analysis"></a>有关 Rust 的类型系统及其 Analysis</h1><h2 id="ty-模块"><a href="#ty-模块" class="headerlink" title="ty 模块"></a>ty 模块</h2><h3 id="ty-Ty"><a href="#ty-Ty" class="headerlink" title="ty::Ty"></a>ty::Ty</h3><p>The specific Ty we are referring to is <code>rustc_middle::ty::Ty</code> (and not <code>rustc_hir::Ty</code>). The distinction is important, so we will discuss it first before going into the details of <code>ty::Ty</code>.</p><p>In contrast, <code>ty::Ty</code> represents the semantics of a type, that is, the meaning of what the user wrote. For example, <code>rustc_hir::Ty</code> would record the fact that a user used the name <code>u32</code> twice in their program, but the <code>ty::Ty</code> would record the fact that both usages refer to the same type.</p><h4 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h4><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">foo</span></span>(x: <span class="built_in">u32</span>) → <span class="built_in">u32</span> &#123; x &#125;</span><br></pre></td></tr></table></figure><p>In this function, we see that <code>u32</code> appears twice. We know that that is the same type, i.e. the function takes an argument and returns an argument of the same type, but from the point of view of the HIR, there would be two distinct type instances because these are occurring in two different places in the program. That is, they have two different Spans (locations).</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">foo</span></span>(x: &amp;<span class="built_in">u32</span>) -&gt; &amp;<span class="built_in">u32</span></span><br></pre></td></tr></table></figure><p>进一步的，HIR 可能会丢弃一些信息。比如 <code>&amp;u32</code> 是一个 incomplete 的类型，因为它还缺少一个 lifetime。但我们并不需要写这些 lifetime，因为一些 elision rules 的缘故。其最终的表示类似于 <code>fn foo&lt;&#39;a&gt;(x: &amp;&#39;a u32) -&gt; &amp;&#39;a u32</code>。</p><p>在 HIR 级别，这样的表示并没有被生成，所以我们可以说类型是 incomplete 的。但是在 <code>ty::Ty</code> 级别，这些信息会被补足，所以现在类型是 complete 了。进一步的，对于每一个类型，只会有一个 <code>ty::Ty</code>。比如一个 u32 的 <code>ty::Ty</code> 会在整个程序中都被 share。这不同于 <code>rustc_hir::Ty</code>。</p><h3 id="Order"><a href="#Order" class="headerlink" title="Order"></a>Order</h3><p>HIR is built directly from the AST, so it happens before any <code>ty::Ty</code> is produced. After HIR is built, some basic type inference and type checking is done. During the type inference, we figure out what the <code>ty::Ty</code> of everything is and we also check if the type of something is ambiguous. The <code>ty::Ty</code> is then used for type checking while making sure everything has the expected type. </p><p>The <code>hir_ty_lowering</code> module is where the code responsible for lowering a <code>rustc_hir::Ty</code> to a <code>ty::Ty</code> is located. The main routine used is <code>lower_ty</code>.</p><h3 id="How-semantics-drive-the-two-instances-of-Ty"><a href="#How-semantics-drive-the-two-instances-of-Ty" class="headerlink" title="How semantics drive the two instances of Ty"></a>How semantics drive the two instances of Ty</h3><p>从类型推断的观点来说，HIR 去对类型进行更少的假设。我们假设两个类型是不同的，除非随后它们被证明是相同的。换句话说，知道的越少，假设就越少。</p><p>考虑 <code>fn foo&lt;T&gt;(x: T) -&gt; u32</code>. 考虑调用了 <code>foo::&lt;u32&gt;(0)</code>. 此时，T 和 u32 最终都是同一个类型，所以最终使用同一个 <code>ty::Ty</code>，但 rustc_hir::Ty 还是不同的。当然这个例子有点过于简单了，因为在 type checking 的时候，会 check the function generically and would still have a T distinct from u32。在后续的 code generation 的时候，才会进行 monomorphized，也就是对于泛型函数的每个版本生成对应的替换掉泛型变量的函数。</p><h3 id="ty-Ty-implementation"><a href="#ty-Ty-implementation" class="headerlink" title="ty::Ty implementation"></a>ty::Ty implementation</h3><p><code>rustc_middle::ty::Ty</code> is actually a wrapper around <code>Interned&lt;WithCachedTypeInfo&lt;TyKind&gt;&gt;</code>. Interned 可以忽略，它还起到一个指针的作用，反正解引用也可以被折叠。<code>TyKind</code> is a big enum with variants to represent many different Rust types，比如原始类型、引用、ADT、泛型以及 lifetime 等。 <code>WithCachedTypeInfo</code> has a few cached values like flags and <code>outer_exclusive_binder</code>. They are convenient hacks for efficiency and summarize information about the type that we may want to know, but they don’t come into the picture as much here. </p><h3 id="Allocating-and-working-with-types"><a href="#Allocating-and-working-with-types" class="headerlink" title="Allocating and working with types"></a>Allocating and working with types</h3><p>To allocate a new type, you can use the various new_* methods defined on Ty. These have names that correspond mostly to the various kinds of types. For example:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> array_ty = Ty::new_array_with_const_len(tcx, ty, count);</span><br></pre></td></tr></table></figure><p>类似的方法返回一个 <code>Ty&lt;&#39;tcx&gt;</code>。注意获得的 lifetime 是 tctx 所访问的哪个 arena 的 lifetime。Types are always canonicalized and interned (so we never allocate exactly the same type twice).</p><h3 id="Comparing-types"><a href="#Comparing-types" class="headerlink" title="Comparing types"></a>Comparing types</h3><h3 id="ty-TyKind-Variants"><a href="#ty-TyKind-Variants" class="headerlink" title="ty::TyKind Variants"></a>ty::TyKind Variants</h3><h3 id="ADTs-Representation"><a href="#ADTs-Representation" class="headerlink" title="ADTs Representation"></a>ADTs Representation</h3><h2 id="Bound-vars-and-parameters"><a href="#Bound-vars-and-parameters" class="headerlink" title="Bound vars and parameters"></a>Bound vars and parameters</h2><h2 id="Type-inference"><a href="#Type-inference" class="headerlink" title="Type inference"></a>Type inference</h2><p>下面代码中的 <code>things</code> 的类型被推断为 <code>Vec&lt;&amp;str&gt;</code>，因为我们往 things 中加入了 <code>&amp;str</code>。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> things = <span class="built_in">vec!</span>[];</span><br><span class="line">    things.push(<span class="string">"thing"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The type inference is based on the standard Hindley-Milner (HM) type inference algorithm, but extended in various way to accommodate subtyping, region inference, and higher-ranked types.</p><h3 id="Inference-variables"><a href="#Inference-variables" class="headerlink" title="Inference variables"></a>Inference variables</h3><p>inference context 的主要目的是容纳一系列的 inference variable。这些表示那些具体值还没有被确定的 type 或者 region。这些值会在 type-checking 的时候被计算得到。</p><p>如果了解 HM 类型系统或者像 Prolog 的逻辑语言就能理解类似的概念。</p><p>All told, the inference context stores five kinds of inference variables (as of March 2023):</p><p>inference context 存放 5 种 inference variable：</p><ul><li>Type variables, which come in three varieties:<ul><li>General type variables (the most common). These can be unified with any type.</li><li>Integral type variables, which can only be unified with an integral type, and arise from an integer literal expression like <code>22</code>.</li><li>Float type variables, which can only be unified with a float type, and arise from a float literal expression like <code>22.0</code>.</li></ul></li><li>Region variables, which represent lifetimes, and arise all over the place.</li><li>Const variables, which represent constants.</li></ul><p>All the type variables work in much the same way: you can create a new type variable, and what you get is <code>Ty&lt;&#39;tcx&gt;</code> representing an unresolved type <code>?T</code>. Then later you can apply the various operations that the inferencer supports, such as equality or subtyping, and it will possibly instantiate (or bind) that <code>?T</code> to a specific value as a result.</p><p>对于 Region variable 情况不同，会在稍后 Region constraints 中讨论。</p><h3 id="补充说明：lexical-region-和-non-lexical-region"><a href="#补充说明：lexical-region-和-non-lexical-region" class="headerlink" title="补充说明：lexical region 和 non-lexical region"></a>补充说明：lexical region 和 non-lexical region</h3><p><a href="https://stackoverflow.com/questions/50251487/what-are-non-lexical-lifetimes" target="_blank" rel="noopener">如下所示</a>，在 non-lexical lifetime 出现之前，下面的代码会编译失败。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> scores = <span class="built_in">vec!</span>[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line">    <span class="keyword">let</span> score = &amp;scores[<span class="number">0</span>];</span><br><span class="line">    scores.push(<span class="number">4</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译报错如下，当然我发现现如今的 rust 已经无法复现了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">error[E0502]: cannot borrow `scores` as mutable because it is also borrowed as immutable</span><br><span class="line"> --&gt; src/main.rs:4:5</span><br><span class="line">  |</span><br><span class="line">3 |     let score = &amp;scores[0];</span><br><span class="line">  |                  ------ immutable borrow occurs here</span><br><span class="line">4 |     scores.push(4);</span><br><span class="line">  |     ^^^^^^ mutable borrow occurs here</span><br><span class="line">5 | &#125;</span><br><span class="line">  | - immutable borrow ends here</span><br></pre></td></tr></table></figure><p>这里报错的原因是 score 是通过 <a href="https://en.wikipedia.org/wiki/Scope_(computer_science)#Lexical_scoping" target="_blank" rel="noopener">lexical</a> 的方式 borrow 的 scores 的。</p><h3 id="Region-constraints"><a href="#Region-constraints" class="headerlink" title="Region constraints"></a>Region constraints</h3><p>Regions are inferenced somewhat differently from types. Rather than eagerly unifying things, we simply collect constraints as we go, but make (almost) no attempt to solve regions. These constraints have the form of an “outlives” constraint:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">'a</span>: <span class="symbol">'b</span></span><br></pre></td></tr></table></figure><p>实际上这个代码将 <code>&#39;a</code> 和 <code>&#39;b</code> 视作了 subregion 的关系，但实际上是一个意思</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">'b</span> &lt;= <span class="symbol">'a</span></span><br></pre></td></tr></table></figure><p>(There are various other kinds of constraints, such as “verifys”; see the <code>region_constraints</code> module for details.)</p><p>但是依然有一个常见，我们会做一些 eager unification。也就是如果有一个 equality constraint between two regions，如</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">'a</span> = <span class="symbol">'b</span></span><br></pre></td></tr></table></figure><p>那么我们就会将这个事实记录在一个 unification table 中。可以使用 <code>opportunistic_resolve_var</code> to convert <code>&#39;b</code> to <code>&#39;a</code>，或者反过来也可以. This is sometimes needed to ensure termination of fixed-point algorithms.</p><h3 id="Solving-region-constraints"><a href="#Solving-region-constraints" class="headerlink" title="Solving region constraints"></a>Solving region constraints</h3><p>Region constraints are only solved at the very end of typechecking, once all other constraints are known and all other obligations have been proven. There are two ways to solve region constraints right now: lexical and non-lexical. Eventually there will only be one.</p><p>An exception here is the leak-check which is used during trait solving and relies on region constraints containing higher-ranked regions. Region constraints in the root universe (i.e. not arising from a <code>for&lt;&#39;a&gt;</code>) must not influence the trait system, as these regions are all erased during codegen.</p><p>To solve lexical region constraints, you invoke <code>resolve_regions_and_report_errors</code>. This “closes” the region constraint process and invokes the <code>lexical_region_resolve</code> code. Once this is done, any further attempt to equate or create a subtyping relationship will yield an ICE.</p><p>The NLL solver (actually, the MIR type-checker) does things slightly differently. It uses canonical queries for trait solving which use <code>take_and_reset_region_constraints</code> at the end. This extracts all of the outlives constraints added during the canonical query. This is required as the NLL solver must not only know what regions outlive each other, but also where. Finally, the NLL solver invokes <code>take_region_var_origins</code>, providing all region variables to the solver.</p><h3 id="Lexical-region-resolution"><a href="#Lexical-region-resolution" class="headerlink" title="Lexical region resolution"></a>Lexical region resolution</h3><p>Lexical region resolution is done by initially assigning each region variable to an empty value. We then process each outlives constraint repeatedly, growing region variables until a fixed-point is reached. Region variables can be grown using a least-upper-bound relation on the region lattice in a fairly straightforward fashion.</p><p><a href="https://internals.rust-lang.org/t/how-does-region-inference-work/7511/3" target="_blank" rel="noopener">https://internals.rust-lang.org/t/how-does-region-inference-work/7511/3</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Constraints | Ordering | Region-lattice </span><br><span class="line">------------|----------|--------------</span><br><span class="line">  &apos;a:&apos;b+&apos;c  | &apos;a &lt;= &apos;b |      &apos;d      Join, LUB (Most Specific Supertype)</span><br><span class="line">  &apos;b:&apos;d     | &apos;a &lt;= &apos;c |      / \     </span><br><span class="line">  &apos;c:&apos;d     | &apos;b &lt;= &apos;d |    &apos;b  &apos;c    </span><br><span class="line">  &apos;d        | &apos;c &lt;= &apos;d |      \ /     </span><br><span class="line">            |          |      &apos;a      Meet, GLB (Most Common Subtype)</span><br></pre></td></tr></table></figure><h1 id="有关-Borrow-checker"><a href="#有关-Borrow-checker" class="headerlink" title="有关 Borrow checker"></a>有关 Borrow checker</h1><p>The borrow checker operates on the MIR. An older implementation operated on the HIR. Doing borrow checking on MIR has several advantages:</p><ol><li>The MIR is far less complex than the HIR; the radical desugaring helps prevent bugs in the borrow checker. (If you’re curious, you can see a list of bugs that the MIR-based borrow checker fixes here.)</li><li>Even more importantly, using the MIR enables “non-lexical lifetimes”, which are regions derived from the control-flow graph.</li></ol><h2 id="Tracking-moves-and-initialization"><a href="#Tracking-moves-and-initialization" class="headerlink" title="Tracking moves and initialization"></a>Tracking moves and initialization</h2><p>其作用如下，检查哪些变量是 uninitialized 的状态。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">foo</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> a: (<span class="built_in">Vec</span>&lt;<span class="built_in">u32</span>&gt;, <span class="built_in">Vec</span>&lt;<span class="built_in">u32</span>&gt;) = (<span class="built_in">vec!</span>[<span class="number">22</span>], <span class="built_in">vec!</span>[<span class="number">44</span>]);</span><br><span class="line">    <span class="comment">// a.0 and a.1 are both initialized</span></span><br><span class="line">    <span class="keyword">let</span> b = a.<span class="number">0</span>; <span class="comment">// moves a.0</span></span><br><span class="line">    <span class="comment">// a.0 is not initialized, but a.1 still is</span></span><br><span class="line">    <span class="keyword">let</span> c = a.<span class="number">0</span>; <span class="comment">// ERROR</span></span><br><span class="line">    <span class="keyword">let</span> d = a.<span class="number">1</span>; <span class="comment">// OK</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为 Rust 现在允许只 move 一个 field 比如 <code>a.0</code> 了，所以 trace local variable 是不够的。Rust 根据 move path 为粒度去 trace。<br>A <a href="https://doc.rust-lang.org/nightly/nightly-rustc/rustc_mir_dataflow/move_paths/struct.MovePath.html" target="_blank" rel="noopener">MovePath</a> represents some location that the user can initialize, move, etc. So e.g. there is a move-path representing the local variable a, and there is a move-path representing a.0. Move paths roughly correspond to the concept of a Place from MIR, but they are indexed in ways that enable us to do move analysis more efficiently.</p><p>所有的 <code>MovePath</code> 存储在一个 vector 中，我们通过 <code>MovePathIndex</code> 去访问。</p><p>One of the first things we do in the MIR borrow check is to construct the set of move paths. This is done as part of the <code>MoveData::gather_moves</code> function. This function uses a MIR visitor called <code>Gatherer</code> to walk the MIR and look at how each <code>Place</code> within is accessed. For each such <code>Place</code>, it constructs a corresponding <code>MovePathIndex</code>. It also records when/where that particular move path is moved/initialized, but we’ll get to that in a later section.</p><p>We don’t actually create a move-path for every <code>Place</code> that gets used. In particular, if it is illegal to move from a <code>Place</code>, then there is no need for a <code>MovePathIndex</code>. Some examples:</p><ul><li>You cannot move from a static variable, so we do not create a <code>MovePathIndex</code> for static variables.</li><li>You cannot move an individual element of an array, so if we have e.g. <code>foo: [String; 3]</code>, there would be no move-path for <code>foo[1]</code>.</li><li>You cannot move from inside of a borrowed reference, so if we have e.g. <code>foo: &amp;String</code>, there would be no move-path for <code>*foo</code>.</li></ul><p>These rules are enforced by the <code>move_path_for</code> function, which converts a <code>Place</code> into a <code>MovePathIndex</code>。在诸如上面的错误的场景下，返回错误 <code>Err</code>。这也说明了我们并不需要 track 这些 <code>Place</code> 是否已经 initialized 了，从而减少了开销.</p><p>If you have a <code>Place</code> and you would like to convert it to a <code>MovePathIndex</code>, you can do that using the <code>MovePathLookup</code> structure found in the <code>rev_lookup</code> field of <code>MoveData</code>. There are two different methods:</p><ol><li><code>find_local</code>, which takes a <code>mir::Local</code> representing a local variable. This is the easier method, because we always create a <code>MovePathIndex</code> for every local variable.</li><li><code>find</code>, 可以处理任意的 <code>Place</code>。所以，只会返回一个 <code>LookupResult</code>，表示最近的 path。例如对 <code>foo[1]</code> 返回 <code>foo</code>。</li></ol><p>As we noted above, move-paths are stored in a big vector and referenced via their <code>MovePathIndex</code>. 但是在这个 vector 中，它们也被构建为一棵树。例如 if you have the <code>MovePathIndex</code> for <code>a.b.c</code>, you can go to its parent move-path <code>a.b</code>. 也可以遍历所有的 child path。比如对于 <code>a.b</code>, you might iterate to find the path <code>a.b.c</code> (here you are iterating just over the paths that are <strong>actually referenced</strong> in the source, not all <strong>possible</strong> paths that could have been referenced). These references are used for example in the <code>find_in_move_path_or_its_descendants</code> function, which determines whether a move-path (e.g., <code>a.b</code>) or any child of that move-path (e.g.,<code>a.b.c</code>) matches a given predicate.</p><h2 id="The-MIR-type-check"><a href="#The-MIR-type-check" class="headerlink" title="The MIR type-check"></a>The MIR type-check</h2><p>A key component of the borrow check is the MIR type-check. This check walks the MIR and does a complete “type check” – the same kind you might find in any other language. In the process of doing this type-check, we also uncover the region constraints that apply to the program.</p><h3 id="User-types"><a href="#User-types" class="headerlink" title="User types"></a>User types</h3><p>在 MIR type check 的开始，we replace all regions in the body with new unconstrained regions. However, this would cause us to accept the following program:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">foo</span></span>&lt;<span class="symbol">'a</span>&gt;(x: &amp;<span class="symbol">'a</span> <span class="built_in">u32</span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> y: &amp;<span class="symbol">'static</span> <span class="built_in">u32</span> = x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>By erasing the lifetimes in the type of <code>y</code> we no longer know that it is supposed to be <code>&#39;static</code>, ignoring the intentions of the user.</p><p>To deal with this we remember all places where the user explicitly mentioned a type during HIR type-check as <code>CanonicalUserTypeAnnotations</code>.</p><p>There are two different annotations we care about:</p><ol><li>Explicit type ascriptions, 比如 <code>let y: &amp;&#39;static u32</code> 会产生 <code>UserType::Ty(&amp;&#39;static u32)</code>.</li><li>Explicit generic arguments, 比如 <code>x.foo&lt;&amp;&#39;a u32, Vec&lt;String&gt;&gt;</code> 会产生 <code>UserType::TypeOf(foo_def_id, [&amp;&#39;a u32, Vec&lt;String&gt;])</code>.</li></ol><h2 id="Drop-Check"><a href="#Drop-Check" class="headerlink" title="Drop Check"></a>Drop Check</h2><h3 id="Implicit-drop"><a href="#Implicit-drop" class="headerlink" title="Implicit drop"></a>Implicit drop</h3><p>通常，只要 local 被使用，就必须要 local 的 type 是 well-formed 的。This includes proving the where-bounds of the local and also requires all regions used by it to be live.</p><p>唯一的特例是在 value go out of scope 的时候，隐式 drop 掉 value，这不需要 value 是 live 的。<br>如下所示，x 在注释处已经 out of scope 了，并且这是在指向 y 的引用被 invalidate 之后。也就是说在 drop <code>x</code> 的时候，它的类型不是 well-formed 的。但这是个特例，实际上也是唯一 drop value 操作不需要访问任何 dead region 的情况。We check this by requiring the type of the value to be drop-live. The requirements for which are computed in fn <code>dropck_outlives</code>.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> x = <span class="built_in">vec!</span>[];</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">let</span> y = <span class="built_in">String</span>::from(<span class="string">"I am temporary"</span>);</span><br><span class="line">        x.push(&amp;y);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// `x` goes out of scope here, after the reference to `y`</span></span><br><span class="line">    <span class="comment">// is invalidated. This means that while dropping `x` its type</span></span><br><span class="line">    <span class="comment">// is not well-formed as it contain regions which are not live.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="How-values-are-dropped"><a href="#How-values-are-dropped" class="headerlink" title="How values are dropped"></a>How values are dropped</h3><p>At its core, a value of type T is dropped by executing its “drop glue”. Drop glue is compiler generated and first calls<code> &lt;T as Drop&gt;::drop</code> and then recursively calls the drop glue of any recursively owned values.</p><ul><li>If T has an explicit Drop impl, call <code>&lt;T as Drop&gt;::drop</code>.</li><li>Regardless of whether <code>T</code> implements <code>Drop</code>, recurse into all values owned by T:<ul><li>references, raw pointers, function pointers, function items, trait objects1, and scalars do not own anything.<br>  对于 trait object，可以认为它有一个内置的 Drop 实现，该实现会直接调用 vtable 中的 <code>drop_in_place</code>。这个 Drop 实现需要所有它所有的 generic parameter 都是 alive 的。</li><li>tuples, slices, and arrays consider their elements to be owned. For arrays of length zero we do not own any value of the element type.</li><li>all fields (of all variants) of ADTs are considered owned. We consider all variants for enums.<br>  The exception here is <code>ManuallyDrop&lt;U&gt;</code> which is not considered to own U.<br>  <code>PhantomData&lt;U&gt;</code> also does not own anything.</li><li>closures and generators own their captured upvars.</li></ul></li></ul><p>可以通过 <code>fn Ty::needs_drop</code> 判断是否一个类型是否有 drop glue。</p><h3 id="Partially-dropping-a-local"><a href="#Partially-dropping-a-local" class="headerlink" title="Partially dropping a local"></a>Partially dropping a local</h3><p>如果一个 type 没有实现 Drop，就可以在 drop 掉剩下的成员前 move 掉一些其他的成员。此时，只有那些没有被 move 的成员会被触发 drop glue。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">PrintOnDrop</span></span>&lt;<span class="symbol">'a</span>&gt;(&amp;<span class="symbol">'a</span> <span class="built_in">str</span>);</span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">'a</span>&gt; <span class="built_in">Drop</span> <span class="keyword">for</span> PrintOnDrop&lt;<span class="symbol">'_</span>&gt; &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">drop</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">"&#123;&#125;"</span>, <span class="keyword">self</span>.<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> x = (PrintOnDrop(<span class="string">"third"</span>), PrintOnDrop(<span class="string">"first"</span>));</span><br><span class="line">    <span class="built_in">drop</span>(x.<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">"second"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是如果遇到下面的代码，则会报错 <code>cannot move out of type Tup&lt;&#39;_&gt;, which implements the Drop trait</code>。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Tup</span></span>&lt;<span class="symbol">'a</span>&gt; &#123;</span><br><span class="line">    a: PrintOnDrop&lt;<span class="symbol">'a</span>&gt;,</span><br><span class="line">    b: PrintOnDrop&lt;<span class="symbol">'a</span>&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">'a</span>&gt; <span class="built_in">Drop</span> <span class="keyword">for</span> Tup&lt;<span class="symbol">'a</span>&gt; &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">drop</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> x = Tup&#123;a: PrintOnDrop(<span class="string">"third"</span>), b: PrintOnDrop(<span class="string">"first"</span>)&#125;;</span><br><span class="line">    <span class="built_in">drop</span>(x.b);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">"second"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>During MIR building we assume that a local may get dropped whenever it goes out of scope as long as its type needs drop.<br>Computing the exact drop glue for a variable happens after borrowck in the <code>ElaborateDrops</code> pass. 也就是说，即使 local 中的一些成员之前已经被 drop 了，dropck 依然需要这些 value 是 alive 的。</p><p>如下所示，完全 move 了 local 的情况下也是这样。<code>x</code> borrow 了 temp，然后被 drop 了。但依然会有下面的报错。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> x;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">let</span> temp = <span class="built_in">String</span>::from(<span class="string">"I am temporary"</span>);</span><br><span class="line">        x = PrintOnDrop(&amp;temp);</span><br><span class="line">        <span class="built_in">drop</span>(x);</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="comment">//~ ERROR `temp` dropped here while still borrowed</span></span><br></pre></td></tr></table></figure><h3 id="dropck-outlives"><a href="#dropck-outlives" class="headerlink" title="dropck_outlives"></a>dropck_outlives</h3><p>There are two distinct “liveness” computations that we perform:</p><ul><li>a value v is use-live at location L if it may be “used” later; a use here is basically anything that is not a drop</li><li>a value v is drop-live at location L if it maybe dropped later</li></ul><p>When things are <code>use-live</code>, their entire type must be valid at L.<br>When they are <code>drop-live</code>, all regions that are required by dropck must be valid at L. The values dropped in the MIR are places.</p><h2 id="Region-inference-Non-Lexical-Lifetime-NLL"><a href="#Region-inference-Non-Lexical-Lifetime-NLL" class="headerlink" title="Region inference (Non-Lexical Lifetime, NLL)"></a>Region inference (Non-Lexical Lifetime, NLL)</h2><p>The MIR-based region checking code is located in the <code>rustc_mir::borrow_check</code> module.</p><p>The MIR-based region analysis consists of two major functions:</p><ul><li><code>replace_regions_in_mir</code>, invoked first, has two jobs:<ul><li>First, it finds the set of regions that appear within the signature of the function (e.g., <code>&#39;a</code> in <code>fn foo&lt;&#39;a&gt;(&amp;&#39;a u32) { ... }</code>). These are called the “universal” or “free” regions – in particular, they are the regions that appear free in the function body.</li><li>Second, it replaces all the regions from the function body with fresh inference variables. This is because (presently) those regions are the results of lexical region inference and hence are not of much interest. The intention is that – eventually – they will be “erased regions” (i.e., no information at all), since we won’t be doing lexical region inference at all.</li></ul></li><li><code>compute_regions</code>, invoked second: this is given as argument the results of move analysis. It has the job of computing values for all the inference variables that <code>replace_regions_in_mir</code> introduced.<ul><li>To do that, it first runs the MIR type checker. This is basically a normal type-checker but specialized to MIR, which is much simpler than full Rust, of course. Running the MIR type checker will however create various constraints between region variables, indicating their potential values and relationships to one another.</li><li>After this, we perform constraint propagation by creating a <code>RegionInferenceContext</code> and invoking its solve method.</li><li>The NLL RFC also includes fairly thorough (and hopefully readable) coverage.</li></ul></li></ul><h2 id="Universal-regions"><a href="#Universal-regions" class="headerlink" title="Universal regions"></a>Universal regions</h2><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://rustc-dev-guide.rust-lang.org/appendix/background.html" target="_blank" rel="noopener">https://rustc-dev-guide.rust-lang.org/appendix/background.html</a><br> 编译器的一些基础知识。</li><li><a href="https://rustc-dev-guide.rust-lang.org/hir.html" target="_blank" rel="noopener">https://rustc-dev-guide.rust-lang.org/hir.html</a><br> HIR。</li><li><a href="https://rustc-dev-guide.rust-lang.org/thir.html" target="_blank" rel="noopener">https://rustc-dev-guide.rust-lang.org/thir.html</a><br> THIR。</li><li><a href="https://rustc-dev-guide.rust-lang.org/ty.html" target="_blank" rel="noopener">https://rustc-dev-guide.rust-lang.org/ty.html</a><br> 关于 rust 类型系统的介绍。</li><li><a href="https://blog.logrocket.com/introducing-the-rust-borrow-checker/" target="_blank" rel="noopener">https://blog.logrocket.com/introducing-the-rust-borrow-checker/</a></li><li><a href="https://rustc-dev-guide.rust-lang.org/borrow_check.html" target="_blank" rel="noopener">https://rustc-dev-guide.rust-lang.org/borrow_check.html</a><br> Rust Compiler Development Guide 上的讲解</li><li><a href="https://www.zybuluo.com/darwin-yuan/note/424724" target="_blank" rel="noopener">https://www.zybuluo.com/darwin-yuan/note/424724</a><br> Hindley-Milner类型系统</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍 Rust 的 Borrow Checker 的原理。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Rust" scheme="http://www.calvinneo.com/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 1</title>
    <link href="http://www.calvinneo.com/2024/03/08/database-paper-1/"/>
    <id>http://www.calvinneo.com/2024/03/08/database-paper-1/</id>
    <published>2024-03-08T13:33:22.000Z</published>
    <updated>2024-11-04T03:54:04.609Z</updated>
    
    <content type="html"><![CDATA[<p>在比较早的时候，我使用腾讯文档记录一些数据库的论文。但我越来越无法忍受腾讯文档的 bug 等不便利。因此我打算将这些文章转移到博客中，即使它们中的部分的完成度并不是很高。</p><p>这篇文章中，包含 CStore、Kudu、Masstree 和 Ceph。</p><a id="more"></a><h1 id="CStore"><a href="#CStore" class="headerlink" title="CStore"></a>CStore</h1><p>C-Store 引入了一个混合架构，包括一个针对频繁插入和更新优化的写存储组件 WS 和一个针对查询性能优化的读存储组件 RS。这也是 TiFlash 列存的 Delta Merge 架构的来源。</p><p>按照 projection 存储，一个 projection 对应了一个表的一个或者几个列。<br>每个 projection 有自己独立的 sort key。不同的 projection 之间，用 join indexes 来维护它们的对应关系。<br>每个 projection 会水平分区为多个 segment，每个 segment 有自己的一个 sid。<br>每个 segment 分为 RS 和 WS。storage key 用来表示在 segment 上的一行。定义 storage key：</p><ol><li>在 RS 上，直接按序存储，通过遍历获得 index</li><li>在 WS 上，每次插入获取一个 storage key，大于 RS 上的最大值</li></ol><p>从上面看到，(sid, storage key) 可以唯一索引一个 key，它可能在 RS 上，也可能在 WS 上。</p><p>在 WS 上，projection 上的每一列用 B tree 来存，是按照 storage key 来排序的。所以还要额外维护 sort key -&gt; projection key 的映射关系。<br>【Q】为什么 WS 上也不按照 storage key 自增来处理呢？这样就不需要一个 B tree 了啊。这是因为同一个 Segment 中不同列里具有相同 SK 的数据属于同一个 Logical Tuple，所以实际上是做不到递增的。为什么要这样设计呢？原因是 join indexes 就可以只维护每个 projection 上每一行到 (sid, storage key) 的映射关系就行了。如<a href="https://zhuanlan.zhihu.com/p/656631833" target="_blank" rel="noopener">下图</a>所示</p><p><img src="/img/dbpaper/cstore/joinindex.png"></p><p>从实现上来讲，当一个 tuple 到 WS 的时候，为它分配一个 storage key 也是很自然的。<br>对于只读查询来说，如果允许其读取过去任意时间的快照（其实就是 Time Travel Query），代价是非常大的。C-Store 维护了一个高水位（High Water Mark，HWM）和一个低水位（Low Water Mark，LWM），这两个水位其实对应了只读查询可读取的时间范围的上限和下限。</p><p>CStore 的 MVCC 是以 epoch 为单位的。epoch 的粒度应该是比较大的。我们可以读 epoch e 上的事务，当 epoch e 上的所有事务都被提交完毕。</p><p>RS 的存储有优化：<br>1.排序列+Cardinality 较少：run length 编码<br>2.排序列+Cardinality 较多：bitmap 编码<br>3.非排序列+Cardinality较少：delta encoding<br>4.非排序列+Cardinality较多：正常存储</p><h1 id="Kudu"><a href="#Kudu" class="headerlink" title="Kudu"></a>Kudu</h1><p><a href="https://kudu.apache.org/kudu.pdf" target="_blank" rel="noopener">https://kudu.apache.org/kudu.pdf</a></p><p>Hadoop 系统中的结构化数据的两种存储方式：</p><ol><li>静态数据<br> 使用 Avro 行存或者 Parquet 列存来存储，但它们对 UPDATE 单条记录，或者随机访问并不友好。</li><li>可变数据<br> 存在 semi-structed 仓库中，类似 HBase 或者 Cassandra。<br> 这些存储有很低的读写延迟，但是相比静态数据，其顺序读写的带宽不高，从而不适用于 OLAP 或者机器学习。</li></ol><p>一种折衷的方案是像 Cloudera 的一些用户一样，数据和修改流式写入 HBase，再定期导出为 HDFS 上的 Parquet 文件。但这样的架构会有以下问题：</p><ol><li>应用端要写复杂的代码维护两套系统。</li><li>要跨系统维护一致性的备份、安全策略、监控。</li><li>更新进入 HBase 到最终能被查询到的延时可能很久。</li><li>实际场景中经常有要修改已经持久化到 HDFS 的文件的需求，包括迟来的数据，或者修正之前的数据。文件重写是高开销的，还可能要人工介入。</li></ol><p>Kudu 从一开始就想要 high-throughput sequential-access storage systems(HDFS) 的好处，也想要 low-latency random-access systems(such as HBase or Cassandra) 的好处。Kudu 是选择成为一个 happy medium 选择。In particular, Kudu offers a simple API for row-level inserts, updates, and deletes, while providing table scans at throughputs similar to Parquet, a commonly-used columnar format for static data.</p><h2 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h2><h3 id="Write"><a href="#Write" class="headerlink" title="Write"></a>Write</h3><h3 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h3><p>Kudu 只提供一个 Scan 操作。Scan 操作支持两种 predicate：comparisons between a column and a constant value,<br>and composite primary key ranges。</p><p>用户可以为一个 scan 指定 projection。因为 Kudu 的盘上存储是列存，所以指定 projection 能够显著提高效率。</p><h3 id="Consistency-Model"><a href="#Consistency-Model" class="headerlink" title="Consistency Model"></a>Consistency Model</h3><p>The default consistency mode is snapshot consistency. 这里应该说的类似 Snapshot Isolation 吧。<br>A scan is guaranteed to yield a snapshot with no anomalies in which causality would be violated.<br>As such, it also guarantees read-your-writes consistency from a single client.</p><h3 id="Timestamp"><a href="#Timestamp" class="headerlink" title="Timestamp"></a>Timestamp</h3><p>不像 HBase 或者 Cassandra 一样将时间戳作为 first-class 的对象。</p><h2 id="Partitioning"><a href="#Partitioning" class="headerlink" title="Partitioning"></a>Partitioning</h2><p>类似于大多数的水平分布的数据库系统，Kudu 里面的 table 也是 partition 的，Kudu 和 Bigtable 都把它们称作 horizontal partitions tablets。每个 row 会被映射到一个 partition 上。对于需要吞吐量的大表，Kudu 推荐一个机器上有 10-100 个 tablet，每个 tablet 可以有 10GB 大小。</p><p>Bigtable 只提供 key-range 形式的分区，Cassandra 基本只会使用 hash 分区，Kudu 同时支持两种分区方式。</p><p>The partition schema is made up of zero or more hash-partitioning rules followed by an optional range-partitioning rule:</p><ol><li>Hash Partition 将 tuple 中的某些 column 连接起来组成 binary key，然后计算这个串的 hash 值。<br> 比如 <code>DISTRIBUTE BY HASH(hostname, ts) INTO 16 BUCKETS</code> 会将指定的这些列连接起来，然后计算结果的 hash，并 mod 下 bucket 的总数。</li><li>Range Partition 将 tuple 中的某些 column 连接起来组成 binary key，然后用 order-preserving encoding 来确定所处的 range。</li></ol><h2 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h2><p>Kudu 的 Leader 会负责用本地的 Lock Manager 去串行化 Concurrent 的操作，选择对应的 MVCC 时间戳，并且 propose 到 Raft 上。Raft 层复制的是每个 tablet 的逻辑日志，比如 insert、update、delete 等。<br>Kudu 说 there is no restriction that the leader must write an operation to its local log before it may be committed，所以能够保障很好的延迟。这里指的应该是 Raft 的 commit，也就是说只要有 quorum 的节点持久化日志就行，Leader 未必要持久化对应的日志，其实也是对 Raft 的优化。<br>此外，它还列出了两点和 Raft 有关的优化，这里略过。</p><p>再次强调，Kudu 并不是复制 tablet 的物理日志，而是 operation log。它的目的是在各个 Replica 之间解耦，从而得到下面的好处：</p><ol><li>避免所有的 replica 同时经历物理层的开销较大的操作，比如 flush 或者 compaction。这可以降低 client 在写入时感受到的 tail latency。后续还可以实现 speculative read requests，从而减少读的 tail latency。<br> 当然，我觉得这也有坏处，例如各个 Replica 之间的 Snapshot 不太好做了。实际上也是 TiKV 做的时候面临的取舍。</li><li>有机会及时发现某个 replica 被 corrupt 了，从而即使进行修复。</li></ol><p>针对 Raft 的成员变更，主要引入了 Pre Voter，我理解类似于 Learner 追进度的方式来保证不损失可用性。</p><h2 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h2><p>这里讲述的 Kudu 的 root service 的实现。主要包括的功能有：<br>1.作为 catalog manager，记录所有的 table 和 tablet，以及对应的元信息，比如 schema、replication level 等。处理 DDL。<br>2.作为 cluster coordinator，记录存活的 server，并进行 rebalance。<br>3.作为 tablet directory，记录每个 tablet 在哪些 server 上分布。</p><p>所以 Master 的工作量还是蛮大的，既要管理数据库的 schema，又要管理集群，又要管理数据分区。</p><h3 id="catalog-manager"><a href="#catalog-manager" class="headerlink" title="catalog manager"></a>catalog manager</h3><p>Master 会管理一个专有的 tablet。它会在内部将 catalog information 写到这个 tablet 里面，同时也会有一个 full write-through 的 cache 在内存里面。Kudu 并不担心占用太多内存，如果后面确实占用了，就把它放到一个 paged cache 里面。</p><p>The catalog table maintains a small amount of state for each table in the system. In particular, it keeps the current version of the table schema, the state of the table (creating, running, deleting, etc), and the set of tablets which comprise the table. </p><ol><li>first writing a table record to the catalog table indicating a CREATING state</li><li>Asynchronously, it selects tablet servers to host tablet replicas, creates the Master-side tablet metadata</li><li>Sends asynchronous requests to create the replicas on the tablet servers<br> a. If the replica creation fails or times out on a majority of replicas, the tablet can be safely deleted and a new tablet created with a new set of replicas.<br> b. If the Master fails in the middle of this operation, the table record indicates that a roll-forward is necessary and the master can resume where it left off.</li></ol><p>对于 delete 或者 change，会先 propogate 到相关的 tablet server，然后 Master 再写自己的存储。</p><p>A similar approach is used for other operations such as schema changes and deletion, where the Master ensures that the change is propagated to the relevant tablet servers before writing the new state to its own storage. 对于所有的情况，Master 发往 tablet server 的消息都是幂等的，这样在故障重启的时候，可以被重复发送。</p><p>因为 catalog 表也是存放在专有的 tablet 里面的，所以 Master 也会用 Raft 去复制持久化的状态，到 backup master 上。目前，backup master 只是作为 Raft follower，不处理 client 请求。当当选后，会扫描 catalog 表，加载内存中的 cache，并开始作为 active master 存在。</p><h3 id="cluster-coordinator"><a href="#cluster-coordinator" class="headerlink" title="cluster coordinator"></a>cluster coordinator</h3><p>每个 tablet 会记录所有 Master 节点的地址。启动之后会开始向这些 master 不断汇报自己上面的 tablet。第一次汇报是全量，后面的是增量。<br>Kudu 有个关键设计，就是尽管 Master 是 catalog 的 source of truth，但是它只是集群状态的 observer。集群中的 tablet server 会提供比如 tablet replica 的位置信息、Raft 相关、schema version 等信息。tablet 的相关变化也是通过 raft log 记录的。因此 Master 可以借助于 raft log 的 index 去比较 tablet state 的新旧。<br>Tablet server 承担了更多的责任，每个 tablet 的 Leader replica 负责检查有没有 crash 的 follower。发现后会发起配置变更将这个 follower 移除，并在配置变更完成后通知 Master。Master 负责选择新 replica 所在的 server，然后让 Leader replica 发起新的一轮配置变更。</p><h3 id="tablet-directory"><a href="#tablet-directory" class="headerlink" title="tablet directory"></a>tablet directory</h3><p>client 会直接请求 Master 询问 tablet 的位置信息，也会缓存很多最近的信息。当缓存的信息陈旧，则会被拒绝，此时需要重新联系 Master 要最新的 Leader。<br>Master 会将所有的 table partition range 存在内存中，所以请求变多，回复依然还是比较快。即使 tablet directory 变成瓶颈，Kudu 也可以返回陈旧的 location 信息。这里原因是客户端会失败，从而重试。所以论文中说 this portion of the Master can be trivially partitioned and replicated across any number of machines. 我理解是可以从 Master 的其他副本读，但这里实际上的瓶颈不应该是内存么？</p><h2 id="Tablet-storage"><a href="#Tablet-storage" class="headerlink" title="Tablet storage"></a>Tablet storage</h2><h3 id="RowSets"><a href="#RowSets" class="headerlink" title="RowSets"></a>RowSets</h3><p>Tablet 的下层结构是 RowSets。分为 DiskRowSets 和 MemRowSets。RowSets 的 range 可能重复，但如果一个 row 存在，那么一定只在一个 RowSets 中。<br>一个 Tablet 只有一个 MemRowSet。这一部分包括 flush 无需赘述。</p><h4 id="MemRowSets"><a href="#MemRowSets" class="headerlink" title="MemRowSets"></a>MemRowSets</h4><p>MemRowSets 是一个类似 Mass tree 的 B 树。但有一些优化：</p><ol><li>不支持从树上删除元素。Kudu 也是通过 MVCC 来逻辑删除。</li><li>同样也不支持任意地 inplace 地修改树上的 record<br> 作为代替，允许不改变值大小的修改，这样方便进行 CAS 操作。<br> 允许 CAS 的目的是方便构建下面提到的链表。</li><li>We link together leaf nodes with a next pointer, as in the B+-tree. This improves our sequential scan performance, a critical operation.<br> 链表一般被用来链接 B+ 树的叶子节点，从而提高扫表效率。</li><li>并不完全实现 trie of trees，而是只使用一棵树。因为并不需要考虑极端的随机访问。</li></ol><p>为了提高扫描性能，使用更大的 internal 和 leaf 节点大小，到 256 bytes 大小。</p><p>MemRowSets 是行存，因为内存结构，所以性能也是可以接受的。为了在行存下依然能够提高 throughput，Kudu 使用 SSE2 memory prefetch 指令，去 prefetch one leaf node ahead of our scanner。他还会 JIT-compile record projection operations。这些做法对性能提升很高。</p><p>最终插入到 B-tree 里面的 key 会根据每行的 PK，使用 order-preserving encoding 编码，从而只需要 memcmp 就可以实现比较。因此，在树上遍历会更加快。因为 MemRowSet 本来也是 sorted 的，所以也能提供有效率的扫描。</p><h4 id="DiskRowSet"><a href="#DiskRowSet" class="headerlink" title="DiskRowSet"></a>DiskRowSet</h4><p>DiskRowSet 被分成若干个 32MB 大小的文件，目的是确保它不会太大，从而支持后面要将的 Incremental compaction。</p><p>一个 DiskRowSet 被分成两部分，base data 和 delta store：</p><h5 id="base-data"><a href="#base-data" class="headerlink" title="base data"></a>base data</h5><p>base data 是列存。<br>每个 Column 被单独存储。它们按照连续的 block 的方式被写入磁盘。一个 Column 本身被分成很多个小 page 来存储，从而保障随机读。有一个 B 树索引用来根据 row 的 offset 来查找它所在的 page。<br>Column page 的编码支持字典，bitshuffle 等格式。可以指定进一步的压缩方法。</p><p>除了 flush 指定的那些 Column 之外，还会写一个 PK 索引列，用来存储每个 PK 的编码后的 PK（应该就是前面说的 order-preserving encoding）。<br>还会存储 Bloom filter。</p><h5 id="delta-store"><a href="#delta-store" class="headerlink" title="delta store"></a>delta store</h5><p>因为列存在 encode 之后就难以 inplace 更新了，所以更新和删除通过 delta store 来记录。</p><p>delta store 可以是 DeltaMemStores 或者 DeltaFile：</p><ol><li>DeltaMemStore 是一个和上面一样的 B 树。</li><li>DeltaFile 是一个二进制编码的 column block。</li></ol><p>delta store维护了 (row offset, timestamp) tuple 到 RowChangeList 的映射。其中 row offset 就是一个 row 在 row set 中的 index。timestamp 就是 MVCC 时间戳。RowChangeList 表示对一个 row 的变更，是一个二进制编码的 list。<br>在处理 update 时，首先查找 PK 列，然后可以通过它的 B 树索引来获得对应行所处的 page。然后通过查找这个 page 可以获得对应的 row 在整个 DiskRowSet 中的 offset。然后就可以根据这个索引插入一条更新的数据了。</p><p>因为 Delta Store 是以 row-offset 作为主键，所以相比于 Primary key 这个过程会更快。这就是为什么插入时要费那么多功夫去获取 row-offset，可以理解为 Kudu 在 Insert/Read 的性能平衡中更倾向于优化 Read 性能。</p><h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><h3 id="Delta-Compaction"><a href="#Delta-Compaction" class="headerlink" title="Delta Compaction"></a>Delta Compaction</h3><p>因为 delta 并不是列存，所以当有很多 delta 被 apply 到 base data 的时候，scan tablet 的速度就会变慢。因此 Kudu 的 background maintenance manager 会定期扫描，寻找有大量 delta 的 DiskRowSets，然后调度一个 delta compaction operation，将这些 delta 数据 merge 到 base data 列中。</p><p>In particular, the delta compaction operation identifies the common case where the majority of deltas only apply to a subset of columns: for example, it is common for a SQL batch operation to update just one column out of a wide table. In this case, the delta compaction will only rewrite that single column, avoiding IO on the other unmodified columns.</p><h3 id="RowSet-Compaction"><a href="#RowSet-Compaction" class="headerlink" title="RowSet Compaction"></a>RowSet Compaction</h3><p>Kudu 也会定期将不同的 DiskRowSets 压缩到一起，这称为 RowSet compaction。这个过程会执行一个 keybased merge of two or more DiskRowSets，产生一个有序的 row 的流。然后就不听 next 这个流，从而写回到 DiskRowSet 里面。这里写回的 DiskRowSet 同样是 32MB 的大小。</p><p>RowSet compaction has two goals:</p><ol><li>We take this opportunity to remove deleted rows.</li><li>This process reduces the number of DiskRowSets that overlap in key range. By reducing the amount by which RowSets overlap, we reduce the number of RowSets which are expected to contain a randomly selected key in the tablet. This value acts as an upper bound for the number of Bloom filter lookups, and thus disk seeks, expected to service a write operation within the table.</li></ol><h3 id="Scheduling-maintainance"><a href="#Scheduling-maintainance" class="headerlink" title="Scheduling maintainance"></a>Scheduling maintainance</h3><ol><li>如果 insert 负担变重，则调度偏向于处理“flush”，也就是将 MemRowSets 写成 DiskRowSets。</li><li>如果 insert 负担减轻，则偏向于处理 rowset compaction 或者 delta compaction。</li><li>Because the maintenance threads are always running small units of work, the operations can react quickly to changes in workload behavior. For example, when insertion workload increases, the scheduler quickly reacts and flushes in-memory stores to disk. When the insertion workload reduces, the server performs compactions in the background to increase performance for future writes. This provides smooth transitions in performance, making it easier for developers and operators to perform capacity planning and estimate the latency profile of their workloads.</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/137243163" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/137243163</a></li></ol><h1 id="Masstree"><a href="#Masstree" class="headerlink" title="Masstree"></a>Masstree</h1><h2 id="Intros"><a href="#Intros" class="headerlink" title="Intros"></a>Intros</h2><p>这里首先强调了，尽管可以 scale out，但是单机的性能依然很重要。然后 This paper presents Masstree, a storage system specialized for key-value data in which all data fits in memory, but must persist across server restarts. Within these constraints, Masstree aims to provide a flexible storage model.<br>它的 key 的长度是任意的，支持 range 查询。很多 key 可以共享前缀，从而提高性能。对于比较大的 value 也有优化。它使用了一些 OLFIT 和 rcu 的办法来处理并发：</p><ol><li>查询不使用锁或者 interlock 指令，所以它不会 invalidate shared cache line，并且和大多数 insert 和 update 是平行的。</li><li>update 只会锁相关的 tree node，树的其他部分不受影响。</li></ol><p>Masstree 中所有的 core 都使用一棵树，从而避免 load imbalances that can occur in partitioned designs。相比于其他的将一棵树分开存储的设计，能够彻底解决 imbalance 的问题。<br>这棵树是 a trie-like concatenation of B+-trees。对 long common key prefixes 特别友好，遥遥领先。查询耗时主要由 total DRAM fetch time of successive nodes during tree descent 来决定。因此，Masstree 使用一个较大的 fanout 从而减少树的深度。同时 fetch 多个 nodes，从而 overlap fetch latencies。另外还会精心设计 cache line 以减少每个 node 需要的 data。</p><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p>几点挑战：</p><ol><li>Masstree must efficiently support many key distributions, including variable-length binary keys where many keys might have long common prefixes.</li><li>for high performance and scalability, Masstree must allow fine-grained concurrent access, and its get operations must never dirty shared cache lines by writing shared data structures. </li><li>Masstree’s layout must support prefetching and collocate important information on small numbers of cache lines.<br>其中 2 和 3 就是 Masstree 的 cache craftiness，即缓存友好性。</li></ol><p>Masstree 是一个 trie 树，trie 树的每个节点是一个 B+ 树。trie 树的 fanout 是 2^64，也就是 8 个 bytes。通过 trie 的目的是利用 long key 的 shared prefix。通过 B+ 树 是支持 short key，以及 fine-grained concurrency。B+ 树的 fanout 是中等的，所以能有效利用内存。</p><p><img src="/img/dbpaper/masstree/1.png"></p><p>每个 B+ 树都会有至少一个 border node 也就是图中的矩形节点，以及 0 个或多个 interior node 也就是图中的圆形节点。border node 中按照传统的 B+ 树的方式组织 leaf nodes 也就是图中的五角星节点。可以看到 B+ 树的 border node 用来连接到下一层的 trie node，也就是一棵新的 B+ 树上。<br>Masstree 用一种比较 lazy 的方式去生成更深的层：</p><ol><li>Keys shorter than 8h+8 bytes are stored at layer ≤ h.</li><li>Any keys stored in the same layer h tree have the same 8h-byte prefix.</li><li>When two keys share a prefix, they are stored at least as deep as the shared prefix.</li></ol><p>Masstree creates layers as needed (as is usual for tries). Key insertion prefers to use existing trees; new trees are created only when insertion would otherwise violate an invariant. 比如 “01234567AB” 会被存在 root layer 中，直到插入一个 “01234567XY” 之后会产生一个新的 layer。新的 layer 中会有一个 B+ 树，其中存放 AB 和 XY。</p><p>复杂度分析</p><ol><li>查询复杂度和 B 树相同。对于 B 树，需要检查 O(log n) 个 nodes，进行 O(log n) 次比较。假设 key 的长度是 O(l)，所以总的比较开销是 O(l logn)。Masstree 要在 O(l) 层中比较，每层比较的开销是 O(log n)，所以总的代价也是 O(l logn)。但如果有公共前缀那么 Masstree 的代价就是 O(l + log n) 了。</li><li>Masstree’s range queries have higher worst-case complexity than in a B+-tree, since they must traverse multiple layers of tree.</li></ol><h2 id="Layout"><a href="#Layout" class="headerlink" title="Layout"></a>Layout</h2><p>Figure 2 展示了节点的定义。这里面大量的 15 说明这里使用了 fanout 为 15 的 B+ 树。<code>node *child[16]</code> 中的 node 既可以是 border node，也可以是 interior node。<br>所有的 Border node 被链接，从而能够实现快速 remove 和 getrange 操作。keyslice 用 64 位 integer 数组表示字符串，相当于是 <code>64 * ceil(n / 8)</code> 代替 <code>8*n</code>，这能提高 13-19% 的效率。后面讲如何处理 ‘\0’。然后，A single tree can store at most 10 keys with the same slice, namely keys with lengths 0 through 8 plus either one key with length &gt; 8 or a link to a deeper trie layer. 这个也好理解，因为如果有第二个 key 的话，比如上面的 01234567XY，就必须分裂了。我们保证所有 slice 相同的 key 会存在同一个 border node 中。这个设计简化了 interior node，它不必包含 key 的长度。也简化了并发操作的复杂度，带来的一点代价就是在节点分裂时需要做一些检查。</p><p>下面讲如何维护 border node 上的 suffix，这些 suffix 最多有 15 个。这里的做法是自适应地 inline 存，或者放在单独的内存块上面。目的是节省内存。总而言之这一块讲得是比较模糊的。</p><p>Masstree prefetches all of a tree node’s cache lines in parallel before using the node, so the entire node can be used after a single DRAM latency. Up to a point, this allows larger tree nodes to be fetched in the same amount of time as smaller ones; larger nodes have wider fanout and thus reduce tree height.</p><h3 id="Nonconcurrent-modification"><a href="#Nonconcurrent-modification" class="headerlink" title="Nonconcurrent modification"></a>Nonconcurrent modification</h3><h3 id="Concurrency-overview"><a href="#Concurrency-overview" class="headerlink" title="Concurrency overview"></a>Concurrency overview</h3><p>主要包含细粒度的锁，以及 optimistic concurrency control。<br>细粒度的锁指的是 update 操作只需要 local lock。OCC 指的是读操作并不需要锁，也不会写全局的共享内存。这里应该指的是引用计数之类的东西，会导致 reader 竞争 read lock。<br>因为 reader 并不会 block 并发的 write 操作。所以可能会读到中间数据。因此，writer 在写之前会将一个 dirty 位标记。在写完之后，再自增 version。Reader 会在读取这节点前记录 version，并在读取后再次比较 version 和 dirty 位。<br>这里，根据更新的种类是 insert 还是 split，会更新 version 中的不同区域。version 的 layout 如下所示。</p><p><img src="/img/dbpaper/masstree/3.png"></p><p>The biggest challenge in preserving correctness is concurrent splits and removes, which can shift responsibility for a key away from a subtree even as a reader traverses that subtree.</p><h2 id="Writer–writer-coordination"><a href="#Writer–writer-coordination" class="headerlink" title="Writer–writer coordination"></a>Writer–writer coordination</h2><p>通过自旋锁来维护，这个锁在 version 里面的 locked 位上。<br>但是节点上的一些字段是被其他节点的锁来保护的，比如：</p><ol><li>parent 指针收到父节点的锁保护</li><li>border node 的 prev指针受到左边 sibling 的保护<br>这能减少 split 操作的时候需要 acquire 的锁的数量。比如当某个中间节点 split 的时候它不需要子节点的锁，就可以替他们修改 parent 指针了。<br>但尽管如此，当节点 n 分裂的时候，还是需要：</li><li>n 自己的锁<br> a.目的是避免被并发修改。</li><li>n 的新的 sibling 的锁<br> a. 从后面来看，这里指的就是获取新分裂出来的 n’ 的锁。n’ 的 prev 是 n。<br> b. 要不要获取分裂前的 prev 的锁，防止 prev 同时分裂？</li><li>n 的 parent 的锁<br> a. 防止父节点被其他线程分裂，从而让新分出来的节点 attach 错了 parent。<br> b. 从后文来看，更重要的原因是便于因为 parent 可能也满了，所以需要同时分裂 parent。</li></ol><h3 id="Writer–reader-coordination"><a href="#Writer–reader-coordination" class="headerlink" title="Writer–reader coordination"></a>Writer–reader coordination</h3><p>基本上就是对之前的 OCC 的一些展开的论述。<br>这里说了，universal 的 before-and-after version 检查能够让 reader 发现任何并发的 split，但也会影响性能。有一些性能优化措施，比如让某些操作比如 update，实际上可以避免更新 version。</p><h4 id="Update"><a href="#Update" class="headerlink" title="Update"></a>Update</h4><p>主要将通过对齐 version 的 alignment，让对它的写是原子的。<br>所以 update 操作不需要更新 version。</p><p>Update 操作时，writer 不能直接把旧的值删除掉，因为此时可能还有 reader 在读。这个是通过 RCU 来解决的。其实这里类似的方法还有 hazard pointer 等。</p><h4 id="Border-inserts"><a href="#Border-inserts" class="headerlink" title="Border inserts"></a>Border inserts</h4><p>阅读本章前，可以回顾下 Figure2 的 <code>keyslice</code> 实现。<br>Border nodes 结构中的 permulation 字段是一个 <code>uint64_t</code>，其最低的 4 个 bit 组成 <code>uint4_t</code> 用来表示 key 的数量。因为 B+ 树的 fanout 是 15，所以正好。高 60 个 bit 组成了 <code>uint4_t[15]</code>，用来索引每一个 key 的实际位置。<br>在插入时，会加载 permutation，并且重新组织 permutation 字段，匀出一个没有使用的 slot，存储正确的插入位置。<br>这个操作大部分时候需要一个 compiler fence，在一些机器上需要在写 kv 和写 permutation 中间加一个 memory fence。</p><h4 id="New-layers"><a href="#New-layers" class="headerlink" title="New layers"></a>New layers</h4><p>在阅读本章前，可以先看下 Figure2 的 <code>link_or_value</code> 的实现。<br>插入 k1 到某个 border node，如果发现其中还有个冲突的 k2（这里冲突的含义看前面），那么就创建一个新的 border node 即 <code>n&#39;</code>。将 k2 插入 <code>n&#39;</code> 上的合适的 keyrange 上，并且将 k2 在 n 中的 value 替换成一个 pointer，这个 pointer 指向 next_layer 这一棵新的 B+ 树。然后，它可以解锁 n，并且继续插入 k1。此时 k1 会插入到新层的 <code>n&#39;</code> 上。</p><p>这里的过程只涉及到一个 key，也就是 k1，所以并不需要更新 n 的 version 或者 permutation。我们回顾上文，会比较明白为什么之前这么设计了。</p><p>这个场景下需要注意的点是，reader 需要区分 value 和 pointer。因为 pointer 和 layermarker 是分别存放的。首先 writer 要把 key 标记为 UNSTABLE 状态，然后 reader 检查到这个标记的时候就会 retry。然后 writer 会写入 layer pointer 指针，最后把 key 标记为 LAYER。<br>这里的 UNSTABLE 或者 LAYER 啥的，根据上文，是由 keylen 这个字段来区分的。</p><h4 id="Splits"><a href="#Splits" class="headerlink" title="Splits"></a>Splits</h4><p>Split 相比非 Split 操作，需要将一些 key 移动到另一个 node 中。所以 get 操作很容易就会丢掉这些被转移了的 key。所以，writer 需要去更新 version 里面的 split 字段。</p><p>Split 操作用了 hand-over-hand locking。这个实际上就是同时持有 cur 和 next 的 lock。在 Masstree 里面就是较低层的节点被 lock，并且被 mark 为 splitting。然后依次再更高层上在做同样的工作。这里认为 root 是最高的层。<br>不妨考虑下面的场景，B 需要分裂出一个 B’ 新节点。其中虚线箭头表示要被迁移到 B’ 上的 pointer。</p><p><img src="/img/dbpaper/masstree/split.png"></p><p>行为如下：</p><ol><li>B 和 B’ 都被标注为 splitting</li><li>包含 X 在内的孩子们被转移到 B’ 上</li><li>锁 A，并且标记为 inserting</li><li>将 B’ 插入到 A</li><li>将 A、B 和 B’ 都解锁，这里指掉那些 flag 状态。增加 A 的 vinsert，以及 B 和 B’ 的 vsplit</li></ol><p>下面需要假设一个并发的 findborder(X) 操作，它尝试从 node A 开始寻找某个 key 所在的 border 节点。下面要证明这个操作要么会找到 X，要么就会重试。<br>首先，假设找到了 B’，那么它就可以找到已经被移动到 B’ 的 X，但这个时候 B’ 还没有被链接到 A 上，也就是说 B’ 还没有被 publish。<br>反过来，假设找到了 B。并且因为在 handle-over-hand validation 中，先加载 child 的 version，再double check parent 的 verison，所以我们在将 A 设置为 inserting 之前就已经记录下 B 的 version 了。我们还可以推断 B 的 version 是在 step1 之前被记录的，这是因为如果发现 B 在 splitting 状态，那么就会重试。这样的话就有两个可能：<br>1.如果在 step1 前，findborder 就完成了，那么就肯定能读到 X。<br>2.否则，B.version ⊕ v 这个操作就会失败，因为看到了 B的 splitting 状态。这个 splitting 状态需要到 step5 才会被清理，但这个时候 vsplit 又会变了。这里还需要注意，vsplit 和 splitting 都是在 verison 上的，所以这个更新无疑是原子的。</p><p><img src="/img/dbpaper/masstree/6.png"></p><p>reader 处理 split 和 insert 的方式是不同的。insert 会在当前节点 retry，而 split 需要从 root 开始retry。<br>这里，因为 B 树的 fanout 是比较大的，并且这一块代码没什么锁，跑起来应该挺快，这也意味着并发的 split 实际上并不常见。在测试中，每 10^6 个请求中才有一个因为并发 split 从而需要从 root 开始 retry。相比之下，并发 insert 就会频繁很多，而它们也很容易在本地被处理，这也是为什么 masstree 将两个分开存储的原因。</p><h4 id="get"><a href="#get" class="headerlink" title="get"></a>get</h4><p><img src="/img/dbpaper/masstree/7.png"></p><p>Border node 因为彼此之间有 link，所以可以借助于 link 来处理 split。这里的规则是总是把右边部分分出去创建新 node。<br>Masstree 还有下面的规定：<br>1.B+ 树中的第一个 node 是 border node。他不会删除，除非整棵树都被删掉了。它始终是整棵树中最小的节点。<br>2.每个 border node 管理区间 [lowkey(n), highkey(n))。Split 或者 delete 操作可能修改右区间，但是不会修改左区间。<br>所以，get操作可以始终通过和下一个 border node 的 lowkey 比较来找到自己要找的 node。</p><h4 id="Remove"><a href="#Remove" class="headerlink" title="Remove"></a>Remove</h4><p>首先回忆之前的 border insert，在里面并没有更新 vinsert。在这里的场景中我们会介绍和 remove 操作组合起来的时候，因为 remove 也不修改 version 所以可能出现错误。我理解这有点像像是 ABA 问题。<br>考虑下面的场景，get 操作和 remove 操作重叠了，所以 remove 操作不能 gc 掉 k1 和 v1，不然就影响了 reader。这里应该是对应了前面的 RCU？<br>相应的，remove 操作是修改 permutation。但如果后续有一个 put操作，刚好把 key 也放到了 i 上。这就会导致 get 返回 v2 了。所以当已经删除了的 slot 被重用的时候，也要更新 vinsert。</p><p><img src="/img/dbpaper/masstree/remove.png"></p><h1 id="Ceph"><a href="#Ceph" class="headerlink" title="Ceph"></a>Ceph</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>目前有一些依赖对象存储的设计，其中对象存储设备，即 object storage device 也被称作 OSD，元数据服务器即 metadata server，也被称作 MDS。现在并不是读 block 了，而是读更大的 named objects，并且这些 object 的大小也未必要相同。底层的 block 分配由设备处理。Clients typically interact with a metadata server (MDS) to perform metadata operations (open, rename), while communicating directly with OSDs to perform file I/O (reads and writes), significantly improving overall scalability.<br>这样的架构依然不能解决 MDS 本身的扩展性，元数据没有做 partition。在设计上依旧依赖 allocation lists 和 inode tables，并且不愿意下推一些决策给 OSD。<br>Ceph 的设计基于的假设是 PB 级的存储实际上是动态的：</p><ol><li>大的系统是基于增量构建出来的</li><li>节点 failure 是通常情况</li><li>workload 的强度和特征总是在变化</li></ol><p>Ceph 将 file allocation tables 替换称为 generating function，从而解耦数据和元数据，这个函数也就是后面的 <strong>CRUSH 函数</strong>。这样 Ceph 就能同时考虑 OSD 了，具体优化的场景包括：</p><ol><li>data access 的 distribution</li><li>update serialization，这里指的应该是维护各个 update 操作之间的关系</li><li>failure detection</li><li>recovery<br>Ceph 用了一个分布式元数据集群来提高元数据访问的 scalability。</li></ol><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Ceph 对 scalability 的要求包括几个方面：</p><ol><li>整个系统的 capacity 和 throughput</li><li>每个 client 的性能</li><li>每个目录和文件的性能<br> 这里包括大量并发读写同一个文件，或者读写同一个目录。</li></ol><p><img src="/img/dbpaper/ceph/1.png"></p><h3 id="Decoupled-Data-and-Metadata"><a href="#Decoupled-Data-and-Metadata" class="headerlink" title="Decoupled Data and Metadata"></a>Decoupled Data and Metadata</h3><p>元数据相关的工作包括 open、rename 等。<br>对象存储一直以来都是将底层 block 的分配权给各个设备处理的，并且它们也已经将 per-file block list 替换为更短的 object list。但是 Ceph 直接去掉了 allocation list。为了替代，文件中的数据被分成一系列固定命名规则(predictably named)的对象，并且通过一个 CRUSH 函数被映射到具体的设备中。这有个显然的好处，就是组成一个文件的所有对象的名字和位置可以被计算得到，而不需要从某个中心化的地方查询了。</p><h3 id="Dynamic-Distributed-Metadata-Management"><a href="#Dynamic-Distributed-Metadata-Management" class="headerlink" title="Dynamic Distributed Metadata Management"></a>Dynamic Distributed Metadata Management</h3><p>Ceph utilizes a novel metadata cluster architecture based on Dynamic Subtree Partitioning.<br>这个算法可以将维护目录树的任务分发给很多个 MDS 来处理。我理解就是一种 partition 策略帮助减轻单个 MDS 节点的负担。</p><h3 id="Reliable-Autonomic-Distributed-Object-Storage"><a href="#Reliable-Autonomic-Distributed-Object-Storage" class="headerlink" title="Reliable Autonomic Distributed Object Storage"></a>Reliable Autonomic Distributed Object Storage</h3><p>OSD来处理数据迁移、replication、failure detection 和 failure recovery。对于 MSD 来说，它们好像就是一个单节点的存储。</p><h2 id="Client-Operation"><a href="#Client-Operation" class="headerlink" title="Client Operation"></a>Client Operation</h2><h3 id="File-IO-and-capabilities"><a href="#File-IO-and-capabilities" class="headerlink" title="File IO and capabilities"></a>File IO and capabilities</h3><p>当进程需要打开文件时，client 会发送一个请求给 MDS 服务器，后者遍历自己的目录层级，然后将文件名翻译成 inode。如果一切顺利， MDS 会返回诸如 inode 等信息。并且还会包含 striping strategy，这里指的是文件是条带化存储的，一个文件可以对应到若干 object 上。<br>客户端的 capability 分为 read、cache read、write 和 buffer write。后续也会支持管控。<br>Ceph 的 striping strategy 中为了避免 file allocation metadata，object name 只包含 inode number 和 stripe number。然后就借助于 CRUSH 去将它们映射到 OSD 上。比如说，只要一个 client 知道 inode number、layout 和 file size，它就可以定位到文件对应的所有对象。</p><h3 id="Client-Synchronization"><a href="#Client-Synchronization" class="headerlink" title="Client Synchronization"></a>Client Synchronization</h3><p>POSIX semantics sensibly require that reads reflect any data previously written, and that writes are atomic. 这里我理解就是强一致性。<br>如果有读写或者写写冲突，那么 MDS 就会撤回之前发出的 read caching 和 write buffereing 的 capacity，强制同步 IO。也就是说，所有应用的读和写都会被 block，直到被 OSD 确认。这样 update serialization 和 synchronization 的负担被转移给了 OSD。<br>当写请求跨越 object 的边界的时候，会向所有对象对应的 OSD 请求各自的锁，然后提交 write 并释放锁。Object locks are similarly used to mask latency for large writes by acquiring locks and flushing data asynchronously.</p><p>当然，同步 IO 对特别是小读写请求的影响比较大，因为每次都会请求一次 OSD。在一些情况下，可以选择更松的一致性要求。当然，性能和一致性是一组 tradeoff。<br>Ceph 支持一些 POSIX IO 的 HPC 接口，比如 O_LAZY flag，也就是放松了 coherency 要求。但是，HPC 程序自己会去控制一致性。这是因为一些应用可能只是让不同的线程写同一个文件的不同部分，这样就和一致性不冲突。<br>还有两个高级功能，lazyio_propagate 能够 flush 一个 range 到 object store 上。lazyio_ synchronize will ensure that the effects of previous propagations are reflected in any subsequent reads.</p><h3 id="Namespace-Operations"><a href="#Namespace-Operations" class="headerlink" title="Namespace Operations"></a>Namespace Operations</h3><p>Namespace Operations 诸如 readdir、unlink、chmod 之类的由 MDS 处理。<br>For simplicity, no metadata locks or leases are issued to clients. For HPC workloads in particular, callbacks offer minimal upside at a high potential cost in complexity.</p><p>Ceph 会对一些最常见的 metadata 访问场景进行优化，比如 readir 后面接一系列 stat 这个场景是 performance killer，Ceph 会选择在 readdir 的时候就直接取回来缓存。因为中间某个文件的属性可能变更了，访问缓存可能会牺牲一点 coherence，但性能提升很大。<br>对此的另一个优化手段是在 stat 被触发时，MDS 撤回所有的 write capacity，让所有的写暂停。然后获取所有的 writer 上的最新文件大小和 mtime，选择其中的最大的值返回。<br>当然，如果只有一个 writer，那么就可以直接从 writing client 取到正确的值，从而就不需要上面的过程了。<br>Applications for which coherent behavior is unnecesssary-victims of a POSIX interface that doesn’t align with their needs-can use <code>statlite</code>, which takes a bit mask specifying which inode fields are not required to be coherent. 这里不太看得懂。</p><h2 id="Dynamically-Distributed-Metadata"><a href="#Dynamically-Distributed-Metadata" class="headerlink" title="Dynamically Distributed Metadata"></a>Dynamically Distributed Metadata</h2><p>Metadata operation 通常占据了近乎一半的文件系统开销，并且处在 critical path 上。Metadata management also presents a critical scaling challenge in distributed file systems: although capacity and aggregate I/O rates can scale almost arbitrarily with the addition of more storage devices, metadata operations involve a greater degree of interdependence that makes scalable consistency and coherence management more difficult.</p><p>Ceph 的上的 metadata 很小，基本只包含 file name 和 inode。对象名通过 inode 构建出来，并且通过 CRUSH 来分布到不同的 OSD 上。这简化了 metadata workload，并且让 Ceph 管理能力和文件的大小无关。<br>此外，Ceph 还要减少和 metadata 相关的 IO 次数。它使用了一个 two-tiered storage strategy，并且通过 Dynamic Subtree Partitioning 最大化 locality，并且提高 cache efficiency。</p><h3 id="Metatada-storage"><a href="#Metatada-storage" class="headerlink" title="Metatada storage"></a>Metatada storage</h3><p>MDS 使用 journal 来持久化。每个 journal 有几百兆，可以 absorb repetitive metadata updates。journer 被 lazy 和流式地地写入 OSD 集群。<br>这个设计有几点好处，但说得有点模糊。<br>This strategy provides the best of both worlds: streaming updates to disk in an efficient (sequential) fashion, and a vastly reduced re-write workload, allowing the long-term on-disk storage layout to be optimized for future read access. In particular, inodes are embedded directly within directories, allowing the MDS to prefetch entire directories with a single OSD read request and exploit the high degree of directory locality present in most workloads [22]. Each directory’s content is written to the OSD cluster using the same striping and distribution strategy as metadata journals and file data. Inode numbers are allocated in ranges to metadata servers and considered immutable in our prototype, although in the future they could be trivially reclaimed on file deletion. An auxiliary anchor table [28] keeps the rare inode with multiple hard links globally addressable by inode number-all without encumbering the overwhelmingly common case of singly-linked files with an enormous, sparsely populated and cumbersome inode table.</p><h3 id="Dynamic-Subtree-Partitioning"><a href="#Dynamic-Subtree-Partitioning" class="headerlink" title="Dynamic Subtree Partitioning"></a>Dynamic Subtree Partitioning</h3><p>SOTA 的方案包括静态子树切割，或者动态地基于 hash 来做。哈希的方案会破坏元数据的 locality，也会破坏 prefetch 的可能性。<br>Ceph 的 Dynamic Subtree Partitioning 首先是引入了 hierachy。然后通过 counters with an exponential time decay 维护元数据的 popularity。这个 popularity 会向上往树根处传播，从而 MDS 可以得到一棵反映负载分布的权重树。MDS 可以通过迁移子树的方式来实现负载均衡。这个负载均衡可以只在内存中进行，从而减少对 coherence lock 或者 client capability 的影响。The resulting subtree-based partition is kept coarse to minimize prefix replication overhead and to preserve locality. 不太明白这里说的 prefix replication 是什么。</p><p>在 replication 的时候，inode 的内容被分为三块：security、file 和 immutable。security、file 两个组会被使用单独的 FSM 管理。其目的是减少 lock contention。这里也不太明白说的是什么。</p><h3 id="Traffic-control"><a href="#Traffic-control" class="headerlink" title="Traffic control"></a>Traffic control</h3><p>尽管做了 partition，但是还是会存在 hotspot 或者 flash crowds(瞬时拥堵)的问题，比如很多个客户端同时访问同一个文件或者目录。Ceph 会根据 popularity 来决定是否将 hotspot 进行分散，同时也会想办法避免损失 locality：<br>1.读取压力比较大的目录会设有多个 replica 来分散负载。如果一个目录不 popular，那么他就不会被创建其他的 replica。<br>2.写入压力比较大的目录中的文件会被 hash 到不同的节点上。这会牺牲目录的 locality，但负载是均衡的。写入会直接被 direct 到 authority 节点上。</p><h2 id="Distributed-Object-Storage"><a href="#Distributed-Object-Storage" class="headerlink" title="Distributed Object Storage"></a>Distributed Object Storage</h2><p>让 OSD 处理注入 replicate 之类的工作，让 Ceph 的 RADOS 取得在容量和聚合能力上的线性伸缩。</p><h3 id="CRUSH"><a href="#CRUSH" class="headerlink" title="CRUSH"></a>CRUSH</h3><p>首先Ceph 会把对象映射到不同的 PG 里面。这是通过一个简单的哈希函数实现的。<br>然后通过 CRUSH 也就是 Controlled Replication Under Scalable Hashing 函数将 PG 映射到 OSD。</p><p><img src="/img/dbpaper/ceph/3.png"></p><p>那么定位一个对象就只需要知道 PG 和一个 OSD cluster map。因为这个 map 不会很频繁变化，或者变化也是只其中一小部分，比如上下线节点，所以会元数据也不会被动来动去。<br>OSD cluster map 是分层的描述，比如可以分为 shelf、rack cabinet、row of cabinet。<br>CRUSH 会根据 placement rule 将 PG 映射到 OSD。<br>OSD cluster map 还包含 down 或者 inactive 机器的列表，以及一个 version 号。所有对 OSD 的请求都会带上 version 号。</p><h3 id="Replication-1"><a href="#Replication-1" class="headerlink" title="Replication"></a>Replication</h3><p>Replication 的粒度是 PG。<br>Primary 会确保所有的 replica 都被写完之后，再回复 client。</p><h3 id="Data-safety"><a href="#Data-safety" class="headerlink" title="Data safety"></a>Data safety</h3><p>RADOS 解耦了 sync 和 safety。他的意思是共享存储有两个作用，第一个是同步，也就是让一个更新尽快对其他 client 可见。第二个是可靠性，也就是持久化。<br>所以，当所有的 OSD 写完 in-memory buffer cache 之后，primary OSD 就会给 client 回复一个 ack，表示 sync 结束了。<br>之后，当数据被落盘之后，primary OSD 还会再回复一个 commit 给客户端，表示数据 safe 了。</p><h3 id="故障检测"><a href="#故障检测" class="headerlink" title="故障检测"></a>故障检测</h3><p>主要是分为两个阶段。短暂的无响应会被标记为 down，此时会移交 primary。长期的无响应会被标记为 out，会派其他的 OSD 来接管。这么做的目的也是为了减少数据的搬运。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在比较早的时候，我使用腾讯文档记录一些数据库的论文。但我越来越无法忍受腾讯文档的 bug 等不便利。因此我打算将这些文章转移到博客中，即使它们中的部分的完成度并不是很高。&lt;/p&gt;
&lt;p&gt;这篇文章中，包含 CStore、Kudu、Masstree 和 Ceph。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>通用架构设计归纳</title>
    <link href="http://www.calvinneo.com/2024/02/24/common-arch-design/"/>
    <id>http://www.calvinneo.com/2024/02/24/common-arch-design/</id>
    <published>2024-02-24T04:34:22.000Z</published>
    <updated>2024-02-24T16:18:28.682Z</updated>
    
    <content type="html"><![CDATA[<p>介绍软件工程领域一些通用的设计方案。</p><a id="more"></a><h1 id="Lease"><a href="#Lease" class="headerlink" title="Lease"></a>Lease</h1><p>通过 Lease 可以解决或者缓解下面的一些问题：</p><ol><li>减少 invalidation 检查的开销</li><li>减少惊群带来的大量无效计算</li></ol><h1 id="Backoff"><a href="#Backoff" class="headerlink" title="Backoff"></a>Backoff</h1><h1 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h1><h1 id="Partial-Ordering"><a href="#Partial-Ordering" class="headerlink" title="Partial Ordering"></a>Partial Ordering</h1><p>通常面临这样的场景，很多个命令构成了全序关系，但其实它们可以被拆成多组彼此 concurrent 的偏序关系：</p><ol><li>在 NewSQL 的事务层+共识层的架构中，将 (start_ts, commit_ts) 的事务拆到多个共识组中，多个共识组之间可以并发 apply。对于共识组中不相交的事务，可以通过并行 apply 继续提高并发度。</li><li>CPU 中的 superscalar 技术</li></ol><h1 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h1><p>我们往往在异步线程中预处理一些对象，并最后将它们 link 到主干上，或者从主干上 unlink 对象，并最后 gc 掉。如果这中间发生重启，那么这些对象就会游离在存储中。如何区分被 unlink 但尚未被回收的对象，和刚被创建但还没有被 link 的对象呢？这里的通用思路是在重启后对比主干和存储中的对象，所有不出现在主干中的对象就需要被删掉。然后依赖重放来解决第一种情况。</p><h1 id="Trade-off"><a href="#Trade-off" class="headerlink" title="Trade off"></a>Trade off</h1><h2 id="读和写"><a href="#读和写" class="headerlink" title="读和写"></a>读和写</h2><h2 id="锁和非锁"><a href="#锁和非锁" class="headerlink" title="锁和非锁"></a>锁和非锁</h2><p>锁意味着串行逻辑，通常用来避免写写冲突。<br>非锁的方案往往涉及多个版本：</p><ol><li>CAS 的方案本质上是异步完成新版本的构建，再原子替换上去。它并不是避免冲突，而是在冲突时退出。</li><li>MVCC 的方案本质上是让读不会阻塞写，解决读写冲突。</li></ol><p>类似的思想出现很多：</p><ol><li>TiDB 中使用乐观锁或者悲观锁处理写写冲突，通过 MVCC 处理读写冲突。</li><li>Masstree 中使用锁解决写写冲突，引入版本号解决读写冲突。</li><li>Snapshot Isolation 中，读不会被写影响。</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍软件工程领域一些通用的设计方案。&lt;/p&gt;</summary>
    
    
    
    
    <category term="分布式" scheme="http://www.calvinneo.com/tags/分布式/"/>
    
  </entry>
  
  <entry>
    <title>ZFC 公理系统</title>
    <link href="http://www.calvinneo.com/2024/02/10/on_zfc/"/>
    <id>http://www.calvinneo.com/2024/02/10/on_zfc/</id>
    <published>2024-02-10T11:20:33.000Z</published>
    <updated>2024-02-24T14:55:39.455Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 ZF 和 ZFC 集合论的由来。</p><a id="more"></a><h1 id="罗素悖论"><a href="#罗素悖论" class="headerlink" title="罗素悖论"></a>罗素悖论</h1><p>在朴素集合论中，将“集合的元素”也视为集合。</p><p>可以得到概括公理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exists s: forall x, (x in s &lt;-&gt; P(x))</span><br></pre></td></tr></table></figure><p>概括公理说，对于任意的 Prop P，存在集合 s，它里面是所有满足性质 P(x) 的 x。</p><p>罗素提出一个悖论，考虑 <code>S = {x | x notin x}</code>，<code>S in S</code> 是否成立？<code>S notin S</code> 是否成立？如果 <code>S in S</code> 成立，则根据定义应该有 S notin S，和假设矛盾。如果 <code>S notin S</code> 成立，则能推出 <code>S in S</code>，有矛盾。</p><h2 id="哥德尔不完备定理"><a href="#哥德尔不完备定理" class="headerlink" title="哥德尔不完备定理"></a>哥德尔不完备定理</h2><h3 id="定理1"><a href="#定理1" class="headerlink" title="定理1"></a>定理1</h3><p>任何自洽的形式系统，只要蕴涵皮亚诺算术公理，就可以在其中构造在体系中不能被证明的真命题，因此通过推理演绎不能得到所有真命题。也就是说体系不完备。</p><h3 id="定理2"><a href="#定理2" class="headerlink" title="定理2"></a>定理2</h3><p>任何逻辑自洽的形式系统，只要蕴涵皮亚诺算术公理，它就不能用于证明其本身的自洽性。</p><h1 id="ZF-和-ZFC-集合论"><a href="#ZF-和-ZFC-集合论" class="headerlink" title="ZF 和 ZFC 集合论"></a>ZF 和 ZFC 集合论</h1><h2 id="几个公理"><a href="#几个公理" class="headerlink" title="几个公理"></a>几个公理</h2><h3 id="外延公理"><a href="#外延公理" class="headerlink" title="外延公理"></a>外延公理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">forall x,</span><br><span class="line">    forall y,</span><br><span class="line">        &#123;forall z | z in x &lt;-&gt; z in y&#125; -&gt; x = y</span><br></pre></td></tr></table></figure><h3 id="正规公理"><a href="#正规公理" class="headerlink" title="正规公理"></a>正规公理</h3><p>每个非空集合 x 都包含一个成员 y，使得 x 和 y 不相交。这里 <code>exists a (a in x)</code> 是非空集合的条件，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">forall x,</span><br><span class="line">    exists a (a in x) -&gt; exists y</span><br><span class="line">        y in x /\ not (exists z)</span><br><span class="line">            z in y /\ z in x</span><br></pre></td></tr></table></figure><p>正则公理可以用来防止罗素悖论。</p><p>证明如果 A 是集合，则 <code>A not in A</code>。不妨假定 <code>A in A</code>，则有 <code>A in {A}</code>，所以有 <code>A intersect {A} = {A}</code>。根据正规公理，可以得到 <code>{A}</code> 是空集，这是矛盾的。</p><h3 id="替代公理"><a href="#替代公理" class="headerlink" title="替代公理"></a>替代公理</h3><p>如果给定任何集合 x，有一个唯一的集合 y 使得 P 对 x 和 y 成立，那么给定任何集合 A，有着一个集合 B 使得，给定任何集合 y，y 是 B 的一个成员，当且仅当有是 A 的成员的一个集合 x 使得 P 对于 x 和 y 成立。</p><p>因为在一阶逻辑中无法 quantify 可定义的函数，one instance of the schema is included for each formula f in the language of set theory with free variables among w1, …, wn, A, x, y; but B is not free in f.</p><p><img src="/img/zfc/replacement_complex.png"></p><p>简单的形式如下，可以看出这里的 f 指定了一个从 x 到 y 的对应关系，类似 F 在 A 上的应用。所有由此得到的 y 可以被定义为集合 B，类似于 F(A)。</p><p><img src="/img/zfc/replacement_simple.png"></p><p>这里有个简单记法。唯一性可以写为 <code>!x, P(x)</code>。它被定义为: <code>forall x, forall y, P(x) /\ P(y) -&gt; x = y</code>。</p><h3 id="概括公理模式、分类公理模式、分离公理模式"><a href="#概括公理模式、分类公理模式、分离公理模式" class="headerlink" title="概括公理模式、分类公理模式、分离公理模式"></a>概括公理模式、分类公理模式、分离公理模式</h3><p>这个公理类似于弱化版的概括公理。因为它实际上只允许 <code>{a in s: P(x)}</code> 这样的集合，不允许 <code>{a: P(x)}</code> 这样的集合。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">forall x,</span><br><span class="line">    exists s,</span><br><span class="line">        forall a,</span><br><span class="line">            a in s &lt;-&gt; a in x /\ P</span><br></pre></td></tr></table></figure><p>这个公理可以被用来证明空集的存在。我们可以去找一个所有集合都没有的性质，比如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">forall w, &#123;u in w | (u in u) /\ not (u in u)&#125;</span><br></pre></td></tr></table></figure><h3 id="配对公理"><a href="#配对公理" class="headerlink" title="配对公理"></a>配对公理</h3><p>如果 x 和 y 是集合，则存在一个集合包含 x 和 y。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">forall x, forall y, exists (x in z /\ y in z)</span><br></pre></td></tr></table></figure><h3 id="并集公理"><a href="#并集公理" class="headerlink" title="并集公理"></a>并集公理</h3><p>对任一个集合 F 总存在一个集合 A 包含每个为 F 的某个成员的成员的集合。<br><img src="/img/zfc/union.png"></p><h3 id="无穷公理"><a href="#无穷公理" class="headerlink" title="无穷公理"></a>无穷公理</h3><p>存在一个有无限多成员的集合 X。<br>形式化来说，令 S(x) 为 <code>x union {x}</code>，其中 x 为某个集合。存在一个集合 X 使得空集 ∅ 为 X 的成员，且当一个集合 y 为 X 的成员时，S(y) 也是 X 的成员。</p><p><img src="/img/zfc/infinity.png"></p><h3 id="幂集公理"><a href="#幂集公理" class="headerlink" title="幂集公理"></a>幂集公理</h3><p>对于任意的集合 x，都存在一个集合 y 为 x 的幂集的父集。<br>这里的 <code>forall z [...]</code> 实际上定义了幂集。</p><p><img src="/img/zfc/power_set.png"></p><h2 id="选择公理"><a href="#选择公理" class="headerlink" title="选择公理"></a>选择公理</h2><p>良序定理，等价于选择公理，声称所有集合都可以被良序排序。</p><p>良序定理形式。</p><h1 id="势和序数"><a href="#势和序数" class="headerlink" title="势和序数"></a>势和序数</h1><h2 id="集合的势"><a href="#集合的势" class="headerlink" title="集合的势"></a>集合的势</h2><ol><li>任何势小于自然数集的集合称为有限集合。</li><li>任何势和自然数集一样的集合称为可数无限集合。</li><li>任何势大于自然数集的集合称为不可数集合。</li></ol><h3 id="对角论证法"><a href="#对角论证法" class="headerlink" title="对角论证法"></a>对角论证法</h3><p>假设实数区间 [0,1] 是可数无穷大的，那么就可以将其组成排列 <code>r1, r2, ...</code>。比如如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">r1 = 0 . 5 1 0 5 1 1 0 ...</span><br><span class="line">r2 = 0 . 4 1 3 2 0 4 3 ...</span><br><span class="line">r3 = 0 . 8 2 4 5 0 2 6 ...</span><br><span class="line">r4 = 0 . 2 3 3 0 1 2 6 ...</span><br><span class="line">r5 = 0 . 4 1 0 7 2 4 6 ...</span><br><span class="line">r6 = 0 . 9 9 3 7 8 3 8 ...</span><br><span class="line">r7 = 0 . 0 1 0 5 1 3 5 ...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>现在如果能构造出一个 x，它一定不等于所有的 <code>r[k]</code>，那么就可以通过反证法证明了实数区间 [0,1] 不是可数无穷大的。<br>构造方法就是 x 的第 k 位，让它和 <code>r[k]</code> 的第 k 位不同。这是肯定能做到的。<br>这样的话 x 就会和所有的 <code>r[k]</code> 至少有一位不同。</p><h3 id="连续统假设"><a href="#连续统假设" class="headerlink" title="连续统假设"></a>连续统假设</h3><p>自然数集的势标记为 N0，实数集的势则被标记为 c。可以证明 <code>c = 2^N0 &gt; N0</code>。连续统假设断言不存在介于实数集的势和自然数集的势之间的基数，亦即 c = N1。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://zh.wikipedia.org/zh-hans/%E7%AD%96%E6%A2%85%E6%B4%9B-%E5%BC%97%E5%85%B0%E5%85%8B%E5%B0%94%E9%9B%86%E5%90%88%E8%AE%BA" target="_blank" rel="noopener">https://zh.wikipedia.org/zh-hans/%E7%AD%96%E6%A2%85%E6%B4%9B-%E5%BC%97%E5%85%B0%E5%85%8B%E5%B0%94%E9%9B%86%E5%90%88%E8%AE%BA</a><br> 注意，中文版里面的符号可能不太准确。</li><li><a href="https://zh.wikipedia.org/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86</a></li><li><a href="https://zhuanlan.zhihu.com/p/90761830" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/90761830</a></li><li><a href="https://zh.wikipedia.org/wiki/%E5%8A%BF_(%E6%95%B0%E5%AD%A6)" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E5%8A%BF_(%E6%95%B0%E5%AD%A6)</a></li><li><a href="https://zh.wikipedia.org/wiki/%E5%B0%8D%E8%A7%92%E8%AB%96%E8%AD%89%E6%B3%95" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E5%B0%8D%E8%A7%92%E8%AB%96%E8%AD%89%E6%B3%95</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍 ZF 和 ZFC 集合论的由来。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数学" scheme="http://www.calvinneo.com/tags/数学/"/>
    
  </entry>
  
  <entry>
    <title>Software Foundation 做题的 Notes</title>
    <link href="http://www.calvinneo.com/2024/02/03/note-on-sf-1/"/>
    <id>http://www.calvinneo.com/2024/02/03/note-on-sf-1/</id>
    <published>2024-02-03T11:46:32.000Z</published>
    <updated>2024-03-08T15:07:58.086Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/CalvinNeo/SF-zh" target="_blank" rel="noopener">https://github.com/CalvinNeo/SF-zh</a> 做题笔记。</p><a id="more"></a><h1 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h1><p>intro 和 intros 会按顺序将命题中的 forall 里面的，和 <code>-&gt;</code> 左边的按照顺序移动下来作为假设。</p><p>reflexivity 相当于是化简等号两边，看是否相等。</p><p><code>rewrite -&gt; H</code> 是用 H 改写 goal 右边的部分，可以被简写为 <code>rewrite H</code>。<code>rewrite &lt;- H</code> 则是从右到左改写。</p><p>有个证明 <code>andb b c = true -&gt; c = true</code> 的看起来挺奇怪的，但实际上后面可以用 discriminate 来证明。</p><h1 id="Induction"><a href="#Induction" class="headerlink" title="Induction"></a>Induction</h1><p>Coq 中 induction 的归纳，不是数学归纳，而是根据构造函数归纳。比如皮亚诺自然数就有两个构造函数 S 和 O。</p><h1 id="Lists"><a href="#Lists" class="headerlink" title="Lists"></a>Lists</h1><h1 id="Poly"><a href="#Poly" class="headerlink" title="Poly"></a>Poly</h1><p>一般证明一些结论，用到 induction 的时候，会用某个操作符对某个操作符的分配率。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plus_n_Sm: <span class="keyword">forall</span> n m : nat, S (n + m) = n + S m</span><br><span class="line">plus_Sn_m: <span class="keyword">forall</span> n m : nat, S n + m = S (n + m)</span><br></pre></td></tr></table></figure><p>其目的是用分配率，把“递推”条件里面的部分给拆掉，一部分用 <code>IHl&#39;</code> 直接 apply 过去，剩下来一部分是比较简单处理的。<br>对 list 而言，就是证明各种函数，如 length、rev 和 ++ 之间的关系。</p><h1 id="Tactic"><a href="#Tactic" class="headerlink" title="Tactic"></a>Tactic</h1><p>这里 <code>apply eq2. apply eq1</code> 好像三段论一样，eq2 是大前提，eq1 是小前提。 </p><p><code>apply</code> 类似于反过来推。<code>apply H</code>，如果 <code>H</code> 是 <code>x = y</code>，则可以进行代入的改写，这不是很直观。但如果 <code>H</code> 是 <code>x -&gt; y</code> 这样，就可以将 <code>y</code> 这样的 goal 改写成 <code>x</code>，这就类似于是倒推了。<br>要使用 apply 策略，被应用的事实（的结论）必须精确地匹配证明目标。甚至等号反一下都不行，需要 symmetry 倒过来。<br><code>apply x in H</code> 类似于正过来推。它是把 x 应用到假设 H 而不是 goal 上。具体来说，[apply L in H] 会针对上下文中的假设 [H] 匹配某些形如 [X -&gt; Y] 的条件语句 [L]。[apply L in H] 会针对 [X] 匹配 [H]，如果成功，就将其替换为 [Y]。简而言之，就还是用 L 改写，但是改写 H 了。</p><p>同理，<code>simpl in H</code> 也是简化假设 H 而不是 goal。同理，也有 <code>rewrite ... in H</code> 来改写前提。</p><p><code>apply x with (m:=xxx)</code>，也就是帮助 apply 选择把 <code>m</code> 代成是什么。这里我不太清楚如果有多个 forall 如何逐个指定。但另外有一种方式是 pose proof。</p><p><code>injection</code> 是利用单射的性质。能方便的证明 <code>S n = S m -&gt; n = m</code> 这样的命题。在 evSS_ev_remember 中也能看到有使用处理 <code>S (S n&#39;) = S (S n)</code>。主要目的还是用来去掉包在外面的上下文。<br>通过编写 <code>injection H as Hmn1 Hmn2</code> 这样，我们让 Coq 利用构造子的单射性来产生所有它能从 H 所推出的等式。 每一个这样的等式都作为假设被添加到上下文中。</p><p><code>discriminate</code> 用来处理 <code>False -&gt; P</code> 这样的问题。也就是后面提到的 ex_falso_quodlibet，爆炸原理。</p><p><code>plus_n_n_injective</code> 的证明很 tricky，我有几种方式都不太证得了，不知道为啥。</p><p><code>eqb_true</code> 里面 <code>intros [] eq</code> 和 <code>intros m eq</code> 是有区别的。</p><p><code>intros</code> 有个问题是，它始终是按照顺序引入的。如果我 <code>intros n m</code>，但我只想对 m 归纳，继续 forall n，那就需要 <code>generalize dependent n</code> 这样把 n 再还回去。<br><code>intros</code> 另一个问题是，如果多引入了假设，或者少引入了假设，会导致后面处理会比较奇怪。所以一般直接 <code>intros</code>，看自己要用哪些。</p><p>用 <code>unfold</code> 展开定义。同理也有 <code>unfold... in H</code>。类似的展开方法还有 destruct。如 <code>silly_fact_2</code> 中举的例子一样，可以用 destruct 把用 match 讨论的 bar 函数的各个构造函数 destruct 出来讨论。</p><p>可以使用 <code>destruct (n =? 3) eqn:E1</code> 这样对表达式的结果进行讨论。</p><p>本文中最后总结了已有的一些策略。</p><h2 id="一些-case"><a href="#一些-case" class="headerlink" title="一些 case"></a>一些 case</h2><p>split 可以使用 match 做一个单 arm 的 destruct。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> combine_split : <span class="keyword">forall</span> X Y (l : list (X * Y)) l1 l2,</span><br><span class="line">  <span class="built_in">split</span> l = (l1, l2) -&gt;</span><br><span class="line">  combine l1 l2 = l.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">  <span class="built_in">intros</span> tx ty l.</span><br><span class="line">  <span class="built_in">induction</span> l <span class="built_in">as</span> [| <span class="type">h</span> t IH].</span><br><span class="line">  - <span class="built_in">simpl</span>. <span class="built_in">intros</span> l1 l2 H. <span class="built_in">simpl</span> <span class="built_in">in</span> H. <span class="built_in">inversion</span> H. <span class="built_in">reflexivity</span>.</span><br><span class="line">  - <span class="built_in">intros</span> r1 r2 H.</span><br><span class="line">    <span class="built_in">destruct</span> h.</span><br><span class="line">    <span class="built_in">destruct</span> (<span class="built_in">split</span> t) eqn: E.</span><br></pre></td></tr></table></figure><p>下面就引入了多余的 <code>n&#39;</code></p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> mult_assoc : <span class="keyword">forall</span> n m p : nat,</span><br><span class="line">  n * (m * p) = (n * m) * p.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">  <span class="built_in">intros</span> n.</span><br><span class="line">  <span class="built_in">induction</span> n <span class="built_in">as</span> [| <span class="type">n</span>' IHn] eqn: eq1.</span><br><span class="line">  - <span class="built_in">reflexivity</span>.</span><br><span class="line">  - <span class="built_in">simpl</span>. <span class="built_in">intros</span> m p.</span><br><span class="line">    <span class="built_in">assert</span> (H3: (m + n' * m) * p = m * p + n' * m * p).</span><br><span class="line">    <span class="built_in">apply</span> mult_plus_distr_r.</span><br><span class="line">    <span class="built_in">rewrite</span> H3.</span><br></pre></td></tr></table></figure><h1 id="Logic"><a href="#Logic" class="headerlink" title="Logic"></a>Logic</h1><p>本章开始提到了之前证明了很多 <code>a = b</code>、<code>a -&gt; b</code> 和 <code>forall x, P x</code> 的命题。<br>表达式 n = m 只是 eq n m 的语法糖（它使用 Notation 机制定义在 Coq 标准库中）。由于 eq 可被用于任何类型的元素，因此它也是多态的。</p><p>遇到 <code>\/</code> 作为条件，可以 destruct H as [H1 | H2]，产生两个 subgoal。然后用 bullet 去讨论。也可以直接 intros [H1 | H2] 甚至 intros [H | H]。<br>遇到 <code>\/</code> 作为 goal，可以用 left 或者 right 选择要证明哪一边。<br>遇到 <code>/\</code> 作为条件，可以用 destruct 分离成两个条件。<br>遇到 <code>/\</code> 作为 goal，需要用 split 将它分开成两个 subgoal，用 bullet 组织。</p><p>在 ex_falso_quodlibet 的证明中，会发现有的时候 False 出现在条件中，这个时候只需要 destruct 这个条件就可以了。如 <code>destruct contra</code>。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> goal</span><br><span class="line">P : <span class="keyword">Prop</span></span><br><span class="line">contra : False</span><br><span class="line">______________________________________(<span class="number">1</span>/<span class="number">1</span>)</span><br><span class="line">P</span><br></pre></td></tr></table></figure><p>如果在条件中出现 <code>P -&gt; False</code>，但 goal 是 <code>P</code>，则可以使用 exfalso。我感觉好像他的作用是把 goal 变成 False。</p><p>一个诸如 H : exists x : A, f x = y /\ In x t 这样的条件，可以被 destruct 为 [w [h1 h2]] 这样。此时 w 就是这个 x。可以直接假设 exists w。</p><p>对于后面的排中律系列，在 <code>(P \/ P -&gt; False)</code> 时，建议选择 right，因为 right 会得到一个 P 的假设。</p><p><a href="https://stackoverflow.com/questions/77949233/why-i-cant-use-exact-p-if-p-is-a-prop" target="_blank" rel="noopener">注意</a><br>1.P : Prop means “let P be an arbitrary proposition”. It could be true, it could be false.<br>2.p : P means “let p be a proof of P”. That’s what means that P is true.</p><h2 id="对映"><a href="#对映" class="headerlink" title="对映"></a>对映</h2><p>我们可以通过以下两种方式来断言 n 为偶数：<br>evenb n 求值为 true</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Example</span> even_42_bool : evenb <span class="number">42</span> = true.</span><br></pre></td></tr></table></figure><p>或者存在某个 k 使得 n = double k</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Example</span> even_42_prop : even <span class="number">42.</span></span><br></pre></td></tr></table></figure><p>解释了之前为什么要证明一个很奇怪的什么 eqb_true 的东西。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> eqb_true : <span class="keyword">forall</span> n m,</span><br><span class="line">    n =? m = true -&gt; n = m.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line"><span class="built_in">intro</span> n. <span class="built_in">induction</span> n <span class="built_in">as</span> [| <span class="type">n</span>' IHn'].</span><br><span class="line">  - <span class="built_in">intro</span> m. <span class="built_in">induction</span> m <span class="built_in">as</span> [| <span class="type">m</span>' IHm'].</span><br><span class="line">    + <span class="built_in">reflexivity</span>.</span><br><span class="line">    + <span class="built_in">discriminate</span>.</span><br><span class="line">  - <span class="built_in">intros</span> m eq. <span class="built_in">induction</span> m <span class="built_in">as</span> [| <span class="type">m</span>' IHm'].</span><br><span class="line">    + <span class="built_in">simpl</span>. <span class="built_in">discriminate</span>.</span><br><span class="line">    + <span class="built_in">apply</span> <span class="built_in">f_equal</span>. <span class="built_in">apply</span> IHn'. <span class="built_in">apply</span> eq.</span><br><span class="line"><span class="keyword">Qed</span>.</span><br></pre></td></tr></table></figure><h2 id="一些-case-1"><a href="#一些-case-1" class="headerlink" title="一些 case"></a>一些 case</h2><p>In_map_iff 的思路是考虑 H 的话，如果 y = x 则是另外的情况，否则 y 在 l 里面。就可以 destruct 出来，一部分匹配 IHl。<br>另外，下面的 <code>intros [H | H]</code> 的意思是把 <code>f h = y \/ In y (map f t) -&gt;</code> 引入，但生成两个 subgoal。第一个 goal 是对 <code>f h = y</code> 证明成立，第二个是对 <code>In y (map f t)</code> 成立。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Lemma</span> In_map_iff :</span><br><span class="line">  <span class="keyword">forall</span> (A B : <span class="keyword">Type</span>) (f : A -&gt; B) (l : list A) (y : B),</span><br><span class="line">    In y (map f l) &lt;-&gt;</span><br><span class="line">    <span class="built_in">exists</span> x, f x = y /\ In x l.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">  <span class="built_in">intros</span> A B f l y. <span class="built_in">split</span>.</span><br><span class="line">  <span class="built_in">induction</span> l <span class="built_in">as</span> [| <span class="type">h</span> t IHl].</span><br><span class="line">  - <span class="built_in">simpl</span>. <span class="built_in">intros</span>. <span class="built_in">destruct</span> H.</span><br><span class="line">  <span class="comment">(* In y (map f (h :: t)) -&gt; exists x : A, f x = y /\ In x (h :: t) *)</span></span><br><span class="line">  - <span class="built_in">simpl</span>. <span class="built_in">intros</span> [H | <span class="type">H</span>].</span><br><span class="line">    + <span class="built_in">exists</span> h. <span class="built_in">simpl</span>. <span class="built_in">split</span>.</span><br><span class="line">      * <span class="built_in">apply</span> H.</span><br><span class="line">      * <span class="built_in">left</span>. <span class="built_in">reflexivity</span>.</span><br><span class="line">    <span class="comment">(* f x != y *)</span></span><br><span class="line">    + <span class="built_in">apply</span> IHl <span class="built_in">in</span> H. <span class="built_in">destruct</span> H <span class="built_in">as</span> [w [h1 h2]].</span><br><span class="line">      <span class="comment">(* now H is useable *)</span></span><br><span class="line">      <span class="built_in">exists</span> w. <span class="built_in">split</span>.</span><br><span class="line">      * <span class="built_in">apply</span> h1.</span><br><span class="line">      * <span class="built_in">right</span>. <span class="built_in">apply</span> h2.</span><br><span class="line">  <span class="comment">(* (exists x : A, f x = y /\ In x l) -&gt; In y (map f l) *)</span></span><br><span class="line">  - <span class="built_in">intros</span> [w [h1 h2]].</span><br><span class="line">    <span class="built_in">rewrite</span> &lt;- h1. <span class="built_in">apply</span> In_map. <span class="built_in">exact</span> h2.</span><br><span class="line"><span class="keyword">Qed</span>.</span><br></pre></td></tr></table></figure><p>另外，下面这个目标中的 x = x 如何被 simpl 掉？似乎没办法执行。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Lemma</span> In_map_iff2 :</span><br><span class="line">  <span class="keyword">forall</span> (A B : <span class="keyword">Type</span>) (f : A -&gt; B) (l : list A) (y : B),</span><br><span class="line">    In y (map f l) &lt;-&gt;</span><br><span class="line">    <span class="built_in">exists</span> x, f x = y /\ In x l.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">  <span class="built_in">intros</span> A B f l y. <span class="built_in">split</span>.</span><br><span class="line">    <span class="built_in">induction</span> l.</span><br><span class="line">    - <span class="built_in">simpl</span>. <span class="built_in">intros</span>. <span class="built_in">destruct</span> H.</span><br><span class="line">    - <span class="built_in">intros</span>. <span class="built_in">simpl</span>. <span class="built_in">exists</span> x. <span class="built_in">split</span>.</span><br><span class="line">      <span class="built_in">destruct</span> H. <span class="built_in">apply</span> H. <span class="built_in">apply</span> IHl <span class="built_in">in</span> H.</span><br><span class="line">      + <span class="built_in">admit</span>.</span><br><span class="line">      + <span class="built_in">simpl</span>.</span><br></pre></td></tr></table></figure><p>对应的 goal 如下</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> goal</span><br><span class="line">A : <span class="keyword">Type</span></span><br><span class="line">B : <span class="keyword">Type</span></span><br><span class="line">f : A -&gt; B</span><br><span class="line">x : A</span><br><span class="line">l : list A</span><br><span class="line">y : B</span><br><span class="line">IHl : In y (map f l) -&gt; <span class="built_in">exists</span> x : A, f x = y /\ In x l</span><br><span class="line">H : In y (map f (x :: l))</span><br><span class="line">______________________________________(<span class="number">1</span>/<span class="number">1</span>)</span><br><span class="line">f x = y /\ (x = x \/ In x l)</span><br></pre></td></tr></table></figure><p>下面这里的 apply H 我觉得比较有意思。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> excluded_middle_2_double_negation_elimination :</span><br><span class="line">  excluded_middle &lt;-&gt; double_negation_elimination.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">  <span class="built_in">split</span>.</span><br><span class="line">  - <span class="built_in">unfold</span> excluded_middle.</span><br><span class="line">    <span class="built_in">unfold</span> double_negation_elimination.</span><br><span class="line">    <span class="built_in">unfold</span> not.</span><br><span class="line">    <span class="built_in">intros</span>.</span><br><span class="line">    <span class="built_in">destruct</span> (H P).</span><br><span class="line">    + <span class="built_in">apply</span> H1.</span><br><span class="line">    + <span class="built_in">exfalso</span>. <span class="built_in">apply</span> H1. <span class="built_in">apply</span> H0 <span class="built_in">in</span> H1. <span class="built_in">destruct</span> H1.</span><br><span class="line">  - <span class="built_in">unfold</span> excluded_middle.</span><br><span class="line">    <span class="built_in">unfold</span> double_negation_elimination.</span><br><span class="line">    <span class="built_in">unfold</span> not.</span><br><span class="line">    <span class="built_in">intros</span>.</span><br><span class="line">    <span class="comment">(* Get rid of forall *)</span></span><br><span class="line">    <span class="built_in">apply</span> H.</span><br><span class="line">    <span class="built_in">intros</span>.</span><br><span class="line">    <span class="built_in">apply</span> H0.</span><br><span class="line">    <span class="built_in">right</span>. <span class="built_in">intros</span>. <span class="built_in">apply</span> H0. <span class="built_in">left</span>. <span class="built_in">apply</span> H1.</span><br><span class="line"><span class="keyword">Qed</span>.</span><br></pre></td></tr></table></figure><p>当时的 goal 是</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> goal</span><br><span class="line">H : <span class="keyword">forall</span> P : <span class="keyword">Prop</span>, ((P -&gt; False) -&gt; False) -&gt; P</span><br><span class="line">P : <span class="keyword">Prop</span></span><br><span class="line">______________________________________(<span class="number">1</span>/<span class="number">1</span>)</span><br><span class="line">P \/ (P -&gt; False)</span><br></pre></td></tr></table></figure><p>容易想到的是 left 或者 right 这样。但会陷入循环。比如我 <code>left. apply H. apply H. apply H0. apply H.</code>，最终是回到了最初的起点了。但是 apply H 完了之后，就得到</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(P \/ (P -&gt; False) -&gt; False) -&gt; False</span><br></pre></td></tr></table></figure><p>如果我 right. apply H. intros. apply H0. intros. apply H in H1. 就会得到如下的形式。我们不能 apply H in H1，因为这会得到什么呢？注意，这里是前向 apply 了，我们用 P 代换得不到sm东西。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> goal</span><br><span class="line">H : <span class="keyword">forall</span> P : <span class="keyword">Prop</span>, ((P -&gt; False) -&gt; False) -&gt; P</span><br><span class="line">P : <span class="keyword">Prop</span></span><br><span class="line">H0 : (P -&gt; False) -&gt; False</span><br><span class="line">H1 : P</span><br><span class="line">______________________________________(<span class="number">1</span>/<span class="number">1</span>)</span><br><span class="line">False</span><br></pre></td></tr></table></figure><p>这个应该是用 <code>((P -&gt; False) -&gt; False)</code> 代换了原来 goal 中的两处 P，然后再利用各种结合率啥的重新组合得到的。所以我觉得如果有 forall P : Prop, … -&gt; P 这样的东西，右边很简单的，不如大胆做个代换。</p><p>我们会遇到如 andb_true_iff 或者 ev5_nonsense 这样的，给一堆条件，证明 <code>false = true</code> 或者 <code>ev 5 -&gt; 2 + 2 = 9</code> 这样奇怪的命题。我们要做的并不是去 discriminate 掉 goal，而是要在条件中构造出一个 False，然后通过爆炸原理来证明。这里我觉得主要是，如果假设中能退出 True，那实际上是要证明 True -&gt; False，这个命题实际上是错误的。</p><p>另外，在 andb_true_iff  中需要注意 False 和 false 的区别。False 的定义是</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Inductive <span class="literal">False</span> : <span class="type">Prop</span> :=  .</span><br></pre></td></tr></table></figure><p>而 false 只是我们定义的 bool 类型的一个构造函数。而 False 是一个 type，或者一个 proposition。所以无法证明 (false = true) = false。相应的，我们应该证明 <code>false = true &lt;-&gt; False</code>。</p><p><a href="https://stackoverflow.com/questions/77957169/how-can-i-handle-this-false-true-case/77974227#77974227" target="_blank" rel="noopener">另一个回答说</a>，他说 falsehood 通常的构造办法：<br>1.假设从一个空集中去一个值，这个值就不能被创造出来<br>2.两个值从不同的构造函数中构造出来的值是相同的，而凑早函数被认为是 injective 的。<br>比如，如果假设中有 <code>H: False</code> 我们可以 destruct H。如果假设中有 <code>false = true</code>，那么就可以 inversion。</p><h2 id="承认排中律"><a href="#承认排中律" class="headerlink" title="承认排中律"></a>承认排中律</h2><p>不需要排中律即可证明 <code>double_neg</code> 即 <code>P -&gt; ~~P</code>。但是反过来的 <code>~~P -&gt; P</code> 则需要排中律来证明。其实 <code>~~P -&gt; P</code> 感觉就是反证法。</p><p><code>~~(P \/ ~P)</code> 可以被证明，但 <code>P \/ ~P</code> 排中律则依赖选择公理。为什么前者可以被证明呢？因为我们不能同时证明 <code>P \/ ~P</code> 和证伪 <code>P \/ ~P</code>。这样 <code>(P \/ ~P)</code> 和 <code>~(P \/ ~P)</code> 不能同时为真。因为 <code>forall P: Prop, P -&gt; ~~P</code>，所以 <code>~~(P \/ ~P)</code> 和 <code>~(P \/ ~P)</code> 不能同时为真。</p><p><code>~~(P \/ ~P)</code> 的证明流程。unfold 去掉 not，得到的 goal 是 <code>forall P : Prop, (P \/ (P -&gt; False) -&gt; False) -&gt; False</code>。好像是证明 “<code>P \/ (P -&gt; False)</code> 是不可能的”是不可能的。intros 把 <code>P \/ (P -&gt; False) -&gt; False</code> 作为假设，goal 变成 False。这里发现可以进一步 apply 这个假设，替换到如下的形式</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> goal</span><br><span class="line">P : <span class="keyword">Prop</span></span><br><span class="line">H : P \/ (P -&gt; False) -&gt; False</span><br><span class="line">______________________________________(<span class="number">1</span>/<span class="number">1</span>)</span><br><span class="line">P \/ (P -&gt; False)</span><br></pre></td></tr></table></figure><p>看起来好像是承认 Q -&gt; False 的情况下，反过来证明 Q 成立？继续证明。现在是给定 <code>H : P \/ (P -&gt; False) -&gt; False</code> 要证明 <code>P \/ (P -&gt; False)</code>。假设 P -&gt; False 成立，用 intros，假设 P 成立，证明 False。而已知条件是 <code>P \/ (P -&gt; False) -&gt; False</code>，不如再假设 P 成立，然后证明 <code>P \/ (P -&gt; False)</code>。</p><p>排中律本身和其他一些定理可以串起来形成一个证明的圈。这个和实数那几个的定理一样。</p><h1 id="InductionProp"><a href="#InductionProp" class="headerlink" title="InductionProp"></a>InductionProp</h1><p>之前，我们定义偶数一般是使用 nat。但现在介绍用 nat -&gt; Prop 这样的形式来定义偶数 ev。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Inductive</span> ev : nat -&gt; <span class="keyword">Prop</span> :=</span><br><span class="line">| <span class="type">ev_0</span> : ev <span class="number">0</span></span><br><span class="line">| <span class="type">ev_SS</span> (n : nat) (H : ev n) : ev (S (S n)).</span><br></pre></td></tr></table></figure><p>注意，另一种方式会出错，也就是将 nat 放到 <code>:</code> 的左侧。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Fail <span class="keyword">Inductive</span> wrong_ev (n : nat) : <span class="keyword">Prop</span> :=</span><br><span class="line">| <span class="type">wrong_ev_0</span> : wrong_ev <span class="number">0</span></span><br><span class="line">| <span class="type">wrong_ev_SS</span> (H: wrong_ev n) : wrong_ev (S (S n)).</span><br></pre></td></tr></table></figure><ul><li>We already know how to perform case analysis on <code>n</code> using destruct or induction</li><li>But for some proofs we may instead want to analyze the evidence that <code>ev n</code> directly<br>这是因为如果某人展示了对于 [ev n] 的 evidence [E]，那么我们知道 [E] 要么从 ev_0 来的，要么从 ev_SS 来的。<br>一个反演命题。这个命题是对 ev 这个判断奇偶性的命题而言的。对这个命题直接使用 induction 是搞不定的，因为<figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> ev_inversion :</span><br><span class="line">  <span class="keyword">forall</span> (n : nat), ev n -&gt;</span><br><span class="line">    (n = <span class="number">0</span>) \/ (<span class="built_in">exists</span> n', n = S (S n') /\ ev n').</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">  <span class="built_in">intros</span> n E.</span><br><span class="line">  <span class="built_in">destruct</span> E <span class="built_in">as</span> [ | <span class="type">n</span>' E'].</span><br><span class="line">  - <span class="comment">(* E = ev_0 : ev 0 *)</span></span><br><span class="line">    <span class="built_in">left</span>. <span class="built_in">reflexivity</span>.</span><br><span class="line">  - <span class="comment">(* E = ev_SS n' E' : ev (S (S n')) *)</span></span><br><span class="line">    <span class="built_in">right</span>. <span class="built_in">exists</span> n'. <span class="built_in">split</span>. <span class="built_in">reflexivity</span>. <span class="built_in">apply</span> E'.</span><br><span class="line"><span class="keyword">Qed</span>.</span><br></pre></td></tr></table></figure></li></ul><p>The [inversion] tactic can detect that:<br>1.the first case ([n =0]) does not apply<br>2.the [n’] that appears in the [ev_SS] case must be the same as [n].  </p><p>It has an “[as]” variant similar to [destruct], allowing us to assign names rather than have Coq choose them.</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> evSS_ev' : <span class="keyword">forall</span> n,</span><br><span class="line">  ev (S (S n)) -&gt; ev n.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">  <span class="built_in">intros</span> n E.</span><br><span class="line">  <span class="built_in">inversion</span> E <span class="built_in">as</span> [| <span class="type">n</span>' E' EQ].</span><br><span class="line">  <span class="comment">(* We are in the [E = ev_SS n' E'] case now. *)</span></span><br><span class="line">  <span class="built_in">apply</span> E'.</span><br><span class="line"><span class="keyword">Qed</span>.</span><br></pre></td></tr></table></figure><p><code>inversion</code> 策略会做很多东西，比如如果对一个等式使用，就相当于 discriminate 加上 injection。另外，它还会带上使用 injection 可能必须的 intros 和 rewrite。它还可以被 apply，去 analyze evident for inductively defined 命题。下面会用 inversion 来尝试证明 Tactics 章节中涉及的一些定理。</p><p>[inversion] 的工作原理大致如下：假设 [H] 指代上下文中的假设 [P]，且 [P] 由 [Inductive] 归纳定义，则对于 [P] 每一种可能的构造，[inversion H] 各为其生成子目标。子目标中自相矛盾者被忽略，证明其余子命题即可得证原命题。<br>在证明子目标时，上下文中的 [H] 会替换为 [P] 的构造条件，即其构造子所需参数以及必要的等式关系。例如：倘若 [ev n] 由 [ev_SS] 构造，上下文中会引入参数 [n’]、[ev n’]，以及等式 [S (S n’) = n]。</p><p>下面，是另一个问题。为了证明 [n] 的性质对于 [ev n] 成立的所有数字都成立。我们需要在 [ev n] 上 induction。证明分为两块，和 [ev n] 的两个构造函数对应。如果他通过 [ev_0] 构造，则 n = 0，那么性质肯定对 [0] 成立。如果他通过 [ev_SS] 构造，那么 [ev n] 的证据就具有形式 [en_SS n’ E’]，其中 [n = S (S n’)] ，[E’] 是 [eb n’] 的证据。这样，the inductive hypothesis says that the property we are trying to prove holds for [n’]。</p><p>注意，这里的 <code>exists (S k&#39;).</code> 来自于 ev 的定义，我们这里没有展开 ev。</p><p>从 le 的定义来看，可以总结出 destruct、inversion 和 induction 三种策略在 H: le e1 e2 上的作用。destruct H 能够产生两个 case。第一个 case 中 destruct H 产生两个情况，第一个是 e1 = e2，此时 e2 被 e1 替换掉。在第二个 case 中，e2 = S n’，并且对于某个 n’ 有 le e1 n’ 成立，并且用 S n’ 替换 e2。inversion H 会移除不可能的 case，并且将生成的新的等式添加到上下文中。执行 induction H，在第二种情况下，会将 induction hypothesis 的 e2 用 n’ 替换。</p><h2 id="具体-case"><a href="#具体-case" class="headerlink" title="具体 case"></a>具体 case</h2><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> ev'_ev_try1 : <span class="keyword">forall</span> n, ev' n &lt;-&gt; ev n.</span><br><span class="line"></span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">  <span class="built_in">intros</span>.</span><br><span class="line">  <span class="built_in">split</span>.</span><br><span class="line">  - <span class="built_in">induction</span> n.</span><br><span class="line">    + <span class="built_in">intros</span>. <span class="built_in">apply</span> ev_0.</span><br><span class="line">    + <span class="built_in">simpl</span>. <span class="keyword">Abort</span>.</span><br></pre></td></tr></table></figure><p>对应的 goal 如下，S n 肯定对 ev’ 啥的不成立了啊。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> goal</span><br><span class="line">n : nat</span><br><span class="line">IHn : ev' n -&gt; ev n</span><br><span class="line">______________________________________(<span class="number">1</span>/<span class="number">1</span>)</span><br><span class="line">ev' (S n) -&gt; ev (S n)</span><br></pre></td></tr></table></figure><p>这里和 le_trans 相关的命题都是放缩法。遇到 S n，就通过 le_S 去掉 S。但是放缩法要符合情理。比如 n_le_m__Sn_le_Sm 里面就不能从 S n &lt;= S m 放缩到 S n &lt;= m。<br>要从 H : S n &lt;= 1 推导 n &lt;= 0，可以 inversion H。从 H1 : S n &lt;= 0 推 n &lt;= 0，也可以 inversion。感觉总的来说，inversion 是将一个更强的条件去分解为多个较弱的条件。<br>这里一个问题是不能用 injection 解决S n &lt;= S (S m) 推导 n &lt;= S m。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> le_S_ab2_try : <span class="keyword">forall</span> a b,</span><br><span class="line">  S a &lt;= b -&gt; a &lt;= b.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">  <span class="built_in">intros</span> a b. </span><br><span class="line">  <span class="built_in">induction</span> a.</span><br><span class="line">  - <span class="built_in">intros</span>. <span class="built_in">inversion</span> H.</span><br><span class="line">    <span class="built_in">apply</span> le_S. <span class="built_in">apply</span> le_n. <span class="built_in">apply</span> O_le_n.</span><br><span class="line">  - <span class="built_in">intros</span>. <span class="built_in">inversion</span> H.</span><br><span class="line"></span><br><span class="line"><span class="number">2</span> goals</span><br><span class="line">a, b : nat</span><br><span class="line">IHa : S a &lt;= b -&gt; a &lt;= b</span><br><span class="line">H : S (S a) &lt;= b</span><br><span class="line">H0 : S (S a) = b</span><br><span class="line">______________________________________(<span class="number">1</span>/<span class="number">2</span>)</span><br><span class="line">S a &lt;= S (S a)</span><br><span class="line">______________________________________(<span class="number">2</span>/<span class="number">2</span>)</span><br><span class="line">S a &lt;= S m</span><br></pre></td></tr></table></figure><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> le_S_ab2 : <span class="keyword">forall</span> a b,</span><br><span class="line">  S a &lt;= b -&gt; a &lt;= b.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">  <span class="built_in">intros</span> a b. </span><br><span class="line">  <span class="built_in">generalize</span> <span class="built_in">dependent</span> a.</span><br><span class="line">  <span class="built_in">induction</span> b.</span><br><span class="line">  - <span class="built_in">intros</span>. <span class="built_in">inversion</span> H.</span><br><span class="line">  - <span class="built_in">intros</span>. <span class="built_in">inversion</span> H. <span class="built_in">apply</span> le_S. <span class="built_in">apply</span> le_n.</span><br><span class="line">    <span class="built_in">apply</span> le_S. <span class="built_in">apply</span> IHb. <span class="built_in">apply</span> H1.</span><br><span class="line"><span class="keyword">Qed</span>.</span><br><span class="line"></span><br><span class="line"><span class="number">2</span> goals</span><br><span class="line">b : nat</span><br><span class="line">IHb : <span class="keyword">forall</span> a : nat, S a &lt;= b -&gt; a &lt;= b</span><br><span class="line">a : nat</span><br><span class="line">H : S a &lt;= S b</span><br><span class="line">H1 : a = b</span><br><span class="line">______________________________________(<span class="number">1</span>/<span class="number">2</span>)</span><br><span class="line">b &lt;= S b</span><br><span class="line">______________________________________(<span class="number">2</span>/<span class="number">2</span>)</span><br><span class="line">a &lt;= S b</span><br></pre></td></tr></table></figure><p>比较有意思的是这里又找到一个必须要 apply with 的结构</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> add_le_cases : <span class="keyword">forall</span> n m p q,</span><br><span class="line">    n + m &lt;= p + q -&gt; n &lt;= p \/ m &lt;= q.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">    <span class="built_in">intros</span>.</span><br><span class="line">    <span class="built_in">generalize</span> <span class="built_in">dependent</span> p.</span><br><span class="line">    <span class="built_in">induction</span> n. <span class="built_in">left</span>. <span class="built_in">apply</span> O_le_n.</span><br><span class="line">    <span class="built_in">intros</span>. <span class="built_in">destruct</span> p.</span><br><span class="line">    * <span class="built_in">right</span>. <span class="built_in">rewrite</span> plus_O_n <span class="built_in">in</span> H. <span class="built_in">apply</span> le_S_ab2.</span><br><span class="line">      <span class="built_in">apply</span> add_le_cases_helper.</span><br><span class="line"></span><br><span class="line">Unable to find an instance <span class="keyword">for</span> the variable n.</span><br></pre></td></tr></table></figure><p>另一个启发是不要过早地使用 left 或者 right 策略。会出现如下所示的问题，我们的条件和 goal 是不相关的。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> add_le_cases : <span class="keyword">forall</span> n m p q,</span><br><span class="line">    n + m &lt;= p + q -&gt; n &lt;= p \/ m &lt;= q.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">    <span class="built_in">intros</span>.</span><br><span class="line">    <span class="built_in">generalize</span> <span class="built_in">dependent</span> p.</span><br><span class="line">    <span class="built_in">induction</span> n. <span class="built_in">left</span>. <span class="built_in">apply</span> O_le_n.</span><br><span class="line">    <span class="built_in">intros</span>. <span class="built_in">destruct</span> p.</span><br><span class="line">    * <span class="built_in">right</span>. <span class="built_in">rewrite</span> plus_O_n <span class="built_in">in</span> H. <span class="built_in">apply</span> le_S_ab2.</span><br><span class="line">      <span class="built_in">apply</span> add_le_cases_helper <span class="built_in">with</span> (n:=n). <span class="built_in">exact</span> H.</span><br><span class="line">    * <span class="built_in">left</span>. <span class="built_in">simpl</span> <span class="built_in">in</span> H. <span class="built_in">apply</span> add_le_helper2 <span class="built_in">in</span> H. <span class="built_in">apply</span> IHn <span class="built_in">in</span> H.</span><br><span class="line">      <span class="built_in">destruct</span> H.</span><br><span class="line">      - <span class="built_in">apply</span> n_le_m__Sn_le_Sm. <span class="built_in">exact</span> H.</span><br><span class="line">      - </span><br><span class="line"><span class="number">1</span> goal</span><br><span class="line">n, m, q : nat</span><br><span class="line">IHn : <span class="keyword">forall</span> p : nat, n + m &lt;= p + q -&gt; n &lt;= p \/ m &lt;= q</span><br><span class="line">p : nat</span><br><span class="line">H : m &lt;= q</span><br><span class="line">______________________________________(<span class="number">1</span>/<span class="number">1</span>)</span><br><span class="line">S n &lt;= S p</span><br></pre></td></tr></table></figure><p>其实在第二个目标中，不要那么早使用 left 策略，而是先想办法 destruct H，根据 destruct 得到的条件选择是 left 还是 right 就能解决问题了。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Theorem</span> add_le_cases : <span class="keyword">forall</span> n m p q,</span><br><span class="line">    n + m &lt;= p + q -&gt; n &lt;= p \/ m &lt;= q.</span><br><span class="line"><span class="keyword">Proof</span>.</span><br><span class="line">    <span class="built_in">intros</span>.</span><br><span class="line">    <span class="built_in">generalize</span> <span class="built_in">dependent</span> p.</span><br><span class="line">    <span class="built_in">induction</span> n. <span class="built_in">left</span>. <span class="built_in">apply</span> O_le_n.</span><br><span class="line">    <span class="built_in">intros</span>. <span class="built_in">destruct</span> p.</span><br><span class="line">    * <span class="built_in">right</span>. <span class="built_in">rewrite</span> plus_O_n <span class="built_in">in</span> H. <span class="built_in">apply</span> le_S_ab2.</span><br><span class="line">      <span class="built_in">apply</span> add_le_cases_helper <span class="built_in">with</span> (n:=n). <span class="built_in">exact</span> H.</span><br><span class="line">    * <span class="built_in">simpl</span> <span class="built_in">in</span> H. <span class="built_in">apply</span> add_le_helper2 <span class="built_in">in</span> H. <span class="built_in">apply</span> IHn <span class="built_in">in</span> H.</span><br><span class="line">      <span class="built_in">destruct</span> H.</span><br><span class="line">      - <span class="built_in">left</span>. <span class="built_in">apply</span> n_le_m__Sn_le_Sm. <span class="built_in">exact</span> H.</span><br><span class="line">      - <span class="built_in">right</span>. <span class="built_in">exact</span> H.</span><br><span class="line"><span class="keyword">Qed</span>.</span><br></pre></td></tr></table></figure><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://coq.inria.fr/doc/V8.13+beta1/refman/proofs/writing-proofs/rewriting.html" target="_blank" rel="noopener">https://coq.inria.fr/doc/V8.13+beta1/refman/proofs/writing-proofs/rewriting.html</a><br> 介绍 rewrite</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://github.com/CalvinNeo/SF-zh&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/CalvinNeo/SF-zh&lt;/a&gt; 做题笔记。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Coq" scheme="http://www.calvinneo.com/tags/Coq/"/>
    
  </entry>
  
  <entry>
    <title>GhostCell</title>
    <link href="http://www.calvinneo.com/2024/01/31/ghost_cell/"/>
    <id>http://www.calvinneo.com/2024/01/31/ghost_cell/</id>
    <published>2024-01-31T11:20:33.000Z</published>
    <updated>2024-02-10T14:51:54.480Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://crates.io/crates/ghost-cell" target="_blank" rel="noopener">GhostCell</a> 是另一个内部可变性的实现。相比 RefCell，它实现的是编译期的检查。</p><a id="more"></a><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>Rust 中面临所谓 AXM 的问题。A 指的是 Aliasing，M 指的是 Mutability。AXM 表示 A Xor M，也就是这两个只能保证其一。</p><p>这让 Rust 容易实现树状结构，而难以实现图状结构（比如双向链表、图等）。其原因是图状结构中有环，环意味着 internal sharing。</p><p>对此，Rust 一般提供两种做法：</p><ol><li>raw 指针<br> 具有下面的特点：<ul><li>Unsafe，也就是 Rust 的类型系统无法进行约束</li><li>没有 AXM 限制</li></ul></li><li>Interior Mutability<ul><li>非线程安全的有 Cell 和 RefCell，它们允许通过一个不可变借用 <code>&amp;T</code> 去修改内部的对象</li><li>线程安全的有 Mutex 和 RwLock</li></ul></li></ol><p>比如双向链表就可以写成</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span></span>&lt;T&gt; &#123;</span><br><span class="line">    data: T,</span><br><span class="line">    prev: <span class="built_in">Option</span>&lt;NodeRef&lt;T&gt;&gt;,</span><br><span class="line">    next: <span class="built_in">Option</span>&lt;NodeRef&lt;T&gt;&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">NodeRef</span></span>&lt;T&gt;= &amp;RwLock&lt;Node&lt;T&gt;&gt;;</span><br></pre></td></tr></table></figure><p>作者就说这样的话一个 Node 会有一个 RwLock。如果我们希望链表可以被多个线程同时修改，这是有用的，但如果只是希望在整个链表上实现 AXM，就有点 overkill 了。</p><p>当然，我觉得始终可以去把整个链表外面包一层来解决 AXM 的问题的吧。</p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>作者宣称 GhostCell 有如下的特性：</p><ol><li>支持 internal sharing</li><li>zero cost abstraction</li><li>safe，通过 Coq 证明</li><li>flexible，是 thread-safe 的，对 type T 没有要求</li></ol><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>作者说 Rust 将 permission 和 data 绑定了。所以这导致了 AXM 在一个很细的粒度上，比如链表中的每个节点。</p><p>因此，GhostCell 将 permission 和 data 分开来。让一个 permission 可以和一整个data 关联，比如整个链表。</p><p>这个想法称为 Brand Types，来自于 ST monad 的启发。</p><p>GhostCell 表示一个大结构里面的某个小元素。这个大结构有一个 brand 为 <code>&#39;id</code>。<br>GhostToken 是一个 Permission，可以用来访问任意的标有 <code>&#39;id</code> 的 GhostCell。</p><p><img src="/img/ghostcell/btype.png"></p><p>以链表为例，进行如下的修改即可使用 GhostCell。<br><img src="/img/ghostcell/ll.png"></p><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>如下所示，创建一个 vec，其中元素都为 cell 的引用。我修改 <code>vec[n / 2]</code> 的值，然后再读取 cell，会发现 cell 的值也被修改了。这里的逻辑没问题，但是 GhostToken 能够避免 borrow checker 的检查报错。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> ghost_cell::&#123;GhostToken, GhostCell&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">demo</span></span>(n: <span class="built_in">usize</span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> value = GhostToken::new(|<span class="keyword">mut</span> token| &#123;</span><br><span class="line">        <span class="keyword">let</span> cell = GhostCell::new(<span class="number">42</span>);</span><br><span class="line">        <span class="keyword">let</span> vec: <span class="built_in">Vec</span>&lt;_&gt; = (<span class="number">0</span>..n).map(|_| &amp;cell).collect();</span><br><span class="line">        *vec[n / <span class="number">2</span>].borrow_mut(&amp;<span class="keyword">mut</span> token) = <span class="number">33</span>;</span><br><span class="line">        *cell.borrow(&amp;token)</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">assert_eq!</span>(value, <span class="number">33</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">InvariantLifetime</span></span>&lt;<span class="symbol">'brand</span>&gt; = PhantomData&lt;<span class="function"><span class="keyword">fn</span></span>(&amp;<span class="symbol">'brand</span> ()) -&gt; &amp;<span class="symbol">'brand</span> ()&gt;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// A `GhostToken&lt;'x&gt;` is _the_ key to access the content of any `&amp;GhostCell&lt;'x, _&gt;` sharing the same brand.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Each `GhostToken&lt;'x&gt;` is created alongside a unique brand (its lifetime), and each `GhostCell&lt;'x, T&gt;` is associated</span></span><br><span class="line"><span class="comment">/// to one, and only one, `GhostToken` at a time via this brand. The entire set of `GhostCell&lt;'x, T&gt;` associated to a</span></span><br><span class="line"><span class="comment">/// given `GhostToken&lt;'x&gt;` creates a pool of cells all being accessible solely through the one token they are associated</span></span><br><span class="line"><span class="comment">/// to.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// The pool of `GhostCell` associated to a token need not be homogeneous, each may own a value of a different type.</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">GhostToken</span></span>&lt;<span class="symbol">'brand</span>&gt; &#123;</span><br><span class="line">    _marker: InvariantLifetime&lt;<span class="symbol">'brand</span>&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">'brand</span>&gt; GhostToken&lt;<span class="symbol">'brand</span>&gt; &#123;</span><br><span class="line">    <span class="comment">/// Creates a fresh token to which `GhostCell`s can be tied to later.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// Due to the use of a lifetime, the `GhostCell`s tied to a given token can only live within the confines of the</span></span><br><span class="line">    <span class="comment">/// invocation of the `fun` closure.</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">#[allow(clippy::new_ret_no_self)]</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">new</span></span>&lt;R, F&gt;(fun: F) -&gt; R</span><br><span class="line">    <span class="keyword">where</span></span><br><span class="line">        <span class="keyword">for</span>&lt;<span class="symbol">'new_brand</span>&gt; F: <span class="built_in">FnOnce</span>(GhostToken&lt;<span class="symbol">'new_brand</span>&gt;) -&gt; R,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">let</span> token = <span class="keyword">Self</span> &#123;</span><br><span class="line">            _marker: InvariantLifetime::<span class="keyword">default</span>(),</span><br><span class="line">        &#125;;</span><br><span class="line">        fun(token)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">'brand</span>, T: ?<span class="built_in">Sized</span>&gt; GhostCell&lt;<span class="symbol">'brand</span>, T&gt; &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">borrow</span></span>&lt;<span class="symbol">'a</span>&gt;(&amp;<span class="symbol">'a</span> <span class="keyword">self</span>, _: &amp;<span class="symbol">'a</span> GhostToken&lt;<span class="symbol">'brand</span>&gt;) -&gt; &amp;<span class="symbol">'a</span> T &#123;</span><br><span class="line">        <span class="comment">//  Safety:</span></span><br><span class="line">        <span class="comment">//  -   The cell is borrowed immutably by this call, it therefore cannot already be borrowed mutably.</span></span><br><span class="line">        <span class="comment">//  -   The token is borrowed immutably by this call, it therefore cannot be already borrowed mutably.</span></span><br><span class="line">        <span class="comment">//  -   `self.value` therefore cannot be already borrowed mutably, as doing so requires calling either:</span></span><br><span class="line">        <span class="comment">//      -   `borrow_mut`, which would borrow the token mutably.</span></span><br><span class="line">        <span class="comment">//      -   `get_mut`, which would borrow the cell mutably.</span></span><br><span class="line">        <span class="keyword">unsafe</span> &#123; &amp;*<span class="keyword">self</span>.value.get() &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">borrow_mut</span></span>&lt;<span class="symbol">'a</span>&gt;(&amp;<span class="symbol">'a</span> <span class="keyword">self</span>, _: &amp;<span class="symbol">'a</span> <span class="keyword">mut</span> GhostToken&lt;<span class="symbol">'brand</span>&gt;) -&gt; &amp;<span class="symbol">'a</span> <span class="keyword">mut</span> T &#123;</span><br><span class="line">        <span class="comment">//  Safety:</span></span><br><span class="line">        <span class="comment">//  -   The cell is borrowed immutably by this call, it therefore cannot already be borrowed mutably.</span></span><br><span class="line">        <span class="comment">//  -   The token is borrowed mutably by this call, it therefore cannot be already borrowed.</span></span><br><span class="line">        <span class="comment">//  -   `self.value` therefore cannot already be borrowed, as doing so requires calling either:</span></span><br><span class="line">        <span class="comment">//      -   `borrow` or `borrow_mut`, which would borrow the token.</span></span><br><span class="line">        <span class="comment">//      -   `get_mut`, which would borrow the cell mutably.</span></span><br><span class="line">        <span class="keyword">unsafe</span> &#123; &amp;<span class="keyword">mut</span> *<span class="keyword">self</span>.value.get() &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">from_mut</span></span>(t: &amp;<span class="keyword">mut</span> T) -&gt; &amp;<span class="keyword">mut</span> <span class="keyword">Self</span> &#123;</span><br><span class="line">        <span class="comment">//  Safety:</span></span><br><span class="line">        <span class="comment">//  -   `t` is mutably borrowed for the duration.</span></span><br><span class="line">        <span class="comment">//  -   `GhostCell&lt;'_, T&gt;` has the same in-memory representation as `T`.</span></span><br><span class="line">        <span class="keyword">unsafe</span> &#123; mem::transmute(t) &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.bilibili.com/video/BV1HP4y1s762/" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1HP4y1s762/</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://crates.io/crates/ghost-cell&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GhostCell&lt;/a&gt; 是另一个内部可变性的实现。相比 RefCell，它实现的是编译期的检查。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Rust" scheme="http://www.calvinneo.com/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Performance analysis and tuning on modern CPUs 学习笔记</title>
    <link href="http://www.calvinneo.com/2023/12/17/patmc/"/>
    <id>http://www.calvinneo.com/2023/12/17/patmc/</id>
    <published>2023-12-17T02:57:32.000Z</published>
    <updated>2024-01-29T15:25:44.930Z</updated>
    
    <content type="html"><![CDATA[<p>According to 老板，according to yifan，这本书很好，所以我就来学习一下了。</p><a id="more"></a><h1 id="Part-1-的说明"><a href="#Part-1-的说明" class="headerlink" title="Part 1 的说明"></a>Part 1 的说明</h1><h1 id="Measuring-Performance"><a href="#Measuring-Performance" class="headerlink" title="Measuring Performance"></a>Measuring Performance</h1><p>Changing a seemingly unrelated part of the source code can surprise us with a significant impact on program performance. This phenomenon is called measurement bias. … Instead, we will just focus on high-level ideas and directions to follow.</p><p>This chapter will give a brief introduction to why modern systems yield noisy performance measurements and what you can do about it.</p><h2 id="Noise-In-Modern-Systems"><a href="#Noise-In-Modern-Systems" class="headerlink" title="Noise In Modern Systems"></a>Noise In Modern Systems</h2><p>一种叫 Dynamic Frequency Scaling 的技术可以短时间内提升 CPU 的频率，但它是基于核心温度的，所以不确定。在散热不太好的笔记本上经常发生第一个 run 会 turbo，但第二个 run 回归到 base frequency 的情况。</p><p>软件层面的因素，包括 file cache 是否 warm。有论文说，env var 的大小，以及 link 的顺序都能影响性能。影响内存布局也可以影响性能，有研究说 efficiently and repeatedly randomizing the placement of code, stack, and heap objects at runtime 可以解决处理内存布局带来的问题。</p><p>如果 benchmark 一个云处理器环境，上述的 noise 和 variation 基本难以被消除。</p><p>temci 这个工具能够设置环境，从而确保一个 low variance。</p><h2 id="Measuring-Performance-In-Production"><a href="#Measuring-Performance-In-Production" class="headerlink" title="Measuring Performance In Production"></a>Measuring Performance In Production</h2><h1 id="CPU-Microarchitecture"><a href="#CPU-Microarchitecture" class="headerlink" title="CPU Microarchitecture"></a>CPU Microarchitecture</h1><h2 id="Instruction-Set-Architecture"><a href="#Instruction-Set-Architecture" class="headerlink" title="Instruction Set Architecture"></a>Instruction Set Architecture</h2><p>the critical CPU architecture and microarchitecture features that impact performance</p><p>In addition to providing the basic functions in the ISA such as<br>load, store, control, scalar arithmetic operations using integers and floating-point, the widely deployed architectures continue to enhance their ISA to support new computing paradigms. These include enhanced vector processing instructions (e.g., Intel AVX2, AVX512, ARM SVE) and matrix/tensor instructions (Intel AMX). Software mapped to use these advanced instructions typically provide orders of magnitude improvement in performance.</p><p>深度学习中，即使使用较少的 bits 效果也挺好，所以一些处理器倾向于引入 8bit integer 等来节约计算和内存带宽。</p><h2 id="Pipelining"><a href="#Pipelining" class="headerlink" title="Pipelining"></a>Pipelining</h2><p>The processing of instructions is divided into stages. The stages operate in parallel, working on different parts of different instructions.</p><p>在 CSAPP 里面已经学习了取指、解码、执行、访存、写回的流水线。</p><p>The throughput of a pipelined CPU is defined as the number of instructions that complete and exit the pipeline per unit of time.</p><p>The latency for any given instruction is the total time through all the stages of the pipeline.</p><p>The time required to move an instruction from one stage to the other defines the basic machine cycle or clock for the CPU. The value chosen for the clock for a given pipeline is defined by the <strong>slowest stage</strong> of the pipeline. 因此这里的优化点是均衡或者重新设计 pipeline，消除最慢的 stage 的 bottleneck。</p><p>假定所有的 stage 都是完美 balanced，没有任何 stall，那么通过 pipeline，可以让一个指令的处理时间减少到原来的 n_stage 分之一。</p><p>下面提到三种冒险，其中 Structural hazard 指的是对硬件资源的争抢，通常通过复制硬件解决。剩下两种在 CSAPP 中详细介绍过了，本教程做了归纳。<br>数据冒险是程序中的数据依赖，分三类：</p><ol><li><p>Read after write<br> x 的写结束前，x + 1 就需要读到 x 的写的内容，不然 x + 1 会读到更旧的数据。通常使用 bypassing 的办法，将数据从流水线的后面(指令 x + 1 的阶段) forward 到前面(指令 x 的阶段)。</p></li><li><p>Write after read<br> x 在读完之后，x + 1 才能写，不然 x 会读到更新的数据。译码阶段总是在写回阶段前面，为什么会有 WAR 场景？原因是需要考虑处理器乱序执行。如下所示，R0 上存在 WAR 场景。</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">R1 = R0 ADD 1</span><br><span class="line">R0 = R2 ADD 2</span><br></pre></td></tr></table></figure><p> WAR 可以被 register renaming 解决。 Logical (architectural) registers, the ones that are defined by the ISA, are just aliases over a wider register file。因此，只需要将第二个 R0，以及之后的所有的 R0 重命名到另一个寄存器文件上即可解决问题。因此这两个指令之间就可以被乱序执行了。<br> 【Q】这些 physical register file 如何被 gc 呢？旧的 R0 alias 不知道新的 R0 alias 的存在啊。看 CPU backend 的介绍时发现，这个是 ROB 做的。</p></li><li><p>Write after write<br> 同样可以通过 register renaming 解决。</p></li></ol><p>控制冒险主要指分支预测之类的东西，影响取指阶段。诸如动态分支预测、 speculative execution 能优化。</p><h2 id="Exploiting-Instruction-Level-Parallelism-ILP"><a href="#Exploiting-Instruction-Level-Parallelism-ILP" class="headerlink" title="Exploiting Instruction Level Parallelism (ILP)"></a>Exploiting Instruction Level Parallelism (ILP)</h2><p>大多数的指令可以被并行执行，因为它们是不相关的。</p><h3 id="OOO-Execution"><a href="#OOO-Execution" class="headerlink" title="OOO Execution"></a>OOO Execution</h3><p>An instruction is called retired when it is finally executed, and its results are correct and visible in the <a href="https://en.wikipedia.org/wiki/Architectural_state" target="_blank" rel="noopener">architectural state</a>. To ensure correctness, CPUs must retire all instructions in the program order. 这里 architectural state 主要区分于 microarchitectural state，后者是隐藏的 state，例如 pipeline registers、cache tag、branch predictor 等。</p><p>OOO is primarily used to avoid underutilization of CPU resources due to stalls caused by dependencies, especially in superscalar engines described in the next section.</p><p>scoreboard 被用来 schedule the in-order retirement and all machine state updates。它需要记录每一条指令的数据依赖 and where in the pipe the data is available。scoreboard 的大小决定了 CPU 能够超前多少调度彼此无关的指令。</p><p>下图中，x + 1 因为一些冲突，插入了一些气泡。而 OOO 的执行可以使 x + 2 这个 independent 的指令先进入执行(EXE)阶段。但是所有的指令还是要 按照 program order 来 retire，也就是最后的写回阶段是要按顺序的。<br><img src="/img/patmc/3.8.png"></p><h3 id="Superscalar-Engines-and-VLIW"><a href="#Superscalar-Engines-and-VLIW" class="headerlink" title="Superscalar Engines and VLIW"></a>Superscalar Engines and VLIW</h3><p>Most modern CPUs are superscalar i.e., they can issue more than one instruction in a given cycle. Issue-width is the maximum number of instructions that can be issued during the same cycle.</p><p>目前处理器的 issue width 在 2 到 6 之间。为了处理这些 instruction，目前 CPU 也会支持 more than one execution unit and/or pipelined execution units。Superscalar 也可以和之前提到的 pipeline 和 OOO 结合起来用。</p><p>下图展示了 issue width = 2 的情况。 Superscalar CPU 中支持多个 independent execution units 能够执行指令，而避免冲突。<br><img src="/img/patmc/3.9.png"></p><p>Intel 使用 VLIW，即 Very Long Instruction Word 技术将调度 Superscalar 和 multi execution unit 的负担转移给编译器。这是因为 software pipelining, loop unrolling 这些编译器优化相比硬件能看到的更多。</p><h3 id="Speculative-Execution"><a href="#Speculative-Execution" class="headerlink" title="Speculative Execution"></a>Speculative Execution</h3><p>下面介绍了 Speculative Execution 是什么，不翻译了。</p><blockquote><p>As noted in the previous section, control hazards can cause significant performance loss in a pipeline if instructions are stalled until the branch condition is resolved. One technique to avoid this performance loss is hardware branch prediction logic to predict the likely direction of branches and allow executing instructions from the predicted path (speculative execution).</p></blockquote><p>如下所示，Speculative Execution 不会等 branch 预测结果，而是直接执行 foo，如打星号所示，但是实际的状态变化直到 condition 被 resolve 之后才会被 commit，这样才能保证 architecture state 不会被 speculative executing 影响。</p><p><img src="/img/patmc/3.10.png"></p><p>在现实中，branch 命令可能依赖从内存中加载上来的某个值，这可能需要花费上百个 cycle。如果分支预测的是不正确的，也就是实际应该调用 bar 了，那么 speculative 执行的结果需要被扔掉，称为 branch misprediction penalty。</p><p>为了记录 speculation 的进度，CPU 支持一个叫 ReOrder Buffer 即 ROB 的结构。ROB 中依照顺序了所有指令，包括已经 retire 的指令的状态。如果 speculation 是正确的华，speculative execution 的结果按照 program order 会写到 ROB 里面，然后被 commit 到 architecture register 中。</p><p>CPUs can also combine speculative execution with out-of-order execution and use the ROB to track both speculation and out-of-order execution.</p><h2 id="Exploiting-Thread-Level-Parallelism"><a href="#Exploiting-Thread-Level-Parallelism" class="headerlink" title="Exploiting Thread Level Parallelism"></a>Exploiting Thread Level Parallelism</h2><p>A hardware multi-threaded CPU supports dedicated hardware resources to track the state (aka context) of each thread independently.<br>The main motivation for such a multi-threaded CPU is to switch from one context to another with the smallest latency (without incurring the cost of saving and restoring thread context) when a thread is blocked due to a long latency activity such as memory references</p><h3 id="Simultaneous-Multithreading"><a href="#Simultaneous-Multithreading" class="headerlink" title="Simultaneous Multithreading"></a>Simultaneous Multithreading</h3><p>ILP techniques and multi-threading 被结合使用。不同线程中的指令在同一个 cycle 中被并发地执行。同时从多个线程中 dispatch 指令可以充分利用 superscalar 资源，提高 CPU 总体性能。为了支持 SMT，CPU 需要复制硬件去存储 thread state，例如 PC 和寄存器等。追踪 OOO 和 speculative execution 的资源可以复制，也可以共享。一些 Cache 被 hardware 线程共享。</p><h2 id="Memory-Hierarchy"><a href="#Memory-Hierarchy" class="headerlink" title="Memory Hierarchy"></a>Memory Hierarchy</h2><p>Memory Hierarchy 从下面两种性质构造：</p><ol><li>Temporal locality</li><li>Spatial locality</li></ol><p>CSAPP 中进行了更为详细的讨论。</p><h3 id="Cache-Hierarchy"><a href="#Cache-Hierarchy" class="headerlink" title="Cache Hierarchy"></a>Cache Hierarchy</h3><p>A particular level of the cache hierarchy can be used exclusively for code (instruction cache, i-cache) or for data (data cache, d-cache), or shared between code and data (unified cache).</p><h4 id="Placement-of-data-within-the-cache"><a href="#Placement-of-data-within-the-cache" class="headerlink" title="Placement of data within the cache"></a>Placement of data within the cache</h4><h4 id="Finding-data-in-the-cache"><a href="#Finding-data-in-the-cache" class="headerlink" title="Finding data in the cache"></a>Finding data in the cache</h4><h4 id="Managing-misses"><a href="#Managing-misses" class="headerlink" title="Managing misses"></a>Managing misses</h4><p>对 direct-mapped 来讲，它会 evict 掉之前的 block。<br>对 set-associative 来讲，需要一个例如 LRU cache 的算法。</p><h4 id="Managing-writes"><a href="#Managing-writes" class="headerlink" title="Managing writes"></a>Managing writes</h4><p>CPU designs use two basic mechanisms to handle writes that hit in the cache:</p><ol><li>In a write-through cache<br> hit data is written to both the block in the cache and to the next lower level of the hierarchy</li><li>In a write-back cache<br> hit data is only written to the cache.<br> Subsequently, lower levels of the hierarchy contain stale data.<br> The state of the modified line is tracked through a dirty bit in the tag. When a modified cache line is eventually evicted from the cache, a write-back operation forces the data to be written back to the next lower level.</li></ol><p>Cache misses on write operations can be handled using two different options:</p><ol><li>write-allocate or fetch on write miss cache<br> 数据会被从下一级缓存中被加载上来，并且当前 write operation 会被视作一次 write hit。</li><li>no-write-allocate policy<br> cache miss 会直接被发送到下一级缓存，并且该缓存不会被加载到当前缓存。</li></ol><p>Out of these options, most designs typically choose to implement a write-back cache with a write-allocate policy as both of these techniques try to convert subsequent write transactions into cache-hits, without additional traffic to the lower levels of the hierarchy.</p><p>Write through caches typically use the no-write-allocate policy.</p><h4 id="Other-cache-optimization-techniques"><a href="#Other-cache-optimization-techniques" class="headerlink" title="Other cache optimization techniques"></a>Other cache optimization techniques</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Average Access Latency = Hit Time + Miss Rate × Miss Penalty</span><br></pre></td></tr></table></figure><p>硬件工程师们努力减少 Hit Time，以及 Miss Penalty。而 Miss Rate 取决于 block size 和 associativity，以及软件。</p><h4 id="HW-and-SW-Prefetching"><a href="#HW-and-SW-Prefetching" class="headerlink" title="HW and SW Prefetching"></a>HW and SW Prefetching</h4><p>Prefetch 指令和数据可以减少 cache miss 和后续的 stall 的发生。</p><p>Hardware prefetchers observe the behavior of a running application and initiate prefetching on repetitive patterns of cache misses. Hardware prefetching can automatically adapt to the dynamic behavior of the application, such as varying data sets, and does not require support from an optimizing compiler or profiling support. Also, the hardware prefetching works without the overhead of additional address-generation and prefetch instructions. 当然，hardware prefetching 只限于某几种 cache miss pattern。</p><p>Software memory prefetching 中，开发者可制定一些内存位置，或者让编译器自行添加一些 prefetch 指令。</p><h3 id="Main-memory"><a href="#Main-memory" class="headerlink" title="Main memory"></a>Main memory</h3><p>Main memory uses DRAM (dynamic RAM) technology that supports large capacities at reasonable cost points.</p><p>主存被三个属性描述，latency、bandwidth 和 capacity。</p><p>Latency 主要是两个指标，Memory access time 是从请求，到数据 available 的时间。Memory cycle time 是两个连续的访存操作之间最小的时间间隔。</p><p>DDR (double data rate) DRAM 是主要的 DRAM 技术。历史上，DRAM bandwidth 每一代都会被提高，但是 DRAM 的 latency 原地踏步，甚至会更高。下面的表中展示了最近三代的 DDR 技术的相关数据。MT/s 指的是 a million transfers per sec。</p><p><img src="/img/patmc/t2.png"></p><h2 id="Virtual-Memory"><a href="#Virtual-Memory" class="headerlink" title="Virtual Memory"></a>Virtual Memory</h2><p>Virtual Memory 实现多个程序共享一个内存。具有特性：</p><ol><li>protection<br> 也就是不能访问其他进程的内存</li><li>relocation<br> 也就是不改变逻辑地址，但是将程序加载到任意的物理地址</li></ol><p>vitual 地址和物理地址通过 page table 进行转换。vitual 地址分为两部分。virtual page number 用来索引具体的 page table，这个 page table 可能是一层，也有可能嵌套了很多层。page offset 用来 access the physical memory location at the same offset in the mapped physical page。<br>如果需要的 page 不在主存里面，就会发生 page fault。操作系统负责告诉硬件去处理 page fault，这样一个 LRU 的 page 会被 evict 掉，腾出空间给新 page。</p><p>CPUs typically use a hierarchical page table format to map virtual address bits efficiently to<br>the available physical memory. CPU 会使用一个有层级的 page table 去维护 virtual address 和 physical memory 的关系。但 page fault 的惩罚是很大的，需要从 hierarchy 中 traverse 查找。所以 CPU 支持一个硬件结构 translation lookaside buffer (TLB) 来保存最近的地址翻译结果。</p><p><img src="/img/patmc/3.12.png"></p><h2 id="SIMD-Multiprocessors"><a href="#SIMD-Multiprocessors" class="headerlink" title="SIMD Multiprocessors"></a>SIMD Multiprocessors</h2><p>SIMD (Single Instruction, Multiple Data) multiprocessors 是相对于之前的 MIMD 来说的。SIMD 会在一个 cycle 中将一条指令运用于多个数据上，从而利用多个 functional units。</p><p>下图是 SISD 和 SIMD 的对比。<br><img src="/img/patmc/3.13.png"></p><h2 id="Modern-CPU-design"><a href="#Modern-CPU-design" class="headerlink" title="Modern CPU design"></a>Modern CPU design</h2><p>下图是 Skylake(2015) 的架构。 The Skylake core is split into an in-order front-end that fetches and decodes x86 instructions into u-ops and an 8-way superscalar, out-of-order backend.</p><p>The core supports 2-way SMT. It has a 32KB, 8-way first-level instruction cache (L1 I-cache), and a 32KB, 8-way first-level data cache (L1 D-cache). The L1 caches are backed up by a unified 1MB second-level cache, the L2 cache. The L1 and L2 caches are private to each core.</p><p><img src="/img/patmc/3.14.png"></p><h3 id="CPU-Front-End"><a href="#CPU-Front-End" class="headerlink" title="CPU Front-End"></a>CPU Front-End</h3><p>前端负责 fetch and decode instructions from memory，将准备好的指令喂给后端执行。</p><p>每一个 cycle，前端从 L1 I-cache 中取 16 bytes 的指令。它们被两个线程分享，所以实际上是第一个周期线程 A 取，第二个周期线程 B 取，然后又是线程 A 这样。这些指令是复杂的可变长度的指令，pipeline 的 pre-decode 和 decode 阶段将它们分成 micro Ops(UOPs)，并且把它们排在 Allocation Queue (IDQ) 队列中。</p><p>pre-decode 主要标记指令的边界。指令的长度从 1 到 15 bytes 不等。这个阶段还 identifies branch instructions。这个阶段移动最多 6 条指令，或者称为 Macro Instructions 到 instruction queue 中。instruction queue is split between the two threads. instruction queue 中有个 macro-op fusion unit，可以检测两个 macroinstructions 是否可以 fuse 为一个指令、</p><p>一个周期中，最多5个被 pre-decode 完毕的指令会被发送到 instruction queue，同样是两个线程轮流分享这个接口。Decoder 将复杂的 macro-Op 转化为固定长度的 UOP，也就是上文提到的 micro Op。Decoder 是 5-way 的。</p><p>前端主要的性能提升组件是 Decoded Stream Buffer (DSB)，或者称为 UOP Cache。它的目的是将 macro Op 到 UOP 的转换保存在单独的 DSB 结构中。在取指阶段，会先在 DSB 查询。频繁执行的 macro op 会命中 DSB，pipeline 就能够避免昂贵的 pre-decode 和 decode 环节。</p><p>DSB 提供 6 个 UOP，这个和前端到后端的接口匹配。DSB 和 BPU 也就是 branch prediction unit 协同工作。</p><p>一些非常复杂的指令需要超过 decoder 能够处理的 UOP，它们就会被送给 Microcode Sequencer (MSROM) 处理。这些命令包含字符串处理、加密、同步等指令。另外，MSROM 也会保存 microcode operation，以便处理分支预测出错（需要刷新 pipeline），或者 floating-point 等异常情况。 </p><p>Instruction Decode Queue (IDQ) 是在 inorder 的前端和 OOO 的后端之间的桥梁。每个 hardware thread 上 IDQ 大小 64 个 UOP，总计大小 128 UOP。</p><h3 id="CPU-Back-End"><a href="#CPU-Back-End" class="headerlink" title="CPU Back-End"></a>CPU Back-End</h3><p>后端是一些 OOO engine，执行指令并且存储结果。<br>后端的心脏是一个 ReOrder Buffer，即 ROB，它有 224 条 entry。它的功能：</p><ol><li>维护 architecture-visible registers 到 physical registers 的映射。这个映射被 Reservation Station/Scheduler (RS) 使用。</li><li>支持 register renaming。</li><li>记录 speculative execution。</li></ol><p>ROB entry 按照 program order retire。</p><p>Reservation Station/Scheduler (RS) 结构记录一个 UOP 所使用的所有资源的 availablility。一旦这些资源满足了，就会将这个 UOP dispatch 到某一个 port。因为 the core（不知道指的是什么）是 8-way superscalar，所以 RS 在一个 cycle 中可以 dispatch 最多 8 个 UOP。如上面图 14 所示，这些 Port 分别支持不同的操作：</p><ul><li>Ports 0, 1, 5, and 6 provide all the integer, FP, and vector ALU. UOPs dispatched to those ports do not require memory operations.</li><li>Ports 2 and 3 are used for address generation and for load operations.</li><li>Port 4 is used for store operations.</li><li>Port 7 is used for address generation.</li></ul><h3 id="Performance-Monitoring-Unit"><a href="#Performance-Monitoring-Unit" class="headerlink" title="Performance Monitoring Unit"></a>Performance Monitoring Unit</h3><h4 id="Performance-Monitoring-Counters"><a href="#Performance-Monitoring-Counters" class="headerlink" title="Performance Monitoring Counters"></a>Performance Monitoring Counters</h4><p>这也就是后面在 Sampling 中提到的 PMC。PMC 会收集 CPU 中各个组件的统计信息。<br><img src="/img/patmc/3.16.png"></p><p>一般来说，PMC 有 48bit 宽，这样可以允许分析工具能够跑更长时间，而不至于被中断触发。这是因为当 PMC overflow 的时候，程序执行会被中断，SW 需要存储 overflow 的情况。在 Sampling 章节也会进一步看到分析工具是如何利用这个特性的。</p><p>PMC 是 HW register，被实现为 Model Specific Register(MSR)。也就是具体有哪些，每种 CPU 是不一样的，并且 width 也不一定是 48bit。</p><h1 id="Terminology-and-metrics-in-performance-analysis"><a href="#Terminology-and-metrics-in-performance-analysis" class="headerlink" title="Terminology and metrics in performance analysis"></a>Terminology and metrics in performance analysis</h1><p>perf 命令或者 Intel VTune Profiler 里面的术语很难懂，本章进行介绍。</p><h2 id="Retired-vs-Executed-Instruction"><a href="#Retired-vs-Executed-Instruction" class="headerlink" title="Retired vs. Executed Instruction"></a>Retired vs. Executed Instruction</h2><ol><li>正常情况，the CPU commits results once they are available, and all precedinginstructions are already retired.</li><li>Speculative 执行，the CPU keeps their results without immediately committing their results. When the speculation turns out to be correct, the CPU unblocks such instructions and proceeds as normal. 如果预测失败，则会丢弃所有的结果，并且不 retire 它们。</li></ol><h2 id="CPU-Utilization"><a href="#CPU-Utilization" class="headerlink" title="CPU Utilization"></a>CPU Utilization</h2><p>CPU 不在跑 idle 线程的时候，即被认为是 utilize 的。</p><h2 id="CPI-amp-IPC"><a href="#CPI-amp-IPC" class="headerlink" title="CPI &amp; IPC"></a>CPI &amp; IPC</h2><p><img src="/img/patmc/cpiipc.png"></p><h2 id="UOPs-micro-ops"><a href="#UOPs-micro-ops" class="headerlink" title="UOPs (micro-ops)"></a>UOPs (micro-ops)</h2><p>Microprocessors with the x86 architecture translate complex CISC-like instructions into simple RISC-like59 microoperations - abbreviated µops or uops. 这里 CISC 指的是 Complex Instruction Set Computer。RISC 指的是 Reduced Instruction Set Computer。</p><p>这个转换的好处在于，UOP 可以被 OOO 地执行。一个简单的加法指令，例如 ADD EXA,EBX 只会产生一个 UOP。而一个复杂的指令，例如 ADD EAX,[MEM1] 可能生成两个 UOP，一个用来读内存到一个临时的，没有名字的寄存器中，另一个指令将这个临时寄存器中的数字加到 EAX 中。同理，ADD [MEM1],EAX 会产生三个 UOP，一个读内存，一个加，一个写内存。不同的 CPU 处理这些指令，比如如何将它们划分为不同的 UOP 的方式，是不一样的。</p><p>除了将复杂的 CISC-like 的指令分解为 RISC-lick 的 UOP 或者说 microoperations 之外，还有一种策略是融合一些指令。有两种融合的类型：</p><ol><li><p>Microfusion<br> 对同一个指令中的多个 UOP 进行 fuse。如下所示，访存操作和加法在 decode 阶段被 fuse 了。</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Read the memory location [ESI] and add it to EAX</span><br><span class="line"># Two uops are fused into one at the decoding step.</span><br><span class="line">add eax, [esi]</span><br></pre></td></tr></table></figure></li><li><p>Macrofusion<br> 如下所示，一个代数计算和一个条件跳转指令被 fuse 为一个 compute-and-branch UOP 了。</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Two uops from DEC and JNZ instructions are fused into one</span><br><span class="line">.loop:</span><br><span class="line">dec rdi</span><br><span class="line">jnz .loop</span><br></pre></td></tr></table></figure></li></ol><p>Both Micro- and Macrofusion save bandwidth in all stages of the pipeline from decoding to retirement. The fused operations share a single entry in the reorder buffer (ROB). The capacity of the ROB is increased when a fused uop uses only one entry。我想这就是为什么要 fuse 指令的原因，因为它们节约了 ROB 的空间。在执行的时候，这个表示两个操作的 ROB entry 会被两个 execution units 处理，被发送到两个不同的 execution ports，但最后作为一个 unit 被 retire。</p><p>Linux perf users can collect the number of issued, executed, and retired uops for their workload by running the following command:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ perf stat -e uops_issued.any,uops_executed.thread,uops_retired.all -- a.exe</span><br><span class="line">2856278 uops_issued.any</span><br><span class="line">2720241 uops_executed.thread</span><br><span class="line">2557884 uops_retired.all</span><br></pre></td></tr></table></figure><h2 id="Pipeline-Slot"><a href="#Pipeline-Slot" class="headerlink" title="Pipeline Slot"></a>Pipeline Slot</h2><p>A pipeline slot represents hardware resources needed to process one uop.</p><h2 id="Core-vs-Reference-Cycles"><a href="#Core-vs-Reference-Cycles" class="headerlink" title="Core vs. Reference Cycles"></a>Core vs. Reference Cycles</h2><p>Reference Cycles 是 CPU 计算 cycle 数量，仿佛没有 frequency scaling 一般。相当于不 tuebo，base frequency 下运行的 cycles。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ perf stat -e cycles,ref-cycles ./a.exe</span><br><span class="line">    43340884632 cycles # 3.97 GHz</span><br><span class="line">    37028245322 ref-cycles # 3.39 GHz</span><br><span class="line">    10,899462364 seconds time elapsed</span><br></pre></td></tr></table></figure><p>The core clock cycle counter is very useful when testing which version of a piece of code is fastest because you can avoid the problem that the clock frequency goes up and down.</p><h2 id="Cache-miss"><a href="#Cache-miss" class="headerlink" title="Cache miss"></a>Cache miss</h2><h2 id="Mispredicted-branch"><a href="#Mispredicted-branch" class="headerlink" title="Mispredicted branch"></a>Mispredicted branch</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ perf stat -e branches,branch-misses -- a.exe</span><br><span class="line">358209 branches</span><br><span class="line">14026 branch-misses</span><br></pre></td></tr></table></figure><h1 id="Performance-Analysis-Approaches"><a href="#Performance-Analysis-Approaches" class="headerlink" title="Performance Analysis Approaches"></a>Performance Analysis Approaches</h1><h2 id="Code-Instrumentation"><a href="#Code-Instrumentation" class="headerlink" title="Code Instrumentation"></a>Code Instrumentation</h2><p>比如用 printf 调试，打印一个函数执行了多少次这样。这是 macro level 的，而不是 mirco level 的。<br>这个技术的主要用处是，能够快速定位到具体问题的模块。因为性能问题不仅和代码有关，也和数据有关。例如一个场景渲染比较慢，有可能是数据压缩问题，也有可能是场景元素过多。<br>当然，缺点就是只在 app 层级，到不了内核以及更下层。另外，调试代码需要重新编译，会降低性能，甚至改变现场。</p><p>Binary instrumentation 技术的特点：</p><ol><li>对二进制分析</li><li>提供 static 和 dynamic 两种模式<br> dynamic 模式可以动态开启，可以限制只对某些函数调试</li></ol><p>诸如 Intel Pin 的工具可以拦截某个事件，并且在之后插入代码。</p><ol><li>instruction count and function call counts.</li><li>intercepting function calls and execution of any instruction in an application.</li><li>allows “record and replay” the program region by capturing the memory and HW registers state at the beginning of the region.</li></ol><h2 id="Tracing"><a href="#Tracing" class="headerlink" title="Tracing"></a>Tracing</h2><p>strace 工具跟踪系统调用，可以被视作对内核的测量。Intel Processor Traces 工具跟踪 CPU 指令，可以被视作对 CPU 的测量。<br>Tracing is often used as the black-box approach, where a user cannot modify the code of the application, yet they want insight on what the program is doing behind the scenes。</p><p>Tracing 用来检查异常。例如一个系统十秒都不响应了，这个时候，Code Instrumentation 可能就不管用，但 tracing 可以去了解到底发生了什么。</p><h2 id="Workload-Characterization"><a href="#Workload-Characterization" class="headerlink" title="Workload Characterization"></a>Workload Characterization</h2><p>Workload characterization is a process of describing a workload by means of quantitative parameters and functions。</p><h3 id="Counting-Performance-Events"><a href="#Counting-Performance-Events" class="headerlink" title="Counting Performance Events"></a>Counting Performance Events</h3><p>用一个 Counter 记录在跑一个 workload 时，某个事件在一段时间内发生的次数。</p><h3 id="Manual-performance-counters-collection"><a href="#Manual-performance-counters-collection" class="headerlink" title="Manual performance counters collection"></a>Manual performance counters collection</h3><p>一般来说，不建议直接观察 PMC，而是使用 Intel Vtune Profiler 去看一个处理后的结果。</p><p>可以通过 perf list 查看可以访问的 PMC。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ perf list</span><br><span class="line">branches [Hardware event]</span><br><span class="line">branch-misses [Hardware event]</span><br><span class="line">bus-cycles [Hardware event]</span><br><span class="line">cache-misses [Hardware event]</span><br><span class="line">cycles [Hardware event]</span><br><span class="line">instructions [Hardware event]</span><br><span class="line">ref-cycles [Hardware event]</span><br></pre></td></tr></table></figure><p>对于没列出的，可以使用下面的来检查</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">perf stat -e cpu/event=0xc4,umask=0x0,name=BR_INST_RETIRED.ALL_BRANCHES/</span><br><span class="line">-- ./a.exe</span><br></pre></td></tr></table></figure><h3 id="Multiplexing-and-scaling-events"><a href="#Multiplexing-and-scaling-events" class="headerlink" title="Multiplexing and scaling events"></a>Multiplexing and scaling events</h3><p>考虑到有时候需要同时记录多个事件，但只有一个 counter。所以 PMU 会为每个 HW 线程提供四个 counter。但可能还是不够。<br>Top-Down Analysis Methodology (TMA) 需要一次执行过程中收集最多 100 个不同的 performance event。<br>这个时候，就引入了 multiplexing 技术，如下图所示。<br><img src="/img/patmc/5.19.png"></p><h2 id="Sampling"><a href="#Sampling" class="headerlink" title="Sampling"></a>Sampling</h2><p>人们常常用 profiling 这个词去指代 sampling，但其实 profiling 这个词包含的范围更广。</p><h3 id="User-Mode-And-Hardware-Event-based-Sampling"><a href="#User-Mode-And-Hardware-Event-based-Sampling" class="headerlink" title="User-Mode And Hardware Event-based Sampling"></a>User-Mode And Hardware Event-based Sampling</h3><p>User-mode sampling 是个 SW 方案，也就是在用户程序中 embed 一个库。这个库会为每个线程设置 OS timer，在 timer 超时的时候，程序会收到 SIGPROF 信号。<br>EBS 是一个 HW 方案，它使用 PMC 去触发中断。</p><p>SW 方案只能被用来发现热点。而 HW 方案还可以被用来采样 cache miss，TMA(section 6.1) 等。</p><p>SW 方案的 overhead 更大。HW 方案更准确，因为允许采样更多的数据。</p><h3 id="Finding-Hotspots"><a href="#Finding-Hotspots" class="headerlink" title="Finding Hotspots"></a>Finding Hotspots</h3><p>下面的一个技术使用了 counter overflow 技术。也就是当 counter 溢出的时候，触发 performance monitoring interrupt(PMI)。<br><img src="/img/patmc/5.25.png"></p><p>我们不一定要 sample CPU cycle，例如如果要检查程序中哪里出现了最多的 L3 cache miss，就可以 sample <code>MEM_LOAD_RETIRED.L3_MISS</code> 这个事件。</p><p>流程如下：</p><ol><li>配置 PMC 去计算某项指标，例如 cycle 数</li><li>在执行过程中，PMC 会递增</li><li>PMC 最终会 overflow，HW 会触发 PMI</li><li>Profile 工具会抓住中断，并使用配置了的 Interrupt Service Routine(ISR) 去处理这个事件<ul><li>禁止掉 counting</li><li>reset counter 到 N</li><li>继续 benchmark 过程</li></ul></li></ol><p>通过 N 的不同取值，可以决定采样的频率。</p><h3 id="Collecting-Call-Stacks"><a href="#Collecting-Call-Stacks" class="headerlink" title="Collecting Call Stacks"></a>Collecting Call Stacks</h3><p>常见情况是，最热点的函数是被多个 caller 调用的。这个时候就需要知道是 Control Flow Graph (CFG) 里面的哪一条路径导致的。想要去追踪 foo 的所有 caller 是很耗时的，但我们只是想最终那些导致 foo 变成 hotspot 的，或者说是想找到 CFG 中经过 foo 的最热的路径。</p><p>下面三种方法：</p><ol><li>Frame pointer<br> perf record –call-graph fp<br> 这需要二进制被以 -fnoomit-frame-pointer 形式编译。历史上，Frame pointer 也就是 BP 寄存器被用来 debug，是因为它允许 get the call stack without popping all the arguments from the stack(stack unwinding)。Frame pointer 可以直接告诉我们 return address。</li><li>DWARF debug info<br> perf record –call-graph dwarf<br> 这需要程序被按照 -g (-gline-tables-only) 形式编译。</li><li>Intel Last Branch Record (LBR)<br> perf record –call-graph lbr<br> 这种方式得到的 call graph 的深度不如前面两者。</li></ol><h3 id="Flame-graph"><a href="#Flame-graph" class="headerlink" title="Flame graph"></a>Flame graph</h3><p>相比上面提到的，一个更流行的办法是火焰图。</p><h2 id="Roofline-Performance-Model"><a href="#Roofline-Performance-Model" class="headerlink" title="Roofline Performance Model"></a>Roofline Performance Model</h2><p>这里的 roofline 指的是应用程序的性能不会超过机器本身的容量。每个函数或者每个循环都会被机器本身的计算或者内存容量所限制。</p><p>HW 有两方面限制：</p><ol><li>它可以算多快<br> FLOPS</li><li>它可以多快传输数据<br> GB/s</li></ol><p>一个程序的不同部分，会有不同的 performance characteristics。<br><img src="/img/patmc/5.24.png"></p><p>Arithmetic Intensity (AI) is a ratio between FLOPS and bytes and can be extracted for every loop in a program。不妨对下面的代码来算一下。在最内层循环有一个加法和一个乘法，所以是 2FLOPS。另外，还有三个读操作和一个写操作，所以传输了 <code>4 * 4 = 16</code> 字节。所以 AI 是 <code>2 / 16 = 0.125</code>。这作为图表的横轴。</p><p><img src="/img/patmc/l8.png"></p><p>一般来说，提高程序性能可以分为 vectorization、memory、threading 三个方面。Roofline methodology 可以帮助评估应用的特征。如下所示，在 roofline 图表上，我们可以画出单核、SIMD 单核和 SIMD 多核的性能。因此可以借助于图表来判断优化方向。AI 越高，说明越是 CPU bound 的，就越要考虑 CPU 方面的优化。Vectorization 和 threading 的操作一般能够让图表中的点上移，而 optimize memory access 的操作一般能够将点右移，也可能能将点上移。</p><p><img src="/img/patmc/5.25.png"></p><p>Roffline 分析可以进行前后的对比，如下所示，在执行完交换内外循环，以及 vectorize 后，性能发生了提高。<br><img src="/img/patmc/5.25.png"></p><h2 id="Static-Performance-Analysis"><a href="#Static-Performance-Analysis" class="headerlink" title="Static Performance Analysis"></a>Static Performance Analysis</h2><h2 id="Compiler-Optimization-Reports"><a href="#Compiler-Optimization-Reports" class="headerlink" title="Compiler Optimization Reports"></a>Compiler Optimization Reports</h2><h1 id="CPU-Features-For-Performance-Analysis"><a href="#CPU-Features-For-Performance-Analysis" class="headerlink" title="CPU Features For Performance Analysis"></a>CPU Features For Performance Analysis</h1><p>通常来说，profiling 能够快速发现应用程序的 hotspots。例如考虑 profile 一个函数，你觉得它应该是 cold 的，但你发现它实际花了很长时间并且被调用了很多次。所以你可以使用 cache 等技术来减少调用的次数，从而提高性能。</p><p>当主要的性能优化点都被处理后，就需要 CPU的支持来发现新的性能瓶颈了。所以在了解本章之前，需要先确保程序没有主要的性能问题。</p><p>现代 CPU 提供新的特性来辅助性能分析，这些特性可以用来发现 cache miss 或者 branch misprediction。这些措施包括：</p><ol><li>Top-Down Microarchitecture Analysis Methodology (TMA)<br> 特征化出 workload 的瓶颈，并且能够在源码中进行定位。</li><li>Last Branch Record (LBR)<br> 持续地记录最近的 branch outcomes。被用来记录 call stacks，识别 hot branch，计算 misprediction rates of individual branches。</li><li>Processor Event-Based Sampling (PEBS)</li><li>Intel Processor Traces (PT)<br> 能够回放程序的执行。</li></ol><h2 id="Top-Down-Microarchitecture-Analysis"><a href="#Top-Down-Microarchitecture-Analysis" class="headerlink" title="Top-Down Microarchitecture Analysis"></a>Top-Down Microarchitecture Analysis</h2><p><img src="/img/patmc/6.28.png"></p><h1 id="Part-2-的说明"><a href="#Part-2-的说明" class="headerlink" title="Part 2 的说明"></a>Part 2 的说明</h1><p>In part 2, we will take a look at how to use CPU monitoring features (see section 6) to find the places in the code which can be tuned for execution on a CPU. For performance-critical applications like large distributed cloud services, scientific HPC software, ‘AAA’ games, etc. it is very important to know how underlying HW works.</p><p>面对 performance-critical 负载时，一些经典算法未必有效。例如链表并不适合用来处理 flat 的数据。原因是需要逐节点动态分配，并且每个元素是零散分布在内存中的。</p><p>Some data structures, like binary trees, have natural linked-list-like representation, so it might be tempting to implement them in a pointer chasing manner. However, more efficient “flat” versions of those data structures exist, see boost::flat_map, boost::flat_set.</p><p>另一方面，即使算法是最好的，但它未必对某些特定的 case 是最好的。例如对有序数组使用二分查找是最优的，但他的 branch miss 很高，因为是 50-50 的失败率。因此对于短数组，常常是线性查找。</p><p>在讲解 CPU 微架构的优化前，先列出一些更高层级的优化方案：</p><ol><li>If a program is written using interpreted languages (python, javascript, etc.), rewrite its performance-critical portion in a language with less overhead.</li><li>Analyze the algorithms and data structures used in the program, see if you can find better ones.</li><li>Tune compiler options. Check that you use at least these three compiler flags: -O3 (enables machine-independent optimizations), -march (enables optimizations for particular CPU generation), -flto (enables inter-procedural optimizations).</li><li>If a problem is a highly parallelizable computation, make it threaded, or consider running<br>it on a GPU.</li><li>Use async IO to avoid blocking while waiting for IO operations.</li><li>Leverage using more RAM to reduce the amount of CPU and IO you have to use (memoization, look-up tables, caching of data, compression, etc.)</li></ol><p>此外，并不是所有的优化方式都对每个平台有效。例如 <a href="https://en.wikipedia.org/wiki/Loop_nest_optimization" target="_blank" rel="noopener">loop blocking</a> 对 memory hierarchy 很敏感，特别是 L2 和 L3 的大小。loop blocking 优化就是如果两层循环都比较大，那么可能内层循环中的元素会在一轮中被 evict 掉，从而导致外层循环在下轮中重新加载。通过重排循环，可以减少重新加载的次数。可以详细看 <a href="https://zhuanlan.zhihu.com/p/292539074" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/292539074</a> 的解读。</p><h2 id="Data-Driven-Optimizations"><a href="#Data-Driven-Optimizations" class="headerlink" title="Data-Driven Optimizations"></a>Data-Driven Optimizations</h2><p>Data-Driven 优化的一个经典案例是 Structure-Of-Array to Array-Of-Structures (SOA-to-AOS)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line"><span class="keyword">int</span> a[N];</span><br><span class="line"><span class="keyword">int</span> b[N];</span><br><span class="line"><span class="keyword">int</span> c[N];</span><br><span class="line"><span class="comment">// many other fields</span></span><br><span class="line">&#125;;</span><br><span class="line">&lt;=&gt;</span><br><span class="line">struct S &#123;</span><br><span class="line"><span class="keyword">int</span> a;</span><br><span class="line"><span class="keyword">int</span> b;</span><br><span class="line"><span class="keyword">int</span> c;</span><br><span class="line"><span class="comment">// many other fields</span></span><br><span class="line">&#125;;</span><br><span class="line">S s[N];</span><br></pre></td></tr></table></figure><p>如何选择取决于数据的读取模式，我理解类似于行存和列存的区别：</p><ol><li>If the program iterates over the data structure and only accesses field b, then SOA is better because all memory accesses will be sequential (spatial locality). </li><li>If the program iterates over the data structure and does excessive operations on all the fields of the object (i.e. a, b, c), then AOS is better because it’s likely that all the members of the structure will reside in the same cache line. It will additionally better utilize the memory bandwidth since fewer cache line reads will be required.</li></ol><p>Data-Driven 优化的另一个案例是 Small Size optimization。也就是提前分配一些内存，用来减少后续的动态内存分配开销。</p><h1 id="CPU-Front-End-Optimizations"><a href="#CPU-Front-End-Optimizations" class="headerlink" title="CPU Front-End Optimizations"></a>CPU Front-End Optimizations</h1><p>CPU Front-End (FE) component is discussed in section 3.8.1. Most of the time, inefficiencies in CPU FE can be described as a situation when Back-End is waiting for instructions to execute, but FE is not able to provide them. As a result, CPU cycles are wasted without doing any actual useful work. Because modern processors are 4-wide (i.e., they can provide four uops every cycle), there can be a situation when not all four available slots are filled. This can be a source of inefficient execution as well. In fact, IDQ_UOPS_NOT_DELIVERED performance event is counting how many available slots were not utilized due to a front-end stall. TMA uses this performance counter value to calculate its “Front-End Bound” metric.</p><h2 id="Machine-code-layout"><a href="#Machine-code-layout" class="headerlink" title="Machine code layout"></a>Machine code layout</h2><p>Assembly instructions will be encoded and laid out in memory consequently. This is what is called machine code layout.</p><h2 id="Basic-Block"><a href="#Basic-Block" class="headerlink" title="Basic Block"></a>Basic Block</h2><p>A basic block is a sequence of instructions with a single entry and single exit.<br>一个 basic block 中的代码会并且只会被执行一次，所以可以减少 control flow graph analysis and transformations。</p><h2 id="Basic-block-placement"><a href="#Basic-block-placement" class="headerlink" title="Basic block placement"></a>Basic block placement</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// hot path</span></span><br><span class="line"><span class="keyword">if</span> (cond)</span><br><span class="line">    coldFunc();</span><br><span class="line"><span class="comment">// hot path again</span></span><br></pre></td></tr></table></figure><p><img src="/img/patmc/7.41.png"></p><p>原因：</p><ol><li>Not taken branches are fundamentally cheaper than taken.<br> In the general case, modern Intel CPUs can execute two untaken branches per cycle but only one taken branch every two cycles.</li><li>右边这幅图能够更好地利用 instruction cache 和 uop cache（之前提到的 DSB）。这是因为如果把所有的 hot code 连起来，就没有 cache line fragmentation。L1I Cache 中的所有的 Cache line 都被 hot code 使用。这点对 uop cache 也是一样的，因为它的 cache 也是基于下层的 code layout。</li><li>如果 taken branch 了，CPU 的 fetch 部分也会受影响。因为它也是 fetch 连续的 16 bytes 指令的。</li></ol><p>通过指定 likely 和 unlikely 可以帮助编译器优化。如果一个分支是 unlikely 的，编译器可能选择不 inline，从而减少大小。likely 还可以在 switch 中使用。</p><h2 id="Basic-block-alignment"><a href="#Basic-block-alignment" class="headerlink" title="Basic block alignment"></a>Basic block alignment</h2><p>Skylake 的 instruction cache line 的大小是 64 bytes，下面的代码可能被编译得跨越两个 cache line。这对 CPU 前端的性能会有影响，特别是像这种小循环。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">benchmark_func</span><span class="params">(<span class="keyword">int</span>* a)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; ++i)</span><br><span class="line">        a[i] += <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面的优化通过添加 nop 指令让整个循环都在一个缓存行里面。为什么这能提高性能比较复杂，因此就不解释了。<br><img src="/img/patmc/7.42.png"></p><p>By default, the LLVM compiler recognizes loops and aligns them at 16B boundaries，就和上面图中未优化的情况一样。通过指定 <code>-mllvm -align-all-blocks</code> 可以变成优化后的样子。但是要慎重做这样的处理，因为增加 NOP 指令会影响执行时间。尽管 NOP 不执行，但是他同样需要被 fetch、解码、retire。所以需要额外地耗费在 FE 中的空间。</p><h2 id="Function-splitting"><a href="#Function-splitting" class="headerlink" title="Function splitting"></a>Function splitting</h2><p>目的是将 hot 部分和 cold 部分分离出来。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">bool</span> cond1, <span class="keyword">bool</span> cond2)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// hot path</span></span><br><span class="line">    <span class="keyword">if</span> (cond1) &#123;</span><br><span class="line">        <span class="comment">// large amount of cold code (1)</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// hot path</span></span><br><span class="line">    <span class="keyword">if</span> (cond2) &#123;</span><br><span class="line">        <span class="comment">// large amount of cold code (2)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>分离后</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">bool</span> cond1, <span class="keyword">bool</span> cond2)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// hot path</span></span><br><span class="line">    <span class="keyword">if</span> (cond1)</span><br><span class="line">        cold1();</span><br><span class="line">    <span class="comment">// hot path</span></span><br><span class="line">    <span class="keyword">if</span> (cond2)</span><br><span class="line">        cold2();</span><br><span class="line">&#125;</span><br><span class="line">void cold1() __attribute__((noinline)) &#123; // cold code (1) &#125;</span><br><span class="line">void cold2() __attribute__((noinline)) &#123; // cold code (2) &#125;</span><br></pre></td></tr></table></figure><p>如下图所示，因为在 hot path 中只保留了 CALL，所以下一条指令很有可能在同一个 cache line 里面。这也说明了，对冷代码而言，应该避免它被 inline。<br><img src="/img/patmc/7.43.png"></p><p>特别地，冷函数可以被放在 .text.old 中，从而避免在运行时加载。</p><h2 id="Function-grouping"><a href="#Function-grouping" class="headerlink" title="Function grouping"></a>Function grouping</h2><p>Figure 44 gives a graphical representation of grouping foo, bar, and zoo. The default layout (see fig. 44a) requires four cache line reads, while in the improved version (see fig. 44b), code of foo, bar and zoo fits in only three cache lines. Additionally, when we call zoo from foo, the beginning of zoo is already in the I-cache since we fetched that cache line already.</p><p><img src="/img/patmc/7.44.png"></p><p>和之前一样，function grouping 能提高 I-Cache 和 DSB-cache 的效率。</p><p>使用 ld.gold 链接器来指定顺序：</p><ol><li><code>-ffunction-sections</code> flag, which will put each function into a separate section.</li><li><code>--section-ordering-file=order.txt</code> option should be used to provide a file with a sorted list of function names that reflects the desired final layout.</li></ol><p>一个叫 HFSort 的工具可以帮助 group function。</p><h2 id="Profile-Guided-Optimizations"><a href="#Profile-Guided-Optimizations" class="headerlink" title="Profile Guided Optimizations"></a>Profile Guided Optimizations</h2><h2 id="Optimizing-for-ITLB"><a href="#Optimizing-for-ITLB" class="headerlink" title="Optimizing for ITLB"></a>Optimizing for ITLB</h2><p>Virtual-to-physical address translation of memory address 也影响了 CPU FE 的效率。通常，这是被 TLB 来处理，TLB 会缓存最近的地址。When TLB cannot serve translation request, a time-consuming page walk of the kernel page table takes place to calculate the correct physical address for each referenced virtual address.</p><p>如果 TMA 指示了 high ITLB overhead，那么下面的内容就很重要：</p><ol><li>将一些 performance-critical code 中的部分映射到较大的 page 中。</li><li>使用一些标准的 I-cache performance 优化办法，例如 reorder 函数让 hot 函数更为 collocated。或者通过 LTO 或者 IPO 技术减少 hot region 的大小。或者使用 profile guided optimization。或者使用激进的 inline 技术。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="/img/patmc/t6.png"></p><h1 id="CPU-Back-End-Optimizations"><a href="#CPU-Back-End-Optimizations" class="headerlink" title="CPU Back-End Optimizations"></a>CPU Back-End Optimizations</h1><p>Most of the time, inefficiencies in CPU BE can be described as a situation when FE has fetched and decoded instructions, but BE is overloaded and can’t handle new instructions. Technically speaking, it is a situation when FE cannot deliver uops due to a lack of required resources for accepting new uops in the Backend. An example of it may be a stall due to data-cache miss or a stall due to the divider unit being overloaded.<br>I want to emphasize to the reader that it’s recommended to start looking into optimizing code for CPU BE only when TMA points to a high “Back-End Bound” metric. TMA further divides the Backend Bound metric into two main categories: Memory Bound and Core Bound, which we will discuss next.</p><h2 id="Memory-Bound"><a href="#Memory-Bound" class="headerlink" title="Memory Bound"></a>Memory Bound</h2><p>如下图所示，截止 2010 年，CPU 的提升比内存的提升要快很多。【Q】最近还是这样么？<br><img src="/img/patmc/8.45.png"></p><p>通过 TMA，Memory Bound estimates a fraction of slots where the CPU pipeline is likely stalled due to demand load or store instructions。</p><h3 id="Cache-Friendly-Data-Structures"><a href="#Cache-Friendly-Data-Structures" class="headerlink" title="Cache-Friendly Data Structures"></a>Cache-Friendly Data Structures</h3><p>A variable can be fetched from the cache in just a few clock cycles, but it can take more than a hundred clock cycles to fetch the variable from RAM memory if it is not in the cache.<br>下面一张图展示了各个 CPU 操作的耗时。<br><img src="/img/patmc/ext1.png"></p><p>Cache-friendly code 的关键是 temporal 和 spatial locality。</p><h4 id="Access-data-sequentially"><a href="#Access-data-sequentially" class="headerlink" title="Access data sequentially"></a>Access data sequentially</h4><p>让 HW Prefetcher 感知到我们在顺序访问，从而提前取出下一个 chunk 的数据。<br>下面代码之所以是 cache friendly 的，是因为它的访问模式和它存储的 layout 是一致的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (row = <span class="number">0</span>; row &lt; NUMROWS; row++)</span><br><span class="line">    <span class="keyword">for</span> (column = <span class="number">0</span>; column &lt; NUMCOLUMNS; column++)</span><br><span class="line">        matrix[row][column] = row + column;</span><br></pre></td></tr></table></figure><p>又比如，传统的二分查找算法并没有很好的空间局部性，因为它会测试彼此之间相距很远的元素，这些元素可能在不同的 cache line 上。一个解决方案是使用 <a href="https://en.algorithmica.org/hpc/data-structures/binary-search/" target="_blank" rel="noopener">Eytzinger layout</a>。我理解就是存在一个类似二叉堆的结构中。</p><h4 id="Use-appropriate-containers"><a href="#Use-appropriate-containers" class="headerlink" title="Use appropriate containers"></a>Use appropriate containers</h4><p>或者说是在 array 中直接存对象，还是存指针。如果排序，适合存指针。如果仅仅是线性遍历，适合存对象。</p><h4 id="Packing-the-data"><a href="#Packing-the-data" class="headerlink" title="Packing the data"></a>Packing the data</h4><ol><li>位域</li><li>重新排列 field 以减少 padding 和 aligning 带来的内存浪费 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S1</span> &#123;</span></span><br><span class="line">    <span class="keyword">bool</span> b;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">short</span> s;</span><br><span class="line">&#125;; <span class="comment">// S1 is sizeof(int) * 3</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S2</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">short</span> s;</span><br><span class="line">    <span class="keyword">bool</span> b;</span><br><span class="line">&#125;; <span class="comment">// S2 is sizeof(int) * 2</span></span><br></pre></td></tr></table></figure></li></ol><h4 id="Aligning-and-padding"><a href="#Aligning-and-padding" class="headerlink" title="Aligning and padding"></a>Aligning and padding</h4><p>比如，一个 16 bytes 的对象可能占用两个 cache line。读取这样的对象需要读两次 cache line。</p><p>A variable is accessed most efficiently if it is stored at a memory address, which is divisible by the size of the variable.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Make an aligned array</span></span><br><span class="line">alignas(<span class="number">16</span>) <span class="keyword">int16_t</span> a[N];</span><br><span class="line"><span class="comment">// Objects of struct S are aligned at cache line boundaries</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CACHELINE_ALIGN alignas(64)</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">CACHELINE_ALIGN</span> <span class="title">S</span> &#123;</span></span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>Padding 技术还可以备用来解决 cache contention 和 false sharing 问题。</p><p>For example, false sharing issues might occur in multithreaded applications when two threads, A and B, access different fields of the same structure. An example of code when such a situation might happen is shown on Listing 24. Because a and b members of struct S could potentially occupy the same cache line, cache coherency issues might significantly slow down the program.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> a; <span class="comment">// written by thread A</span></span><br><span class="line">    <span class="keyword">int</span> b; <span class="comment">// written by thread B</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>通过 padding 来解决伪共享</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CACHELINE_ALIGN alignas(64)</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> a; <span class="comment">// written by thread A</span></span><br><span class="line">    CACHELINE_ALIGN <span class="keyword">int</span> b; <span class="comment">// written by thread B</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>When it comes to dynamic allocations via malloc, it is guaranteed that the returned memory address satisfies the target platform’s minimum alignment requirements. Some applications might benefit from a stricter alignment. For example, dynamically allocating 16 bytes with a 64 bytes alignment instead of the default 16 bytes alignment. In order to leverage this, users of POSIX systems can use memalign API.</p><h4 id="Dynamic-memory-allocation"><a href="#Dynamic-memory-allocation" class="headerlink" title="Dynamic memory allocation"></a>Dynamic memory allocation</h4><ol><li>使用诸如 jemalloc 或者 tcmalloc 的实现</li><li>使用 custom allocator<br> 例如 arena allocator。这样 allocator 不需要在每次分配的时候都 sys call。<br> 另外，也更灵活，支持不同的策略。比如冷数据一个 arena，热数据一个 arena。将热数据放一起可以有机会共享 cache line。从而提高内存贷款和 spatial locality。同时还可以提高 TLB 利用率，因为 hot data 会占用更少的 page。<br> 此外，还是 thread-aware 的，可以实现 thread local 的分配策略，从而避免线程间的同步。</li></ol><h4 id="Tune-the-code-for-memory-hierarchy"><a href="#Tune-the-code-for-memory-hierarchy" class="headerlink" title="Tune the code for memory hierarchy"></a>Tune the code for memory hierarchy</h4><p>这里还是 loop blocking 的例子。也就是将 matrix 切成多个小块，让每一块能够被装在 L2 cache 里面。</p><h3 id="Explicit-Memory-Prefetching"><a href="#Explicit-Memory-Prefetching" class="headerlink" title="Explicit Memory Prefetching"></a>Explicit Memory Prefetching</h3><p>如下代码所示，如果 calcNextIndex 返回的是很随机的数字，那么 arr[j] 会频繁 cache miss。如果 arr 很大，那么 HW prefetcher 就不能去识别 pattern，然后 prefetch。<br>因为在计算 j 和访问 arr[j] 之间有不少操作，所以可以借助 <code>__builtin_prefetch</code> 来 prefetch。这也是要点，一定要提前足够的时间。但也不能提前太多，从而污染 cache。在后面的 6.2.5 节中会介绍如何选择。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">    <span class="keyword">int</span> j = calcNextIndex();</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    doSomeExtensiveComputation();</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    x = arr[j]; <span class="comment">// this load misses in L3 cache a lot</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一般比较通用的是提前获取下一个 iter 的数据</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">    <span class="keyword">int</span> j = calcNextIndex();</span><br><span class="line">    __builtin_prefetch(a + j, <span class="number">0</span>, <span class="number">1</span>); <span class="comment">// well before the load</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    doSomeExtensiveComputation();</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    x = arr[j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需要注意，Explicit Memory Prefetching 不是 portable 的。可能在别的平台上反而会让性能变差。Consider a situation when we want to insert a prefetch instruction into the piece of code that has average IPC=2, and every DRAM access takes 100 cycles. To have the best effect, we would need to insert prefetching instruction 200 instructions before the load. It is not always possible, especially if the load address is computed right before the load itself. The pointer chasing problem can be a good example when explicit prefetching is helpless.</p><p>另外，prefetch 指令会加重 CPU 前端的开销。</p><h3 id="Optimizing-For-DTLB"><a href="#Optimizing-For-DTLB" class="headerlink" title="Optimizing For DTLB"></a>Optimizing For DTLB</h3><p>如前介绍，TLB is a fast but finite per-core cache for virtual-to-physical address translations of memory addresses. 没有它，每次内存访问都需要去遍历内核的 page table，然后计算出正确的 physical address。</p><p>TLB 由 L1 ITLB(instructions)、L1 DTLB(data) 和 L2 STLB(shared by data and instructions) 组成。L1 ITLB 的 cache miss 的惩罚很小，通常能够被 OOO 执行掩盖掉。L2 STLB 的 cache miss 就会导致遍历内核的 page table 了。这个 penalty 是可被观测的，因为这段时间 CPU 是 stall 的。假设 Linux 的默认 page size 是 4KB，L1 TLB 只能够存几百个 entry，覆盖大约 1MB 的地址空间。L2 STLB 覆盖大概一千多个。</p><p>一种减少 ITLB cache miss 的方案是使用更大的 page size。TLB 也支持使用 2MB 和 1GB 的 page。</p><p>Large memory applications such as relational database systems (e.g., MySQL, PostgreSQL, Oracle, etc.) and Java applications configured with large heap regions frequently benefit from using large pages.</p><p>On Linux OS, there are two ways of using large pages in an application: Explicit and Transparent Huge Pages.</p><h4 id="Explicit-Hugepages"><a href="#Explicit-Hugepages" class="headerlink" title="Explicit Hugepages"></a>Explicit Hugepages</h4><p>用户可以通过 mmap 等指令去访问。可以通过 <code>cat /proc/meminfo</code> 并检查 <code>HugePages_Total</code> 来检查相关配置。</p><p>Huge page 可以在系统启动，或者运行的时候被保留。在启动期间保留的成功率更高，因为此时系统的内存空间没有被显著碎片化(fragmented)。</p><p>可以通过 libhugetlbfs 来 override 掉 malloc 调用。只需要调整环境变量酒席了。</p><ol><li>mmap using the MAP_HUGETLB flag<br> <a href="https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/map_hugetlb.c" target="_blank" rel="noopener">https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/map_hugetlb.c</a></li><li>mmap using a file from a mounted hugetlbfs filesystem<br> <a href="https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/hugepage-mmap.c" target="_blank" rel="noopener">https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/hugepage-mmap.c</a></li><li>shmget using the SHM_HUGETLB flag<br> <a href="https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/hugepage-shm.c" target="_blank" rel="noopener">https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/hugepage-shm.c</a></li></ol><h4 id="Transparent-Hugepages"><a href="#Transparent-Hugepages" class="headerlink" title="Transparent Hugepages"></a>Transparent Hugepages</h4><p>Linux also offers Transparent Hugepage Support(THP)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">always [madvise] never</span><br></pre></td></tr></table></figure><p>always 表示 system wide，madvise 表示 per process。</p><h4 id="Explicit-vs-Transparent-Hugepages"><a href="#Explicit-vs-Transparent-Hugepages" class="headerlink" title="Explicit vs. Transparent Hugepages"></a>Explicit vs. Transparent Hugepages</h4><ol><li>Background maintenance of transparent huge pages incurs non-deterministic latency overhead from the kernel as it manages the inevitable fragmentation and swapping issues. EHP is not subject to memory fragmentation and cannot be swapped to the disk.</li><li>EHP is available for use on all segments of an application, including text segments (i.e., benefits both DTLB and ITLB), while THP is only available for dynamically allocated memory regions.</li></ol><h2 id="Core-Bound"><a href="#Core-Bound" class="headerlink" title="Core Bound"></a>Core Bound</h2><p>也就是在 OOO 执行过程中所有不是因为内存原因造成的 stall。包含：</p><ol><li>Shortage in hardware compute resources<br> 比如除法和平方根计算被 Divider Unit 处理，耗时比较长。如果这方面的操作比较多，那么就会造成 stall。</li><li>Dependencies between software’s instructions</li></ol><h3 id="Inlining-Functions"><a href="#Inlining-Functions" class="headerlink" title="Inlining Functions"></a>Inlining Functions</h3><p>它不仅能够去掉调用函数的开销，同时也让其他优化变为可能。因为此时编译期能看到更多的代码。<br>对 LLVM 编译期而言，基于 computing cost 和 a threshold for each function call(callsite) 来计算。如果 cost 比 threshold 更低，就会 inline。</p><p>threshold 的选取通常是固定的，一般来说有一些启发式的方法：</p><ol><li>小函数基本总是会被 inline</li><li>只有一个 callsite 的函数会被倾向于 inline</li><li>大函数通常不会 inline，因为它们让 caller 变大</li></ol><p>有些不能 inline 的情况：</p><ol><li>递归函数不能 inline</li><li>Function that is referred to through a pointer can be inlined in place of a direct call but has to stay in the binary, i.e., cannot be fully inlined and eliminated. The same is true for functions with external linkage.</li></ol><p>One way to find potential candidates for inlining in a program is by looking at the profiling data, and in particular, how hot is the prologue and the epilogue of the function. 下面的 demo 中，这个函数的 profile 中体现了 prologue 和 epilogue 花费了大概 50% 的时间。这<strong>可能</strong>说明了如果我们 inline 这个函数，就能减少 prologue 和 epilogue 的开销。但这不是绝对的，因为 inline 会导致一系列变化，所以很难预测结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Overhead | Source code &amp; Disassembly</span><br><span class="line">(%) | of function `foo`</span><br><span class="line">--------------------------------------------</span><br><span class="line">3.77 : 418be0: push r15 # prologue</span><br><span class="line">4.62 : 418be2: mov r15d,0x64</span><br><span class="line">2.14 : 418be8: push r14</span><br><span class="line">1.34 : 418bea: mov r14,rsi</span><br><span class="line">3.43 : 418bed: push r13</span><br><span class="line">3.08 : 418bef: mov r13,rdi</span><br><span class="line">1.24 : 418bf2: push r12</span><br><span class="line">1.14 : 418bf4: mov r12,rcx</span><br><span class="line">3.08 : 418bf7: push rbp</span><br><span class="line">3.43 : 418bf8: mov rbp,rdx</span><br><span class="line">1.94 : 418bfb: push rbx</span><br><span class="line">0.50 : 418bfc: sub rsp,0x8</span><br><span class="line">...</span><br><span class="line"># # function body</span><br><span class="line">...</span><br><span class="line">4.17 : 418d43: add rsp,0x8 # epilogue</span><br><span class="line">3.67 : 418d47: pop rbx</span><br><span class="line">0.35 : 418d48: pop rbp</span><br><span class="line">0.94 : 418d49: pop r12</span><br><span class="line">4.72 : 418d4b: pop r13</span><br><span class="line">4.12 : 418d4d: pop r14</span><br><span class="line">0.00 : 418d4f: pop r15</span><br><span class="line">1.59 : 418d51: ret</span><br></pre></td></tr></table></figure><h3 id="Loop-Optimizations"><a href="#Loop-Optimizations" class="headerlink" title="Loop Optimizations"></a>Loop Optimizations</h3><p>通常，循环的性能被下面几点限制：</p><ol><li>memory lantency</li><li>memory bandwidth</li><li>机器的 compute capability</li></ol><p>Roofline Perfoemance Model 是评估 HW 理论最大值和不同的 loop 实际之间的方法。Top-Down Microarchitecture Analusis 是另外一个瓶颈相关的信息来源。</p><p>这一节中，首先讨论 low-level 的优化，也就是将代码在一个 loop 中移动。这样的优化方式让循环内的计算更有效率。然后是 high-level 的优化，会 restructure loops，通常会影响多个 loop。第二种优化的目的主要是提高 memory access。eliminating memory bandwidth 和 memory lantency 问题。</p><h4 id="Low-level-optimizations"><a href="#Low-level-optimizations" class="headerlink" title="Low-level optimizations"></a>Low-level optimizations</h4><p>下面这些优化通常能够提高具有 high arithmetic intensity 的 loop 的性能，比如循环是 CPU-compute-bound 的。大部分情况下，编译器能够自己做相关优化，少部分情况下，需要人工帮助。</p><h5 id="Loop-Invariant-Code-Motion-LICM"><a href="#Loop-Invariant-Code-Motion-LICM" class="headerlink" title="Loop Invariant Code Motion (LICM)"></a>Loop Invariant Code Motion (LICM)</h5><p>将循环中的不变量移出循环。<br>什么是循环中的不变量呢？ Expressions evaluated in a loop that never change are called loop invariants.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0; i &lt; N; ++i)</span><br><span class="line">    for (int j = 0; j &lt; N; ++j)</span><br><span class="line">        a[j] = b[j] * c[i]; </span><br><span class="line"></span><br><span class="line">==&gt;</span><br><span class="line"></span><br><span class="line">for (int i = 0; i &lt; N; ++i) &#123;</span><br><span class="line">    auto temp = c[i];</span><br><span class="line">    for (int j = 0; j &lt; N; ++j)</span><br><span class="line">        a[j] = b[j] * temp;</span><br></pre></td></tr></table></figure><h5 id="Loop-Unrolling"><a href="#Loop-Unrolling" class="headerlink" title="Loop Unrolling"></a>Loop Unrolling</h5><p>循环的 induction variable，也就是 for i 的那个 i，每个 iteration 去修改它的代价是比较大的。所以可以选择 unroll 一个循环。</p><p>下面的例子中，unroll the loop by a factor of 2. 从而减少了 compare 和 branch 指令的开销到原来的一半。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0; i &lt; N; ++i)</span><br><span class="line">    a[i] = b[i] * c[i];</span><br><span class="line"></span><br><span class="line">==&gt;</span><br><span class="line"></span><br><span class="line">for (int i = 0; i &lt; N; i+=2) &#123;</span><br><span class="line">    a[i] = b[i] * c[i];</span><br><span class="line">    a[i+1] = b[i+1] * c[i+1];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>作者建议不要手工展开循环：</p><ol><li>编译器很擅长做这个，并且做得很好</li><li>处理器有一个 “embedded unroller”，thanks to their OOO speculative execution engine<br> 当处理器正等待第一个 iteration 的负载完成时，它可能预先开始执行第二个 iteration 的负载了。This spans to multiple iterations ahead, effectively unrolling the loop in the instruction Reorder Buffer (ROB).</li></ol><h5 id="Loop-Strength-Reduction-LSR"><a href="#Loop-Strength-Reduction-LSR" class="headerlink" title="Loop Strength Reduction (LSR)"></a>Loop Strength Reduction (LSR)</h5><p>将开销比较大的操作换为开销更小的操作。通常和 induction variable 上的计算有关。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0; i &lt; N; ++i)</span><br><span class="line">    a[i] = b[i * 10] * c[i];</span><br><span class="line"></span><br><span class="line">==&gt;</span><br><span class="line"></span><br><span class="line">int j = 0;</span><br><span class="line">for (int i = 0; i &lt; N; ++i) &#123;</span><br><span class="line">    a[i] = b[j] * c[i];</span><br><span class="line">    j += 10;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="Loop-Unswitching"><a href="#Loop-Unswitching" class="headerlink" title="Loop Unswitching"></a>Loop Unswitching</h5><p>这个很简单，尝试能不能把 loop 中的 branch 提出来，分成两个 loop</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">for (i = 0; i &lt; N; i++) &#123;</span><br><span class="line">    a[i] += b[i];</span><br><span class="line">    if (c)</span><br><span class="line">        b[i] = 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if (c)</span><br><span class="line">    for (i = 0; i &lt; N; i++) &#123;</span><br><span class="line">        a[i] += b[i];</span><br><span class="line">        b[i] = 0;</span><br><span class="line">    &#125;</span><br><span class="line">else</span><br><span class="line">    for (i = 0; i &lt; N; i++) &#123;</span><br><span class="line">        a[i] += b[i];</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="High-level-optimizations"><a href="#High-level-optimizations" class="headerlink" title="High-level optimizations"></a>High-level optimizations</h4><p>下面的一些变换，从编译器的角度比较难合法地或者自动地进行。所以很多时候可能需要手动做。</p><h5 id="Loop-Interchange"><a href="#Loop-Interchange" class="headerlink" title="Loop Interchange"></a>Loop Interchange</h5><p>交换多层循环的 order。<br>目的是 perform sequential memory accesses to the elements of a multi-dimensional array。<br>如下所示，在一个按行存储的数组中，让 i 到内层循环的空间局部性更好。</p><p><img src="/img/patmc/l32.png"></p><h5 id="Loop-Blocking-Tiling"><a href="#Loop-Blocking-Tiling" class="headerlink" title="Loop Blocking (Tiling)"></a>Loop Blocking (Tiling)</h5><h5 id="Loop-Fusion-and-Distribution-Fission"><a href="#Loop-Fusion-and-Distribution-Fission" class="headerlink" title="Loop Fusion and Distribution (Fission)"></a>Loop Fusion and Distribution (Fission)</h5><p>Loop fusion 可以用来：</p><ol><li>减少 loop overhead，因为它会复用相同的 induction variable</li><li>可以提高 memory access 的 temporal locality<br> 如下代码中，如果 x 和 y 都位于同一个缓存行上面，那么将两个 loop fuse 在一起能够避免加载同一个缓存行两次。<br> 这样就能减少 cache footprint，并且提高 memory bandwidth utilization。</li></ol><p><img src="/img/patmc/l34.png"></p><p>相反地有 Loop Distribution 即 Loop Fission。其目的是：</p><ol><li>可以先在一个循环中 pre-filter、sort、reorg 数据</li><li>减少一个 iteration 中需要访问的数据，从而提高 memory access 的 temporal locality。这对具有较高 cache contention 的场景，也就是大 loop 中会比较有用</li><li>减少对寄存器的压力，同样是因为一个 iteration 中会执行更少的操作了</li><li>通常还可能提升 CPU FE 的性能，因为 cache utilization 会更好</li><li>编译期能够更好地优化小循环</li></ol><h4 id="Discovering-loop-optimization-opportunities"><a href="#Discovering-loop-optimization-opportunities" class="headerlink" title="Discovering loop optimization opportunities"></a>Discovering loop optimization opportunities</h4><p>如下所示，编译器不能把 strlen 移出循环体。这是因为 a 和 b 两个数组可能是 overlap 的。所以，需要通过 restrict 关键词来显式声明这两段内存不会 overlap。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">char</span>* a, <span class="keyword">char</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="built_in">strlen</span>(a); ++i)</span><br><span class="line">        b[i] = (a[i] == <span class="string">'x'</span>) ? <span class="string">'y'</span> : <span class="string">'n'</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在一些时候，编译期可以通过 compiler optimization remarks (sec 5.7) 告诉我们失败了的优化。但对于上面的情况，Clang 10 和 GCC 10 目前还都不行。目前只能通过反编译出来的代码才能看出来。</p><p>有一些指令可以配置编译器的优化行为，例如 <code>#pragma unroll(8)</code>。</p><h4 id="Use-Loop-Optimization-Frameworks"><a href="#Use-Loop-Optimization-Frameworks" class="headerlink" title="Use Loop Optimization Frameworks"></a>Use Loop Optimization Frameworks</h4><p>目前有一些框架可以检测 loop transformation 的合法性了。例如 polyhedral 框架，polyhedral 的意思是多面体。LLVM 系列也有自己的 polyheral 框架，即 Polly。LLVM 默认不启用。对于 GEMM 内核，Polly 能提供 20 倍左右的提速。</p><h3 id="Vectorization"><a href="#Vectorization" class="headerlink" title="Vectorization"></a>Vectorization</h3><p>大部分情况下，Vectorization 能够被编译器发现，然后自动发生。<br>一般来说，在编译器中完成三种 Vectorization：</p><ol><li>inner loop vectorization</li><li>outer loop vectorization</li><li>SLP (Superword-Level Parallelism) vectorization</li></ol><p>第一种最常见。</p><h4 id="Compiler-Autovectorization"><a href="#Compiler-Autovectorization" class="headerlink" title="Compiler Autovectorization"></a>Compiler Autovectorization</h4><p>阻止 Autovectorization 的情况：</p><ol><li>unsigned loop-indices 溢出</li><li>两个指针可能指向重叠的内存区间</li><li>处理器本身不支持比如 predicated (bitmask-controlled) load and store operation</li><li>vector-wide format conversion between signed integers to doubles because the result operates on vector registers of different sizes</li></ol><p>所以一般分为三步：</p><ol><li>Legality-check<br> 检查 the loop progresses linearly。<br> 确保 the memory and arithmetic operations in the loop can be widened into consecutive operations。<br> That the control flow of the loop is uniform across all lanes and that the memory access patterns are uniform。没看懂是在说什么。<br> 确保不会访问和修改不应该的内存。<br> analyze the possible range of pointers, and if it has some missing information, it has to assume that the transformation is illegal。看不懂。</li><li>Profitability-check<br> It needs to take into account the added instructions that shuffle data into registers, predict register pressure, and estimate the cost of the loop guards that ensure that preconditions that allow vectorizations are met. 我觉得作者这样说就是在让人看不懂。</li><li>Transformation</li></ol><h4 id="Discovering-vectorization-opportunities"><a href="#Discovering-vectorization-opportunities" class="headerlink" title="Discovering vectorization opportunities"></a>Discovering vectorization opportunities</h4><p>检查 compiler vectorization remarks 可以发现编译期进行了什么优化，包含是否 vectorized 了，vectorization factor(VF) 是多少。</p><h4 id="Vectorization-is-illegal"><a href="#Vectorization-is-illegal" class="headerlink" title="Vectorization is illegal"></a>Vectorization is illegal</h4><p>下面的函数不是 vectorizable 的。因为是 read-after-write dependence.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">vectorDependence</span><span class="params">(<span class="keyword">int</span> *A, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; i++)</span><br><span class="line">        A[i] = A[i<span class="number">-1</span>] * <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面的函数不是 vectorizable 的。因为是 floating-point arithmetic。一般来说，浮点数加法是可交换的，但浮点数加法不是可结合的。如果向量化，则会导致不同的 round decision，和一个不同的结果。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">calcSum</span><span class="params">(<span class="keyword">float</span>* a, <span class="keyword">unsigned</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> sum = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">unsigned</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">        sum += a[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如下所示的代码，GCC 会为其创建两个不同的版本。如果发现 a 和 b 和 c 有 overlap，则运行普通版本，否则运行 simd 版本。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">float</span>* a, <span class="keyword">float</span>* b, <span class="keyword">float</span>* c, <span class="keyword">unsigned</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">unsigned</span> i = <span class="number">1</span>; i &lt; N; i++) &#123;</span><br><span class="line">        c[i] = b[i];</span><br><span class="line">        a[i] = c[i<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -O3 -march=core-avx2 -fopt-info</span><br><span class="line">a.cpp:2:26: optimized: loop vectorized using 32 byte vectors</span><br><span class="line">a.cpp:2:26: optimized: loop versioned for vectorization because of possible</span><br><span class="line">aliasing</span><br></pre></td></tr></table></figure><h4 id="Vectorization-is-not-beneficial"><a href="#Vectorization-is-not-beneficial" class="headerlink" title="Vectorization is not beneficial"></a>Vectorization is not beneficial</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">stridedLoads</span><span class="params">(<span class="keyword">int</span> *A, <span class="keyword">int</span> *B, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">        A[i] += B[i * <span class="number">3</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Loop-vectorized-but-scalar-version-used"><a href="#Loop-vectorized-but-scalar-version-used" class="headerlink" title="Loop vectorized but scalar version used"></a>Loop vectorized but scalar version used</h4><p>一般是因为 loop trip 比较小。比如以 AVX2 来说，如果同时加上 unroll 循环的技术，假设 unroll 4-5 倍，那么一个 loop iteration 需要处理 40 个元素。所以这种情况下，会直接 fallback 到处理剩余尾数的普通循环中。<br>此时，可以强制使用更小的 vectorization factor 或者 unroll count。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> clang loop vectorize_width(N)</span></span><br></pre></td></tr></table></figure><h4 id="Loop-vectorized-in-a-suboptimal-way"><a href="#Loop-vectorized-in-a-suboptimal-way" class="headerlink" title="Loop vectorized in a suboptimal way"></a>Loop vectorized in a suboptimal way</h4><p>最优的 vectorization factor 是难以通过直觉判断的，因为存在以下因素：</p><ol><li>很难在大脑中模拟 CPU 的运行模式<br> Vector shuffles that touch multiple vector lanes could be more or less expensive than expected, depending on many factors.<br> 什么是 vector shuffle？</li><li>运行时，程序可能以非预期的方式运行，取决于 port pressure 或者其他因素<br> 人类可以通过 Vectorization pragmas 来尝试各种  vectorization factor。也可以尝试各种 unroll factor 来选出最优的。但编译器做不到。</li><li>非 vec 的版本可能更好<br> 因为 gather/scatter loads, masking, shuffle 这些向量操作更昂贵。<br> 所以也需要尝试禁用向量化比较性能。如使用 <code>-fno-vectorize</code> 和 <code>-fno-slp-vectorize</code>，或者 <code>#pragma clang loop vectorize(enable)</code>。</li></ol><h4 id="Use-languages-with-explicit-vectorization"><a href="#Use-languages-with-explicit-vectorization" class="headerlink" title="Use languages with explicit vectorization"></a>Use languages with explicit vectorization</h4><h4 id="“Close-to-the-metal”-programming-model"><a href="#“Close-to-the-metal”-programming-model" class="headerlink" title="“Close to the metal” programming model"></a>“Close to the metal” programming model</h4><p>这里说的是传统的 C 和 C++ 中没有向量化的概念，所以总是需要通过 compiler intrinsics 来做这个工作。而像 ISPC 这样的语言中 <code>+=</code> 这样的操作符会被隐式地认为是 SIMD 操作，并会并行的执行多个加法。</p><h1 id="Optimizing-Bad-Speculation"><a href="#Optimizing-Bad-Speculation" class="headerlink" title="Optimizing Bad Speculation"></a>Optimizing Bad Speculation</h1><p>Mispredicting a branch can add a significant speed penalty when it happens regularly. When such an event happens, a CPU is required to clear all the speculative work that was done ahead of time and later was proven to be wrong. It also needs to flush the whole pipeline and start filling it with instructions from the correct path. Typically, modern CPUs experience a 15-20 cycles penalty as a result of a branch misprediction.</p><p>现在的处理器能够进行分支预测，不仅仅是静态的规则，甚至可以发现动态的模式。</p><p>我们可以通过 TMA Bad Speculation 指标来查看一个程序在多大程度上收到分支预测的影响。对此，作者推荐只有当分支预测失败率在 10% 以上的时候，再进行关注。</p><p>从前，可以在分治命令前加上前缀 0x2E 或者 0x3E 来分别表示是否选择这个分支。但随着后面分支预测机制的完善，这个功能被去掉了。所以目前唯一能够避免分支预测失败的<strong>直接</strong>办法是不使用分支。下面介绍两种避免分支的办法。</p><p>注：likely 和 unlikely 是通过放置可能性较大的指令到靠近分支跳转指令<a href="https://zhuanlan.zhihu.com/p/357434227" target="_blank" rel="noopener">来实现优化</a>的。</p><h2 id="Replace-branches-with-lookup"><a href="#Replace-branches-with-lookup" class="headerlink" title="Replace branches with lookup"></a>Replace branches with lookup</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">mapToBucket</span><span class="params">(<span class="keyword">unsigned</span> v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (v &gt;= <span class="number">0</span> &amp;&amp; v &lt; <span class="number">10</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (v &gt;= <span class="number">10</span> &amp;&amp; v &lt; <span class="number">20</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (v &gt;= <span class="number">20</span> &amp;&amp; v &lt; <span class="number">30</span>) <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> (v &gt;= <span class="number">30</span> &amp;&amp; v &lt; <span class="number">40</span>) <span class="keyword">return</span> <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">if</span> (v &gt;= <span class="number">40</span> &amp;&amp; v &lt; <span class="number">50</span>) <span class="keyword">return</span> <span class="number">4</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">==&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> buckets[<span class="number">256</span>] = &#123;</span><br><span class="line">    <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">    <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">    <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>,</span><br><span class="line">    <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>,</span><br><span class="line">    <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>,</span><br><span class="line">    <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>,</span><br><span class="line">    <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>,</span><br><span class="line">... &#125;;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">mapToBucket</span><span class="params">(<span class="keyword">unsigned</span> v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (v &lt; (<span class="keyword">sizeof</span> (buckets) / <span class="keyword">sizeof</span> (<span class="keyword">int</span>)))</span><br><span class="line">    <span class="keyword">return</span> buckets[v];</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Replace-branches-with-predication"><a href="#Replace-branches-with-predication" class="headerlink" title="Replace branches with predication"></a>Replace branches with predication</h2><h1 id="额外说明"><a href="#额外说明" class="headerlink" title="额外说明"></a>额外说明</h1><h2 id="superscalar-和-SMT"><a href="#superscalar-和-SMT" class="headerlink" title="superscalar 和 SMT"></a>superscalar 和 SMT</h2><p>在“Superscalar Engines and VLIW”中介绍了 superscalar 技术。superscalar 指的是在一条流水线中，有多个执行单元，所以在一个 cycle 中可以 issue 多条指令。所以这就导致原先串行的命令中，不冲突的命令不再构成全序关系，这也就是所谓的 OOO 乱序执行。BTW，将全序关系拆解成多个不冲突的偏序关系也是一种并行或者分布式领域的常用技术。</p><p>SMT 也就是 Simultaneous Multithreading，也被称为 hyperthreading。指一个核心同时拥有两套寄存器、缓存，保存两个线程工作的现场。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;According to 老板，according to yifan，这本书很好，所以我就来学习一下了。&lt;/p&gt;</summary>
    
    
    
    
    <category term="性能" scheme="http://www.calvinneo.com/tags/性能/"/>
    
  </entry>
  
  <entry>
    <title>Grafana 使用 histogram_quantile 和 rate 的精度问题</title>
    <link href="http://www.calvinneo.com/2023/09/11/grafana-issue-floating/"/>
    <id>http://www.calvinneo.com/2023/09/11/grafana-issue-floating/</id>
    <published>2023-09-11T14:57:32.000Z</published>
    <updated>2024-10-31T13:30:02.212Z</updated>
    
    <content type="html"><![CDATA[<p>Grafana 上如果观测离群点，会发现它的值漂移地很厉害。往往一个实际 2min 的指标能显示出是几个 hour。<br>如 <a href="https://github.com/pingcap/tiflash/issues/8076" target="_blank" rel="noopener">https://github.com/pingcap/tiflash/issues/8076</a> 所述。这个问题发生需要同时使用 histogram_quantile 和 rate。</p><p>此外，可以从这个解决方案延伸出一个浮点压缩算法 ALP。</p><a id="more"></a><p>其原因是 rate 会将 count 除成小数，因为 IEEE 浮点数不能精确表示，所以引入了噪音数据。<br>如下所示，8.192 和 67108.864 这两个桶对应的 sum 应该是相等的。但因为浮点数加法的问题，它们不相等了。因此这些立群值就会被放到 bucket 序号更大的桶里面了。<br><img src="/img/grafana/1.jpg"></p><p><a href="https://github.com/m3db/m3/issues/3706" target="_blank" rel="noopener">https://github.com/m3db/m3/issues/3706</a></p><p>The problem is that the rate function, while doing its magic, turns counts into fractions. Most fractions can’t be expressed exactly as a floating point number (IEEE754 standard). The resulting number that represents the fraction is just an approximation that uses up all bits of mantissa.</p><p>因为精度的问题，导致在某个 edge 上会进一位。所以可以用 <code>histogram_quantile(1.0, sum(round(1000000000*rate(xxx{}[5m]))) by (le) / 1000000000)</code> 这样来规避。</p><p>这也体现出浮点数的性质不咋样，连结合律都不满足。在工程上来讲，不满足结合律意味着没法分治。</p><h1 id="ALP-压缩算法"><a href="#ALP-压缩算法" class="headerlink" title="ALP 压缩算法"></a>ALP 压缩算法</h1><p>这个算法是给浮点数乘一个 <code>10**e</code> 让它变成一个整数。从上面可以知道，这个 e 可能要远大于实际的小数位数，才能在除回来之后是无损的。为了免于存储后面大量的 0，算法还引入一个 f，表示最后 f 个零，我们就不放在整数里面了。</p><p>但是经过同事测试，选择 vector 长度为 10k，exceptional vector 的长度确实是有限的大约在 800 左右，说明选择合适的 e 和 f 还是能取得比较好的覆盖率的。但是实际压缩率只有 0.5，这是非常差的成绩，就算按照 (e,f,int) 三个 int 换一个的方式压缩，都不至于这么低。据说这是因为对 integer 的 bitpacking 压缩效率不是很高。这里原因是 f32 也是会被编码为 u64 的，所以后面很依赖 bitpacking 的压缩。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Grafana 上如果观测离群点，会发现它的值漂移地很厉害。往往一个实际 2min 的指标能显示出是几个 hour。&lt;br&gt;如 &lt;a href=&quot;https://github.com/pingcap/tiflash/issues/8076&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/pingcap/tiflash/issues/8076&lt;/a&gt; 所述。这个问题发生需要同时使用 histogram_quantile 和 rate。&lt;/p&gt;
&lt;p&gt;此外，可以从这个解决方案延伸出一个浮点压缩算法 ALP。&lt;/p&gt;</summary>
    
    
    
    
    <category term="grafana" scheme="http://www.calvinneo.com/tags/grafana/"/>
    
  </entry>
  
  <entry>
    <title>关于 TiKV、TiDB、TiFlash 的一些思考</title>
    <link href="http://www.calvinneo.com/2023/07/22/tikv-tidb-thought/"/>
    <id>http://www.calvinneo.com/2023/07/22/tikv-tidb-thought/</id>
    <published>2023-07-22T15:20:37.000Z</published>
    <updated>2024-10-31T15:24:22.582Z</updated>
    
    <content type="html"><![CDATA[<p>一些常见问题的思考，只代表个人见解。</p><a id="more"></a><h1 id="TiKV-相关"><a href="#TiKV-相关" class="headerlink" title="TiKV 相关"></a>TiKV 相关</h1><h2 id="TiKV-写入性能"><a href="#TiKV-写入性能" class="headerlink" title="TiKV 写入性能"></a>TiKV 写入性能</h2><h3 id="KV-热点"><a href="#KV-热点" class="headerlink" title="KV 热点"></a>KV 热点</h3><p>如果出现热点 Key，机器会吃不消么？写热点是难以避免的。TiKV 选择按 Range 切割，但是 User Key 不跨 Region。一段区间内的写热点，会导致容量超过上限而分裂，新分裂出来的 Region 可以被调度到其他 Node 上，从而实现负载均衡。在<a href="https://zhuanlan.zhihu.com/p/81316899" target="_blank" rel="noopener">文章</a>中提到，可以通过预分区的方式来划分 Region。可是对于单调递增的主键，或者索引，它会永远写在最后一个 Region 上。但我认为热点 Region 未必意味着热点机器，可以先进行 Split，然后通过 Leader Transfer 给其他的 Peer，或者通过 Conf Change 直接干掉自己。我猜测这个主要取决于数据迁移的效率和中心化服务的质量，如果在 Raft Log 阶段就能检测到流量问题并分裂，那么负载有可能被分流到多个相邻的 Region 中。</p><p>TiKV 提供了 SHARD_ROW_ID_BITS 来进行打散，这类似于 Spanner 架构中提到的利用哈希解决 Append 写的思路。TiBD 提供了 AUTO_RANDOM 替代 AUTO_INCREMENT。</p><p>注意，如果负载是频繁对某个特定的 key 更新，则 TS 一定也被用来计算哈希，不然热点 key 一定是在同一个 Region 内。这样一个 key 的不同版本就分布在不同的 Region 中，就不利于扫表了。因为下推到 TiKV 的请求可以理解为从 [l, r] 去扫出来所有 <a href="https://blog.csdn.net/TiDB_PingCAP/article/details/100535768" target="_blank" rel="noopener">commit_ts &lt;= scan_ts</a> 的数据，这样的扫表一定是会涉及到所有的机器，性能会很差。对于点查也一样，我们始终要找一个大于 user_key + ts 的 TiKV Key，哈希分片不好 seek。特别地，如果是 SI，那还得扫 [0, scan_ts] 中有没有 Lock，这个过程也要访问多个机器。</p><p>如果在构造 key 的时候就进行分片，比如在最左边加一个 shard_id，这样 rehash 会很困难。shard_id 可以比如是通过某个特定字段哈希得到。</p><p>在 Spanner 中存在 Tablet，也就是将多个同时访问比较频繁的 Region co-locate，这些 Region 彼此之间未必是有序的，甚至可能属于不同的表。</p><h3 id="关于-Region-大小的讨论"><a href="#关于-Region-大小的讨论" class="headerlink" title="关于 Region 大小的讨论"></a>关于 Region 大小的讨论</h3><p>较小的 Region 的好处：</p><ol><li>每个 Region 中较低的并发</li><li>更加快速的调度</li></ol><p>较大的 Region 的好处：</p><ol><li>Placement Driver 的压力变小</li><li>CompactLog、Heartbeat 等网络开销变小</li><li>1PC 的事务更多</li></ol><h3 id="Raft-存储"><a href="#Raft-存储" class="headerlink" title="Raft 存储"></a>Raft 存储</h3><p>原来 TiKV 使用 RocksDB 存储 Raft Log 和相关 Meta，存在几个问题：</p><ol><li>WAL + 实际数据，需要写两次盘。</li><li>数据变多，Compaction 负担变大，写放大更大。层数更多，写放大更大。</li></ol><p>因此引入了类似 bitcask 架构的 RaftEngine 来解决这个问题。RaftEngine 中每个 Region 对应一个 Memtable，数据先通过 Group Write 写入到文件中，然后再注册到 Memtable 中。在读取时从 Memtable 获取位置，再从文件中读取。因此随着 Region 日志 Apply 进度的不同，RaftEngine 在文件中会存在空洞，因此需要 rewrite。这使得存在一部分 CPU 和 IO 花费在 rewrite 逻辑上，而不能像 PolarDB 一样按照水位线直接删除。RaftEngine 这么做可以减少 fsync 的调用频率，并且充分利用文件系统 buffer 来做聚合。</p><p>此外，Raftstore 还使用 async_io 来异步落盘 Raft 日志和 Raft 状态。这样，Raftstore 线程不被 io 阻塞，能够处理更多的 Raft 相关请求和日志。需要注意，这反过来可能会加重 PeerFsm、ApplyFsm 和网络的负担，对 CPU 的要求更高。</p><h3 id="日志和数据分离存储"><a href="#日志和数据分离存储" class="headerlink" title="日志和数据分离存储"></a>日志和数据分离存储</h3><h3 id="Titan"><a href="#Titan" class="headerlink" title="Titan"></a>Titan</h3><p>Titan 的思路是将 RocksDB 中的 value 拿出来存，减少 Compaction 对 CPU 和 IO 的开销，但会带来空间放大。并且数据局部性差，所以范围查询性能较差。</p><p>Titan 将这些大 value 有序地存放在一些 blob file 中，并且保存了 value 对应的 user key 用来反查 RocksDB。反查的原因是 blob file 本身需要 gc，所以要通过 user key 来查询是否过期，这会带来一些写放大。</p><p>Titan 使用了 TablePropertiesCollector 的 feature。具体来说，它是定义了 BlobFileSizeCollector 这个 Collector，它会记录一个 SST 中到底有多少数据室放在 blob file 中的。</p><p>Titan 有两种 gc 策略：</p><ol><li>定时 rewrite blob file<br> 监听每次 Compaction 事件，从而维护每个 blob 文件中无效数据的大小。每次重写 invalid 率最高的几个文件，并更新回 RocksDB。旧的文件需要确保不再有 Snapshot 引用才可被删除。<br> 具体来说，Compaction 此时只是计算和合并 SST 中的 <code>&lt;blob_offset, size&gt;</code> 了。在 Compaction 结束之后，是可以旧的 blob file 中到底有多少数据不再被新 SST 引用了。Titan 只有在 BlobFile 可丢弃的数据达到一定比例之后才会对其进行 GC。</li><li>在 LSM-tree compaction 的时候同时进行 blob 文件的重写<br> 也就是在 Compaction 的同时写到一份新的 blob 文件中。因为不需要的 kv 会在 Compaction 的时候被过滤掉，也就相当于自动完成了 gc。这种方案的有序性会更好点，所以 scan 性能理论上会高。<br> 这种方案要求 blob 文件也需要伴随着 SST 进行分层，从而带来写放大。并且也有不小的空间放大。因此，考虑到大部分数据都在最后两层，该策略只对最下面两层生效。</li></ol><p>在一些场景中，Titan 能够带来收益。业界也有类似 Titan 的 KV 分离存储方案，比如 WiscKey 等。从测试结果来看，行宽越大，Update 提升越明显。从 1KB 时候的 2 倍不到，到 32KB 时候的大概 5 倍向上。</p><h2 id="TiKV-读取"><a href="#TiKV-读取" class="headerlink" title="TiKV 读取"></a>TiKV 读取</h2><h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h3><p>TiKV 处理读请求对 Block Cache 要求较高，较低的 Block Cache Hit 会导致读性能倍数下滑。Block Cache 需要占用接近一般的内存，但也需要保留一部分给系统作为 Page Cache，以及处理查询时的内存。</p><p>不同的压缩方式，对 CPU 的压力不同。</p><h2 id="Coprocessor"><a href="#Coprocessor" class="headerlink" title="Coprocessor"></a>Coprocessor</h2><h3 id="Cop-可以支持写入么？"><a href="#Cop-可以支持写入么？" class="headerlink" title="Cop 可以支持写入么？"></a>Cop 可以支持写入么？</h3><p>一个合理的优化是让 Cop 能支持 update where 类型的下推。这样就能免去从 TiKV 到 TiDB 的额外一次处理的开销。当然，对于 TiKV 本身来说还是需要将数据从 Rocksdb 读出来，在写回去，从而导致缓存被刷新的问题的。</p><h1 id="Multi-Raft-相关"><a href="#Multi-Raft-相关" class="headerlink" title="Multi Raft 相关"></a>Multi Raft 相关</h1><h2 id="关于-Raft-协议本身"><a href="#关于-Raft-协议本身" class="headerlink" title="关于 Raft 协议本身"></a>关于 Raft 协议本身</h2><h3 id="Follower-Replication-和-Follower-Snapshot"><a href="#Follower-Replication-和-Follower-Snapshot" class="headerlink" title="Follower Replication 和 Follower Snapshot"></a>Follower Replication 和 Follower Snapshot</h3><p>Follower Snapshot 的好处有：</p><ol><li>因为是有处于一个 Zone 的 Follower 发送 Snapshot，所以可能更快。并且跨 Zone 流量也少</li><li>减少 Leader 的负担</li></ol><p>TiFlash 做了 Learner Snapshot，相比 Follower Snapshot，它甚至是一个异构的 Snapshot。CRDB 做了类似的工作，称为 <a href="https://www.cockroachlabs.com/docs/stable/architecture/replication-layer" target="_blank" rel="noopener">Delegate Snapshot</a>。TiKV 目前还不支持。</p><h3 id="关于读"><a href="#关于读" class="headerlink" title="关于读"></a>关于读</h3><p>Raft 的一个问题就是读的时候无论是 Leader 还是 Follower 都需要 Read Index。比如，对 Leader 而言，它需要问 quorum 自己当前是否还是 Leader。TiKV 一般 Leader Read 提供两种方案，第一种是 read_local，也就是 Leader 节点上 lease 读，另一种是 read_index，也就是在不确定自己是否还是 Leader 的时候，进行 ReadIndex。</p><h2 id="Raft-状态的思考"><a href="#Raft-状态的思考" class="headerlink" title="Raft 状态的思考"></a>Raft 状态的思考</h2><p>RaftLocalState 中相比 Raft 协议多包含了 last_index 和 commit。其中 commit 可以避免重启后不能立即 apply 的情况。</p><h2 id="存储-Raft-状态和-Region-状态"><a href="#存储-Raft-状态和-Region-状态" class="headerlink" title="存储 Raft 状态和 Region 状态"></a>存储 Raft 状态和 Region 状态</h2><p>TiKV 使用 Raft Engine 存储 Raft 元信息和 Raft 日志。使用 KV Engine 存 Region 信息、Region Apply 信息和具体的 KV数据。</p><h3 id="一个-Eager-落盘导致的问题"><a href="#一个-Eager-落盘导致的问题" class="headerlink" title="一个 Eager 落盘导致的问题"></a>一个 Eager 落盘导致的问题</h3><p>并不是所有时候，eager 落盘都能保证正确性问题。下面就是一个例子。<br>前面说过，在 TiKV 的实现中有两个 engine，KVEngine 存储 KV Meta 和 KV Data，RaftEngine 存储 Raft Meta 和 Raft Data。其中有一个 Apply Snapshot 的场景会同时原子地修改这两个 Engine，但可惜这两个 Engine 无法做到原子地落盘。并且因为两个 Engine 中都存有 Meta 和 Data，所以任意的先后顺序，都会导致数据不一致。这里的解决方式是将 RaftEngine 中的的 Raft Meta 写到 KVEngine 中，称为 Snapshot Meta。写入的时候，会先写 KVEngine，再写 RaftEngine。当在两个非原子写入中间出现宕机，从而不一致的时候，会使用 KVEngine 中的 Raft Meta 替换 RaftEngine 中的 Raft Meta。</p><p>在<a href="https://github.com/tikv/tikv/blob/1ce8ee7df84503e889ff8bc6834a57128a858a16/components/raftstore/src/store/peer_storage.rs#L645" target="_blank" rel="noopener">Apply Snapshot</a>阶段开始时，它会调用 <code>clear_meta</code> 删除掉 KV Meta、Raft Meta 和 Raft Data，但这个删除是不应该立即落盘的，而是在 WriteBatch 里面。在这之后，还会再往 WriteBatch 中写入 Snapshot Meta 等。这些写入会被一起发送给一个 Async Write 写入。我们的错误是，在实现删除 Raft Engine 数据时，并不是写 Write Batch，而是直接写盘。在 <code>clear_meta</code> 之后系统又立即宕机了。这样重启恢复后，就会看到空的 Raft Meta 和 Raft Data，但 KV Meta 却还存在。这是一个 Panic 错误，因为两个 Meta 不一致了。</p><p>这样的错误是难以调查的，我们可以加日志获得重启后从磁盘中读到的结果，但仍然不知道这个结果是如何被写入的。查的方式是脑补，也就是针对这样的场景，假设在不同时刻宕机，考虑会出现什么样的持久化状态。<br>这里，KV Meta 的落盘信息是有的，它可能是没清就宕机了，也可能是写完新的数据之后宕机的。考量这个可以看一些 Meta 信息有没有写入，比如我们发现 Snapshot Meta 并不存在，因此说明是前一种情况。既然如此，为什么 Raft Meta 和 Data 都没了呢？只能说明是 Raft 的清早了。</p><p>当然，这里有个迷惑点，就是 KV Meta 提示当前是在 Applying Snapshot 状态，而如果我们是第一种情况的话，这个 Applying 状态应该还没有被写入。这个原因是这个实例发生了多次重启，在 T-2 次启动后 Apply Snapshot 时，KVEngine 和 RaftEngine 都落盘成功了，但是后续的流程没进行下去就重启了。所以在 T-1 次启动会重新 Apply Snapshot，但这一次甚至没到落盘就重启了，而 Snapshot Meta 是金标准。然后就是我们见到的 T 次启动的错误。这启示我们不能只通过一个元数据来判断当前集群的状态，而是要检查所有的元数据，来石锤当前状态是如何得到的。</p><h2 id="Multi-Raft-的思考"><a href="#Multi-Raft-的思考" class="headerlink" title="Multi Raft 的思考"></a>Multi Raft 的思考</h2><h3 id="共识层和事务层的关系"><a href="#共识层和事务层的关系" class="headerlink" title="共识层和事务层的关系"></a>共识层和事务层的关系</h3><p>Percolator 事务提交模型中，commit_ts(R) &lt; start_ts(T) 的事务 R 对事务 T 可⻅。不满⾜该关系的事务为并发事务，并发事务如果访问相同的 key 将会导致其中⼀个事务会碰到 Lock ⽽回滚。<br>Raft 的 Read Index 模型中，一个读请求需要等到 applied_index 大于等于 read_index 时，才能读取数据。但并不保证是否能读到 applied_index = x + 1 时的数据。实际上无论是否读到，都不违背强一致读的原则。因为如果一个读 A 能读到 applied_index = x + 1，而另一个读 B happen after 读 A，那么读 B 一定会读到 applied_index &gt;= x + 1 的数据。</p><p>TiKV 的共识层在事务层之下。在事务 Commit 之前的很多数据也会被复制到多数节点上，这产生了一些写放大。但也需要注意其带来的好处：</p><ol><li>共识层实际为 Percolator 提供了类似 BigTable 的存储。<br> 首先提供了外部一致性。<br> 然后提供了 PUT default/PUT lock 和 PUT write/DEL lock 的原子性写入。<br> 当然，这里要先读后写，可能会有 Write Skew。</li><li>共识层本身也可以作为一个 Raw KV 对外服务。</li><li>共识层参与定序。这个在后面介绍。</li><li>多个 Raft Group 组成的共识层提高了并发能力。</li><li>Lock 的存在性和⼀致性由该⾏所处的 Raft Group 保障。</li><li>事务提交后，会写⼊ Write 并删除 Lock，其原⼦性由 Raft Write Batch 保障。</li><li>共识层提供了全序广播语义。<br> “在 xx 之前，一定不会有别的 Lock 和 Write 了”</li></ol><p>当然这也存在一个 argue 点，因为 Raft Log 本身也是 total order 的。虽然我们目前不是全局一个 Raft Group 的，但看起来会有一些冗余。后面会讨论。<br>特别地，在 CDC 服务和 TiFlash 中，我们实际上不会处理未 Commit 的数据。</p><h3 id="共识序和事务序"><a href="#共识序和事务序" class="headerlink" title="共识序和事务序"></a>共识序和事务序</h3><h4 id="双重定序"><a href="#双重定序" class="headerlink" title="双重定序"></a>双重定序</h4><p>事务层的实现中，为了满足隔离性，通常会给事务分配 id 来表示相互依赖的事务之间的偏序关系。TiDB 中使用了 TSO，Spanner 中使用了 TrueTime，CRDB 中使用了 HLC。<br>共识层的实现中，为了实现容灾和高可用，使用共识算法在各个 RSM 之间复制日志，这些日志为全序关系，RSM 可以应用这个全序关系确保所有副本间是线性一致的。</p><p>事务层生成 TSO 和共识层生成 Log 两个行为：</p><ol><li>不是原子的</li><li>也不构成全序关系<br> 实际上也没必要，两个不相交的事务按照事务序本来可以并行 Commit 的，但因为要写到共识层，必须又要排出一个全序关系来。</li><li>甚至一个事务的 commit_ts （相比某个特定事务）更小，而 index 更大<br> 下面会展示这种情况，并详细阐述。</li></ol><p>总而言之，Percolator 协议保证了事务层能够生成一个特定的排序，并且按照它的二阶段方式写入到共识层。共识层保证了所有的副本都会应用该特定排序。</p><h4 id="共识层为事务层提供帮助"><a href="#共识层为事务层提供帮助" class="headerlink" title="共识层为事务层提供帮助"></a>共识层为事务层提供帮助</h4><p>目前 TiKV 通过一个 pd 分配一个全局的 tso 来作为事务的 start_ts 和 commit_ts，所以它们之间彼此构成全序关系。当然，实际上不同的事务可能具有同一个 commit_ts，但这并不影响我们的讨论。通过 start_ts 和 commit_ts 可以构建有依赖的事务之间偏序关系，也可以用来判断事务是否是 concurrent 的。如果在单个节点上串行地 commit 这些事务，则面临问题：</p><ol><li>整个系统毫无并行度<br> 这个应该算是 MultiRaft 的一个 bonus，正如后面讲的，如果没有 MultiRaft，同样可以做 partitioning。<br> 因此，TiKV 在多个线性一致的存储(Region)上储存这些事务，它保证了每个事务在每个 Region 上都遵循了 start_ts 和 commit_ts 所 imply 的顺序，也 Percolator 那一套。这样尽管各个 Region 之间是并发的了，但只要 Region 内遵循这个 order 就行了。<blockquote><p>当然，这个切分也未必是按照 Region 来，比如 CDC 会使用表来切分。无论按照哪种方式来切分，我觉得一个实现的要点是每个 shard 在调度上是不可以再分的了。比如一个 Region 的一部分数据在 store 1 上，另一部分数据在 store 2 上，这样做实际上会导致无论在 store 1 和 store 2 上都很难独立构建出该 Region 上数据的全序关系，比如 store 1 如果不和 store 2 交互，那么就很难知道 store 2 上还有没有 happen before 它的事务了。比如说，如果两个 store 上 apply 这个 Region 的 log 的进度不一样。</p></blockquote></li><li>如何判断某个 tso 之前还有没有其他 Lock 或者 Write？<br> 因此，读事务会在取得 start_ts 后，再通过 ReadIndex 请求一下 Region Leader 上的 commit_index。那么假设在这之前 Region 上有写入任意的 Lock 或者 Write，都能被 ReadIndex 扫到。这样就保证了读事务能看到 start_ts 之前的所有修改。至于 start_ts 之后的也有 Lock 可以帮忙。<br> 同样考虑一个<a href="/2017/09/20/transaction/">Snapshot Isolation(SI)/一个两难问题</a>，这里不再详细展开具体内容。但 ReadIndex 提供了一个保证，就是截止到 read_index，这个 Region 上到底有没有 Write，是很确定的。我理解这实际上就是一种全序广播了。破坏这种全序广播可能会有严重后果，比如如果将 Write 乱序到 Lock 前面，则违反了 Percolator 事务的约束。我们实际上也没办法很好的处理，在“跨 Region 提交事务”中，就构造出了这样的场景。</li></ol><p>此外，对于并发事务，共识层也会对它们之间排出一个串行的顺序，比如两个并发的事务不能同时 Commit，而要等到 Log 按序 apply 而这可能有点过强。诸如 ParallelRaft 或者 MultiPaxos 的算法允许并行 apply，可以解决此问题，但会导致 Leader 和 Follower 之间的 apply order 难以统一，从而无法实现 Follower Read。</p><h4 id="共识层对并发事务的乱序"><a href="#共识层对并发事务的乱序" class="headerlink" title="共识层对并发事务的乱序"></a>共识层对并发事务的乱序</h4><p>刚才说过，共识层未必会按照事务序写入。这也很容易理解，因为取 start_ts 和 commit_ts 和真正写共识层不是原子的。<br>TiKV 事务在读取时，需要同时接收事务层和共识层的定序。为了满⾜线性⼀致读，需要⾸先带上 start_ts，发送⼀个 ReadIndexRequest 给对应的 Region，求出⼀个 applied_index。在实际实现中，start_ts 并⽆作⽤。<br>如下所示，Key a 和 Key b 属于两个事务。在事务提交前，可以看到或者得到的保证是：</p><ol><li>start_ts(a) &lt; commit_ts(a)</li><li>start_ts(b) &lt; commit_ts(b)</li><li>start_ts(a) &lt; start_ts(b)</li><li>并且这两个是并发事务，也就是说 commit_ts(a) &gt; start_ts(b)</li></ol><p>共识层的序至少保证了同一个 key 的 prewrite 在 commit 前面。</p><p>不妨假设 commit_ts 分别为 4 和 6，然后再假如以 (read_ts=7, read_index=202) 读取，如下所示。</p><ol><li>Key a：(start_ts: 1, applied_index: 100), (commit_ts: 4, applied_index: 210）</li><li>Key b：(start_ts: 3, applied_index: 101), (commit_ts: 6, applied_index: 200)</li></ol><p>从事务层上讲，Key a 和 Key b 的写入对 read_ts=7 的读取事务可见，从共识层上讲 applied_index 等于 read_index，或者超过它的的任意时刻都可以读了。因此，此时可能读到一个锁和 Key b（刚好 apply 到 read_index），或者读到 Key a 和 Key b（apply 超过 read_index 很多，比如到 211 了）。前者需要 ResolveLock，实际上导致以新的 read_index 来重新读取。</p><p>反过来讲，如果共识层给出下面的顺序，我们看到了中间的 a 或者 b 上有锁。因为这两个事务是并发事务，所以这也是 OK 的</p><ol><li>Key a：(start_ts: 1, applied_index: 100), (commit_ts: 4, applied_index: 200）</li><li>Key b：(start_ts: 3, applied_index: 101), (commit_ts: 6, applied_index: 210)</li></ol><p><img src="/img/ti-arch-thought/consensus_order_txn_order.png"></p><p>可以看到，尽管将事务拆到了 N 个线性一致的存储上执行，并且这些存储可能对并发事务任意定序，但最终读到的结果还是满足了线性一致，以及事务隔离层的要求的。</p><h4 id="并发事务的共识序"><a href="#并发事务的共识序" class="headerlink" title="并发事务的共识序"></a>并发事务的共识序</h4><p>并发事务 1 和 2，假设 start_ts1 &lt; start_ts2 &lt; commit_ts1 &lt; commit_ts2，那么两个事务彼此不可见，或者说是并发事务。假设这两个事务写入同一个 region，那么在 raft log entry 层面，完全可以出现 commit_ts1 对应的 raft log 的 index 更靠后，而 commit_ts2 对应的更靠前。比如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">index 10: Put Write CF commit_ts2</span><br><span class="line">index 11: Put Write CF commit_ts1</span><br></pre></td></tr></table></figure><h4 id="跨-Region-提交事务"><a href="#跨-Region-提交事务" class="headerlink" title="跨 Region 提交事务"></a>跨 Region 提交事务</h4><p>TiFlash 不能在看到第一个 write 记录时“提交”该事务的所有 key，这里的“提交”指的是写入下层存储，比如将 Default 写过去，但并不包含删除 Lock 等。<br>现在比如考虑两个事务，假设 a 在一个 region r1，b 和 c 在另一个 region r2 让：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">commit a(applied_index@r1=100), commit b(applied_index@r2=300), commit_ts=4</span><br><span class="line">                                commit c(applied_index@r2=200), commit_ts=1</span><br></pre></td></tr></table></figure><p>从事务层上来看，一定有读事务能看到 c，或者 a、b、c。现在如果看到 a 提交了，能不能跑到 b 的 region 上把 b 也提交了呢？我认为是不可以的，因为从共识层上来说，b 在 c 的后面被 commit 的，如果用 (start_ts &gt; 4, read_index = 250) 去读的话，可能读到 lock b，甚至可能连 lock b 也还没被写入，当然也有可能读到 b。但如果我们在 apply a 的 write 记录的时候发现了 a 被 write 了，就直接写 b 的 write 记录，那么就导致 b 一定在 c 前面就能被读到，实际上违反了共识层的序。</p><p>具体来说，不妨考虑 client 先后从 Learner 和 Leader 读：</p><ol><li>在 Learner 上，它使用 read_index = 250 读，但是因为 commit a 已经被 apply 的原因，所以它一定读到了 commit b。<br> 当然细究下来，因为 lock + default 是原子的，所以实际上 write 无法被正确执行。但这就是 orphan write key 的问题，之前在处理 multi rocks 的时候就解过，我觉得很复杂。在这个场景下，我觉得免不了要去进行等待。在异步系统中的等待，我觉得可以理解为是一种活性问题。</li><li>在 Leader 上，此时 Leader apply 到了 260，所以此时 Leader 上一定没有 commit b，这导致它读不到 commit b。</li></ol><p>这里线性一致读就被破坏了。反之，如果按共识序 commit，则不会有这种情况。具体就不展开了。</p><p>这个场景在单 Region 上无法构造，原因是单 Region 上是串行的。尽管“在看到第一个 write 记录时‘提交’该事务的所有 key”可能相当于让一部分 Write 被乱序，但这种乱序不是直接去把 Write 挪到 Lock 之前那样是破坏性的。比如说，因为 Percolator 的特性，单 Region 上的某个事务的 Prewrite 一定都在 Commit 前面。因此，就算在看到第一个 Write 时候，将该事务的所有 Default 都提前写到下层存储，也不至于提前到某个 Lock 前面。这样被写的 Key 始终有 Lock 保护，直到看到它对应的 Write。<br>而在多 Region 中不同 Region 可以说是完全异步的（不考虑 Split 等），那我就可以构造一个无比提前的 Write，让它失去 Lock 的保护。</p><h3 id="Split-Merge-和事务"><a href="#Split-Merge-和事务" class="headerlink" title="Split/Merge 和事务"></a>Split/Merge 和事务</h3><h3 id="Split-Merge-和-Read"><a href="#Split-Merge-和-Read" class="headerlink" title="Split/Merge 和 Read"></a>Split/Merge 和 Read</h3><p>Split 和 Merge 会导致 Region 发生变化，自然也可能会影响读取。主要体现在下面几个方面：</p><ol><li>影响 Lease 本身或者 Lease 续约</li><li>推高 RegionEpoch 从而导致 ReadIndex 失败</li></ol><h3 id="Split-Merge-和-Apply-Snapshot"><a href="#Split-Merge-和-Apply-Snapshot" class="headerlink" title="Split/Merge 和 Apply Snapshot"></a>Split/Merge 和 Apply Snapshot</h3><p>Multi Raft 实现的复杂度，很大程度在处理 Split/Merge 和 Apply Snapshot 的冲突上。</p><h4 id="Split-和-Apply-Snapshot-的冲突"><a href="#Split-和-Apply-Snapshot-的冲突" class="headerlink" title="Split 和 Apply Snapshot 的冲突"></a>Split 和 Apply Snapshot 的冲突</h4><p>我们需要处理一个 Region 上的 Follower 还没有执行到分裂为 Base 和 Derived 前，一份来自 Derived 的 Snapshot 已经被发过来的情况。这会产生 Region Overlap 的问题，在一些下层存储中会导致数据损坏。一种方案是在 Base 完成分裂前根据 Epoch 拒绝掉这些 Snapshot。</p><h4 id="Merge-和-Apply-Snapshot-的冲突"><a href="#Merge-和-Apply-Snapshot-的冲突" class="headerlink" title="Merge 和 Apply Snapshot 的冲突"></a>Merge 和 Apply Snapshot 的冲突</h4><p>Merge 过程可以简单理解为下面几步：</p><ol><li>调度 Source 和 Target Region 的各个 Peer，让它们对齐到同一个 Store 上。</li><li>Source Peer 执行 Prepare Merge。</li><li>Source Peer 等待 Target Peer 追完 Source Peer 的日志。</li><li>Source Peer 对 Target Peer 去 Propose Commit Merge。</li><li>Target Peer 执行 Commit Merge。</li></ol><p>可能在下面一些阶段收到 Snapshot：</p><ol><li>Prepare Merge 结束</li><li>Leader 上的 Commit Merge 结束，但 Follower 上的 Commit Merge 还没有开始</li></ol><h4 id="Split-和-Generate-Snapshot-的冲突"><a href="#Split-和-Generate-Snapshot-的冲突" class="headerlink" title="Split 和 Generate Snapshot 的冲突"></a>Split 和 Generate Snapshot 的冲突</h4><p>主要指 Split 等会改变 RegionEpoch 从而导致 Snapshot 失效。</p><h3 id="Raft-Group-和-Data-Range-的对应关系"><a href="#Raft-Group-和-Data-Range-的对应关系" class="headerlink" title="Raft Group 和 Data Range 的对应关系"></a>Raft Group 和 Data Range 的对应关系</h3><p>TiKV 中，Raft Group 和 Region 严格一一对应。TiKV 中 Region 管理一段范围内的数据，在其他一些实现中，这段范围可能被称作 Shard、Partition 等。讨论下这个设计：</p><ol><li>Raft 本身和 Region 数据的版本引入了全序关系<br> 首先，Raft Admin Command 会穿插在写入之间形成很多 barrier，带来额外的持久化负担。<br> 然后，这导致了新创建的 peer 只能通过 Snapshot 追进度的情况。从 Raft 协议来看，ConfChange 之前的日志的提交和复制应当遵守 C_old 的配置项目，但是它并没有禁止进入 C_new 状态的 Leader 给新 peer 发送 ConfChange 之前的日志。但考虑到如果新 peer 还在处理 C_old 时代的日志，它的本地状态比如 RegionLocalState 肯定对应了 C_old，这个时候它接受到了一个“不认识”的 store 的 AppendEntries，这是比较奇怪的。</li><li>Raft Group 不稳定<br> Split 会分出独立的 Raft Group，给 pd 调度带来压力。也变相增大了 recover 的工作量。<br> Merge 两个 Region 会销毁一个 Raft Group，这里面有不少 corner case。比如 Leader 关掉后的孤儿 Learner 问题。</li></ol><p>我觉得可能 Spanner 的架构会更好一点。也就是说：</p><ol><li>一个 “Spanner Region” 一个 Raft Group，但这个 “Spanner Region” 不再和某个 Key range 绑定。</li><li>一个 “Spanner Region” 下可以被调度多个 Key range。例如有局部性的 Key range 可以被调度在一起，或者处于打散负载的目的可以将 Key range 进行随机的分布。</li></ol><h4 id="Raft-Group-和-Data-Range-分开的架构"><a href="#Raft-Group-和-Data-Range-分开的架构" class="headerlink" title="Raft Group 和 Data Range 分开的架构"></a>Raft Group 和 Data Range 分开的架构</h4><p>即使 Raft Group 和 Data Range 是一一对应的，那么在这之上还有一些设计：</p><ol><li>全局需要维护多少个 Raft Group？<br> 一个 Raft Group 可能需要处理不同 Key range 的数据。但全局关系肯定是过强了，破坏了 Partitioning 的初衷。所以会更倾向于引入乱序 Apply 机制来提高 RSM 的吞吐量。</li><li>谁有权限写 Data Range？<br> 一般来说，会将对应的 Raft Group Leader 设置为 Data Range 的 “Leader”，让它来处理写入。这样做的好处是可以减少一次 RPC。</li></ol><p>另外，分开的实现还有个好处，就是如果 Raft 层的 Leader 发生切换，Data Range 层的读取不会收到影响，而是可以 bypass 掉 Raft 层。<a href="https://www.cockroachlabs.com/docs/stable/architecture/replication-layer#leases" target="_blank" rel="noopener">CRDB</a> 就是这样实现的，也就是类似是 Data Range 上的 LeaseRead。相比之下，TiKV 的 LeaseRead 和 Raft Leader 的生命周期是绑定的。</p><p>另外值得一提的是 <a href="https://www.cockroachlabs.com/docs/stable/architecture/replication-layer#epoch-based-leases-table-data" target="_blank" rel="noopener">CRDB</a> 将 Lease 和机器绑定而不是和 Data Range 绑定，从而减少网络开销。它的做法是每个 Data Range 的 “Leader” 会去维护一个 meta 表（也是一个 Data Range）上的 liveness 记录。我理解它可以以一个比较低的频率去更新 liveness 记录，因为如果不是节点挂了下线，或者是重新调度到当前 Raft Leader 的节点上这两种情况，Raft Leader 就还是同一个，那么就完全没有必要续期。而 TiKV 的绑定方式则必须要求 Lease 是比 Election Timeout 要短的。对于 meta 表自己的 Lease，是通过 expiration time 来维护的。</p><p>当某个 node 宕掉之后，CRDB 还是要重新选出一个新的 Lease Leader，而这个<a href="https://www.cockroachlabs.com/docs/stable/architecture/replication-layer#how-leases-are-transferred-from-a-dead-node" target="_blank" rel="noopener">依旧是通过 Raft 选举来实现的</a>。</p><p>当然，对于 meta 表，就不能像上面那样去做了。否则会导致循环依赖。此时：</p><ol><li>如果一个节点依旧能够不停地 propose，那么它就能够一直续期 lease</li><li>否则，下一个尝试对这个 range 读写的 node 会成为 leader</li></ol><p>在本文的后面还会提到 Follower Read 相关的话题，特别是它和乱序 apply 的关系。我个人觉得，如果将 Data Range 和 Raft Group 分开，我们仍然是可以实现 Follower Read 的。如果你把 Data Range 看成一个 RSM，那这种架构就类似于一个 Raft Group 去管理多个 RSM。我们在 Data Range 上维护一个 index，应该就行了。</p><h3 id="Raft-日志的内容"><a href="#Raft-日志的内容" class="headerlink" title="Raft 日志的内容"></a>Raft 日志的内容</h3><p>Raft 日志中到底记录什么呢？可以看下面的总结：</p><ol><li>TiKV<br> TiKV 中 Raft 日志分为 Admin 和 Write。Admin 基本只和 Raft 和 Region 管理有关。Raft 指的是 Raft 的成员变更，比如 Add/Remove Voter/Learner，TransferLeader 等。Region 指的是管理的 key range 的元数据变更，比如 Split、Merge、数据校验等。<br> Admin 和 Write 在一起构成全序关系，这个话题之前已经展开讨论过了。<br> Write 包含 Put、Delete、DeleteRange 和 IngestSST，这些都是逻辑日志，或者说是不 aware 下层 rocksdb 的。</li><li>OceanBase<br> OceanBase 中复制的是 clog。从<a href="https://en.oceanbase.com/docs/common-oceanbase-database-10000000001029737" target="_blank" rel="noopener">文档</a>来看，它们复制的是物理日志。通过 replay clog，能够得到同样的 log 文件，其中记录的是 redo log。<br> 下面来自<a href="https://www.oceanbase.com/docs/community-observer-cn-10000000000016344" target="_blank" rel="noopener">Oceanbase 文档</a><blockquote><p>OceanBase 数据库单台物理机上启动一个 observer 进程，有几万到十万分区，所有分区同时共用一个 Clog 文件，当写入的 Clog 文件超过配置的阈值（默认为 64 MB）时，会打开新的 Clog 文件进行写入。<br>OBServer 收到的某个分区 Leader 的写请求产生的 Clog、其他节点 OBServer 同步过来的 Clog（存在分区同在一个 Paxos Group)，都写入 Log Buffer 中，由单个 IO 线程批量刷入 Clog 文件。</p></blockquote></li><li>PolarDB<br> 在《PolarFS: An Ultra-low Latency and Failure Resilient Distributed File System for Shared Storage Cloud Database》中讲得比较清楚。<br> PolarDB 的存储层基于 PolarFS，计算节点共享地访问这个存储层。PolarDB 中每个数据库对应 PolarFS 中的一个卷，每个卷由若干 Chunk 组成。不同于 TiKV 的 Region，这里 Chunk 大小为 10GB，而卷的大小在 10GB 到 100TB 之间，所以它们元数据节点的调度压力会小很多，并且所有节点的元数据都可以缓存在内存中。一个 Chunck Server 管理多个 Chunk，PolarDB 通过增加 ChunkServer 的数量来平衡热点。这里我觉得 TiKV 的 multi rocks 方案可能更好，因为它允许一个 hot region 被分裂。在 PolarDB 中，一个服务器上运行多个 ChunkServer，但每个 ChunkServer 对应一个专用的 SSD，并且绑定一个专用的 CPU 核心。<br> 一个 Chunk 由 64KB 大小的 block 组成。PolarFS 的 Raft 日志实际复制的是这些 block 的 WAL。</li><li>Kudu<br> Kudu 中复制的是逻辑日志。他们的观点是这样可以实现各个 Replica 在存储格式上是解耦的。</li></ol><h3 id="进一步讨论：日志和选举的关系"><a href="#进一步讨论：日志和选举的关系" class="headerlink" title="进一步讨论：日志和选举的关系"></a>进一步讨论：日志和选举的关系</h3><p>Raft 中的领导人完全性原则要求 Leader 必须拥有所有已提交的日志，这实际上是一个比较强的约束。在 Ongaro 等人对于 MultiPaxos 的描述中，可以发现该约束是可以被消减掉的，从而选举过程可以不关注日志的完备性。<br>在此基础上，可以让选举体现出其他的优先级。以 Ob 的 Palf 为例，它的“一呼百应”的方案，可以始终给距离自己最“近”的节点投票。而 Raft 选举的实质是谁状态更新，谁就更容易当选。这个方案目前来看，无论是否效果最优，但确实代价比较大。</p><p>有关 Raft 的日志和选举关系的讨论，可以见 <a href="/2019/03/12/raft-algorithm/">Raft 算法介绍中的“日志和选举”章节</a> 详细讨论。</p><h3 id="进一步讨论：日志和事务的关系"><a href="#进一步讨论：日志和事务的关系" class="headerlink" title="进一步讨论：日志和事务的关系"></a>进一步讨论：日志和事务的关系</h3><p>将多个分区的写入统一到一个 Raft Group 中进行复制，应该是有利于事务的。因为如果一个事务跨 Region，就会是一个分布式事务，而如果只有一个 Raft Group，那么就不会涉及到跨 Region 的问题。</p><h3 id="Mono-LSM-和-Multi-LSM-的考量"><a href="#Mono-LSM-和-Multi-LSM-的考量" class="headerlink" title="Mono LSM 和 Multi LSM 的考量"></a>Mono LSM 和 Multi LSM 的考量</h3><p>这里指的是不同的 Region 的数据是否 share 一个 LSM 树。我认为如果使用 range partition，那么 multi lsm 的策略是一个非常重要的优化。</p><h2 id="线性一致读"><a href="#线性一致读" class="headerlink" title="线性一致读"></a>线性一致读</h2><h3 id="Follower-Read"><a href="#Follower-Read" class="headerlink" title="Follower Read"></a>Follower Read</h3><p>TiDB 支持<a href="https://docs.pingcap.com/zh/tidb/stable/follower-read" target="_blank" rel="noopener">多种读取方式</a>，例如最近 Peer、Leader、Follower、Learner、自适应等多种模式，这些依赖于 Follower Read，在这之前都需要从 Raft Leader 读取。</p><p>不同于 ParallelRaft 和 MultiPaxos 的部分实现，TiKV 会串行地 apply raft log。</p><ol><li>这样的好处是，更容易通过 Read Index 实现 Follower Read 了。TiKV 在这一点上行得通，主要还是因为它的数据和 Raft Group 绑定的缘故。也就是以 scheduler 为代价来实现 Partitioning，从而减少各个 Raft Group 的压力。</li><li>这样的坏处是，引入了更强的全序关系。因为我们实现共识层的目的是服务上层的事务层，而事务层本身就允许并行事务以任意的顺序被提交，所以在共识层排成强序，实际上是多余的。当然，Partitioning 分成多个 Raft Group 能减少这部分的强序关系的数量。</li></ol><p>总的来说，TiKV 实现的 Follower Read，是通常被称作 <a href="https://www.cockroachlabs.com/docs/v23.2/follower-reads" target="_blank" rel="noopener">Strong Follower Read</a> 的类型。</p><h3 id="Learner-Read"><a href="#Learner-Read" class="headerlink" title="Learner Read"></a>Learner Read</h3><p>不同于 Follower，Learner 不是 Voter，没有选举功能。所以 Learner Read 和 Follower Read 有不同。<br>Learner Read 在 TiFlash 场景下更为丰富，在 TiFlash 章节讨论。</p><h3 id="强一致读（加上事务）"><a href="#强一致读（加上事务）" class="headerlink" title="强一致读（加上事务）"></a>强一致读（加上事务）</h3><p>从共识层上来讲，强一致，或者线性一致有明确的定义。<a href="https://www.cockroachlabs.com/docs/v23.2/architecture/transaction-layer" target="_blank" rel="noopener">CRDB</a>将其“推广”到事务层之上，也就是归结到所谓的 non-stale 读上。因为 CRDB 只有 leaseholder 也就是所谓的 Leader 能服务读。但推广到有 Follower Read 的场景下就是，在任意的节点上：</p><ol><li>在 SERIALIZABLE 下，读事务应该能看到在它之前已经提交了的所有的写事务。这里的“它之前”我理解根据事务的实现的不同而不同，但至少要在事务的第一个读之前。比如 Percolator 模型中就是 start_ts。</li><li>在 RC 级别上，事务中的每一个读语句能看到在它之前已经提交了的所有的写事务。</li></ol><h4 id="Stale-Read"><a href="#Stale-Read" class="headerlink" title="Stale Read"></a>Stale Read</h4><p>Stale Read 的作用是让读请求被分配到任一节点上，从而避免某热点机器，或者跨数据中心的 read index 请求产生的延迟。</p><p>这样的事务只能服务读，并且 staleness 也是需要被严格控制的。</p><p>Stale Read 是读 ts 时间点上所有已提交事务的旧数据。因为读不到最新的写入，所以不是强一致的。但它仍然保持有<a href="https://docs.pingcap.com/zh/tidb/stable/stale-read" target="_blank" rel="noopener">全局事务记录一致性</a>，并且不破坏隔离级别。我理解可能就是所谓的 Time travel query。</p><p>一般提供两种：</p><ol><li>精确时间戳</li><li>有界时间<br> 在给定的时间范围内选择一个合适的时间戳，该时间戳能保证所访问的副本上不存在开始于这个时间戳之前且还没有提交的相关事务，即能保证所访问的可用副本上执行读取操作而且不会被阻塞。<br> 因此这样的读取方式能提高可用性。</li></ol><p>使用 Stale Read 需要 NTP 的支持。</p><p>所以它并不是“弱一致读”，无论从哪一个节点返回的结果都是一致的，不会出现 A 返回 1000 笔记录，而 B 返回 1111 笔记录的情况。</p><h2 id="多-Region-的调度"><a href="#多-Region-的调度" class="headerlink" title="多 Region 的调度"></a>多 Region 的调度</h2><h3 id="TiKV-的做法"><a href="#TiKV-的做法" class="headerlink" title="TiKV 的做法"></a>TiKV 的做法</h3><p><a href="https://docs.pingcap.com/zh/tidb/stable/pd-scheduling-best-practices" target="_blank" rel="noopener">PD</a> 中有一些策略：</p><ol><li>balance-leader<br> 目的是均衡 client 请求服务的压力</li><li>balance-region<br> 目的是分散存储压力，防止爆盘。因此会在磁盘剩余空间充足的时候使得使用量均衡，在不充足的时候使得剩余量均衡。</li><li>hot-region-scheduler<br> 目的是分散热点 Region</li><li>location-labels</li></ol><p>实际上这些策略不太够，还需要：</p><ol><li>balance-leader-within-table</li><li>balance-region-within-table</li></ol><h1 id="事务相关"><a href="#事务相关" class="headerlink" title="事务相关"></a>事务相关</h1><h2 id="加锁的时机"><a href="#加锁的时机" class="headerlink" title="加锁的时机"></a>加锁的时机</h2><p>无论是悲观锁还是乐观锁，都面临加锁时机的选取。</p><p>在提交时加锁存在下面的问题：</p><ol><li>乐观锁的问题</li><li>因为整个事务需要缓存在内存中，所以大事务面临 OOM</li></ol><p>在 DML 时加锁存在下面的问题：</p><ol><li>每写一个 key 都要和 TiKV 通讯一次</li><li>多次对同一个 key 的 prewrite 无法确认先后（网络可能被任意延迟）</li><li>对 TiFlash 而言，因为列需要按照 commit_ts 排序，所以最好等到 commit 之后再行转列，而 DML 加锁意味着 DML 阶段 prewrite，那么在 DML 阶段就可以行转列了</li></ol><h2 id="Percolator-事务和共识层乱序"><a href="#Percolator-事务和共识层乱序" class="headerlink" title="Percolator 事务和共识层乱序"></a>Percolator 事务和共识层乱序</h2><p>在什么程度上共识层可以乱序呢？我的结论是：</p><ol><li>跨 Region 情况下会破坏线性一致读，并且从事务层修正的难度比较大，可能引入很长的等待</li><li>单 Region 上，如果保证 Lock 和 Write 的全局序，但只在发现事务 A 的第一个 commit 的时候，将事务相关的所有的 Default 写入，这种情况应该是可以的。对于较为基础的 case 我有 tla 证明<br> 根据具体实现，需要落盘 Default 和 Lock 是一起的，比如先落盘 Lock 再落盘 Default。可以不用原子落盘两个 cf。</li></ol><h1 id="Partitioned-RaftKV-相关"><a href="#Partitioned-RaftKV-相关" class="headerlink" title="Partitioned RaftKV 相关"></a>Partitioned RaftKV 相关</h1><h2 id="和-Mono-store-RaftKV-的兼容性问题"><a href="#和-Mono-store-RaftKV-的兼容性问题" class="headerlink" title="和 Mono-store RaftKV 的兼容性问题"></a>和 Mono-store RaftKV 的兼容性问题</h2><p>新架构简化了 Snapshot 的生成和注入流程：</p><ol><li>在生成时，只需要对当前 Region 对应的 RocksDB 做一个 Snapshot 就行。这个 Snapshot 包含的数据可以新于 Raft Local State。</li><li>在注入时，只需要重命名 RocksDB 文件夹即可。不需要处理 range overlap 的问题。因此不需要引入单线程的 region worker。</li></ol><p>因此 Mono-store RaftKV 需要处理下列问题：</p><ol><li>RocksDB 数据和 Raft 状态不一致。</li><li>Snapshot 的 Range 可能和其他本地 Region Overlap。</li></ol><p>不光是 Snapshot，在 Partitioned RaftKV 中，Region Peer 之间也可能互相 Overlap。所幸这个场景只会出现在 BatchSplit 和调度 Peer 发生冲突的情况下。</p><p>在新架构中，Apply 的落盘也实现了异步化，现在下层引擎可以选择在任意时刻落盘数据，并且在落盘完毕后通知 raftstore。这对 TiFlash 来说是一件好事，我们可以由此来让 KVStore 的落盘不再阻塞。</p><h2 id="采用更大的-Region-的性能影响"><a href="#采用更大的-Region-的性能影响" class="headerlink" title="采用更大的 Region 的性能影响"></a>采用更大的 Region 的性能影响</h2><ol><li>可以采用 Parallel Raft 的方式实现并行 Apply。</li><li>单个 Region 的 Apply 压力会增大，但是下层 RocksDB 的负担减轻了。相比于单个实例的 RocksDB，新架构的层数更少，并且并发写入也更少。后续还可以尝试支持多盘部署。</li></ol><p>另一个考量点是如果集群中出现很多小表，那么大 Region 的效果不能完全展示：</p><ol><li>因为编码的问题，table 编码不相邻的表不能被合并到同一个 Region 中。</li><li>相邻的 table 合并会给 TiFlash 带来不少问题。例如如果给一些小表添加 TiFlash 副本，并且这个小表被合并到一个大 Region 中，那么发来的 Snapshot 可能非常大，并且包含了大量 TiFlash 不需要的数据。此外，TiFlash 本身的存储引擎也需要做出调整。</li></ol><h1 id="TiFlash-相关"><a href="#TiFlash-相关" class="headerlink" title="TiFlash 相关"></a>TiFlash 相关</h1><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><h3 id="为什么-TiFlash-实现-HTAP-基于-Raft？"><a href="#为什么-TiFlash-实现-HTAP-基于-Raft？" class="headerlink" title="为什么 TiFlash 实现 HTAP 基于 Raft？"></a>为什么 TiFlash 实现 HTAP 基于 Raft？</h3><p>Raft 帮助我们实现：</p><ol><li>LB</li><li>HA</li><li>Sharding</li></ol><p>但是 TiFlash 只通过 Raft 同步各个表的 record 部分的数据。我们不同步索引，因为不需要。我们不同步 DDL 相关结构，因为并不是所有表都存在 TiFlash 副本。取而代之的是在解析失败，或者后台任务中，定期取请求 TiKV 的 Schema。</p><p>另一种强一致的方案是基于 CDC 和 safe TS，这样的方案理论上达不到和 Raft 一样的性能。这是因为类似 CDC 的方案的 safe TS 是基于表的，而 Raft 的 applied_index 是基于 Region 的。在一些场景下，如果一个 write 涉及到多个 Region，那么为了保证原子性，需要这些 Region 上的数据全部被写完，才能前进 ts，这会影响大事务的同步效率。另外，在读取时，也需要等待 safe TS 前进之后，才能读取。而基于 Raft 的方案只需要相关的 Region 的 applied_index 前进到 ReadIndex 就可以了。另外，CDC 也只保证单表事务。</p><h3 id="为什么在-TiSpark-之外还开发-TiFlash"><a href="#为什么在-TiSpark-之外还开发-TiFlash" class="headerlink" title="为什么在 TiSpark 之外还开发 TiFlash"></a>为什么在 TiSpark 之外还开发 TiFlash</h3><p>TiSpark 直接操作 TiKV，绕过了事务层，可能产生一致性问题。<br>TiSpark 没有自己的列式存储，处理分析性查询并不占优势。</p><h3 id="TiFlash-是副本越多越好么？"><a href="#TiFlash-是副本越多越好么？" class="headerlink" title="TiFlash 是副本越多越好么？"></a>TiFlash 是副本越多越好么？</h3><p>不是。理论上是 1 副本的性能最好，但是考虑到高可用，通常建议 2 副本。</p><p>1 副本性能最好的原因是，DeltaTree 的 Segment 的粒度要显著比 TiKV 的 region 大，因此同一个 Segment 上会存在多个 Region。</p><p>考虑存在 4 个 Region，从 A 到 D，如果只设置一个副本，其分布类似</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Store1: [A0, B0]</span><br><span class="line">Store2: [C0, D0]</span><br></pre></td></tr></table></figure><p>而如果设置两个副本，其分布类似</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Store1: [A0, B0, C0, D0]</span><br><span class="line">Store2: [A1, B1, C1, D1]</span><br></pre></td></tr></table></figure><p>假如一个查询同时覆盖这 4 个 region，那么一副本的情况下，Store1 和 Store2 分别扫描自己的一部分数据就行了。而两副本的情况下，则可能扫描到多余的 Region 的数据。</p><p>有一些人还会觉得副本数越多，并发能力越强。但在基于 Raft 的分区策略下，并发能力是通过合理的 Sharding 来提升的。而具体到一个副本上是可以支持大量的并发查询的，并且我们也更容易对这些查询做 Cache，当然在 AP 场景下可能有限。</p><h3 id="DDL-如何同步？"><a href="#DDL-如何同步？" class="headerlink" title="DDL 如何同步？"></a>DDL 如何同步？</h3><p>TiDB 的 DDL 的优化点：</p><ol><li>延迟 reorg 到读<br> 例如 add column 的 reorg 阶段实际上不会写入默认值，而是在读的时候才返回默认值。</li><li>以新增代替变更<br> 例如 alter column 只会扩大列的值域，比如 int8 扩大为 int64。如果涉及缩小至于或者改变类型，则会体现为新增一个 column，然后把老的 detach 掉。<br> 因此新的 Schema 能够解析老的 Schema。</li></ol><p>TiFlash 上 DDL 的特点：</p><ol><li>TiFlash 只需要同步需要表的 DDL。</li><li>TiFlash 只需要同步部分 DDL 类型，诸如 add index 等 DDL 并不需要处理，更没有 reorg 过程。</li><li>尽管 TiDB 将 schema 存在 TiKV 上，但 TiKV 是 schemaless 的。所以如果 TiFlash 只从 TiKV 同步数据，就会涉及解码等工作。</li></ol><p>因此，TiFlash 有两种 DDL 同步方式：</p><ol><li>定期拉取（一般是 10s）并更新<br> 根据 TiFlash 和 TiDB 上 version 落后的情况，可以分为拉 diff 和拉全量。<br> 该方式已经能解决大部分 drop table 的问题了。但通过该方式无法保证当前任意时间点上的 schema 一定和 TiDB 是一致的，所以一定存在解析失败的情况。</li><li>当解析 row 失败的时候更新 schema，称为 lazy sync</li></ol><p>在更新之后，TiFlash 会自己维护一份 schema。</p><p>这里面存在的问题主要是两种 DDL 同步方式和实际 raft log 是异步的。因为 TiDB 和 TiFlash 的特点，这个异步是可以被处理的，并且尽可能去掉全序的依赖是很多系统的设计理念，所以这种做法本身也是挺好的，但其中 corner case 很多。例如：</p><ol><li>Schema 和 row data 中的列数对不上。这种情况无论是谁缺，至少可以通过拉一次 Schema 来解决。有些场景甚至可以不拉 schema。</li><li>某个列的类型变了</li><li>一张表 drop 后，TiKV 中就无法读取该表的 schema 了。如果在 drop 前有一条 add column，但 lazy sync 又没有读到，那么 TiFlash 就看不到。所以如果后续有一条 row 写入过来，TiFlash 就会丢弃这个 column。假如这个 table 被 recover 了，那么 TiFlash 就会读不到这个 column 的数据。</li><li><a href="https://github.com/pingcap/tiflash/pull/8422" target="_blank" rel="noopener">在</a>一张表对应的 DeltaMerge 实例创建前，这张表就被 drop 掉了。在此之后，row 数据到来，并导致 DeltaMerge 实例被创建。</li></ol><h3 id="TiFlash-的高可用"><a href="#TiFlash-的高可用" class="headerlink" title="TiFlash 的高可用"></a>TiFlash 的高可用</h3><p>对于复制自动机的系统，高可用主要取决于选举的速度。<br>对于 TiFlash 来说，它不参与选举，但选举本身同样会有影响，一方面是 ReadIndex，另一方面是无主的时候无法复制日志。但除此之外，TiFlash 自身的宕机和重启也影响高可用。因为一个批量查询会被下推给 tiflash，以避免影响 TP，如果此时 TiFlash 没追上，则查询会 hang 住。所以 TiFlash 的高可用还和追日志的规模有关。</p><h2 id="Raft-共识层"><a href="#Raft-共识层" class="headerlink" title="Raft 共识层"></a>Raft 共识层</h2><h3 id="有关-Learner-的问题"><a href="#有关-Learner-的问题" class="headerlink" title="有关 Learner 的问题"></a>有关 Learner 的问题</h3><h4 id="Peer-活性"><a href="#Peer-活性" class="headerlink" title="Peer 活性"></a>Peer 活性</h4><p>Learner 尽管在 Raft Group 中，但不参与投票。所以当 Voter 节点因为 Region 被销毁（通常因为 merge）全部被销毁后，Learner 节点就无法找到 Leader 节点。对于 Voter 节点来说，这种情况它可以发起选举，然后发现其他节点上的 Tombstone 标记，从而确认 Region 已经被摧毁了。但因为 Learner 不参与投票，所以是无法发现这种情况的，从而僵死。这给 TiFlash 带来了不少 Corner Case：</p><ol><li>在 Region 销毁的场景如 CommitMerge，target region 的 Voter 至少可以在 Leader 销毁之后，因为超时触发选举，从而启动自毁。而 Learner 则不行，会 miss leader 然后卡死<br> 特别地，CommitMerge 本身对 Source Peer 也会有检查，所以这里可能造成连环等待。比如如果在等待 Source 追数据，就会 Yield 为 WaitMergeSource。如果卡在 CommitMerge 上，那么后续的 RemovePeer 也无法执行。</li><li>在 ConfChange 中，如果删除了某个 Learner，但又没有能够将该日志复制给 Learner，那么稍后 Learner 就不会得到 Leader 的任何消息，从而一样卡死。</li><li>在 BatchSplit 中，如果新 Split 出来的 Region 在 TiFlash apply BatchSplit 命令前就在所有 Voter 节点中被删除的话，后续 TiFlash 节点即使 apply 完 BatchSplit，也无法再收到任何日志，因为 Leader peer 已经不存在了</li></ol><p>上述的卡死在之前需要等待 2h 之后触发存活性检查才会被发现。或者人工将僵死的 Region peer 设置为 tombstone 状态。</p><h4 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h4><p>另外，Raft Log GC 也需要 respect Learner 的进度，不然会导致频繁的 Snapshot 生成失败。</p><h3 id="有关-Learner-Read"><a href="#有关-Learner-Read" class="headerlink" title="有关 Learner Read"></a>有关 Learner Read</h3><p>由 Follower Read 派生出来的 Learner Read 也让 TiFlash 成为一个强一致的 HTAP。</p><h4 id="Learner-Read-和-commit-ts"><a href="#Learner-Read-和-commit-ts" class="headerlink" title="Learner Read 和 commit_ts"></a>Learner Read 和 commit_ts</h4><p>即使有在 read index 的时候推进 max ts 的机制，依然会发生在收到 Leader 关于带有 read_ts 的 Read Index 请求的回复后，在 Wait Index 超过返回的 applied_index 之后，看到具有更小的 commit_ts 的提交。但这种情况并不会导致问题，因为在 applied_index 之前，我们至少可以看到对应的锁。</p><p>比如 read_ts 是 10，返回了 applied_index 是 1000。那么在 apply 到 1001 时，可能它对应了一个 commit_ts 为 5 的事务。这里可以参考我之前对并发事务的讨论。</p><h4 id="Read-index"><a href="#Read-index" class="headerlink" title="Read index"></a>Read index</h4><p>TiFlash 自己给自己发送一个 ReadIndex Command，后者会触发一个 ReadIndex Message。为什么要这么做呢？因为走 ReadIndex Command 的链路才是完整的，否则会丢掉包括要求 Concurrency manager 推高 max_ts 的部分。</p><ol><li>对 Leader，会检查 Lease 并续约，之后再 Read</li><li>对 Follower，会推动 Raft 发送 RaftIndex 类型的 RaftMessage 给 Leader。这个 RaftMessage 包含一个 raft_cmdpb::ReadIndexRequest 作为 entry.data。</li></ol><p>在处理 ReadIndex RaftMessage 时候，会推进 maxts 并且返回 memlock。</p><p>具体来说：</p><ol><li>根据 read tso 和 range 构造一个 kvrpcpb::ReadIndexRequest</li><li>ReadIndex 接受这个 kvrpcpb::ReadIndexRequest</li><li>创建一个 raft_cmdpb::Request<br> 其类型为 CmdType::ReadIndex。将 kvrpcpb::ReadIndexRequest 中的数据移动到 raft_cmdpb::Request 中。</li><li>通过 RaftRouter 发送这个请求，并等待回调。</li></ol><p>这里 ReadIndexRequest 中传入的 start_ts 会间接推高 min_commit_ts。其原理是一个事务涉及多个 key，则这些 key 依次 prewrite 的时候，后面 prewrite 的 key 的 min_commit_ts 会因为 max_ts 变得更高，尽管前面 key 的 min_commit_ts 是一直不变的。最终事务提交的 ts 是所有的 key 的 min_commit_ts 取最大。</p><h4 id="Batch-read-index"><a href="#Batch-read-index" class="headerlink" title="Batch read index"></a>Batch read index</h4><ol><li>在同一个查询中，如果一个 Region 上已经被做过 read index，则复用</li><li>在同一个 Region 上的每个 Read index 请求前，首先查询历史记录，看看是否有对应 ts 的记录可以复用</li><li>同一个 Region 上的多个 Read index 请求组成一个 batch，用其中的最大的 ts 去请求 TiKV leader。如果发现有 memlock，则返回这个 lock。这说明这个 ts 上有 lock，而其他的 ts 则不确定需要重试。如果返回没有 lock 则使用最大的 index 来重试。</li></ol><p>注意，没有 memlock 并不代表没有 lock。一个 key 上是否有 lock，还需要读 lock cf 来判断。memlock 的引入是 Async Commit 导致的。memlock 指的是在某个短暂阶段，事务层上有一些锁在内存中，还没有写到 raftstore。</p><h4 id="Remote-Read-机制"><a href="#Remote-Read-机制" class="headerlink" title="Remote Read 机制"></a>Remote Read 机制</h4><p>TiFlash 中存在 Remote Read 机制，在 BatchCop 的 prepare 阶段，会分析哪些 Region 是可以本地读的，哪些 Region 是需要从其他 TiFlash 读的。在存算分离版本的 TiFlash 中，CN 通常都需要进行 Remote Read 从对应的 WN 读取最新的数据。</p><p>在 Remote Read 的过程中，也会触发 Resolve Lock 机制，从而推动 TiKV 去判断事务提交与否。这个通常对应了 Cop 请求的发送和处理。Remote Read 请求可能最终还是发送给自己。</p><h4 id="Bypass-lock-机制"><a href="#Bypass-lock-机制" class="headerlink" title="Bypass lock 机制"></a>Bypass lock 机制</h4><p>这是 Learner read 层的优化。<br>TiFlash 存在 remote read 的机制。在第一次遇到 lock 的时候，会由 client-c 去 resolve lock。此时，会有几种情况：</p><ol><li>事务已经 commit 了，并且 commit_ts 大于 read_ts</li><li>事务还没有 commit，但是 min_commit_ts 大于 read_ts</li><li>其他情况</li></ol><p>对于第一、二种情况，我们不应该读到这个锁对应的数据。它们都保证了事务已经或者最终要以高于 read_ts 的 ts 来提交。因此，既然这个 lock 对应的写入是不需要对 read_ts 的读可见的，因此在下一次读的时候，就可以 bypass 掉这个 lock，而不需要等待它们的 commit 了。</p><h4 id="Read-through-lock-机制"><a href="#Read-through-lock-机制" class="headerlink" title="Read through lock 机制"></a>Read through lock 机制</h4><p>这是一个事务层的优化。<br>Read through lock 特性指的是当确定某个事务可以被 commit 的时候，跳过 resolve lock 的过程，而直接读。而这锁最终会被下一次写同一个 key 的时候 resolve。<br>具体做法是，它首先是事务上一个 secondary key 的锁，我们在通过 secondary lock 去查询 PK 的 lock 的时候，会发现 PK 上的事务提交了。因此，这个事务一定是提交了的，所以可以 read through lock。<br>这个“lazy”地 resolve lock 的方式也被用在了大事务的支持上。</p><h3 id="Raft-Log-的存储"><a href="#Raft-Log-的存储" class="headerlink" title="Raft Log 的存储"></a>Raft Log 的存储</h3><h2 id="存储-–-KVStore"><a href="#存储-–-KVStore" class="headerlink" title="存储 – KVStore"></a>存储 – KVStore</h2><h3 id="为什么在列存前还有一个-KVStore？"><a href="#为什么在列存前还有一个-KVStore？" class="headerlink" title="为什么在列存前还有一个 KVStore？"></a>为什么在列存前还有一个 KVStore？</h3><p>在 CStore 模型中，WS 和 RS 都是列存，WS 的数据通过 Tuple Mover 被批量合并到 RS 中。体现在 TiFlash 中，WS 是 DM 中基于 PS 的 Delta 层，而 RS 是 Stable 层。</p><p>除此之外，TiFlash 还有一个 KVStore，目的是：</p><ol><li>保存未提交的数据，并实现 Percolator 事务的部分功能<br> 因为只有已提交的数据才会写入行存，为了和 Apply 状态机一致，所以未提交的数据同样需要持久化，因此引入 KVStore。</li><li>KVStore 管控 Apply 进度，对 DM 屏蔽了上游。DM 可以异步落盘。日志复制的架构下，上游的落盘进度不能比下游更新，因为下游更新，重放是幂等的；而上游更新，会丢数据。</li></ol><h3 id="为什么不将未提交的数据直接写在列存中呢？"><a href="#为什么不将未提交的数据直接写在列存中呢？" class="headerlink" title="为什么不将未提交的数据直接写在列存中呢？"></a>为什么不将未提交的数据直接写在列存中呢？</h3><ol><li>KVStore 需要负责维护 apply 状态机<br> 当然我们可以将这一部分作为单独的 Raft 模块，所以这不是很 solid 的理由。</li><li>KVStore 不仅是一个容器，还是 Percolator 事务的执行器<br> 例如，它需要维护当前 Region 上的所有 Lock。在一个查询过来时，需要检查该查询是否和 Lock 冲突，并尝试 resolve lock。而在列存中维护 lock cf 会很奇怪。</li><li>这意味着要执行近乎实时的行转列<br> 首先，如果存一些未提交数据在 KVStore 中，然后在提交时 batch 执行行转列，有可能可以只读取一次 schema 结构，减少开销。<br> 其次，TiDB 中存在乐观事务和悲观事务。如果使用乐观事务，并且冲突比较大，那么很可能 TiFlash 要花费大量时间在多余的行转列上。</li></ol><p>实际上，在后续支持大事务的实践中，我们确实会进行一部分提前的行转列。但这是处于内存的优化，并且也存在很大的局限，例如暂时无法做到跨 Region Spill。</p><h3 id="KVStore-的落盘模式相关问题"><a href="#KVStore-的落盘模式相关问题" class="headerlink" title="KVStore 的落盘模式相关问题"></a>KVStore 的落盘模式相关问题</h3><p>理论上 KVStore 也可以做到独立写盘，从而使得 DM 的落盘进度不会阻塞 Raft Log 的回收。缺点是会使 KVStore 完全变成上游，写链路更长。虽然我们底层用的 PS，Compaction 相对较少，但同样有写放大。但这目前也无法实现，因为：</p><ol><li>KVStore 落盘是全量的，KVStore 和 DM 的内存操作又绑在一块。<br> 这导致在落盘 KVStore 前必须先落盘 DM。并且整个过程还需要加自己的锁，否则会导致数据丢失，而加锁导致阻塞 Apply。特别在一些场景下，少量的 Raft Log 就会导致 KVStore 和 DM 的落盘，严重影响读取延迟。</li><li>Raftstore V1 的 Apply 落盘又是同步的。<br> 在 Raftstore V1 中，写入的数据可能在操作系统的 Page Cache 中，也有可能被刷入了磁盘。如果是前者，那么会在 raftlog_gc 等地方被显式地 sync。但困难在于，V1 中无法精确获得这些时刻，从而进行通知。又因为 TiFlash 的状态不能落后于 Proxy，否则 Proxy 的 applied_index 可能比 KVStore 新从而丢数据。所以这里索性当做同步落盘处理，让 TiFlash 先落盘。代价是我们要劫持 TiKV 所有可能写 apply state 的行为，哪怕这个写不是 sync 写。后面会介绍我的一些异步落盘的想法。</li></ol><p>一个优化方案是解耦 KVStore 和 DM 的落盘。也就是在 DM 落盘后，再清理掉 KVStore 中的数据。这需要将 Region 中的数据拆分成 KV 对落盘，但这会失去对 KV 对做聚合的能力，从而将顺序写转换为随机写，如果写入很密集，性能也许会比较差，所以这个在功能和性能上都依赖 UniPS。</p><p>另一种方案比较简单，也就是限制由 KVStore，实际上就是 Raftstore 发起的落盘，改为由 DM 发起。但这个方案并不感知 Raft Log 的占用，可能导致它膨胀。</p><p>前面提到异步落盘 KVStore 的问题，一个思路是落盘时使用过去的状态+当前的数据。但存在一些问题：</p><ol><li>这个“过去的状态”也需要比 DM 的落盘状态要新，所以还是要先加锁获取 KVStore 状态，再无锁落盘 DM，再用旧状态落盘 KVStore。这样不能解耦和 DM 的落盘，但能够在落盘 DM 的时候无锁已经很好了。</li><li>Split/Merge 或者可能 Apply Snapshot 改变了全局状态。这样的指令在 V1 中是不能被重放的，不然新 Split 出来的 Region 可能和重启前已经被 Split 和 Persist 出来的 Region 冲突。这样就需要在处理这些 Admin 指令的时候同步等待异步的 Persist 完成。其实更简单的方式是根据之前加锁获取的状态来推断有没有执行这些 Admin。</li><li>需要让 KVStore 支持其他命令的重放。目前来看，应该存在一些 corner case。</li><li>需要让 KVStore 通知 Proxy，当前落盘的 applied_index 并不是期望的 applied_index。这实际上破坏了 TiKV 的 MultiRaft 约束，更好的方式是拒接来自 Proxy 的落盘请求，然后从 KVStore 重新主动发起一个。</li><li>落盘 KVStore 同样需要加锁，从而阻塞 Raft 层的写入。</li></ol><p>另一种方案是过去的状态和过去的数据。比如可以在 KVStore 在落盘时，新开一个 Memtable 处理新写入。此时需要处理新 Memtable 上的 Write 可能依赖老 Memtable 上的 Default 之类的问题。这样的好处是在落盘 KVStore 的时候都不需要加锁了。但是还存在两个问题：</p><ol><li>在这前面需要落盘 DM，当然这个锁先前说了可以去掉。</li><li>如果写入很大，那么可能在旧的 Memtable 还没写完之前，新的 Memtable 就满了。这样还是 Write Stall。</li></ol><p>如果希望彻底和 DM 解耦，就需要想办法保存上次 DM 落盘到现在落盘 KVStore 期间被写到 DMCache 上的数据。这是困难的。</p><h3 id="KVStore-如何处理事务"><a href="#KVStore-如何处理事务" class="headerlink" title="KVStore 如何处理事务"></a>KVStore 如何处理事务</h3><p>在每一次 Raftstore 的 apply 写入时，会遍历所有 write 写入，并进行事务提交，也就是将数据从 KVStore 移动到 DeltaMerge。事务提交并不一定落盘，大部分情况是写在 DeltaMerge 的 DeltaCache 中的。<br>如果出现事务 rollback 回滚，则 TiKV 不仅会删除掉之前写的 default 和 lock，还会写一条 Rollback 记录，它也会被写到 Write CF 中，其用途是避免同 start_ts 事务再次被发起，client 需要用新请求的 start_ts。<br>可以看到，因为共识层的存在，TiFlash 无需处理事务 rollback 的问题。这也是 KVStore 存在的意义之一。</p><h3 id="KVStore-的存储格式"><a href="#KVStore-的存储格式" class="headerlink" title="KVStore 的存储格式"></a>KVStore 的存储格式</h3><h4 id="是否直接用-protobuf-存储-Region？"><a href="#是否直接用-protobuf-存储-Region？" class="headerlink" title="是否直接用 protobuf 存储 Region？"></a>是否直接用 protobuf 存储 Region？</h4><p>protobuf 具有的几个特性让它不适合存储 Region：</p><ol><li>较大的 size 下性能较差</li><li>不能只读取部分数据</li></ol><h4 id="是否使用-flag-存储-Region-Extension？"><a href="#是否使用-flag-存储-Region-Extension？" class="headerlink" title="是否使用 flag 存储 Region Extension？"></a>是否使用 flag 存储 Region Extension？</h4><p><a href="https://github.com/pingcap/tiflash/issues/8590" target="_blank" rel="noopener">https://github.com/pingcap/tiflash/issues/8590</a> 不建议这样做。</p><h3 id="Raft-机制带来的内存和存储开销"><a href="#Raft-机制带来的内存和存储开销" class="headerlink" title="Raft 机制带来的内存和存储开销"></a>Raft 机制带来的内存和存储开销</h3><p>有没有可能 TiFlash 自己 truncate 日志呢？理论上 Learner 不会成为 Leader 从而发送日志，也不会处理 Follower Snapshot 请求。而 Raft 协议本身就是让每个节点自己做 Snapshot 然后 truncate 日志的。</p><p>我们在云上 TiFlash 做这样的称为 Eager GC 的优化，因为云上使用的 UniPS 对内存更敏感。PageDirectory 为每个 Page 占用大约 0.5KB 的内存。另一方面，UniPS 全部受我们控制，所以相比 Raft Engine 也更好做透明的回收。透明回收小于 persisted applied_index 的所有 Entry，如果 Raftstore 会访问已经被回收的 Entry，会给一个 Panic。</p><h3 id="TiFlash-如何处理-Raft-Snapshot？"><a href="#TiFlash-如何处理-Raft-Snapshot？" class="headerlink" title="TiFlash 如何处理 Raft Snapshot？"></a>TiFlash 如何处理 Raft Snapshot？</h3><ol><li>raftstore 执行 apply snapshot</li><li>raftstore 将 snapshot 入队 region worker</li><li>TiFlash 进行 Prehandle</li><li>TiFlash 执行 apply snapshot data</li></ol><h3 id="为什么-TiFlash-不处理-DeleteRange？"><a href="#为什么-TiFlash-不处理-DeleteRange？" class="headerlink" title="为什么 TiFlash 不处理 DeleteRange？"></a>为什么 TiFlash 不处理 DeleteRange？</h3><p>TiKV 通过 DeleteRange 来删表。TiFlash 则是通过拉取 DDL，并确保已经过了 gc safepoint 后，才会物理删除表。</p><p>需要注意的是，除了删表之外，pd 可能从 TiFlash 调度走某个 Region，这也涉及删除操作。对于这样的操作，TiFlash 就得立即响应。</p><p>在 gc 时，在 write cf 上写一个 DEL 记录，也就是所谓的 tombstone key 是比较少见的。现在的做法是在 Compaction 的时候将这些 key filter 掉。<br>当然 DEL lock cf 是很常见的，这通常发生在提交事务的时候。</p><h2 id="存储-–-列存"><a href="#存储-–-列存" class="headerlink" title="存储 – 列存"></a>存储 – 列存</h2><h3 id="为什么-TiFlash-使用-DeltaTree-作为存储"><a href="#为什么-TiFlash-使用-DeltaTree-作为存储" class="headerlink" title="为什么 TiFlash 使用 DeltaTree 作为存储"></a>为什么 TiFlash 使用 DeltaTree 作为存储</h3><p>目的是为了适应频繁的更新。我们采用类似 <a href="https://gogim1.github.io/posts/c_store" target="_blank" rel="noopener">CStore</a>的思路，引入了 PageStorage 这个对象存储。其中针对写优化的部分称为 Delta 层，类似于 RocksDB 的 L0，存储在 PageStorage 中。针对读优化的部分称为 Stable 层，以 DTFile 文件的形式存储，但文件路径在 PageStorage 作为 External Page 的形式维护。</p><h3 id="存储模型的进一步讨论"><a href="#存储模型的进一步讨论" class="headerlink" title="存储模型的进一步讨论"></a>存储模型的进一步讨论</h3><h4 id="和-StarRocks-的比较"><a href="#和-StarRocks-的比较" class="headerlink" title="和 StarRocks 的比较"></a>和 StarRocks 的比较</h4><p>例如可以将 update 操作分为 delete 和 insert 操作。查询时，同时查询 delete 和 insert，并决定最终的输出。StarRocks 使用这样的方式，他们指出 Delete+Insert 这样的模式<a href="https://zhuanlan.zhihu.com/p/566219916" target="_blank" rel="noopener">有利于下推 Filter</a>。StarRocks 据此实现了<a href="https://docs.starrocks.io/zh/docs/table_design/table_types/primary_key_table/" target="_blank" rel="noopener">主键模型</a>。<br>这里需要区分他们的<a href="https://docs.starrocks.io/zh/docs/table_design/table_types/unique_key_table/" target="_blank" rel="noopener">更新模型</a>，也就是一种不支持 MVCC，始终返回最新数据的模型。这种模型应该就是一种类似 LSM 的方案，在 Compaction 的时候只保留一个版本。但是在查询的时候仍然需要 merge 多个版本，并且不支持下推 filter。<br>主键模型的优势就是查询时不需要 merge，并且支持下推 filter 和索引。这种方式主要是将主键索引加载到内存中，对于 Update 操作，通过主键索引找到记录的位置，写一个 Delete，然后再写一个 Insert。可以发现这种方案仍然是不支持 MVCC 的，我理解如果要支持 MVCC 那么 merge 可能是必然的。<br>此外，主键模型对内存是有开销的，我理解这个应该不是关键问题。首先，如果数据有冷热之分，可以持久化一部分主键索引到磁盘上。其次，这个场景在大宽表有优势。</p><h4 id="来自-TiKV-的约束"><a href="#来自-TiKV-的约束" class="headerlink" title="来自 TiKV 的约束"></a>来自 TiKV 的约束</h4><p>从 Raft 层接入数据导致 TiFlash 的存储层的分区会收到 TiKV Key Format 的影响。例如尽管 TiFlash 的 Segment 和 TiKV 的 Region 并不对应，Segment 远大于 Region。但它们都被映射到同一个 Key Range 上。</p><p>这就导致 TiFlash 数据的物理排列一定是根据 TiKV 的主键有序的，TiFlash 无法自行指定主键。另外 TiFlash 本身也没有二级索引。</p><p>目前来自 TiKV 的约束有：</p><ol><li>MVCC 字段<br> 如果要和 TiDB 一起玩，就必须要支持 MVCC，不能只保存最新的版本。</li><li>Unique 的主键</li></ol><h3 id="DM-的-Delta-层是如何实现的？"><a href="#DM-的-Delta-层是如何实现的？" class="headerlink" title="DM 的 Delta 层是如何实现的？"></a>DM 的 Delta 层是如何实现的？</h3><p>PageStorage 先前使用 Append 写加上 GC 的方案，但带来写放大、读放大和空间放大。因为这里 GC 采用的 Copy Out 的方式，所以理论上写放大和空间放大构成一个 trade off：</p><ol><li>如果允许更少的有效数据和更多的碎片，那么空间放大更严重</li><li>否则，写放大更严重</li></ol><p>旧的 PageStorage 主要存在下面的问题：</p><ol><li>GC 开销很大，因为需要遍历所有的 Version 或者说 Snapshot 才能得到可以被安全删除的数据。这样会产生很多额外的遍历。</li><li>每张表一个实例，如果存在很多小表，则会产生非常多的文件，甚至会用光 fd。</li><li>冷热数据分离。因为 meta 一般会被频繁更新，而实际上存在一些比较冷的 data。这会导致冷 data 阻碍 meta 进行 gc，这样会产生空间放大。到一定程度之后，又会触发 gc，进一步加剧问题。</li></ol><p>在 SSD 盘上，随机写和顺序写的差距不大，原因是 FTL 会将随机写转换为顺序写，所以寻址相关的开销并不是很大。尽管如此，顺序写依然存在优势，首先顺序写可以做聚合，同样的 IOPS 写入带宽是会比随机写要大很多，然后是顺序写的 gc 会更容易。此外，因为变成随机读，性能会变差。特别是对类似 Raft Log 这样的 scan 场景。</p><p>新一版本的设计，TiFlash 会通过 SpaceMap 尽量选择从已有的文件中分配一块合适的空间用来写入 blob。当 blob 被分配完毕后，多个 writer 可以并发地写自己的部分。在写入 blob 完成后，会写 WAL 记录相关元信息。在这之后就可以更新内存中的数据。</p><h3 id="DM-的-Stable-层是如何实现的？"><a href="#DM-的-Stable-层是如何实现的？" class="headerlink" title="DM 的 Stable 层是如何实现的？"></a>DM 的 Stable 层是如何实现的？</h3><p>Stable 层数据是按照 DTFile 的形式存储的，且每个 DTFile 中包含多个 Pack，一个 Pack 默认是包含 8192 行数据。但是相同主键不同版本的行都会写在一个 Pack 里面，目的之一是方便构造 Min-Max 索引。</p><p>我们为每个 Pack 维护一个 Min-Max 索引，这样可以在扫描的时候比较方便地跳过某些 Pack。理论上 Pack 越小，MinMax 索引的效率越好。因为更容易有 Pack 被整个选中，或者整个拒绝。</p><h3 id="为什么只有-Min-Max-索引？"><a href="#为什么只有-Min-Max-索引？" class="headerlink" title="为什么只有 Min-Max 索引？"></a>为什么只有 Min-Max 索引？</h3><p>还有其他索引没有来得及实现。</p><p>但对于 BloomFilter 这是一个例外，因为按照目前 TiFlash 的查询 Pattern，布隆过滤器在大部分场景下优化不是很大，这样的查询其实是可以下推给 TiKV 来做的。只有在一些子查询里面如果出现点查，则可能会有作用。</p><h3 id="为什么-DM-的-Stable-只有一层？"><a href="#为什么-DM-的-Stable-只有一层？" class="headerlink" title="为什么 DM 的 Stable 只有一层？"></a>为什么 DM 的 Stable 只有一层？</h3><p>DM 的设计目标包含优化读性能和支持 MVCC 过滤。这就导致要<a href="https://tidb.net/book/tidb-monthly/2022/2022-04/update/tiflash-storage" target="_blank" rel="noopener">解决下面的场景</a>：</p><blockquote><p>TiFlash 有比较多的数据更新操作，与此同时承载的读请求，都会需要通过 MVCC 版本过滤出需要读的数据。而以 LSM Tree 形式组织数据的话，在处理 Scan 操作的时候，会需要从 L0 的所有文件，以及其他层中与查询的 key-range 有 overlap 的所有文件，以堆排序的形式合并、过滤数据。在合并数据的这个入堆、出堆的过程中 CPU 的分支经常会 miss，cache 命中也会很低。测试结果表明，在处理 Scan 请求的时候，大量的 CPU 都消耗在这个堆排序的过程中。</p></blockquote><blockquote><p>另外，采用 LSM Tree 结构，对于过期数据的清理，通常在 level compaction 的过程中，才能被清理掉（即 Lk-1 层与 Lk 层 overlap 的文件进行 compaction）。而 level compaction 的过程造成的写放大会比较严重。当后台 compaction 流量比较大的时候，会影响到前台的写入和数据读取的性能，造成性能不稳定。</p></blockquote><p>为了缓解单层带来的写放大，DM 按照 key range 分成了多个 Segment。每个 Segment 中包含自己的 Stable 和 Delta。其中 Delta 合并 Stable 会产生一个新的 Stable。</p><h3 id="为什么-TiFlash-按-TSO-升序存储？"><a href="#为什么-TiFlash-按-TSO-升序存储？" class="headerlink" title="为什么 TiFlash 按 TSO 升序存储？"></a>为什么 TiFlash 按 TSO 升序存储？</h3><p>TiKV 的 TSO 按照逆序存，有利于找新版本。<br>TiFlash 因为都是处理扫表，所以逆序的收益不是很大。ClickHouse 使用升序存储，所以 TiFlash 也沿用了升序。<br>但这里就导致在处理 Snapshot 写入的时候，需要读完每个 row key 的所有版本，并在一个 read 调用中返回给下游的 stream。</p><h2 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h2><h3 id="为什么-TiFlash-没有-buffer-pool"><a href="#为什么-TiFlash-没有-buffer-pool" class="headerlink" title="为什么 TiFlash 没有 buffer pool"></a>为什么 TiFlash 没有 buffer pool</h3><p>对于 AP 负载，扫表的数据规模很大，Cache 起不到太大作用。</p><h2 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h2><h3 id="弹性的资源管理和存算分离"><a href="#弹性的资源管理和存算分离" class="headerlink" title="弹性的资源管理和存算分离"></a>弹性的资源管理和存算分离</h3><p>在目前的计算机架构下，进程是资源的分配单位。这就意味着如果程序对除了 CPU 之外的某个资源的需求存在很大的弹性，那么就需要将这一部分单独剥离出来。<br>TiFlash Cloud 中就使用了存算分离，当然还使用了 OSS 等方案，但我认为是正交的设计。</p><h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p>历史上计算层出现过不少因为查询过大导致的 OOM，计算层通过 kill query 或者 spill 的方式进行解决。但存储层目前还缺少这块。理论上存储层的开销主要分为几类：</p><ol><li>Memtable<br> 包含 KVStore 的 RegionData 和 DeltaTree 的 DeltaCache。<br> 这类场景下，OOM 主要发生在大事务场景。</li><li>Cache<br> 主要用来服务计算节点，列存主要是扫表，所以没有做 Block cache 或者 row cache。</li><li>索引<br> 包含 DeltaTree 的 DeltaIndex，PageStorage 的 PageDirectory 等。</li><li>Compact 相关，比如 delte merge 等</li><li>行转列相关</li></ol><p>在一些场景下，因为存储层和计算层并不互相感知，会导致存储层会被计算层的大任务干到 OOM 或者报异常。而实际上这些任务可以被 kill，stall 或者通过 kill query 抢占计算层的内存。</p><p>因此，在 TiFlash 侧实现一个<a href="/2024/08/23/monitor-alloc-in-C++/">统一的内存管理</a>还是有必要的。</p><h4 id="空指针"><a href="#空指针" class="headerlink" title="空指针"></a>空指针</h4><p>严格来讲避免空指针也不完全算是内存管理。但确实是工作中遇到的一个比较关键的问题。我在 <a href="/2023/01/12/high-concurrency/">分布式架构和高并发相关场景</a> 这篇文章里面说吧。</p><h3 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h3><h3 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h3><h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><h3 id="off-CPU"><a href="#off-CPU" class="headerlink" title="off-CPU"></a>off-CPU</h3><p>off-CPU 例如在等待阻塞 IO、锁、page swap 等的时间。这些时间不会通过普通的火焰图被反映出来，但却是影响读取性能的一个因素。我们常常要回答问题，为什么我们的 CPU 没有被用满，但是查询依然比较慢。</p><h1 id="TiFlash-Cloud"><a href="#TiFlash-Cloud" class="headerlink" title="TiFlash Cloud"></a>TiFlash Cloud</h1><h2 id="快速扩容-FAP-What-amp-why？"><a href="#快速扩容-FAP-What-amp-why？" class="headerlink" title="快速扩容(FAP) What &amp; why？"></a>快速扩容(FAP) What &amp; why？</h2><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><ol><li>复用 TiFlash 行转列的结果。减少 TiKV 生成、传输和 TiFlash 接收、转换 Snapshot 的开销。<br> 在测试中，发现能够减少 96% 的 CPU 开销和 20% 的内存开销。<br> 如果提升调度的 limiter，能够大幅提高吞吐量，体现为添加副本总时间的减少。但该增长不是线性的，也取决于 TiFlash 侧线程池的大小，以及串行 ingest 的开销。<br> 需要注意，因为 Region 和 Raft Group 绑定，导致 FAP 必须等待 apply Confchange 之后的 Checkpoint，所以对于单个小 Region 来说，可能要花费更长的时间来处理。<br> 目前，TiFlash 上会有一些自建索引，FAP 也会避免这些自建索引被重复构建。</li><li>利用如 S3 的特性，减少跨 Region 通信。</li><li>提高副本迁移，特别是单副本迁移的效率。</li><li>在扩容场景下，新节点可能因为处理全量 Snapshot 更慢，导致进度落后，从而进一步触发全量 Snapshot。此时新机器无法处理被 dispatch 过来的请求。</li></ol><h3 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h3><ol><li>使用 PageStorage 替换 RaftEngine。这样使得 Raft、KVStore 和 DeltaTree 数据都一起被存到同一个 checkpoint 里面，保证原子性和一致性。</li><li>副本选择和由 Learner 管理的副本创建。用来快速扩容的 TiFlash Checkpoint，必须要比扩容对应的 confchange log entry 要新。这是因为 TiKV 通过一个 Snapshot 来帮助新 node 追日志，而这个 Snapshot 必然在 confchange 后产生。如果接受一个更早的 Checkpoint，那么就要确保 raft 能够给新 peer 发送 confchange 前的日志。即使能，这也意味着新 peer 要处理添加自己的 confchange cmd。即使通过忽略等方案处理，那么在这之前的 batch split cmd 就需要伪装成生成 Checkpoint 的那个 peer，并将这个 region 重新切开（涉及一些行转列和写盘）。而如果与此同时，batch split 得到的某个 split 的最新版本又通过正常途径调度过来，并且在 apply snapshot，那么这里就可能产生 region overlap 导致的数据问题。可以看出，因为违反了 TiKV 的约束，所以产生了很多的潜在问题。</li><li>注入数据。需要注意，原有的 TiKV 的通过 Snapshot 初始化副本的流程需要重新走一遍。</li><li>对旧版本数据的清理。</li></ol><p>这个 feature 类似于 Learner Snapshot，所以为什么不通过 Follower/Learner Snapshot 来实现 FAP 呢？</p><ol><li>TiKV 主要需要该 Feature 来避免跨地区的 Snapshot 复制，而 TiFlash 需要该 Feature 实现异构的 Snapshot，侧重点上有所不同。</li><li>该 feature 需要在 TiKV 或者 PD 等组件中实现一定的调度机制。所以 FAP 实际可以视为一个部分的实现，后续有可能进行推广。届时 FAP 的 phase 1 过程就有可能被移动到 prehandle snapshot 中处理了。</li><li>Follower Snapshot 有可能会失败，例如 Follower 节点实际上做不了该 Snapshot。此时 Snapshot 依然会由 Leader 来处理。目前 TiKV 的模型还不支持这种模式。<br> FAP 可以实现从 FAP Snapshot 到 Regular Snapshot 的 fallback。具体来说，如果构建失败后，FAP 就会退出，此时对 MsgAppend 的屏蔽就会被去掉，从而走到 Regular Snapshot 的逻辑中。而 FAP Snapshot 在构建完后，会发送一个 meta 等同于 Regular Snapshot 的 Snapshot，只是不包含数据而已。在 Prehandle Snapshot 的逻辑中，会先检查是否存在 FAP Snapshot 并且它的 <code>(snapshot_index, snapshot_term)</code> 是否 meta 中匹配。如果不匹配，说明这是后来的一个 Regular Snapshot，需要覆盖 FAP Snapshot。如果匹配，那么无论这个 Snapshot 是否包含数据，都是和 FAP Snapshot 等价的。</li></ol><h3 id="FAP-对-UniPS-的改造"><a href="#FAP-对-UniPS-的改造" class="headerlink" title="FAP 对 UniPS 的改造"></a>FAP 对 UniPS 的改造</h3><ol><li>Checkpoint 中不仅需要上传 Stable 数据，也要上传 Delta 数据<br> 原因是必须要上传对应的 Raft Meta 数据才能构建出副本。由此，必须要上传 KVStore 和 Delta 层。此时唯一的可选项就是 applied_index 之后的没有被 apply 的日志了。目前是同样选择上传的，原因是代价可控。并且上传了 Raft Log 后，能够避免新建立的副本从 TiKV Leader 处继续下载这些 Log，从而造成新一轮的落后。</li><li>S3 文件的读写<br> 过去 UniPS 使用了 Lazy 的方式处理 FAP 添加得到的 Page，在 write 的时候只是记录远程的 Page 在 S3 blob file 中的 offset 和 size，在第一次读取的时候，才将这些 Page 下载下来。但在上传 Delta 和 Raft 数据后，需要处理的 Page 数量明显变多了。如果对于每一个 Page 调用一次 GetObject API 花费几十到几百毫秒下载，代价对于可能有几万 Page 的 Region 来说是无法承受的。<br> 这里通过 Prefetch + Reuse 的方式可以优化掉存在顺序读的部分，而顺序读的场景是占大多数的。因为上传 Checkpoint 的时候，会对所有的 Page 按照 PageID 的顺序进行 Compaction，以避免 S3 的空间放大。因此只要按照 page id 的顺序遍历，实际上就是顺序读写 blob file，就可以用上优化。<br> 对于零散的小写入，我们是利用了操作系统的 page cache 来避免大量小 io。</li><li>S3 文件的锁<br> 为了避免 FAP 引用的 blob file 被 GC，引入了 S3 文件锁。这里的做法是对于每一个 blob file，都可能存在多个 <code>${data_file_name}.lock_${store_id}</code> 文件，表示这个 blob file 被哪些 store 引用。只有一个 blob file 上没有关联 lock 文件的时候，才会清理掉。</li></ol><h2 id="使用-UniPS-替换-RaftEngine"><a href="#使用-UniPS-替换-RaftEngine" class="headerlink" title="使用 UniPS 替换 RaftEngine"></a>使用 UniPS 替换 RaftEngine</h2><p>目前 TiKV 使用 engine_traits 描述了一个可以用来作为 raftstore 的存储的 engine 所需要的接口。这些接口基本是基于 RocksDB 而抽象出来的。因此 UniPS 需要模拟出其中关键的特性，例如 WriteBatch 等。</p><p>UniPS 的性能劣于 RaftEngine，写入延迟大约是两倍。另外，scan 性能预期也比较差。但是仍有不少优化空间。</p><h2 id="为什么-TiFlash-Cloud-目前还是两副本？"><a href="#为什么-TiFlash-Cloud-目前还是两副本？" class="headerlink" title="为什么 TiFlash Cloud 目前还是两副本？"></a>为什么 TiFlash Cloud 目前还是两副本？</h2><p>目前快速恢复还是实验状态。TiFlash 重启后也需要进行一些整理和追日志才能服务，可能影响 HA，这些需要时间优化。尽管如此，快速恢复依然是一个很好的特性，因为：</p><ol><li>快速恢复在 1 wn 下，可以从本节点重启，减少 TiKV 生成 Snapshot 的负担。而这个负担在 v1 版本的 TiKV 上是比较大的。</li><li>减少宕机一个节点恢复后，集群恢复到正常 2 副本的时间。</li></ol><p>因为基于 Raft，所以本地数据的丢失只会导致从上一个 S3 Checkpoint 开始回放。如果只有一个存储节点，会失去 HA 特性。</p><h2 id="S3-在-TiFlash-Cloud-中起到什么作用？"><a href="#S3-在-TiFlash-Cloud-中起到什么作用？" class="headerlink" title="S3 在 TiFlash Cloud 中起到什么作用？"></a>S3 在 TiFlash Cloud 中起到什么作用？</h2><ol><li>TiFlash Cloud 会定期上传 Checkpoint 到 S3 上，Checkpoint 是一个完整的快照，可以用来做容灾。即使在存储节点宕机后，其上传的那部分数据依然可以被用来查询，可能只能用来服务 stale read？</li><li>TiFlash 计算节点可以从 S3 获得数据，相比从存储节点直接获取要更为便宜。存储节点只需要提供一些比较新的数据的读取，减少压力。</li><li>快速扩容逻辑可以复用其他存储节点的数据，此时新节点并不需要从 TiKV 或者其他 TiFlash 获得全部的数据。副本迁移同理，不需要涉及全部数据的移动。</li></ol><p>尽管如此，S3 并不是当前 TiFlash 数据的全集。本地会存在：</p><ol><li>上传间隔时间内，还没有上传到 S3 的数据。</li><li>因为生命周期太短，在上传前就被 tombstone 的数据。</li><li>尚在内存中的数据。</li></ol><h3 id="S3-vs-EBS"><a href="#S3-vs-EBS" class="headerlink" title="S3 vs EBS"></a>S3 vs EBS</h3><p>对于 <a href="https://aws.amazon.com/cn/s3/storage-classes/" target="_blank" rel="noopener">S3</a> 而言：</p><ol><li>具备 99.999999999% 的持久性和 99.99% 的可用性。<br> 也就是说一天中的不可用时间大约在 9s 左右。</li></ol><p><a href="https://aws.amazon.com/cn/s3/pricing/?nc=sn&loc=4" target="_blank" rel="noopener">定价</a>：</p><ol><li>PUT/POST/LIST/COPY 0.005</li><li>GET/SELECT 0.0004</li><li>存储每 GB 0.022 USD 每月</li></ol><p>可以看到，S3 的定价相比 EBS 要便宜不少。此外，从灾备上来讲，使用 EBS 可能需要为跨 AZ 容灾付出更多的成本，而 S3 可以实现跨 AZ 容灾。</p><p>当然 S3 也有缺陷，比如访问延迟比较高。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://docs.pingcap.com/zh/tidb/stable/troubleshoot-hot-spot-issues" target="_blank" rel="noopener">https://docs.pingcap.com/zh/tidb/stable/troubleshoot-hot-spot-issues</a></li><li><a href="https://www.infoq.com/articles/raft-engine-tikv-database/" target="_blank" rel="noopener">https://www.infoq.com/articles/raft-engine-tikv-database/</a> RaftEngine</li><li><a href="https://www.zhihu.com/question/47544675" target="_blank" rel="noopener">https://www.zhihu.com/question/47544675</a> 固态硬盘性能</li><li><a href="https://docs.pingcap.com/zh/tidb/stable/titan-overview" target="_blank" rel="noopener">https://docs.pingcap.com/zh/tidb/stable/titan-overview</a> Titan 设计</li><li>Fast scans on key-value stores</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;一些常见问题的思考，只代表个人见解。&lt;/p&gt;</summary>
    
    
    
    
    <category term="分布式" scheme="http://www.calvinneo.com/tags/分布式/"/>
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>TiFlash 性能测试的一个场景</title>
    <link href="http://www.calvinneo.com/2023/07/14/tiflash-pt-1/"/>
    <id>http://www.calvinneo.com/2023/07/14/tiflash-pt-1/</id>
    <published>2023-07-14T15:20:37.000Z</published>
    <updated>2024-01-03T15:59:34.592Z</updated>
    
    <content type="html"><![CDATA[<p>我们需要测试在有大量活跃 Region 情况下 TiFlash 的性能，具体负载是对一个大表压 update where。因为原有的测试工具需要加载全量数据到内存，并且只能单线程运行，所以重新做了<a href="https://github.com/CalvinNeo/pressure" target="_blank" rel="noopener">一个专门的压测工具</a>。这个工具是从 N 条数据中 sample 出 K 个出来，并启动多个 worker 发送 SQL 命令。</p><p>本文讲述在压测过程中发现的几个现象，并讲述作为工程师如何快速定位集群中出现的这些。</p><a id="more"></a><h1 id="第一个问题"><a href="#第一个问题" class="headerlink" title="第一个问题"></a>第一个问题</h1><p>第一个问题很好解决，原因是我用了 mysql 这个 crate，而它是阻塞的。这样我们开了很多线程，从而带来了很多的上下文切换。后面替换成 async-mysql 并且基于 tokio runtime，这样当任务需要等待的时候只会 yield，原线程还可以接着做其他任务。</p><table><thead><tr><th align="center">前</th><th align="center">后</th></tr></thead><tbody><tr><td align="center"><img src="/img/tiflash-pt/perf1.jpg"></td><td align="center"><img src="/img/tiflash-pt/perf2.jpg"></td></tr></tbody></table><h1 id="第二个问题"><a href="#第二个问题" class="headerlink" title="第二个问题"></a>第二个问题</h1><p>现在 N = 500m，b = 10k，它们是尽量平均存放的。因为压测机器内存的限制，它只能选取 N 中的 K 个数据作为集合，然后在这个集合上 sample 构造请求。因为 cpu 的限制，一次只能 sample i 个作为请求发送。现在观察到下面的现象：</p><ol><li>如果 k 较小，则这些请求分布的 region 很不均匀。反之，则分布更均匀。<br> 这里是因为如果 region 分布均匀，那么同样数量的请求会覆盖更多的 region，从而导致更多 region 被激活。而集群的某个指标和 region 被激活的数量有关。所以我们通过这个性质判断是否分布均匀。</li><li>请求的 QPS 是稳定的。</li></ol><p>现在调查这个问题，首先是进行统计学的分析，k 的大小会不会影响对 k 进行二次抽样得到的 i 个数据的分布均匀度呢？不得而知，但可以考虑一个简单的问题，也就是从 N 中抽 K 个，那么能覆盖多少个 region？得到下面的期望 E(cover)</p><p>$$<br>E(cover) = b (1 - (\frac{b - 1}{b})^k)<br>$$</p><p>从这个期望看到，只要 k 达到 N 的 1%，那么就基本能够覆盖全部的 region 了。那对于有 N 和 i 的场景，就借助于模拟进行验证。通过<a href="/asset/highconcurrency/sim.py">模拟的验证</a>，上面的期望是也是使用的。</p><p>如果既然直接 sample i 和在 k 中 sample i 是一样的，也就是不影响均匀程度，那么上面观察的结果是非预期的。这是因为对于同样的 i，k 不同，均匀程度不同，于是怀疑代码实现。特别地，如果数据处理算法没有问题，那么会首先考虑数据本身的问题。</p><p>我们的数据是从 n 个数据中抽样 k 个得到的，抽样算法是蓄水池算法。于是怀疑蓄水池算法的实现。果不其然，我发现 evict 的判定被我写反了，应该是满足 <code>k / j</code> 的情况下，会 evict，结果我按照不 evict 处理了。</p><p>综上，对于这种因为随机数写错了，导致的非 panic 的 bug。我们通过先统计学建模，再计算机模拟验证的方式，证明了数据生成过程是不符合预期的，进而找到了 bug。</p><h1 id="第三个问题"><a href="#第三个问题" class="headerlink" title="第三个问题"></a>第三个问题</h1><p>在解决这个问题之后，请求确实均匀了。但并发还是上不去，只有 1K+ QPS，检查发现是 TiKV 磁盘满了，导致限流。</p><h1 id="第四个问题"><a href="#第四个问题" class="headerlink" title="第四个问题"></a>第四个问题</h1><p>在解决上面三个问题后，压测的 SQL 可以达到 3K+ QPS。但进一步观察到另一个奇怪的现象。当 K 为 N 的 1% 的时候，是打到了 3K 并发，但是进一步增大 K，并发数反而降低了。调节压测程序的参数，发现压不上去，因此判定是集群的问题。</p><p>这里让人奇怪的点是，K 无论是 1% 还是 10% 的 N，它的 E(cover) 都已经能覆盖所有 region 了。那为什么 QPS 会不一样？</p><p>出于第三个问题的经验，首先查看了 TiKV 的写入指标。这里 15.15 对应的 10% 的情况，15.25 对应的是 1% 的情况。</p><p><img src="/img/tiflash-pt/ioutil.jpg"></p><p>可以看出两个情况下 SSD 都满了，那么为啥 QPS 还能分出个高下呢？同事说 <code>procinfo::pid::io_task</code> 测出来是 100%，但不意味着 SSD 到了瓶颈。</p><p>进一步查看写入，可以发现前台写入确实拉开了不小的差距。<br><img src="/img/tiflash-pt/fgw.jpg"></p><p>总体的写入上来看，也看不出两个负载之间有什么特别大的区别。<br><img src="/img/tiflash-pt/allw.jpg"></p><p>比较 io，可以看到前半段 write iops 稍微高一点或者相等，但是 write bandwidth 明显低，考虑是有较多的小写入。难道是因为前面的写入更散导致的？</p><table><thead><tr><th align="center">IOPS</th><th align="center">IO bandwidth</th></tr></thead><tbody><tr><td align="center"><img src="/img/tiflash-pt/iops.jpg"></td><td align="center"><img src="/img/tiflash-pt/ioband.jpg"></td></tr></tbody></table><p>后面，大佬同事给出一个观察，他认为 QPS 的问题可能是因为读取慢而不是写入慢导致的。确实从下面的监控来说，后半段读取耗时少了很多。</p><p><img src="/img/tiflash-pt/read.jpg"></p><p>他也发现了 running task 出现了堆积。也就是入得多出得少。并且 1 和 2 两台机器尤其吃紧。</p><p><img src="/img/tiflash-pt/rt.jpg"></p><p>进一步检查 qps，发现不同机器之间的写 qps 差别也比较大。读的 qps 差距不大，但这可能是因为 lb 的原因，例如如果有机器是 15kops，那么其他机器计算能到 30kops 也会被限制在 15kops 的。<br><img src="/img/tiflash-pt/qps.jpg"></p><p>关于写入的问题，检查 compaction，发现非 L0 到 L1 的 Major Compaction 很多。从而怀疑是否是因为第二个负载的池子比较有限，最多就涉及总共的 1% 的数据，而第一个池子的负载有总共池子的 10% 的数据。导致第二个池子的 hot key 实际上很少，compaction 不会到很下层。但因为第一个负载的 Compaction 没有明显多余第二个负载，所以这个怀疑应该也是不正确的。<br><img src="/img/tiflash-pt/compaction.jpg"></p><p>这里大佬又观察到 Block Cache Hit 上第二个负载明显高于第一个负载。这能解释一部分问题了。因为第一个池子是 10% 的样本，写入更散，Block Cache 容易被打穿到磁盘，所以读就变慢了。而我们的 update where 又是需要读的。<br><img src="/img/tiflash-pt/bchit.jpg"></p><p>这也解释了为什么要从 1Kops 跑一段时间才能到 3Kops，其实是在预热缓存。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们需要测试在有大量活跃 Region 情况下 TiFlash 的性能，具体负载是对一个大表压 update where。因为原有的测试工具需要加载全量数据到内存，并且只能单线程运行，所以重新做了&lt;a href=&quot;https://github.com/CalvinNeo/pressure&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;一个专门的压测工具&lt;/a&gt;。这个工具是从 N 条数据中 sample 出 K 个出来，并启动多个 worker 发送 SQL 命令。&lt;/p&gt;
&lt;p&gt;本文讲述在压测过程中发现的几个现象，并讲述作为工程师如何快速定位集群中出现的这些。&lt;/p&gt;</summary>
    
    
    
    
    <category term="分布式" scheme="http://www.calvinneo.com/tags/分布式/"/>
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>tuxun 游戏经验</title>
    <link href="http://www.calvinneo.com/2023/05/28/tuxun/"/>
    <id>http://www.calvinneo.com/2023/05/28/tuxun/</id>
    <published>2023-05-28T11:20:33.000Z</published>
    <updated>2023-06-09T17:05:53.203Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://tuxun.fun/" target="_blank" rel="noopener">图寻</a>是一个有趣的通过图片猜测地点的游戏。</p><a id="more"></a><script>    var show = false;    function btnClick() {        document.getElementById("mainbody").style.display = "block";    }</script><p><strong>注意，本文所引用的图片均来自于诸如百度、新浪、维基百科等官方资料网站。这些地图中的标注可能存在有主权争议的标注，这些标注是资料提供方的立场，而非我本人的立场。本人谴责部分人群居高临下，罔顾历史和主权去划分国界的行为。当然，本人使用这些图片的目的只是作为和国家主权领土无关的方面的示意，我发现在这些特定方面上，这些图片的水平很高。但限于地理知识和精力有限，本人没有能力对此一一校核。即使发现有问题，也没有能力基于这些图片进行改正。</strong></p><button onclick="btnClick()"><a>我同意上述免责声明，请向我展示内容</a></button><div style="display: none" id="mainbody"><br><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="基础方位"><a href="#基础方位" class="headerlink" title="基础方位"></a>基础方位</h2><p>判断南北半球，点击左下角指南针归正，此时面向北方。如果能明显见到太阳，则说明太阳在北方，我们位于南半球。反之则在北半球。如果太阳出现在头顶，或者东西两侧，则不太好分辨南北半球。<br>或者可以让指南针指向太阳，看对着的方向。<br>如果太阳在头顶，那么这个地方肯定在回归线以内。<br>还可以通过卫星锅的夹角来判断纬度。</p><p>判断和海洋的方位。</p><h2 id="行车方向"><a href="#行车方向" class="headerlink" title="行车方向"></a>行车方向</h2><p>根据行车方向判断国家或地区。</p><ul><li>亚洲：<ul><li>巴基斯坦</li><li>马来西亚</li><li>斯里兰卡</li><li>新加坡</li><li>香港</li></ul></li><li>欧洲：<ul><li>英国</li><li>爱尔兰</li><li>马耳他</li><li>塞浦路斯</li></ul></li><li>非洲：<ul><li>非洲南部<ul><li>南非</li><li>斯威士兰<br>  南非国中国</li><li>莱索托<br>  南非国中国</li><li>博茨瓦纳<br>  南非北边</li><li>津巴布韦<br>  博茨瓦纳北边</li><li>纳米比亚<br>  博茨瓦纳西边</li><li>赞比亚<br>  津巴布韦北边</li></ul></li><li>非洲岛国<ul><li>马达加斯加</li><li>毛里求斯<br>  马达加斯加旁边的岛国</li><li>塞舌尔<br>  马达加斯加北边</li></ul></li></ul><ul><li>开曼群岛</li><li>马拉维</li><li>常绿岛</li></ul></li><li>大洋洲：<ul><li>澳大利亚</li><li>新西兰</li><li>巴布亚新几内亚</li><li>萨摩亚</li><li>所罗门群岛</li><li>汤加</li></ul></li></ul><h2 id="语言"><a href="#语言" class="headerlink" title="语言"></a>语言</h2><p>根据语言判断国家或地区。</p><ul><li>西班牙语<br>  <img src="/img/tuxun/lang/his.svg"></li><li>法语<br>  <img src="/img/tuxun/lang/fra.svg"></li><li>葡萄牙语<br>  <img src="/img/tuxun/lang/por.svg"></li><li>欧洲各国语言<br>  <img src="/img/tuxun/lang/eur.png"></li></ul><p>西班牙语字母表<br><img src="/img/tuxun/lang/his_alpha.png"></p><p>葡萄牙语字母表<br><img src="/img/tuxun/lang/por_alpha.png"><br>部分方言包含Ç。</p><p>法语字母表<br><img src="/img/tuxun/lang/fra_alpha.png"></p><p>印地語、孟加拉语<a href="https://zhuanlan.zhihu.com/p/635034128" target="_blank" rel="noopener">对照</a></p><blockquote><p>以”我爱你”为例，各语言文字的写法如下：<br>印地語：मुझे तुमसे प्यार है<br>孟加拉语：আমি তোমাকে ভালোবাসি<br>马拉地语：मी तुझ्यावर प्रेम करतो<br>泰卢固语：నేను నిన్ను ప్రేమిస్తున్నాను<br>泰米尔语：நான் உன்னை காதலிக்கிறேன்<br>古吉拉特语：હું તને પ્રેમ કરું છુ</p></blockquote><h2 id="国旗"><a href="#国旗" class="headerlink" title="国旗"></a>国旗</h2><p>根据国旗判断国家或地区。<br><img src="/img/tuxun/flag/flag2023.png"></p><h1 id="自然气候"><a href="#自然气候" class="headerlink" title="自然气候"></a>自然气候</h1><h2 id="气候类型"><a href="#气候类型" class="headerlink" title="气候类型"></a>气候类型</h2><h3 id="气候分布图"><a href="#气候分布图" class="headerlink" title="气候分布图"></a>气候分布图</h3><p><img src="/img/tuxun/cli/simple.jpg"></p><h4 id="欧洲详图"><a href="#欧洲详图" class="headerlink" title="欧洲详图"></a>欧洲详图</h4><p><img src="/img/tuxun/cli/eur.jpg"></p><h4 id="北美洲详图"><a href="#北美洲详图" class="headerlink" title="北美洲详图"></a>北美洲详图</h4><p><img src="/img/tuxun/cli/nm.png"></p><h4 id="南美洲详图"><a href="#南美洲详图" class="headerlink" title="南美洲详图"></a>南美洲详图</h4><p><img src="/img/tuxun/cli/sm.jpg"></p><h4 id="非洲详图"><a href="#非洲详图" class="headerlink" title="非洲详图"></a>非洲详图</h4><p><img src="/img/tuxun/cli/af.webp"></p><h4 id="大洋洲详图"><a href="#大洋洲详图" class="headerlink" title="大洋洲详图"></a>大洋洲详图</h4><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>海洋性气候、大陆性气候、季风性气候：</p><ol><li>大陆性气候特点是降水少</li><li>海洋性气候特点是降水多且均匀，年温差小</li><li>季风气候的特点是降水差别大，年温差大</li></ol><h3 id="温带大陆性气候"><a href="#温带大陆性气候" class="headerlink" title="温带大陆性气候"></a>温带大陆性气候</h3><ol><li>北美洲中东部</li><li>西伯利亚</li><li>巴塔哥尼亚高原<br> 位于阿根廷和智利。也就是安第斯山脉东边的一长条。</li><li>欧洲部分</li></ol><p>温带大陆性气候的植被根据纬度不同可以是<strong>荒漠</strong>、<strong>草原</strong>和<strong>针叶林</strong>。<br>温带大陆性气候会被一些地方细分为温带沙漠气候和温带草原气候等。</p><h3 id="温带海洋性气候"><a href="#温带海洋性气候" class="headerlink" title="温带海洋性气候"></a>温带海洋性气候</h3><ol><li>西欧<br> 例如英国、比利时。</li><li>落基山脉西的北美<br> 例如西雅图、温哥华。</li><li>澳大利亚东南、新西兰</li><li>智利最南端</li></ol><p>温带海洋性气候通常出现在大陆西端。<br>植被类型是温带落叶阔叶林。<br>温带海洋性气候给人一种位于青山绿水的童话世界中的感觉。</p><h3 id="温带季风气候"><a href="#温带季风气候" class="headerlink" title="温带季风气候"></a>温带季风气候</h3><ol><li>中国北方的东部地区、俄罗斯远东地区南部、日本朝鲜等北部。</li></ol><p>温带季风气候通常出现在大陆东端。<br>温带季风气候的主要植被是落叶阔叶林，以及针阔叶混交林。</p><h3 id="亚热带季风气候"><a href="#亚热带季风气候" class="headerlink" title="亚热带季风气候"></a>亚热带季风气候</h3><ol><li>中国东南沿海</li><li>美国东南沿海</li><li>澳大利亚东部沿海</li></ol><p>温带季风气候的主要植被是常绿阔叶林。</p><h3 id="地中海气候"><a href="#地中海气候" class="headerlink" title="地中海气候"></a>地中海气候</h3><p>地中海气候是一种亚热带气候。</p><ol><li>地中海沿岸</li><li>黑海沿岸</li><li>加州</li><li>澳大利亚珀斯、阿德莱德</li><li>南非西南</li><li>智利中部</li></ol><p>雨热不同期。</p><p>典型植被为硬叶常绿旱生林和灌丛。<br>夏季过后，树林中干燥的枯枝落叶多。</p><h3 id="热带草原气候"><a href="#热带草原气候" class="headerlink" title="热带草原气候"></a>热带草原气候</h3><ol><li>非洲中部<br> <img src="/img/tuxun/cli/tsny.jpg"></li><li>南美巴西大部</li><li>澳大利亚东部和北部<br> <img src="/img/tuxun/cli/north_australia.jpg"></li></ol><p>特点是全年高温，分为明显的干季和湿季。<br>热带草原的植物具有旱生特性，不少植物<strong>树干粗大，树皮厚</strong>，可贮存大量水分以保证在旱季能进行生命活动。代表树种有猴面包树、纺锤树、金合欢树、波巴布树等，另外是具有许多珍稀的多肉植物种类。</p><h3 id="热带沙漠气候"><a href="#热带沙漠气候" class="headerlink" title="热带沙漠气候"></a>热带沙漠气候</h3><ol><li>撒哈拉沙漠</li><li>TODO</li></ol><h3 id="热带季风气候"><a href="#热带季风气候" class="headerlink" title="热带季风气候"></a>热带季风气候</h3><ol><li>印度、斯里兰卡</li><li>泰国北部、缅甸、越南等</li></ol><p>植被和热带雨林的<a href="http://www.igsnrr.cas.cn/cbkx/kpyd/dlzs/climate/202009/t20200910_5692629.html" target="_blank" rel="noopener">差别</a>在于：</p><ol><li>树木多数不再常绿，每到旱季便落叶</li><li>森林结构简化，树木的密度及分层减少</li></ol><p>所以人们称之为季雨林。</p><p>热带季风气候需要和温带大陆性气候区分，因为两者都会落叶。但热带季风更可能是干枯，可以看 Case5。</p><h3 id="热带雨林气候"><a href="#热带雨林气候" class="headerlink" title="热带雨林气候"></a>热带雨林气候</h3><ol><li>非洲西部刚果河流域，几内亚湾（也就是西南角）北岸<br> 注意，非洲其实大部分是热带草原和热带沙漠</li><li>马达加斯加岛东部</li><li>印尼，马来半岛南部，马来群岛，菲律宾群岛南部</li><li>亚马逊河流域</li><li>中美洲东部</li><li>澳大利亚的东北部</li></ol><p>植被<a href="http://www.igsnrr.cas.cn/cbkx/kpyd/dlzs/climate/202009/t20200910_5692631.html" target="_blank" rel="noopener">特点</a>：</p><ol><li>种类最丰富，树种混杂</li><li>树林有明显的分层，一般有五到八层<br> 最高的乔木层高达60～80米，林下有小乔木、灌木和草本植物，加上树上缠绕的藤本植物、附生植物和寄生植物</li><li>四季常青</li><li>为争夺阳光，植物都拼命往高处长</li></ol><h3 id="寒带气候"><a href="#寒带气候" class="headerlink" title="寒带气候"></a>寒带气候</h3><p>分为极地苔原气候和极地冰原气候。<br>极地苔原气候：</p><ol><li>北美洲北部</li><li>亚欧大陆北部</li><li>格陵兰以及北冰洋群岛</li><li>马尔维纳斯群岛、南设得兰群岛、南奥克尼群岛</li></ol><p>极地冰原气候：</p><ol><li>格陵兰、南极大陆和北冰洋群岛</li></ol><h2 id="植被"><a href="#植被" class="headerlink" title="植被"></a>植被</h2><p>温带落叶林</p><ol><li>枫树<br> <img src="/img/tuxun/green/fs.png"></li><li>橡树<br> <img src="/img/tuxun/green/xs.png"></li><li>白桦树<br> <img src="/img/tuxun/green/bhs.png"></li><li>水青冈属如山毛榉<br> <img src="/img/tuxun/green/smj.png"></li><li>榆树<br> <img src="/img/tuxun/green/ys.png"></li></ol><p>尽管可以通过叶子颜色判断是否是落叶林。但需要注意，有些颜色并不是来自于叶子，而可能来自于枝干。</p><p>热带亚热带常绿阔叶林</p><ol><li>樟科<br> <img src="/img/tuxun/green/zs.png"></li><li>山茶科</li><li>木兰科<br> <img src="/img/tuxun/green/ml.png"></li><li>水青冈属如山毛榉</li></ol><p>热带稀树草原</p><h1 id="地形地貌"><a href="#地形地貌" class="headerlink" title="地形地貌"></a>地形地貌</h1><h2 id="全球地形"><a href="#全球地形" class="headerlink" title="全球地形"></a>全球地形</h2><p>全球山地<br><img src="/img/tuxun/geo/global_mountain.jpg"></p><h2 id="各地土壤"><a href="#各地土壤" class="headerlink" title="各地土壤"></a>各地土壤</h2><p>巴西红土<br>美国平原黑土</p><p>一般热带雨林+红土考虑非洲。</p><h2 id="各地的山"><a href="#各地的山" class="headerlink" title="各地的山"></a>各地的山</h2><h1 id="人文"><a href="#人文" class="headerlink" title="人文"></a>人文</h1><h2 id="建筑"><a href="#建筑" class="headerlink" title="建筑"></a>建筑</h2><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>吊脚楼</p><h3 id="外墙"><a href="#外墙" class="headerlink" title="外墙"></a>外墙</h3><h3 id="屋顶"><a href="#屋顶" class="headerlink" title="屋顶"></a>屋顶</h3><p>一般有积雪的地方会修斜顶屋。</p><h2 id="民族服饰"><a href="#民族服饰" class="headerlink" title="民族服饰"></a>民族服饰</h2><h2 id="作物和畜牧业"><a href="#作物和畜牧业" class="headerlink" title="作物和畜牧业"></a>作物和畜牧业</h2><p>牧场</p><h2 id="交通"><a href="#交通" class="headerlink" title="交通"></a>交通</h2><h3 id="道路划线"><a href="#道路划线" class="headerlink" title="道路划线"></a>道路划线</h3><p>中间白线主要是在欧洲。</p><p>中间白线，两边黄线是在南非。</p><p>中间黄线主要是在北美南美</p><ol><li>加拿大</li><li>芬兰</li></ol><h3 id="路桩"><a href="#路桩" class="headerlink" title="路桩"></a>路桩</h3><p>出现在澳大利亚。<br><img src="/img/tuxun/traffic/pile/1.png"></p><h3 id="护栏"><a href="#护栏" class="headerlink" title="护栏"></a>护栏</h3><h3 id="交通标志"><a href="#交通标志" class="headerlink" title="交通标志"></a>交通标志</h3><h3 id="电线杆"><a href="#电线杆" class="headerlink" title="电线杆"></a>电线杆</h3><p>木头电线杆：</p><ol><li>加拿大</li></ol><p>马来西亚电线杆上有黄色或者黑色贴纸。<br>日本北海道电线杆上有一个写满数字的牌子。</p><h2 id="车牌"><a href="#车牌" class="headerlink" title="车牌"></a>车牌</h2><h3 id="欧盟"><a href="#欧盟" class="headerlink" title="欧盟"></a>欧盟</h3><p>塞浦路斯、荷兰、卢森堡的车牌主体是黄色，而不是其他国家的白色。<br>法国和意大利车牌的右边也是蓝色。<br>葡萄牙的车牌右边是黄色的。</p><h3 id="欧洲"><a href="#欧洲" class="headerlink" title="欧洲"></a>欧洲</h3><p>阿尔巴尼亚和土耳其不是欧盟国家，但车牌和欧盟类似。<br>英国车牌前白后黄，emm，和香港一样啊。<br>俄罗斯车牌是白色底的。</p><h3 id="亚洲"><a href="#亚洲" class="headerlink" title="亚洲"></a>亚洲</h3><p>印度的车牌是白色长条。</p><p>马来西亚的车牌是黑色长条。</p><h2 id="插座"><a href="#插座" class="headerlink" title="插座"></a>插座</h2><h1 id="Fine-tune"><a href="#Fine-tune" class="headerlink" title="Fine tune"></a>Fine tune</h1><h2 id="找路"><a href="#找路" class="headerlink" title="找路"></a>找路</h2><h1 id="经验"><a href="#经验" class="headerlink" title="经验"></a>经验</h1><p>同样是温带大陆性气候，如何判断是在美洲还是亚欧大陆呢？</p><p>如何分辨巴西中部、非洲以及澳大利亚的热带草原气候呢？</p><h1 id="Case"><a href="#Case" class="headerlink" title="Case"></a>Case</h1><h2 id="1-10"><a href="#1-10" class="headerlink" title="1-10"></a>1-10</h2><p>下图所示，植被为草，考虑热带草原或者温带大陆性气候。但观察到远处有雪山，则选项只有：埃塞尔比亚、巴西阿根廷附近、美国、青藏高原附近。显然要排除埃塞尔比亚和青藏高原。本题是在阿根廷。<br><img src="/img/tuxun/cases/1.png"></p><p>下图所示，植被为草。明显感觉更旺盛一点，考虑热带草原。本题位于澳大利亚 Bourke 附近的 B71 公路。<br><img src="/img/tuxun/cases/2.png"></p><p>下图所示，植被为草，灌木和树叶有枯黄，考虑温带大陆性气候。本题位于加里宁格勒。<br><img src="/img/tuxun/cases/3.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=7e9a0270-ff12-11ed-914f-4914ef59bdbe&round=4" target="_blank" rel="noopener">下图所示</a>，植被为草，草是会枯黄的。地形高低起伏，有牧场。第一印象就是新西兰。但总觉得这个比较干，感觉是温带大陆性气候。其实这确实应该是海洋性，只是在秋天黄了一些。大陆性感觉类似于“温带沙漠/草原气候”？<br><img src="/img/tuxun/cases/4.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=eaeb2350-ffb7-11ed-b236-951b8abb12f6&round=6" target="_blank" rel="noopener">下图所示</a>位于泰国沙湾拿吉附近。这个我会把它认为是温带大陆性气候，原因是叶子枯萎，然后比较干燥。但这个可能是热带季风的干季。<br><img src="/img/tuxun/cases/5.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=83d757e0-ffcd-11ed-9b28-99b63e42e398&round=4" target="_blank" rel="noopener">下图所示</a>是在南非。我们错选了巴西。这两个都是南半球的热带草原气候。<br><img src="/img/tuxun/cases/6.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=55243880-06d2-11ee-ab40-2bdea2c51865&round=2" target="_blank" rel="noopener">下图所示</a>是在土耳其的亚洲部分。观察到国旗，并且是温带大陆性气候，并且四周较为平坦。<br><img src="/img/tuxun/cases/7.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=16ecb580-06d0-11ee-ab40-2bdea2c51865&amp;round=3" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=16ecb580-06d0-11ee-ab40-2bdea2c51865&amp;round=3</a> 是在喜马拉雅山南麓的不丹廷布。这个山看上去比较光，感觉是大陆性或者草原气候，我选了热带草原。但廷布确实是比较干燥的气候，但确实乔木要比热带草原要多。<br><img src="/img/tuxun/cases/8.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=55243880-06d2-11ee-ab40-2bdea2c51865&amp;round=1" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=55243880-06d2-11ee-ab40-2bdea2c51865&amp;round=1</a> 考虑是温带海洋性气候，所以考虑欧洲。看到有雪山，但是有树林，考虑是阿尔卑斯山，或者北欧。这里我选了阿尔卑斯，是错的。答案是在挪威北部。其实这里的海洋性不是很明显，因为气候看上去比较干燥，并且也是以针叶林为主，实际上应该是是大陆性气候。<br><img src="/img/tuxun/cases/9.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=55243880-06d2-11ee-ab40-2bdea2c51865&amp;round=3" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=55243880-06d2-11ee-ab40-2bdea2c51865&amp;round=3</a> 这个我填的是格陵兰，但实际上是喀喇昆仑附近。</p><p><img src="/img/tuxun/cases/10.png"></p><h2 id="11-20"><a href="#11-20" class="headerlink" title="11-20"></a>11-20</h2><p><a href="https://tuxun.fun/replay_pano?gameId=6c141871-06ce-11ee-b443-ed29a6596b57&amp;round=4" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=6c141871-06ce-11ee-b443-ed29a6596b57&amp;round=4</a> 这我对了，这就是典型的墨西哥。<br><img src="/img/tuxun/cases/11.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=3fcedfa0-06df-11ee-96e6-452f8f9a8409&amp;round=4" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=3fcedfa0-06df-11ee-96e6-452f8f9a8409&amp;round=4</a> 这张图我看植被常绿分层比较明显，考虑是热带雨林。道路左行，考虑是赞比亚。但实际上这是南非的热带草原气候，这还比较有趣。<br><img src="/img/tuxun/cases/12.png"></p><p>但我往前走了点，确实发现树干比较粗大。<br><img src="/img/tuxun/cases/12b.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=3fcedfa0-06df-11ee-96e6-452f8f9a8409&amp;round=3" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=3fcedfa0-06df-11ee-96e6-452f8f9a8409&amp;round=3</a> 这个一眼菲律宾南部的雨林气候。<br><img src="/img/tuxun/cases/13.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=873b1af0-06e1-11ee-86d7-1101216a0f3c&amp;round=2" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=873b1af0-06e1-11ee-86d7-1101216a0f3c&amp;round=2</a> 这个我觉得是非洲刚果河附近的热带雨林气候，但实际上是柬埔寨西南角的戈功附近。不知道为啥这是一个热带季风气候。可能你去想深圳其实也是季风气候，和这个有点像。<br><img src="/img/tuxun/cases/14.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=873b1af0-06e1-11ee-86d7-1101216a0f3c&amp;round=1" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=873b1af0-06e1-11ee-86d7-1101216a0f3c&amp;round=1</a> 看到这道路和广袤的农田，觉得是美国中部。但实际上是英国的剑桥北边一点。其实英国是有很多这样的平原的。<br><img src="/img/tuxun/cases/15.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=873b1af0-06e1-11ee-86d7-1101216a0f3c&amp;round=3" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=873b1af0-06e1-11ee-86d7-1101216a0f3c&amp;round=3</a> 这个居然也还是南非。这个确实看上去就是热带草原或者温带大陆性。我选了温带大陆性，那么就是阿根廷的南部。实际上这是热带草原，温带大陆性的话应该不会有这么典型的一团一团的草的。<br><img src="/img/tuxun/cases/16.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=16ecb580-06d0-11ee-ab40-2bdea2c51865&amp;round=1" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=16ecb580-06d0-11ee-ab40-2bdea2c51865&amp;round=1</a> 这是希腊，我选的俄罗斯。因为我觉得这里叶子有枯，并且是变黄的，应该是秋冬的落叶，而不是干燥所致，所以是大陆性气候。<br><img src="/img/tuxun/cases/17.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=3f2b8c00-06e5-11ee-96e6-452f8f9a8409&amp;round=2" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=3f2b8c00-06e5-11ee-96e6-452f8f9a8409&amp;round=2</a> 这是第二次遇到日本九州岛了。我又把它当成北方的温带大陆气候了。这图里面很多芦苇。<br><img src="/img/tuxun/cases/18.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=3f2b8c00-06e5-11ee-96e6-452f8f9a8409&amp;round=1" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=3f2b8c00-06e5-11ee-96e6-452f8f9a8409&amp;round=1</a> 这是典型的热带草原，南半球。东西北三面环山，我选的巴西东北，实际上阿根廷西北也构成。<br><img src="/img/tuxun/cases/19.png"><br>这题是看电线杆来判定么？<br><img src="/img/tuxun/cases/19b.png"></p><p><a href="https://tuxun.fun/replay_pano?gameId=31403e90-06e7-11ee-86d7-1101216a0f3c&amp;round=3" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=31403e90-06e7-11ee-86d7-1101216a0f3c&amp;round=3</a> 这是个热带季风气候。实际上是印度靠近新德里附近。<br><img src="/img/tuxun/cases/20.png"></p><h2 id="21-30"><a href="#21-30" class="headerlink" title="21-30"></a>21-30</h2><p><a href="https://tuxun.fun/replay_pano?gameId=31403e90-06e7-11ee-86d7-1101216a0f3c&amp;round=1" target="_blank" rel="noopener">https://tuxun.fun/replay_pano?gameId=31403e90-06e7-11ee-86d7-1101216a0f3c&amp;round=1</a> 这种树林墙我就想到俄罗斯。但这个是阔叶林的墙，俄罗斯的可能偏针叶林一点，最终这个是在拉脱维亚和爱沙尼亚交界处。所谓波罗的海三国。看来漂亮的还是海洋性气候啊。</p><h1 id="有趣的复盘链接"><a href="#有趣的复盘链接" class="headerlink" title="有趣的复盘链接"></a>有趣的复盘链接</h1><p><a href="https://tuxun.fun/replay?gameId=58618676-ff01-11ed-9f6a-9f7cb4f02bb2" target="_blank" rel="noopener">https://tuxun.fun/replay?gameId=58618676-ff01-11ed-9f6a-9f7cb4f02bb2</a></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://zh.wikipedia.org/zh-hans/%E9%81%93%E8%B7%AF%E9%80%9A%E8%A1%8C%E6%96%B9%E5%90%91" target="_blank" rel="noopener">https://zh.wikipedia.org/zh-hans/%E9%81%93%E8%B7%AF%E9%80%9A%E8%A1%8C%E6%96%B9%E5%90%91</a><br> 道路行驶方向</li><li><a href="https://zhuanlan.zhihu.com/p/95605737" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/95605737</a></li><li><a href="https://www.bilibili.com/video/BV1Zg4y1V7Pe/?spm_id_from=333.337.search-card.all.click&amp;vd_source=5814e098499298bf9802aa74e8e48451" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1Zg4y1V7Pe/?spm_id_from=333.337.search-card.all.click&amp;vd_source=5814e098499298bf9802aa74e8e48451</a></li></ol></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://tuxun.fun/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;图寻&lt;/a&gt;是一个有趣的通过图片猜测地点的游戏。&lt;/p&gt;</summary>
    
    
    
    
    <category term="游戏" scheme="http://www.calvinneo.com/tags/游戏/"/>
    
    <category term="地理" scheme="http://www.calvinneo.com/tags/地理/"/>
    
  </entry>
  
  <entry>
    <title>Hazard Pointer</title>
    <link href="http://www.calvinneo.com/2023/05/16/hazptr/"/>
    <id>http://www.calvinneo.com/2023/05/16/hazptr/</id>
    <published>2023-05-16T12:34:22.000Z</published>
    <updated>2023-05-19T16:41:58.642Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 Hazard Pointer。</p><a id="more"></a><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><a href="http://www.cs.otago.ac.nz/cosc440/readings/hazard-pointers.pdf" target="_blank" rel="noopener">Hazard Pointer</a>类似于面向多线程的智能指针，它能够无等待地进行<strong>线程安全的 GC</strong>。在前面提到的 MS 队列中，它的 free 就可以由 HazardPointer 实现。<br>维护一个全局数组 <code>HP hp[N]</code>，其中 N 表示线程的数量。HP 看上去是 ThreadLocal 的，但实际上不是。因为虽然每个线程只能写自己的 HP，但是却可以读所有其他线程的 HP。<br>当需要访问某个指针时，就将这个指针赋值给自己的 HP，也就是通知别人不要释放这个指针。这里的释放被称为 reclaim 或者 deallocate，指的是销毁这个对象。<br>如果同时访问多个指针呢？同样可以扩展HP。比如 HazardPointer 的思维通常是在无锁队列中出现，这个场景最多也就操作一个节点的指针。而如果操作其他数据结构比如树或者图，那么一个线程可以同时访问多个指针。<br>每个线程维护一个私有链表，称为 retired。当该线程准备释放一个指针时，如果此时这个指针还有 reader，则不能立即 gc 掉这个指针，此时把该指针放入 retired 链表中。被 retire 的指针不再可以被新的 reader 访问了，但它仍旧可以被之前就已经指向了的 reader 访问。<br>当一个线程要释放某个指针时，它需要检查全局的 HP 数组。如果有一个线程的 HP 指向这个指针，则不能释放。</p><h2 id="Why-Hazard-Pointer"><a href="#Why-Hazard-Pointer" class="headerlink" title="Why Hazard Pointer"></a>Why Hazard Pointer</h2><p>HP 是用来实现安全地释放某个指针的。这里的安全指的是当有 reader 在读的时候，不能立即销毁该指针指向的对象。例如考虑一个线程在遍历链表，另一个线程在移除链表中的某些节点，这两个线程是不互相知晓对方的。如果在删除时，读线程已经持有了访问该节点的指针，那么这个节点就不能被立即删除。诸如此类的场景称为 Deferred Reclamation。</p><p>一些做法可以解决该问题，比如引用计数。例如可以分别维护读引用计数和写引用计数，这样当一个写在发生前，总可以先检查两个引用计数是否都是0。它的缺点是，无论是读还是写，都需要访问一个共享的用来计数的结构。也许这个结构可以借助于原子操作实现得“轻量”，但无论如何，竞争访问(contention)是少不了的。但考虑一个读多写少的场景，也就是大部分时候压根就不会写那个借助引用计数维护的对象，无论它是一个链表节点，或者是一个别的什么。那是否可以让读操作避免去访问共享对象，从而减少竞争呢？这就是 Hazard Pointer 的思想。这样各个读操作之间没有竞争。</p><p>除了 hazard pointer，还有诸如 epoch-based 或者 RCU 的做法来解决问题。</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>本章节中会进一步研究 hp 实现的原理，并基于 folly 的实现给出一份 Rust 的实现。</p><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>如下所示，蓝色的是读线程，紫色的是写线程。reader 在读 hp 指向的那个 x，而 writer 通过 cas 来把 x 替换成 y。每个 reader，都持有一个 harzard pointer。这里面的东西，要么是空的，要么是当前线程正在使用的 pointer。writer 会检查所有的 hp，检查里面是否包含了自己要 gc 的地址。如果有，说明现在还有 reader 访问，writer 就会 yield 掉，做一些其他的事情，等过一段时间再检查 hazard pointer。等到没有 reader 访问这个 old value 了，writer 就会销毁掉它。</p><p>对于每个对象，它所有的 reader 组成一个链表。如何保证 hp 链表的线程安全？我们不会在使用完某个 hp 后就释放它，而是通过 cas 将它设置为空。所以这些链表中的 hp 是可以被复用的。所以，在获取 hp 的时候，是有一些竞争的，但相比新分配一个 hp，或者 cas 整个链表会好很多。</p><p><img src="/img/hazptr/folly1.png"></p><blockquote><p>这里还讲了 wait free 的实现依赖于 memory reclamation，而不是反过来。所以无法利用某种 wait free 的算法来实现 hp。</p></blockquote><blockquote><p>epoch 的方式更 batch 一些，也更消耗内存。因为只有在 epoch 结束之后，才能释放这个 epoch 中的所有对象。</p></blockquote><p>reader 如何访问 x 呢？ reader 设置 hp，然后后面的 writer 在释放 old value 前进行检查会看到有 hp 被设置了，从而推迟销毁。<br>但这个方案是存在问题的，问题的实质是 hp 和 hp 保护的 ptr 的读写不是原子的。所以考虑下面的顺序，可以发现 W 在还有 R 读 old value 的时候就把 old value 销毁了，这显然是不安全的</p><ol><li>R 读 ptr</li><li>W 更新 ptr</li><li>W 检查 hp</li><li>W 销毁 old value</li><li>R 更新 hp</li></ol><p><img src="/img/hazptr/folly2.png"></p><p>这里有个疑问，如果先更新 hp，再读取 ptr 是否可行呢？这是不可行的，因为 hp 里面要填入它保护的 ptr，所以必须先取到 ptr。</p><p>因此设计下面的过程：</p><ol><li>R 读 ptr，读到值为 ptr1。</li><li>R 更新 hp。</li><li>R 再读 ptr，确保此时读到的值还是 ptr1，此时视为 R 可以安全读 ptr 的值。否则 R 就需要加载最新的 ptr，然后重复这个过程。</li><li>W 更新 ptr。</li><li>W 检查 hp。</li></ol><p>这样的话，如果在 2 和 3 之间有一个 writer 进行了 CAS，那么它会导致 3 读出来的 ptr 发生变化，这样 reader 就能重试。如果在 3 之后有一个 writer，那么 writer 在看到 hp 之后就会重试。</p><h2 id="folly-的接口"><a href="#folly-的接口" class="headerlink" title="folly 的接口"></a>folly 的接口</h2><p>本章节中，研究 folly 的接口，并尝试用 Rust 来实现一份接口。</p><p>一个类继承 hazptr_obj_base 才可以被用 hp 维护。这个 hazptr_obj_base 中有一个 retire 方法。为什么要这么做呢？其实大可以把 MyType 用 HazPtrTarget 包一层，但这样就多了一层间接，用起来不方便。就是想把 HazPtrTarget 里面的一些功能 trait 出来，让 MyType 实现。这样的话，就不需要外面包一层了。当然，后面会发现因为 Rust 中不能往 trait 里面放比如 <code>hazptrs: LinkedList&lt;HazPtrHolder&gt;</code> 之类的 field，所以作者还是包了一层。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">AtomicPtr&lt;MyType&gt;</span><br><span class="line">AtomicPtr&lt;HazPtrTarget&lt;MyType&gt;&gt;</span><br></pre></td></tr></table></figure><p>一个 retire 的对象，不再 accessible，但仍然被 hp 保护。在 reclaim 阶段，会检查该对象是否可以被删除。</p><p>另外，为什么提供一个显式的 retire 函数，而不直接在析构的时候做 retire 相关的事情。作者觉得这是一个 taste 的问题，<code>drop(*)</code> 有点奇怪的。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> old: *<span class="keyword">mut</span> HazPtrTarget&lt;MyType&gt; = x.swap(new);</span><br><span class="line">HazPtrTarget::retire(old); <span class="comment">// 1</span></span><br><span class="line"><span class="built_in">drop</span>(*old); <span class="comment">// 2</span></span><br></pre></td></tr></table></figure><p>在访问需要保护的对象前，需要首先创建一个 hazptr_holder。holder 是 reader 实际操作的对象。holder 会检查自己是否拥有 hp，如果没有的话，会从对应的 domain 去 acquire 一个。<br>holder 的方法 get_protected 接受一个 <code>AtomicPtr&lt;T&gt;</code>，也就是需要保护的对象。它返回一个不可变引用，这个引用是被 hp 保护的了。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span> HazPtrHolder &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">get_protected</span></span>&lt;<span class="symbol">'a</span>, T&gt;(&amp;<span class="symbol">'a</span> <span class="keyword">mut</span> <span class="keyword">self</span>, &amp;<span class="symbol">'_</span> AtomicPtr&lt;T&gt;) -&gt; &amp;<span class="symbol">'a</span> T;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先，无所谓这个 <code>AtomicPtr&lt;T&gt;</code> 的生命周期，因为实际是为了拿到它维护的指针。【Q】那为什么要这个 AtomicPtr 保护一下呢？这和之前说的要读两次 ptr 有关，也就是需要原子地从 ptr 上 load 出它当前的值。<br>其次，即使返回 &amp;T，我们依旧需要 &amp;mut self。这是为了避免先 get_protected a 之后又 get_protected b，这样 a 实际上就不被保护了。<br>最后，返回的 &amp;T 的生命周期是和 HazPtrHolder 一致的。</p><p>如图所示，retire(x) 调用时，发现 x 还在被访问，不能直接 reclaim，所以记录到 retire 表中。retire(y) 调用的时候，发现 y 在被访问，但 x 已经不再被访问了，所以 reclaim x，然后把 y 记录在表中。<br><img src="/img/hazptr/folly3.png"></p><p>演讲者认为 folly 的 demo 存在一些疏漏。如果 V 是一个引用类型的话，则可能出现问题。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">///   // Called frequently</span></span><br><span class="line"><span class="comment">///   U get_config(V v) &#123;</span></span><br><span class="line"><span class="comment">///     hazptr_holder h = make_hazard_pointer();</span></span><br><span class="line"><span class="comment">///     Config* ptr = h.protect(config_);</span></span><br><span class="line"><span class="comment">///     /* safe to access *ptr as long as it is protected by h */</span></span><br><span class="line"><span class="comment">///     return ptr-&gt;get_config(v);</span></span><br><span class="line"><span class="comment">///     /* h dtor resets and releases the owned hazard pointer,</span></span><br><span class="line"><span class="comment">///        *ptr will be no longer protected by this hazard pointer */</span></span><br><span class="line"><span class="comment">///   &#125;</span></span><br></pre></td></tr></table></figure><p>下图列出 haz holder、haz pointer、atomic 和 haz obj 的关系。<br>看起来 holder 是 reader 实际操作的对象。holder 会检查自己是否拥有 hp，如果没有的话，会从对应的 domain 去 acquire 一个。<br><img src="/img/hazptr/folly4.png"></p><p>这里 non-typical 的是比如去 dfs 遍历一棵树，然后对于树的每一层都有一个 hp 来记录。这样的话，每个线程的 hp 的数量是 log(d) 而不是常数。<br>第二段的意思是，retire 但还没有 reclaim 的 haz ptr 的数量，和 hp 的数量是线性的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Memory Usage</span></span><br><span class="line"><span class="comment">/// ------------</span></span><br><span class="line"><span class="comment">/// - The size of the metadata for the hazptr library is linear in the</span></span><br><span class="line"><span class="comment">///   number of threads using hazard pointers, assuming a constant</span></span><br><span class="line"><span class="comment">///   number of hazard pointers per thread, which is typical.</span></span><br><span class="line"><span class="comment">/// - The typical number of reclaimable but not yet reclaimed of</span></span><br><span class="line"><span class="comment">///   objects is linear in the number of hazard pointers, which</span></span><br><span class="line"><span class="comment">///   typically is linear in the number of threads using hazard</span></span><br><span class="line"><span class="comment">///   pointers.</span></span><br></pre></td></tr></table></figure><p>下面的 Rust 代码展示了 hp 的大概使用方法。这里的 HazPtrHolder::load 类似于 get_protected。可以看到，当 HazPtrHolder 被析构后，就不再可以使用 my_x 了。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[test]</span></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">feels_good</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> x = AtomicPtr::new(<span class="built_in">Box</span>::into_raw(<span class="built_in">Box</span>::new(<span class="number">42</span>))); <span class="comment">// x: AtomicPtr&lt;i32&gt;</span></span><br><span class="line">    <span class="comment">// As a reader:</span></span><br><span class="line">    <span class="keyword">let</span> h = HazPtrHolder::<span class="keyword">default</span>();</span><br><span class="line">    <span class="keyword">let</span> my_x: &amp;<span class="built_in">i32</span> = h.load(&amp;x);</span><br><span class="line">    <span class="built_in">drop</span>(h);</span><br><span class="line">    <span class="comment">// invalid:</span></span><br><span class="line">    <span class="keyword">let</span> _ = *my_x;</span><br><span class="line">    <span class="comment">// As a writer:</span></span><br><span class="line">    <span class="keyword">let</span> old = x.swap(</span><br><span class="line">        <span class="built_in">Box</span>::into_raw(<span class="built_in">Box</span>::new(<span class="number">9001</span>)),</span><br><span class="line">        Ordering::SeqCst,</span><br><span class="line">    );</span><br><span class="line">    HazPtrobject::retire(old);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码也有几个不尽如人意的地方：</p><ol><li>首先是 AtomicPtr 可能接受一个 null，但我们的场景中实际要禁止 null。显然 Rust 中缺少一个 NotNullAtomicPtr 的结构。</li></ol><p>下面就是 load 的实现。分为两部分：</p><ol><li>尝试获得一个 hp，如果当前的 holder 尚未绑定一个 hp，就从 domain 上 acquire 一个。acquire 的实现类似从链表里面取一个可用节点，这在后面介绍。</li><li>从 AtomicPtr 中加载 ptr，放到刚才获得的 hp 里面，也就是 protect 方法。然后再从 ptr 中读一遍，确保现在读到的 ptr2 等于之前的 ptr1。</li></ol><p>这里能够在 ptr1 == ptr2 的时候返回 ptr1，其安全性在于：</p><ol><li>ptr1 不可能被释放，因为它此时至少受到我们刚创建的 hp 的保护。</li><li>caller 保证 AtomicPtr 非空，并且只可能通过 retire 来被释放掉。</li></ol><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">unsafe</span> <span class="function"><span class="keyword">fn</span> <span class="title">load</span></span>&lt;T&gt;(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, ptr: &amp;<span class="symbol">'_</span> AtomicPtr&lt;T&gt;) -&gt; <span class="built_in">Option</span>&lt;&amp;T&gt;</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">let</span> hazptr = <span class="keyword">if</span> <span class="keyword">let</span> <span class="literal">Some</span>(hazptr) = <span class="keyword">self</span>.<span class="number">0</span> &#123;</span><br><span class="line">        hazptr</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> hazptr = SHARED_DOMAIN.acquire();</span><br><span class="line">        <span class="keyword">self</span>.<span class="number">0</span> = <span class="literal">Some</span>(hazptr);</span><br><span class="line">        hazptr</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> ptr1 = ptr.load(Ordering::SeqCst);</span><br><span class="line">    <span class="keyword">loop</span> &#123;</span><br><span class="line">        hazptr.protect(ptr1);</span><br><span class="line">        <span class="keyword">let</span> ptr2 = ptr.load(Ordering::SeqCst);</span><br><span class="line">        <span class="keyword">if</span> ptr1 == ptr2 &#123;</span><br><span class="line">            <span class="comment">// All good -- protected</span></span><br><span class="line">            <span class="keyword">break</span> <span class="literal">Some</span>(todo!())</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            ptr1 = ptr2;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>后面卡在 <code>impl&lt;T&gt; HazPtrObject for T</code> 的 domain 方法上了。这个 domain 方法要返回一个 HazPtrDomain，但写不下去了。因为无法从 trait HazPtrObject 或者任一类型 T 中去取到它被绑定的 domain。所以我们得引入一个 <code>HazPtrObjectWrapper&lt;T&gt;</code> 来保存 domain。这个 Wrapper 可以解引用为 T，还实现了 HazPtrObject。哎，所以这不是走回 <code>AtomicPtr&lt;HazPtrTarget&lt;MyType&gt;&gt;</code> 这样的老路了么。</p><p>这里遇到一个 Drop 相关的问题，他要把 self cast 成一个 <code>*mut dyn Drop</code>，这要求 HazPtrObject 的 Self 必须 impl Drop。但 Rust 又报一个 warning 说 HazPtrObject 继承一个 Drop trait 是多余的。搞到最后作者也没办法去掉这 warning，只能通过 drop_bounds 去禁用掉这个 warning。在视频的第二部分，通过用一个新的空的 trait Reclaim 替换 Drop 来解决掉那个多的 warning。毕竟我们核心只是要一个虚表。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[allow(drop_bounds)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">HazPtrObject</span></span></span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    <span class="keyword">Self</span>: <span class="built_in">Sized</span> + <span class="built_in">Drop</span> + <span class="symbol">'static</span>,</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">domain</span></span>(&amp;<span class="keyword">self</span>) -&gt; &amp;HazPtrDomain;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">unsafe</span> <span class="function"><span class="keyword">fn</span> <span class="title">retire</span></span>(<span class="keyword">self</span>: *<span class="keyword">mut</span> <span class="keyword">Self</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> !std::mem::needs_drop::&lt;<span class="keyword">Self</span>&gt;() &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">unsafe</span> &#123; &amp;*<span class="keyword">self</span> &#125;.domain().retire(<span class="keyword">self</span> <span class="keyword">as</span> *<span class="keyword">mut</span> dyn <span class="built_in">Drop</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>后续引入一个 trait Deleter，给到 retire 函数，用来指定如何删除这个对象。</p><p>然后说了下，测试里面的 swap 之后，还需要 retire 才能语义上保证 old 不会再 accessible 了。borrow checker 保证了，在调用 reset 的时候，不可能持有一个 load 得到的 &amp;T 指针。这是因为 load 和 reset 都需要 mut borrow。</p><p>下面实现 HazPtrDomain::acquire。我们遍历 domain 维护的整个链表，找到第一个 active 为 false 的节点并返回。注意 active 为 true 表示这个 node 正在被使用。如果遍历完整个链表都找不到，则需要扩容链表。这里的链表扩容挺符合直觉的，是一个经典的 loop cas，每次都想办法更新 head。如果 cas 失败，说明 head 已经被其他线程更新了，就重试一次。但是重试前要更新自己的 next 为新的 head。</p><p>bulk_reclaim 尝试 reclaim 掉所有可以被 gc 的对象。这里说一下，一个对象 retire 之后，就会从 hp 链表中被删掉，然后放到 retire 链表里。如果是这样的话，又在放到 retire 链表之前线程崩了，那么这个对象是不是泄露了？其实 retire 只会设置 hp 的 active 为 false。</p><p>如果此时 retire 被某个线程拿过去回收了，所以 retire 是 nullptr，然后又有一个新的节点要加到 retire 上，会不会导致出现两个 retire 链表？关于这个问题，看后面的实现就可以知道不会发生。他的做法并不是 swap 两个链表，而是在处理完老 retire 的 tail 后，将它的 next 设置为新 retired 链表的 head，然后再尝试更新 retire 为老 retire 的 head。结果就是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| 老 retire 中尚未释放的链表的 head | 新 retire 的 head |</span><br></pre></td></tr></table></figure><p>如何判断 retire 链表中的元素是可以被安全删除的呢？这里会遍历 hazptrs 链表，将遍历得到的指针全记录在 guarded_ptrs 中。我想其中一个要点是，如果一个指针被 retire 了：</p><ol><li>那么它就不会再出现在 hazptrs 链表中，因为它不可能被新的线程所访问。</li><li>因为它还没有被 reclaim，所以也不会在 hazptrs 中出现分配在同一个位置上的另一个对象。</li></ol><p>后面是对 Deleter 的实现。Deleter 是负责真正 reclaim 这个 ptr 的。Deleter 的作用是标记到底要 delete 什么对象。这个是通过 trait 里面的 vtable 来实现的。<br>第一版是这个写法。DropBox 适合用来析构从 Box 创建的对象。而 drop_in_place 应该可以在任何情况下被使用。但如果这个 ptr type 本身需要 drop 的话，可能会内存泄露。所以作者两种都提供了。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">DropInPlace</span></span>;</span><br><span class="line"><span class="keyword">impl</span> Deleter <span class="keyword">for</span> DropInPlace &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">delete</span></span>(ptr: *<span class="keyword">mut</span> dyn <span class="built_in">Drop</span>) &#123;</span><br><span class="line">        <span class="keyword">unsafe</span> std::ptr::drop_in_place(ptr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">DropBox</span></span>;</span><br><span class="line"><span class="keyword">impl</span> Deleter <span class="keyword">for</span> DropBox &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">delete</span></span>(ptr: *<span class="keyword">mut</span> dyn <span class="built_in">Drop</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> _ = <span class="built_in">Box</span>::from_raw(ptr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后可能是他觉得用一个类包一下有点丑，所以就写了下面的方案。但这样写会报错，说后面那个 fn 没有 impl Deleter。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span> Deleter <span class="keyword">for</span> <span class="function"><span class="keyword">fn</span></span>(*<span class="keyword">mut</span> (dyn <span class="built_in">Drop</span> +<span class="symbol">'static</span>)) &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">delete</span></span>(&amp;<span class="keyword">self</span>, ptr:*<span class="keyword">mut</span> dyn <span class="built_in">Drop</span>) &#123;</span><br><span class="line">        (*<span class="keyword">self</span>)(ptr)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的原因是，需要传一个 fat pointer，一个带虚表的 pointer 给 retire，但一个 raw function 不是 fat pointer。</p><p>下面的代码是可以过的</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">drop_box</span></span>(ptr:*<span class="keyword">mut</span> dyn <span class="built_in">Drop</span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> _ = <span class="keyword">unsafe</span> &#123; <span class="built_in">Box</span>::from_raw(ptr) &#125;;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">static</span> FOO: <span class="function"><span class="keyword">fn</span></span>(*<span class="keyword">mut</span> dyn <span class="built_in">Drop</span>) = drop_box;</span><br><span class="line"></span><br><span class="line"><span class="keyword">unsafe</span> &#123; old.retire(&amp;FOO) &#125;;</span><br></pre></td></tr></table></figure><p>另外，类型转换也能过</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">drop_in_place</span></span>(ptr: *<span class="keyword">mut</span> dyn <span class="built_in">Drop</span>) &#123;</span><br><span class="line">    <span class="keyword">unsafe</span> &#123; std::ptr::drop_in_place(ptr) &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">unsafe</span> &#123; old.retire(&amp;(drop_in_place <span class="keyword">as</span> <span class="function"><span class="keyword">fn</span></span>(*<span class="keyword">mut</span> dyn <span class="built_in">Drop</span>))) &#125;;</span><br></pre></td></tr></table></figure><p>在这个讲座的第二部分，介绍了原代码的几个问题：</p><ol><li>在 reclaim 统计 ptr 数量的时候，需要过滤掉 inactive 的。这个也说明了 active 的作用，就是当一个 hp 被 retire 之后，它会被标记为 inactive，等待下一轮被拿出来复用，而不是从链表中摘出来释放掉。</li><li>在之前 HazPtrObject::reclaim 的实现中，也许 Self 不需要被 drop。但 <code>*mut Self</code> 可能来自于一个 Box，这个 Box 本身需要被 drop。因此不能简单判断 needs_drop 然后就跳过。</li><li>在 HazPtrDomain::bulk_reclaim 中，在没有判断 <code>guarded_ptrs.contains(&amp;(n.ptr as *mut u8))</code> 的前提下，就在前面 Box::from_raw 去获取所有权了。这个是不正确的，因为此时可能有 reader 在访问。<br> 正确的做法应该如下所示，去获取 <code>n</code> 也就是解出来的一个共享的引用。 <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> n = <span class="keyword">unsafe</span> &#123; &amp;*node &#125;;</span><br><span class="line">node = n.next.get_mut():</span><br></pre></td></tr></table></figure></li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p1121r3.pdf" target="_blank" rel="noopener">https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p1121r3.pdf</a></li><li><a href="https://github.com/jonhoo/haphazard/blob/7f0d8d62e071f8bc55233a3d2437225d6282e368/src/lib.rs" target="_blank" rel="noopener">https://github.com/jonhoo/haphazard/blob/7f0d8d62e071f8bc55233a3d2437225d6282e368/src/lib.rs</a><br> Rust HazPtr 作者的第一部视频结束后的代码。</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍 Hazard Pointer。&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
    <category term="多线程" scheme="http://www.calvinneo.com/tags/多线程/"/>
    
    <category term="Rust" scheme="http://www.calvinneo.com/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Excerpt from Harry Potter</title>
    <link href="http://www.calvinneo.com/2023/04/09/excerpt_harry_potter/"/>
    <id>http://www.calvinneo.com/2023/04/09/excerpt_harry_potter/</id>
    <published>2023-04-09T15:20:37.000Z</published>
    <updated>2024-02-23T16:58:58.035Z</updated>
    
    <content type="html"><![CDATA[<p>While rereading Harry Potter, I found these passages are inspiring and interesting.</p><a id="more"></a><h1 id="HP1"><a href="#HP1" class="headerlink" title="HP1"></a>HP1</h1><p>“No, thanks,” said Harry. “The poor toilet’s never had anything as horrible as your head down it — it might be sick.” Then he ran, before Dudley could work out what he’d said. </p><p>But from that moment on, Hermione Granger became their friend. There are some things you can’t share without ending up liking each other, and knocking out a twelve-foot mountain troll is one of them. </p><p>It does not do to dwell on dreams and forget to live, remember that.</p><p>Everyone fell over laughing except Hermione, who leapt up and performed the countercurse. Neville’s legs sprang apart and he got to his feet, trembling. </p><p>“Call him Voldemort, Harry. Always use the proper name for things. Fear of a name increases fear of the thing itself.”</p><p>“There are all kinds of courage,” said Dumbledore, smiling. “It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends. I therefore award ten points to Mr. Neville Longbottom.”</p><h1 id="HP2"><a href="#HP2" class="headerlink" title="HP2"></a>HP2</h1><p>“Did you really?” said Mr. Weasley eagerly. “Did it go all right? I — I mean,” he faltered as sparks flew from Mrs. Weasley’s eyes, “that — that was very wrong, boys — very wrong indeed. . . .” </p><p>“Rubbish,” said Hermione. “You’ve read his books — look at all those amazing things he’s done —“<br>“He says he’s done,” Ron muttered.</p><p>“I never thought I’d see the day when you’d be persuading us to break rules,” said Ron. “All right, we’ll do it. But not toenails, okay?” </p><p>“See here, Malfoy, if Dumbledore can’t stop them,” said Fudge, whose upper lip was sweating now, “I mean to say, who can?” </p><blockquote><p>help will always be given at Hogwarts to those who ask for it.</p></blockquote><p>“However,” said Dumbledore, speaking very slowly and clearly so that none of them could miss a word, “you will find that I will only truly have left this school when none here are loyal to me. You will also find that help will always be given at Hogwarts to those who ask for it.” </p><blockquote><p>Ahaha</p></blockquote><p>“But one of us seems to be keeping mightily quiet about his part<br>in this dangerous adventure,” Dumbledore added. “Why so modest, Gilderoy?”</p><p>“He tried to do a Memory Charm and the wand backfired,” Ron explained quietly to Dumbledore.<br>“Dear me,” said Dumbledore, shaking his head, his long silver mustache quivering. “Impaled upon your own sword, Gilderoy!”</p><p>“Voldemort put a bit of himself in me?” Harry said, thunderstruck.</p><blockquote><p>“because I asked not to go in Slytherin.” What really matters is one’s choice.</p></blockquote><p>“It only put me in Gryffindor,” said Harry in a defeated voice,<br>“because I asked not to go in Slytherin. . . .”<br>“Exactly,” said Dumbledore, beaming once more. “Which makes you very different from Tom Riddle. It is our choices, Harry, that show what we truly are, far more than our abilities.” Harry sat motionless in his chair, stunned. “If you want proof, Harry, that you belong in Gryffindor, I suggest you look more closely at this.”<br>Dumbledore reached across to Professor McGonagall’s desk, picked up the blood-stained silver sword, and handed it to Harry. Dully, Harry turned it over, the rubies blazing in the firelight. And then he saw the name engraved just below the hilt.<br>Godric Gryffindor.<br>“Only a true Gryffindor could have pulled that out of the hat, Harry,” said Dumbledore simply.</p><blockquote><p>“Dobby is free”</p></blockquote><p>“Master has given a sock,” said the elf in wonderment. “Master gave it to Dobby.”<br>“What’s that?” spat Mr. Malfoy. “What did you say?”<br>“Got a sock,” said Dobby in disbelief. “Master threw it, and Dobby caught it, and Dobby — Dobby is free.”</p><blockquote><p>And the day came eventually…</p></blockquote><p>“Least I could do, Dobby,” said Harry, grinning. “Just promise never to try and save my life again.” </p><h1 id="HP3"><a href="#HP3" class="headerlink" title="HP3"></a>HP3</h1><blockquote><p>Very accurate prophecy</p></blockquote><p>“I dare not, Headmaster! If I join the table, we shall be thirteen! Nothing could be more unlucky! Never forget that when thirteen dine together, the first to rise will be the first to die!”</p><blockquote><p>Very accurate prophecy too</p></blockquote><p>“If you must know, Minerva, I have seen that poor Professor Lupin will not be with us for very long. He seems aware, himself, that his time is short. He positively fled when I offered to crystal gaze for him —“ </p><blockquote><p>This scene is a wonderful scene in the movie<br>“Have you ever seen anything quite as pathetic?” said Malfoy.<br>“And he’s supposed to be our teacher!”<br>Harry and Ron both made furious moves toward Malfoy, but Hermione got there first — SMACK!<br>She had slapped Malfoy across the face with all the strength she could muster. Malfoy staggered. Harry, Ron, Crabbe, and Goyle stood flabbergasted as Hermione raised her hand again.</p></blockquote><p>“YOU CHEATING SCUM!” Lee Jordan was howling into the megaphone, dancing out of Professor McGonagall’s reach. “YOU FILTHY, CHEATING B —“</p><blockquote><p>In Chinese version, it is fist rather than finger. But finger here is more vivid.<br>Professor McGonagall didn”t even bother to tell him off. She was actually shaking her finger in Malfoy’s direction, her hat had fallen off, and she too was shouting furiously.</p></blockquote><p>“I must admit, Peter, I have difficulty in understanding why an innocent man would want to spend twelve years as a rat,” said Lupin evenly.</p><p>“If you made a better rat than a human, it’s not much to boast about, Peter,” said Black harshly. </p><p>“You don’t understand!” whined Pettigrew. “He would have killed me, Sirius!”<br>“THEN YOU SHOULD HAVE DIED!” roared Black. “DIED RATHER THAN BETRAY YOUR FRIENDS, AS WE WOULD HAVE DONE FOR YOU!”<br>Black and Lupin stood shoulder to shoulder, wands raised.<br>“You should have realized,” said Lupin quietly, “if Voldemort didn’t kill you, we would. Good-bye, Peter.” </p><p>“I’m not doing this for you. I’m doing it because — I don’t reckon my dad would’ve wanted them to become killers — just for you.”</p><blockquote><p>You know, Minister, I disagree with Dumbledore on many counts . . . but you cannot deny he’s got style. . . .</p></blockquote><p>“What we need,” said Dumbledore slowly, and his light blue eyes moved from Harry to Hermione, “is more time.”<br>“But —“ Hermione began. And then her eyes became very round. “OH!”<br>“Now, pay attention,” said Dumbledore, speaking very low, and very clearly. “Sirius is locked in Professor Flitwick’s office on the seventh floor. Thirteenth window from the right of the West Tower. If all goes well, you will be able to save more than one innocent life tonight. But remember this, both of you: you must not be seen. Miss Granger, you know the law — you know what is at stake. . . . You — must — not — be — seen.”</p><p>“Dumbledore just said — just said we could save more than one innocent life. . . .” And then it hit him. “Hermione, we’re going to save Buckbeak!”</p><blockquote><p>He knew it!</p></blockquote><p>Harry tugged harder on the rope around Buckbeak’s neck. The hippogriff began to walk, rustling its wings irritably. They were still ten feet away from the forest, in plain view of Hagrid’s back door.<br>“One moment, please, Macnair,” came Dumbledore’s voice.<br>“You need to sign too.” The footsteps stopped. Harry heaved on the rope. Buckbeak snapped his beak and walked a little faster. </p><blockquote><p>You can always rely on yourself</p></blockquote><p>And then it hit him — he understood. He hadn’t seen his father — he had seen himself — Harry flung himself out from behind the bush and pulled out his wand.<br>“EXPECTO PATRONUM!” he yelled. </p><blockquote><p>It made all the difference in the world</p></blockquote><p>“It didn’t make any difference,” said Harry bitterly. “Pettigrew got away.”<br>“Didn’t make any difference?” said Dumbledore quietly. “It made all the difference in the world, Harry. You helped uncover the truth. You saved an innocent man from a terrible fate.”</p><blockquote><p>We all know in HP7, Pettigrew gave his life to save Harry.</p></blockquote><p>This is magic at its deepest, its most impenetrable, Harry. But trust me … the time may come when you will be very glad you saved Pettigrew’s life.</p><p>“You think the dead we loved ever truly leave us? You think that<br>we don”t recall them more clearly than ever in times of great trouble? Your father is alive in you, Harry, and shows himself most plainly when you have need of him. How else could you produce that particular Patronus? Prongs rode again last night.”<br>It took a moment for Harry to realize what Dumbledore had said.</p><h1 id="HP4"><a href="#HP4" class="headerlink" title="HP4"></a>HP4</h1><blockquote><p>The bar that leads to diag alley is called leaking cauldron<br>“We’re not thundering,” said Ron irritably. “We’re walking. Sorry if we’ve disturbed the top-secret workings of the Ministry of Magic.”<br>“What are you working on?” said Harry.<br>“A report for the Department of International Magical Cooperation,” said Percy smugly. “We’re trying to standardize cauldron thickness. Some of these foreign imports are just a shade too thin — leakages have been increasing at a rate of almost three percent a year —“<br>“That’ll change the world, that report will,” said Ron. “Front page of the Daily Prophet, I expect, cauldron leaks.” </p></blockquote><blockquote><p>Crouch can’t even spell Percy’s name correctly.</p></blockquote><p>“Ludo, we need to meet the Bulgarians, you know,” said Mr. Crouch sharply, cutting Bagman’s remarks short. “Thank you for the tea, Weatherby.” </p><blockquote><p>It was the only time the brothers have seem what they will look like when they get old.</p></blockquote><p>The entrance hall rang with laughter. Even Fred and George joined in, once they had gotten to their feet and taken a good look at each other’s beards.</p><blockquote><p>“because Dobby wants paying now”</p></blockquote><p>“Dobby has traveled the country for two whole years, sir, trying to find work!” Dobby squeaked. “But Dobby hasn’t found work, sir, because Dobby wants paying now!”<br>The house-elves all around the kitchen, who had been listening and watching with interest, all looked away at these words, as though Dobby had said something rude and embarrassing.<br>Hermione, however, said, “Good for you, Dobby!”<br>“Thank you, miss!” said Dobby, grinning toothily at her. “But most wizards doesn’t want a house-elf who wants paying, miss. ‘That’s not the point of a house-elf,’ they says, and they slammed the door in Dobby’s face! Dobby likes work, but he wants to wear clothes and he wants to be paid, Harry Potter. . . . Dobby likes being free!”</p><p>“Oh no, sir, no,” said Dobby, looking suddenly serious. “ ‘Tis part of the house-elf’s enslavement, sir. We keeps their secrets and our silence, sir. We upholds the family’s honor, and we never speaks ill of them — though Professor Dumbledore told Dobby he does not insist upon this. Professor Dumbledore said we is free to — to —“<br>Dobby looked suddenly nervous and beckoned Harry closer.<br>Harry bent forward. Dobby whispered, “He said we is free to call him a — a barmy old codger if we likes, sir!”<br>Dobby gave a frightened sort of giggle.<br>“But Dobby is not wanting to, Harry Potter,” he said, talking normally again, and shaking his head so that his ears flapped.<br>“Dobby likes Professor Dumbledore very much, sir, and is proud to keep his secrets and our silence for him.”</p><blockquote><p>“temporarily deaf”</p></blockquote><p>“Of course we still want to know you!” Harry said, staring at Hagrid. “You don’t think anything that Skeeter cow — sorry, Professor,” he added quickly, looking at Dumbledore.<br>“I have gone temporarily deaf and haven’t any idea what you said, Harry,” said Dumbledore, twiddling his thumbs and staring at the ceiling. </p><p>“Really, Hagrid, if you are holding out for universal popularity,<br>I’m afraid you will be in this cabin for a very long time,” said Dumbledore, now peering sternly over his half-moon spectacles. “Not a week has passed since I became headmaster of this school when I haven’t had at least one owl complaining about the way I run it. But what should I do? Barricade myself in my study and refuse to talk to anybody?”</p><blockquote><p>Another subtle foreshadowing. One must finish reading the entire book before being impressed by Dumbledore’s foresight.</p></blockquote><p>For a fleeting instant, Harry thought he saw a gleam of something like triumph in Dumbledore’s eyes.</p><p>“You are blinded,” said Dumbledore, his voice rising now, the aura of power around him palpable, his eyes blazing once more, “by the love of the office you hold, Cornelius! You place too much importance, and you always have done, on the so-called purity of blood! You fail to recognize that it matters not what someone is born, but what they grow to be! Your dementor has just destroyed the last remaining member of a pure-blood family as old as any — and see what that man chose to make of his life! </p><blockquote><p>“make a choice between what is right and what is easy”.</p></blockquote><p>Remember Cedric. Remember, if the time should come when you have to make a choice between what is right and what is easy, remember what happened to a boy who was good, and kind, and brave, because he strayed across the path of Lord Voldemort. Remember Cedric Diggory.</p><p>“Listen,” said Harry firmly. “If you don’t take it, I’m throwing it down the drain. I don’t want it and I don’t need it. But I could do with a few laughs. We could all do with a few laughs. I’ve got a feeling we’re going to need them more than usual before long.” </p><h1 id="HP5"><a href="#HP5" class="headerlink" title="HP5"></a>HP5</h1><blockquote><p>DO NOT SURRENDER YOUR WAND</p></blockquote><p>Harry —<br>Dumbledore’s just arrived at the Ministry, and he’s trying to sort it all out. DO NOT LEAVE YOUR AUNT AND UNCLE’S HOUSE. DO NOT DO ANY MORE MAGIC. DO NOT SURRENDER YOUR WAND</p><blockquote><p>I think it’s funny, since it remind me of Sir Humphrey Appleby.</p></blockquote><p>… because some changes will be for the better, while others will come, in the fullness of time, to be recognized as errors of judgment. Meanwhile, some old habits will be retained, and rightly so, whereas others, outmoded and outworn, must be abandoned. Let us move forward, then, into a new era of openness, effectiveness, and accountability, intent on preserving what ought to be preserved, perfecting what needs to be perfected, and pruning wherever we find practices that ought to be prohibited.</p><p>“You told her He-Who-Must-Not-Be-Named is back?<br>“Yes.”<br>Professor McGonagall sat down behind her desk, frowning at Harry.<br>Then she said, “Have a biscuit, Potter.”</p><blockquote><p>That tells the difference between Hermione and Percy.</p></blockquote><p>“You disagree?”<br>“Yes, I do,” said Hermione, who, unlike Umbridge, was not whispering, but speaking in a clear, carrying voice that had by now attracted the rest of the class’s attention. “Mr. Slinkhard doesn’t like jinxes, does he? But I think they can be very useful when they’re used defensively.” </p><blockquote><p>Ron’s awkward compliment shows the subtle change in his relationship with Hermione.</p></blockquote><p>“We do try,” said Ron. “We just haven’t got your brains or your memory or your concentration — you’re just cleverer than we are — is it nice to rub it in?”<br>“Oh, don’t give me that rubbish,” said Hermione, but she looked slightly mollified as she led the way out into the damp courtyard. </p><blockquote><p>Excellent sarcasm.</p></blockquote><p>“For disrupting my class with pointless interruptions,” said Professor Umbridge smoothly. “I am here to teach you using a Ministry approved method that does not include inviting students to give their opinions on matters about which they understand very little. Your previous teachers in this subject may have allowed you more license, but as none of them — with the possible exception of Professor Quirrell, who did at least appear to have restricted himself to age-appropriate subjects — would have passed a Ministry inspection —“<br>“Yeah, Quirrell was a great teacher,” said Harry loudly, “there was just that minor drawback of him having Lord Voldemort sticking out of the back of his head.” </p><blockquote><p>Hermione is not a nerd.</p></blockquote><p>Nobody raised objections after Ernie, though Harry saw Cho’s friend give her a rather reproachful look before adding her name. When the last person — Zacharias — had signed, Hermione took the parchment back and slipped it carefully into her bag. There was an odd feeling in the group now. It was as though they had just signed some kind of contract.</p><p>He was on the sixth stair when it happened. There was a loud, wailing, klaxonlike sound and the steps melted together to make a long, smooth stone slide. There was a brief moment when Ron tried to keep running, arms working madly like windmills, then he toppled over backward and shot down the newly created slide, coming to rest on his back at Harry’s feet. </p><blockquote><p>Umbridge’s confrontation with Snape. Snape refused to say one more word to deal with Umbridge’s nonsense.</p></blockquote><p>“Well, the class seems fairly advanced for their level,” she said briskly to Snape’s back. “Though I would question whether it is advisable to teach them a potion like the Strengthening Solution. I think the Ministry would prefer it if that was removed from the syllabus.”<br>Snape straightened up slowly and turned to look at her.<br>“Now … how long have you been teaching at Hogwarts?” she asked, her quill poised over her clipboard.<br>“Fourteen years,” Snape replied. His expression was unfathomable.<br>His eyes on Snape, Harry added a few drops to his potion; it hissed menacingly and turned from turquoise to orange.<br>“You applied first for the Defense Against the Dark Arts post, I believe?” Professor Umbridge asked Snape.<br>“Yes,” said Snape quietly.<br>“But you were unsuccessful?”<br>Snape’s lip curled.<br>“Obviously.”<br>Professor Umbridge scribbled on her clipboard.<br>“And you have applied regularly for the Defense Against the Dark Arts post since you first joined the school, I believe?”<br>“Yes,” said Snape quietly, barely moving his lips. He looked very angry.<br>“Do you have any idea why Dumbledore has consistently refused to appoint you?” asked Umbridge.<br>“I suggest you ask him,” said Snape jerkily.<br>“Oh I shall,” said Professor Umbridge with a sweet smile.<br>“I suppose this is relevant?” Snape asked, his black eyes narrowed.</p><blockquote><p>It is always wise to take fate firmly in one’s own hands.</p></blockquote><p>“Well, better expelled and able to defend yourselves than sitting safely in school without a clue,” said Sirius. </p><blockquote><p>Some parents are “living through us”.</p></blockquote><p>“You don’t think he has become … sort of … reckless … since he’s been cooped up in Grimmauld Place? You don’t think he’s … kind of … living through us?” </p><blockquote><p>there are things worth dying for</p></blockquote><p>“Your father knew what he was getting into, and he won’t thank you for messing things up for the Order!” said Sirius angrily in his turn. “This is how it is — this is why you’re not in the Order — you don’t understand — there are things worth dying for!”<br>“Easy for you to say, stuck here!” bellowed Fred. “I don’t see you risking your neck!” </p><blockquote><p>Being a victim is not a shame. However, being a fighter is more honorable.</p></blockquote><p>“What’s this?” said Mrs. Longbottom sharply. “Haven’t you told your friends about your parents, Neville?”<br>Neville took a deep breath, looked up at the ceiling, and shook his head. Harry could not remember ever feeling sorrier for anyone, but he could not think of any way of helping Neville out of the situation.<br>“Well, it’s nothing to be ashamed of!” said Mrs. Longbottom angrily. “You should be proud, Neville, proud! They didn’t give their health and their sanity so their only son would be ashamed of them, you know!”<br>“I’m not ashamed,” said Neville very faintly, still looking anywhere but at Harry and the others. Ron was now standing on tiptoe to look over at the inhabitants of the two beds.<br>“Well, you’ve got a funny way of showing it!” said Mrs. Longbottom. “My son and his wife,” she said, turning haughtily to Harry, Ron, Hermione, and Ginny, “were tortured into insanity by You-Know-Who’s followers.”<br>Hermione and Ginny both clapped their hands over their mouths.<br>Ron stopped craning his neck to catch a glimpse of Neville’s parents and looked mortified.<br>“They were Aurors, you know, and very well respected within the Wizarding community,” Mrs. Longbottom went on. “Highly gifted, the pair of them. I — yes, Alice dear, what is it?” </p><blockquote><p>An incisive comment on speech censorship. </p></blockquote><p>“Oh Harry, don’t you see?” Hermione breathed. “If she could have done one thing to make absolutely sure that every single person in this school will read your interview, it was banning it!”</p><blockquote><p>Brilliant irony.</p></blockquote><p>“Oh, so that’s why he wasn’t prosecuted for setting up all those regurgitating toilets!” said Professor McGonagall, raising her eyebrows. “What an interesting insight into our justice system!” </p><blockquote><p>I cannot allow you to manhandle my students</p></blockquote><p>“Well, usually when a person shakes their head,” said McGonagall coldly, “they mean ‘no.’ So unless Miss Edgecombe is using a form of sign language as yet unknown to humans —“<br>Professor Umbridge seized Marietta, pulled her around to face her, and began shaking her very hard. A split second later Dumbledore was on his feet, his wand raised. Kingsley started forward and Umbridge leapt back from Marietta, waving her hands in the air as though they had been burned.<br>“I cannot allow you to manhandle my students, Dolores,” said Dumbledore, and for the first time, he looked angry.<br>“You want to calm yourself, Madam Umbridge,” said Kingsley in  his deep, slow voice. “You don’t want to get yourself into trouble now.”</p><blockquote><p>Dumbledore’s contempt of Fudge jumps off the page.</p></blockquote><p>“Well, the game is up,” he said simply. “Would you like a written confession from me, Cornelius — or will a statement before these witnesses suffice?”<br>Harry saw McGonagall and Kingsley look at each other. There was fear in both faces. He did not understand what was going on, and neither, apparently, did Fudge.<br>“Statement?” said Fudge slowly. “What — I don’t — ?”<br>“Dumbledore’s Army, Cornelius,” said Dumbledore, still smiling as he waved the list of names before Fudge’s face. “Not Potter’s Army. Dumbledore’s Army.”<br>“But — but —“<br>Understanding blazed suddenly in Fudge’s face. He took a horrified step backward, yelped, and jumped out of the fire again.<br>“You?” he whispered, stamping again on his smoldering cloak.<br>“That’s right,” said Dumbledore pleasantly.<br>“You organized this?”<br>“I did,” said Dumbledore.<br>“You recruited these students for — for your army?”<br>“Tonight was supposed to be the first meeting,” said Dumbledore, nodding. “Merely to see whether they would be interested in joining me. I see now that it was a mistake to invite Miss Edgecombe, of course.”<br>Marietta nodded. Fudge looked from her to Dumbledore, his chest swelling.<br>“Then you have been plotting against me!” he yelled.<br>“That’s right,” said Dumbledore cheerfully.<br>“NO!” shouted Harry.<br>Kingsley flashed a look of warning at him, McGonagall widened her eyes threateningly, but it had suddenly dawned upon Harry what Dumbledore was about to do, and he could not let it happen.<br>“No — Professor Dumbledore!”<br>“Be quiet, Harry, or I am afraid you will have to leave my office,” said Dumbledore calmly.<br>“Yes, shut up, Potter!” barked Fudge, who was still ogling Dumbledore with a kind of horrified delight. “Well, well, well — I came here tonight expecting to expel Potter and instead —“<br>“Instead you get to arrest me,” said Dumbledore, smiling. “It’s like losing a Knut and finding a Galleon, isn’t it?”<br>“Weasley!” cried Fudge, now positively quivering with delight, “Weasley, have you written it all down, everything he’s said, his confession, have you got it?”<br>“Yes, sir, I think so, sir!” said Percy eagerly, whose nose was splattered with ink from the speed of his note-taking.<br>“The bit about how he’s been trying to build up an army against the Ministry, how he’s been working to destabilize me?”<br>“Yes, sir, I’ve got it, yes!” said Percy, scanning his notes joyfully.<br>“Very well, then,” said Fudge, now radiant with glee. “Duplicate your notes, Weasley, and send a copy to the Daily Prophet at once. If we send a fast owl we should make the morning edition!” Percy dashed from the room, slamming the door behind him, and Fudge turned back to Dumbledore. “You will now be escorted back to the Ministry, where you will be formally charged and then sent to Azkaban to await trial!”<br>“Ah,” said Dumbledore gently, “yes. Yes, I thought we might hit that little snag.”<br>“Snag?” said Fudge, his voice still vibrating with joy. “I see no snag, Dumbledore!”<br>“Well,” said Dumbledore apologetically, “I’m afraid I do.”<br>“Oh really?”<br>“Well — it’s just that you seem to be laboring under the delusion that I am going to — what is the phrase? ‘Come quietly’ I am afraid I am not going to come quietly at all, Cornelius. I have absolutely no intention of being sent to Azkaban. I could break out, of course — but what a waste of time, and frankly, I can think of a whole host of things I would rather be doing.”<br>Umbridge’s face was growing steadily redder, she looked as though she was being filled with boiling water. Fudge stared at Dumbledore with a very silly expression on his face, as though he had just been stunned by a sudden blow and could not quite believe it had happened. He made a small choking noise and then looked around at Kingsley and the man with short gray hair, who alone of everyone in the room had remained entirely silent so far. The latter gave Fudge a reassuring nod and moved forward a little, away from the wall. Harry saw his hand drift, almost casually, toward his pocket.<br>“Don’t be silly, Dawlish,” said Dumbledore kindly. “I’m sure you are an excellent Auror, I seem to remember that you achieved ‘Outstanding’ in all your N.E.W.T.s, but if you attempt to — er — ‘bring me in’ by force, I will have to hurt you.”<br>The man called Dawlish blinked, looking rather foolish. He looked toward Fudge again, but this time seemed to be hoping for a clue as to what to do next.<br>“So,” sneered Fudge, recovering himself, “you intend to take on Dawlish, Shacklebolt, Dolores, and myself single-handed, do you, Dumbledore?”<br>“Merlin’s beard, no,” said Dumbledore, smiling. “Not unless you are foolish enough to force me to.”<br>“He will not be single-handed!” said Professor McGonagall loudly, plunging her hand inside her robes.<br>“Oh yes he will, Minerva!” said Dumbledore sharply. “Hogwarts needs you!”<br>“Enough of this rubbish!” said Fudge, pulling out his own wand.<br>“Dawlish! Shacklebolt! Take him!”<br>A streak of silver light flashed around the room. There was a bang  like a gunshot, and the floor trembled. A hand grabbed the scruff of  Harry’s neck and forced him down on the floor as a second silver flash went off — several of the portraits yelled, Fawkes screeched, and a cloud of dust filled the air. Coughing in the dust, Harry saw a dark figure fall to the ground with a crash in front of him. There was a shriek and a thud and somebody cried, “No!” Then the sound of breaking glass, frantically scuffling footsteps, a groan — and silence.<br>Harry struggled around to see who was half-strangling him and saw  Professor McGonagall crouched beside him. She had forced both him and Marietta out of harm’s way. Dust was still floating gently down  through the air onto them. Panting slightly, Harry saw a very tall figure moving toward them. </p><p>“ ‘Course we have,” said George. “Never been expelled, have we?”<br>“We’ve always known where to draw the line,” said Fred.<br>“We might have put a toe across it occasionally,” said George.<br>“But we’ve always stopped short of causing real mayhem,” said Fred.<br>“But now?” said Ron tentatively.<br>“Well, now —“ said George.<br>“— what with Dumbledore gone —“ said Fred.<br>“— we reckon a bit of mayhem —“ said George.<br>“— is exactly what our dear new Head deserves,” said Fred.<br>“You mustn’t!” whispered Hermione. “You really mustn’t! She’d love a reason to expel you!”<br>“You don’t get it, Hermione, do you?” said Fred, smiling at her.<br>“We don’t care about staying anymore. We’d walk out right now if we weren’t determined to do our bit for Dumbledore first. So anyway,” he checked his watch, “phase one is about to begin. I’d get in the Great Hall for lunch if I were you, that way the teachers will see you can’t have had anything to do with it.”</p><p>“Thank you so much, Professor!” said Professor Flitwick in his squeaky little voice. “I could have got rid of the sparklers myself, of course, but I wasn’t sure whether I had the authority… .” </p><blockquote><p>Hermione and rebellious…</p></blockquote><p>“Oh, why don’t we have a night off?” said Hermione brightly, as a silver-tailed Weasley rocket zoomed past the window. “After all, the Easter holidays start on Friday, we’ll have plenty of time then… .”<br>“Are you feeling all right?” Ron asked, staring at her in disbelief.<br>“Now you mention it,” said Hermione happily, “d’you know … I think I’m feeling a bit … rebellious.” </p><blockquote><p>When it comes to satire, McGonagall will never let you down.</p></blockquote><p>“I should have made my meaning plainer,” said Professor McGonagall, turning at last to look Umbridge directly in the eyes. “He has achieved high marks in all Defense Against the Dark Arts tests set by a competent teacher.” </p><blockquote><p>“She towered over”</p></blockquote><p>Professor McGonagall got to her feet too, and in her case this was a much more impressive move. She towered over Professor Umbridge.<br>“Potter,” she said in ringing tones, “I will assist you to become an Auror if it is the last thing I do! If I have to coach you nightly I will make sure you achieve the required results!”<br>“The Minister of Magic will never employ Harry Potter!” said Umbridge, her voice rising furiously.<br>“There may well be a new Minister of Magic by the time Potter is ready to join!” shouted Professor McGonagall. </p><blockquote><p>Glorious finale of Fred and George’s schooling.</p></blockquote><p>“You know what?” said Fred. “I don’t think we are.”<br>He turned to his twin.<br>“George,” said Fred, “I think we’ve outgrown full-time education.”<br>“Yeah, I’ve been feeling that way myself,” said George lightly.<br>“Time to test our talents in the real world, d’you reckon?” asked Fred.<br>“Definitely,” said George.<br>And before Umbridge could say a word, they raised their wands and said together, “Accio Brooms!”<br>Harry heard a loud crash somewhere in the distance. Looking to his left he ducked just in time — Fred and George’s broomsticks, one still trailing the heavy chain and iron peg with which Umbridge had fastened them to the wall, were hurtling along the corridor toward their owners. They turned left, streaked down the stairs, and stopped sharply in front of the twins, the chain clattering loudly on the flagged stone floor.<br>“We won’t be seeing you,” Fred told Professor Umbridge, swinging his leg over his broomstick.<br>“Yeah, don’t bother to keep in touch,” said George, mounting his own.<br>Fred looked around at the assembled students, and at the silent, watchful crowd.<br>“If anyone fancies buying a Portable Swamp, as demonstrated upstairs, come to number ninety-three, Diagon Alley — Weasleys’ Wizarding Wheezes,” he said in a loud voice. “Our new premises!”<br>“Special discounts to Hogwarts students who swear they’re going to use our products to get rid of this old bat,” added George, pointing at Professor Umbridge.<br>“STOP THEM!” shrieked Umbridge, but it was too late. As the Inquisitorial Squad closed in, Fred and George kicked off from the floor, shooting fifteen feet into the air, the iron peg swinging dangerously below. Fred looked across the hall at the poltergeist bobbing on his level above the crowd.<br>“Give her hell from us, Peeves.”<br>And Peeves, whom Harry had never seen take an order from a student before, swept his belled hat from his head and sprang to a salute as Fred and George wheeled about to tumultuous applause from the students below and sped out of the open front doors into the glorious sunset. </p><p>Indeed, a week after Fred and George’s departure Harry witnessed Professor McGonagall walking right past Peeves, who was determinedly loosening a crystal chandelier, and could have sworn he heard her tell the poltergeist out of the corner of her mouth, “It unscrews the other way.”</p><blockquote><p>there are things much worse than death</p></blockquote><p>“We both know that there are other ways of destroying a man, Tom,” Dumbledore said calmly, continuing to walk toward Voldemort as though he had not a fear in the world, as though nothing had happened to interrupt his stroll up the hall. “Merely taking your life would not satisfy me, I admit —“<br>“There is nothing worse than death, Dumbledore!” snarled Voldemort.<br>“You are quite wrong,” said Dumbledore, still closing in upon Voldemort and speaking as lightly as though they were discussing the matter over drinks. Harry felt scared to see him walking along, undefended, shieldless. He wanted to cry out a warning, but his headless guard kept shunting him backward toward the wall, blocking his every attempt to get out from behind it. “Indeed, your failure to understand that there are things much worse than death has always been your greatest weakness —“</p><blockquote><p>faltered … as surveyed … magisterially over …<br>This is one of the few scenes in which Dumbledore act very aggresively. Don’t forget that he used to hand out with Grindelwald.</p></blockquote><p>“Now see here, Dumbledore!” said Fudge, as Dumbledore picked up the head and walked back to Harry carrying it. “You haven’t got authorization for that Portkey! You can’t do things like that right in front of the Minister of Magic, you — you —“<br>His voice faltered as Dumbledore surveyed him magisterially over his half-moon spectacles.<br>“You will give the order to remove Dolores Umbridge from Hogwarts,” said Dumbledore. “You will tell your Aurors to stop searching for my Care of Magical Creatures teacher so that he can return to work. I will give you …” Dumbledore pulled a watch with twelve hands from his pocket and glanced at it, “half an hour of my time tonight, in which I think we shall be more than able to cover the important points of what has happened here. After that, I shall need to return to my school. If you need more help from me you are, of course, more than welcome to contact me at Hogwarts. Letters addressed to the headmaster will find me.”</p><p>“Kreacher is what he has been made by wizards, Harry,” said Dumbledore. “Yes, he is to be pitied. His existence has been as miserable as your friend Dobby’s. He was forced to do Sirius’s bidding, because Sirius was the last of the family to which he was enslaved, but he felt no true loyalty to him. And whatever Kreacher’s faults, it must be admitted that Sirius did nothing to make Kreacher’s lot easier —“ </p><p>“Sirius did not hate Kreacher,” said Dumbledore. “He regarded him as a servant unworthy of much interest or notice. Indifference and neglect often do much more damage than outright dislike… .<br>The fountain we destroyed tonight told a lie. We wizards have mistreated and abused our fellows for too long, and we are now reaping our reward.”</p><p>Well, Flitwick’s got rid of Fred and George’s swamp,” said Ginny.<br>“He did it in about three seconds. But he left a tiny patch under the window and he’s roped it off —“<br>“Why?” said Hermione, looking startled.<br>“Oh, he just says it was a really good bit of magic,” said Ginny, shrugging.<br>“I think he left it as a monument to Fred and George,” said Ron through a mouthful of chocolate. “They sent me all these, you know,” he told Harry, pointing at the small mountain of Frogs beside him.<br>“Must be doing all right out of that joke shop, eh?” </p><blockquote><p>who can be intimidated</p></blockquote><p>“And do I look like the kind of man who can be intimidated?” barked Uncle Vernon.<br>“Well …” said Moody, pushing back his bowler hat to reveal his sinisterly revolving magical eye. Uncle Vernon leapt backward in horror and collided painfully with a luggage trolley. “Yes, I’d have to say you do, Dursley.” </p><h1 id="HP6"><a href="#HP6" class="headerlink" title="HP6"></a>HP6</h1><blockquote><p>“You are determined to hate him”</p></blockquote><p>“You are determined to hate him, Harry,” said Lupin with a faint smile. </p><blockquote><p>Snape’s irony </p></blockquote><p>“Yes, indeed, most admirable,” said Snape in a bored voice. “Of course, you weren’t a lot of use to him in prison, but the gesture was undoubtedly fine —“<br>“Gesture!” she shrieked; in her fury she looked slightly mad.<br>“While I endured the dementors, you remained at Hogwarts, comfortably playing Dumbledore’s pet!”</p><blockquote><p>Greate self-defending</p></blockquote><p>“Think!” said Snape, impatient again. “Think! By waiting two hours, just two hours, I ensured that I could remain at Hogwarts as a spy! By allowing Dumbledore to think that I was only returning to the Dark Lord’s side because I was ordered to, I have been able to pass information on Dumbledore and the Order of the Phoenix ever since! Consider, Bellatrix: The Dark Mark had been growing stronger for months. I knew he must be about to return, all the Death Eaters knew! I had plenty of time to think about what I wanted to do, to plan my next move, to escape like Karkaroff, didn’t I?</p><p>Harry got to his feet. As he walked across the room, his eyes fell upon the little table on which Marvolo Gaunt’s ring had rested last time, but the ring was no longer there.<br>“Yes, Harry?” said Dumbledore, for Harry had come to a halt.<br>“The ring’s gone,” said Harry, looking around. “But I thought you might have the mouth organ or something.”<br>Dumbledore beamed at him, peering over the top of his halfmoon spectacles.<br>“Very astute, Harry, but the mouth organ was only ever a mouth organ.”<br>And on that enigmatic note he waved to Harry, who understood himself to be dismissed. </p><blockquote><p>A very tough conversation with the Ministry.</p></blockquote><p>“But if I keep running in and out of the Ministry,” said Harry, still endeavoring to keep his voice friendly, “won’t that seem as though I approve of what the Ministry’s up to?”<br>“Well,” said Scrimgeour, frowning slightly, “well, yes, that’s partly why we’d like —“<br>“No, I don’t think that’ll work,” said Harry pleasantly. “You see, I don’t like some of the things the Ministry’s doing. Locking up Stan Shunpike, for instance.”<br>Scrimgeour did not speak for a moment but his expression hardened instantly. “I would not expect you to understand,” he said, and he was not as successful at keeping anger out of his voice as Harry had been. “These are dangerous times, and certain measures need to be taken. You are sixteen years old —“<br>“Dumbledore’s a lot older than sixteen, and he doesn’t think Stan should be in Azkaban either,” said Harry. “You’re making Stan a scapegoat, just like you want to make me a mascot.”<br>They looked at each other, long and hard. Finally Scrimgeour said, with no pretense at warmth, “I see. You prefer — like your hero, Dumbledore — to disassociate yourself from the Ministry?”<br>“I don’t want to be used,” said Harry.<br>“Some would say it’s your duty to be used by the Ministry!”<br>“Yeah, and others might say it’s your duty to check that people really are Death Eaters before you chuck them in prison,” said Harry, his temper rising now. “You’re doing what Barty Crouch  did. You never get it right, you people, do you? Either we’ve got Fudge, pretending everything’s lovely while people get murdered right under his nose, or we’ve got you, chucking the wrong people into jail and trying to pretend you’ve got ‘the Chosen One’ working for you!”<br>“So you’re not ‘the Chosen One’?” said Scrimgeour.<br>“I thought you said it didn’t matter either way?” said Harry, with a bitter laugh. “Not to you anyway.”<br>“I shouldn’t have said that,” said Scrimgeour quickly. “It was tactless —“<br>“No, it was honest,” said Harry. “One of the only honest things you’ve said to me. You don’t care whether I live or die, but you do care that I help you convince everyone you’re winning the war against Voldemort. I haven’t forgotten, Minister… .”<br>He raised his right fist. There, shining white on the back of his cold hand, were the scars which Dolores Umbridge had forced him to carve into his own flesh: I must not tell lies.<br>“I don’t remember you rushing to my defense when I was trying to tell everyone Voldemort was back. The Ministry wasn’t so keen to be pals last year.”<br>They stood in silence as icy as the ground beneath their feet. The gnome had finally managed to extricate his worm and was now sucking on it happily, leaning against the bottommost branches of the rhododendron bush.<br>“What is Dumbledore up to?” said Scrimgeour brusquely.<br>“Where does he go when he is absent from Hogwarts?”<br>“No idea,” said Harry.<br>“And you wouldn’t tell me if you knew,” said Scrimgeour, “would you?”<br>“No, I wouldn’t,” said Harry. </p><blockquote><p>“a baboon brandishing a stick”, LOL<br>“Harry’s already Apparated,” Ron told a slightly abashed Seamus, after Professor Flitwick had dried himself off with a wave of his wand and set Seamus lines: “I am a wizard, not a baboon brandishing a stick.” “Dum — er — someone took him. Side-Along Apparition, you know.”</p></blockquote><p>“He accused me of being ‘Dumbledore’s man through and through.’ “<br>“How very rude of him.”<br>“I told him I was.” </p><p>He raised his glass as though toasting Voldemort, whose face remained expressionless. Nevertheless, Harry felt the atmosphere in the room change subtly: Dumbledore’s refusal to use Voldemort’s chosen name was a refusal to allow Voldemort to dictate the terms of the meeting, and Harry could tell that Voldemort took it as such. </p><blockquote><p>“For the greater good”.</p></blockquote><p>“You call it ‘greatness,’ what you have been doing, do you?” asked Dumbledore delicately.<br>“Certainly,” said Voldemort, and his eyes seemed to burn red. “I have experimented; I have pushed the boundaries of magic further, perhaps, than they have ever been pushed —“<br>“Of some kinds of magic,” Dumbledore corrected him quietly. “Of some. Of others, you remain … forgive me … woefully ignorant.” </p><p>“I am glad to hear that you consider them friends,” said Dumbledore. “I was under the impression that they are more in the order of servants.”</p><p>“Let us speak openly. Why have you come here tonight, surrounded by henchmen, to request a job we both know you do not want?”<br>Voldemort looked coldly surprised. “A job I do not want? On the contrary, Dumbledore, I want it very much.”<br>“Oh, you want to come back to Hogwarts, but you do not want to teach any more than you wanted to when you were eighteen. What is it you’re after, Tom? Why not try an open request for once?”<br>Voldemort sneered. “If you do not want to give me a job —“<br>“Of course I don’t,” said Dumbledore. “And I don’t think for a moment you expected me to. Nevertheless, you came here, you asked, you must have had a purpose.” </p><blockquote><p>The most valuable thing of a man is braveness.</p></blockquote><p>“Of course, it doesn’t matter how he looks… . It’s not r-really important … but he was a very handsome little b-boy … always very handsome … and he was g-going to be married!”<br>“And what do you mean by zat?” said Fleur suddenly and loudly.<br>“What do you mean, ‘ ‘e was going to be married?’ “<br>Mrs. Weasley raised her tear-stained face, looking startled.<br>“Well — only that —“<br>“You theenk Bill will not wish to marry me anymore?” demanded Fleur. “You theenk, because of these bites, he will not love me?”<br>“No, that’s not what I —“<br>“Because ‘e will!” said Fleur, drawing herself up to her full height and throwing back her long mane of silver hair. “It would take more zan a werewolf to stop Bill loving me!”<br>“Well, yes, I’m sure,” said Mrs. Weasley, “but I thought perhaps — given how — how he —“<br>“You thought I would not weesh to marry him? Or per’aps, you hoped?” said Fleur, her nostrils flaring. “What do I care how he looks? I am good-looking enough for both of us, I theenk! All these scars show is zat my husband is brave! And I shall do zat!” she added fiercely, pushing Mrs. Weasley aside and snatching the ointment from her.<br>Mrs. Weasley fell back against her husband and watched Fleur mopping up Bill’s wounds with a most curious expression upon her face. Nobody said anything; Harry did not dare move. Like everybody else, he was waiting for the explosion.<br>“Our Great-Auntie Muriel,” said Mrs. Weasley after a long pause, “has a very beautiful tiara — goblin-made — which I am sure I could persuade her to lend you for the wedding. She is very fond of Bill, you know, and it would look lovely with your hair.”<br>“Thank you,” said Fleur stiffly. “I am sure zat will be lovely.”<br>And then, Harry did not quite see how it happened, both women were crying and hugging each other. Completely bewildered, wondering whether the world had gone mad, he turned around: Ron looked as stunned as he felt and Ginny and Hermione were exchanging startled looks. </p><blockquote><p>she would not say, “Be careful,” or “Don’t do it,” but accept his decision, because she would not have expected anything less of him</p></blockquote><p>Harry looked at Ginny, Ron, and Hermione: Ron’s face was screwed up as though the sunlight were blinding him. Hermione’s face was glazed with tears, but Ginny was no longer crying. She met Harry’s gaze with the same hard, blazing look that he had seen when she had hugged him after winning the Quidditch Cup in his absence, and he knew that at that moment they understood each other perfectly, and that when he told her what he was going to do now, she would not say, “Be careful,” or “Don’t do it,” but accept his decision, because she would not have expected anything less of him. And so he steeled himself to say what he had known he must say ever since Dumbledore had died.</p><h1 id="HP7"><a href="#HP7" class="headerlink" title="HP7"></a>HP7</h1><blockquote><p>“He must’ve known you’d always want to come back.”</p></blockquote><p>But I don’t think so, not anymore. He knew what he was doing when he gave me the Deluminator, didn’t he? He — well,” Ron’s ears turned bright red and he became engrossed in a tuft of grass at his feet, which he prodded with his toe, “he must’ve known I’d run out on you.”<br>“No,” Harry corrected him. “He must’ve known you’d always want to come back.” </p><blockquote><p>“And if it does fall into his grasp,” said Dumbledore, almost, it seemed, as an aside, “I have your word that you will do all in your power to protect the students of Hogwarts?”</p></blockquote><p>“Professor Snape sent them into the Forbidden Forest, to do some work for the oaf, Hagrid.”<br>“Hagrid’s not an oaf!” said Hermione shrilly.<br>“And Snape might’ve thought that was a punishment,” said Harry, “but Ginny, Neville, and Luna probably had a good laugh with Hagrid. The Forbidden Forest . . . they’ve faced plenty worse than the Forbidden Forest, big deal!” </p><blockquote><p>This is a very giant change of Harry. He finally learned how to shut his mind from Voldemort, and he’s no longer obsessed with Hallows.</p></blockquote><p>His scar burned, but he was master of the pain; he felt it, yet was apart from it. He had learned control at last, learned to shut his mind to Voldemort, the very thing Dumbledore had wanted him to learn from Snape. Just as Voldemort had not been able to possess Harry while Harry was consumed with grief for Sirius, so his thoughts could not penetrate Harry now, while he mourned Dobby.<br>Grief, it seemed, drove Voldemort out . . . though Dumbledore, of course, would have said that it was love. . . .<br>On Harry dug, deeper and deeper into the hard, cold earth, subsuming his grief in sweat, denying the pain in his scar. In the darkness, with nothing but the sound of his own breath and the rushing sea to keep him company, the things that had happened at the Malfoys’ returned to him, the things he had heard came back to him, and understanding blossomed in the darkness. . . .<br>The steady rhythm of his arms beat time with his thoughts. Hallows . . . Horcruxes . . . Hallows . . . Horcruxes . . . Yet he no longer burned with that weird, obsessive longing. Loss and fear had snuffed it out: He felt as though he had been slapped awake again.<br>Deeper and deeper Harry sank into the grave, and he knew where Voldemort had been tonight, and whom he had killed in the topmost cell of Nurmengard, and why. . . .<br>And he thought of Wormtail, dead because of one small unconscious impulse of mercy. . . . Dumbledore had foreseen that. . . . How much more had he known?</p><blockquote><p>Another side depiction of Naville’s family.</p></blockquote><p>“Yeah, well, I couldn’t ask people to go through what Michael did, so we dropped those kinds of stunts. But we were still fighting, doing underground stuff, right up until a couple of weeks ago. That’s when they decided there was only one way to stop me, I suppose, and they went for Gran.”<br>“They what?” said Harry, Ron, and Hermione together.<br>“Yeah,” said Neville, panting a little now, because the passage was climbing so steeply, “well, you can see their thinking. It had worked really well, kidnapping kids to force their relatives to behave, I s’pose it was only a matter of time before they did it the other way around. Thing was,” he faced them, and Harry was astonished to see that he was grinning, “they bit off a bit more than they could chew with Gran. Little old witch living alone, they probably thought they didn’t need to send anyone particularly powerful. Anyway,” Neville laughed, “Dawlish is still in St. Mungo’s and Gran’s on the run. She sent me a letter,” he clapped a hand to the breast pocket of his robes, “telling me she was proud of me, that I’m my parents’ son, and to keep it up.” </p><blockquote><p>This little episode shows Ron’s character traits vividly.<br>“Your mother can’t produce food out of thin air,” said Hermione. “No one can. Food is the first of the five Principal Exceptions to Gamp’s Law of Elemental Transfigur —“<br>“Oh, speak English, can”t you?” Ron said, prising a fish bone outfrom between his teeth. </p></blockquote><p>“Yeah, well, food’s one of the five exceptions to Gamp’s Law of Elemental Transfiguration,” said Ron to general astonishment. </p><p>“Why would Harry Potter try to get inside Ravenclaw Tower? Potter belongs in my House!”<br>Beneath the disbelief and anger, Harry heard a little strain of pride in her voice, and affection for Minerva McGonagall gushed up inside him. </p><p>“It’s not a case of what you’ll permit, Minerva McGonagall. Your time’s over. It’s us what’s in charge here now, and you’ll back me up or you’ll pay the price.” And he spat in her face.<br>Harry pulled the Cloak off himself, raised his wand, and said, “You shouldn’t have done that.”<br>As Amycus spun around, Harry shouted, “Crucio!” </p><p>“Potter, I — that was very — very gallant of you — but don’t you realize — ?”</p><p>There was a sound of movement, of clinking glass: Amycus was coming round. Before Harry or Luna could act, Professor McGonagall rose to her feet, pointed her wand at the groggy Death Eater, and said, “Imperio.” </p><p>The aged caretaker had just come hobbling into view, shouting, “Students out of bed! Students in the corridors!”<br>“They’re supposed to be, you blithering idiot!” shouted McGonagall. “Now go and do something constructive! Find Peeves!”</p><blockquote><p>Percy returns to the arms of his family.</p></blockquote><p>“I was a fool!” Percy roared, so loudly that Lupin nearly dropped his photograph. “I was an idiot, I was a pompous prat, I was a — a —“<br>“Ministry-loving, family-disowning, power-hungry moron,” said Fred.<br>Percy swallowed.<br>“Yes, I was!”<br>“Well, you can’t say fairer than that,” said Fred, holding out his hand to Percy.<br>Mrs. Weasley burst into tears. She ran forward, pushed Fred aside, and pulled Percy into a strangling hug, while he patted her on the back, his eyes on his father. </p><p>“Well, we do look to our prefects to take a lead at times such as these,” said George in a good imitation of Percy’s most pompous manner. “Now let’s get upstairs and fight, or all the good Death Eaters’ll be taken.”</p><blockquote><p>“I am not such a coward.”</p></blockquote><p>“Karkaroff’s Mark is becoming darker too. He is panicking, he fears retribution; you know how much help he gave the Ministry after the Dark Lord fell.” Snape looked sideways at Dumbledore’s crooked-nosed profile. “Karkaroff intends to flee if the Mark burns.”<br>“Does he?” said Dumbledore softly, as Fleur Delacour and Roger Davies came giggling in from the grounds. “And are you tempted to join him?”<br>“No,” said Snape, his black eyes on Fleur’s and Roger’s retreating figures. “I am not such a coward.”<br>“No,” agreed Dumbledore. “You are a braver man by far than Igor Karkaroff. You know, I sometimes think we Sort too soon… .”</p><blockquote><p>Snape began to care for his soul. This is a big change of him.</p></blockquote><p>“If you don’t mind dying,” said Snape roughly, “why not let Draco do it?”<br>“That boy’s soul is not yet so damaged,” said Dumbledore. “I would not have it ripped apart on my account.”<br>“And my soul, Dumbledore? Mine?”<br>“You alone know whether it will harm your soul to help an old man avoid pain and humiliation,” said Dumbledore.</p><blockquote><p>This is also a very important conversation. Snape no longer fight only for Lily, but for justice now.</p></blockquote><p>“Don’t be shocked, Severus. How many men and women have you watched die?”<br>“Lately, only those whom I could not save,” said Snape. He stood up. “You have used me.”<br>“Meaning?”<br>“I have spied for you and lied for you, put myself in mortal danger for you. Everything was supposed to be to keep Lily Potter’s son safe. Now you tell me you have been raising him like a pig for slaughter —“<br>“But this is touching, Severus,” said Dumbledore seriously. “Have you grown to care for the boy, after all?”<br>“For him?” shouted Snape. “Expecto Patronum!”<br>From the tip of his wand burst the silver doe: She landed on the office floor, bounded once across the office, and soared out of the window. Dumbledore watched her fly away, and as her silvery glow faded he turned back to Snape, and his eyes were full of tears.<br>“After all this time?”<br>“Always,” said Snape.</p><blockquote><p>There is always something worth giving your life for.</p></blockquote><p>“I am sorry too,” said Lupin. “Sorry I will never know him … but he will know why I died and I hope he will understand. I was trying to make a world in which he could live a happier life.” </p><p>“Would I?” asked Dumbledore heavily. “I am not so sure. I had proven, as a very young man, that power was my weakness and my temptation. It is a curious thing, Harry, but perhaps those who are best suited to power are those who have never sought it. Those who, like you, have leadership thrust upon them, and take up the mantle because they must, and find to their own surprise that they wear it well. </p><p>At last he said, “Grindelwald tried to stop Voldemort going after the wand. He lied, you know, pretended he had never had it.”</p><p>You are the true master of death, because the true master does not seek to run away from Death. He accepts that he must die, and understands that there are far, far worse things in the living world than dying.</p><blockquote><p>Pity the living</p></blockquote><p>“I’ve got to go back, haven’t I?”<br>“That is up to you.”<br>“I’ve got a choice?”<br>“Oh yes.” Dumbledore smiled at him. “We are in King’s Cross, you say? I think that if you decided not to go back, you would be able to … let’s say … board a train.”<br>“And where would it take me?”<br>“On,” said Dumbledore simply.<br>Silence again.<br>“Voldemort’s got the Elder Wand.”<br>“True. Voldemort has the Elder Wand.”<br>“But you want me to go back?”<br>“I think,” said Dumbledore, “that if you choose to return, there is a chance that he may be finished for good. I cannot promise it. But I know this, Harry, that you have less to fear from returning here than he does.”<br>Harry glanced again at the raw-looking thing that trembled and choked in the shadow beneath the distant chair.<br>“Do not pity the dead, Harry. Pity the living, and, above all, those who live without love. By returning, you may ensure that fewer souls are maimed, fewer families are torn apart. If that seems to you a worthy goal, then we say good-bye for the present.” </p><p>“Of course it is happening inside your head, Harry, but why on earth should that mean that it is not real?” </p>]]></content>
    
    
    <summary type="html">&lt;p&gt;While rereading Harry Potter, I found these passages are inspiring and interesting.&lt;/p&gt;</summary>
    
    
    
    
    <category term="文学" scheme="http://www.calvinneo.com/tags/文学/"/>
    
    <category term="读书笔记" scheme="http://www.calvinneo.com/tags/读书笔记/"/>
    
  </entry>
  
  <entry>
    <title>Church 编码</title>
    <link href="http://www.calvinneo.com/2023/04/04/church-encoding/"/>
    <id>http://www.calvinneo.com/2023/04/04/church-encoding/</id>
    <published>2023-04-04T15:20:37.000Z</published>
    <updated>2023-04-10T13:53:40.059Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 Church 编码和 Scott 编码。</p><a id="more"></a><p>邱奇数使用 lambda 构成的高阶函数来描述自然数。事实上邱奇编码可以用来描述一些很基本的结构，例如布尔值、元组、列表和 tagged unions。<br>可以将 0 表示为函数 zero 即 <code>\f x. x</code>。x 是什么并不重要，但我们可以将 f 令为 add1，将 x 令为 0。那么 0 就是 <code>zero(add1, 0) = 0</code>。<br>然后，可以将 1 表示为函数 one 即 <code>\f x. f x</code>。进行代换可以得到 <code>one(add1, 0) = add1(0)</code>。同理，将 2 表示为 <code>\f x. f (f x)</code>。<br>任意一个数 <code>n</code> 可以表示为<code>($) f^n x</code>，我们要想出一个结构实现把 <code>f</code> 执行 <code>n</code> 次，那实际上需要套一个递归的概念。下面来定义这个 Successor 函数 <code>s</code>。<br>递推函数 <code>s</code> 可以求出 <code>n</code> 的 Successor 为 <code>\n f x -&gt; f (($) n f x)</code>。检查类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ghci&gt; :t s</span><br><span class="line">s :: ((t1 -&gt; t2) -&gt; t3 -&gt; t1) -&gt; (t1 -&gt; t2) -&gt; t3 -&gt; t2</span><br></pre></td></tr></table></figure><p>可以理解为 <code>s</code> 是接受一个函数 <code>n</code>，返回另一个和 <code>f</code>/<code>x</code> 有关的函数。不妨简单带入</p><ol><li><code>add1 (($) zero add1 0)</code> 为 1</li><li><code>add1 (($) one add1 0)</code> 为 2</li></ol><p>实现加法函数<code>plus(m, n) = m + n</code>，<code>plus = \m n f x. m f(n f x)</code>。这里用到了性质<code>f^(m+n) x = f^m f^n x</code>。<br>实现乘法函数<code>multi(m, n) = m * n</code>，<code>multi = \m n f x. m (n f) x</code>。相当于将 <code>n f</code> 应用 <code>m</code> 次在 <code>x</code> 上。而 <code>n f</code> 表示 <code>n</code>。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">add1</span> x = x + <span class="number">1</span></span><br><span class="line"><span class="title">shownat</span> n = ($) n add1 <span class="number">0</span></span><br><span class="line"><span class="title">zero</span> = \f x -&gt; x</span><br><span class="line"><span class="title">s</span> = \n f x -&gt; f (($) n f x)</span><br><span class="line"><span class="title">one</span> = s zero</span><br><span class="line"><span class="title">two</span> = s one</span><br><span class="line"><span class="title">three</span> = s two</span><br><span class="line"><span class="title">shownat</span> one</span><br><span class="line"></span><br><span class="line"><span class="title">add</span> n m f x = ($) n f (($) m f x)</span><br><span class="line"><span class="title">multi</span> n m f = n (m f)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ghci&gt; :t zero</span><br><span class="line">zero :: p1 -&gt; p2 -&gt; p2</span><br><span class="line">ghci&gt; :t one</span><br><span class="line">one :: (t1 -&gt; t2) -&gt; t1 -&gt; t2</span><br><span class="line">ghci&gt; :t two</span><br><span class="line">two :: (t3 -&gt; t3) -&gt; t3 -&gt; t3</span><br><span class="line">ghci&gt; :t three</span><br><span class="line">three :: (t3 -&gt; t3) -&gt; t3 -&gt; t3</span><br></pre></td></tr></table></figure><p>下面定义和 bool 量有关的函数。可以看到，true 就是传两个元素选择第一个，false 就是选择第二个。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">true</span> x y = x</span><br><span class="line"><span class="title">false</span> x y = y</span><br><span class="line"><span class="title">showbool</span> b = ($) b <span class="type">True</span> <span class="type">False</span></span><br></pre></td></tr></table></figure><p>容易看出，通过 true 和 false，可以自然而然定义出 if-then-else 语义</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">ifte</span> pred x y = ($) pred x y</span><br></pre></td></tr></table></figure><p>下面定义 pair 结构。不同于一般编程中指定如何构造结构，这里的思路是定义如何去消费这个结构。这里可以传入一个 sel。sel 可以是 fst 和 snd，表示选出 a 或者 b。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">pair</span> a b sel = ($) sel a b</span><br><span class="line"><span class="title">fst</span> p = p true</span><br><span class="line"><span class="title">snd</span> p = p false</span><br><span class="line"><span class="title">shownat</span> (fst (($) pair one two))</span><br></pre></td></tr></table></figure><p>这里有个小问题，写成 <code>pair a b sel = sel $ a b</code> 会有错误</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;interactive&gt;:<span class="number">28</span>:<span class="number">1</span>: error:</span><br><span class="line">    ? <span class="type">Non</span> <span class="class"><span class="keyword">type</span>-variable argument in the constraint: <span class="type">Num</span> (<span class="title">t3</span> -&gt; <span class="title">t3</span>)</span></span><br><span class="line">      (<span class="type">Use</span> <span class="type">FlexibleContexts</span> to permit this)</span><br><span class="line">    ? <span class="type">When</span> checking the inferred <span class="class"><span class="keyword">type</span></span></span><br><span class="line">        it :: <span class="keyword">forall</span> &#123;t3&#125;. <span class="type">Num</span> (t3 -&gt; t3) =&gt; t3 -&gt; t3</span><br></pre></td></tr></table></figure><p>下面定义 pair 上的函数 next。<code>(next (: pair a b))</code> 返回 <code>(: pair (s a) a)</code>，可以理解为 pair 上的 Successor。<br>思路很简单，新构造一个 pair，它的第二个元素是 <code>(fst p)</code>，第一个元素是 <code>s (fst p)</code>&gt;</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">next</span> p = ($) pair (s (fst p)) (fst p)</span><br><span class="line"><span class="title">nn_of_a</span> a = ($) fst (next (($) pair a a))</span><br><span class="line"><span class="title">shownat</span> $ nn_of_a one</span><br></pre></td></tr></table></figure><p>实现减法函数，首先先实现一个 pred 函数。它可以求出 n - 1 是什么。例如 <code>pred two</code> 是 <code>one</code>，但 <code>pred zero</code> 是 <code>zero</code>。这里的方案是从 <code>pair zero zero</code> 开始，调用 n 次 next，就可以得到 <code>(n, n - 1)</code>。使用 snd 返回就行。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">pred</span> n = snd (($) n next (($) pair zero zero))</span><br></pre></td></tr></table></figure><p>减法函数</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">sub</span> m n = ($) m (pred n)</span><br></pre></td></tr></table></figure><p>下面这个函数用来判断 n 是不是 0。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">isZero</span> n = ($) n (\x -&gt; false) true</span><br></pre></td></tr></table></figure><p>不妨进行代入来看看原理</p><ol><li><p>zero</p> <figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">($) (\f x -&gt; x) (\x -&gt; false) true</span><br></pre></td></tr></table></figure><p> 这里的 <code>f</code> 实际上就是 <code>(\x -&gt; false)</code>，而 x 就是 true。所以肯定是 true。</p></li><li><p>one</p> <figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">($) (\f x -&gt; f x) (\x -&gt; false) true</span><br></pre></td></tr></table></figure><p> 这里代入就是 <code>(\x -&gt; false) true</code>，即 false。</p></li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="http://learnyouahaskell.com/" target="_blank" rel="noopener">http://learnyouahaskell.com</a></li><li><a href="https://www.zhihu.com/question/19804597" target="_blank" rel="noopener">https://www.zhihu.com/question/19804597</a><br> Church 编码</li><li><a href="https://faculty.iiit.ac.in/~venkatesh.choppella/popl/current-topics/lambda-calculus-2/index.html" target="_blank" rel="noopener">https://faculty.iiit.ac.in/~venkatesh.choppella/popl/current-topics/lambda-calculus-2/index.html</a><br> Church 编码</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍 Church 编码和 Scott 编码。&lt;/p&gt;</summary>
    
    
    
    
    <category term="lambda" scheme="http://www.calvinneo.com/tags/lambda/"/>
    
    <category term="函数式" scheme="http://www.calvinneo.com/tags/函数式/"/>
    
  </entry>
  
</feed>
