<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Calvin&#39;s Marbles</title>
  
  
  <link href="http://www.calvinneo.com/atom.xml" rel="self"/>
  
  <link href="http://www.calvinneo.com/"/>
  <updated>2025-09-29T17:26:38.283Z</updated>
  <id>http://www.calvinneo.com/</id>
  
  <author>
    <name>Calvin Neo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Zero-Copy 技术</title>
    <link href="http://www.calvinneo.com/2025/09/30/zero-copy/"/>
    <id>http://www.calvinneo.com/2025/09/30/zero-copy/</id>
    <published>2025-09-30T15:07:22.000Z</published>
    <updated>2025-09-29T17:26:38.283Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 Linux 中的零拷贝技术。从 <a href="/2025/03/09/learn-fuse/">Fuse 学习</a> 中独立出来。</p><a id="more"></a><h1 id="read、write-接口"><a href="#read、write-接口" class="headerlink" title="read、write 接口"></a>read、write 接口</h1><p>从普通文件 read，涉及两次复制：</p><ul><li>从磁盘通过 DMA 读到内核的 page cache<br>  这里的 page cache 机制也是一种 kernel buffer，但专门提供给磁盘文件的。</li><li>从内核的 page cache 复制到 user buffer</li></ul><p>从套接口读数据：</p><ul><li>从网卡通过 DMA 直接写入 kernel buffer</li><li>从 kernel buffer 复制到 user buffer</li></ul><p>注意，在使用 DMA 之前，磁盘读出来的数据会放到一个寄存器里面，然后通过中断通知 CPU 把数据写到临时的内存中攒批，最后写到 page cache 中。但是该方式性能太差，早已经淘汰了。</p><p>读数据过程：</p><ul><li>调用 read() 函数陷入内核，第一次 context switch</li><li>DMA 控制器将数据从磁盘拷贝到 kernel buffer，这是第一次 DMA 拷贝</li><li>CPU 将数据从 kernel buffer 复制到 user buffer，这是第一次 CPU 拷贝</li><li>CPU 完成拷贝之后，read() 函数返回到用户态，第二次 context switch</li></ul><p>写过程类似。</p><h1 id="mmap"><a href="#mmap" class="headerlink" title="mmap"></a>mmap</h1><p>把 kernel space 的页映射到 user space，所以可以避免从 kernel space 到 user space 的一次复制。<br>关于 mmap 可以见 <a href="/2025/01/03/memory-context-knowledge/">内存领域知识</a>。</p><h1 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h1><h2 id="原始-sendfile"><a href="#原始-sendfile" class="headerlink" title="原始 sendfile"></a>原始 sendfile</h2><p>sendfile 将数据从磁盘读到内核的 page cache，然后将 page cache 复制到 socket 的 buffer 中。</p><p>它的好处是减少了 syscall 的次数。将 read + write 或者 mmap + write 打包了。<br>但是，仍然需要 2 次 DMA 拷贝和 1 次 CPU 拷贝。</p><h2 id="sendfile-DMA-优化"><a href="#sendfile-DMA-优化" class="headerlink" title="sendfile + DMA 优化"></a>sendfile + DMA 优化</h2><p>将从 page cache 到 socket buffer 的那一次 CPU 拷贝去掉了。DMA 可以直接从 page cache 拷贝数据到网卡里面。</p><h1 id="splice"><a href="#splice" class="headerlink" title="splice"></a>splice</h1>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍 Linux 中的零拷贝技术。从 &lt;a href=&quot;/2025/03/09/learn-fuse/&quot;&gt;Fuse 学习&lt;/a&gt; 中独立出来。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Linux" scheme="http://www.calvinneo.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Our Experience Building a Hybrid Rust - C++ Project</title>
    <link href="http://www.calvinneo.com/2025/07/21/start-new-rust-project/"/>
    <id>http://www.calvinneo.com/2025/07/21/start-new-rust-project/</id>
    <published>2025-07-21T15:07:22.000Z</published>
    <updated>2025-09-22T02:18:33.490Z</updated>
    
    <content type="html"><![CDATA[<p>For the past four months, I’ve been actively contributing to a new Rust-C++ project. Through this process, I’ve gained valuable insights and lessons. While I can’t disclose many project details, there are numerous technical challenges worth elaborating.</p><a id="more"></a><h1 id="The-linking-problem"><a href="#The-linking-problem" class="headerlink" title="The linking problem"></a>The linking problem</h1><h1 id="Thread-or-coroutine"><a href="#Thread-or-coroutine" class="headerlink" title="Thread or coroutine?"></a>Thread or coroutine?</h1><p>Benefits of using coroutine:</p><ul><li>Smaller memory cost, so we can create more coroutines</li><li>Context switch is faster because there is no syscall</li></ul><p>Pitfalls of using tokio:</p><ul><li><code>Runtime</code> can only be created outside the “async context” of tokio. So if we need to use tuned <code>Runtime</code>s, we have to create them in advance. This involves lots of refactors.</li></ul><h1 id="Shared-Memory-or-Actor"><a href="#Shared-Memory-or-Actor" class="headerlink" title="Shared Memory or Actor?"></a>Shared Memory or Actor?</h1>]]></content>
    
    
    <summary type="html">&lt;p&gt;For the past four months, I’ve been actively contributing to a new Rust-C++ project. Through this process, I’ve gained valuable insights and lessons. While I can’t disclose many project details, there are numerous technical challenges worth elaborating.&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
    <category term="Rust" scheme="http://www.calvinneo.com/tags/Rust/"/>
    
    <category term="Articles" scheme="http://www.calvinneo.com/tags/Articles/"/>
    
  </entry>
  
  <entry>
    <title>乒乓球训练纪实</title>
    <link href="http://www.calvinneo.com/2025/06/11/table-tennis/"/>
    <id>http://www.calvinneo.com/2025/06/11/table-tennis/</id>
    <published>2025-06-11T15:07:22.000Z</published>
    <updated>2025-09-29T14:15:18.388Z</updated>
    
    <content type="html"><![CDATA[<p>因为五一节打羽毛球把膝盖打出问题了，现在主要学习乒乓球了</p><a id="more"></a><h1 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h1><p>主要修正了下反手动作。</p><p>这里，我最重要的是不要架肘。打的时候，可以用左手稍微按着一点左边的大臂。<br>然后，乒乓球反手是小臂带动大臂，大臂基本上不用特别发力，而是让小臂画 1/4 的圆弧。<br>在打完之后，需要还原。击球时，击球点不要太到台内，仿佛把整个手都要伸出去一般。<br>击球的是高点期。注意，不要急，而是等球到位之后再打，实际上质量更好。<br>当球落点朝着左边或者右边偏斜的时候，可以考虑靠只移动上半身来接。<br>作为初学者，不需要手腕有特别大的扭转。</p><p>-&gt; 初学者，可以采用下蹲马步，然后再站起来这样。但是最终，是要一直处于一种扎马步的状态，主要是前脚掌着地。然后用一些垫步还是啥的完成重心转换。</p><h1 id="Day-2"><a href="#Day-2" class="headerlink" title="Day 2"></a>Day 2</h1><p>主要纠正了下正手动作。</p><p>我正手有几点问题：</p><ul><li>撅手腕，教练说撅着手腕可能是因为击打点太靠前，以至于要“等球：</li><li>大臂架着</li><li>大臂还喜欢架着往后拉，实际上应该是转腰，而不是动大臂</li><li>握拍应该虎口直接对着拍子的“侧棱”，类似于羽毛球一样，我可能会喜欢转一点</li></ul><h1 id="Day-3"><a href="#Day-3" class="headerlink" title="Day 3"></a>Day 3</h1><p>继续是正手和反手的练习，下雨，只有 1.5h。</p><p>提到了一些细节：</p><ul><li>反手可以尝试蹲起，然后站立这种击打方式</li></ul><p>录制了一些视频，视频中可以发现，还是喜欢撅着手腕。</p><h1 id="Day-4"><a href="#Day-4" class="headerlink" title="Day 4"></a>Day 4</h1><p>继续是正手和反手的练习，有事，只有 1.5h。</p><h1 id="Aug-21"><a href="#Aug-21" class="headerlink" title="Aug 21"></a>Aug 21</h1><h1 id="Sept-12"><a href="#Sept-12" class="headerlink" title="Sept 12"></a>Sept 12</h1><h1 id="Sept-19"><a href="#Sept-19" class="headerlink" title="Sept 19"></a>Sept 19</h1><p>因为重新看了下医生，说暂时不要运动，因此这次就练了下搓球。</p><p>搓球的话主要几点：</p><ul><li>腿要伸进去</li><li>重心一定要压低压低！可以感受到脸要贴着桌子的感觉</li><li>击球点要低，基本上是二跳要落下，就要完蛋的那个时候搓。但尽管如此，人是要先上去的，所以这里有一个停顿</li></ul><h1 id="Sept-26"><a href="#Sept-26" class="headerlink" title="Sept 26"></a>Sept 26</h1><p>本周停止</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;因为五一节打羽毛球把膝盖打出问题了，现在主要学习乒乓球了&lt;/p&gt;</summary>
    
    
    
    
    <category term="运动" scheme="http://www.calvinneo.com/tags/运动/"/>
    
  </entry>
  
  <entry>
    <title>关西2</title>
    <link href="http://www.calvinneo.com/2025/04/08/kensai-2/"/>
    <id>http://www.calvinneo.com/2025/04/08/kensai-2/</id>
    <published>2025-04-08T12:06:11.000Z</published>
    <updated>2025-04-12T08:20:49.168Z</updated>
    
    <content type="html"><![CDATA[<p>趁着清明节又去了一趟关西。本以为是度假，但实际上累得要死。</p><a id="more"></a><h1 id="D1"><a href="#D1" class="headerlink" title="D1"></a>D1</h1><p>这一次从南京直飞大阪。机票照例没有提前多久定，但是两个人往返也才 4k 出头，相当便宜。宾馆就是贵的离谱了。京都的宾馆单人 1.5k，双人接近 4k 感觉简直在抢钱。我先在大阪定了 2 天 700 左右的。然后又订了一天姬路和大阪的。然后最后一天住哪不清楚，大概先这样。</p><p>关西机场入国变得麻烦多了，这次虽然没有坐小火车（吉祥航空），但入关排队感觉就花了将近一个小时了。在飞机上被发了入境单要填，我觉得挺麻烦的，现在都是电子化了啊。结果到了入境口发现有 abcd 四个 route，但完全不知道区别是什么。一个国际机场居然没有英文的说明，工作人员也只说日语和简单的英语。Anyway，他有个扫描护照的机器，感觉挺方便的。我用机器扫完，然后就再往前排队等人工。走到一半发现大家还有个 QR code 也不知道是啥，但是这些人扫完 QR 之后又要填一遍纸单子。。。</p><p>反正轮到我我就说 I have no QA code but I’ve already finished the note, and I’ve already registered on that machine. 然后那人把我的纸收了就直接贴入境单了，很丝滑很快。这次不去京都，就直接走南海电车了，更便宜。坐到 namba 才 900。</p><p>吃完饭，就去附近的 apple 店买个表。现在日本的 apple 店居然不能退税了，只有部分非官方 retailer 可以退税，但是我又不知道哪里靠谱。46mm 的要 3200，国内才 2600。但是因为国内啥啥都没，没快充慢的一批，所以还是买了。总不能为这个专门跑一次 hk 吧。</p><p>去 711 给交通卡充值，发现只能用现金。幸亏我带了 15000 jpy 来，本意是上次玩没用掉，这次结果救了命。</p><p>晚上出去吃饭回来，发现大阪真的冷，幸亏穿了两件，不然真的冻死。</p><p>回来发现日本的窗子真的好隔音，薄薄的平开窗，毫无特点的铝合金，居然这么猛。</p><h1 id="D2-京都"><a href="#D2-京都" class="headerlink" title="D2 京都"></a>D2 京都</h1><p>因为地铁卡充值要现金感觉不方便，所以我今天就打算不用地铁卡，用 iPhone Wallet 了。这鬼东西又不能用信用卡，我弄了半天才弄了个储蓄卡上去。上地铁又刷坏了，墨迹了半天。到了大阪梅田站，她出不了站，刷了半天不知道怎么就出去了。结果到了 JR 大阪站发现进不去，问工作人员说这个是 osaka subway，我觉得很奇怪，因为 icoca 是通用的，工作人员也说我的 iPhone 是可以的。于是我觉得肯定是被锁了。无论如何，这里可以支付宝买纸票，于是我们就去京都了。</p><p>京都的公交车排队排了感觉有半个多小时，后面上了个临时的加班车。这边还不让带行李上公交车，幸亏我们都放在了大阪，就带了个小包。公交车里面非常拥挤，但我们进去的早，所以有个位置。公交车开的特别慢，感觉甚至不如走路。开到清水寺附近感觉花了大概二十多分钟。我们试图在五年阪下车，结果被堵住了，然后司机就不让我们下了。然后后面一个傻逼老外就说 you come here late, you have to follow their rules, it’s not your country 啥的。非常 offensive。</p><p>清水寺我们没进去，我对象说没啥意思，我之前去过，感觉也没啥意思，人还特别多。门口的御守他也觉得贼丑。然后我们就顺着三年半二年阪往下走，去找法观寺。我们都已经看到高台寺公园了，发现法观寺走过了，有绕回去找。结果法观寺就是我们来的路上的那个我觉得一般的唐代风格的塔，好像是京都的最老的塔，也不让进去。然后我们又走回到高台寺。</p><p>高台寺的垂樱是挺好看的。</p><p>高台寺出来很快就到了八阪神社，里面和好吃街一样，我们找了下垂樱在哪里，就去吃那个鳗鱼饭了。</p><p>鳗鱼饭吃完出来，就在木屋町那条小路那边拍樱花，感觉比鸭川的樱花好看。</p><p>然后又绕回去看了下花见小路，照旧非常无聊。路尽头是什么建仁寺的，大家都没有兴趣看。</p><p>然后又走了一大段路去看顶法寺。顶法寺不要钱，里面的樱花很漂亮。还有几个小和尚的雕塑也很有意思。</p><p>晚上实在走不动了，就坐了京阪电车，因为阪急还要多走 300m。至于京都 JR，因为坐公交体验太差，完全不考虑了。我们坐的是 18.59 的京阪电车去的大阪。其实以后真的可以坐京阪电车到京都东边，比 JR 方便很多，还便宜。但这次京阪电车属实是个坑货。它终点站在大阪是 yodoyabashi 淀屋桥，但是又有一些车是到一个叫 yodo 淀的地方。然后我就被这个车丢在了 yodo。后面上了个准急的，几乎就是站站乐了，感觉总共花了大概一个多小时才到大阪。</p><p>回到大阪，找大阪地铁说明了情况，列车长问我们要不要 refund。我说不要，他就说 OK。然后就解锁了，结果发现之前坐的 namba 的南海的钱居然也没被扣。南海真的血亏啊。</p><h1 id="D3-姬路"><a href="#D3-姬路" class="headerlink" title="D3 姬路"></a>D3 姬路</h1><p>起来去姬路。这次发现他们电车同一个方向有两个轨道，一边是 local 一边是 express。上车前可以看站台上的屏幕，上车时可以看车的屏幕确认。上车前可以看 Google 或者 Apple 的 map 到达的时间确定自己是不是对应班次的车。上车后也可以听播报。基本上 Rapid、Express 的车都比较推荐，大阪、神户市区的大站基本都停。Limited Express 特急要特价券我没见过。</p><p>姬路是个小城市，我们的酒店在车站南边一点。应该是此行中比较大的酒店了。酒店不能提前办理入住，但是可以预先寄存。</p><p>姬路站北面正对姬路城，通过一个大道可以直接走过去。大道两侧不少店铺比较出名，我们吃了个咖啡，然后就立即前往姬路城了。</p><p>城里面樱花很漂亮，右边走还有个动物园。登城口在左边，要排队，但是队伍很快，等了大概半小时就进去了。买票 +50 yen 就能得到一个旁边的花园的门票。花园里面有个餐厅，我们去的时候已经关门了。姬路城主要就是两块，一个是西之丸庭院，可以脱掉鞋子登上去，类似于一个走廊，有多个城橹。从化妆橹可以下来，据说这个是给城主夫人化妆用的地方。西之丸庭院相比大阪城比较小巧，里面也有不少樱花。</p><p>从庭院出来就可以走到天守的口了。然后就是穿过一道道什么 yi 之门、wa 之门、ni 之门，然后走到天守的下面的小庭院内。然后就走过水之 X 门走到大天守里面。大天守有 6 层，第 2 层开始大排长队，人贼多。</p><h1 id="D4-神户"><a href="#D4-神户" class="headerlink" title="D4 神户"></a>D4 神户</h1><p>神户的酒店在三宫门口，应该是本次我找的最近、最便宜的酒店了，才 500。住宿体验很舒适。</p><p>放完东西，去神户动物园。我们应该是顶门到的，进去刷票的时候，我对象把票根掉了，检票员说必须要把票找回来。</p><p>在那个破落商店里面有一家后来知道叫 Yellow Submarine 的桌游超市，还挺大的。回来我去问了下有没有那个骰子游戏，他带我去找，然后翻了下，说 sold out 了。我以为附近南京町还有一家，走过去发现那是个别的地方，已经关门了。</p><h1 id="D5-奈良-大阪"><a href="#D5-奈良-大阪" class="headerlink" title="D5 奈良 - 大阪"></a>D5 奈良 - 大阪</h1><p>下了奈良站，在 5 号口附近找到一个柜子，600 yen 就可以放两个小箱子和一个包了。不过只接受 100 yen 的硬币，我还要去旁边换。</p><p>出去吃了那个口水麻薯，一堆老外在那边拍照。去看了兴福寺，要钱，没意思没进去。兴福寺下来就能看到鹿，鹿很现实，看到我们没买饼就不磕头了。我们到最后也没买，主打白嫖。</p><p>旁边的奈良博物馆关门了。</p><p>我印象里上次去若草山有个大坡可以坐着休息，但这次去好像就是一些大草坪可以走，有椅子可以坐。大草坪也许是封起来了吧，因为当时看到大草坪上没有人，而且往若草山方向有被拦住。</p><p>在大阪这最后一晚住的酒店是最拉胯的。</p><h1 id="D6-大阪"><a href="#D6-大阪" class="headerlink" title="D6 大阪"></a>D6 大阪</h1>]]></content>
    
    
    <summary type="html">&lt;p&gt;趁着清明节又去了一趟关西。本以为是度假，但实际上累得要死。&lt;/p&gt;</summary>
    
    
    
    
    <category term="游记" scheme="http://www.calvinneo.com/tags/游记/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 7</title>
    <link href="http://www.calvinneo.com/2025/03/15/database-paper-7/"/>
    <id>http://www.calvinneo.com/2025/03/15/database-paper-7/</id>
    <published>2025-03-15T13:33:22.000Z</published>
    <updated>2025-03-15T14:00:06.214Z</updated>
    
    <content type="html"><![CDATA[<p>包含：</p><ul><li>We Ain’t Afraid of No File Fragmentation: Causes and Prevention of Its Performance Impact on Modern Flash SSDs</li></ul><a id="more"></a><h1 id="We-Ain’t-Afraid-of-No-File-Fragmentation-Causes-and-Prevention-of-Its-Performance-Impact-on-Modern-Flash-SSDs"><a href="#We-Ain’t-Afraid-of-No-File-Fragmentation-Causes-and-Prevention-of-Its-Performance-Impact-on-Modern-Flash-SSDs" class="headerlink" title="We Ain’t Afraid of No File Fragmentation: Causes and Prevention of Its Performance Impact on Modern Flash SSDs"></a>We Ain’t Afraid of No File Fragmentation: Causes and Prevention of Its Performance Impact on Modern Flash SSDs</h1><p><a href="https://www.usenix.org/system/files/fast24-jun.pdf" target="_blank" rel="noopener">https://www.usenix.org/system/files/fast24-jun.pdf</a></p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><blockquote><p>The primary cause of the degraded performance is <strong>not due to request splitting</strong> but stems from a significant increase in <strong>die-level collisions</strong>.</p></blockquote><p>如果在写连续的 file block 中，有其他的写入过来，那么这些 file block 就不会在连续的 die 上，从而产生 random die allocation。这种情况比如发生在 file overwrite 的时候。</p><blockquote><p>In SSDs, when other writes come between writes of neighboring file blocks, the file blocks are not placed on consecutive dies, resulting in random die allocation. This randomness escalates the chances of die-level collisions, causing deteriorated read performance later. We also reveal that this may happen when a file is overwritten.</p></blockquote><p>Evaluations with commercial SSDs and an SSD emulator indicate that our approach effectively curtails the read performance drop arising from both fragmentation and overwrites, all without the need for defragmentation. Representatively, when a 162 MB SQLite database was fragmented into 10,011 pieces, our approach limited the performance drop to 3.5%, while the conventional system experienced a 40% decline.</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>To prevent performance degradation caused by fragmentation, file systems utilize various techniques [35], such as delayed allocation [23] and preallocation of data blocks [2], to maintain continuity among data blocks. </p><p>SSD 中没有磁头的物理移动，所以减少了顺序读和随机读之间的性能 gap。但 [4] 中说，SSD 上读 fragmented 的文件，也有 2-5 倍的性能损失。诸如 [13, 31, 42] 的文件只是认为这些性能损失的原因是 request splitting in the kernel I/O path due to fragmentation。</p><p>这篇文章指出 fragmentation 导致的性能损失实际上根因是 die-level collisions。而 die-level collisions 会减少 SSD 内部的并发度。</p><blockquote><p><strong>An SSD’s firmware allocates its flash memory pages in a round-robin manner across the flash memory dies based on the order in which they are written.</strong></p></blockquote><p>所以，如果发生了 fragmentation，那么 the pages storing contiguous file blocks 不能被放置在 contiguous dies 上，而是被分配在任意的 dies 上。</p><p>这个论文修改了 nvme 的协议，让 write 命令指定 page-to-die mapping。</p><blockquote><p>With these hints, the page for an appending write is mapped to the die following the die where the previous file block’s page was assigned to. In addition, the page for an overwrite operation to an existing file block, which also disrupts the page-to-die mapping pattern, is mapped to the same die where the original page was located.</p></blockquote><h2 id="Background-and-Motivation"><a href="#Background-and-Motivation" class="headerlink" title="Background and Motivation"></a>Background and Motivation</h2><h3 id="Old-Wisdom-on-File-Fragmentation"><a href="#Old-Wisdom-on-File-Fragmentation" class="headerlink" title="Old Wisdom on File Fragmentation"></a>Old Wisdom on File Fragmentation</h3><blockquote><p>In the HDD era, the primary and direct cause of performance degradation from file fragmentation was <strong>the seek time</strong> between dispersed sectors of the file.</p></blockquote><p>Fragmentation 对读取的影响更大，因为读取必须要等待完成，而写入则可以被 buffer。</p><p>Fragmentation 在三个层面影响性能：</p><ul><li>kernel I/O path<br>  Only a single command is required for the host to instruct the storage device to perform read or write operations on contiguous storage space.<br>  Thus, when a sequential read occurs for a file, the Linux kernel reads the data block mapping in the file’s inode, and for each contiguous data block region, it creates a bio (block I/O) data structure. This data structure is used to create the corresponding request data structure to be passed to the device driver, which then issues the command for the request to the device.<br>  Through this process, a single sequential file access may be <strong>split into multiple <code>bio</code>s</strong> and corresponding requests to the storage device, depending on the degree of file fragmentation.</li><li>storage device interface<br>  This request splitting is known to increase I/O execution time, as it increases the number of data structure creations and calls to underlying functions, including the device driver code.<br>  Specifically, the frequency of fetching, decoding, translating commands into storage media operations, and queuing media access operations increases. Therefore, file fragmentation also delays the processing time of the storage device controller.</li><li>storage media access</li></ul><p><img src="/img/dbpaper/ssd-die-collision/1.png"></p><p>ext4 为了减少 fragment 产生的优化：</p><ul><li>The <strong>delayed allocation</strong> technique used in the <strong>ext4</strong> file system performs data block allocation not at the write system call handling but <strong>at the time of page flush</strong>.</li><li>In addition, ext4 reserves a predefined window of free data blocks for each file’s inode. These reserved free blocks will be actually allocated to the file for its successive append writes.</li></ul><p>defragmentation 的手段：</p><ul><li>【Sato】Allocates contiguous free blocks to a temporary inode, copies the fragmented file data to the temporary inode, deletes the original file, and renames the temporary inode to the original’s.</li></ul><h3 id="File-Fragmentation-in-SSD-Era"><a href="#File-Fragmentation-in-SSD-Era" class="headerlink" title="File Fragmentation in SSD-Era"></a>File Fragmentation in SSD-Era</h3><p>很多学者和厂商说 SSD 不受 fragmentation 的影响，defragmentation 反而可能会损害 SSD 的寿命。</p><p>SSDs offer significantly higher performance than a single flash memory die (chip) because they operate multiple flash dies in parallel. </p><p>NVMe 有 65535 个命令队列，每个队列能 queue 65535 个 commands。总共 65535 的平方，可以说非常大了。</p><blockquote><p>Specifically, NVMe SSDs offer 65,535 command queues, each capable of queueing 65,536 commands.</p></blockquote><blockquote><p>Even when fragmentation leads to smaller request sizes that cannot fully utilize die-level parallelism, smaller flash operations in the command queues can still be processed out-of-order, allowing most dies to be fully utilized.</p></blockquote><p>因此，很多学者认为 kernel I/O path 和 storage device interface 中的 request splitting 是影响性能的关键。</p><h3 id="Internals-of-Modern-Flash-SSDs"><a href="#Internals-of-Modern-Flash-SSDs" class="headerlink" title="Internals of Modern Flash SSDs"></a>Internals of Modern Flash SSDs</h3><blockquote><p>a die can only process one request at a time.</p></blockquote><p>FTL 会将需要写入的 page 存储到尽可能多的 die 中。</p><blockquote><p>To prevent die-level collisions for read operations, the flash translation layer (FTL) of an SSD’s firmware must perform physical page allocation in a manner that distributes the physical pages storing contiguous logical pages across as many dies as possible.</p></blockquote><p>所以，是 rr 地选择 die，而不是一股脑全写到一个 die 里面。</p><blockquote><p>For this purpose, the FTL of most modern SSDs selects a die in a round-robin manner when allocating a flash page for processing an incoming page write request.</p></blockquote><blockquote><p>Additionally, modern FTLs perform the valid page copy within the die where the page resides during the garbage collection (GC) process if the die has a sufficient number of free pages.</p></blockquote><p>For example, in Fig. 2, File A is evenly distributed across four dies since its four pages were written without interference. Thus, a sequential read of File A will be performed simultaneously on these four dies, resulting in a bandwidth of up to four times the flash die performance. </p><p>In contrast, assume that the writes to File B and File C were interleaved. As the die for storing a logical page is assigned in a round-robin manner according to the order of writes performed within the SSD, both the third and last pages of File B ended up being allocated to Die 3. As a result, the time to read File B is twice as long as that for reading an ideally-placed file of the same size, such as File A.</p><p><img src="/img/dbpaper/ssd-die-collision/2.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We Ain’t Afraid of No File Fragmentation: Causes and Prevention of Its Performance Impact on Modern Flash SSDs&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>法语学习纪要</title>
    <link href="http://www.calvinneo.com/2025/03/13/french/"/>
    <id>http://www.calvinneo.com/2025/03/13/french/</id>
    <published>2025-03-13T15:09:06.000Z</published>
    <updated>2025-09-29T16:49:02.536Z</updated>
    
    <content type="html"><![CDATA[<p>在小绿鸟上学法语。</p><a id="more"></a><h1 id="常见变位"><a href="#常见变位" class="headerlink" title="常见变位"></a>常见变位</h1><ul><li>aller：去<ul><li>je vais</li><li>tu vas</li><li>il/elle va</li><li>nous allons</li><li>vous allez</li><li>ils/elles vont</li></ul></li><li>avoir：有<ul><li>j’ai</li><li>tu as</li><li>il/elle a</li><li>nous avons</li><li>vous avez</li><li>ils/elles ont</li></ul></li><li>être：是<ul><li>je suis</li><li>tu es</li><li>il/elle est</li><li>nous sommes</li><li>vous êtes</li><li>ils/elles sont</li></ul></li><li>venir：来<ul><li>je viens</li><li>tu viens</li><li>il/elle vient</li><li>nous venons</li><li>vous venez</li><li>ils/elles viennent</li></ul></li><li>faire：做<ul><li>je fais</li><li>tu fais</li><li>il/elle fait</li><li>nous faisons</li><li>vous faites</li><li>ils/elles font</li></ul></li><li>falloir：必须，这是个绝对无人称动词<ul><li>il faut</li></ul></li><li>devoir：必须<ul><li>je dois</li><li>tu dois</li><li>il/elle doit</li><li>nous devons</li><li>vous devez</li><li>ils/elles doivent</li></ul></li></ul><ul><li>aimer：喜欢<ul><li>j’aime</li><li>tu aimes</li><li>il/elle aime</li><li>nous aimons</li><li>vous aimez</li><li>ils/elles aiment</li></ul></li><li>parler: 说<ul><li>je parle</li><li>tu parles</li><li>il/elle parle</li><li>nous parlons</li><li>vous parlez</li><li>ils/elles parlent</li></ul></li><li>prendre：take<ul><li>je prends</li><li>tu prends</li><li>il/elle prend</li><li>nous prenons</li><li>vous prenez</li><li>ils/elles prennent</li></ul></li><li>sortir：出<ul><li>je sors</li><li>tu sors</li><li>il/elle sort</li><li>nous sortons</li><li>vous sortez</li><li>ils/elles sortent</li></ul></li><li>rentrer：come back in<ul><li>je rentre</li><li>tu rentres</li><li>il/elle rentre</li><li>nous rentrons</li><li>vous rentrez</li><li>ils/elles rentrent</li></ul></li><li>écouter：听<ul><li>j’écoute</li><li>tu écoutes</li><li>il/elle écoute</li><li>nous écoutons</li><li>vous écoutez</li><li>ils/elles écoutent</li></ul></li><li>lire：读<ul><li>je lis</li><li>tu lis</li><li>il/elle lit</li><li>nous lisons</li><li>vous lisez</li><li>ils/elles lisent</li></ul></li><li>ecris：写<ul><li>j’écris</li><li>tu écris</li><li>il/elle écrit</li><li>nous écrivons</li><li>vous écrivez</li><li>ils/elles écrivent</li></ul></li></ul><ul><li>paye：付费<ul><li>je paye</li><li>tu payes</li><li>il/elle paye</li><li>nous payons</li><li>vous payez</li><li>ils/elles payent</li></ul></li><li>finir:<ul><li>je finis</li><li>tu finis</li><li>il/elle finit</li><li>nous finissons</li><li>vous finissez</li><li>ils/elles finissent</li></ul></li><li>courir：跑<ul><li>je cours</li><li>tu cours</li><li>il/elle court</li><li>nous courons</li><li>vous courez</li><li>ils/elles courent</li></ul></li></ul><h1 id="人称代词"><a href="#人称代词" class="headerlink" title="人称代词"></a>人称代词</h1><p>重读人称代词：</p><ul><li>在 C’est 后作表语<br>  C’est moi.</li><li>在介词之后<br>  Je suis avec toi.</li><li>用于表强调</li><li>命令式<br>  Regarde-toi.</li></ul><ul><li>第一人称单数<ul><li>je</li><li>所有格的阳性 mon</li><li>所有格的阴性 ma</li><li>所有格的复数 mes</li><li>间接宾语 me</li><li>重读 moi</li></ul></li><li>第二人称单数<ul><li>tu</li><li>所有格的阳性 ton</li><li>所有格的阴性 ta</li><li>所有格的复数 tes</li><li>间接宾语 te</li><li>重读 toi</li></ul></li><li>第三人称单数<ul><li>il/elle</li><li>所有格的阳性 son</li><li>所有格的阴性 sa</li><li>所有格的复数 ses</li><li>间接宾语 lui</li><li>重读 lui/elle</li></ul></li><li>第一人称复数<ul><li>nous</li><li>所有格单数 notre</li><li>所有格复数 nos</li><li>间接宾语 nous</li><li>重读 nous</li></ul></li><li>第二人称复数<ul><li>vous</li><li>所有格单数 votre</li><li>所有格复数 vos</li><li>间接宾语 vous</li><li>重读 vous</li></ul></li><li>第三人称复数<ul><li>ils/elles</li><li>所有格单数 leur</li><li>所有格复数 leurs</li><li>间接宾语 leur</li><li>eux/elles</li></ul></li><li>泛指代词<ul><li>on</li><li>重读 soi</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://www.collinsdictionary.com/zh/conjugation/french-conjugation/aller" target="_blank" rel="noopener">https://www.collinsdictionary.com/zh/conjugation/french-conjugation/aller</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;在小绿鸟上学法语。&lt;/p&gt;</summary>
    
    
    
    
    <category term="法语" scheme="http://www.calvinneo.com/tags/法语/"/>
    
  </entry>
  
  <entry>
    <title>Fuse 学习</title>
    <link href="http://www.calvinneo.com/2025/03/09/learn-fuse/"/>
    <id>http://www.calvinneo.com/2025/03/09/learn-fuse/</id>
    <published>2025-03-09T14:48:32.000Z</published>
    <updated>2025-09-29T17:06:29.217Z</updated>
    
    <content type="html"><![CDATA[<p>看下 FUSE 的相关知识。</p><p>Filesystem In Userspace 也就是 fuse，是 linux 的一个内核模块。</p><a id="more"></a><p>Fuse 的优势在于：</p><ul><li>允许非管理员权限去 mount 一个文件系统，例如 overlayfs</li><li>允许不通过内核实现一个文件系统</li></ul><p>但是 Fuse 并不是在用户态访问文件系统，在调用文件系统时，依然需要陷入内核访问 VFS，并通过内核完成 IO。Fuse 在用户态做的是将内核传递的 fuse request 处理，并调用 VFS。</p><h1 id="To-FUSE-or-not-to-FUSE-Analysis-and-Performance-Characterization-of-the-FUSE-User-Space-File-System-Framework"><a href="#To-FUSE-or-not-to-FUSE-Analysis-and-Performance-Characterization-of-the-FUSE-User-Space-File-System-Framework" class="headerlink" title="To FUSE or not to FUSE - Analysis and Performance Characterization of the FUSE User-Space File System Framework"></a>To FUSE or not to FUSE - Analysis and Performance Characterization of the FUSE User-Space File System Framework</h1><h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><p>fuse 的内核部分是 fuse.ko，会注册三个文件系统的类型：fuse、fuseblk、fusectl，它们在 /proc/filesystems 中都可见。fuse 类型的文件系统并不需要下层的块设备，而 fuseblk 类型的文件系统则需要。</p><p><code>fuseblk</code> provides following features:</p><ol><li>Locking the block device on mount and unlocking on release;</li><li>Sharing the file system for multiple mounts;</li><li>Allowing swap files to bypass the file system in accessing the underlying device;</li></ol><p>fuse 和 fuseblk 都是一些不同的 FUSE 文件系统的 proxy，所以后面统称为 FUSE。</p><p>几点说明：</p><ul><li>FUSE 文件系统的名字一般是 <code>[fuse|fusectl].$NAME</code>。</li><li>/dev/fuse 是一个块设备，被用来支持用户态的 FUSE daemon 和内核之间的通信。简单来说，用户态的 daemon 会从 /dev/fuse 中读出请求，进行处理，然后再写回到 /dev/fuse 中。</li></ul><p>这个经典的图，是 FUSE 的链路<br><img src="/img/dbpaper/fuse/fuseornot/2.1.png"></p><blockquote><p>When a user application performs some operation on a mounted FUSE file system, the VFS routes the operation to FUSE’s kernel (file system) driver. The driver allocates a FUSE request structure and puts it in a FUSE queue. At this point, the<br>process that submitted the operation is usually put in a wait state.<br>FUSE’s user-level daemon then picks the request from the kernel queue by reading from <code>/dev/fuse</code> and processes the request. Processing the request might require <strong>re-entering</strong> the kernel again: for example, in case of a stackable FUSE file system, the daemon submits operations to the underlying file system (e.g., Ext4); or in case of a block-based FUSE file system, the daemon reads or writes from the block device; and in case of a network or in-memory file system, the FUSE daemon might still need to re-enter the kernel to obtain certain system services (e.g., create a socket or get the time of day).<br>When done with processing the request, the FUSE daemon writes the response back to <code>/dev/fuse</code>; FUSE’s kernel driver then marks the request as completed, and wakes up the original user process which submitted the request.</p></blockquote><p>一些文件系统的操作并不需要和用户态的 FUSE daemon 交流，就可以完成。例如，读一个之前读过的文件，因为它的 page 已经被存在 page cache 里面了，所以就不需要再把请求 forward 给 FUSE driver 了。这里可能被 cache 的不仅包括 data，还包括一些 meta data。例如 stat 查询 inode 和 dentry 的信息，它们被存在 Linux 的 dcache 中，可以直接在内核态处理，而不需要调用 FUSE daemon 了。</p><p><img src="/img/dbpaper/fuse/fuseornot/t2.1.png"></p><h3 id="2-2-User-Kernel-Protocol"><a href="#2-2-User-Kernel-Protocol" class="headerlink" title="2.2 User-Kernel Protocol"></a>2.2 User-Kernel Protocol</h3><h3 id="2-3-Library-and-API-Levels"><a href="#2-3-Library-and-API-Levels" class="headerlink" title="2.3 Library and API Levels"></a>2.3 Library and API Levels</h3><p>High-level 的 API 允许开发者跳过 path-to-inode 映射。或者说 inode 在 high level API 中根本不存在了，high level API 只操作路径。FORGET inode method 根本就不需要了。</p><p>无论是 high 还是 low level，反正大概都是要实现 42 个方法。</p><p><img src="/img/dbpaper/fuse/fuseornot/2.2.png"></p><h3 id="2-4-Queues"><a href="#2-4-Queues" class="headerlink" title="2.4 Queues"></a>2.4 Queues</h3><p>一个请求在同一时间只能属于下面五个队列的其中一个。</p><p><img src="/img/dbpaper/fuse/fuseornot/2.3.png"></p><p>FORGET requests are sent when the inode is evicted, and these requests are would queue up together with regular file system requests, if a separate forgets queue did not exist. 如果有大量的 FORGET 请求，就无法处理其他的文件系统请求了。这个行为是在一个有 3200 万的 inode 节点上看到的，当所有的 inode 被从 icache evict 的时候，系统可能会 hang 大概 30min。</p><p>pending queue 中是同步请求。</p><p>当 daemon 从 /dev/fuse 中读取时，会以下面的顺序：</p><ul><li>最高优先级会处理 Interrupts 队列中的请求</li><li>FORGET 和非 FORGET 请求会被公平地选择，处理完 8 个非 FORGET 请求，会再处理 16 个 FORGET 请求。这也保障了 FORGET 请求不会堆积起来。</li></ul><p>请求处理的流程是：</p><ul><li>pending queue 中最老的请求会被传送到 user space，然后被 processing queue 立即处理。<br>  INTERRUPT 和 FORGET 队列并不会从 user daemon 获得回复，所以当 daemon 读取这些请求的时候，它们就终止了。</li><li>如果 pending queue 上没有请求，那么 FUSE daemon 就会阻塞在一个 read 调用上。</li><li>如果 daemon 回复了，对应的请求就会被从 processing queue 中被移除，这个请求就完成了。同时，blocked user processes (e.g., the ones waiting for READ to complete) are notified that they can proceed.</li></ul><p>background queue 是对异步请求的。默认情况下，只有读是异步的，因为可以 read ahead。如果开启 writeback cache，则 write 也会走到 background queue 中。开启 writeback cache 后，从 user process 来的 write 会先聚集在 page cache 中，然后 bdflush 线程会醒来，去刷脏页。</p><p>background queue 中的请求会一点点汇到 pending queue 中，在 pending queue 中的异步请求的数量是根据 max_background 参数（默认 12）来调整的。目的是：</p><ul><li>避免异步请求影响同步请求</li><li>开启 multi-threaded 选项后，限制 user daemon 线程的数量</li></ul><h3 id="2-5-Splicing-and-FUSE-Buffers"><a href="#2-5-Splicing-and-FUSE-Buffers" class="headerlink" title="2.5 Splicing and FUSE Buffers"></a>2.5 Splicing and FUSE Buffers</h3><p>FUSE 使用了 Linux 内核的 splicing 技术，目的是为了避免 read 和 write 请求在内核和用户态之间复制大量内存。splice() 系列的系统调用可以在用户在，在两个 in-kernel memory buffer 之间传递数据，这样就不需要到用户态拷贝一次了。</p><blockquote><p>例如 sendfile、mmap、splice 都是 Linux 中的零拷贝技术，主要是消除一些不需要的拷贝</p></blockquote><p>FUSE 将它的 buffer 表示为任意一种形式：</p><ul><li>The regular memory region identified by a pointer in the user daemon’s address space, or</li><li>The kernel-space memory pointed by a file descriptor of a pipe where the data resides.</li></ul><p>If a user-space file system implements the <code>write_buf()</code> method (in the low-level API), then FUSE first splices the data from <code>/dev/fuse</code> to a Linux pipe and then passes the data directly to this method as a buffer containing a file descriptor of the pipe. FUSE splices only WRITE requests and only the ones that contain more than a single page of data.</p><blockquote><p>注意，为了实现这个特性，FUSE 就需要使用普通的 read 调用去读取那个 pipe 的 fd，所以这里肯定会存在 memory copy。即</p></blockquote><p>However, the header of every single request needs to be examined, for example to identify the request’s type and size. This examination is not possible if the FUSE buffer has only the file descriptor of a pipe where the data resides. So, for every request the header is then read from the pipe using regular read() calls (i.e., small, at most 80 bytes, memory copying is always perfomed). FUSE then splices the requested data if its size is larger than a single page (excluding the header): therefore only big writes are spliced. For reads, replies larger than two pages are spliced.</p><p>Similar logic applies to the replies to READ requests if the <code>read_buf()</code> method is implemented. However, the <code>read_buf()</code> method is only present in the high-level API; for the low-level API, the file-system developer has to differentiate between splice and non-splice flows inside the read method itself.</p><p>【Q】为什么这里读会让开发者自己决定要不要 splice？</p><h3 id="2-6-Notifications"><a href="#2-6-Notifications" class="headerlink" title="2.6 Notifications"></a>2.6 Notifications</h3><p>FUSE 可以通过回复内核的 request 向内核传递消息。但有时候，它需要主动向内核传递消息，比如 poll 调用时，如果事件发生了，FUSE 需要主动通知内核。</p><p><img src="/img/dbpaper/fuse/fuseornot/t2.2.png"></p><h3 id="2-7-Multithreading"><a href="#2-7-Multithreading" class="headerlink" title="2.7 Multithreading"></a>2.7 Multithreading</h3><p>如果 pending queue 里面有多个请求，FUSE 会启动新的线程。<strong>每个线程处理一个请求</strong>，我理解这里是内核线程。处理完后，会检查是否有超过 10 个线程，如果是，则线程退出。</p><p>There is no explicit upper limit on the number of threads created by the FUSE library.<br>The implicit limit arises due to two factors.</p><ul><li>First, by default, only 12 asynchronous requests (max background parameter) can be in the pending queue at one time.</li><li>Second, the number of synchronous requests in the pending queue is constrained by the number of user processes that submit requests.</li><li>In addition, for every INTERRUPT and FORGET requests, a new thread is invoked. </li></ul><p>Therefore, the total number of FUSE daemon threads is at most (12 + number of processes with outstanding I/O + number of interrupts + no of forgets).</p><h3 id="2-8-Linux-Write-back-Cache-and-FUSE"><a href="#2-8-Linux-Write-back-Cache-and-FUSE" class="headerlink" title="2.8 Linux Write-back Cache and FUSE"></a>2.8 Linux Write-back Cache and FUSE</h3><h4 id="2-8-1-Linux-Page-Cache"><a href="#2-8-1-Linux-Page-Cache" class="headerlink" title="2.8.1 Linux Page Cache"></a>2.8.1 Linux Page Cache</h4><p>Page cache 的作用是减少 disk IO，行为是将数据存在 RAM 里面。</p><p>对于读，就是很简单的 cache。对于写，是三个策略：</p><ul><li>no-write 直接写 disk，invalidate cache</li><li>write-through 写 disk 也写 cache</li><li>write-back 只写 cache，后续异步写 disk。这些中间状态的 page 也被称为 dirty page</li></ul><p>刷 diety page 发生在三个情况：</p><ul><li>free memory 低于阈值</li><li>dirty data 比某个阈值老了</li><li>用户调用了 sync 或者 fsync</li></ul><p>All of the above three tasks are performed by the group of flusher threads. First, flusher threads flush dirty data to disk when the amount of free memory in the system drops below a threshold value.<br>This is done by a flusher thread calling a function <code>bdi_writeback_all</code>, which continues to write data to disk until following two conditions are true:</p><ol><li>The specified number of pages has been written out; and</li><li>The amount of free memory is above the threshold.</li></ol><p>在 2.6 内核前，内核中有 bdflush 和 kupdated 两个线程，它们的作用和现在的 flusher 一样：</p><ul><li>bdflush 负责后台 writeback dirty page，当 free memory 变少的时候</li><li>kupdated 负责周期性地 writeback dirty page</li></ul><blockquote><p>The major disadvantage in bdflush was that it consisted of one thread. This led to congestion during heavy page writeback where the single bdflush thread blocked on a single slow device. </p></blockquote><p>在 2.6 内核中，引入了 pdflush 这种线程，它们会根据 io load 调整为 2 到 8 中间的数量。The pdflush threads were not associated with any specific disk, but instead they were global to all disks. The downside of pdflush was that it can easily bottleneck on congested disks, starving other devices from getting service.</p><p>Therefore, a per-spindle flushing method was introduced to improve performace. The flusher threads replaced the pdflush threads in the 2.6.32 kernel.</p><p>The 2.6.32 kernel solved this problem by enabling multiple flusher threads to exists where each thread individually flushes dirty pages to a disk, allowing different threads to flush data at different rates to different disks. This also introduced the concept of per-backing device info (BDI) structure which maintains the per-device (disk) information like dirty list, read ahead size, flags, and B.D.Mn.R and B.D.Mx.R which are discussed in the next section.</p><h4 id="2-8-2-Page-Cache-Parameters"><a href="#2-8-2-Page-Cache-Parameters" class="headerlink" title="2.8.2 Page Cache Parameters"></a>2.8.2 Page Cache Parameters</h4><p>Global Background Ratio (G.B.R): The percentage of Total Available Memory filled with dirty pages at which the background kernel flusher threads wake up and start writing the dirty pages out. The processes that generate dirty pages are not throttled at this point. G.B.R can be changed by the user at /proc/sys/vm/dirty_background_ratio. By default this value is set to 10%.</p><p>Global Dirty Ratio (G.D.R): The percentage of Total Available Memory that can be filled with dirty pages before the system starts to throttle incoming writes. When the system gets to this point, all new I/O’s get blocked and the dirty data is written to disk until the amount of dirty pages in the system falls below this G.D.R. This value can be changed by the user at /proc/sys/vm/dirty ratio. By default this value is set to 20%.</p><p>Global Background Threshold (G.B.T): The absolute number of pages in the system that, when crossed, the background kernel flusher thread will start writing out the dirty data. This is obtained from the following formula:<br>G.B.T = T otalAvailableMemory × G.B.R</p><p>Global Dirty Threshold (G.D.T): The absolute number of pages that can be filled with dirty pages before the system starts to throttle incoming writes. This is obtained from the following formula:<br>G.D.T = T otalAvailableMemory × G.D.R</p><p>下面两个参数主要是限制不同设备能够使用的 page cache 的比例</p><p>BDI Min Ratio (B.Mn.R): Generally, each device is given a part of the page cache that relates to its current average write-out speed in relation to the other devices. This parameter gives the minimum percentage of the G.D.T (page cache) that is available to the file system. This value can be changed by the user at <code>/sys/class/bdi/&lt;bdi&gt;/min</code> ratio after the mount, where <code>&lt;bdi&gt;</code> is either a device number for block devices, or the value of st_dev on non-block-based file systems which set their own BDI information (e.g., a fuse file system). By default this value is set to 0%.</p><p>BDI Max Ratio (B.Mx.R): The maximum percentage of the G.D.T that can be given to the file system (100% by default). This limits the particular file system to use no more than the given percentage of the G.D.T. It is useful in situations where we want to prevent one file system from consuming all or most of the page cache.</p><p>BDI Dirty Threshold (B.D.T): The absolute number of pages that belong to write-back cache that can be allotted to a particular device. This is similar to the G.D.T but for a particular BDI device. As a system runs, B.D.T fluctuates between the lower limit (G.D.T × B.Mn.R) and the upper limit (G.D.T × B.Mx.R).</p><p>BDI Background Threshold (B.B.T): When the absolute number of pages which are a percentage of G.D.T is crossed, then the background kernel flusher thread starts writing out the data. This is similar to the G.B.T but for a particular file system using BDI. B.B.T = B.D.T × G.B.T / G.D.T</p><p>NR FILE DIRTY: The total number of pages in the system that are dirty. This parameter is incremented/decremented by the VFS (page cache).</p><p>NR WRITEBACK: The total number of pages in the system that are currently under write-back. This parameter is incremented/decremented by the VFS (page cache).</p><p>BDI RECLAIMABLE: The total number of pages belonging to all the BDI devices that are dirty. A file system that supports BDI is responsible for incrementing/decrementing the values of this parameter.</p><p>BDI WRITEBACK: The total number of pages belonging to all the BDI devices that are currently under write-back. A file system that supports BDI is responsible for incrementing/decrementing the values for this parameter.</p><h2 id="Implementations"><a href="#Implementations" class="headerlink" title="Implementations"></a>Implementations</h2><p>主要是做了一个 stackfs。</p><p>主要介绍了下面几个方面：</p><ul><li>inode</li><li>lookup</li><li>session information<br>  主要是是每个 FUSE session/connection 的数据管理。</li><li>directories</li><li>file create and open</li></ul><blockquote><p>Stackfs assigns its inode the number equal to the address of the inode structure in memory (by type-casting)</p></blockquote><p>也就是说，Stackfs 的 inode number 数值上是等于 inode struct 的地址的。而 FUSE 的 high level API 中，需要维护 FUSE inode number 到 inode struct 所在位置的映射关系。</p><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p>FUSE has evolved significantly over the years and added several useful optimizations: a writeback cache, zero-copy via splicing, and multi-threading. In our experience, some in the storage community tend to pre-judge FUSE’s performance—assuming it is poor—mainly due to not having enough information about the improvements FUSE has made over the years.</p><p>为了比较近年来 FUSE的优化：</p><ul><li>StackfsBase</li><li>StackfsOpt -&gt; 包含了所有的 FUSE 优化项目<ul><li>writeback cache</li><li>单个 FUSE 请求的最大尺寸 4KiB -&gt; 128KiB</li><li>user daemon 跑在 muitl-thread，也就是 fuse_session_loop_mt</li><li>splicing is activated for all operations，应该指的是 splice 这个零拷贝技术</li></ul></li></ul><h1 id="一些知识"><a href="#一些知识" class="headerlink" title="一些知识"></a>一些知识</h1><h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><p><a href="/2025/09/30/zero-copy/">见 Zero-Copy 技术</a></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://github.com/0voice/kernel_awsome_feature/blob/main/Fuse/FUSE.pdf" target="_blank" rel="noopener">https://github.com/0voice/kernel_awsome_feature/blob/main/Fuse/FUSE.pdf</a></li><li><a href="https://github.com/libfuse/libfuse/blob/master/example/passthrough.c" target="_blank" rel="noopener">https://github.com/libfuse/libfuse/blob/master/example/passthrough.c</a></li><li><a href="https://github.com/0voice/kernel_awsome_feature/blob/main/%E8%87%AA%E5%88%B6%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%20%E2%80%94%2003%20Go%E5%AE%9E%E6%88%98%EF%BC%9Ahello%20world%20%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.md" target="_blank" rel="noopener">https://github.com/0voice/kernel_awsome_feature/blob/main/%E8%87%AA%E5%88%B6%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%20%E2%80%94%2003%20Go%E5%AE%9E%E6%88%98%EF%BC%9Ahello%20world%20%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.md</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;看下 FUSE 的相关知识。&lt;/p&gt;
&lt;p&gt;Filesystem In Userspace 也就是 fuse，是 linux 的一个内核模块。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>Excerpt from Yes Minister</title>
    <link href="http://www.calvinneo.com/2025/02/15/from-ym/"/>
    <id>http://www.calvinneo.com/2025/02/15/from-ym/</id>
    <published>2025-02-15T15:42:32.000Z</published>
    <updated>2025-06-11T13:49:27.241Z</updated>
    
    <content type="html"><![CDATA[<p>The novel of Yes Minister. Including metaphors, grammar issues and funny paragraphs.</p><a id="more"></a><h1 id="Editor’s-Note"><a href="#Editor’s-Note" class="headerlink" title="Editor’s Note"></a>Editor’s Note</h1><blockquote><p>Years of political training and experience had taught Hacker to use twenty words where one would do, to dictate millions of words where mere thousands would suffice, and to use language to blur and fudge issues and events so that they became incomprehensible to others. Incomprehensibility can be a haven for some politicians, for therein lies temporary safety.</p></blockquote><blockquote><p>But his natural gift for the misuse of language, though invaluable to an active politician, was not an asset to a would-be author.</p></blockquote><h1 id="OPEN-GOVERMENT"><a href="#OPEN-GOVERMENT" class="headerlink" title="OPEN GOVERMENT"></a>OPEN GOVERMENT</h1><p>电视剧中增加了一段误接 BBC 采访电话的剧情，我觉得挺棒的。</p><blockquote><p>‘Then why don’t you marry him?’ she asked. ‘I now pronounce you man and political adviser. Whom politics has joined let no wife put asunder.’</p></blockquote><h1 id="THE-OFFICIAL-VISIT"><a href="#THE-OFFICIAL-VISIT" class="headerlink" title="THE OFFICIAL VISIT"></a>THE OFFICIAL VISIT</h1><blockquote><p>‘Shall we scramble?’ he said.<br>‘Where to?’ I said, then felt rather foolosh as I realised what he was talking about. Then I relised it was another of Bernards’s draft suggestions: what’s the point of scrambling a phonw conversation about something that’s just been on the television news?</p></blockquote><p>scramble 既有匍匐前进、攀登的意思，也有干扰无线电，使得只有特殊的人才能够听到通话的意思。</p><blockquote><p>And if the new president is Marxist-backed, who better to win him over to our side than Her Majesty?</p></blockquote><p>如果新总统背后有马克思主义支持，还有谁比陛下更能说服他站到我们这边呢？</p><blockquote><p>there was one 747 that belonged to nine different African airlines in one month. They called it the mumbo-jumbo.</p></blockquote><h1 id="THE-ECONOMY-DRIVE"><a href="#THE-ECONOMY-DRIVE" class="headerlink" title="THE ECONOMY DRIVE"></a>THE ECONOMY DRIVE</h1><blockquote><p>I was forced to move on to the next two white elephants.</p></blockquote><p>我被迫继续处理接下来的那两个烫手山芋。</p><blockquote><p>‘Government buildings do not need fire fafety clearance’<br>‘Why?’<br>‘Perhaps,’ Humphrey offered, ‘because Her Majesty’s Civil Servants are not easily inflamed.’</p></blockquote><blockquote><p>Frank chimed in eagerly, ‘Yes, that would get rid of ninety civil servants at a stroke.’<br>‘Or indeed,’ said Sir Humphrey, ‘at a strike.’</p></blockquote><p>后面还有经典的 smile at 和 smile on。</p><h1 id="BIG-BROTHER"><a href="#BIG-BROTHER" class="headerlink" title="BIG BROTHER"></a>BIG BROTHER</h1><blockquote><p>The local party, the constituency, my family, all of them are proud of me for getting into the Cabinet – yet they are all resentful that I have less time to spend on them and are keen to remind me that I’m nothing special, just their local MP, and that I mustn’t get ‘too big for my boots’. They manage both to grovel and patronise me simultaneously. It’s hard to know how to handle it.</p></blockquote><blockquote><p>And he assumes, rightly, that the Minister has too much else to do. [The whole process is called Creative Inertia – Ed.]</p></blockquote><blockquote><p>He also warned me of the ‘Three Varieties of Civil Service Silence’, which would be  Humphrey’s last resort if completely cornered:<br>The silence when they do not want to tell you the facts: Discreet Silence.<br>The silence when they do not intend to take any action: Stubborn Silence.<br>The silence when you catch them out and they haven’t a leg to stand on. They imply that they could vindicate themselves completely if only they were free to tell all, but they are too honourable to do so: Courageous Silence.</p></blockquote><blockquote><p>I explained to her that the Opposition aren’t really the opposition. They’re just called the Opposition. But, in fact, they are the opposition in exile. The Civil Service are the opposition in residence.</p></blockquote><blockquote><p>In the second place, if there had been investigations, which there haven’t or not necessarily, or I am not at liberty to say if there have, there would have been a project team which, had it existed, on which I cannot comment, would now be disbanded if it had existed and the members returned to their original departments, had there indeed been any such members.</p></blockquote><p>经典虚拟语气。</p><blockquote><p>But they’ve convinced me that they can. Indeed my Permanant Secretary is staking his reputation on it. And, if not, heads will roll.</p></blockquote><p>Hacker 对媒体的了解，经典的媒体逼宫战术。在后面的交通总管一事中，也被 PM 用来赶鸭子上架。</p><h1 id="THE-WRITING-ON-THE-WALL"><a href="#THE-WRITING-ON-THE-WALL" class="headerlink" title="THE WRITING ON THE WALL"></a>THE WRITING ON THE WALL</h1><blockquote><p>Woe betide any Minister who lifts the phone to try to sort out a foreign trade deal, for instance.</p></blockquote><p>Woe betide 在一起表示 XXX 样就会倒霉。Betide 的意思是降临。</p><blockquote><p>‘With respect, Minister,’ countered Sir Humphrey (untruthfully), ‘how do you know it says the opposite if it is totally unintelligible?’</p></blockquote><p>这次是 Humphrey 而不是 Bernard 来挑逻辑问题。</p><blockquote><p>Hacker was beginning to understand Civil Service code language. Other examples are:<br>‘I think we have to be very careful.’ Translation: We are not going to do this.<br>‘Have you thought through all the implications?’ Translation: You are not going to do this.<br>‘It is a slightly puzzling decision.’ Translation: Idiotic!<br>‘Not entirely straightforward.’ Translation: Criminal.<br>‘With the greatest possible respect, Minister . . .’ Translation: Minister, that is the silliest idea I’ve ever heard</p></blockquote><p>这是 Editor 的总结，我觉得很有趣。</p><blockquote><p>If a purely hypothetical Minister were to be unhappy with a departmental draft of evidence to a committee, and if the hypothetical Minister were to be planning to replace it with his own hypothetical draft worked out with his own political advisers at his party HQ, and if this Minister was planning to bring in his own draft so close to the final date for evidence that there would be no time to redraft it, and if the hypothetical Private Secretary were to be aware of this hypothetical draft – in confidence – should the hypothetical Private Secretary pass on the information to the Perm. Sec. of the hypothetical Department?</p></blockquote><p>经典虚拟语气片段。</p><blockquote><p>‘We shall always support you as your standard-bearer, Minister but not as your pall-bearer.’</p></blockquote><blockquote><p>‘If you must do this damn silly thing,’ he said, ‘don’t do it in this damn silly way.’</p></blockquote><p>Humphrey 难得的两次很直的话。</p><blockquote><p>Bernard assured me that I didn’t really need to know much about the proposal because his information on the grapevine, through the Private Office network, was that the proposal would go through on the nod.</p></blockquote><p>为啥 grapevine 还有小道消息的意思？</p><blockquote><p>Donald Hughes, rubbing salt in the wound, apparently described it as ‘approbation, elevation and castration, all in one stroke’. It seems he suggested that I should take the title Lord Hacker of Kamikaze.</p></blockquote><blockquote><p>I told Humphrey I was appalled.<br>‘You’re appalled?’ he said. ‘I’m appalled.’<br>Bernard said he was appalled, too. And, there’s no doubt about it, the situation is appalling.</p></blockquote><blockquote><p>Industrial Harmony. That means strikes.</p></blockquote><p>这里 Editor 有个注解，挺有趣的。</p><blockquote><p>You’ll probably spend the rest of your career in the Vehicle Licensing Centre in Swansea.</p></blockquote><p>对 Swansea 很有敌意啊。</p><blockquote><p>Then Humphrey proposed that we work together on this. This was a novel suggestion, to say the least.</p></blockquote><blockquote><p>‘I’m awfully sorry to quibble again, Minister, but you can’t actually stop things before they start,’ intervened Bernard, the wet-hen-in-chief. He’s really useless in a crisis.</p></blockquote><blockquote><p>‘Same reason,’ came the reply. ‘It’s just like the United Nations. The more members it has, the more arguments you can stir up, and the more futile and impotent it becomes.’</p></blockquote><p>感觉很有洞见。</p><blockquote><p>Then I had an idea. I suddenly realised that Martin will be on my side. I can’t imagine why I didn’t think of it before. He’s Foreign Secretary – and, to my certain knowledge, Martin is genuinely pro Europe. (Humphrey calls him ‘naïf’). Also I ran his campaign against the PM, and he only stands to lose if I’m squeezed out.</p></blockquote><blockquote><p>I agreed, and remarked that this Europass thing is the worst disaster to befall the government since I was made a member of the Cabinet. [We don’t think that Hacker actually meant what he seems to be saying here Ed.]</p></blockquote><blockquote><p>It’s awarded to the statesman who has made the biggest contribution to European unity since Napoleon. [That’s if you don’t count Hitler – Ed.]</p></blockquote><p>这几段 Editor 的注解都很有趣。</p><blockquote><p>when you’ve got them by the balls, their hearts and minds will follow.</p></blockquote><h1 id="THE-RIGHT-TO-KNOW"><a href="#THE-RIGHT-TO-KNOW" class="headerlink" title="THE RIGHT TO KNOW"></a>THE RIGHT TO KNOW</h1><blockquote><p>Sir Humphrey replied that I need not look far – Private Secretaries who could not occupy their Ministers were a threatened species.</p></blockquote><blockquote><p>‘Almost anything can be attacked as a loss of amenity and almost anything can be defended as not a significant loss of amenity. One must appreciate the significance of significant.’</p></blockquote><blockquote><p>Humphrey suggested I look inside them. I did, and to my utter astonishment I saw that there were a handful of signatures in each book, about a hundred altogether at the most. A very cunning ploy – a press photo of a petition of six fat books is so much more impressive than a list of names on a sheet of Basildon Bond.</p></blockquote><blockquote><p>Those civil servants are always kowtowing to Daddy, but they never take any real notice of him.</p></blockquote><p>Kowtow 就是中文的磕头。</p><blockquote><p>She told me she’d been out with the trots. I was momentarily sympathetic and suggested she saw the doctor. Then I realised she meant the Trotskyites. I’d been slow on the uptake because I didn’t know she was a Trotskyite. Last time we talked she’d been a Maoist.</p></blockquote><blockquote><p>I noted that Lucy was giving out the press release at five p.m. Very professional. Misses the evening papers, which not too many people read, and therefore makes all the dailies. She’s learned something from being a politician’s daughter.</p></blockquote><h1 id="JOBS-FOR-THE-BOYS"><a href="#JOBS-FOR-THE-BOYS" class="headerlink" title="JOBS FOR THE BOYS"></a>JOBS FOR THE BOYS</h1><blockquote><p>you scratch my back, I’ll scratch yours.</p></blockquote><h1 id="THE-COMPASSIONATE-SOCIETY"><a href="#THE-COMPASSIONATE-SOCIETY" class="headerlink" title="THE COMPASSIONATE SOCIETY"></a>THE COMPASSIONATE SOCIETY</h1><p>比较好奇为什么 DAA 会为医院的铺张浪费负责？</p><blockquote><p>I informed Bernard that most of our journalists are so amateur that they would have grave difficulty in finding out that today is Thursday.<br>‘It’s actually Wednesday, Minister,’ he said.</p></blockquote><blockquote><p>Sir Humphrey preferred to write in margins where possible, but, if not possible, simulated margins made him feel perfectly comfortable.</p></blockquote><blockquote><p>We can infer from this note that Mr Bernard Woolley – as he then was – mentioned the matter of St Edward’s Hospital to Sir Humphrey, although when we challenged Sir Bernard – as he now is – on this point he had no recollection of doing so – Ed.</p></blockquote><h1 id="THE-DEATH-LIST"><a href="#THE-DEATH-LIST" class="headerlink" title="THE DEATH LIST"></a>THE DEATH LIST</h1><h1 id="DOING-THE-HONOURS"><a href="#DOING-THE-HONOURS" class="headerlink" title="DOING THE HONOURS"></a>DOING THE HONOURS</h1><p>比较好奇为什么 DAA 会管到教育的事情？</p><blockquote><p>Chat over the port and walnuts</p></blockquote><p>通常用来描述一种轻松的社交场合，人们在享用波特酒（port）和核桃（walnuts）时进行闲聊。</p><blockquote><p>He explained that home students were to be avoided at all costs! Anything but home students.</p></blockquote><blockquote><p>Sir William Guthrie, OM, FRS, FBA, Ph.D, MC, MA (Oxon)<br>Group Captain Christopher Venables, DSC, MA<br>Sir Humphrey Appleby, KCB, MVO, MA (Oxon)<br>Bernard Woolley, MA (Cantab)<br>The Rt Hon. James Hacker, PC, MP, BSc. (Econ)<br>Sir Arnold Robinson, GCMG, CVO, MA (Oxon)</p></blockquote><p>Cantab 指的是剑桥。</p><blockquote><p>In fact, the only time a civil servant is known to have refused a knighthood was in 1496. This was because he already had one.</p></blockquote><blockquote><p>Just as incomes policies have always been manipulated by those that control them: for instance, the 1975 Pay Policy provided exemptions for Civil Service increments and lawyers’ fees. Needless to say, the policy was drafted by civil servants and parliamentary draftsmen, i.e. lawyers.</p></blockquote><blockquote><p>Quis custodiet ipsos custodes?</p></blockquote><blockquote><p>And how did the civil servants get away with creating these remarkably favourable terms of service for themselves? Simply by keeping a low profile. They have somehow managed to make people feel that discussing the matter at all is in rather poor taste.</p></blockquote><p>很有趣的观察，“保持低调”，“讨论这些并不得体”。</p><blockquote><p>Cut no ice with me<br>俗语，表示 XX 对我没用。</p></blockquote><blockquote><p>The penny dropped<br>俗语，表示某人终于明白了某件事情或某人突然明白了之前不明白的事情。</p></blockquote><blockquote><p>‘There is no reason,’ he said, stabbing the air with his finger, ‘to change a system which has worked well in the past.’<br>‘But it hasn’t,’ I said.<br>‘We have to give the present system a fair trial,’ he stated. This seemed quite reasonable on the face of it. But I reminded him that the Most Noble Order of the Garter was founded in 1348 by King Edward III. ‘Surely it must be getting towards the end of its trial period?’ I said.<br>So Humphrey tried a new tack. He said that to block honours pending economies might create a dangerous precedent. What he means by ‘dangerous precedent’ is that if we do the right thing now, then we might be forced to do the right thing again next time. And on that reasoning nothing should ever be done at all.</p></blockquote><blockquote><p>‘How do they award the Thistle?’ I asked.<br>‘A committee sits on it,’ said Bernard</p></blockquote><p>双关。</p><blockquote><p>‘As you know,’ he said, ‘the letters JB are the highest honour in the Commonwealth.’<br>I didn’t know.<br>Humphrey eagerly explained. ‘Jailed by the British. Gandhi, Nkrumah, Makarios, Ben-Gurion, Kenyatta, Nehru, Mugabe – the list of world leaders is endless and contains several of our students.’</p></blockquote><blockquote><p>although the Cabinet Secretary is theoretically primus inter pares he is in reality very much primus. It seems that all Permanent Secretaries are equal but some are more equal than others.</p></blockquote><blockquote><p>thin end of the wedge</p></blockquote><blockquote><p>Perhaps Appleby is not an absolutely first-rank candidate to succeed one as Cabinet Secretary. Not really able in every department. Might do better in a less arduous job, such as chairman of a clearing bank or as an EEC official.</p></blockquote><blockquote><p>‘Of course,’ said Bernard, ‘but it’s years and years since the Department of Transport had a Permanent Secretary from Cambridge.’<br>好像只有 Bernard 是剑桥的。</p></blockquote><h1 id="THE-GREASY-POLE"><a href="#THE-GREASY-POLE" class="headerlink" title="THE GREASY POLE"></a>THE GREASY POLE</h1><p>“The Greasy Pole” is an idiomatic expression used to describe the difficult and often slippery route to advancement in one’s career or profession. It is particularly used in contexts where success is hard to achieve and the path to the top is fraught with challenges and obstacles</p><blockquote><p>‘Simple, Minister,’ he explained. ‘It means “with” or “after”, or sometimes “beyond” – it’s from the Greek, you know.’<br>[Like all Permanent Secretaries, Sir Humphrey Appleby was a generalist. Most of them studied classics, history, PPE or modern languages. Of course you might expect the Permanent Secretary at the Department of Administrative Affairs to have a degree in business administration, but of course you would be wrong – Ed.]<br>Then he went on to explain that metadioxin means ‘with’ or ‘after’ dioxin, depending on whether it’s with the accusative or the genitive: with the accusative it’s ‘beyond’ or ‘after’, with the genitive it’s ‘with’ as in Latin, where the ablative is used for words needing a sense of with to precede them.<br>Bernard added – speaking for the first time in the whole meeting – that of course there is no ablative in Greek, as I would doubtless recall.<br>I told him I recalled no such thing, and later today he wrote me a little memo, explaining all the above Greek and Latin grammar.</p></blockquote><blockquote><p>‘Well,’ he said eventually, ‘inert means that . . . it’s not . . . ert.’</p></blockquote><blockquote><p>I searched desperately for an analogy, ‘It’s like Littler and Hitler,’ I explained. ‘We’re not saying that you’re like Hitler because your name sounds similar.’</p></blockquote><blockquote><p>Stage two: Discredit the evidence that you are not publishing<br>This is, of course, much easier than discrediting evidence that you do publish. You do it indirectly, by press leaks. You say:<br>(a) that it leaves important questions unanswered<br>(b) that much of the evidence is inconclusive<br>(c) that the figures are open to other interpretations<br>(d) that certain findings are contradictory<br>(e) that some of the main conclusions have been questioned<br>Points (a) to (d) are bound to be true. In fact, all of these criticisms can be made of a report without even reading it. There are, for instance, always some questions unanswered – such as the ones they haven’t asked. As regards (e), if some of the main conclusions have not been questioned, question them! Then they have.</p></blockquote><p>这里，有两幅 BBC 的报道，分别是支持和反对某个事情的版本，不过太模糊看不清楚。</p><blockquote><p>‘The public,’ said Sir Humphrey, ‘are ignorant and misguided.’<br>‘What do you mean?’ I demanded. ‘It was the public who elected me.’</p></blockquote><blockquote><p>He was very bitter. And very insulting. ‘Must you always be so concerned with climbing the greasy pole?’<br>I faced the question head on. ‘Humphrey,’ I explained, ‘the greasy pole is important. I have to climb it.’<br>‘Why?’<br>‘Because,’ I said, ‘it’s there.’</p></blockquote><blockquote><p>I asked him how it felt, going from the Commons to the Lords.<br>‘It’s like being moved from the animals to the vegetables,’ he replied.</p></blockquote><h1 id="THE-DEVIL-YOU-KNOW"><a href="#THE-DEVIL-YOU-KNOW" class="headerlink" title="THE DEVIL YOU KNOW"></a>THE DEVIL YOU KNOW</h1><blockquote><p>He sighed. ‘Well, Minister, I’m afraid that this is the penalty we have to pay for trying to pretend that we are Europeans. Believe me, I fully understand your hostility to Europe.’</p></blockquote><blockquote><p>I reminded Humphrey that the typical Common Market official is said to have the organising capacity of the Italians, the flexibility of the Germans and the modesty of the French. He tops all that up with the imagination of the Belgians, the generosity of the Dutch, and the intelligence of the Irish. Finally, for good measure, he has the European spirit of Mr Anthony Wedgwood Benn.</p></blockquote><h1 id="THE-BED-OF-NAILS"><a href="#THE-BED-OF-NAILS" class="headerlink" title="THE BED OF NAILS"></a>THE BED OF NAILS</h1><p>如坐针毡还有的表述是：On Tenterhooks</p><h1 id="常见单词"><a href="#常见单词" class="headerlink" title="常见单词"></a>常见单词</h1>]]></content>
    
    
    <summary type="html">&lt;p&gt;The novel of Yes Minister. Including metaphors, grammar issues and funny paragraphs.&lt;/p&gt;</summary>
    
    
    
    
    <category term="文学" scheme="http://www.calvinneo.com/tags/文学/"/>
    
  </entry>
  
  <entry>
    <title>磁盘上的数据结构</title>
    <link href="http://www.calvinneo.com/2025/02/09/data-structure-on-disk/"/>
    <id>http://www.calvinneo.com/2025/02/09/data-structure-on-disk/</id>
    <published>2025-02-09T12:57:20.000Z</published>
    <updated>2025-03-08T02:25:36.452Z</updated>
    
    <content type="html"><![CDATA[<p>如题。</p><a id="more"></a><h1 id="设计要点"><a href="#设计要点" class="headerlink" title="设计要点"></a>设计要点</h1><h2 id="序列化和反序列化-serde"><a href="#序列化和反序列化-serde" class="headerlink" title="序列化和反序列化(serde)"></a>序列化和反序列化(serde)</h2><p>这里的要点，并不只局限在类似于 protobuf 的库上，而是在设计存储格式的时候，都会考虑的问题。</p><p>需要关注的 feature：</p><ul><li>对于 blob 的支持<br>  解析是否需要占用大量内存？</li><li>读取部分数据<br>  是否需要解压/解码全部结构，才能读取到该数据呢？</li><li>兼容性<br>  新旧版本应该能够处理彼此的数据。例如：<ul><li>旧版本能够忽略新增的字段，对于后续被删除的字段，也会保留其编号。</li><li>新版本对于旧消息中缺失的字段能补上默认值，或者填入 null。</li></ul></li><li>类型的 cast<br>  例如支持从 bool 升级为 enum 或者 int。</li><li>压缩性能</li><li>编码和解码的速度、CPU 开销、内存开销<br>  这一点很重要，例如 json 的编解码性能就比较差。</li><li>是否可以自描述？一般出于空间考虑，这都是不包含的</li><li>是否有足够的容错</li></ul><h2 id="磁盘上的数据结构"><a href="#磁盘上的数据结构" class="headerlink" title="磁盘上的数据结构"></a>磁盘上的数据结构</h2><ul><li>磁盘 IO 的单位</li><li>完整性校验</li><li>尽可能减少 IO 次数</li><li>是否多个文件或者多级文件？</li><li>是否分开存储 meta 和 data？先写 meta 还是先写 data？</li></ul><h1 id="常见格式"><a href="#常见格式" class="headerlink" title="常见格式"></a>常见格式</h1><h2 id="Parquet"><a href="#Parquet" class="headerlink" title="Parquet"></a>Parquet</h2><p>假设一个表中有 N 列，它们被分入了 M 个 row groups 中。那么每个 row groups 中的一个 Column 称为一个 Column Chunk。</p><p>文件的 metadata 包含了每个 Column Chunk 的开始位置。为了能够一趟写完文件，所以最后才会写入 metadata。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">4-byte magic number &quot;PAR1&quot;</span><br><span class="line">&lt;Column 1 Chunk 1&gt;</span><br><span class="line">&lt;Column 2 Chunk 1&gt;</span><br><span class="line">...</span><br><span class="line">&lt;Column N Chunk 1&gt;</span><br><span class="line">&lt;Column 1 Chunk 2&gt;</span><br><span class="line">&lt;Column 2 Chunk 2&gt;</span><br><span class="line">...</span><br><span class="line">&lt;Column N Chunk 2&gt;</span><br><span class="line">...</span><br><span class="line">&lt;Column 1 Chunk M&gt;</span><br><span class="line">&lt;Column 2 Chunk M&gt;</span><br><span class="line">...</span><br><span class="line">&lt;Column N Chunk M&gt;</span><br><span class="line">File Metadata</span><br><span class="line">4-byte length in bytes of file metadata (little endian)</span><br><span class="line">4-byte magic number &quot;PAR1&quot;</span><br></pre></td></tr></table></figure><p>在读取时，首先需要读取 metadata，从而定位到所有要读取的 Column Chunks。这些 Column Chunk 稍后可以被顺序读取出来。</p><p>Parquet 的格式的设计思想是将 metadata 和 data 分开，这使得可以将 Column 们分入到不同的文件中。于此同时，有一个单独的 metadata 文件去索引多个 parquet 文件。</p><blockquote><p>从下面的图片中可以看到，Parquet 文件实际上是自包含的，也就是说单个 Parquet 文件已经包含完整的数据和元数据，无需依赖外部元数据文件。像 Spark 之类的系统确实会创建一个全局的 metadata 文件，但它的作用就是方便快速的索引。</p></blockquote><p><img src="/img/disk-struct/parquet.gif"></p><p>因为 metadata 在 parquet 文件的 Footer 处，所以需要先读取文件的倒数第5到8字节，得到它的大小，然后再往前 seek 这个大小解析出 metadata 部分。</p><p>Parquet 是使用 Thrift 协议解析序列化的。它和 protobuf 其实差不多，不过 Thrift 自带了 RPC。</p><h3 id="Types"><a href="#Types" class="headerlink" title="Types"></a>Types</h3><p>Parquet 会在 Column Chunk 层面保存 min max 值。</p><h3 id="Nested-Encoding"><a href="#Nested-Encoding" class="headerlink" title="Nested Encoding"></a>Nested Encoding</h3><p>关于 Dremel 格式，可以看 <a href="https://paper-notes.zhjwpku.com/datalayout/dremel.html%E3%80%82" target="_blank" rel="noopener">https://paper-notes.zhjwpku.com/datalayout/dremel.html。</a></p><blockquote><p>To encode nested columns, Parquet uses the Dremel encoding with definition and repetition levels. Definition levels specify how many optional fields in the path for the column are defined. Repetition levels specify at what repeated field in the path has the value repeated. The max definition and repetition levels can be computed from the schema (i.e. how much nesting there is). This defines the maximum number of bits required to store the levels (levels are defined for all values in the column).</p></blockquote><p>Two encodings for the levels are supported BIT_PACKED and RLE. Only RLE is now used as it supersedes BIT_PACKED.</p><h3 id="Column-chunks"><a href="#Column-chunks" class="headerlink" title="Column chunks"></a>Column chunks</h3><h3 id="错误恢复"><a href="#错误恢复" class="headerlink" title="错误恢复"></a>错误恢复</h3><p>如果文件的 metadata 丢失了，那么文件损坏。如果 Column 的 metadata 丢失了，那么这个 Column Chunk 就损坏了。但是这个 Column 在其他 row group 中的部分是 OK 的。如果 page header 丢失了，那 chunk 中剩余的 page 就丢失了。如果 page 中的 data 损坏了，那么这个 page 就丢失了。</p><p>因此，如果 row group 设置的比较小，那么文件可能在 resilient 上更好。但是，这会 file metadata 更大。如果在写入 metadata 的时候出现问题，那么所有写入的数据都丢失了。一个做法是每写 N 个 row group，就写一次 metadata。每个 metadata 都是 cumulative 的，并且包含了写到现在所有的 row group。</p><blockquote><p>Combining this with the strategy used for rc or avro files using sync markers, a reader could recover partially written files.</p></blockquote><h2 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h2><h2 id="LevelDB-RocksDB-的-WAL"><a href="#LevelDB-RocksDB-的-WAL" class="headerlink" title="LevelDB/RocksDB 的 WAL"></a>LevelDB/RocksDB 的 WAL</h2><p>见 <a href="/2021/04/23/leveldb-wal/">LevelDB 之 WAL</a></p><h2 id="Dremel"><a href="#Dremel" class="headerlink" title="Dremel"></a>Dremel</h2><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://parquet.apache.org/docs/file-format/" target="_blank" rel="noopener">https://parquet.apache.org/docs/file-format/</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;如题。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="Parquet" scheme="http://www.calvinneo.com/tags/Parquet/"/>
    
  </entry>
  
  <entry>
    <title>形式谬误和非形式谬误</title>
    <link href="http://www.calvinneo.com/2025/02/09/logical-fallacies/"/>
    <id>http://www.calvinneo.com/2025/02/09/logical-fallacies/</id>
    <published>2025-02-09T03:57:20.000Z</published>
    <updated>2025-02-15T12:38:48.994Z</updated>
    
    <content type="html"><![CDATA[<p>介绍下常见的形式谬误和非形式谬误。</p><a id="more"></a><h1 id="非形式谬误"><a href="#非形式谬误" class="headerlink" title="非形式谬误"></a>非形式谬误</h1><h2 id="不相干的谬误"><a href="#不相干的谬误" class="headerlink" title="不相干的谬误"></a>不相干的谬误</h2><p>不相干的谬误(fallacies of relevance)或分散注意力的谬误(fallacies of distraction)是指论证的前提和结论毫无逻辑关联的不当推理方式，这种情况又称不相干的结论(irrelevant conclusion)或制造伪冒理据。</p><p>亦有人将提出与原来的争议主题毫无关联的主张或论证归类为不相干的谬误，这种情况也称作歪曲论题(ignoratio elenchi)或制造伪冒论题。</p><h3 id="稻草人论证"><a href="#稻草人论证" class="headerlink" title="稻草人论证"></a>稻草人论证</h3><p>曲解对方的论点，针对曲解后的论点（替身稻草人）攻击，再宣称已推翻对方论点。</p><blockquote><p>除了把小孩关起来以外，显然还有许多方法让孩童出门而不在大街上乱跑，因而前者无法推理出后者。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：我认为孩童不应该往大街上乱跑。</span><br><span class="line">乙：把小孩关起来，不让他们呼吸新鲜空气，那真是太愚蠢了。</span><br></pre></td></tr></table></figure><blockquote><p>甲把“支持性交易合法化”曲解成“买春过”，然而两者并无必然关系。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：你支持性交易合法化吗？</span><br><span class="line">乙：支持啊。</span><br><span class="line">甲：你果然买春过！</span><br></pre></td></tr></table></figure><h3 id="红鲱鱼"><a href="#红鲱鱼" class="headerlink" title="红鲱鱼"></a>红鲱鱼</h3><p>转移话题。</p><blockquote><p>甲是要讨论酒驾，但是乙却引入超速这个不直接相关的议题，是引入红鲱鱼的做法。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：酒驾会撞死人，而且是可以避免的，而且现在大家都知道酒驾的危害，所以我认为，酒驾应该比照故意杀人处罚。</span><br><span class="line">乙：开快车一样会撞死人，一样是可以避免的，其危害大家也知道，我们应该多讨论超速的危害及处罚！</span><br></pre></td></tr></table></figure><h3 id="诉诸言论自由"><a href="#诉诸言论自由" class="headerlink" title="诉诸言论自由"></a>诉诸言论自由</h3><blockquote><p>有发表意见的权利和意见是否正确可取是不相干的。因此自己有权发表意见并不是支持自己意见正确的恰当理据。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：现在已经很多人穷得买不起房子了，政府还打算课征奢侈税，根本是不管大家死活！</span><br><span class="line">乙：你弄错了，房地产奢侈税只有买房二年内卖掉才需要缴纳，这会让许多炒房的人有所顾忌，有助于降低房价；穷人买房是为了自用，几乎不必缴奢侈税。因此奢侈税是对穷人大有帮助的。</span><br><span class="line">甲：我有权发表意见，请尊重我说话的权利！</span><br></pre></td></tr></table></figure><h2 id="不充分的谬误"><a href="#不充分的谬误" class="headerlink" title="不充分的谬误"></a>不充分的谬误</h2><p>不充分的谬误是指论证的前提虽与结论相干，但前提不能充分支持结论的现象。也就是说，即使所有前提都为真，也不能确保结论为真。</p><h3 id="逆偶例谬误"><a href="#逆偶例谬误" class="headerlink" title="逆偶例谬误"></a>逆偶例谬误</h3><p>基于某个例外的存在，而否定一般性的通则。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">爸爸抽烟抽了四十年都没得肺癌，因此抽烟不会导致肺癌。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">宫崎勤是宅男，又犯下连续强奸杀害女童的罪行，可见动漫是坏东西。</span><br></pre></td></tr></table></figure><h3 id="合成谬误和分割谬误"><a href="#合成谬误和分割谬误" class="headerlink" title="合成谬误和分割谬误"></a>合成谬误和分割谬误</h3><p>合成谬误指的是因为整体中的某些部分具有某性质，从而认为整体本身具备该性质，这是一种以偏概全。</p><p>分割谬误与之相反。</p><p>下面的是合成谬误的例子。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">人体由细胞组成，而细胞是看不见的，因此人体是看不见的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我的论文每一个论点是无懈可击的，因此整篇论文都是无懈可击的。</span><br></pre></td></tr></table></figure><p>下面的是分割谬误的例子。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">宇宙已存在一百亿年，宇宙是由分子组成的，因此宇宙中的每个分子都已存在一百亿年。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">朝鲜是是世界最穷的国家之一，因此朝鲜的每个人都很穷。</span><br></pre></td></tr></table></figure><h3 id="偏差样本（统计）"><a href="#偏差样本（统计）" class="headerlink" title="偏差样本（统计）"></a>偏差样本（统计）</h3><p>根据缺乏代表性的样本（统计方法）推论出一般性的结论。</p><blockquote><p>注意区分朝鲜-朝鲜人，和美国人-美洲人之间的关系。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">美国人很有钱，可见美洲人很有钱。</span><br></pre></td></tr></table></figure><blockquote><p>长期失业的可能有多种原因，未必和大学有关。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">他是重点大学热门科系毕业的，结果还是长期失业，可见念好大学没有用。</span><br></pre></td></tr></table></figure><h3 id="诉诸可能-把合理当正确"><a href="#诉诸可能-把合理当正确" class="headerlink" title="诉诸可能/把合理当正确"></a>诉诸可能/把合理当正确</h3><p>基于一件事有可能或相当可能是真的，就把它当作确定是真的。当思考或决策忽略了其他可能性，把一种合理的、可能的推测当做正确的、必然的真相，就不是恰当的推理。</p><p>此类谬误中，将“一定”改为“可能”，那么逻辑往往正确。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">网络上很多黑客，你上网不装防火墙，你的电脑一定会被黑客入侵的！</span><br></pre></td></tr></table></figure><blockquote><p>小华在侦讯时的表现可作为怀疑小华涉案的线索，但不应据此咬定他必有涉案。<br>不应该认定试图为嫌疑犯辩护的律师都是昧著良心做事。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">小华在侦讯时结结巴巴、言词反复，还数度说谎，这就是他涉入了这起大规模诈欺案的明确证据！</span><br><span class="line">辩护律师找一堆理由帮小华这种恶徒脱罪，真是毫无良心！</span><br></pre></td></tr></table></figure><h3 id="布佛氏论证（诉诸为何相信）"><a href="#布佛氏论证（诉诸为何相信）" class="headerlink" title="布佛氏论证（诉诸为何相信）"></a>布佛氏论证（诉诸为何相信）</h3><p>假定某观点是错的，由此出发解释为什么许多人会相信它，然后断定该观点是错误的。</p><blockquote><p>人们可以有合理的理由怀疑奶茶可能不含鲜奶，但不能据此断定某杯奶茶一定不含鲜奶或一定含有鲜奶。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">奶茶里不需要加入鲜奶，只要加入奶精就可以模拟出鲜奶的味道，因此这杯奶茶一定不含鲜奶。</span><br></pre></td></tr></table></figure><blockquote><p>人们有合理的理由可以怀疑小华可能用诈术，但这不表示小华一定使用诈术，也不表示小华没有使用诈术。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">魔术师可以表演出徒手打碎十块瓦片的诈术，所以小华之前打碎二块瓦片一定不是真的。</span><br></pre></td></tr></table></figure><h3 id="鬼祟谬误（阴谋论）"><a href="#鬼祟谬误（阴谋论）" class="headerlink" title="鬼祟谬误（阴谋论）"></a>鬼祟谬误（阴谋论）</h3><p>断定某些事情一定是某些心怀不轨的团体在背后操作导致。</p><h3 id="单方论证（采樱桃谬误）"><a href="#单方论证（采樱桃谬误）" class="headerlink" title="单方论证（采樱桃谬误）"></a>单方论证（采樱桃谬误）</h3><p>引用貌似证实特定立场的个别案例或数据，而忽略可能与该立场相矛盾的相关和类似案例或数据的重要部分的行为。</p><h3 id="不完整的比较"><a href="#不完整的比较" class="headerlink" title="不完整的比较"></a>不完整的比较</h3><p>透过不完整而难以驳斥的断言证成观点。然而，正因为其不完整，因而也无法有效证成观点。</p><blockquote><p>这是不完整的断言，较完整的断言应该像：“甲公司的产品比乙公司的产品较便宜。”“甲公司的产品销售量比乙公司的产品高。”</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">甲公司的产品比乙公司的产品更好。</span><br></pre></td></tr></table></figure><h3 id="不一致的比较"><a href="#不一致的比较" class="headerlink" title="不一致的比较"></a>不一致的比较</h3><p>将对不同对象采用不同基准作出的比较，并列作为理据证成某主张。这种谬误有时是出于对运用比较数据的概念模糊，是无意而成的。但也有刻意以此为宣传手法，或于辩论中借此误导他人以求胜出。</p><p>例子比如雷军对比法。</p><blockquote><p>可能甲公司的产品功能较乙公司的少，而价格却比丙公司的高，因此即使该陈述为真实，亦不足以使“甲公司的产品最好”此一结论成立</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">甲公司的产品比乙公司的更便宜，比丙公司的更多功能。</span><br></pre></td></tr></table></figure><h3 id="涅槃谬误（完美主义谬误）-权宜主义谬误"><a href="#涅槃谬误（完美主义谬误）-权宜主义谬误" class="headerlink" title="涅槃谬误（完美主义谬误）/权宜主义谬误"></a>涅槃谬误（完美主义谬误）/权宜主义谬误</h3><p>涅槃谬误：因为这做法不完美，所以这做法便没用。</p><p>权宜主义谬误：基于某方案目的很重要而无视方案的一切缺陷。</p><p>权宜主义谬误包括</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">偷窃是错的，不能不处罚，我主张偷窃者唯一死刑！</span><br></pre></td></tr></table></figure><p>特别地，两个谬误可以并存，如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">有做总比没做好，再吵就干脆啥都不做</span><br></pre></td></tr></table></figure><p>或者</p><blockquote><p>涅槃谬误在“死刑”上，权宜主义谬误在“废除死刑”上</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">死刑不可避免会冤狱错杀，而且死刑对谋杀并无更强的吓阻效果，所以即使多数民意反对废除死刑，政府也应该尽速废除死刑</span><br></pre></td></tr></table></figure><h3 id="偶例谬误"><a href="#偶例谬误" class="headerlink" title="偶例谬误"></a>偶例谬误</h3><p>和先前的逆偶例谬误相反，基于某个通则的存在，而否定例外的存在或正当性，即不恰当地以一个普遍原则来解释一个特殊事例。</p><p>当在三段论中应用经验法则的时候忽略了特例，就会出现有效的推论但是得出谬误的结论。</p><blockquote><p>可以思考下这个命题的逆偶例谬误如何阐述。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">超速是不对的，所以救护车不应该超速。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">鸟会飞，驼鸟是鸟，所以驼鸟会飞。</span><br></pre></td></tr></table></figure><h3 id="区群谬误（生态谬误、层次谬误）"><a href="#区群谬误（生态谬误、层次谬误）" class="headerlink" title="区群谬误（生态谬误、层次谬误）"></a>区群谬误（生态谬误、层次谬误）</h3><p>和以偏概全相反，区群谬误是一种以全概偏，如果仅基于群体的统计数据就对其下属的个体性质作出推论，就是犯了区群谬误。</p><p>个人感觉有点类似于偏差样本，或者合成谬误。但是合成谬误并不依赖统计数据，而偏差样本中又不存在整体-个体的关系。这个问题感觉还可以被拓展为辛普森悖论。</p><p>区群谬误的相反情况为化约主义（还原论）。</p><blockquote><p>因为统计结果只是对两城的平均智商作比较，乙城个别市民智商可能比甲城的个别市民高；在极端情况下，两城之中智商最高的一位市民可能生活在乙城。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一项研究发现甲城市民的智商平均比乙城市民高，因此认为在两个城市各自随机抽取一个市民，甲城那位市民的智商都会比乙城的那位高</span><br></pre></td></tr></table></figure><blockquote><p>事实上，贫穷才是癌症的风险因素，区群谬误带来相反的结论。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">假设甲城和乙城都各有相同人数的富人和穷人，富人都住在山上，而穷人都住在排放致癌物的工厂附近，故此在两个城市的穷人癌症发病率都比富人高很多倍。在甲城的都是高增值高污染工业，故此在甲城无论是富人和穷人的平均工资都比乙城高，但同时甲城穷人的癌症发病率也因此比乙城高。</span><br><span class="line"></span><br><span class="line">一位教授希望找出癌症的风险因素，他在国家统计刊物找到甲城和乙城的癌症发病率和工资中位数，发现工资中位数较高的甲城有更高的癌症发病率，得出高收入是癌症风险因素的结论。</span><br></pre></td></tr></table></figure><h3 id="懒于归纳（诉诸巧合）"><a href="#懒于归纳（诉诸巧合）" class="headerlink" title="懒于归纳（诉诸巧合）"></a>懒于归纳（诉诸巧合）</h3><p>主张一切统计性、归纳性的结论都不可取。特点是尽管证据显示甲导致乙，但论者依旧主张乙是因为其他事情导致的。</p><p>相反的谬误是草率归纳。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：你们拉面店的服务生千濑在第一个月就打破了五十个盘子，而有强烈的证据显示这是因为她动作笨拙所致，为了整个店的业绩着想，应该对她加强训练。</span><br><span class="line">乙：千濑很可爱，大家都喜欢她！这一切都只是巧合罢了！</span><br></pre></td></tr></table></figure><h2 id="不充分的谬误-因果谬误"><a href="#不充分的谬误-因果谬误" class="headerlink" title="不充分的谬误 - 因果谬误"></a>不充分的谬误 - 因果谬误</h2><p>统计学上很容易发现两个事件 corelate，并不能很好地推断彼此之间的因果关系。</p><h3 id="相关不蕴涵因果（与此故因此、相关不代表因果）"><a href="#相关不蕴涵因果（与此故因此、相关不代表因果）" class="headerlink" title="相关不蕴涵因果（与此故因此、相关不代表因果）"></a>相关不蕴涵因果（与此故因此、相关不代表因果）</h3><p>若两个事件有明显的相关时（即当一件事出现，另一件事也出现），不一定表示两者之间有因果关系。这个实际上是一个很大的范畴，下面列出的其他因果谬误，可能都同样犯有相关不蕴涵因果的问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">统计研究发现，冰淇淋销量最高的时候，就是公共泳池的溺水事故发生得最多的时候。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明感冒后吃了些感冒药，后来就发烧了。一定是这感冒药让他恶化的！</span><br></pre></td></tr></table></figure><blockquote><p>这里同时也犯下了复合结果的谬误。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小华因为发高烧不退，于是发生了脑膜炎。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明上次比赛打棒球的成绩奇差无比，教练把他骂一顿以后，这次比赛的成绩就进步了。因此，责骂可以提升小明打棒球的成绩。</span><br></pre></td></tr></table></figure><h3 id="后此谬误（后此故因此、巧合关系）"><a href="#后此谬误（后此故因此、巧合关系）" class="headerlink" title="后此谬误（后此故因此、巧合关系）"></a>后此谬误（后此故因此、巧合关系）</h3><p>指这样一种不正确的推理：如果 A 事件先于 B 事件发生，A 事件则是 B 事件的原因。</p><blockquote><p>发烧可能是感冒本身造成，未必是感冒药造成的。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明感冒了，他吃了一些感冒药，然后他发烧了。所以，一定是这感冒药让他发烧的。</span><br></pre></td></tr></table></figure><h3 id="倒果为因"><a href="#倒果为因" class="headerlink" title="倒果为因"></a>倒果为因</h3><blockquote><p>事实也有可能是：被迫担任苦力才肌肉发达。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">清末的苦力肌肉较发达，可见肌肉较发达的人比较喜欢担任苦力。</span><br></pre></td></tr></table></figure><blockquote><p>事实也有可能是：盲人由于依听力过活，听力开发后变得比一般人更敏锐。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">盲人的听力比明眼人好，可见听力好的人容易失明。</span><br></pre></td></tr></table></figure><blockquote><p>事实也有可能是：人民对政府有所不满，才会有反政府团体的出现。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">就是因为有这些唯恐天下不乱的反政府团体，人民内部才会有反政府的声音的。</span><br></pre></td></tr></table></figure><h3 id="单因谬误"><a href="#单因谬误" class="headerlink" title="单因谬误"></a>单因谬误</h3><p>认定某事由一个单独原因造成，而未考虑可能是由许多原因共同导致，即复合原因（complex cause）。</p><blockquote><p>考试成绩差除了可能天天玩游戏机而排挤读书时间以外，可能还有其他原因。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明考试成绩那么差，一定是因为他天天玩游戏机的关系。</span><br></pre></td></tr></table></figure><blockquote><p>妹喜、妲己和褒姒这三位美女，未必是这些夏商周这三个朝代灭亡的主要原因，甚至美女的存在根本就不是原因。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">作为臣子的我曾听说：贤能的士人，是国家的珍宝、而美女则是国家的祸害。例如夏朝因妺喜而灭亡、商朝因妲己而灭亡、周朝因褒姒而灭亡。《吴越春秋》</span><br></pre></td></tr></table></figure><h3 id="复合结果"><a href="#复合结果" class="headerlink" title="复合结果"></a>复合结果</h3><p>当某些原因导致多个结果时，在多个结果之间建立因果关联。</p><p>我认为这个算是“相关不蕴涵因果”的一种特殊形式。因为“当某些原因导致多个结果”时，那么这多个结果肯定是 corelate 的。</p><blockquote><p>即使房子没被炮火所毁，小明一家人仍可能因为“国家发生战乱”而从北部逃到南部。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">国家发生战乱，小明一家人因为房子被炮火所毁而从北部逃到南部。</span><br></pre></td></tr></table></figure><blockquote><p>即使没有“发高烧不退”（比如吃了很多退烧药），小华仍可能因为“细菌感染没妥善控制”造成“脑膜炎”。<br>注意，也同时犯下了相关不蕴涵因果谬误。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小华因为发高烧不退，于是发生了脑膜炎。</span><br></pre></td></tr></table></figure><h3 id="无足轻重"><a href="#无足轻重" class="headerlink" title="无足轻重"></a>无足轻重</h3><p>将真实但不重要的原因作为论证基础，却遗漏了重要的主因。</p><blockquote><p>导致空气质量变差的主因可能是交通工具或工厂排放的废气，烧纸钱虽也会影响空气，然而对空气质量的影响与交通工具或工厂排放的废气相比甚微。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">烧纸钱使空气质量每况愈下，所以政府应该不许民众再烧了。</span><br></pre></td></tr></table></figure><blockquote><p>电脑开一夜对全球变暖的影响甚微。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">你电脑开一夜没关，所以你是造成全球变暖的凶手。</span><br></pre></td></tr></table></figure><blockquote><p>有理由认为了解和传播凶杀案资讯的重要性超过这些情绪反应所带来的问题，因此以“引发情绪”为由叫人不要转载凶杀案的资讯并不恰当。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在面对凶杀案时呼吁人们“请不要转载任何的图片、电视画面，毕竟这些都会制造无谓的恐慌与难过”。</span><br></pre></td></tr></table></figure><h3 id="回归谬误"><a href="#回归谬误" class="headerlink" title="回归谬误"></a>回归谬误</h3><p>因未考虑统计学上随机起落的回归现象，造成不恰当的因果推论。</p><blockquote><p>发烧二天后，即使不吃药也很可能自行好转，不能就此认定是药物的效果。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明前天发烧，今天吃了退烧药，小明烧退是退烧药的效果。</span><br></pre></td></tr></table></figure><blockquote><p>也是相关不蕴涵因果。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明上次打棒球的成绩奇差无比，教练把他骂一顿以后，这次比赛的成绩就进步了。因此，责骂可以提升小明打棒球的成绩。</span><br></pre></td></tr></table></figure><h3 id="滑坡谬误"><a href="#滑坡谬误" class="headerlink" title="滑坡谬误"></a>滑坡谬误</h3><p>从形式逻辑上是属于假言三段论，使用连串的因果推论，却夸大了每个环节中的因果强度，将“可能性”转化为“必然性”，从而得到不合理的结论 ，然而事实不一定会按照线性推论而发生，而有其他的可能性。</p><blockquote><p>小华今天借十元，不表示他明天就会借一百元。就算小华今天借一百元，也不表示明天就会借一千元。就算小华借一千元甚至一万元，也不表示乙就会破产，因为乙有权选择不借。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：小华临时打电话没钱，为什么你不愿意借他十元呢？</span><br><span class="line">乙：如果我借了，他明天又会跟我借一百元，接下来就借一千元、一万元，我岂不破产？</span><br></pre></td></tr></table></figure><blockquote><p>公司损失也不表示公司会赚不到钱，就算公司赚不到钱也不表示公司就要裁员，就算公司裁员也不表示被裁员的人会没工作，就算被裁员的人没工作也不表示会为了生计无恶不作。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">员工偷懒公司便会损失，公司赚不到钱就要裁员，被裁员的人会没工作，没工作的人为了生计就会无恶不作。因此，上班偷懒是非常严重的罪恶。</span><br></pre></td></tr></table></figure><h2 id="不当预设的谬误"><a href="#不当预设的谬误" class="headerlink" title="不当预设的谬误"></a>不当预设的谬误</h2><h3 id="乞题（窃取论点）"><a href="#乞题（窃取论点）" class="headerlink" title="乞题（窃取论点）"></a>乞题（窃取论点）</h3><p>在论证时把不该视为理所当然的命题预设为理所当然，这是一种不当预设的非形式谬误。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明有罪，因为小明有罪。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">男人体力最好，因为女人体力没那么好。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">桌上有一块蛋糕，大宝切了二分之一留给自己，然后给二宝和三宝各四分之一。</span><br><span class="line"></span><br><span class="line">二宝和三宝：不公平！你凭什么拿比较多？</span><br><span class="line">大宝：因为我比较聪明。</span><br><span class="line">二宝和三宝：凭什么说你比较聪明？</span><br><span class="line">大宝：因为我拿到比较多的蛋糕。</span><br></pre></td></tr></table></figure><p>下面是三段论中的乞题</p><blockquote><p>论证预设了“上帝拥有一切美德”，但是“一切美德”中又包含了“仁爱”，所以实际上就是在预设“上帝是仁爱的”。但“上帝拥有一切美德”这个是不确定需要证明的。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">上帝是仁爱的，因为上帝拥有一切美德。</span><br></pre></td></tr></table></figure><blockquote><p>这里的乞题是预设了“美国人都很有钱”</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">美籍教师彼得很有钱，因为美国人都很有钱。</span><br></pre></td></tr></table></figure><blockquote><p>本例的前提“合理的法律和司法判决和个人感受无关”这点相当可疑、需要证明。因为有理由认为，对当事人主观感受的同理心在司法正义的实现中至为重要。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我认为，如果我家人被杀，那么司法该怎么判，和我个人的感受无关。</span><br></pre></td></tr></table></figure><blockquote><p>考虑未明言的隐藏前提，本例论证可分析为：</p><ul><li>汤姆必须找到好工作（隐藏前提）</li><li>汤姆必须减少花在玩乐和社团活动的时间，才能读好书（隐藏前提）</li><li>汤姆不读好书以后一定会找不到好工作（前提）</li><li>因此，汤姆必须减少花在玩乐和社团活动的时间（结论）</li></ul></blockquote><blockquote><p>然而这些前提都可能有争议，在特定情境下可能会是不当的，例如，如果汤姆显然不擅长读书，但非常擅长演戏，且正有星探尝试挖掘，“汤姆不读好书以后一定会找不到好工作”可能是不当预设；如果汤姆是读书天才，“汤姆必须减少花在玩乐和社团活动的时间，才能读好书”可能是不当预设；如果汤姆的价值观就是没有好工作也无所谓，“汤姆必须找到好工作”便是不当预设（需要提供理由说服汤姆接受）。此类情境下这样的论证便有乞题之虞。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">妈妈对汤姆说：你不读好书以后一定会找不到好工作，因此你必须减少花在玩乐和社团活动的时间！</span><br></pre></td></tr></table></figure><h3 id="循环论证"><a href="#循环论证" class="headerlink" title="循环论证"></a>循环论证</h3><p>直接的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明有罪，因为他有罪。</span><br></pre></td></tr></table></figure><p>间接的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：小明是音乐神童，因为他很懂音乐。</span><br><span class="line">乙：怎么知道小明很懂音乐？</span><br><span class="line">甲：因为小明是音乐神童</span><br></pre></td></tr></table></figure><p>更为复杂的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：大雄是卖国贼，因为他替胖虎这个间谍辩护！</span><br><span class="line">乙：怎么知道胖虎是间谍？</span><br><span class="line">甲：因为大雄这个卖国贼替他辩护。</span><br></pre></td></tr></table></figure><h3 id="既定观点用词、诉诸情感"><a href="#既定观点用词、诉诸情感" class="headerlink" title="既定观点用词、诉诸情感"></a>既定观点用词、诉诸情感</h3><p>既定观点词语</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">公元前209年，陈胜和吴广发动大泽乡起义，建立张楚政权，反抗暴秦苛政</span><br></pre></td></tr></table></figure><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="双管问题（一题多问）"><a href="#双管问题（一题多问）" class="headerlink" title="双管问题（一题多问）"></a>双管问题（一题多问）</h3><p>指在一个问题以合取（且）或析取（或）等方式组合多个子问题，却只允许简单的答案。</p><blockquote><p>有多个可能性：小明是职业选手，但不厉害；小明不是职业选手，但很厉害；小明不是职业选手，也不厉害。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：小明是不是厉害的职业选手？</span><br><span class="line">乙：不是。</span><br><span class="line">甲：哦，所以小明是不厉害的职业选手</span><br></pre></td></tr></table></figure><blockquote><p>投反对票的人可能认为：应加入世界金融组织，且不应改善经济；不应加入世界金融组织，且应改善经济；不应加入世界金融组织，且不应改善经济。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">公投题目：“是否赞成我国加入世界金融组织以改善经济？”</span><br><span class="line">投票结果，反对票多于赞成票。</span><br><span class="line">评论者：“多数民众认为没有改善经济的需要。”</span><br></pre></td></tr></table></figure><h3 id="两难推理（非黑即白、伪二分法）"><a href="#两难推理（非黑即白、伪二分法）" class="headerlink" title="两难推理（非黑即白、伪二分法）"></a>两难推理（非黑即白、伪二分法）</h3><h3 id="否认对立"><a href="#否认对立" class="headerlink" title="否认对立"></a>否认对立</h3><p>当某人在需要从两个相互排斥的陈述中作出选择的情况下，没有选择其中一个，而是引入了第三个选择时，这个谬误可能会发生。这通常是为了分散注意力，而使得自己不必在可能两个选项之间做出选择。</p><p>有点类似于“不相干的谬误”，更类似于打岔。</p><blockquote><p>人们期望得到“是”或“不是”的答案，而这也是这种问题的唯一可接受的答案；但乙却通过提供第三个答案选项来转移问题，使原来的问题没有得到回答。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：你杀了路人甲吗？</span><br><span class="line">乙：我和他打过架。</span><br></pre></td></tr></table></figure><h3 id="打压对立"><a href="#打压对立" class="headerlink" title="打压对立"></a>打压对立</h3><p>借由修改对立概念的定义，使对立概念难以发生，藉以宣称某概念的普遍性</p><blockquote><p>此例将“快”的外延缩小，使“快”难以发生，而且“快”是一个相对概念，车子没有比战斗喷射机快，不等没有比其他多数车辆快。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：我的车可以跑很快。</span><br><span class="line">乙：它能比战斗喷射机快吗？我想不行，所以它并不快。</span><br></pre></td></tr></table></figure><h3 id="诉诸纯洁（没有真正的苏格兰人）"><a href="#诉诸纯洁（没有真正的苏格兰人）" class="headerlink" title="诉诸纯洁（没有真正的苏格兰人）"></a>诉诸纯洁（没有真正的苏格兰人）</h3><p>在普遍宣称遇到反例时，提出理想的标准为其辩护。</p><blockquote><p>此例“真正的苏格兰人”有歧义，一为甲自行的定义，二为通俗的理解。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：没有苏格兰人会在粥里加糖。</span><br><span class="line">乙：我是苏格兰人，我会在粥里加糖啊。</span><br><span class="line">甲：好吧，“真正的”苏格兰人不会在粥里加糖。</span><br></pre></td></tr></table></figure><h1 id="常见逻辑错误辨析"><a href="#常见逻辑错误辨析" class="headerlink" title="常见逻辑错误辨析"></a>常见逻辑错误辨析</h1><h2 id="劝学"><a href="#劝学" class="headerlink" title="劝学"></a>劝学</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">蟹六跪而二螯，非蛇鳝之穴无可寄托者，用心躁也。</span><br></pre></td></tr></table></figure><ul><li>倒果为因<br>  “蟹六跪而二螯”可能是它为了寄生而进化的结果。</li><li>以偏概全<br>  这篇《劝学》的观点是“用心一”能够取得成功，但这是以偏概全的。决定是否成功的因素是多种多样的。</li><li>类比失当<br>  用动物本能现象论证人类主观能动性问题，两类事物本质不同（生物学现象 vs 主观意志），导致类比失效。<br>  具体来说，这里发生了拟人化谬误。</li></ul><h2 id="一则知乎上的评论"><a href="#一则知乎上的评论" class="headerlink" title="一则知乎上的评论"></a>一则知乎上的评论</h2><p>以下分别为原文和修复语法错误之后的文字</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">觉得6千少的可以走人，现在不是封建社会，而不是为了私欲核爆公司领导隐私，企图把作为领导也好朋友也好全都拖累。何况小李到现在都还在林身边工作，小李都能一直干，那证明奖金少不了。</span><br><span class="line"></span><br><span class="line">觉得6千工资少的可以走人，而不是为了私欲核爆公司领导隐私，企图把领导和好朋友全都拖累。何况小李到现在都还在林身边工作，小李都能一直干，那证明奖金少不了。</span><br></pre></td></tr></table></figure><ul><li>诉诸情感、既定观点用词<br>  “为了私欲核爆公司领导隐私，企图把领导和好朋友全都拖累”这种表述试图通过激发读者的道德情感来影响判断，而不是基于事实和逻辑进行论证。<br>  它并没有根据具体的事实或逻辑依据来证明某人的行为是否合理。</li><li>类比失当、诉诸权威<br>  具体表现：“小李都能一直干，那证明奖金少不了”。<ul><li>这里将小李的情况错误地类比为其他人的处境。小李能够一直工作并获得奖金，不能直接证明其他人也会有同样的待遇。这种类比忽略了个体差异和其他可能影响奖金的因素，如工作表现、公司政策变化等。</li><li>暗示小李的选择是权威的。这种表述试图通过小李的行为来证明某种观点的正确性，而没有考虑小李的行为是否合理或是否适用于其他人。它依赖于小李的权威性，而不是基于事实和逻辑的论证。</li></ul></li><li>滑坡谬误<br>  暗示核爆公司领导隐私，会拖累好朋友。然而，核爆领导隐私并不一定会拖累好朋友。<br>  这种说法假设了一个极端的负面后果，而没有提供任何证据或逻辑链条来支持这种后果的必然性。</li><li>因果谬误<br>  暗示领导是因为被“核爆公司领导隐私”而被拖累的。这种观点<strong>可能</strong>错误地将因果关系颠倒了。<br>  比如，如果曝光的是一件丑闻，那么它本身的存在才是损害领导形象的根本原因，而不是揭露的行为。揭露丑闻的人只是让公众知晓了这一问题，从而促使解决问题，防止类似事件再次发生。</li><li>单因谬误<br>  具体表现：“小李都能一直干，那证明奖金少不了”。<br>  这种说法忽略了其他可能影响奖金的因素。仅仅因为小李能够一直工作并获得奖金，就认为其他人也会有同样的待遇。</li><li>不当关联<br>  “觉得6千工资少”、“走人”、“为了私欲”、“核爆公司领导隐私”之间并没有必然的逻辑联系：<ul><li>“觉得6千工资少”可能只是生活所迫，而并非“为了私欲”。</li><li>“核爆公司领导隐私”并不一定是“为了私欲”，可能是出于主张公道而一时冲动。</li></ul></li><li>双管问题<br>  “走人”、“核爆公司领导隐私”并不是互斥关系，可以两个都做，也可以两个都不做，或者只做其中一个。</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://zh.wikipedia.org/wiki/Category:%E9%9D%9E%E5%BD%A2%E5%BC%8F%E8%AC%AC%E8%AA%A4" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Category:%E9%9D%9E%E5%BD%A2%E5%BC%8F%E8%AC%AC%E8%AA%A4</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍下常见的形式谬误和非形式谬误。&lt;/p&gt;</summary>
    
    
    
    
    <category term="逻辑" scheme="http://www.calvinneo.com/tags/逻辑/"/>
    
  </entry>
  
  <entry>
    <title>Raft learner</title>
    <link href="http://www.calvinneo.com/2025/01/19/raft-learner/"/>
    <id>http://www.calvinneo.com/2025/01/19/raft-learner/</id>
    <published>2025-01-19T10:07:22.000Z</published>
    <updated>2025-03-14T04:52:06.704Z</updated>
    
    <content type="html"><![CDATA[<p>TiFlash 的整个 replication 机制建立在 Raft learner 协议之上。</p><p>在本文中介绍 Raft learner 相关的 case 以及优化，主要包括：</p><ul><li>涉及 Learner 的活性问题</li><li>Learner Snapshot</li><li>Learner Read<ul><li>作为前置，还会说明 Leader 的 Lease Read</li><li>作为直接的扩展，还会说明 Stale Read</li></ul></li></ul><a id="more"></a><p>本文大部分是从 <a href="/2023/07/22/tikv-tidb-thought/">关于 TiKV、TiDB、TiFlash 的一些思考</a>中取出的，并进行了扩展。</p><h1 id="Learner-的总体作用"><a href="#Learner-的总体作用" class="headerlink" title="Learner 的总体作用"></a>Learner 的总体作用</h1><ul><li>新增的 Voter 节点以 Learner 角色先追进度</li><li>观测 Raft Group 中的数据变更</li><li>支持 Replica Read</li></ul><h1 id="Learner-peer"><a href="#Learner-peer" class="headerlink" title="Learner peer"></a>Learner peer</h1><h2 id="活性"><a href="#活性" class="headerlink" title="活性"></a>活性</h2><h3 id="Add-Learner"><a href="#Add-Learner" class="headerlink" title="Add Learner"></a>Add Learner</h3><p>Raft 中添加一个 Learner 并不需要经过该 Learner。我引入了一些<a href="https://github.com/pingcap/tidb-engine-ext/blob/raftstore-proxy/proxy_tests/proxy/v1_specific/region_ext.rs" target="_blank" rel="noopener">测试</a>来描述相关的行为。</p><p>但是，如果 Learner peer 始终不 ready，则它会变为 pending-peer 甚至 down-peer。</p><h3 id="Orphan-Learner"><a href="#Orphan-Learner" class="headerlink" title="Orphan Learner"></a>Orphan Learner</h3><p>Learner 尽管在 Raft Group 中，但不参与投票。所以当 Voter 节点因为 Region 被销毁（通常因为 merge）全部被销毁后，Learner 节点就无法找到 Leader 节点。对于 Voter 节点来说，这种情况它可以发起选举，然后发现其他节点上的 Tombstone 标记，从而确认 Region 已经被摧毁了。但因为 Learner 不参与投票，所以是无法发现这种情况的，从而僵死。</p><p>上述的卡死在之前需要等待 2h 之后触发存活性检查才会被发现，后续会发送一个 Tombstone 消息从而执行 gc peer 的操作。否则，就需要人工将僵死的 Region peer 设置为 Tombstone 状态。因此，后续进行了优化，将 Tombstone 消息的发送间隔调小。</p><p>Learner 可能因为多种原因导致丢失 Leader，从而变为孤儿节点：</p><ol><li>在 Region 销毁的场景如 CommitMerge，target region 的 Voter 至少可以在 Leader 销毁之后，因为超时触发选举，从而启动自毁。而 Learner 则不行，会 miss leader 然后卡死<br> 特别地，CommitMerge 本身对 Source Peer 也会有检查，这里还可能造成连环等待。比如如果在等待 Source 追数据，就会 Yield 为 WaitMergeSource。如果卡在 CommitMerge 上，那么后续的 RemovePeer 也无法执行。</li><li>在 ConfChange 中，如果删除了某个 Learner，但又没有能够将该日志复制给 Learner，那么稍后 Learner 就不会得到 Leader 的任何消息，从而一样卡死。</li><li>在 BatchSplit 中，如果新 Split 出来的 Region 在 TiFlash apply BatchSplit 命令前就在所有 Voter 节点中被删除的话，后续 TiFlash 节点即使 apply 完 BatchSplit，也无法再收到任何日志，因为 Leader peer 已经不存在了。</li></ol><h2 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h2><p>Raft Log GC 也需要 respect Learner 的进度，原因：</p><ul><li>诸如 TiFlash 这样的引擎，底层存储非 Rocksdb，因此不能直接 ingest。因此对 Raft Snapshot 进行转换存在大量 CPU 开销。并且，Snapshot 本身被用来 bootstrap 一个 Region peer，所以在它被处理完之前，无法处理后续的 append。因此，异步转换 Snapshot 的收益不是特别大，不如后续引入 Remote Decoder 去 offload 一部分开销。</li><li>进一步，如果 Snapshot 处理时间过长，则可能超过下一轮的 Raft Log GC，导致需要处理新一轮的 Snapshot，由此往复，该副本始终无法追齐进度。</li></ul><h3 id="Follower-Replication-和-Follower-Snapshot"><a href="#Follower-Replication-和-Follower-Snapshot" class="headerlink" title="Follower Replication 和 Follower Snapshot"></a>Follower Replication 和 Follower Snapshot</h3><p>Follower Snapshot 的好处有：</p><ol><li>因为是有处于一个 Zone 的 Follower 发送 Snapshot，所以可能更快。并且跨 Zone 流量也少</li><li>减少 Leader 的负担</li></ol><p>TiFlash 做了 Learner Snapshot，相比 Follower Snapshot，它甚至是一个异构的 Snapshot。CRDB 做了类似的工作，称为 <a href="https://www.cockroachlabs.com/docs/stable/architecture/replication-layer" target="_blank" rel="noopener">Delegate Snapshot</a>。TiKV 目前还不支持。</p><h1 id="Lease-read"><a href="#Lease-read" class="headerlink" title="Lease read"></a>Lease read</h1><p>为了讲明白 Learner Read，首先需要了解 Leader 的 Lease read，因此就在这里一起讨论了。</p><h2 id="Why-Lease？"><a href="#Why-Lease？" class="headerlink" title="Why Lease？"></a>Why Lease？</h2><p>如果没有 lease，那么 Raft 集群中读取要么就是提交一条新的日志，要么就是去询问所有的节点，从而确认自己依旧是 leader。lease 的作用是保证一段时间中，只有某个节点可能是 leader。</p><p>lease 的主要实现问题是，不同节点上的时间不一定一致，也就是可能出现 clock drift。</p><h2 id="是否有单独的-Lease-Leader？"><a href="#是否有单独的-Lease-Leader？" class="headerlink" title="是否有单独的 Lease Leader？"></a>是否有单独的 Lease Leader？</h2><p>CRDB 的实现中，有单独的 lease leader，而 TiKV 的 lease leader 一定是 raft leader。因此就形成了一些区别：</p><ol><li>在时钟依赖上，TiKV 依赖 NTP，CRDB 依赖 HLC。</li><li>在“谁操作读”上，TiKV 通过 Raft Leader 来读，crdb 通过 lease leader 来读。</li></ol><h2 id="Lease-绑定-node-还是-raft-group？"><a href="#Lease-绑定-node-还是-raft-group？" class="headerlink" title="Lease 绑定 node 还是 raft group？"></a>Lease 绑定 node 还是 raft group？</h2><p><a href="https://www.cockroachlabs.com/docs/stable/architecture/replication-layer#epoch-based-leases-table-data" target="_blank" rel="noopener">CRDB</a> 将 Lease 和机器绑定而不是和 Data Range 绑定，从而减少网络开销。它的做法是每个 Data Range 的 “Leader” 会去维护一个 meta 表（也是一个 Data Range）上的 liveness 记录。我理解是以一个比较低的频率去更新 liveness 记录，因为<strong>如果不是节点挂了下线，或者是重新调度到当前 Raft Leader 的节点上</strong>这两种情况，Raft Leader 就还是同一个，那么就完全没有必要续期。而 TiKV 的绑定方式则必须要求 Lease 是比 Election Timeout 要短的。</p><p>当某个 node 宕掉之后，CRDB 还是要重新选出一个新的 Lease Leader，而这个<a href="https://www.cockroachlabs.com/docs/stable/architecture/replication-layer#how-leases-are-transferred-from-a-dead-node" target="_blank" rel="noopener">依旧是通过 Raft 选举来实现的</a>。</p><p>当然，对于 meta 表，就不能像上面那样去做了。否则会导致循环依赖。对于 meta 表自己的 Lease，是通过 expiration time 来维护的。此时：</p><ol><li>如果一个节点依旧能够不停地 propose，那么它就能够一直续期 lease</li><li>否则，下一个尝试对这个 range 读写的 node 会成为 leader</li></ol><h1 id="Learner-read"><a href="#Learner-read" class="headerlink" title="Learner read"></a>Learner read</h1><h2 id="关于读"><a href="#关于读" class="headerlink" title="关于读"></a>关于读</h2><p>Raft 的一个问题就是读的时候无论是 Leader 还是 Follower 都需要 Read Index。比如，对 Leader 而言，它需要问 quorum 自己当前是否还是 Leader。TiKV 一般 Leader Read 提供两种方案，第一种是 read_local，也就是 Leader 节点上 lease 读，另一种是 read_index，也就是在不确定自己是否还是 Leader 的时候，进行 ReadIndex。</p><h2 id="Follower-Read"><a href="#Follower-Read" class="headerlink" title="Follower Read"></a>Follower Read</h2><p>TiDB 支持<a href="https://docs.pingcap.com/zh/tidb/stable/follower-read" target="_blank" rel="noopener">多种读取方式</a>，例如最近 Peer、Leader、Follower、Learner、自适应等多种模式，这些依赖于 Follower Read，在这之前都需要从 Raft Leader 读取。</p><p>不同于 ParallelRaft 和 MultiPaxos 的部分实现，TiKV 会串行地 apply raft log。</p><ol><li>这样的好处是，更容易通过 Read Index 实现 Follower Read 了。TiKV 在这一点上行得通，主要还是因为它的数据和 Raft Group 绑定的缘故。也就是以 scheduler 为代价来实现 Partitioning，从而减少各个 Raft Group 的压力。</li><li>这样的坏处是，引入了更强的全序关系。因为我们实现共识层的目的是服务上层的事务层，而事务层本身就允许并行事务以任意的顺序被提交，所以在共识层排成强序，实际上是多余的。当然，Partitioning 分成多个 Raft Group 能减少这部分的强序关系的数量。</li></ol><p>总的来说，TiKV 实现的 Follower Read，是通常被称作 <a href="https://www.cockroachlabs.com/docs/v23.2/follower-reads" target="_blank" rel="noopener">Strong Follower Read</a> 的类型。</p><h2 id="Non-stale-Read"><a href="#Non-stale-Read" class="headerlink" title="Non-stale Read"></a>Non-stale Read</h2><p>从共识层上来讲，强一致或者说线性一致有明确的定义。<a href="https://www.cockroachlabs.com/docs/v23.2/architecture/transaction-layer" target="_blank" rel="noopener">CRDB</a>将其“推广”到事务层之上，也就是归结到所谓的 non-stale 读上。因为 CRDB 只有 leaseholder 也就是所谓的 Leader 能服务读请求。不过还是推广到有 Follower Read 的场景下。此时，在任意的节点上：</p><ol><li>在 SERIALIZABLE 下，读事务应该能看到在<strong>它之前</strong>已经提交了的所有的写事务。这里的“<strong>它之前</strong>”我理解取决于如何给事务排序，但至少要在事务的第一个读之前。比如 Percolator 模型中就是 start_ts。</li><li>在 RC 级别上，事务中的每一个读语句能看到在<strong>它之前</strong>已经提交了的所有的写事务。</li></ol><h2 id="Stale-Read"><a href="#Stale-Read" class="headerlink" title="Stale Read"></a>Stale Read</h2><p>Stale Read 的作用是让读请求被分配到任一节点上，从而避免某热点机器，或者跨数据中心的 read index 请求产生的延迟。</p><p>这样的事务只能服务读，并且 staleness 也是需要被严格控制的。</p><p>Stale Read 是读 ts 时间点上所有已提交事务的旧数据。因为读不到最新的写入，所以不是强一致的。但它仍然保持有<a href="https://docs.pingcap.com/zh/tidb/stable/stale-read" target="_blank" rel="noopener">全局事务记录一致性</a>，并且不破坏隔离级别。我理解可能就是所谓的 Time travel query。</p><p>一般提供两种：</p><ol><li>精确时间戳</li><li>有界时间<br> 在给定的时间范围内选择一个合适的时间戳，该时间戳能保证所访问的副本上不存在开始于这个时间戳之前且还没有提交的相关事务，即能保证所访问的可用副本上执行读取操作而且不会被阻塞。<br> 因此这样的读取方式能提高可用性。</li></ol><p>使用 Stale Read 需要 NTP 的支持。</p><p>所以它并不是“弱一致读”，无论从哪一个节点返回的结果都是一致的，不会出现 A 返回 1000 笔记录，而 B 返回 1111 笔记录的情况。</p><h2 id="Learner-Read"><a href="#Learner-Read" class="headerlink" title="Learner Read"></a>Learner Read</h2><p>不同于 Follower，Learner 不是 Voter，没有选举功能。所以 Learner Read 和 Follower Read 有不同。<br>Learner Read 在 TiFlash 场景下更为丰富，在 TiFlash 章节讨论。</p><h3 id="Learner-Read-和-commit-ts"><a href="#Learner-Read-和-commit-ts" class="headerlink" title="Learner Read 和 commit_ts"></a>Learner Read 和 commit_ts</h3><p>即使有在 read index 的时候推进 max ts 的机制，依然会发生在收到 Leader 关于带有 read_ts 的 Read Index 请求的回复后，在 Wait Index 超过返回的 applied_index 之后，看到具有更小的 commit_ts 的提交。但这种情况并不会导致问题，因为在 applied_index 之前，我们至少可以看到对应的锁。</p><p>比如 read_ts 是 10，返回了 applied_index 是 1000。那么在 apply 到 1001 时，可能它对应了一个 commit_ts 为 5 的事务。这里可以参考<a href="/2025/01/18/percolator-2/">我对并发事务的讨论</a>。</p><h4 id="Learner-Read-和乱序-apply"><a href="#Learner-Read-和乱序-apply" class="headerlink" title="Learner Read 和乱序 apply"></a>Learner Read 和乱序 apply</h4><p>如果将 Data Range 和 Raft Group 分开，仍然是可以实现 Learner Read 的。<strong>因为本质上 Learner Read 是基于 RSM 做的</strong>。<br>假如 Data Range 和 Raft Group 不绑定了，一个 Raft Group 会维护多个 Data Range 上的数据。但如果把 Data Range 看成一个 RSM，那这种架构就类似于一个 Raft Group 去管理多个 RSM。我们在 Data Range 上维护一个 index，应该就行了。</p><p>在<a href="/2017/09/21/distributed-consistency/">分布式一致性详解</a>中的“线性一致与提交顺序”中，我们进一步进行了说明。</p><h2 id="Read-index"><a href="#Read-index" class="headerlink" title="Read index"></a>Read index</h2><p>TiFlash 自己给自己发送一个 ReadIndex Command，后者会触发一个 ReadIndex Message。为什么要这么做呢？因为走 ReadIndex Command 的链路才是完整的，否则会丢掉包括要求 Concurrency manager 推高 max_ts 的部分。</p><ol><li>对 Leader，会检查 Lease 并续约，之后再 Read</li><li>对 Follower，会推动 Raft 发送 RaftIndex 类型的 RaftMessage 给 Leader。这个 RaftMessage 包含一个 raft_cmdpb::ReadIndexRequest 作为 entry.data。</li></ol><p>在处理 ReadIndex RaftMessage 时候，会推进 maxts 并且返回 memlock。</p><p>具体来说：</p><ol><li>根据 read tso 和 range 构造一个 kvrpcpb::ReadIndexRequest</li><li>ReadIndex 接受这个 kvrpcpb::ReadIndexRequest</li><li>创建一个 raft_cmdpb::Request<br> 其类型为 CmdType::ReadIndex。将 kvrpcpb::ReadIndexRequest 中的数据移动到 raft_cmdpb::Request 中。</li><li>通过 RaftRouter 发送这个请求，并等待回调。</li></ol><p>这里 ReadIndexRequest 中传入的 start_ts 会间接推高 min_commit_ts。其原理是一个事务涉及多个 key，则这些 key 依次 prewrite 的时候，后面 prewrite 的 key 的 min_commit_ts 会因为 max_ts 变得更高，尽管前面 key 的 min_commit_ts 是一直不变的。最终事务提交的 ts 是所有的 key 的 min_commit_ts 取最大。</p><h3 id="Batch-read-index"><a href="#Batch-read-index" class="headerlink" title="Batch read index"></a>Batch read index</h3><ol><li>在同一个查询中，如果一个 Region 上已经被做过 read index，则复用</li><li>在同一个 Region 上的每个 Read index 请求前，首先查询历史记录，看看是否有对应 ts 的记录可以复用</li><li>同一个 Region 上的多个 Read index 请求组成一个 batch，用其中的最大的 ts 去请求 TiKV leader。如果发现有 memlock，则返回这个 lock。这说明这个 ts 上有 lock，而其他的 ts 则不确定需要重试。如果返回没有 lock 则使用最大的 index 来重试</li></ol><p>注意，没有 memlock 并不代表没有 lock。一个 key 上是否有 lock，还需要读 lock cf 来判断。memlock 的引入是 Async Commit 导致的。memlock 指的是在某个短暂阶段，事务层上有一些锁在内存中，还没有写到 raftstore。</p><h2 id="Remote-Read-机制"><a href="#Remote-Read-机制" class="headerlink" title="Remote Read 机制"></a>Remote Read 机制</h2><p>TiFlash 中存在 Remote Read 机制，在 BatchCop 的 prepare 阶段，会分析哪些 Region 是可以本地读的，哪些 Region 是需要从其他 TiFlash 读的。在存算分离版本的 TiFlash 中，CN 通常都需要进行 Remote Read 从对应的 WN 读取最新的数据。</p><p>在 Remote Read 的过程中，也会触发 Resolve Lock 机制，从而推动 TiKV 去判断事务提交与否。这个通常对应了 Cop 请求的发送和处理。Remote Read 请求可能最终还是发送给自己。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;TiFlash 的整个 replication 机制建立在 Raft learner 协议之上。&lt;/p&gt;
&lt;p&gt;在本文中介绍 Raft learner 相关的 case 以及优化，主要包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;涉及 Learner 的活性问题&lt;/li&gt;
&lt;li&gt;Learner Snapshot&lt;/li&gt;
&lt;li&gt;Learner Read&lt;ul&gt;
&lt;li&gt;作为前置，还会说明 Leader 的 Lease Read&lt;/li&gt;
&lt;li&gt;作为直接的扩展，还会说明 Stale Read&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="raft" scheme="http://www.calvinneo.com/tags/raft/"/>
    
    <category term="一致性" scheme="http://www.calvinneo.com/tags/一致性/"/>
    
  </entry>
  
  <entry>
    <title>TiFlash 的快速新建副本(FAP)特性</title>
    <link href="http://www.calvinneo.com/2025/01/19/on-fap/"/>
    <id>http://www.calvinneo.com/2025/01/19/on-fap/</id>
    <published>2025-01-19T03:57:20.000Z</published>
    <updated>2025-08-19T11:57:52.497Z</updated>
    
    <content type="html"><![CDATA[<p>目前 FAP 特性在 TiDB Serverless 上已经发布，减少了新建副本的 CPU 和内存开销，提高了吞吐量。在大部分情况下，还能</p><a id="more"></a><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><ol><li>复用 TiFlash 行转列的结果。减少 TiKV 生成、传输和 TiFlash 接收、转换 Snapshot 的开销。<br> 在测试中，发现能够减少 96% 的 CPU 开销和 20% 的内存开销。<br> 如果提升调度的 limiter，能够大幅提高吞吐量，体现为添加副本总时间的减少。但该增长不是线性的，也取决于 TiFlash 侧线程池的大小，以及串行 ingest 的开销。<br> 需要注意，因为 Region 和 Raft Group 绑定，导致 FAP 必须等待 apply Confchange 之后的 Checkpoint，所以对于单个小 Region 来说，可能要花费更长的时间来处理。<br> 目前，TiFlash 上会有一些自建索引，FAP 也会避免这些自建索引被重复构建。</li><li>利用如 S3 的特性，减少跨 Region 通信。</li><li>提高副本迁移，特别是单副本迁移的效率。</li><li>在扩容场景下，新节点可能因为处理全量 Snapshot 更慢，导致进度落后，从而进一步触发全量 Snapshot。此时新机器无法处理被 dispatch 过来的请求。</li></ol><h2 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h2><h3 id="实现内容"><a href="#实现内容" class="headerlink" title="实现内容"></a>实现内容</h3><ol><li>使用 PageStorage 替换 RaftEngine。这样使得 Raft、KVStore 和 DeltaTree 数据都一起被存到同一个 checkpoint 里面，保证原子性和一致性。</li><li>副本选择和由 Learner 管理的副本创建。用来快速扩容的 TiFlash Checkpoint，必须要比扩容对应的 confchange log entry 要新。这是因为 TiKV 通过一个 Snapshot 来帮助新 node 追日志，而这个 Snapshot 必然在 confchange 后产生。如果接受一个更早的 Checkpoint，那么就要确保 raft 能够给新 peer 发送 confchange 前的日志。即使能，这也意味着新 peer 要处理添加自己的 confchange cmd。即使通过忽略等方案处理，那么在这之前的 batch split cmd 就需要伪装成生成 Checkpoint 的那个 peer，并将这个 region 重新切开（涉及一些行转列和写盘）。而如果与此同时，batch split 得到的某个 split 的最新版本又通过正常途径调度过来，并且在 apply snapshot，那么这里就可能产生 region overlap 导致的数据问题。可以看出，因为违反了 TiKV 的约束，所以产生了很多的潜在问题。</li><li>注入数据。需要注意，原有的 TiKV 的通过 Snapshot 初始化副本的流程需要重新走一遍。</li><li>对旧版本数据的清理。</li></ol><h3 id="Learner-Snapshot"><a href="#Learner-Snapshot" class="headerlink" title="Learner Snapshot"></a>Learner Snapshot</h3><p>这个 feature 类似于 Learner Snapshot，其实后续我们也希望在 TiKV 实现 Learner Snapshot。目前方案的原因是：</p><ol><li>TiKV 主要需要该 Feature 来避免跨地区的 Snapshot 复制，而 TiFlash 需要该 Feature 实现异构的 Snapshot，侧重点上有所不同。</li><li>该 feature 需要在 TiKV 或者 PD 等组件中实现一定的调度机制。所以 FAP 实际可以视为一个部分的实现，后续有可能进行推广。届时 FAP 的 phase 1 过程就有可能被移动到 prehandle snapshot 中处理了。</li><li>Follower Snapshot 有可能会失败，例如 Follower 节点实际上做不了该 Snapshot。此时 Snapshot 依然会由 Leader 来处理。目前 TiKV 的模型还不支持这种模式。</li></ol><h3 id="从-FAP-的-fallback"><a href="#从-FAP-的-fallback" class="headerlink" title="从 FAP 的 fallback"></a>从 FAP 的 fallback</h3><p>FAP 可以实现从 FAP Snapshot 到 Regular Snapshot 的 fallback。具体来说，如果构建失败后，FAP 就会退出，此时对 MsgAppend 的屏蔽就会被去掉，从而走到 Regular Snapshot 的逻辑中。而 FAP Snapshot 在构建完后，会发送一个 meta 等同于 Regular Snapshot 的 Snapshot，只是不包含数据而已。在 Prehandle Snapshot 的逻辑中，会先检查是否存在 FAP Snapshot 并且它的 <code>(snapshot_index, snapshot_term)</code> 是否 meta 中匹配。如果不匹配，说明这是后来的一个 Regular Snapshot，需要覆盖 FAP Snapshot。如果匹配，那么无论这个 Snapshot 是否包含数据，都是和 FAP Snapshot 等价的。</p><h3 id="云上存储结构"><a href="#云上存储结构" class="headerlink" title="云上存储结构"></a>云上存储结构</h3><p>TiFlash 的云上存储主要包含 Manifest File 和 Data File。Manifest File 是一个 Page Directoy，大概是几十 M 的大小。Data File 则是 PageStorage 的 blob file。另外，和列存相关的 DMFile 也会被单独上传。这些被 blob file 和 DM File 都会被 GC Worker 定期地清理掉。</p><p>在生成 Data File 的时候，会扫描增量的数据。同时会执行 Compaction，只保留同一个 Page ID 的最新版本。</p><h3 id="pitfall"><a href="#pitfall" class="headerlink" title="pitfall"></a>pitfall</h3><h4 id="和-raftstore-相关"><a href="#和-raftstore-相关" class="headerlink" title="和 raftstore 相关"></a>和 raftstore 相关</h4><ul><li>如果一个 FAP Snapshot 已经被发送了，那么就需要等待它被处理完毕。所以后面我们通过记录 <code>(snapshot_index, snapshot_term)</code>，这样我们就无所谓 FAP Snapshot 的状态了。只要完成发送，就可以恢复 MsgAppend。事实上，后续发现了 cse 上因为限流原因发送 FAP Snapshot 失败的情况，此时，真正的 Raft Leader 发来了一个 Snapshot。因为这边的处理逻辑是有对应的 FAP Snapshot 就复用该 Snapshot，所以这种情况我们也能处理。</li><li>如果需要发送 msgAppend 时候，Leader 的日志被 truncate 掉了，那么就需要直接发送 msgSnapshot</li><li>如果收到一个 msgSnapshot，需要判断它是 Leader 发过来的要直接被屏蔽的 msgSnapshot，还是 FAP 自己的 snapshot。这里的办法就是如果 FAP snapshot 发出去了，那么无论是哪一种 Snapshot，都不再拒绝了。在 prehandle 的时候，会比较 FAP snapshot 的 (index, term) 和 Raft Snapshot 的 (index, term)，只要不一致，就 abort 掉 FAP snapshot 的处理并清理掉。</li><li>使用 <code>inited_or_fallback</code> 维护一个内存中的状态，如果 fallback，或者 apply snapshot，或者看到 <code>RegionChangeEvent::Create</code> 事件，或者通过 <code>is_initialized</code> 读取 meta 信息检查到副本在 raftstore 中已经创建了，则跳过 fap。特别是最后一点很重要，因为 <code>apply_snapshot</code> 这个函数调用和 Proxy 是异步的，所以 <code>apply_snapshot</code> 之后，<code>is_initialized</code> 返回 true 表示 snapshot 已经 apply 了，只等待 ingest 数据。这个时候，就需要将 <code>inited_or_fallback</code> 设置为 true 才行，不然会导致 fap snapshot 覆盖。但因为我们在 <code>apply_snapshot</code> 的时候没有 hook，所以只能随时检测。</li><li>restore 后的 apply snapshot 可能会被重放。</li></ul><h4 id="和性能相关"><a href="#和性能相关" class="headerlink" title="和性能相关"></a>和性能相关</h4><ul><li>raftstore 线程会直接轮询 FAP builder 线程的结果，如果发现超时，会 cancel。这里的 cancel 是一个 blocked 的过程，因为必须确保可能写入的 FAP snapshot 被删除才行。这就要求 FAP builder 线程不能被 block 住。在过去，我们有一个 cache 去缓存 segment meta 信息，所有请求同一个表的 FAP 任务会 block 地等待其中一个任务构建 cache。因为 raftstore 线程显著少于 FAP 线程，所以会导致如果 build cache 任务超时，则没有 raftstore 线程可以去取消对应的 FAP 任务。后续因为这个 cache 的复用率不是很高，所以我们直接把 cache 干掉了，所以 FAP 上不会有 block 了。另外，我们也实现了 async cancel 的机制，因为 raftstore 在轮询，所以只要发现超时之后，可以直接 async cancel，然后在后续的轮询中，不断查询 Cancel 状态即可。</li><li>S3 的访问延迟还是比较大的。看 P99，线上最高的 PutObject 在 1.5s，GetObject 在 500ms。</li><li>并发较高的时候，对 CPU 的开销较大，同时可能触发 S3 的限流。<br>  解决方案主要是：<ul><li>利用 PageStorage 的 data locality。</li><li>缓存<ul><li>先前我们 cache 的 segment meta 信息，但并不是很顺手。因为 segment 很多的时候，总是需要遍历完所有的 segment 才能够返回结果。如果构建 cache 对应的线程要找的 segment 在很后面，构建 cache 就会很慢，从而会造成之前阻塞的情况。</li><li>后面我们是通过缓存的 <code>(file_name, offset) -&gt; data</code> 来处理的。这里同样是利用了局部性，但是因为 cache 的粒度变小了，对应的 block 现象也会变小。</li></ul></li></ul></li><li>TiFlash 大量使用 LIST 去轮询 S3 上的状态。一般来说，LIST 的 qps 要低于 1000，否则会造成比较严重的读放大。FAP 中主要使用 LIST 来追踪某个 Region 对应的 Checkpoint 的上传状态，所以 LIST 的并发是和 FAP 的并发相关的。</li></ul><h2 id="FAP-对-UniPS-的改造"><a href="#FAP-对-UniPS-的改造" class="headerlink" title="FAP 对 UniPS 的改造"></a>FAP 对 UniPS 的改造</h2><ol><li>Checkpoint 中不仅需要上传 Stable 数据，也要上传 Delta 和 Raft Log 数据<br> 原因是必须要上传对应的 Raft Meta 数据才能构建出副本。由此，必须要上传 KVStore 和 Delta 层。此时唯一的可选项就是 applied_index 之后的没有被 apply 的日志了。目前是同样选择上传的，原因是代价可控。并且上传了 Raft Log 后，能够避免新建立的副本从 TiKV Leader 处继续下载这些 Log，从而造成新一轮的落后。<br> 理论上，上传 Delta 数据后，CN 可以从 S3 去读取这些 Delta 数据，从而避免重复请求 WN。我们现在没有做主要是发现 Delta 层的数据流处理没有给 TiFlash 产生太大的性能开销。<br> 在上传 Raft Log 和 Meta 数据后，甚至可以在 CN 上处理 Learner Read 强一致读。但这可能得不偿失，因为读 S3 的开销可能更大。并且我们还是要在 CN 上实现一套 Read Index 的。<br> 相比之下 Snowflake 将事务层移动到 Cloud Service 层上，从而使得可以直接从 S3 读存储层。但可能它们的写入场景应该没有 TiFlash 频繁。</li><li>S3 文件的读写<br> 过去 UniPS 使用了 Lazy 的方式处理 FAP 添加得到的 Page，在 write 的时候只是记录远程的 Page 在 S3 blob file 中的 offset 和 size，在第一次读取的时候，才将这些 Page 下载下来。但在上传 Delta 和 Raft 数据后，需要处理的 Page 数量明显变多了。如果对于每一个 Page 调用一次 GetObject API 花费几十到几百毫秒下载，代价对于可能有几万 Page 的 Region 来说是无法承受的。<br> 这里通过 Prefetch + Reuse 的方式可以优化掉存在顺序读的部分，而顺序读的场景是占大多数的。因为上传 Checkpoint 的时候，会对所有的 Page 按照 PageID 的顺序进行 Compaction，以避免 S3 的空间放大。因此只要按照 page id 的顺序遍历，实际上就是顺序读写 blob file，就可以用上优化。<br> 对于零散的小写入，我们是利用了操作系统的 page cache 来避免大量小 io。</li><li>S3 文件的锁<br> 为了避免 FAP 引用的 blob file 被 GC，引入了 S3 文件锁。这里的做法是对于每一个 blob file，都可能存在多个 <code>${data_file_name}.lock_${store_id}</code> 文件，表示这个 blob file 被哪些 store 引用。只有一个 blob file 上没有关联 lock 文件的时候，才会清理掉。</li></ol><h1 id="个人感悟"><a href="#个人感悟" class="headerlink" title="个人感悟"></a>个人感悟</h1><h2 id="兼容性"><a href="#兼容性" class="headerlink" title="兼容性"></a>兼容性</h2><p>FAP 的兼容问题，主要是在自己构造 FAP Snapshot 上。因为构造 Snapshot 的逻辑只有 TiKV Leader 上有，所以里面有两块考量：</p><ul><li>之前说的 Follower/Learner Snapshot</li><li>CSE TiKV 相对于 TiKV Master 上产生了大量的改动</li></ul><p>这两个就导致了 FAP 的设计考虑是：</p><ul><li>要走完 Normal Snapshot 的所有流程，让这个 Snapshot 首先对 TiKV 来说是合法的，避免任何的 stale snapshot 或者 overlap range 的问题</li><li>要避免 TiKV 上任何错误对可用性产生的影响，例如：<ul><li>后续观察到 CSE 上 Learner 发送 Snapshot 给自己可能会被限流</li><li>提供 Checkpoint 的 TiFlash 上的 Proxy 可能会非常 eager 地 truncate raft log，从而可能产生 commitIndex 对应的 log 不存在的情况</li><li>CSE 上可能对 Snapshot 有其他的定制</li></ul></li></ul><p>这里，我们主要通过 (index, term) 相等的 Snapshot 一定是相同的这个特性来处理。即使后续有了 raftstore v2，也可以使用 orphan keys 机制来处理。</p><h2 id="上线"><a href="#上线" class="headerlink" title="上线"></a>上线</h2><p>上线过程中的逃逸路径的设计非常重要。在 TiFlash 存算分离上线的过程中，使用了双写的方式来避免影响生产环境。在一个月确认稳定后，正式开启这个特性。</p><p>FAP 的场景下，采用的方法是只对一个 TiFlash replica 开启 FAP 特性。并且我们在 CN 上增加了一个 blocklist 功能，如果这个节点因为 FAP 损坏，则可以立即设置 blocklist 将它屏蔽。此时，至少还有一个节点可以服务。而在过去，一个节点如果宕机，其实在它上面的查询会死掉，从而影响可用性。</p><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;目前 FAP 特性在 TiDB Serverless 上已经发布，减少了新建副本的 CPU 和内存开销，提高了吞吐量。在大部分情况下，还能&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>关于 Percolator 的进一步论述</title>
    <link href="http://www.calvinneo.com/2025/01/18/percolator-2/"/>
    <id>http://www.calvinneo.com/2025/01/18/percolator-2/</id>
    <published>2025-01-18T03:57:20.000Z</published>
    <updated>2025-01-18T16:59:15.825Z</updated>
    
    <content type="html"><![CDATA[<p>将 <a href="/2023/07/22/tikv-tidb-thought/">关于 TiKV、TiDB、TiFlash 的一些思考</a>中关于 Percolator 事务的部分独立出来。</p><a id="more"></a><h1 id="Percolator-的性能优化"><a href="#Percolator-的性能优化" class="headerlink" title="Percolator 的性能优化"></a>Percolator 的性能优化</h1><h2 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h2><p>Percolator 主要定义了事务提交模型，因此有一些不够完备的地方：</p><ul><li>对于提交前的行为没有作规定<ul><li>Modify Set 的储存方式</li><li>Snapshot Isolation Read 的实现方式，当然 SI Read 一般都是在 Snapshot 上基于 MVCC 实现的</li></ul></li><li>对于悲观事务的支持</li></ul><p>在性能上，也有一些缺点：</p><ul><li>依赖一个 BigTable 类似的一致性 KVStore 作为底座。容易产生跨节点的分布式事务。这种情况下，Percolator 也是 2PC 的，任何一个参与节点的 failure 或者 jitter 都会影响事务提交的性能。</li><li>乐观事务，回滚开销大。</li><li>依赖一个全局单点生成时间戳为事务定序。</li></ul><h2 id="加锁的时机"><a href="#加锁的时机" class="headerlink" title="加锁的时机"></a>加锁的时机</h2><p>无论是悲观锁还是乐观锁，都面临加锁时机的选取。</p><p>在提交时加锁存在下面的问题：</p><ol><li>乐观锁的问题</li><li>因为整个事务需要缓存在内存中，所以大事务面临 OOM</li></ol><p>在 DML 时加锁存在下面的问题：</p><ol><li>每写一个 key 都要和 TiKV 通讯一次</li><li>多次对同一个 key 的 prewrite 无法确认先后（网络可能被任意延迟）</li><li>对 TiFlash 而言，因为列需要按照 commit_ts 排序，所以最好等到 commit 之后再行转列，而 DML 加锁意味着 DML 阶段 prewrite，那么在 DML 阶段就可以行转列了</li></ol><h2 id="Percolator-事务和共识层乱序"><a href="#Percolator-事务和共识层乱序" class="headerlink" title="Percolator 事务和共识层乱序"></a>Percolator 事务和共识层乱序</h2><p>在什么程度上共识层可以乱序呢？我的结论是：</p><ol><li>跨 Region 情况下会破坏线性一致读，并且从事务层修正的难度比较大，可能引入很长的等待</li><li>单 Region 上，如果保证 Lock 和 Write 的全局序，但只在发现事务 A 的第一个 commit 的时候，将事务相关的所有的 Default 写入，这种情况应该是可以的。对于较为基础的 case 我有 tla 证明<br> 根据具体实现，需要落盘 Default 和 Lock 是一起的，比如先落盘 Lock 再落盘 Default。可以不用原子落盘两个 cf。</li></ol><h2 id="Async-Commit"><a href="#Async-Commit" class="headerlink" title="Async Commit"></a>Async Commit</h2><p>Async Commit 的核心思想是：</p><ul><li>在 Prewrite 阶段完成后，不需要等待所有键都被确认提交。</li><li>Primary Key 的提交操作即被视为事务完成，其它 Secondary Key 的提交可以异步完成。</li></ul><p>这使得事务提交延迟主要取决于 Prewrite 的耗时，而不是整个 2PC 流程。</p><p>实现方式是在每个 key 的 lock 中声明一个 min_commit_ts，表示事务不会在这个之前提交。后续的读取可能会继续推高 min_commit_ts。当事务提交时，需要选择所有 min_commit_ts 中最大的一个作为 commit_ts。</p><p>因此，在这个优化后，不同事务的 commit_ts 可能相同，但是 start_ts 依然是不相同的。</p><h2 id="Bypass-lock-机制"><a href="#Bypass-lock-机制" class="headerlink" title="Bypass lock 机制"></a>Bypass lock 机制</h2><p>这是 Learner read 层的优化。<br>TiFlash 存在 remote read 的机制。在第一次遇到 lock 的时候，会由 client-c 去 resolve lock。此时，会有几种情况：</p><ol><li>事务已经 commit 了，并且 commit_ts 大于 read_ts</li><li>事务还没有 commit，但是 min_commit_ts 大于 read_ts</li><li>其他情况</li></ol><p>对于第一、二种情况，我们不应该读到这个锁对应的数据。它们都保证了事务已经或者最终要以高于 read_ts 的 ts 来提交。因此，既然这个 lock 对应的写入是不需要对 read_ts 的读可见的，因此在下一次读的时候，就可以 bypass 掉这个 lock，而不需要等待它们的 commit 了。</p><h2 id="Read-through-lock-机制"><a href="#Read-through-lock-机制" class="headerlink" title="Read through lock 机制"></a>Read through lock 机制</h2><p>这是一个事务层的优化。<br>Read through lock 特性指的是当确定某个事务可以被 commit 的时候，跳过 resolve lock 的过程，而直接读。而这锁最终会被下一次写同一个 key 的时候 resolve。<br>具体做法是，它首先是事务上一个 secondary key 的锁，我们在通过 secondary lock 去查询 PK 的 lock 的时候，会发现 PK 上的事务提交了。因此，这个事务一定是提交了的，所以可以 read through lock。<br>这个“lazy”地 resolve lock 的方式也被用在了大事务的支持上。</p><h1 id="基于共识层之上的事务"><a href="#基于共识层之上的事务" class="headerlink" title="基于共识层之上的事务"></a>基于共识层之上的事务</h1><h2 id="事务的“序”"><a href="#事务的“序”" class="headerlink" title="事务的“序”"></a>事务的“序”</h2><h3 id="几个问题"><a href="#几个问题" class="headerlink" title="几个问题"></a>几个问题</h3><p>不妨考虑几个问题：</p><ul><li>是不是 start_ts 越大的事务，体现在 log index 上更大？commit_ts 呢？</li><li>两个事务可以有相同的 start_ts 么？</li><li>两个事务可以有相同的 commit_ts 么？</li><li>假设一个事务 [ST1, CT1] 准备提交了，它可以看到另一个事务 [ST2, ?]，并且 ST2 小于 ST1。请问此时它是否可以立即提交？</li></ul><p>答案：</p><ul><li>不一定<br>  参考下面的双重定序</li><li>不可以</li><li>可以<br>  比如 Async Commit 特性就会产生这样的现象。</li><li>不能<br>  参考“一个两难问题”</li></ul><h3 id="一个两难问题"><a href="#一个两难问题" class="headerlink" title="一个两难问题"></a>一个两难问题</h3><blockquote><p>假设一个事务 [ST1, CT1] 准备提交了，它可以看到另一个事务 [ST2, ?]，并且 ST2 小于 ST1。请问此时它是否可以立即提交？</p></blockquote><p>答案是不行，因为不知道 ST2 这个事务的 Commit TS 是多少。在一个异步系统中，这个消息总是可以被任意延迟的。</p><p>在 Percolator 中的解决方式是：ST2 意味着会读到一个 Lock，所以 ST1 这个事务要先 Resolve Lock。</p><p>这个问题，就展现了事务序和共识序之间的相互关联。这就如同之前全序广播中论述的一样，核心是能够确保消息被不重不漏地编号，例如 TCP 的 seq 一样。共识系统通过日志的全序性来保障了这一点。</p><h3 id="共识层和事务层的关系"><a href="#共识层和事务层的关系" class="headerlink" title="共识层和事务层的关系"></a>共识层和事务层的关系</h3><p>Percolator 事务提交模型中，commit_ts(R) &lt; start_ts(T) 的事务 R 对事务 T 可⻅。不满⾜该关系的事务为并发事务，并发事务如果访问相同的 key 将会导致其中⼀个事务会碰到 Lock ⽽回滚。因此，Percolator 本质上是一个 2PL 协议，因为一个事务会在 Prewrite 阶段尝试获得自己所有需要的锁。start_ts 此时被用来决议这些锁的 order。</p><p>Raft 的 Read Index 模型中，一个读请求需要等到 applied_index 大于等于 read_index 时，才能读取数据。<strong>但并不保证是否能读到 <code>applied_index = x + 1</code> 时的数据</strong>。实际上无论是否读到，都不违背强一致读的原则。因为如果一个读 A 能读到 applied_index = x + 1，而另一个读 B happen after 读 A，那么读 B 一定会读到 <code>applied_index &gt;= x + 1</code> 的数据。</p><p>TiKV 的共识层在事务层之下。在事务 Commit 之前的很多数据也会被复制到多数节点上，这产生了一些写放大。但也需要注意其带来的好处：</p><ol><li>共识层实际为 Percolator 提供了类似 BigTable 的一致性存储保障。<br> 首先提供了外部一致性。<br> 然后提供了 PUT default/PUT lock 和 PUT write/DEL lock 的原子性写入。<br> 当然，这里要先读后写，可能会有 Write Skew。</li><li>共识层本身也可以作为一个 Raw KV 对外服务。</li><li>共识层参与定序。这个在后面介绍。</li><li>多个 Raft Group 组成的共识层提高了并发能力。</li><li>Lock 的存在性和⼀致性由该⾏所处的 Raft Group 保障。</li><li>事务提交后，会写⼊ Write 并删除 Lock，其原⼦性由 Raft Write Batch 保障。</li><li>共识层提供了全序广播语义。<br> “在 xx 之前，一定不会有别的 Lock 和 Write 了”</li></ol><p>当然这也存在一个 argue 点，因为 Raft Log 本身也是 total order 的。虽然我们目前不是全局一个 Raft Group 的，但看起来会有一些冗余，在后面会讨论。<br>特别地，在 CDC 服务和 TiFlash 中，实际上不会处理未 Commit 的数据。</p><h4 id="双重定序"><a href="#双重定序" class="headerlink" title="双重定序"></a>双重定序</h4><p>事务层的实现中，为了满足隔离性，通常会给事务分配 id 来表示相互依赖的事务之间的偏序关系。TiDB 中使用了 TSO，Spanner 中使用了 TrueTime，CRDB 中使用了 HLC。<br>共识层的实现中，为了实现容灾和高可用，使用共识算法在各个 RSM 之间复制日志，这些日志为全序关系，RSM 可以应用这个全序关系确保线性一致。</p><p>事务层生成 TSO 和共识层生成 Log 两个行为：</p><ol><li>不是原子的</li><li>也不构成全序关系<br> 实际上也没必要，两个不相交的事务按照事务序本来可以并行 Commit 的，但因为要写到共识层，必须又要排出一个全序关系来。</li><li>甚至一个事务的 commit_ts （相比某个特定事务）更小，而 index 更大<br> 下面会展示这种情况，并详细阐述。</li></ol><p>总而言之：</p><ul><li>Percolator 协议保证了事务层能够生成一个特定的排序，并且按照它的二阶段方式写入到共识层</li><li>共识层保证了所有的副本都会应用该特定排序</li></ul><h4 id="共识层为事务层提供帮助"><a href="#共识层为事务层提供帮助" class="headerlink" title="共识层为事务层提供帮助"></a>共识层为事务层提供帮助</h4><p>目前 TiKV 通过一个 pd 分配一个全局的 tso 来作为事务的 start_ts 和 commit_ts，所以它们之间彼此构成全序关系。当然，实际上不同的事务可能具有同一个 commit_ts，但这并不影响下面的讨论。通过 start_ts 和 commit_ts 可以构建有依赖的事务之间偏序关系，也可以用来判断事务是否是 concurrent 的。如果在单个节点上串行地 commit 这些事务，则面临问题：</p><ol><li>整个系统毫无并行度<br> 这个应该算是 MultiRaft 的一个 bonus，正如后面讲的，如果没有 MultiRaft，同样可以做 partitioning。<br> 因此，TiKV 在多个线性一致的存储(Region)上储存这些事务，它保证了每个事务在每个 Region 上都遵循了 start_ts 和 commit_ts 所 imply 的顺序，也 Percolator 那一套。这样尽管各个 Region 之间是并发的了，但只要 Region 内遵循这个 order 就行了。<blockquote><p>当然，这个切分也未必是按照 Region 来，比如 CDC 会使用表来切分。无论按照哪种方式来切分，我觉得一个实现的要点是每个 shard 在调度上是不可以再分的了。比如一个 Region 的一部分数据在 store 1 上，另一部分数据在 store 2 上，这样做实际上会导致无论在 store 1 和 store 2 上都很难独立构建出该 Region 上数据的全序关系，比如 store 1 如果不和 store 2 交互，那么就很难知道 store 2 上还有没有 happen before 它的事务了。比如说，如果两个 store 上 apply 这个 Region 的 log 的进度不一样。</p></blockquote></li><li>如何判断某个 tso 之前还有没有其他 Lock 或者 Write？<br> 因此，读事务会在取得 start_ts 后，再通过 ReadIndex 请求一下 Region Leader 上的 commit_index。那么假设在这之前 Region 上有写入任意的 Lock 或者 Write，都能被 ReadIndex 扫到。这样就保证了读事务能看到 start_ts 之前的所有修改。至于 start_ts 之后的也有 Lock 可以帮忙。<br> 同样考虑一个<a href="/2017/09/20/transaction/">Snapshot Isolation(SI)/一个两难问题</a>，这里不再详细展开具体内容。但 ReadIndex 提供了一个保证，就是截止到 read_index，这个 Region 上到底有没有 Write，是很确定的。我理解这实际上就是一种全序广播了。破坏这种全序广播可能会有严重后果，比如如果将 Write 乱序到 Lock 前面，则违反了 Percolator 事务的约束。我们实际上也没办法很好的处理，在“跨 Region 提交事务”中，就构造出了这样的场景。</li></ol><p>此外，对于并发事务，共识层也会对它们之间排出一个串行的顺序，比如两个并发的事务不能同时 Commit，而要等到 Log 按序 apply 而这可能有点过强。诸如 ParallelRaft 或者 MultiPaxos 的算法允许并行 apply，可以解决此问题，但会导致 Leader 和 Follower 之间的 apply order 难以统一，从而无法实现 Follower Read。</p><h4 id="共识层对并发事务的乱序"><a href="#共识层对并发事务的乱序" class="headerlink" title="共识层对并发事务的乱序"></a>共识层对并发事务的乱序</h4><p>刚才说过，共识层未必会按照事务序写入。这也很容易理解，因为取 start_ts 和 commit_ts 和真正写共识层不是原子的。<br>TiKV 事务在读取时，需要同时接收事务层和共识层的定序。为了满⾜线性⼀致读，需要⾸先带上 start_ts，发送⼀个 ReadIndexRequest 给对应的 Region，求出⼀个 applied_index。在实际实现中，start_ts 并⽆作⽤。<br>如下所示，Key a 和 Key b 属于两个事务。在事务提交前，可以看到或者得到的保证是：</p><ol><li>start_ts(a) &lt; commit_ts(a)</li><li>start_ts(b) &lt; commit_ts(b)</li><li>start_ts(a) &lt; start_ts(b)</li><li>并且这两个是并发事务，也就是说 commit_ts(a) &gt; start_ts(b)</li></ol><p>共识层的序至少保证了同一个 key 的 prewrite 在 commit 前面。</p><p>不妨假设 commit_ts 分别为 4 和 6，然后再假如以 (read_ts=7, read_index=202) 读取，如下所示。</p><ol><li>Key a：(start_ts: 1, applied_index: 100), (commit_ts: 4, applied_index: 210）</li><li>Key b：(start_ts: 3, applied_index: 101), (commit_ts: 6, applied_index: 200)</li></ol><p>从事务层上讲，Key a 和 Key b 的写入对 read_ts=7 的读取事务可见，从共识层上讲 applied_index 等于 read_index，或者超过它的的任意时刻都可以读了。因此，此时可能读到一个锁和 Key b（刚好 apply 到 read_index），或者读到 Key a 和 Key b（apply 超过 read_index 很多，比如到 211 了）。前者需要 ResolveLock，实际上导致以新的 read_index 来重新读取。</p><p>反过来讲，如果共识层给出下面的顺序，我们看到了中间的 a 或者 b 上有锁。因为这两个事务是并发事务，所以这也是 OK 的</p><ol><li>Key a：(start_ts: 1, applied_index: 100), (commit_ts: 4, applied_index: 200）</li><li>Key b：(start_ts: 3, applied_index: 101), (commit_ts: 6, applied_index: 210)</li></ol><p><img src="/img/ti-arch-thought/consensus_order_txn_order.png"></p><p>可以看到，尽管将事务拆到了 N 个线性一致的存储上执行，并且这些存储可能对并发事务任意定序，但最终读到的结果还是满足了线性一致，以及事务隔离层的要求的。</p><h4 id="并发事务的共识序"><a href="#并发事务的共识序" class="headerlink" title="并发事务的共识序"></a>并发事务的共识序</h4><p>并发事务 1 和 2，假设 start_ts1 &lt; start_ts2 &lt; commit_ts1 &lt; commit_ts2，那么两个事务彼此不可见，或者说是并发事务。假设这两个事务写入同一个 region，那么在 raft log entry 层面，完全可以出现 commit_ts1 对应的 raft log 的 index 更靠后，而 commit_ts2 对应的更靠前。比如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">index 10: Put Write CF commit_ts2</span><br><span class="line">index 11: Put Write CF commit_ts1</span><br></pre></td></tr></table></figure><h4 id="跨-Region-提交事务？"><a href="#跨-Region-提交事务？" class="headerlink" title="跨 Region 提交事务？"></a>跨 Region 提交事务？</h4><blockquote><p>能不能在看到第一个 write 记录时“提交”该事务的所有 key？</p></blockquote><p>这里的“提交”指的是写入下层存储，比如将 Default 写过去，但并不包含删除 Lock 等。</p><p>现在比如考虑两个事务，假设 a 在一个 region r1，b 和 c 在另一个 region r2 让：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">commit a(applied_index@r1=100), commit b(applied_index@r2=300), commit_ts=4</span><br><span class="line">                                commit c(applied_index@r2=200), commit_ts=1</span><br></pre></td></tr></table></figure><p>从事务层上来看，一定有读事务能看到 c，或者 a、b、c。现在如果看到 a 提交了，能不能跑到 b 的 region 上把 b 也提交了呢？我认为是不可以的，因为从共识层上来说，b 在 c 的后面被 commit 的，如果用 (start_ts &gt; 4, read_index = 250) 去读的话，可能读到 lock b，甚至可能连 lock b 也还没被写入，当然也有可能读到 b。但如果我们在 apply a 的 write 记录的时候发现了 a 被 write 了，就直接写 b 的 write 记录，那么就导致 b 一定在 c 前面就能被读到，实际上违反了共识层的序。</p><p>具体来说，不妨考虑 client 先后从 Learner 和 Leader 读：</p><ol><li>在 Learner 上，它使用 read_index = 250 读，但是因为 commit a 已经被 apply 的原因，所以它一定读到了 commit b。<br> 当然细究下来，因为 lock + default 是原子的，所以实际上 write 无法被正确执行。但这就是 orphan write key 的问题，之前在处理 multi rocks 的时候就解过，我觉得很复杂。在这个场景下，我觉得免不了要去进行等待。在异步系统中的等待，我觉得可以理解为是一种活性问题。</li><li>在 Leader 上，此时 Leader apply 到了 260，所以此时 Leader 上一定没有 commit b，这导致它读不到 commit b。</li></ol><p>这里线性一致读就被破坏了。反之，如果按共识序 commit，则不会有这种情况。具体就不展开了。</p><h4 id="单-Region-上提交事务？"><a href="#单-Region-上提交事务？" class="headerlink" title="单 Region 上提交事务？"></a>单 Region 上提交事务？</h4><blockquote><p>限定事务只在一个 Region 中发生，能不能在看到第一个 write 记录时“提交”该事务的所有 key？</p></blockquote><p>上述场景在单 Region 上无法构造，原因是单 Region 是串行的。</p><p>尽管“在看到第一个 write 记录时‘提交’该事务的所有 key”可能相当于让一部分 Write 被乱序，但这种乱序不是直接去把 Write 挪到 Lock 之前。比如说，因为 Percolator 的特性，单 Region 上的某个事务的 Prewrite 一定都在 Commit 前面。因此，就算在看到第一个 Write 时候，将该事务的所有 Default 都提前写到下层存储，也不至于提前到某个 Lock 前面。这样被写的 Key 始终有 Lock 保护，直到看到它对应的 Write。</p><p>而在多 Region 中不同 Region 可以说是完全异步的（不考虑 Split 等），那我就可以构造一个无比提前的 Write，让它失去 Lock 的保护。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;将 &lt;a href=&quot;/2023/07/22/tikv-tidb-thought/&quot;&gt;关于 TiKV、TiDB、TiFlash 的一些思考&lt;/a&gt;中关于 Percolator 事务的部分独立出来。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>TiKV 的资源管理模型</title>
    <link href="http://www.calvinneo.com/2025/01/12/tikv-resource-management/"/>
    <id>http://www.calvinneo.com/2025/01/12/tikv-resource-management/</id>
    <published>2025-01-12T03:57:20.000Z</published>
    <updated>2025-01-19T09:32:27.533Z</updated>
    
    <content type="html"><![CDATA[<p>介绍下 TiKV 的资源管理模型。</p><a id="more"></a><h1 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h1><p>TiKV 的内存包含下面的部分：</p><ul><li><p>Entry cache<br>  主要包含 cache 和 trace 两部分。</p><ul><li>cache 主要包含了 proposed 之后的 entry，可以看做是 raft-engine 的缓存。这个缓存可以被 leader 用来 append entries。</li><li>trace 主要包含了会被发送给 Apply 类，用来 apply 的 CachedEntries 对象。在 apply 结束后就可以被删除掉。</li></ul></li><li><p>Block cache</p></li><li><p>Raft Message<br>  主要是收到的 Raft Message 的占用内存。</p></li><li><p>Raft Entry<br>  主要是收到的 Raft Entry 占用的内存。Raft Message 被 step 之后，对应的内存就会给到 Raft Entry。</p></li><li><p>Peer FSM<br>  主要是和 Raft 的复制直接相关的。</p>  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">PeerMemoryTrace</span></span> &#123;</span><br><span class="line">    <span class="comment">/// `ReadOnly` memory usage in Raft groups.</span></span><br><span class="line">    <span class="keyword">pub</span> read_only: <span class="built_in">usize</span>,</span><br><span class="line">    <span class="comment">/// `Progress` memory usage in Raft groups.</span></span><br><span class="line">    <span class="keyword">pub</span> progress: <span class="built_in">usize</span>,</span><br><span class="line">    <span class="comment">/// `Proposal` memory usage for peers.</span></span><br><span class="line">    <span class="keyword">pub</span> proposals: <span class="built_in">usize</span>,</span><br><span class="line">    <span class="keyword">pub</span> rest: <span class="built_in">usize</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Apply FSM<br>  这里主要包括等待 apply 的 cmd 以及对应的 entry。</p></li><li><p>Coprocessor</p></li></ul><p>TiKV 默认的内存分配方案</p><ul><li>系统内存的 75% 作为 high water 水位<ul><li>Block cache 占用 45%</li><li>Write buffer 占用 20%</li></ul></li><li>剩下来的 25% 是留给操作系统的 Page Cache</li></ul><p>因为用户可以仅指定 Block cache 或者 write buffer 的期望大小，所以在计算 high water 的时候，会换算出各自的 high water 水位，选择其中的较大值。这个较大值不会大于内存的总大小，但可能大于 75%，这个时候会输出一个警告。</p><p>TiKV 使用 <code>procinfo::pid::statm_self()</code> 获取当前的系统内存。当超过 high water 后，有两个行动</p><ul><li>reject msg append<br>  计算 Raft Message + Raft Entry + Entry cache + Apply FSM 超过 reject_messages_on_memory_ratio 就会拒绝 raft message。</li><li>evict entry cache</li></ul><h1 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h1>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍下 TiKV 的资源管理模型。&lt;/p&gt;</summary>
    
    
    
    
    <category term="内存管理" scheme="http://www.calvinneo.com/tags/内存管理/"/>
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>桌游品鉴</title>
    <link href="http://www.calvinneo.com/2025/01/11/board-game/"/>
    <id>http://www.calvinneo.com/2025/01/11/board-game/</id>
    <published>2025-01-11T15:07:22.000Z</published>
    <updated>2025-09-01T10:00:21.902Z</updated>
    
    <content type="html"><![CDATA[<p>介绍玩过的一些桌游。大概是按照结识的顺序来的。</p><a id="more"></a><h1 id="桌游机制分类"><a href="#桌游机制分类" class="headerlink" title="桌游机制分类"></a>桌游机制分类</h1><h2 id="卡牌构筑"><a href="#卡牌构筑" class="headerlink" title="卡牌构筑"></a>卡牌构筑</h2><h2 id="工人放置"><a href="#工人放置" class="headerlink" title="工人放置"></a>工人放置</h2><h2 id="板图放置"><a href="#板图放置" class="headerlink" title="板图放置"></a>板图放置</h2><h2 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h2><h2 id="骰子驱动"><a href="#骰子驱动" class="headerlink" title="骰子驱动"></a>骰子驱动</h2><h2 id="拍卖"><a href="#拍卖" class="headerlink" title="拍卖"></a>拍卖</h2><h1 id="早期桌游"><a href="#早期桌游" class="headerlink" title="早期桌游"></a>早期桌游</h1><h2 id="UNO"><a href="#UNO" class="headerlink" title="UNO"></a>UNO</h2><p>UNO 村规很多，玩之前一定要说清楚。</p><h2 id="卡卡颂"><a href="#卡卡颂" class="headerlink" title="卡卡颂"></a>卡卡颂</h2><p>上本科开始玩的，当时是和菡姐、cjw 他们一起玩，算是桌游启蒙了。</p><h2 id="谁是大老板"><a href="#谁是大老板" class="headerlink" title="谁是大老板"></a>谁是大老板</h2><h2 id="璀璨宝石（宝石商人）"><a href="#璀璨宝石（宝石商人）" class="headerlink" title="璀璨宝石（宝石商人）"></a>璀璨宝石（宝石商人）</h2><p>应该是第一轻策德式了，经典入门。</p><h2 id="香料之路"><a href="#香料之路" class="headerlink" title="香料之路"></a>香料之路</h2><p>卡牌构筑的游戏。买香料，升级香料，最后用香料换巨人，比谁分数多。</p><h2 id="富饶之城"><a href="#富饶之城" class="headerlink" title="富饶之城"></a>富饶之城</h2><p>在早期是非常受欢迎的多人桌游。小偷非常关键。商人和建筑师很容易被搞。</p><h2 id="猜狐狸（帕瓦仪式）"><a href="#猜狐狸（帕瓦仪式）" class="headerlink" title="猜狐狸（帕瓦仪式）"></a>猜狐狸（帕瓦仪式）</h2><h2 id="僵尸商场"><a href="#僵尸商场" class="headerlink" title="僵尸商场"></a>僵尸商场</h2><p>交朋友的游戏。</p><h2 id="逃离亚特兰蒂斯"><a href="#逃离亚特兰蒂斯" class="headerlink" title="逃离亚特兰蒂斯"></a>逃离亚特兰蒂斯</h2><p>交朋友的游戏+1。</p><h2 id="大富翁世界之旅"><a href="#大富翁世界之旅" class="headerlink" title="大富翁世界之旅"></a>大富翁世界之旅</h2><h2 id="山屋惊魂（山中小屋）"><a href="#山屋惊魂（山中小屋）" class="headerlink" title="山屋惊魂（山中小屋）"></a>山屋惊魂（山中小屋）</h2><h2 id="逻辑对决"><a href="#逻辑对决" class="headerlink" title="逻辑对决"></a>逻辑对决</h2><p>两个人一个人拿一个草稿纸在那边吭哧吭哧算，看谁先算出来对手都是什么数字。大师买过一个，后面送给别人了。</p><h2 id="达芬奇密码"><a href="#达芬奇密码" class="headerlink" title="达芬奇密码"></a>达芬奇密码</h2><p>每个人摸一张牌，然后猜别人的是什么数字。白板是关键。</p><h2 id="画物语（只言片语）"><a href="#画物语（只言片语）" class="headerlink" title="画物语（只言片语）"></a>画物语（只言片语）</h2><h2 id="印加宝藏"><a href="#印加宝藏" class="headerlink" title="印加宝藏"></a>印加宝藏</h2><p>赌狗游戏。超过三个同样的就爆炸。</p><h2 id="卡坦岛"><a href="#卡坦岛" class="headerlink" title="卡坦岛"></a>卡坦岛</h2><p>首先推荐取消玩家之间交换资源的规定，让游戏更偏向于策略性，为此可以适当增加手牌上限，方便屯牌。</p><p>这个游戏不太适合人多，例如无扩展的 4 人或者有扩展的 6 人，因为抢不到码头，或者村庄点体验会很差，但卡坦岛又耗时比较长。</p><p>我觉得设计上有点瑕疵的是，资源的重要性明显有偏向。例如</p><ul><li>小麦会被用在抽卡、建村庄、升级上，属于全局最重要的资源。</li><li>树木和砖头被用在修路、建村庄上，属于前期必争资源。但这两个后期基本没有用。</li><li>羊被用在建村庄和抽卡上。</li><li>石头被用在升级和抽卡上。</li></ul><p>所以最优解一定是占有木头或者砖头的港口，占有最优势的麦田。</p><h2 id="犯人在跳舞"><a href="#犯人在跳舞" class="headerlink" title="犯人在跳舞"></a>犯人在跳舞</h2><h2 id="情书"><a href="#情书" class="headerlink" title="情书"></a>情书</h2><h2 id="电力公司"><a href="#电力公司" class="headerlink" title="电力公司"></a>电力公司</h2><p>一直在村。直到 25 年春节来了个 3 人，才发现这个游戏可以通过先后手卡资源、轮次卡到发不了电。</p><h2 id="瘟疫危机"><a href="#瘟疫危机" class="headerlink" title="瘟疫危机"></a>瘟疫危机</h2><p>合作游戏，有次亚特兰蒂斯玩之后腰子只愿意玩这个了。</p><h2 id="宇航员"><a href="#宇航员" class="headerlink" title="宇航员"></a>宇航员</h2><p>合作游戏，不适合小黑。</p><h2 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h2><h2 id="展翅翱翔"><a href="#展翅翱翔" class="headerlink" title="展翅翱翔"></a>展翅翱翔</h2><p>大师买过的，贡献了骰塔。</p><h2 id="骇浪求生"><a href="#骇浪求生" class="headerlink" title="骇浪求生"></a>骇浪求生</h2><h1 id="毕业后分界线"><a href="#毕业后分界线" class="headerlink" title="=== 毕业后分界线 ==="></a>=== 毕业后分界线 ===</h1><p>主要是过年搞。</p><h2 id="谍报风云（截码战）"><a href="#谍报风云（截码战）" class="headerlink" title="谍报风云（截码战）"></a>谍报风云（截码战）</h2><p>我们后来又玩了几把。我觉得可以总结为下面几点策略：</p><ul><li>使用超特性，而不是子特性<br>  比如“桌子”，说平、木头这些子特性，在多个轮次之后，对手就能够轻松猜到了，因为是帮对手缩小范围。<br>  但是使用“房屋”来描述，对手就猜不到这是一种房屋，还是房屋里面的某种东西。</li><li>使用比较<br>  比如鬼魂、瘟疫、飞机这三个词出现在一起时，形成比较。因此可以用 dead、dying、will die 来区分。</li><li>使用意思相近，但是有区分度的词<br>  例如虚幻、虚拟、模拟三个词非常类似，但是用在鬼魂、电视、飞行这三词上就很有辨识度。</li><li>使用意思相近，但是存在固定搭配的词<br>  比如 inflight 和 flying 可以表示消息、飞机两个词。</li><li>使用一个模糊+一个精确的词。其中模糊的词可以用来指代 A，也可以用来指代 B。每一轮中，如果同时出现 A 和 B，那么就选择一个精确的词形容 A 或者 B，然后另一个词模糊形容。</li></ul><h2 id="揭秘希特勒"><a href="#揭秘希特勒" class="headerlink" title="揭秘希特勒"></a>揭秘希特勒</h2><h2 id="柯尔特快车"><a href="#柯尔特快车" class="headerlink" title="柯尔特快车"></a>柯尔特快车</h2><p>打枪打拳的。</p><h2 id="牛头王"><a href="#牛头王" class="headerlink" title="牛头王"></a>牛头王</h2><p>聚会第一游戏了。特别是人多的时候，根本算不过来。</p><h2 id="小白世纪"><a href="#小白世纪" class="headerlink" title="小白世纪"></a>小白世纪</h2><h2 id="盛唐园林"><a href="#盛唐园林" class="headerlink" title="盛唐园林"></a>盛唐园林</h2><p>美工还不错，但是感觉可玩性一般。</p><h2 id="七大奇迹"><a href="#七大奇迹" class="headerlink" title="七大奇迹"></a>七大奇迹</h2><p>没啥特点。</p><h2 id="怒海求生"><a href="#怒海求生" class="headerlink" title="怒海求生"></a>怒海求生</h2><p>划船神游。</p><h2 id="大搜查"><a href="#大搜查" class="headerlink" title="大搜查"></a>大搜查</h2><p>桌游模拟器玩的。</p><h2 id="战争之匣"><a href="#战争之匣" class="headerlink" title="战争之匣"></a>战争之匣</h2><p>在桌游模拟器玩的。</p><h2 id="冷战热斗"><a href="#冷战热斗" class="headerlink" title="冷战热斗"></a>冷战热斗</h2><p>和大师在桌游模拟器上玩的。</p><h2 id="诈赌巫师"><a href="#诈赌巫师" class="headerlink" title="诈赌巫师"></a>诈赌巫师</h2><p>换裁判的、修改压注的卡最为牛逼。</p><h2 id="昆虫棋"><a href="#昆虫棋" class="headerlink" title="昆虫棋"></a>昆虫棋</h2><p>和大师网上 pk 的，后来我买了个和我对象玩，基本一直输，可玩性比较差。</p><h2 id="2023-悠嘻分界线"><a href="#2023-悠嘻分界线" class="headerlink" title="=== 2023 悠嘻分界线 ==="></a>=== 2023 悠嘻分界线 ===</h2><p>2023 年秋天左右，开始定期在悠嘻搞桌游。第一次搞了个包厢，喊了 zjx，可惜后面他不来了。但是后面小黑加入，所以桌游能够搞起来。</p><h2 id="出包魔法师"><a href="#出包魔法师" class="headerlink" title="出包魔法师"></a>出包魔法师</h2><p>猜自己面前的是什么。思路：</p><ul><li>勇于猜重复项</li><li>根据别人的猜测情况，必要时勇于猜 1-3</li><li>猜 4 成功的话收益很高，优先猜 4 猫头鹰</li><li>必要时再连猜，因为猜完要补牌从而亏信息（自己补牌别人能看到，相当于人家赚了），因此每次猜要尽可能猜完</li></ul><h2 id="滑板之夏"><a href="#滑板之夏" class="headerlink" title="滑板之夏"></a>滑板之夏</h2><p>也是个赌狗游戏。滑板一开始在 0 位置，不停抽牌，会对位置进行减或者加。</p><h2 id="东京之王"><a href="#东京之王" class="headerlink" title="东京之王"></a>东京之王</h2><h2 id="皂单全收"><a href="#皂单全收" class="headerlink" title="皂单全收"></a>皂单全收</h2><h2 id="农场主"><a href="#农场主" class="headerlink" title="农场主"></a>农场主</h2><h2 id="星际卡坦"><a href="#星际卡坦" class="headerlink" title="星际卡坦"></a>星际卡坦</h2><p>在呦西玩了一把，它是纯英文的。我觉得比卡坦岛，不是特别卡人了。</p><h2 id="现代艺术"><a href="#现代艺术" class="headerlink" title="现代艺术"></a>现代艺术</h2><h2 id="骆驼大赛"><a href="#骆驼大赛" class="headerlink" title="骆驼大赛"></a>骆驼大赛</h2><p>抢放那个板很重要。</p><p>骆驼大赛需要推理的情形比较少，轮次比较好算。</p><h2 id="马尼拉"><a href="#马尼拉" class="headerlink" title="马尼拉"></a>马尼拉</h2><p>划船不用桨，叫我老船长。感觉越早当船长越划算。</p><h2 id="骰子街"><a href="#骰子街" class="headerlink" title="骰子街"></a>骰子街</h2><p>开火车站，然后还是玩一个骰子蹭别人。</p><h2 id="花砖物语"><a href="#花砖物语" class="headerlink" title="花砖物语"></a>花砖物语</h2><p>经典德式。高手们还剩两三个盘子的时候就开始算轮次了。</p><h2 id="暑假日记"><a href="#暑假日记" class="headerlink" title="暑假日记"></a>暑假日记</h2><h2 id="拉斯维加斯"><a href="#拉斯维加斯" class="headerlink" title="拉斯维加斯"></a>拉斯维加斯</h2><p>在性感哥那里玩的赌狗游戏。</p><h2 id="勃艮第城堡"><a href="#勃艮第城堡" class="headerlink" title="勃艮第城堡"></a>勃艮第城堡</h2><p>感觉是简化版的动物园。</p><h2 id="爆珠发明"><a href="#爆珠发明" class="headerlink" title="爆珠发明"></a>爆珠发明</h2><p>一个老早就知道的，类似于璀璨宝石的游戏。不过那个骰塔不太好，老卡壳。</p><h2 id="地产达人（拍卖）"><a href="#地产达人（拍卖）" class="headerlink" title="地产达人（拍卖）"></a>地产达人（拍卖）</h2><p>先拍一轮工厂，然后通过工厂生产一轮东西。最后是剩下的钱加上工厂赚的钱。</p><h2 id="沙丘"><a href="#沙丘" class="headerlink" title="沙丘"></a>沙丘</h2><p>23 年开始玩的，基本都是小黑赢。24 年上半年玩的比较多，然后琥珀赢比较多。</p><p>感觉沙丘人数多少会直接影响工人放置会不会被卡。另外打仗很重要。</p><h2 id="重塑火星"><a href="#重塑火星" class="headerlink" title="重塑火星"></a>重塑火星</h2><p>阅读量惊人。</p><h2 id="熵增猫"><a href="#熵增猫" class="headerlink" title="熵增猫"></a>熵增猫</h2><p>往上叠纸的。</p><h2 id="卡斯卡迪亚"><a href="#卡斯卡迪亚" class="headerlink" title="卡斯卡迪亚"></a>卡斯卡迪亚</h2><p>一开始在桌游模拟器玩的。</p><h1 id="2024-悠嘻分界线"><a href="#2024-悠嘻分界线" class="headerlink" title="=== 2024 悠嘻分界线 ==="></a>=== 2024 悠嘻分界线 ===</h1><h2 id="方鸟"><a href="#方鸟" class="headerlink" title="方鸟"></a>方鸟</h2><p>这是 2024 跨年夜玩的。</p><h2 id="方舟动物园"><a href="#方舟动物园" class="headerlink" title="方舟动物园"></a>方舟动物园</h2><p>这是 2024 跨年夜玩的。拉格朗日老板强烈安利。</p><h2 id="赌命大赛"><a href="#赌命大赛" class="headerlink" title="赌命大赛"></a>赌命大赛</h2><p>比较吸引我的一点是里面有质疑的环节。</p><h2 id="RA"><a href="#RA" class="headerlink" title="RA"></a>RA</h2><p>这是 2024 跨年夜玩的。</p><h2 id="CABO"><a href="#CABO" class="headerlink" title="CABO"></a>CABO</h2><p>这是 2024 跨年夜玩的。这个游戏应该是年度最佳毛线了。</p><h2 id="爆炸猫"><a href="#爆炸猫" class="headerlink" title="爆炸猫"></a>爆炸猫</h2><p>简单的毛线。</p><h2 id="幽港迷城"><a href="#幽港迷城" class="headerlink" title="幽港迷城"></a>幽港迷城</h2><h2 id="德国蟑螂"><a href="#德国蟑螂" class="headerlink" title="德国蟑螂"></a>德国蟑螂</h2><p>诈骗游戏。</p><h2 id="斯凯岛"><a href="#斯凯岛" class="headerlink" title="斯凯岛"></a>斯凯岛</h2><p>一个人每轮三块板，三选二出价，别人可以买，否则自己就按出价买走。</p><h2 id="加拿大棋"><a href="#加拿大棋" class="headerlink" title="加拿大棋"></a>加拿大棋</h2><p>有点类似冰壶。</p><p>有一次桌游店搞活动，我去和店主搞了一把。我两次直接打到圆心里面，结果一把就赢了店主，给我免单了 15 块钱。</p><h2 id="伊斯坦堡"><a href="#伊斯坦堡" class="headerlink" title="伊斯坦堡"></a>伊斯坦堡</h2><p>不停在各个区块走，然后每次停都要下一个蛋，直到走回来。</p><h2 id="骷髅牌"><a href="#骷髅牌" class="headerlink" title="骷髅牌"></a>骷髅牌</h2><p>比谁能咋呼，小黑每次都是假的。</p><h2 id="王权骰铸"><a href="#王权骰铸" class="headerlink" title="王权骰铸"></a>王权骰铸</h2><p>纯赌狗打架游戏。</p><h2 id="璀璨宝石宝可梦"><a href="#璀璨宝石宝可梦" class="headerlink" title="璀璨宝石宝可梦"></a>璀璨宝石宝可梦</h2><p>和原版的高分流完全不一样了。这个是 18 分模式，拿两蛋卡，以及一费卡很重要。</p><h2 id="战国时代"><a href="#战国时代" class="headerlink" title="战国时代"></a>战国时代</h2><p>投骰子的赌狗游戏。大家都喜欢无脑莽春日山城。我记得大师有一次靠着欧皇城极限反杀。</p><h2 id="大宋百商图"><a href="#大宋百商图" class="headerlink" title="大宋百商图"></a>大宋百商图</h2><p>小黑买的游戏。我觉得可以靠删卡流获胜。我赢过几次，倒是靠的那个一下赚 6 分建筑的获胜的。</p><h2 id="串好啦"><a href="#串好啦" class="headerlink" title="串好啦"></a>串好啦</h2><p>垃圾游戏，小黑喜欢玩。</p><h2 id="王者神抽"><a href="#王者神抽" class="headerlink" title="王者神抽"></a>王者神抽</h2><p>鱼钩船锚的。感觉是升级版的印加宝藏。</p><h2 id="L-计划"><a href="#L-计划" class="headerlink" title="L 计划"></a>L 计划</h2><p>很有意思的游戏。后面也重开了好几次。</p><p>感觉要在大师操作，以及让自己快速获得某种类型的拼块之间取得平衡。</p><h2 id="历史奇旅"><a href="#历史奇旅" class="headerlink" title="历史奇旅"></a>历史奇旅</h2><p>很多年份牌，从公元前到公元后。玩家需要按照时间顺序打出年份牌，这个牌组越长，得分越高。</p><h2 id="猫岛"><a href="#猫岛" class="headerlink" title="猫岛"></a>猫岛</h2><p>任务卡得分很多，选择好的任务卡很重要。</p><p>多买点猫很重要，因为无论是空格子，还是完成任务都需要猫的绝对数量。</p><h2 id="以色列麻将（拉密）"><a href="#以色列麻将（拉密）" class="headerlink" title="以色列麻将（拉密）"></a>以色列麻将（拉密）</h2><h2 id="奥丁的盛宴"><a href="#奥丁的盛宴" class="headerlink" title="奥丁的盛宴"></a>奥丁的盛宴</h2><p>很容易作弊。</p><h2 id="纽约动物园"><a href="#纽约动物园" class="headerlink" title="纽约动物园"></a>纽约动物园</h2><h2 id="星露谷物语"><a href="#星露谷物语" class="headerlink" title="星露谷物语"></a>星露谷物语</h2><p>挺无聊的。</p><h2 id="疯狂建筑师"><a href="#疯狂建筑师" class="headerlink" title="疯狂建筑师"></a>疯狂建筑师</h2><p>用棍子越大越高，谁掉下来谁就把掉地上的棍子全吃掉。</p><h2 id="苍翠之星"><a href="#苍翠之星" class="headerlink" title="苍翠之星"></a>苍翠之星</h2><p>挺有创意的游戏。太阳绕一圈，春夏秋冬，计分四次。感觉挺考验统筹能力。</p><h2 id="盖亚计划"><a href="#盖亚计划" class="headerlink" title="盖亚计划"></a>盖亚计划</h2><p>和呦西老板开了轮。后面自己也玩了几把，把把村规，但是很好玩。</p><h2 id="神秘大地"><a href="#神秘大地" class="headerlink" title="神秘大地"></a>神秘大地</h2><p>在大师家玩的比较多，是大创的简化版本。</p><h2 id="异世界公会长"><a href="#异世界公会长" class="headerlink" title="异世界公会长"></a>异世界公会长</h2><p>在大师家玩的。</p><h2 id="永恒之谷"><a href="#永恒之谷" class="headerlink" title="永恒之谷"></a>永恒之谷</h2><p>越到最后越说书，卡牌效果太多了。</p><h2 id="骰子镇"><a href="#骰子镇" class="headerlink" title="骰子镇"></a>骰子镇</h2><p>小黑快乐游戏。</p><h2 id="圣家族大教堂"><a href="#圣家族大教堂" class="headerlink" title="圣家族大教堂"></a>圣家族大教堂</h2><p>从巴塞罗那回来，刚好就玩了这个。</p><h2 id="尖塔奇兵"><a href="#尖塔奇兵" class="headerlink" title="尖塔奇兵"></a>尖塔奇兵</h2><p>忘了怎么玩的了。</p><h2 id="时空神探"><a href="#时空神探" class="headerlink" title="时空神探"></a>时空神探</h2><p>挺有创意的破案游戏。</p><h2 id="迷失代码"><a href="#迷失代码" class="headerlink" title="迷失代码"></a>迷失代码</h2><p>有点像出包魔法师一样，但是这次是猜自己面前六个数字的总和。每次按顺序在桌子中间选择一个轮盘，轮盘越大，域越大越容易猜中，但是得分越低。</p><h2 id="疯狂诡宅"><a href="#疯狂诡宅" class="headerlink" title="疯狂诡宅"></a>疯狂诡宅</h2><h2 id="口袋密室"><a href="#口袋密室" class="headerlink" title="口袋密室"></a>口袋密室</h2><p>非常无厘头的解谜。</p><h2 id="Bohnanza-Das-Wurfelspiel"><a href="#Bohnanza-Das-Wurfelspiel" class="headerlink" title="Bohnanza: Das Würfelspiel"></a>Bohnanza: Das Würfelspiel</h2><p>挺好玩的骰子游戏，实际上是种豆得金的骰子版，去掉了扯皮的交易环节。但买不到。</p><p>直到 25 年八月底，大师自己 diy 了一个。</p><h2 id="神偷大盗"><a href="#神偷大盗" class="headerlink" title="神偷大盗"></a>神偷大盗</h2><h2 id="自然和弦"><a href="#自然和弦" class="headerlink" title="自然和弦"></a>自然和弦</h2><h2 id="开除"><a href="#开除" class="headerlink" title="开除"></a>开除</h2><p>不太平衡的游戏。有个办公用品卡，还是喝酒的好像特别强。</p><h1 id="2025-分割线"><a href="#2025-分割线" class="headerlink" title="=== 2025 分割线 ==="></a>=== 2025 分割线 ===</h1><h2 id="拼布艺术"><a href="#拼布艺术" class="headerlink" title="拼布艺术"></a>拼布艺术</h2><p>没拼完的要扣 2 分 不是一分。</p><h2 id="驭龙狂奔渡渡鸟"><a href="#驭龙狂奔渡渡鸟" class="headerlink" title="驭龙狂奔渡渡鸟"></a>驭龙狂奔渡渡鸟</h2><p>桌上篮球。</p><h2 id="英雄领域"><a href="#英雄领域" class="headerlink" title="英雄领域"></a>英雄领域</h2><h2 id="方格游戏（角斗士棋）"><a href="#方格游戏（角斗士棋）" class="headerlink" title="方格游戏（角斗士棋）"></a>方格游戏（角斗士棋）</h2><p>有点类似于围棋，前期出去占地盘很重要。类似于 1x1 和 1x2 的棋子的作用很关键，它们可以用来在被围住的情况下搭桥逃出来。</p><h2 id="客人来之前"><a href="#客人来之前" class="headerlink" title="客人来之前"></a>客人来之前</h2><h2 id="马戏星探"><a href="#马戏星探" class="headerlink" title="马戏星探"></a>马戏星探</h2><p>一个重要的规则是发完牌之后，是不能自己理牌的。唯一能做的就是选择使用顶部的数字还是底部的数字。</p><h2 id="糟了个糕"><a href="#糟了个糕" class="headerlink" title="糟了个糕"></a>糟了个糕</h2><p>第一个棋子如果能优先走到绿区，并领先对手一个回合，那么很有可能能够嫖到高分绿板。</p><p>但是，走得太快并不一定很好。比如在后方你和别人为了一个反转板块或者高加分的板块而熬鹰，但是因为前面棋子动不了了，就不得不放弃熬鹰动这个棋子。</p><p>有一个棋子在比较靠后的位置挺重要的。</p><h2 id="种豆得金"><a href="#种豆得金" class="headerlink" title="种豆得金"></a>种豆得金</h2><p>本来是想要买 Bohnanza: Das Würfelspiel 的，但是买不到。这个也挺好玩的，核心的点是要通过交易把自己手牌中不要的豆给别人，让手牌更加规整。</p><h2 id="脑洞量表"><a href="#脑洞量表" class="headerlink" title="脑洞量表"></a>脑洞量表</h2><p>没买，用小程序玩的。</p><h2 id="瞎掰王"><a href="#瞎掰王" class="headerlink" title="瞎掰王"></a>瞎掰王</h2><p>春节玩了下。感觉容易放不开，编故事时间比较短，但是老实人总是担心自己说的不够全面。其实这个游戏是允许并且希望老实人忘词的。</p><h2 id="疯狂飞行棋"><a href="#疯狂飞行棋" class="headerlink" title="疯狂飞行棋"></a>疯狂飞行棋</h2><p>觉得不太平衡。我抽了一张场景牌，禁止其他玩家骰子为1的行为。然后中盘有成功把四个飞机叠起来了。最后，又抽了张到了终极轨道就能直接移动的牌。所以赢得非常快。</p><h2 id="并购"><a href="#并购" class="headerlink" title="并购"></a>并购</h2><p>小公司被并购前可以疯狂买便宜的股票。这样二换一很赚。</p><h2 id="森森不息"><a href="#森森不息" class="headerlink" title="森森不息"></a>森森不息</h2><p>要素过多。最后算分太难算了，每个树的分。每个动物的分。动物关联的分。树木关联的分。洞穴的分。</p><h2 id="诡镇奇谈：洛夫克拉夫情书"><a href="#诡镇奇谈：洛夫克拉夫情书" class="headerlink" title="诡镇奇谈：洛夫克拉夫情书"></a>诡镇奇谈：洛夫克拉夫情书</h2><p>类似于弹丸论破版本，感觉一般</p><h2 id="翡翠头骨"><a href="#翡翠头骨" class="headerlink" title="翡翠头骨"></a>翡翠头骨</h2><p>自己投骰子，别人下注赌你结果的游戏。</p><p>刀疤脸感觉也太好做了，觉得不是很平衡。</p><h2 id="动物园吹牛"><a href="#动物园吹牛" class="headerlink" title="动物园吹牛"></a>动物园吹牛</h2><p>感觉村规了，没啥意思</p><h2 id="来包洋芋片"><a href="#来包洋芋片" class="headerlink" title="来包洋芋片"></a>来包洋芋片</h2><p>简易版得州扑克，感觉挺好玩。</p><h2 id="Marrakech"><a href="#Marrakech" class="headerlink" title="Marrakech"></a>Marrakech</h2><p>在上海和性感哥玩的，一个魔毯互相覆盖的游戏。</p><h2 id="仙境幽谷"><a href="#仙境幽谷" class="headerlink" title="仙境幽谷"></a>仙境幽谷</h2><p>特点是有个大树。</p><h2 id="雪球保卫战"><a href="#雪球保卫战" class="headerlink" title="雪球保卫战"></a>雪球保卫战</h2><p>看上去很好玩，实际上很没意思。原因是操作是很有限的，基本上有点坐牢。</p><h2 id="爆炸猫-1"><a href="#爆炸猫-1" class="headerlink" title="爆炸猫"></a>爆炸猫</h2><h2 id="秒懂：心领神会"><a href="#秒懂：心领神会" class="headerlink" title="秒懂：心领神会"></a>秒懂：心领神会</h2><h2 id="还试好游戏"><a href="#还试好游戏" class="headerlink" title="还试好游戏"></a>还试好游戏</h2><h2 id="独家暗语"><a href="#独家暗语" class="headerlink" title="独家暗语"></a>独家暗语</h2><p>本来是想找印象画语的。</p><p>这个游戏感觉画的快太重要了。我觉得应该改为画的快和猜的快分开来算。</p><h2 id="冠军挑战者"><a href="#冠军挑战者" class="headerlink" title="冠军挑战者"></a>冠军挑战者</h2><p>玩法类似于卡牌构筑+自走棋。</p><p>奇数人会轮空打电脑，电脑贼厉害。</p><h2 id="神秘导语"><a href="#神秘导语" class="headerlink" title="神秘导语"></a>神秘导语</h2><p>类似于行动代号，但是提示词是前后相关的。</p><h2 id="空中之城"><a href="#空中之城" class="headerlink" title="空中之城"></a>空中之城</h2><p>类似于复杂一点的印加宝藏，感觉增加的部分让游戏更好玩了。</p><h2 id="犯罪现场"><a href="#犯罪现场" class="headerlink" title="犯罪现场"></a>犯罪现场</h2><p>每个人面前有四张卡片表示凶器，四张卡片表示证据。然后抽取 5 个身份牌，分别是 3 个侦探，1 个目击者，和 1 个凶手。凶手指定凶器和证据，目击者在不同的问题卡上放上序号为 1-6 的标记表示相关度，然后除了目击者之外的所有人都可以破案一次，找到正确的凶器和证据就可以胜利。</p><h2 id="炸弹克星"><a href="#炸弹克星" class="headerlink" title="炸弹克星"></a>炸弹克星</h2><p>挺好玩的，类似于合作版的逻辑对决，达芬奇密码这种。</p><p>关卡比宇航员多，难度比宇航员容易点。</p><p>我们引入了一些新的合作框架下竞争的方案：</p><ul><li>每一次剪线失败，则队员吃屎一个（脑洞量表）</li><li>每一局发生爆炸，则队长以及屎最多的队员吃牛头一个（牛头王）</li></ul><p>并且对于一些特殊局，也有特殊的方案：</p><ul><li>队长指定剪线的人<br>  队长不能恶意指定，队员不能恶意说没有。但是如果队长指定了不能剪线的队员，则队长吃屎。队员剪线失败，则队长吃屎。</li><li>氧气瓶<br>  如果导致了最后一个人剪线失败，则该轮耗费最多氧气的人也需要吃屎。</li></ul><h2 id="卡里巴湖"><a href="#卡里巴湖" class="headerlink" title="卡里巴湖"></a>卡里巴湖</h2><h2 id="电波同步"><a href="#电波同步" class="headerlink" title="电波同步"></a>电波同步</h2><h2 id="落叶翩翩"><a href="#落叶翩翩" class="headerlink" title="落叶翩翩"></a>落叶翩翩</h2><h2 id="榴莲忘返"><a href="#榴莲忘返" class="headerlink" title="榴莲忘返"></a>榴莲忘返</h2><h2 id="巨嘴鸟"><a href="#巨嘴鸟" class="headerlink" title="巨嘴鸟"></a>巨嘴鸟</h2><h2 id="旋转五子棋"><a href="#旋转五子棋" class="headerlink" title="旋转五子棋"></a>旋转五子棋</h2><h2 id="斑点狗"><a href="#斑点狗" class="headerlink" title="斑点狗"></a>斑点狗</h2><h2 id="竹林之中"><a href="#竹林之中" class="headerlink" title="竹林之中"></a>竹林之中</h2><h2 id="图灵机"><a href="#图灵机" class="headerlink" title="图灵机"></a>图灵机</h2><h2 id="巧手猜图"><a href="#巧手猜图" class="headerlink" title="巧手猜图"></a>巧手猜图</h2><h2 id="说梦人"><a href="#说梦人" class="headerlink" title="说梦人"></a>说梦人</h2><h2 id="初创公司"><a href="#初创公司" class="headerlink" title="初创公司"></a>初创公司</h2><h2 id="风声"><a href="#风声" class="headerlink" title="风声"></a>风声</h2><h2 id="菲力猫"><a href="#菲力猫" class="headerlink" title="菲力猫"></a>菲力猫</h2><h2 id="喵星人的星期天"><a href="#喵星人的星期天" class="headerlink" title="喵星人的星期天"></a>喵星人的星期天</h2><h2 id="东海道"><a href="#东海道" class="headerlink" title="东海道"></a>东海道</h2><h2 id="冰冷的她醒来之前"><a href="#冰冷的她醒来之前" class="headerlink" title="冰冷的她醒来之前"></a>冰冷的她醒来之前</h2><h2 id="不了不了"><a href="#不了不了" class="headerlink" title="不了不了"></a>不了不了</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍玩过的一些桌游。大概是按照结识的顺序来的。&lt;/p&gt;</summary>
    
    
    
    
    <category term="游戏" scheme="http://www.calvinneo.com/tags/游戏/"/>
    
  </entry>
  
  <entry>
    <title>TiCI 的设计考量</title>
    <link href="http://www.calvinneo.com/2025/01/11/fts-tici/"/>
    <id>http://www.calvinneo.com/2025/01/11/fts-tici/</id>
    <published>2025-01-11T07:57:20.000Z</published>
    <updated>2025-09-22T01:52:15.861Z</updated>
    
    <content type="html"><![CDATA[<p>主要介绍 TiCI 的一些实现。</p><a id="more"></a><h1 id="TiCI-的设计考量"><a href="#TiCI-的设计考量" class="headerlink" title="TiCI 的设计考量"></a>TiCI 的设计考量</h1><h2 id="写入路径"><a href="#写入路径" class="headerlink" title="写入路径"></a>写入路径</h2><ul><li>确定 Compaction 的策略</li><li>Compaction vs Split</li><li>S3 的 SlowDown</li></ul><h2 id="MetaService"><a href="#MetaService" class="headerlink" title="MetaService"></a>MetaService</h2><h3 id="Shard"><a href="#Shard" class="headerlink" title="Shard"></a>Shard</h3><p>在 shard 的大小上，我们默认设置为 4 GiB，这样对于 80 TiB 的集群规模，会有 20k+ 个 shard。一个 shard 中有多个 fragment，fragment 之间是可以 overlap 的，我们也按照传统方法引入了 leveled compaction。</p><p>过多（小）的 shard 和 fragment，对于查询是不利的：</p><ul><li>过多的 fragment，会导致每个 fragment 中的词典会很小，压缩率不高</li><li>此外，一个查询如果覆盖多个 fragment，就需要按照每个 fragment 的词典都过滤一遍，再 merge，这样并发上不去</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;主要介绍 TiCI 的一些实现。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>Full text search(FTS) 技术调研</title>
    <link href="http://www.calvinneo.com/2025/01/11/fts/"/>
    <id>http://www.calvinneo.com/2025/01/11/fts/</id>
    <published>2025-01-11T03:57:20.000Z</published>
    <updated>2025-09-22T01:50:33.852Z</updated>
    
    <content type="html"><![CDATA[<p>主要介绍 FTS 的一些实现。</p><a id="more"></a><h1 id="分词技术"><a href="#分词技术" class="headerlink" title="分词技术"></a>分词技术</h1><h2 id="ngram"><a href="#ngram" class="headerlink" title="ngram"></a>ngram</h2><h1 id="字典结构"><a href="#字典结构" class="headerlink" title="字典结构"></a>字典结构</h1><h2 id="ngram-bloomfilter"><a href="#ngram-bloomfilter" class="headerlink" title="ngram bloomfilter"></a>ngram bloomfilter</h2><ul><li>生成 N-gram： 将一个输入字符串生成所有可能的 N-gram。</li><li>存储到布隆过滤器： 对每个 N-gram 使用多个哈希函数，将其存储到布隆过滤器中。</li></ul><p>查询： 对查询的字符串生成对应的 N-gram，逐个检查它们是否存在于布隆过滤器中。</p><ul><li>如果布隆过滤器判定所有 N-gram 存在，说明可能是匹配。</li><li>如果至少有一个 N-gram 不存在，可以确定不匹配。</li></ul><p>缺点：</p><ul><li>存在 FP</li><li>不支持删除</li></ul><h2 id="BTree"><a href="#BTree" class="headerlink" title="BTree"></a>BTree</h2><h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><h2 id="KV-结构"><a href="#KV-结构" class="headerlink" title="KV 结构"></a>KV 结构</h2><p>存储分词后的倒排索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&quot;OceanBase&quot; -&gt; [Doc1, Doc2]</span><br><span class="line">&quot;is&quot; -&gt; [Doc1]</span><br><span class="line">&quot;a&quot; -&gt; [Doc1]</span><br><span class="line">&quot;distributed&quot; -&gt; [Doc1]</span><br><span class="line">&quot;supports&quot; -&gt; [Doc2]</span><br><span class="line">&quot;full-text&quot; -&gt; [Doc2]</span><br><span class="line">&quot;search&quot; -&gt; [Doc2]</span><br></pre></td></tr></table></figure><h2 id="FST-Finite-State-Transducer"><a href="#FST-Finite-State-Transducer" class="headerlink" title="FST(Finite-State Transducer)"></a>FST(Finite-State Transducer)</h2><p>FST 是一种 Trie 树的结构。</p><h2 id="MultiValue-Index"><a href="#MultiValue-Index" class="headerlink" title="MultiValue Index"></a>MultiValue Index</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;主要介绍 FTS 的一些实现。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>内存领域知识</title>
    <link href="http://www.calvinneo.com/2025/01/03/memory-context-knowledge/"/>
    <id>http://www.calvinneo.com/2025/01/03/memory-context-knowledge/</id>
    <published>2025-01-03T07:06:10.000Z</published>
    <updated>2025-09-29T14:56:22.653Z</updated>
    
    <content type="html"><![CDATA[<p>从<a href="/2025/01/03/jemalloc-impl/">jemalloc 的实现</a>过来的。</p><a id="more"></a><h1 id="OOMKiller"><a href="#OOMKiller" class="headerlink" title="OOMKiller"></a>OOMKiller</h1><h2 id="Linux-的-overcommit-机制"><a href="#Linux-的-overcommit-机制" class="headerlink" title="Linux 的 overcommit 机制"></a>Linux 的 overcommit 机制</h2><ul><li>如果关闭 overcommit 机制，那么大部分的 OOM 现象将会消失，因为系统分配内存会更加保守</li><li>如果开启 overcommit 机制，会根据物理内存、swap 和 overcommit_ratio 判断是否能够分配出内存，依然可能会分配失败  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CommitLimit = [swap size] + [RAM size] * vm.overcommit_ratio / 100</span><br></pre></td></tr></table></figure></li></ul><h1 id="mmap"><a href="#mmap" class="headerlink" title="mmap"></a>mmap</h1><h2 id="mmap-1"><a href="#mmap-1" class="headerlink" title="mmap"></a>mmap</h2><p>几个 flag：</p><ul><li>MAP_SHARED</li><li>MAP_SHARED_VALIDATE </li><li>MAP_PRIVATE<br>  创建一个 private 的 COW mapping。对这个 mapping 的修改不会对其他进程可见，也不会写到下面的文件里面。<br>  It is unspecified whether changes made to the file after the mmap() call are visible in the mapped region.</li></ul><h2 id="msync"><a href="#msync" class="headerlink" title="msync"></a>msync</h2><p>表示从内存刷回到底层文件中。除此之外，只有 munmap 能确保进行这样的刷盘。</p><ul><li>MS_ASYNC</li><li>MS_SYNC</li><li>MS_INVALIDATE<br>  Asks to invalidate other mappings of the same file (so that they can be updated with the fresh values just written)</li></ul><h2 id="madvise"><a href="#madvise" class="headerlink" title="madvise"></a>madvise</h2><ul><li><p>MADV_NORMAL<br>  默认行为，内核根据普通访问模式处理页面。</p></li><li><p>MADV_RANDOM<br>  随机访问，可能减少 prefetch 操作。</p></li><li><p>MADV_SEQUENTIAL<br>  顺序访问，可以增加 prefetch。</p></li><li><p>MADV_WILLNEED<br>  表示该内存区域将在未来使用，内核可以提前加载到内存。</p></li><li><p>MADV_DONTNEED / MADV_FREE / munmap<br>  三个都是释放内存。后面详细描述。</p></li><li><p>MADV_REMOVE<br>  从文件映射中移除内存区域，释放物理内存，同时在映射的文件中移除相应内容（需要文件映射）。</p></li><li><p>MADV_DONTFORK<br>  子进程不会继承该内存区域。</p></li><li><p>MADV_DOFORK</p></li><li><p>MADV_MERGEABLE<br>  启用内存合并（KSM，Kernel Samepage Merging），允许内核将具有相同内容的内存页面合并以节省内存。</p></li><li><p>MADV_UNMERGEABLE</p></li><li><p>MADV_HUGEPAGE  (since Linux 2.6.38)<br>  表示要去分配一个透明大页，即 Transparent Huge Pages (THP)。</p><ul><li>内核会不停扫描，将一段内存变为透明大页</li><li>如果分配的地址是对齐的，那么内核可能直接分配为透明大页</li></ul><p>  大部分通用的内核都会选择默认开启 THP，而那些嵌入式的系统则可能选择不默认开启。</p></li><li><p>MADV_COLLAPSE<br>  尽力将普通页面转换为透明大页。</p></li><li><p>MADV_NOHUGEPAGE</p></li><li><p>MADV_SOFT_OFFLINE<br>  将指定区域中的坏内存页标记为不可用，但不杀死当前进程。</p></li><li><p>MADV_HWPOISON<br>  强制将页面标记为硬件错误（仅管理员权限可用）。</p></li></ul><p>三个释放内存：</p><ul><li>munmap<br>  即时释放物理内存(RSS)以及虚拟地址。</li><li>MADV_DONTNEED<br>  即时释放物理内存(RSS)。保留虚拟地址，但可能会造成虚拟地址紧张。</li><li>MADV_FREE<br>  延迟释放。</li></ul><p>进一步可以参考 <a href="https://zhuanlan.zhihu.com/p/570033679%E3%80%82%E6%88%91%E7%90%86%E8%A7%A3%E4%BB%8E" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/570033679。我理解从</a> munmap 到 MADV_FREE 代价越来越小。</p><h2 id="关于透明大页"><a href="#关于透明大页" class="headerlink" title="关于透明大页"></a>关于透明大页</h2><p>使用透明大页的缺点：</p><ul><li>透明大页的后台进程 khugepaged 在扫描到目标页时，会短暂挂起进程，这会影响内存读写操作的延迟。</li><li>在 CoW 时，会产生写放大。</li><li>出现 NUMA 跨节点访问的时候，也会出现放大。</li></ul><h1 id="PageCache-和缺页中断"><a href="#PageCache-和缺页中断" class="headerlink" title="PageCache 和缺页中断"></a>PageCache 和缺页中断</h1><h1 id="NUMA-架构"><a href="#NUMA-架构" class="headerlink" title="NUMA 架构"></a>NUMA 架构</h1><h1 id="shm"><a href="#shm" class="headerlink" title="shm"></a>shm</h1><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://man7.org/linux/man-pages/man7/shm_overview.7.html" target="_blank" rel="noopener">https://man7.org/linux/man-pages/man7/shm_overview.7.html</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;从&lt;a href=&quot;/2025/01/03/jemalloc-impl/&quot;&gt;jemalloc 的实现&lt;/a&gt;过来的。&lt;/p&gt;</summary>
    
    
    
    
    <category term="内存管理" scheme="http://www.calvinneo.com/tags/内存管理/"/>
    
  </entry>
  
  <entry>
    <title>jemalloc 的实现</title>
    <link href="http://www.calvinneo.com/2025/01/03/jemalloc-impl/"/>
    <id>http://www.calvinneo.com/2025/01/03/jemalloc-impl/</id>
    <published>2025-01-03T06:06:10.000Z</published>
    <updated>2025-09-29T14:55:59.069Z</updated>
    
    <content type="html"><![CDATA[<p>介绍下 jemalloc 的实现。目前的实现和 4.5 及之前的实现还是有比较大的差别的。因此代码主要是看的 4.5，并介绍了下 5.2.1 的几个重要的变化。</p><a id="more"></a><h1 id="设计理念"><a href="#设计理念" class="headerlink" title="设计理念"></a>设计理念</h1><ul><li>最大化内存分配和释放的性能</li><li>减少内部碎片和外部碎片</li><li>减少线程之间的竞争和 false sharing</li><li>支持 heap profiling</li></ul><h1 id="实现理念"><a href="#实现理念" class="headerlink" title="实现理念"></a>实现理念</h1><h2 id="基本情况"><a href="#基本情况" class="headerlink" title="基本情况"></a>基本情况</h2><p>jemalloc 中定义了一系列 size classes，这是通过 size_classes.h 生成的。从小到大可以进行编号，例如大小在 0 到 8 之间的就是 0 号，8 到 16 之间的就是 1 号。size2index 和 index2size 可以实现转换。</p><h3 id="4-5-版本"><a href="#4-5-版本" class="headerlink" title="4.5 版本"></a>4.5 版本</h3><p>基于内存大小，把申请的内存分为三类：</p><ul><li>Small 的 size 小于 page 大小，为 8/16/32 bytes 等。会返回某个 run 中的一个 region。</li><li>Large 以 page 为单位，小于 chunk 的大小。会返回一个 run。</li><li>Huge 会使用多个 chunk。<br>  所以 Huge 是按照 chunk 对齐的，这通常被用来区分一个地址是否属于 Huge。</li></ul><p>因为 tcache 的存在，内存分配可能和上述相比有更多的优化。</p><p>名词解释：</p><ul><li>page 指的是操作系统的 page，一般是 4KB。mmap 系统调用分配内存以 page 为单位，但分配的内存未必是按照 page size 对齐的，所以可能要多分配一些出来，然后 trim。</li><li>chunk 指的是 jemalloc 向 OS 申请内存的最小单位。它一定是 page size 的倍数。默认是 2MiB。</li><li>run：一个 chunk 分成多个<strong>不同大小</strong>的 run。</li><li>region：一个 run 分成多个<strong>相同大小</strong>的 region。Small 对象的内存分配和释放就是标记某个 region 被使用。</li><li>bin：由 bin 管理存储同一种大小的 Small 对象（也就是说同一种 size class）的多个 run。</li></ul><h2 id="【4-5-版本】chuck-的基本设计"><a href="#【4-5-版本】chuck-的基本设计" class="headerlink" title="【4.5 版本】chuck 的基本设计"></a>【4.5 版本】chuck 的基本设计</h2><p>arena_chunk_s 的结构如下所示：</p><ul><li>extent_node_t 的 node</li><li>arena_chunk_map_bits_t 即 arena_chunk_map_bits_s 类型的 map_bits<br>  包含了 chunk 中除了 header 使用的 page 之外的所有 page 的元信息。</li><li>arena_chunk_map_misc_t 即 arena_chunk_map_misc_s<br>  记录了各个 run 的元信息。<br>  这个结构并没有在 arena_chunk_s 中被表示出来。应该是 C 语言的问题。</li><li>pages，也就是 payload</li></ul><p>这个 map_bits 的长度实际上等于 map_bias，是在 arena_boot 中计算的。这个计算有个神奇的 <code>for (i &lt; 3)</code> 循环，将在后面介绍。</p><p>arena_chunk_map_bits_t 是一个 size_t。它如何设置，取决于 page 是 run 的第一个、中间的、普通的 page。以及 run 的类型是未分配、small 和 large。容易推断出，一个 run 至少对应一个 page。</p><p>在初始化时还会设置：</p><ul><li>arena_maxrun 等于 chunk 的大小减去 header 的大小。</li><li>large_maxclass：Large 类型的 class 的最大的大小。</li></ul><h2 id="【4-5-版本】run-的基本设计"><a href="#【4-5-版本】run-的基本设计" class="headerlink" title="【4.5 版本】run 的基本设计"></a>【4.5 版本】run 的基本设计</h2><p>arena_chunk_map_misc_t 是 run 的元信息，前面提到，它也是存在 chunk 的 header 中，而不会有自己单独的 run header。</p><p>ph_link 有两个互斥的用途：</p><ul><li>在 arena_s 中的 runs_avail 堆，用来管理 arena 中所有可用的 run</li><li>在 arena_bin_s 中的 runs 堆，用来管理分配给某个 bin 的 run</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">arena_chunk_map_misc_s</span> &#123;</span></span><br><span class="line">    phn(<span class="keyword">arena_chunk_map_misc_t</span>)     ph_link;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">union</span> &#123;</span><br><span class="line">        <span class="comment">/* Linkage for list of dirty runs. */</span></span><br><span class="line">        <span class="keyword">arena_runs_dirty_link_t</span>     rd;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Profile counters, used for large object runs. */</span></span><br><span class="line">        <span class="keyword">union</span> &#123;</span><br><span class="line">            <span class="keyword">void</span>            *prof_tctx_pun;</span><br><span class="line">            <span class="keyword">prof_tctx_t</span>     *prof_tctx;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Small region run metadata. */</span></span><br><span class="line">        <span class="keyword">arena_run_t</span>         run;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>通过 arena_run_split_small 函数，可以将 run 分解，得到对应 size 的一系列 run，并交给对应的 bin 管理。</p><p>通过 arena_run_coalesce 函数，run 在释放时也可以被前后合并。</p><p>对于 Small 结构，有 arena_run_t 结构用来维护</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">arena_run_s</span> &#123;</span></span><br><span class="line">    <span class="keyword">szind_t</span>     binind;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">unsigned</span>    nfree;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">bitmap_t</span>    bitmap[BITMAP_GROUPS_MAX];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="【4-5-版本】bin-的基本设计"><a href="#【4-5-版本】bin-的基本设计" class="headerlink" title="【4.5 版本】bin 的基本设计"></a>【4.5 版本】bin 的基本设计</h2><p>runs_avail 是一个数组，数组长度等于 runs_avail_nclasses。分配给 bin 的 run 会从 arena_s 的 runs_avail 中删除，移动到 arena_bin_s 管理。其中，runcur 记录目前正在被用来分配的 run。runs 记录目前非空、非满的 run。此外：</p><ul><li>空的 bin 不会被任何结构记录，因为这个时候内存都已经分配给用户了，用户理应通过 free 来释放内存。</li><li>满的 bin 会被会收到 runs_avail 中</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">arena_bin_s</span> &#123;</span></span><br><span class="line">    <span class="keyword">malloc_mutex_t</span>      lock;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">arena_run_t</span>     *runcur;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">arena_run_heap_t</span>    runs;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Bin statistics. */</span></span><br><span class="line">    <span class="keyword">malloc_bin_stats_t</span>  stats;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>为什么 run 被记录在 arena 而不是 chunk 中呢？</p><h2 id="free"><a href="#free" class="headerlink" title="free"></a>free</h2><p>这里定义 pageind 为</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pageind = ((<span class="keyword">uintptr_t</span>)ptr - (<span class="keyword">uintptr_t</span>)chunk) &gt;&gt; LG_PAGE;</span><br></pre></td></tr></table></figure><h3 id="5-2-1"><a href="#5-2-1" class="headerlink" title="5.2.1"></a>5.2.1</h3><p>首先需要区分 Huge、Large 和 Small：</p><ul><li>Huge 可以判断是否和 chunk 大小也就是 2MiB 对齐。</li><li>Large 可以通过 page 对应的 map_bits 和 CHUNK_MAP_LARGE 做 and 来实现。</li></ul><p>Small 比较麻烦，因为还需要找到对应的 region。</p><p>在 arena_dalloc_small 中处理，主要是调用 arena_dalloc_bin，然后调用 arena_decay_tick。</p><p>步骤是：</p><ul><li>找到对应的 run page offset，也就是 <code>pppppppp pppppppp ppp</code>。也就是这个 region 对应的 run 的第一个 page。</li><li>然后获得这个 run 的 misc 数据。目的是找到 run 对应的 bin 是哪个。</li><li>对对应的 bin 加锁，执行 arena_dalloc_bin_locked_impl。在 4.2.1 中这个函数有一些重复计算的地方不知道为啥。这个函数主要调用 arena_run_reg_dalloc，后面还有一些对 bin 是否为空的判断。</li></ul><p><code>arena_run_reg_dalloc</code> 的有效过程是：</p><ul><li>arena_run_regind 获得 region id</li><li><code>bitmap_unset(run-&gt;bitmap, &amp;bin_info-&gt;bitmap_info, regind);</code> 标记这个 region 被释放。</li></ul><h2 id="【5-2-1-版本】-extent-gt-slab-gt-region"><a href="#【5-2-1-版本】-extent-gt-slab-gt-region" class="headerlink" title="【5.2.1 版本】 extent -&gt; slab -&gt; region"></a>【5.2.1 版本】 extent -&gt; slab -&gt; region</h2><p>从 5.x 版本开始，jemalloc 使用 extent -&gt; slab -&gt; region 代替了原有的三级分配模式。对应的 release node 如下：</p><blockquote><p>Organize virtual memory as “extents” of virtual memory pages, rather than as<br>naturally aligned “chunks”, and store all metadata in arbitrarily distant<br>locations.  This reduces virtual memory external fragmentation, and will<br>interact better with huge pages (not yet explicitly supported).  (@jasone)</p></blockquote><p>对比如下：</p><ul><li>Chunks (Pre-5.0.0)<ul><li>Naturally aligned: Chunks were aligned to their own size boundaries (e.g., a 2MB chunk was aligned to 2MB boundaries) ChangeLog:397-402</li><li>Fixed size: Chunks had predetermined sizes that were powers of 2</li><li>Metadata co-location: Metadata was stored within the chunk itself</li><li>Hierarchy: Used chunk → run → region structure</li></ul></li><li>Extents (5.0.0+)<ul><li>Page-aligned: Extents are only aligned to page boundaries, not their own size ChangeLog:479-482</li><li>Variable size: Extents can be any multiple of the page size</li><li>Metadata separation: Metadata is stored in “arbitrarily distant locations” from the extent data ChangeLog:479-482</li><li>Simplified hierarchy: Uses extent → slab → region structure</li></ul></li></ul><h2 id="purge"><a href="#purge" class="headerlink" title="purge"></a>purge</h2><h3 id="muzzy-和-dirty"><a href="#muzzy-和-dirty" class="headerlink" title="muzzy 和 dirty"></a>muzzy 和 dirty</h3><p>purge <a href="https://youjiali1995.github.io/allocator/jemalloc-purge/" target="_blank" rel="noopener">分为几个阶段</a>：</p><ul><li>active -&gt; dirty<br>  变为 dirty 后，heap profiling 是无法看到的。但是 RSS 依然较高。</li><li>dirty -&gt; muzzy<br>  调用 madvise(MADV_FREE)</li><li>muzzy -&gt; cleaned<br>  调用 madvise(MADV_DONTNEED)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * Methods for purging unused pages differ between operating systems.</span><br><span class="line"> *</span><br><span class="line"> *   madvise(..., MADV_FREE) : This marks pages as being unused, such that they</span><br><span class="line"> *                             will be discarded rather than swapped out.</span><br><span class="line"> *   madvise(..., MADV_DONTNEED) : If JEMALLOC_PURGE_MADVISE_DONTNEED_ZEROS is</span><br><span class="line"> *                                 defined, this immediately discards pages,</span><br><span class="line"> *                                 such that new pages will be demand-zeroed if</span><br><span class="line"> *                                 the address region is later touched;</span><br><span class="line"> *                                 otherwise this behaves similarly to</span><br><span class="line"> *                                 MADV_FREE, though typically with higher</span><br><span class="line"> *                                 system overhead.</span><br><span class="line"> */</span><br></pre></td></tr></table></figure><h3 id="何时-purge"><a href="#何时-purge" class="headerlink" title="何时 purge"></a>何时 purge</h3><p>有两个 ctl，对应了 <code>arena.$i.{purtge,decay}</code> 命令，相关<a href="https://jemalloc.net/jemalloc.3.html" target="_blank" rel="noopener">文档</a>：</p><ul><li>arena_i_purge_ctl<br>  Purge all unused dirty pages for arena <code>&lt;i&gt;</code>, or for all arenas if <code>&lt;i&gt;</code> equals MALLCTL_ARENAS_ALL.</li><li>arena_i_decay_ctl<br>  Trigger decay-based purging of unused dirty/muzzy pages for arena <code>&lt;i&gt;</code>, or for all arenas if <code>&lt;i&gt;</code> equals MALLCTL_ARENAS_ALL.<br>  The proportion of unused dirty/muzzy pages to be purged depends on the current time; see opt.dirty_decay_ms and opt.muzy_decay_ms for details.</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">ctl_named_node_t</span> arena_i_node[] = &#123;</span><br><span class="line">    &#123;NAME(<span class="string">"purge"</span>),     CTL(arena_i_purge)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"decay"</span>),     CTL(arena_i_decay)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"reset"</span>),     CTL(arena_i_reset)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"dss"</span>),       CTL(arena_i_dss)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"lg_dirty_mult"</span>), CTL(arena_i_lg_dirty_mult)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"decay_time"</span>),    CTL(arena_i_decay_time)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"chunk_hooks"</span>),   CTL(arena_i_chunk_hooks)&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>purge 和 decay 的区别，是 <code>arena_purge</code> 的 <code>all</code> 参数。实际上导致了调用的是 <code>arena_purge_to_limit(ndirty_limit=0)</code> 还是 <code>arena_maybe_purge</code>。</p><p>arena_maybe_purge 分为两种模式，受到 opt_purge 管理：</p><ul><li>purge_mode_ratio<br>  purge 更少的 page，直到满足 arena-&gt;ndirty &lt;= ndirty_limit。<br>  这个应该是对应了 lazy 模式。</li><li>purge_mode_decay<br>  purge 尽可能多的 page，但是不违背 arena-&gt;ndirty &gt;= ndirty_limit。<br>  这实际上是默认值。decay 实际上是基于时间的管理。</li></ul><p>实际上这里 ndirty_limit 就是能够容忍的最多的 dirty page 的数量。</p><p>看看默认的 purge_mode_decay 模式，首先要检查下结构 <code>arena_decay_s</code>：</p><ul><li>time<br>  Approximate time in seconds from the creation of a set of unused dirty pages until an equivalent set of unused dirty pages is purged and/or reused.<br>  产生的 dirty pages 会在 decay_time 时间后全部 purge。默认是 10s。</li><li>interval<br>  time / SMOOTHSTEP_NSTEPS。相当于分这么多组去 decay，而不是一次性搞完，从而避免每次占用较多的资源。<br>  SMOOTHSTEP_NSTEPS 等于 200。</li><li>epoch<br>  Time at which the current decay interval logically started.<br>  We do not actually advance to a new epoch until sometime after it starts because of scheduling and computation delays, and it is even possible to completely skip epochs.<br>  In all cases, during epoch advancement we merge all relevant activity into the most recently recorded epoch.<br>  结合 interval 和 deadline 的理解就是 epoch 理论上就是不断自增 interval，但实际上什么时候开始是不确定的，甚至可能跳过某些 epoch。每个 epoch 开始的时候会处理之前的所有工作。</li><li>deadline<br>  Deadline for current epoch.<br>  This is the sum of interval and per epoch jitter. 实际上就是 <code>[epoch + interval, epoch + 2*interval)</code>。<br>  Epochs always advance by precise multiples of interval, but we but we randomize the deadline to reduce the likelihood of arenas purging in lockstep.</li><li>ndirty<br>  epoch 开始的时候 dirty page 的数量。</li><li>backlog<br>  Trailing log of how many unused dirty pages were generated during each of the past SMOOTHSTEP_NSTEPS decay epochs, where the last element is the most recent epoch. Corresponding epoch times are relative to epoch.</li></ul><blockquote><p>因为在 purge 的过程中，会有新的 dirty page 产生，所以将整个 purge 划分为 SMOOTHSTEP_NSTEPS 组，每组分别负责 interval 时间内产生的 dirty page 的回收，每组能保留的 dirty pages 数量根据 Smootherstep 曲线，总的能保留的 dirty page 数量为 200 组的叠加，超出的会 purge。</p></blockquote><p>实现在 arena_maybe_purge_decay：</p><ul><li>arena_decay_deadline_reached 检查 <code>decay.deadline</code> 是否已经到达</li><li>arena_decay_epoch_advance<ul><li>arena_decay_epoch_advance_helper</li><li>arena_decay_epoch_advance_purge<br>  计算出 ndirty_limit。调用 arena_purge_to_limit(ndirty_limit)，更新 decay.dirty。</li></ul></li></ul><h3 id="Smooth-steps-曲线"><a href="#Smooth-steps-曲线" class="headerlink" title="Smooth steps 曲线"></a>Smooth steps 曲线</h3><p>SMOOTHSTEP 是一个表：</p><ul><li>x 从 0.005 开始递增到 1.000</li><li>y 是对应 x 取值时，smooth step 函数的值。对于 jemalloc 的场景，就是在 x 的时刻，需要回收大概多少的内存了</li><li>h 是 y 乘上 <code>2 ** SMOOTHSTEP_BFP</code> 的结果，这样转成整数计算方便很多</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SMOOTHSTEP_VARIANT  <span class="meta-string">"smoother"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SMOOTHSTEP_NSTEPS   200</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SMOOTHSTEP_BFP      24</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SMOOTHSTEP \</span></span><br><span class="line"> <span class="comment">/* STEP(step, h,                            x,     y) */</span> \</span><br><span class="line">    STEP(   <span class="number">1</span>, UINT64_C(<span class="number">0x0000000000000014</span>), <span class="number">0.005</span>, <span class="number">0.000001240643750</span>) \</span><br><span class="line">    STEP(   <span class="number">2</span>, UINT64_C(<span class="number">0x00000000000000a5</span>), <span class="number">0.010</span>, <span class="number">0.000009850600000</span>) \</span><br></pre></td></tr></table></figure><p>这个 SMOOTHSTEP 宏是计算机生成的，但也可以手算，结果如下。可以看到 20 和 0x14 相等。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ dc</span><br><span class="line">&gt; 5 k 2 24 ^ 0.000001240643750 * p</span><br><span class="line">20.814548172800000</span><br></pre></td></tr></table></figure><h3 id="5-2-1-版本的-purge-和-decay"><a href="#5-2-1-版本的-purge-和-decay" class="headerlink" title="5.2.1 版本的 purge 和 decay"></a>5.2.1 版本的 purge 和 decay</h3><p>在 4.5 中，使用 dirty_time。到了 5.2.1 中，就变成了 dirty_decay_ms 和 muzzy_decay_ms 了，但值还是一样的。</p><p>这个<a href="https://github.com/CalvinNeo/jemalloc/tree/debug" target="_blank" rel="noopener">基于 5.2.1 的分支</a>上有我的一些调试记录。</p><p>这里，有个结论是 5.2.1 上如果不开启 background thread 特性，那么指定 dirty_decay_ms 为非 0 值，则可能起不到预期的回收 dirty 页面的效果。我也在 tiflash 这个 binary 上进行了测试，验证过：</p><ul><li>关闭 background thread，但是开启 dirty_decay_ms，则后续手动 purge 仍有 RSS 内存释放</li><li>开启 background thread，且开启 dirty_decau_ms，则内存会被回收，稍后手动 purge 不会进一步释放 RSS 内存</li></ul><p>原因是回收的逻辑大概如下：</p><ul><li>如果 decay_ms 为 0，则在 arena_maybe_decay 中会直接调用 arena_decay_to_limit 去 purge。这实际上是会 purge 最多 current_npages。</li><li>否则判断是否到达这个 epoch 的 deadline<ul><li>如果是，则调用 arena_decay_epoch_advance<br>  在这个函数中，会判断是否开启 background thread 特性。<br>  如果关闭，会调用 arena_decay_try_purge，这也是 background thread 关闭后唯一释放内存的路径。如果开启，则只有当前线程是 background thread 的时候才会调用 arena_decay_try_purge。<br>  如果 purge，会 purge 最多 current_npages。</li><li>如果否，则只有当前线程是 background thread 的时候，才会调用 arena_decay_try_purge。purge 最多 arena_decay_backlog_npages_limit。  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span> (is_background_thread) &#123;</span><br><span class="line">    arena_decay_try_purge(tsdn, arena, decay, extents,</span><br><span class="line">        extents_npages_get(extents),</span><br><span class="line">        arena_decay_backlog_npages_limit(decay),</span><br><span class="line">        is_background_thread);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>从上述逻辑发现，只要 background thread 特性被关闭，则 arena_maybe_decay 即使被调用，也不会有渐进的 decay。</p><p>BTW，这儿的 epoch 确实比较重要，比如 <a href="https://github.com/CalvinNeo/jemalloc/blob/a7a05294e8148007cd29b9630d789b46d7e6a2ae/test.cpp#L116" target="_blank" rel="noopener">这如果不 epoch 一下</a>，就不会更新内存分配情况。</p><p>从 arena_maybe_decay 再往上层的调用关系大概有下面几条链路：</p><ul><li>arena_decay_ms_set 和 arena_decay_impl 会调用 arena_maybe_decay。</li><li>arena_decay_dirty 和 arena_decay_muzzy 会调用 arena_decay_impl。<ul><li>arena_extents_dirty_dalloc 和 arena_decay 会调用 arena_decay_dirty。</li></ul></li></ul><p>我在 test.cpp 中做了实验。在 free 的时候，会调用 arena_extents_dirty_dalloc。而 arena_decay 在下面被调用：</p><ul><li>arena_decay_ticks</li><li>background_work_sleep_once</li><li>ctl 方法 arena_i_decay</li><li>ctl 方法 arena_i_destroy_ctl</li><li>tcache_destroy</li></ul><h4 id="arena-decay-to-limit-的实现"><a href="#arena-decay-to-limit-的实现" class="headerlink" title="arena_decay_to_limit 的实现"></a>arena_decay_to_limit 的实现</h4><p>注意，这一部分的代码，和最新版本又不太一样了，主要是最新版本中又加了 ecache 对象。</p><ol><li>创建一个 extent_list_t。获得当前 arena 的 extent_hook_t。</li><li>arena_stash_decayed<br> 调用 extents_evict，如果返回非 NULL，则 append 到刚创建的 extent_list_t 结构中。</li><li>arena_decay_stashed<br> 遍历 extent_list_t 结构。 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span> (extents_state_get(extents)) &#123;</span><br><span class="line"><span class="keyword">case</span> extent_state_active:</span><br><span class="line">    not_reached();</span><br><span class="line"><span class="keyword">case</span> extent_state_dirty:</span><br><span class="line">    <span class="keyword">if</span> (!all &amp;&amp; muzzy_decay_ms != <span class="number">0</span> &amp;&amp;</span><br><span class="line">        !extent_purge_lazy_wrapper(tsdn, arena,</span><br><span class="line">        r_extent_hooks, extent, <span class="number">0</span>,</span><br><span class="line">        extent_size_get(extent))) &#123;</span><br><span class="line">        extents_dalloc(tsdn, arena, r_extent_hooks,</span><br><span class="line">            &amp;arena-&gt;extents_muzzy, extent);</span><br><span class="line">        arena_background_thread_inactivity_check(tsdn,</span><br><span class="line">            arena, is_background_thread);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* Fall through. */</span></span><br><span class="line"><span class="keyword">case</span> extent_state_muzzy:</span><br><span class="line">    extent_dalloc_wrapper(tsdn, arena, r_extent_hooks,</span><br><span class="line">        extent);</span><br><span class="line">    <span class="keyword">if</span> (config_stats) &#123;</span><br><span class="line">        nunmapped += npages;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> extent_state_retained:</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">    not_reached();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="4-5-如何-purge"><a href="#4-5-如何-purge" class="headerlink" title="4.5 如何 purge"></a>4.5 如何 purge</h3><p>这里以 4.5 的 arena_purge_to_limit 来讲解。</p><p>首先介绍两个结构 rd_link 和 cc_link。它们就是我们要清理的对象，都是 qr 结构的链表。</p><p>rd_link 对应了要回收的 run，cc_link 对应了要回收的 chunk。容易想到，run 和 chunk 的回收方式可能是不一样的，chunk 可能最终会被通过 munmap 返回给系统。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">arena_runs_dirty_link_s</span> &#123;</span></span><br><span class="line">    qr(<span class="keyword">arena_runs_dirty_link_t</span>) rd_link;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">extent_node_s</span> &#123;</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">/* Linkage for arena's runs_dirty and chunks_cache rings. */</span></span><br><span class="line">    <span class="keyword">arena_runs_dirty_link_t</span> rd;</span><br><span class="line">    qr(<span class="keyword">extent_node_t</span>)   cc_link;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>代码如下，可以看到，它将要释放的 chunk 和 run 分别放到 purge_chunks_sentinel 和 purge_runs_sentinel 中进行管理。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">arena_purge_to_limit(<span class="keyword">tsdn_t</span> *tsdn, <span class="keyword">arena_t</span> *arena, <span class="keyword">size_t</span> ndirty_limit)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">chunk_hooks_t</span> chunk_hooks = chunk_hooks_get(tsdn, arena);</span><br><span class="line">    <span class="keyword">size_t</span> npurge, npurged;</span><br><span class="line">    <span class="keyword">arena_runs_dirty_link_t</span> purge_runs_sentinel;</span><br><span class="line">    <span class="keyword">extent_node_t</span> purge_chunks_sentinel;</span><br><span class="line"></span><br><span class="line">    arena-&gt;purging = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Calls to arena_dirty_count() are disabled even for debug builds</span></span><br><span class="line"><span class="comment">     * because overhead grows nonlinearly as memory usage increases.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">false</span> &amp;&amp; config_debug) &#123;</span><br><span class="line">        <span class="keyword">size_t</span> ndirty = arena_dirty_count(arena);</span><br><span class="line">        assert(ndirty == arena-&gt;ndirty);</span><br><span class="line">    &#125;</span><br><span class="line">    assert(opt_purge != purge_mode_ratio || (arena-&gt;nactive &gt;&gt;</span><br><span class="line">        arena-&gt;lg_dirty_mult) &lt; arena-&gt;ndirty || ndirty_limit == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    qr_new(&amp;purge_runs_sentinel, rd_link);</span><br><span class="line">    extent_node_dirty_linkage_init(&amp;purge_chunks_sentinel);</span><br><span class="line"></span><br><span class="line">    npurge = arena_stash_dirty(tsdn, arena, &amp;chunk_hooks, ndirty_limit,</span><br><span class="line">        &amp;purge_runs_sentinel, &amp;purge_chunks_sentinel);</span><br><span class="line">    <span class="keyword">if</span> (npurge == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">goto</span> label_return;</span><br><span class="line">    npurged = arena_purge_stashed(tsdn, arena, &amp;chunk_hooks,</span><br><span class="line">        &amp;purge_runs_sentinel, &amp;purge_chunks_sentinel);</span><br><span class="line">    assert(npurged == npurge);</span><br><span class="line">    arena_unstash_purged(tsdn, arena, &amp;chunk_hooks, &amp;purge_runs_sentinel,</span><br><span class="line">        &amp;purge_chunks_sentinel);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config_stats)</span><br><span class="line">        arena-&gt;stats.npurge++;</span><br><span class="line"></span><br><span class="line">label_return:</span><br><span class="line">    arena-&gt;purging = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的脉络是：</p><ul><li>extent_node_dirty_linkage_init</li><li>arena_stash_dirty</li><li>arena_purge_stashed</li><li>arena_unstash_purged 是真正的释放过程</li></ul><h4 id="chunk-的释放策略"><a href="#chunk-的释放策略" class="headerlink" title="chunk 的释放策略"></a>chunk 的释放策略</h4><p>调用 chunk_dalloc_wrapper，这里面对 chunk_hooks 有个判断，默认是走 chunk_dalloc_default_impl。最终实际上会调用 mummap。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">bool</span></span><br><span class="line">chunk_dalloc_default_impl(<span class="keyword">void</span> *chunk, <span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!have_dss || !chunk_in_dss(chunk))</span><br><span class="line">        <span class="keyword">return</span> (chunk_dalloc_mmap(chunk, size));</span><br><span class="line">    <span class="keyword">return</span> (<span class="literal">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">bool</span></span><br><span class="line">chunk_dalloc_mmap(<span class="keyword">void</span> *chunk, <span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config_munmap)</span><br><span class="line">        pages_unmap(chunk, size);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (!config_munmap);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span></span><br><span class="line">pages_unmap(<span class="keyword">void</span> *addr, <span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> _WIN32</span></span><br><span class="line">    <span class="keyword">if</span> (VirtualFree(addr, <span class="number">0</span>, MEM_RELEASE) == <span class="number">0</span>)</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="keyword">if</span> (munmap(addr, size) == <span class="number">-1</span>)</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    &#123;</span><br><span class="line">...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="run-的释放策略"><a href="#run-的释放策略" class="headerlink" title="run 的释放策略"></a>run 的释放策略</h4><p>调用 arena_run_dalloc。</p><ul><li>如果释放这个 run 导致 chunk 闲置，则调用 arena_chunk_dalloc。这个函数最终可能会走到 arena_maybe_purge，从而导致 chunk 被回收</li><li>如果这个 run 是 dirty bit 被 set 了，则调用 arena_maybe_purge。</li></ul><h2 id="tcache"><a href="#tcache" class="headerlink" title="tcache"></a>tcache</h2><p>tcache 的主要目标是优化多线程下内存分配性能：</p><ul><li>减少锁争用：通过缓存内存块，线程可以在自己的本地缓存中处理分配和释放操作，避免频繁访问共享的全局 arena 数据结构</li><li>提高分配速度：小对象的内存分配和释放可以直接从 tcache 完成</li><li>降低内存碎片化</li></ul><h3 id="tsd"><a href="#tsd" class="headerlink" title="tsd"></a>tsd</h3><p>tsd 的主要作用是避免线程之间的资源竞争。每个线程可以有自己独立的一份分配器状态。tsd 的实现依赖于线程局部存储（Thread-Local Storage，TLS）。tsd 中就包含了 tcache 结构。tsdn 和 tsd 的区别是 tsdn 是 nullable 的。</p><p>“分配器状态”中包含 <code>tsd_state_t</code> 以及 MALLOC_TSD 中的项目。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">tsd_s</span> &#123;</span></span><br><span class="line">    <span class="keyword">tsd_state_t</span> state;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> O(n, t)                             \</span></span><br><span class="line">    t       n;</span><br><span class="line">MALLOC_TSD</span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> O</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>MALLOC_TSD 中的项目有</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MALLOC_TSD                          \</span></span><br><span class="line"><span class="comment">/*  O(name,         type) */</span>                \</span><br><span class="line">    O(tcache,           <span class="keyword">tcache_t</span> *)             \</span><br><span class="line">    O(thread_allocated,     <span class="keyword">uint64_t</span>)               \</span><br><span class="line">    O(thread_deallocated,   <span class="keyword">uint64_t</span>)               \</span><br><span class="line">    O(prof_tdata,       <span class="keyword">prof_tdata_t</span> *)             \</span><br><span class="line">    O(iarena,           <span class="keyword">arena_t</span> *)              \</span><br><span class="line">    O(arena,            <span class="keyword">arena_t</span> *)              \</span><br><span class="line">    O(arenas_tdata,     <span class="keyword">arena_tdata_t</span> *)            \</span><br><span class="line">    O(narenas_tdata,        <span class="keyword">unsigned</span>)               \</span><br><span class="line">    O(arenas_tdata_bypass,  <span class="keyword">bool</span>)                   \</span><br><span class="line">    O(tcache_enabled,       <span class="keyword">tcache_enabled_t</span>)           \</span><br><span class="line">    O(quarantine,       <span class="keyword">quarantine_t</span> *)             \</span><br><span class="line">    O(witnesses,        <span class="keyword">witness_list_t</span>)             \</span><br><span class="line">    O(witness_fork,     <span class="keyword">bool</span>)                   \</span><br></pre></td></tr></table></figure><h3 id="tcache-alloc-small"><a href="#tcache-alloc-small" class="headerlink" title="tcache_alloc_small"></a>tcache_alloc_small</h3><p>以 small 对象为例，尝试分配。</p><p>首先通过 tcache_alloc_easy 从对应的 bin 中选择尝试分配。如果失败，则要调用 arena_tcache_fill_small 从 arena 中申请整块 run 进行分配，run 剩余部分也归这个 tcache。</p><p>首先了解下结构</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">tcache_bin_s</span> &#123;</span></span><br><span class="line">    <span class="keyword">tcache_bin_stats_t</span> tstats;</span><br><span class="line">    <span class="keyword">int</span>     low_water;  <span class="comment">/* Min # cached since last GC. */</span></span><br><span class="line">    <span class="keyword">unsigned</span>    lg_fill_div;    <span class="comment">/* Fill (ncached_max &gt;&gt; lg_fill_div). */</span></span><br><span class="line">    <span class="keyword">unsigned</span>    ncached;    <span class="comment">/* # of cached objects. */</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * To make use of adjacent cacheline prefetch, the items in the avail</span></span><br><span class="line"><span class="comment">     * stack goes to higher address for newer allocations.  avail points</span></span><br><span class="line"><span class="comment">     * just above the available space, which means that</span></span><br><span class="line"><span class="comment">     * avail[-ncached, ... -1] are available items and the lowest item will</span></span><br><span class="line"><span class="comment">     * be allocated first.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">void</span>        **avail;    <span class="comment">/* Stack of available objects. */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>在 full 的时候，需要分配 ncached_max &gt;&gt; lg_fill_div 到 avail 结构中。lg_fill_div 是一个从 1 开始动态调整的值。对于 small 分配，ncached_max 是 TCACHE_NSLOTS_SMALL_MIN = 20。</p><p>arena_tcache_fill_small 的实现就是调用 arena_run_reg_alloc 在 run 中分配。如果没有 run，或者 run 用完了，就 arena_bin_malloc_hard。这个函数也会设置 runcur，所以后续的调用能够使用。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span></span><br><span class="line">arena_tcache_fill_small(<span class="keyword">tsdn_t</span> *tsdn, <span class="keyword">arena_t</span> *arena, <span class="keyword">tcache_bin_t</span> *tbin,</span><br><span class="line">    <span class="keyword">szind_t</span> binind, <span class="keyword">uint64_t</span> prof_accumbytes)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> i, nfill;</span><br><span class="line">    <span class="keyword">arena_bin_t</span> *bin;</span><br><span class="line"></span><br><span class="line">    assert(tbin-&gt;ncached == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config_prof &amp;&amp; arena_prof_accum(tsdn, arena, prof_accumbytes))</span><br><span class="line">        prof_idump(tsdn);</span><br><span class="line">    bin = &amp;arena-&gt;bins[binind];</span><br><span class="line">    malloc_mutex_lock(tsdn, &amp;bin-&gt;lock);</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>, nfill = (tcache_bin_info[binind].ncached_max &gt;&gt;</span><br><span class="line">        tbin-&gt;lg_fill_div); i &lt; nfill; i++) &#123;</span><br><span class="line">        <span class="keyword">arena_run_t</span> *run;</span><br><span class="line">        <span class="keyword">void</span> *ptr;</span><br><span class="line">        <span class="keyword">if</span> ((run = bin-&gt;runcur) != <span class="literal">NULL</span> &amp;&amp; run-&gt;nfree &gt; <span class="number">0</span>)</span><br><span class="line">            ptr = arena_run_reg_alloc(run, &amp;arena_bin_info[binind]);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            ptr = arena_bin_malloc_hard(tsdn, arena, bin);</span><br><span class="line">        <span class="keyword">if</span> (ptr == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * OOM.  tbin-&gt;avail isn't yet filled down to its first</span></span><br><span class="line"><span class="comment">             * element, so the successful allocations (if any) must</span></span><br><span class="line"><span class="comment">             * be moved just before tbin-&gt;avail before bailing out.</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                memmove(tbin-&gt;avail - i, tbin-&gt;avail - nfill,</span><br><span class="line">                    i * <span class="keyword">sizeof</span>(<span class="keyword">void</span> *));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (config_fill &amp;&amp; unlikely(opt_junk_alloc)) &#123;</span><br><span class="line">            arena_alloc_junk_small(ptr, &amp;arena_bin_info[binind],</span><br><span class="line">                <span class="literal">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* Insert such that low regions get used first. */</span></span><br><span class="line">        *(tbin-&gt;avail - nfill + i) = ptr;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (config_stats) &#123;</span><br><span class="line">        bin-&gt;stats.nmalloc += i;</span><br><span class="line">        bin-&gt;stats.nrequests += tbin-&gt;tstats.nrequests;</span><br><span class="line">        bin-&gt;stats.curregs += i;</span><br><span class="line">        bin-&gt;stats.nfills++;</span><br><span class="line">        tbin-&gt;tstats.nrequests = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    malloc_mutex_unlock(tsdn, &amp;bin-&gt;lock);</span><br><span class="line">    tbin-&gt;ncached = i;</span><br><span class="line">    arena_decay_tick(tsdn, arena);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="DSS-Dynamic-Storage-Segments"><a href="#DSS-Dynamic-Storage-Segments" class="headerlink" title="DSS(Dynamic Storage Segments)"></a>DSS(Dynamic Storage Segments)</h2><h2 id="malloc-的简单流程"><a href="#malloc-的简单流程" class="headerlink" title="malloc 的简单流程"></a>malloc 的简单流程</h2><p>主要是调用 ialloc_body。这里 usize 是对应的 size class 的最小值，即 index2size。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">JEMALLOC_EXPORT JEMALLOC_ALLOCATOR JEMALLOC_RESTRICT_RETURN</span><br><span class="line"><span class="keyword">void</span> JEMALLOC_NOTHROW *</span><br><span class="line">JEMALLOC_ATTR(<span class="built_in">malloc</span>) JEMALLOC_ALLOC_SIZE(<span class="number">1</span>)</span><br><span class="line">je_malloc(<span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">void</span> *ret;</span><br><span class="line">    <span class="keyword">tsdn_t</span> *tsdn;</span><br><span class="line">    <span class="keyword">size_t</span> <span class="function">usize <span class="title">JEMALLOC_CC_SILENCE_INIT</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (size == <span class="number">0</span>)</span><br><span class="line">        size = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (likely(!malloc_slow)) &#123;</span><br><span class="line">        ret = ialloc_body(size, <span class="literal">false</span>, &amp;tsdn, &amp;usize, <span class="literal">false</span>);</span><br><span class="line">        ialloc_post_check(ret, tsdn, usize, <span class="string">"malloc"</span>, <span class="literal">true</span>, <span class="literal">false</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        ret = ialloc_body(size, <span class="literal">false</span>, &amp;tsdn, &amp;usize, <span class="literal">true</span>);</span><br><span class="line">        ialloc_post_check(ret, tsdn, usize, <span class="string">"malloc"</span>, <span class="literal">true</span>, <span class="literal">true</span>);</span><br><span class="line">        UTRACE(<span class="number">0</span>, size, ret);</span><br><span class="line">        JEMALLOC_VALGRIND_MALLOC(ret != <span class="literal">NULL</span>, tsdn, ret, usize, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (ret);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ialloc_body 最终通过 ialloc -&gt; iallocztm 走到 arena_malloc。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">JEMALLOC_ALWAYS_INLINE_C <span class="keyword">void</span> *</span><br><span class="line">ialloc_body(<span class="keyword">size_t</span> size, <span class="keyword">bool</span> zero, <span class="keyword">tsdn_t</span> **tsdn, <span class="keyword">size_t</span> *usize,</span><br><span class="line">    <span class="keyword">bool</span> slow_path)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">tsd_t</span> *tsd;</span><br><span class="line">    <span class="keyword">szind_t</span> ind;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (slow_path &amp;&amp; unlikely(malloc_init())) &#123;</span><br><span class="line">        *tsdn = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tsd = tsd_fetch();</span><br><span class="line">    *tsdn = tsd_tsdn(tsd);</span><br><span class="line">    witness_assert_lockless(tsd_tsdn(tsd));</span><br><span class="line"></span><br><span class="line">    ind = size2index(size);</span><br><span class="line">    <span class="keyword">if</span> (unlikely(ind &gt;= NSIZES))</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config_stats || (config_prof &amp;&amp; opt_prof) || (slow_path &amp;&amp;</span><br><span class="line">        config_valgrind &amp;&amp; unlikely(in_valgrind))) &#123;</span><br><span class="line">        *usize = index2size(ind);</span><br><span class="line">        assert(*usize &gt; <span class="number">0</span> &amp;&amp; *usize &lt;= HUGE_MAXCLASS);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config_prof &amp;&amp; opt_prof)</span><br><span class="line">        <span class="keyword">return</span> (ialloc_prof(tsd, *usize, ind, zero, slow_path));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (ialloc(tsd, size, ind, zero, slow_path));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>arena_malloc 中，如果开启了 tcache，就尝试从 tcache 去分配。否则，直接通过 arena_malloc_hard 从 arena 分配。所以在 4.5 中，大部分情况下的 small 和 large 都是通过 tcache 走的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">JEMALLOC_ALWAYS_INLINE <span class="keyword">void</span> *</span><br><span class="line">arena_malloc(<span class="keyword">tsdn_t</span> *tsdn, <span class="keyword">arena_t</span> *arena, <span class="keyword">size_t</span> size, <span class="keyword">szind_t</span> ind, <span class="keyword">bool</span> zero,</span><br><span class="line">    <span class="keyword">tcache_t</span> *tcache, <span class="keyword">bool</span> slow_path)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    assert(!tsdn_null(tsdn) || tcache == <span class="literal">NULL</span>);</span><br><span class="line">    assert(size != <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (likely(tcache != <span class="literal">NULL</span>)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (likely(size &lt;= SMALL_MAXCLASS)) &#123;</span><br><span class="line">            <span class="keyword">return</span> (tcache_alloc_small(tsdn_tsd(tsdn), arena,</span><br><span class="line">                tcache, size, ind, zero, slow_path));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (likely(size &lt;= tcache_maxclass)) &#123;</span><br><span class="line">            <span class="keyword">return</span> (tcache_alloc_large(tsdn_tsd(tsdn), arena,</span><br><span class="line">                tcache, size, ind, zero, slow_path));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* (size &gt; tcache_maxclass) case falls through. */</span></span><br><span class="line">        assert(size &gt; tcache_maxclass);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (arena_malloc_hard(tsdn, arena, size, ind, zero));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="从实现分析设计理念"><a href="#从实现分析设计理念" class="headerlink" title="从实现分析设计理念"></a>从实现分析设计理念</h1><h2 id="最大化内存分配和释放的性能"><a href="#最大化内存分配和释放的性能" class="headerlink" title="最大化内存分配和释放的性能"></a>最大化内存分配和释放的性能</h2><p>主要体现在：</p><ul><li>避免大量的向系统申请内存的动作</li><li>快速定位可以被用来分配的内存</li></ul><p>快速定位上：</p><ul><li>给定任意地址 ptr，通过 CHUNK_ADDR2BASE 就可以找到对应的 chunk 的地址，进而就可以找到对应的几个元信息。诸如 map_bias 的是全局变量，所以也能在常数时间中计算得到 bits 和 mics 的偏移。</li><li>通过 ptr 和 chunk 的地址 c，就可以通过 <code>((uintptr_t)ptr - (uintptr_t)chunk)&gt;&gt;LG_PAGE</code> 算出 page id。</li></ul><p>chunk 的分配上：</p><ul><li>使用红黑树缓存之前已经分配，但是目前空闲的 chunk。使用两种红黑树来支持两种排序方式：size、address 和 address。</li><li>使用 spare 缓存最近空闲的 chunk，减少对红黑树的访问。</li><li>使用 retain 缓存之前已经分配，但是目前被释放了的 chunk。</li></ul><h2 id="减少内部碎片和外部碎片"><a href="#减少内部碎片和外部碎片" class="headerlink" title="减少内部碎片和外部碎片"></a>减少内部碎片和外部碎片</h2><p>chunk 的各个 page 和各个 run 的元信息都放在了 chunk 头部，减少了内部碎片。</p><h2 id="减少线程之间的竞争"><a href="#减少线程之间的竞争" class="headerlink" title="减少线程之间的竞争"></a>减少线程之间的竞争</h2><p>jemalloc 会创建多个 arena，每个线程由一个 arena 负责。默认创建 CPU * 4 数量的 arena。在每个 arena 中使用 nthreads 记录负责的线程数量。</p><p>每个线程分配内存时，会基于下面的逻辑选择 arena：</p><ul><li>若 nthreads==0 已创建的 arena，则选择该 arena</li><li>若还有未创建的 arena，则选择新创建一个 arena</li><li>选择 nthreads 最少的 arena</li></ul><h1 id="后续版本的一些优化"><a href="#后续版本的一些优化" class="headerlink" title="后续版本的一些优化"></a>后续版本的一些优化</h1><h2 id="background-thread"><a href="#background-thread" class="headerlink" title="background thread"></a>background thread</h2><p>线程名是 <code>jemalloc_bg_thd</code>。</p><h2 id="opt-retain"><a href="#opt-retain" class="headerlink" title="opt_retain"></a>opt_retain</h2><p>主要是在 dealloc 的时候要不要调用 pages_unmap。</p><p>在 5.2.1 中引入了 opt_retain。如果开启了 opt_retain，那么进行 munmap 可能还会导致 rss 无法快速释放。原因是 purge 的时候可能使用 MADV_FREE。【Q】但实际我好像没观察到这一部分影响有多大。</p><p>从代码来看，这个功能主要被 extent_purge_lazy_default 调用，实际上对应了 extent_hooks_t 中的 purge_lazy 方法。在代码中还是被广泛使用的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span></span><br><span class="line">pages_purge_lazy(<span class="keyword">void</span> *addr, <span class="keyword">size_t</span> size) &#123;</span><br><span class="line">    assert(ALIGNMENT_ADDR2BASE(addr, os_page) == addr);</span><br><span class="line">    assert(PAGE_CEILING(size) == size);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!pages_can_purge_lazy) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!pages_can_purge_lazy_runtime) &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Built with lazy purge enabled, but detected it was not</span></span><br><span class="line"><span class="comment">         * supported on the current system.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> _WIN32</span></span><br><span class="line">    VirtualAlloc(addr, size, MEM_RESET, PAGE_READWRITE);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(JEMALLOC_PURGE_MADVISE_FREE)</span></span><br><span class="line">    <span class="keyword">return</span> (madvise(addr, size,</span><br><span class="line">#  ifdef MADV_FREE</span><br><span class="line">        MADV_FREE</span><br><span class="line">#  <span class="keyword">else</span></span><br><span class="line">        JEMALLOC_MADV_FREE</span><br><span class="line">#  endif</span><br><span class="line">        ) != <span class="number">0</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(JEMALLOC_PURGE_MADVISE_DONTNEED) &amp;&amp; \</span></span><br><span class="line">    !defined(JEMALLOC_PURGE_MADVISE_DONTNEED_ZEROS)</span><br><span class="line">    <span class="keyword">return</span> (madvise(addr, size, MADV_DONTNEED) != <span class="number">0</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    not_reached();</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，初始化的时候会有检查这个功能是否可以有</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">    <span class="keyword">if</span> (pages_can_purge_lazy) &#123;</span><br><span class="line">        <span class="keyword">bool</span> committed = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">void</span> *madv_free_page = os_pages_map(<span class="literal">NULL</span>, PAGE, PAGE, &amp;committed);</span><br><span class="line">        <span class="keyword">if</span> (madv_free_page == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        assert(pages_can_purge_lazy_runtime);</span><br><span class="line">        <span class="keyword">if</span> (pages_purge_lazy(madv_free_page, PAGE)) &#123;</span><br><span class="line">            pages_can_purge_lazy_runtime = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        os_pages_unmap(madv_free_page, PAGE);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h1 id="一些写法"><a href="#一些写法" class="headerlink" title="一些写法"></a>一些写法</h1><h2 id="计算-map-bias"><a href="#计算-map-bias" class="headerlink" title="计算 map_bias"></a>计算 map_bias</h2><p>在 arena_boot 中计算。</p><p>变量常量介绍：</p><ul><li>chunk_npages 表示 chunk 中 page 的总数。</li><li>LG_PAGE：一个 page 是 2 ** LG_PAGE 这么大。</li></ul><p>每次迭代算出一个 header_size，并向上取整计算 header 需要多少 page 存放。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">map_bias = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">size_t</span> header_size = offsetof(<span class="keyword">arena_chunk_t</span>, map_bits) +</span><br><span class="line">        ( ( <span class="keyword">sizeof</span>(<span class="keyword">arena_chunk_map_bits_t</span>) +</span><br><span class="line">            <span class="keyword">sizeof</span>(<span class="keyword">arena_chunk_map_misc_t</span>) ) * (chunk_npages-map_bias) );</span><br><span class="line">    map_bias = (header_size + PAGE_MASK) &gt;&gt; LG_PAGE;</span><br><span class="line">&#125;</span><br><span class="line">assert(map_bias &gt; <span class="number">0</span>);</span><br></pre></td></tr></table></figure><p>随便取几个值跑下这个算法，可以看出，第二个迭代中，实际分配的 header 的大小 allocated_header_size 可能小于真实需要的 header 大小 real_payload_header_size。如果 bits_size + misc_size 越大，那么这个效应越明显。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> bits_size = <span class="number">4</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> misc_size = <span class="number">128</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> fixed_head = <span class="number">1024</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> chunk_npages = <span class="number">4096</span>;</span><br><span class="line">    <span class="keyword">int</span> map_bias = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">size_t</span> header_size = fixed_head +</span><br><span class="line">            ( ( bits_size +</span><br><span class="line">                misc_size ) * (chunk_npages-map_bias) );</span><br><span class="line">        map_bias = (header_size + <span class="number">4096</span>) &gt;&gt; <span class="number">12</span>;</span><br><span class="line">        <span class="keyword">int</span> allocated_header_size = map_bias * <span class="number">4096</span>;</span><br><span class="line">        <span class="keyword">int</span> real_payload_header_size = (bits_size + misc_size) * (chunk_npages-map_bias) + fixed_head;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"map_bias %u payload %u header_size %u real_payload_header_size %u allocated_header_size %u\n"</span>, map_bias, chunk_npages-map_bias, header_size, real_payload_header_size, allocated_header_size);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">map_bias <span class="number">133</span> payload <span class="number">3963</span> header_size <span class="number">541696</span> real_payload_header_size <span class="number">524140</span> allocated_header_size <span class="number">544768</span></span><br><span class="line">map_bias <span class="number">128</span> payload <span class="number">3968</span> header_size <span class="number">524140</span> real_payload_header_size <span class="number">524800</span> allocated_header_size <span class="number">524288</span></span><br><span class="line">map_bias <span class="number">129</span> payload <span class="number">3967</span> header_size <span class="number">524800</span> real_payload_header_size <span class="number">524668</span> allocated_header_size <span class="number">528384</span></span><br></pre></td></tr></table></figure><p>可见：</p><ul><li>第一个迭代假设每个 page 都有一个 map_bit 和 map_misc，这种情况下算出来的 map_bias 偏大，payload 就少了。</li><li>第二个迭代因为 payload 少了，所以 header 就会偏小。</li></ul><h1 id="一些结构"><a href="#一些结构" class="headerlink" title="一些结构"></a>一些结构</h1><h2 id="pages"><a href="#pages" class="headerlink" title="pages"></a>pages</h2><p>是和 mmap 有关的内存页面分配的基础函数。</p><p>pages_decommit 是一个底层内存管理函数，主要用“解除提交”物理内存（释放物理内存或交换空间），但保留虚拟地址空间的映射。它的行为类似于 mprotect(addr, length, PROT_NONE)。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _WIN32</span></span><br><span class="line"><span class="meta">#  <span class="meta-keyword">define</span> PAGES_PROT_COMMIT (PROT_READ | PROT_WRITE)</span></span><br><span class="line"><span class="meta">#  <span class="meta-keyword">define</span> PAGES_PROT_DECOMMIT (PROT_NONE)</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span>  mmap_flags;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">...</span><br><span class="line">        <span class="keyword">int</span> prot = commit ? PAGES_PROT_COMMIT : PAGES_PROT_DECOMMIT;</span><br><span class="line">        <span class="keyword">void</span> *result = mmap(addr, size, prot, mmap_flags | MAP_FIXED,</span><br><span class="line">            <span class="number">-1</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (result == MAP_FAILED) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (result != addr) &#123;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * We succeeded in mapping memory, but not in the right</span></span><br><span class="line"><span class="comment">             * place.</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            os_pages_unmap(result, size);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h2 id="qr"><a href="#qr" class="headerlink" title="qr"></a>qr</h2><p>是一个 deque，或者 List 的实现。</p><h2 id="rb"><a href="#rb" class="headerlink" title="rb"></a>rb</h2><p>提供了红黑树相关的方法，例如 <code>_remove</code> 等。</p><p>红黑树被广泛使用，例如：</p><ul><li>extent_tree_szad_</li><li>extent_tree_ad_</li></ul><h2 id="【5-2-1】extent"><a href="#【5-2-1】extent" class="headerlink" title="【5.2.1】extent"></a>【5.2.1】extent</h2><p>extent 是一个基于红黑树的，用来分配内存的结构。它被 5.x 之后引入，用来替代 chunk。</p><p>一般调用类似 <code>extent_tree_szad_remove</code> 的方法，表示从 extent 中分配一块内存。此时，会从 extent 的 szad 中删除对应内存的标记信息。</p><h2 id="bitmap"><a href="#bitmap" class="headerlink" title="bitmap"></a>bitmap</h2><p>bitmap 中记录了一些比较有趣的实现。比如 <code>USE_TREE</code> 提出了一个有意思的结构。</p><p>bitmap 初始都是 1，set 一个位会将它变为 0。然后有一系列的比如 full、get、set、unset 之类的方法。包括 sfu 这个方法可以查询第一个 bit 0 的位置，然后将其设置为 1。</p><h2 id="phn"><a href="#phn" class="headerlink" title="phn"></a>phn</h2><p>这是一个堆的实现。</p><h2 id="base"><a href="#base" class="headerlink" title="base"></a>base</h2><p>这是 base allocator，是 jemalloc 初始化时候使用的一个低级分配方式。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> *</span><br><span class="line">base_alloc(<span class="keyword">tsdn_t</span> *tsdn, <span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line">...</span><br><span class="line">    usize = s2u(csize);</span><br><span class="line">    extent_node_init(&amp;key, <span class="literal">NULL</span>, <span class="literal">NULL</span>, usize, <span class="literal">false</span>, <span class="literal">false</span>);</span><br><span class="line">    malloc_mutex_lock(tsdn, &amp;base_mtx);</span><br><span class="line">    node = extent_tree_szad_nsearch(&amp;base_avail_szad, &amp;key);</span><br><span class="line">    <span class="keyword">if</span> (node != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="comment">/* Use existing space. */</span></span><br><span class="line">        extent_tree_szad_remove(&amp;base_avail_szad, node);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/* Try to allocate more space. */</span></span><br><span class="line">        node = base_chunk_alloc(tsdn, csize);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h1 id="一些知识"><a href="#一些知识" class="headerlink" title="一些知识"></a>一些知识</h1><p><a href="/2025/01/03/memory-context-knowledge/">见内存领域知识</a></p><h1 id="一些方法"><a href="#一些方法" class="headerlink" title="一些方法"></a>一些方法</h1><h2 id="如何编译"><a href="#如何编译" class="headerlink" title="如何编译"></a>如何编译</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure --enable-prof --enable-log</span><br><span class="line">make -j40 &amp;&amp; g++ test.cpp -Iinclude -ljemalloc -o test2 &amp;&amp; ./test2</span><br><span class="line">LD_LIBRARY_PATH=./lib/ ./test2</span><br></pre></td></tr></table></figure><h2 id="如何-debug"><a href="#如何-debug" class="headerlink" title="如何 debug"></a>如何 debug</h2><p>指定 log 这个隐藏 conf，就可以打印日志。注意，需要 <code>--enable-log</code> 编译选项。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> MALLOC_CONF=<span class="string">"log:."</span></span><br></pre></td></tr></table></figure><p>在需要的地方可以使用</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOG(<span class="string">"module_name"</span>, <span class="string">"formatter"</span>, ...)</span><br></pre></td></tr></table></figure><p>然后可以指定 <code>log:module_name</code>，从而只打印自己想要的一部分日志。</p><p>例如可以 <code>export MALLOC_CONF=&quot;prof:true,lg_prof_interval:1,prof_active:true,log:.&quot;</code> 测试 dump。</p><h1 id="关于-jeprof-in-脚本"><a href="#关于-jeprof-in-脚本" class="headerlink" title="关于 jeprof.in 脚本"></a>关于 jeprof.in 脚本</h1><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://youjiali1995.github.io/allocator/jemalloc/" target="_blank" rel="noopener">https://youjiali1995.github.io/allocator/jemalloc/</a><br>  基于 4.5 之前的版本</li><li><a href="https://yaoguais.github.io/article/jemalloc/structures.html" target="_blank" rel="noopener">https://yaoguais.github.io/article/jemalloc/structures.html</a></li><li><a href="https://github.com/leebaok/jemalloc-4.2.1-readcode/blob/readcode/readcode/more.md" target="_blank" rel="noopener">https://github.com/leebaok/jemalloc-4.2.1-readcode/blob/readcode/readcode/more.md</a></li><li><a href="https://youjiali1995.github.io/allocator/jemalloc-purge/" target="_blank" rel="noopener">https://youjiali1995.github.io/allocator/jemalloc-purge/</a><br>  5.0.1 版本 purge 的改进</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍下 jemalloc 的实现。目前的实现和 4.5 及之前的实现还是有比较大的差别的。因此代码主要是看的 4.5，并介绍了下 5.2.1 的几个重要的变化。&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
    <category term="内存管理" scheme="http://www.calvinneo.com/tags/内存管理/"/>
    
  </entry>
  
  <entry>
    <title>RocksDB 的 Compaction 策略</title>
    <link href="http://www.calvinneo.com/2024/12/29/rocksdb-compaction/"/>
    <id>http://www.calvinneo.com/2024/12/29/rocksdb-compaction/</id>
    <published>2024-12-29T13:33:22.000Z</published>
    <updated>2025-03-16T13:53:14.273Z</updated>
    
    <content type="html"><![CDATA[<p>如题。</p><a id="more"></a><h1 id="Level-Compaction"><a href="#Level-Compaction" class="headerlink" title="Level Compaction"></a>Level Compaction</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="Compaction-的条件"><a href="#Compaction-的条件" class="headerlink" title="Compaction 的条件"></a>Compaction 的条件</h3><ul><li>当 L0 层的数量达到 level0_file_num_compaction_trigger 后，触发从 L0 到 L1 的 Compaction。<br>  这个值一般是 4，设的较大对写友好，但是读会需要在 L0 扫多个 pass，从而降低读的性能。</li><li>这可能导致 L1 的大小超出限制，此时会选出至少 1 个 L1 层的 SST，和 L2 层合并。</li></ul><p>注意，WAL 切换时不会直接触发 compaction，但是 WAL 切换会导致 MemTable 刷新，并生成新的 SST 文件，这可能间接影响 compaction 的触发条件。</p><h3 id="Parallel-Compaction"><a href="#Parallel-Compaction" class="headerlink" title="Parallel Compaction"></a>Parallel Compaction</h3><ul><li>L1 层往下的 Compaction 是可以并行的</li><li>L0 -&gt; L1 的 Compaction 默认不是并行的，但是有一个 subcompaction-based parallelization 特性。这个时候，一个文件可能会被按照 range 切分，从而和 L1 层的多个文件一同 compact。<br>  <img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/subcompaction.png"></li></ul><h3 id="Pick-Compaction"><a href="#Pick-Compaction" class="headerlink" title="Pick Compaction"></a>Pick Compaction</h3><p>当多个 Level 都满足 Compaction 的条件，则需要计算一个 score，触发最大的 score 对应的那一层：</p><ul><li>对于非 L0，这个得分是当前 size 除以 target size。如果这一层某些文件正在被 compact，那么它们不会被计算在当前 size 内。</li><li>对于 L0，得分是两个的较大者<ul><li>当前 file 的数量，除以 level0_file_num_compaction_trigger</li><li>当前 file 的总大小，除以 max_bytes_for_level_base</li></ul></li></ul><h3 id="Compaction-的条件-1"><a href="#Compaction-的条件-1" class="headerlink" title="Compaction 的条件"></a>Compaction 的条件</h3><ul><li>L0 文件数量超过限制<br>  level0_file_num_compaction_trigger</li><li>层级总大小超过限制<br>  max_bytes_for_level_base</li><li>待压缩数据量超出限制<br>  soft/hard_pending_compaction_bytes_limit</li><li>单个文件大小超过限制<br>  target_file_size_base</li><li>层级间文件重叠</li><li>L0 compaction</li><li>手动触发</li><li>level_compaction_dynamic_level_bytes</li><li>冷数据</li></ul><h3 id="为什么-RocksDB-没有-seek-compaction？"><a href="#为什么-RocksDB-没有-seek-compaction？" class="headerlink" title="为什么 RocksDB 没有 seek compaction？"></a>为什么 RocksDB 没有 seek compaction？</h3><p>首先，RocksDB 有一个 patch，如果一个文件已经被 cache 了，那么就不应该被计算 seek compaction 的惩罚。</p><p><a href="https://github.com/facebook/rocksdb/commit/c1bb32e1ba9da94d9e40af692f60c2c0420685cd" target="_blank" rel="noopener">https://github.com/facebook/rocksdb/commit/c1bb32e1ba9da94d9e40af692f60c2c0420685cd</a></p><blockquote><p>In the current code, a Get() call can trigger compaction if it has to look at more than one file. This causes unnecessary compaction because looking at more than one file is a penalty only if the file is not yet in the cache. Also, th current code counts these files before the bloom filter check is applied.<br>This patch counts a ‘seek’ only if the file fails the bloom filter check and has to read in data block(s) from the storage.</p></blockquote><p>然后发现，<a href="https://wangxuemin.github.io/2016/10/16/leveldb%E7%9A%84seek_compaction/" target="_blank" rel="noopener">改进之后 seek compaction 就较少被触发了</a>，于是为了减少代码复杂度，就被移除了。</p><h2 id="Choose-Level-Compaction-Files"><a href="#Choose-Level-Compaction-Files" class="headerlink" title="Choose Level Compaction Files"></a>Choose Level Compaction Files</h2><p>介绍 Level Compaction 是如何选择 Compact 哪些文件的。</p><h2 id="level-compaction-dynamic-level-bytes"><a href="#level-compaction-dynamic-level-bytes" class="headerlink" title="level_compaction_dynamic_level_bytes"></a>level_compaction_dynamic_level_bytes</h2><p>level_compaction_dynamic_level_bytes 允许 RocksDB 在运行时动态调整每个 Level 的大小，而不是像现在这样使用 10 倍的关系。</p><p>如果 max_bytes_for_level_base 为 false，那么 L1 的大小是 max_bytes_for_level_base，后面每一层都是之前的 max_bytes_for_level_multiplier * max_bytes_for_level_multiplier_additional[n] 倍。</p><p>如果 level_compaction_dynamic_level_bytes 为 true，那么每一层的大小是动态调整的。此时，最下面一层的大小是它的实际大小，然后第 n-1 层的大小是第 n 层的大小除以 max_bytes_for_level_multiplier。如果一层的大小小于 max_bytes_for_level_base / max_bytes_for_level_multiplier，那么我们就不会启用这一层。因此，整个 LSM 结构好像是从最下面一层往上构建的，也就是说 base_level 默认从 1 变成 6，然后逐级向下调整。</p><p><img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/dynamic_level.png"> </p><p>可以简单推演下，当 L6 达到一定阈值后，base_level 会下降到 L5，然后 L0 会直接被 compact 到 L5。当 L5 达到阈值之后，会被 Compact 到 L6，此时 L6 的大小变大，从而推动 L5 的阈值也变大。如此渐进达成收敛，最终 L5 的阈值增大到一定程度后，会产生 L4 来。</p><p>在开启这个选项之后，compaction score 的逻辑也要进行调整。在计算 Ln 的 store 时，现在得 <code>Ln size / (Ln target size + total_downcompact_bytes)</code>。相比之前，加上了一个 total_downcompact_bytes 项。这个项是从 L0 到 Ln-1 一直 compact 到 Ln 所预计需要的总的字节数。如果写入负载更大，那么 compaction debt 更大。这样，更高层的 total_downcompact_bytes 会更大，那么较低的层会被优先 compact。【Q】这段逻辑比较复杂，可能后续需要看看源码。</p><h1 id="Intra-L0-Compaction"><a href="#Intra-L0-Compaction" class="headerlink" title="Intra-L0 Compaction"></a>Intra-L0 Compaction</h1><p>有点类似于 TiFlash 中的 delta compaction。</p><h1 id="FIFO-Compaction"><a href="#FIFO-Compaction" class="headerlink" title="FIFO Compaction"></a>FIFO Compaction</h1><p>实际上是一个很简单的策略。它实际上是定期删除老数据，所以适合时序数据。注意，这种情况下，数据可能被删除。</p><p>在 FIFO Compaction 中，所有的文件都在 level 0。当总大小超过 <code>CompactionOptionsFIFO::max_table_files_size)</code> 之后，就删除最老的 SST。因此写放大是 1，当然，其实还要考虑 WAL 的写放大。</p><p>因为都在 Level 0，所以 FIFO 下 level 0 可能有很多 sst，从而让读取速度变得很慢。这种情况下，建议使用更多的 Bloom bits 从而减少 Bloom filter 的假阳性问题。</p><p>通过设定 <code>CompactionOptionsFIFO.allow_compaction = true</code> 可以拿最少 <code>level0_file_num_compaction_trigger</code> 个文件，将它们 Compaction 到一起。选取的顺序是从新到旧。</p><p>Compact 的逻辑如下面的例子所示。因为 FIFO 中不存在所谓的版本问题了，所以 Compact 的目的就是让多个 SST 文件变成一个有序的大的 SST 文件。</p><blockquote><p>For example, if level0_file_num_compaction_trigger = 8 and every flushed file is 100MB. Then as soon as there is 8 files, they are compacted to one 800MB file. And after we have 8 new 100MB files, they are compacted in the second 800MB, and so on. Eventually we’ll have a list of 800MB files and no more than 8 100MB files.</p></blockquote><p>Compaction 的执行条件：定期检查数据库大小是否超过 <code>compaction_options_fifo.max_table_files_size</code>，如果超过了，就一次 drop 一个最老的文件，直到重新满足大小限制。</p><h2 id="with-TTL"><a href="#with-TTL" class="headerlink" title="with TTL"></a>with TTL</h2><p>现在并不是数据库大小超过某个 size 才 compaction 了。而是直接删除 ttl 比某个值旧的所有 SST 文件。</p><h1 id="Universal-Compaction"><a href="#Universal-Compaction" class="headerlink" title="Universal Compaction"></a>Universal Compaction</h1><h1 id="Remote-Compaction"><a href="#Remote-Compaction" class="headerlink" title="Remote Compaction"></a>Remote Compaction</h1><p><img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/remote_compaction_overview.png"></p><p>从下面的调用图中可以看出，Compaction 命令同样是由 Primary 发出的，但是实际上是由 Compaction worker 执行的。</p><p><img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/remote_compaction_interface.png"></p><ol><li><p>Schedule<br>The first step is primary DB triggers the compaction, instead of running the compaction locally, it sends the compaction information to a callback in CompactionService. The user needs to implement the CompactionService::Schedule(), which sends the compaction information to a remote process to schedule the compaction.</p></li><li><p>Compact<br>On the remote Compaction Worker side, it needs to run DB::OpenAndCompact() with the compaction information sent from the primary. Based on the compaction information, <strong>the worker opens the DB in read-only mode</strong> and runs the compaction. <strong>The compaction worker cannot change the LSM tree</strong>, it outputs the compaction result to a <strong>temporary location</strong> that the user needs to set.</p></li><li><p>Return Result<br>Once the compaction is done, the compaction result needs to be sent back to primary, which includes the metadata about the compacted SSTs and some internal information. The same as scheduling, the user needs to implement the communication between primary and compaction workers.</p></li><li><p>Install &amp; Purge<br>The primary is waiting for the result by callback CompactionService::Wait(). The result should be passed to that API and return function call. After that, the primary will install the result by renaming the result SST files in the temporary workplace to the LSM files. Then the compaction input files will be purged. As RocksDB is renaming the result SST files, make sure the temporary workplace and the DB are on the same file system. If not, the user needs to copy the file to the DB file system before returning the Wait() call.</p></li></ol><h1 id="Compaction-和-Write-Stall"><a href="#Compaction-和-Write-Stall" class="headerlink" title="Compaction 和 Write Stall"></a>Compaction 和 Write Stall</h1><p>ADOC: Automatically Harmonizing Dataflow Between Components in Log-Structured Key-Value Stores for Improved Performance</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://github.com/facebook/rocksdb/wiki/" target="_blank" rel="noopener">https://github.com/facebook/rocksdb/wiki/</a><br> RocksDB Wiki</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;如题。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="leveldb" scheme="http://www.calvinneo.com/tags/leveldb/"/>
    
  </entry>
  
</feed>
