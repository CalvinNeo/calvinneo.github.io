<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Calvin&#39;s Marbles</title>
  
  
  <link href="http://www.calvinneo.com/atom.xml" rel="self"/>
  
  <link href="http://www.calvinneo.com/"/>
  <updated>2024-12-29T17:19:28.296Z</updated>
  <id>http://www.calvinneo.com/</id>
  
  <author>
    <name>Calvin Neo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>RocksDB 的 Compaction 策略</title>
    <link href="http://www.calvinneo.com/2024/12/29/rocksdb-compaction/"/>
    <id>http://www.calvinneo.com/2024/12/29/rocksdb-compaction/</id>
    <published>2024-12-29T13:33:22.000Z</published>
    <updated>2024-12-29T17:19:28.296Z</updated>
    
    <content type="html"><![CDATA[<p>如题。</p><a id="more"></a><h1 id="Level-Compaction"><a href="#Level-Compaction" class="headerlink" title="Level Compaction"></a>Level Compaction</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="Compaction-的条件"><a href="#Compaction-的条件" class="headerlink" title="Compaction 的条件"></a>Compaction 的条件</h3><ul><li>当 L0 层的数量达到 level0_file_num_compaction_trigger 后，触发从 L0 到 L1 的 Compaction。<br>  这个值一般是 4，设的较大对写友好，但是读会需要在 L0 扫多个 pass，从而降低读的性能。</li><li>这可能导致 L1 的大小超出限制，此时会选出至少 1 个 L1 层的 SST，和 L2 层合并。</li></ul><p>注意，WAL 切换时不会直接触发 compaction，但是 WAL 切换会导致 MemTable 刷新，并生成新的 SST 文件，这可能间接影响 compaction 的触发条件。</p><h3 id="Parallel-Compaction"><a href="#Parallel-Compaction" class="headerlink" title="Parallel Compaction"></a>Parallel Compaction</h3><ul><li>L1 层往下的 Compaction 是可以并行的</li><li>L0 -&gt; L1 的 Compaction 默认不是并行的，但是有一个 subcompaction-based parallelization 特性。这个时候，一个文件可能会被按照 range 切分，从而和 L1 层的多个文件一同 compact。<br>  <img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/subcompaction.png"></li></ul><h3 id="Pick-Compaction"><a href="#Pick-Compaction" class="headerlink" title="Pick Compaction"></a>Pick Compaction</h3><p>当多个 Level 都满足 Compaction 的条件，则需要计算一个 score，触发最大的 score 对应的那一层：</p><ul><li>对于非 L0，这个得分是当前 size 除以 target size。如果这一层某些文件正在被 compact，那么它们不会被计算在当前 size 内。</li><li>对于 L0，得分是两个的较大者<ul><li>当前 file 的数量，除以 level0_file_num_compaction_trigger</li><li>当前 file 的总大小，除以 max_bytes_for_level_base</li></ul></li></ul><h3 id="Compaction-的条件-1"><a href="#Compaction-的条件-1" class="headerlink" title="Compaction 的条件"></a>Compaction 的条件</h3><ul><li>L0 文件数量超过限制<br>  level0_file_num_compaction_trigger</li><li>层级总大小超过限制<br>  max_bytes_for_level_base</li><li>待压缩数据量超出限制<br>  soft/hard_pending_compaction_bytes_limit</li><li>单个文件大小超过限制<br>  target_file_size_base</li><li>层级间文件重叠</li><li>L0 compaction</li><li>手动触发</li><li>level_compaction_dynamic_level_bytes</li><li>冷数据</li></ul><h3 id="为什么-RocksDB-没有-seek-compaction？"><a href="#为什么-RocksDB-没有-seek-compaction？" class="headerlink" title="为什么 RocksDB 没有 seek compaction？"></a>为什么 RocksDB 没有 seek compaction？</h3><p>首先，RocksDB 有一个 patch，如果一个文件已经被 cache 了，那么就不应该被计算 seek compaction 的惩罚。</p><p><a href="https://github.com/facebook/rocksdb/commit/c1bb32e1ba9da94d9e40af692f60c2c0420685cd" target="_blank" rel="noopener">https://github.com/facebook/rocksdb/commit/c1bb32e1ba9da94d9e40af692f60c2c0420685cd</a></p><blockquote><p>In the current code, a Get() call can trigger compaction if it has to look at more than one file. This causes unnecessary compaction because looking at more than one file is a penalty only if the file is not yet in the cache. Also, th current code counts these files before the bloom filter check is applied.<br>This patch counts a ‘seek’ only if the file fails the bloom filter check and has to read in data block(s) from the storage.</p></blockquote><p>然后发现，<a href="https://wangxuemin.github.io/2016/10/16/leveldb%E7%9A%84seek_compaction/" target="_blank" rel="noopener">改进之后 seek compaction 就较少被触发了</a>，于是为了减少代码复杂度，就被移除了。</p><h2 id="Choose-Level-Compaction-Files"><a href="#Choose-Level-Compaction-Files" class="headerlink" title="Choose Level Compaction Files"></a>Choose Level Compaction Files</h2><p>介绍 Level Compaction 是如何选择 Compact 哪些文件的。</p><h2 id="level-compaction-dynamic-level-bytes"><a href="#level-compaction-dynamic-level-bytes" class="headerlink" title="level_compaction_dynamic_level_bytes"></a>level_compaction_dynamic_level_bytes</h2><p>level_compaction_dynamic_level_bytes 允许 RocksDB 在运行时动态调整每个 Level 的大小，而不是像现在这样使用 10 倍的关系。</p><p>如果 max_bytes_for_level_base 为 false，那么 L1 的大小是 max_bytes_for_level_base，后面每一层都是之前的 max_bytes_for_level_multiplier * max_bytes_for_level_multiplier_additional[n] 倍。</p><p>如果 level_compaction_dynamic_level_bytes 为 true，那么每一层的大小是动态调整的。此时，最下面一层的大小是它的实际大小，然后第 n-1 层的大小是第 n 层的大小除以 max_bytes_for_level_multiplier。如果一层的大小小于 max_bytes_for_level_base / max_bytes_for_level_multiplier，那么我们就不会启用这一层。因此，整个 LSM 结构好像是从最下面一层往上构建的，也就是说 base_level 默认从 1 变成 6，然后逐级向下调整。</p><p><img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/dynamic_level.png"> </p><p>可以简单推演下，当 L6 达到一定阈值后，base_level 会下降到 L5，然后 L0 会直接被 compact 到 L5。当 L5 达到阈值之后，会被 Compact 到 L6，此时 L6 的大小变大，从而推动 L5 的阈值也变大。如此渐进达成收敛，最终 L5 的阈值增大到一定程度后，会产生 L4 来。</p><p>在开启这个选项之后，compaction score 的逻辑也要进行调整。在计算 Ln 的 store 时，现在得 <code>Ln size / (Ln target size + total_downcompact_bytes)</code>。相比之前，加上了一个 total_downcompact_bytes 项。这个项是从 L0 到 Ln-1 一直 compact 到 Ln 所预计需要的总的字节数。如果写入负载更大，那么 compaction debt 更大。这样，更高层的 total_downcompact_bytes 会更大，那么较低的层会被优先 compact。【Q】这段逻辑比较复杂，可能后续需要看看源码。</p><h1 id="Intra-L0-Compaction"><a href="#Intra-L0-Compaction" class="headerlink" title="Intra-L0 Compaction"></a>Intra-L0 Compaction</h1><p>有点类似于 TiFlash 中的 delta compaction。</p><h1 id="FIFO-Compaction"><a href="#FIFO-Compaction" class="headerlink" title="FIFO Compaction"></a>FIFO Compaction</h1><p>实际上是一个很简单的策略。它实际上是定期删除老数据，所以适合时序数据。注意，这种情况下，数据可能被删除。</p><p>在 FIFO Compaction 中，所有的文件都在 level 0。当总大小超过 <code>CompactionOptionsFIFO::max_table_files_size)</code> 之后，就删除最老的 SST。因此写放大是 1，当然，其实还要考虑 WAL 的写放大。</p><p>因为都在 Level 0，所以 FIFO 下 level 0 可能有很多 sst，从而让读取速度变得很慢。这种情况下，建议使用更多的 Bloom bits 从而减少 Bloom filter 的假阳性问题。</p><p>通过设定 <code>CompactionOptionsFIFO.allow_compaction = true</code> 可以拿最少 <code>level0_file_num_compaction_trigger</code> 个文件，将它们 Compaction 到一起。选取的顺序是从新到旧。</p><p>Compact 的逻辑如下面的例子所示。因为 FIFO 中不存在所谓的版本问题了，所以 Compact 的目的就是让多个 SST 文件变成一个有序的大的 SST 文件。</p><blockquote><p>For example, if level0_file_num_compaction_trigger = 8 and every flushed file is 100MB. Then as soon as there is 8 files, they are compacted to one 800MB file. And after we have 8 new 100MB files, they are compacted in the second 800MB, and so on. Eventually we’ll have a list of 800MB files and no more than 8 100MB files.</p></blockquote><p>Compaction 的执行条件：定期检查数据库大小是否超过 <code>compaction_options_fifo.max_table_files_size</code>，如果超过了，就一次 drop 一个最老的文件，直到重新满足大小限制。</p><h2 id="with-TTL"><a href="#with-TTL" class="headerlink" title="with TTL"></a>with TTL</h2><p>现在并不是数据库大小超过某个 size 才 compaction 了。而是直接删除 ttl 比某个值旧的所有 SST 文件。</p><h1 id="Universal-Compaction"><a href="#Universal-Compaction" class="headerlink" title="Universal Compaction"></a>Universal Compaction</h1><h1 id="Remote-Compaction"><a href="#Remote-Compaction" class="headerlink" title="Remote Compaction"></a>Remote Compaction</h1><p><img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/remote_compaction_overview.png"></p><p>从下面的调用图中可以看出，Compaction 命令同样是由 Primary 发出的，但是实际上是由 Compaction worker 执行的。</p><p><img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/remote_compaction_interface.png"></p><ol><li><p>Schedule<br>The first step is primary DB triggers the compaction, instead of running the compaction locally, it sends the compaction information to a callback in CompactionService. The user needs to implement the CompactionService::Schedule(), which sends the compaction information to a remote process to schedule the compaction.</p></li><li><p>Compact<br>On the remote Compaction Worker side, it needs to run DB::OpenAndCompact() with the compaction information sent from the primary. Based on the compaction information, <strong>the worker opens the DB in read-only mode</strong> and runs the compaction. <strong>The compaction worker cannot change the LSM tree</strong>, it outputs the compaction result to a <strong>temporary location</strong> that the user needs to set.</p></li><li><p>Return Result<br>Once the compaction is done, the compaction result needs to be sent back to primary, which includes the metadata about the compacted SSTs and some internal information. The same as scheduling, the user needs to implement the communication between primary and compaction workers.</p></li><li><p>Install &amp; Purge<br>The primary is waiting for the result by callback CompactionService::Wait(). The result should be passed to that API and return function call. After that, the primary will install the result by renaming the result SST files in the temporary workplace to the LSM files. Then the compaction input files will be purged. As RocksDB is renaming the result SST files, make sure the temporary workplace and the DB are on the same file system. If not, the user needs to copy the file to the DB file system before returning the Wait() call.</p></li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://github.com/facebook/rocksdb/wiki/" target="_blank" rel="noopener">https://github.com/facebook/rocksdb/wiki/</a><br> RocksDB Wiki</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;如题。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="leveldb" scheme="http://www.calvinneo.com/tags/leveldb/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 6</title>
    <link href="http://www.calvinneo.com/2024/12/25/database-paper-6/"/>
    <id>http://www.calvinneo.com/2024/12/25/database-paper-6/</id>
    <published>2024-12-25T13:33:22.000Z</published>
    <updated>2024-12-29T15:02:41.313Z</updated>
    
    <content type="html"><![CDATA[<p>本部分开始为最新的学习笔记。包含 PolarDB Serverless。</p><a id="more"></a><h1 id="PolarDB-Serverless-A-Cloud-Native-Database-for-Disaggregated-Data-Centers"><a href="#PolarDB-Serverless-A-Cloud-Native-Database-for-Disaggregated-Data-Centers" class="headerlink" title="PolarDB Serverless: A Cloud Native Database for Disaggregated Data Centers"></a>PolarDB Serverless: A Cloud Native Database for Disaggregated Data Centers</h1><p><a href="https://users.cs.utah.edu/~lifeifei/papers/polardbserverless-sigmod21.pdf" target="_blank" rel="noopener">https://users.cs.utah.edu/~lifeifei/papers/polardbserverless-sigmod21.pdf</a></p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>大概有三种 cloud 数据库的架构：</p><ol><li>monolithic</li><li>virtual machine with remote disk</li><li>shared storage</li></ol><p>后两种也被统称为存算分离的架构。</p><p>存算一体的架构缺点：</p><ul><li>将 db 分配到对应的机器类似于解决 bin-packing 问题</li><li>难以满足客户的灵活的资源需要</li><li>资源之间没法独立地进行恢复</li></ul><p>下面两种存算分离的架构：CPU 和内存同样存在 bin-packing 的问题，内存开销大。</p><p><img src="/img/dbpaper/polardb-serverless/f1.png"></p><p>因此 PolarDB Serverless 共享了内存。</p><p>和 Aurora、HyperScale 以及 PolarDB 一样，它有一个 RW 的主节点，以及多个 read only replica。它也可以通过提出的 disaggregation 架构支持多个 RW 主节点，但不在这个论文中讨论。</p><p>一些挑战：</p><ul><li>引入共享内存后，事务的正确性。<ul><li>read after write 不会在节点间丢失修改 -&gt; cache invalidation</li><li>RW 节点在 split 或者 merge 一个 B+Tree 的时候，其他的 RO 节点不能看到一个不一致的 B 树 -&gt; global page latch</li><li>不能脏读 -&gt; 在不同的 database node 间同步 read view</li></ul></li></ul><ul><li>网络延迟<ul><li>使用 RDMA CAS 技术提优化 global latch 的获取</li><li>page materialization offloading 技术将 dirty page 从 remote memory 中驱逐，而不是将它们 flush 到存储中</li></ul></li></ul><h2 id="BACKGROUND"><a href="#BACKGROUND" class="headerlink" title="BACKGROUND"></a>BACKGROUND</h2><h3 id="PolarDB"><a href="#PolarDB" class="headerlink" title="PolarDB"></a>PolarDB</h3><p>介绍了 PolarFS。</p><p>RW 和 RO 节点通过 redo log 同步内存状态。通过 LSN 实现一致性，其执行流程是：</p><ol><li>将所有的 redo log flush 到 PolarFS 中</li><li>提交事务</li><li>RW 异步广播消息：read log 以及最新的 LSN 即 LSN_rw。</li><li>当 ROi 收到 RW 的消息后，从 PolarFS 上拉取所有的 redo log，将它们 apply 到 buffer pool 中的 buffered page 里面</li><li>ROi 此时就和 RW 完成了已同步</li><li>ROi 将自己的 LSN_ro 发送给 RW</li><li>RW 可以在后台将 read log 去 truncate 到所有的 LSN_roi 的最小值</li><li>ROi可以处理 LSN_roi 之前的读取，提供 SI 隔离级别</li></ol><p>假设某个 ROk 落后了，比方说落后超过 1M，这样的节点会被发现，并且被踢出集群。</p><p><img src="/img/dbpaper/polardb-serverless/f2.png"></p><h3 id="Disaggregated-Data-Centers"><a href="#Disaggregated-Data-Centers" class="headerlink" title="Disaggregated Data Centers"></a>Disaggregated Data Centers</h3><p><img src="/img/dbpaper/polardb-serverless/f3.png"></p><p>在 disaggregation 架构下，一个数据库实例所需要的计算、内存和存储资源将被分配到同一个 PoD 下面。不同的 db instance 则看见恶意分配到不同的 PoD 下面。计算和内存资源会被尽可能分配到同一个 ToR 下面。</p><p>一台机器有两个 RDMA NIC，他们会被连接到两个 ToR 交换机上面，从而避免网络连接失效。一个 leaf switch group 由多个 leaf switch 组成。ToR switch 连接到 leaf switch 上。</p><h3 id="Serverless-Databases"><a href="#Serverless-Databases" class="headerlink" title="Serverless Databases"></a>Serverless Databases</h3><p>pay-as-you-go model。</p><p>一个 ACU 包含了 2GiB 的内存以及对应的虚拟处理器。这个设定 fixes the resource ratio。比如，分析数据库可能需要更多的内存，而不是 CPU，因为它们可能要 cache 大量的数据。对应的，事务数据库需要大量的 CPU 去处理业务的尖峰。而一个小内存，只要能满足 cache hit，那也是足够的了。</p><h2 id="DESIGN"><a href="#DESIGN" class="headerlink" title="DESIGN"></a>DESIGN</h2><h3 id="Disaggregated-Memory"><a href="#Disaggregated-Memory" class="headerlink" title="Disaggregated Memory"></a>Disaggregated Memory</h3><h4 id="Remote-Memory-Access-Interface"><a href="#Remote-Memory-Access-Interface" class="headerlink" title="Remote Memory Access Interface"></a>Remote Memory Access Interface</h4><p>这里内存也是按照 Page 来组织的。一个 PageID 可以表示为 (space, page_no)。使用 page_register 和 page_unregister 去做类似 RC 一样的内存管理。page_read 从 remote memory pool 拉数据到 local cache。page_write 将 page 从 local cache 写到 remote memory pool。page_invalidate 被 RW 调用，用来将所有 RO 的 local cache 上的 page 设置为无效。</p><h4 id="Remote-Memory-Management"><a href="#Remote-Memory-Management" class="headerlink" title="Remote Memory Management"></a>Remote Memory Management</h4><p>内存分配的单位是 slab，一个 slab 是 1Gb。</p><h5 id="Page-Array-PA"><a href="#Page-Array-PA" class="headerlink" title="Page Array(PA)"></a>Page Array(PA)</h5><p>一个 slab 被一个 PA 结构实现。一个 PA 是一个连续的内存，包含 16KB page 的 array。PA 中的 page 可以被 remote node 通过 RDMA 直接访问，因为他们在启动的时候就已经被注册到 RDMA NIC 上了。</p><p>一个 memory node 也被称为一个 slab node。一个 slab node 管理多个 slab。一个实例可以对应到多个 slab node 上，其中第一个 slab node 称为 home node。home node 中有一些 instance 级别的元数据。</p><h5 id="Page-Address-Table-PAT"><a href="#Page-Address-Table-PAT" class="headerlink" title="Page Address Table (PAT)"></a>Page Address Table (PAT)</h5><p>PAT is a hash table that records the location (slab node id and physical memory address) and reference count of each page. 也就是前面 page_register 和 page_unregister 所操作的东西。</p><p>【Q】这个结构保存在哪里？</p><h5 id="Page-Invalidation-Bitmap-PIB"><a href="#Page-Invalidation-Bitmap-PIB" class="headerlink" title="Page Invalidation Bitmap (PIB)"></a>Page Invalidation Bitmap (PIB)</h5><p>PIB is a bitmap. For each entry in the PAT table, there is an invalidation bit in PIB. Value 0 indicates that the copy of the page in the memory pool is of the latest version, while value 1 means that the RW node has updated the page in its local cache and haven’t written it back to the remote memory pool yet. There is also a local PIB on each RO node, indicating whether each page in the RO node’s local cache is outdated.</p><h3 id="Page-Materialization-Offloading"><a href="#Page-Materialization-Offloading" class="headerlink" title="Page Materialization Offloading"></a>Page Materialization Offloading</h3><p>Aurora 提出 log is database 的理论。将 redo log 看做是增量的 page 修改。Socrates 进一步地，将 log 从 storage 分离。Log 被存在 XLOG 服务中，然后被异步地发送到一系列 page server 中，每一个 page server 负责一个 database partition，独立地重放日志，生成 page 并处理 GetPage@LSN 请求。</p><p>PolarDB 类似于 Socrates，将 PolarFS 设计为分别存放 log 和 page 到两个 chunck 中。redo log 首先被持久化到 log chunkc 中，然后被异步地发送到 page chunck 中。在 page chunck 中，logs 被 apply，从而更新 page。不同于 Socrates，为了重用 PolarFS，log 只会被发送到 page chunk 的 leader 节点，这个节点会物化 page，然后将 update 通过 ParallelRaft 通知给其他的 replica。This method adds additional latency to the ApplyLog operation due to the replication cost. However, it is not a critical issue because ApplyLog is an asynchronous operation not in the critical path. Moreover, since the replicated state machine guarantees data consistency between page chunks, there is no need for an extra gossip protocol among storage nodes like in Aurora.</p><p><img src="/img/dbpaper/polardb-serverless/7.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本部分开始为最新的学习笔记。包含 PolarDB Serverless。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>数据库中的压缩技术</title>
    <link href="http://www.calvinneo.com/2024/12/21/db-compression/"/>
    <id>http://www.calvinneo.com/2024/12/21/db-compression/</id>
    <published>2024-12-21T13:33:22.000Z</published>
    <updated>2024-12-19T16:50:13.852Z</updated>
    
    <content type="html"><![CDATA[<p>主要包含了数据库中的压缩技术。</p><a id="more"></a><h1 id="常见的编码"><a href="#常见的编码" class="headerlink" title="常见的编码"></a>常见的编码</h1><h2 id="Dictionary-Encoding"><a href="#Dictionary-Encoding" class="headerlink" title="Dictionary Encoding"></a>Dictionary Encoding</h2><h2 id="Run-Length-Encoding-RLE"><a href="#Run-Length-Encoding-RLE" class="headerlink" title="Run-Length Encoding, RLE"></a>Run-Length Encoding, RLE</h2><p>重复出现的数字用重复次数代替。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">AAAAABB</span><br><span class="line">==&gt;</span><br><span class="line">A5B2</span><br></pre></td></tr></table></figure><h2 id="Bitmap-Encoding"><a href="#Bitmap-Encoding" class="headerlink" title="Bitmap Encoding"></a>Bitmap Encoding</h2><p>在布尔类型等 low cardinality 数据列中效率好。对位操作很友好。</p><h2 id="Delta-Encoding"><a href="#Delta-Encoding" class="headerlink" title="Delta Encoding"></a>Delta Encoding</h2><p>计算连续值之间的差值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">9999 10000 9998</span><br><span class="line">==&gt;</span><br><span class="line">9999 +1 -2</span><br></pre></td></tr></table></figure><h2 id="ZigZag-Encoding"><a href="#ZigZag-Encoding" class="headerlink" title="ZigZag Encoding"></a>ZigZag Encoding</h2><p>主要解决负数的补码前导零太多影响压缩的问题。</p><h2 id="Prefix-Encoding-Huffman-Encoding"><a href="#Prefix-Encoding-Huffman-Encoding" class="headerlink" title="Prefix Encoding / Huffman Encoding"></a>Prefix Encoding / Huffman Encoding</h2><p>使用短编码表示高频数据，长编码表示低频数据。</p><h1 id="常见的压缩算法"><a href="#常见的压缩算法" class="headerlink" title="常见的压缩算法"></a>常见的压缩算法</h1><h2 id="LZ4"><a href="#LZ4" class="headerlink" title="LZ4"></a>LZ4</h2><h2 id="LZMA-Lempel-Ziv-Markov-Chain-Algorithm"><a href="#LZMA-Lempel-Ziv-Markov-Chain-Algorithm" class="headerlink" title="LZMA(Lempel-Ziv-Markov Chain Algorithm)"></a>LZMA(Lempel-Ziv-Markov Chain Algorithm)</h2><h2 id="Zstd"><a href="#Zstd" class="headerlink" title="Zstd"></a>Zstd</h2><h2 id="Snappy"><a href="#Snappy" class="headerlink" title="Snappy"></a>Snappy</h2><h2 id="Zlib"><a href="#Zlib" class="headerlink" title="Zlib"></a>Zlib</h2><h2 id="GZip"><a href="#GZip" class="headerlink" title="GZip"></a>GZip</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;主要包含了数据库中的压缩技术。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>Branch prediction 和 Branch target prediction</title>
    <link href="http://www.calvinneo.com/2024/12/19/bp-and-btp/"/>
    <id>http://www.calvinneo.com/2024/12/19/bp-and-btp/</id>
    <published>2024-12-19T07:57:20.000Z</published>
    <updated>2024-12-24T15:14:13.927Z</updated>
    
    <content type="html"><![CDATA[<p>假如 predicate 的概率是未知的，抑或 predicate 只会被设置一次，那么下面那种写法的性能更好呢？</p><ol><li><p>Branch prediction</p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dispatch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (predicate)</span><br><span class="line">        logicA();</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        logicB();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Branch target prediction</p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fp = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_fp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (predicate)</span><br><span class="line">        fp = logicA;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        fp = logicB;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dispatch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    fp();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><a id="more"></a><h1 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h1><blockquote><p>Branch prediction is predicting whether or not the branch will be taken. Branch target prediction is prediction where the branch is going to.</p></blockquote><p>Branch prediction 指的是预测是否选择这个分支。Branch target prediction 是预测这个分支走到哪里。从汇编角度来说，Branch prediction 指的是要不要 <code>test</code> 然后 <code>je</code>。Branch target prediction 指的是 <code>jmp</code> 到一个 <code>$12345</code> 还是一个 <code>$eax</code>。</p><ol><li>Unconditional branch, fixed target<ul><li>无限循环</li><li>goto</li><li>break、continue</li><li>非虚函数调用</li></ul></li><li>Unconditional branch, variable target<ul><li><strong>从函数返回</strong></li><li>虚函数调用</li><li>Function pointer call</li><li>switch 语句：如果被编译为 jump table</li></ul></li><li>Conditional branch, fixed target<ul><li>if</li><li>switch 语句：如果被编译为 if</li><li>带 condition 的 loop</li><li><code>&amp;&amp;</code> 和 <code>||</code> 操作符</li><li><code>?:</code> 这个三目运算符</li></ul></li><li>Conditional branch, variable target<br> 这个情况通常不会发生。但作为优化，编译器可能合成出一个来。比如下面的这个可能被编译成一个 conditional indirect jump，比如 <code>jne *%eax</code>。 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (condition) &#123; obj-&gt;VirtualFunctionCall(); &#125;</span><br></pre></td></tr></table></figure></li></ol><p>一般 variable target 跳转无法内联的成本也要考虑在内。</p><h1 id="Branch-Target-Buffer"><a href="#Branch-Target-Buffer" class="headerlink" title="Branch Target Buffer"></a>Branch Target Buffer</h1><p>对于当前 PC 通过 BTB 预测下一条 PC 是什么。如果预测错了，BTB 的对应条目会被更新。一个 naive 的 BTB 需要和程序本身一样大了。</p><p>所以，BTB 也是一个 LRU 一样的东西。只是 cache 住最可能需要被预测的指令。并且，BTB 的 “key” 也不需要整个 PC，而是 PC 的低几位。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://stackoverflow.com/questions/21608874/branch-prediction-vs-branch-target-prediction" target="_blank" rel="noopener">https://stackoverflow.com/questions/21608874/branch-prediction-vs-branch-target-prediction</a></li><li><a href="https://en.wikipedia.org/wiki/Branch_target_predictor" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Branch_target_predictor</a></li><li><a href="https://stackoverflow.com/questions/32290875/branch-prediction-and-branch-target-prediction-optimization" target="_blank" rel="noopener">https://stackoverflow.com/questions/32290875/branch-prediction-and-branch-target-prediction-optimization</a></li><li><a href="https://one2bla.me/cs6290/lesson4/branch-target-buffer.html" target="_blank" rel="noopener">https://one2bla.me/cs6290/lesson4/branch-target-buffer.html</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;假如 predicate 的概率是未知的，抑或 predicate 只会被设置一次，那么下面那种写法的性能更好呢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Branch prediction&lt;/p&gt;
 &lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;dispatch&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (predicate)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        logicA();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        logicB();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Branch target prediction&lt;/p&gt;
 &lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;fp = &lt;span class=&quot;literal&quot;&gt;nullptr&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;set_fp&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (predicate)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fp = logicA;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fp = logicB;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;dispatch&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    fp();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    
    <category term="profiling" scheme="http://www.calvinneo.com/tags/profiling/"/>
    
    <category term="CPU" scheme="http://www.calvinneo.com/tags/CPU/"/>
    
    <category term="性能" scheme="http://www.calvinneo.com/tags/性能/"/>
    
  </entry>
  
  <entry>
    <title>C++ 协程的使用</title>
    <link href="http://www.calvinneo.com/2024/12/01/C++-coroutine-usage/"/>
    <id>http://www.calvinneo.com/2024/12/01/C++-coroutine-usage/</id>
    <published>2024-12-01T15:07:22.000Z</published>
    <updated>2024-12-11T02:51:53.859Z</updated>
    
    <content type="html"><![CDATA[<p>在上一篇中，介绍了 lewissbaker 的三篇文章，实际上覆盖了 C++ 的无栈协程的实现原理，这里介绍几个常见的协程库的使用。</p><a id="more"></a><h1 id="cppcoro"><a href="#cppcoro" class="headerlink" title="cppcoro"></a>cppcoro</h1><p><a href="https://github.com/lewissbaker/cppcoro" target="_blank" rel="noopener">https://github.com/lewissbaker/cppcoro</a></p><h2 id="修改既有代码"><a href="#修改既有代码" class="headerlink" title="修改既有代码"></a>修改既有代码</h2><h3 id="io"><a href="#io" class="headerlink" title="io"></a>io</h3><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>协程调度的核心思想是避免阻塞线程，而 std::mutex 的同步原语通常会导致线程阻塞。因此，需要用 <code>cppcoro::async_mutex</code> 进行替换。</p><p>注意 std::unique_lock 等这样的锁结构并不是同步原语。它的实现中，没有包含线程上下文切换的部分。而相关的逻辑，实际上是通过调用 std::muex 的 lock 和 unlock 函数来实现的。</p><p>尽管如此，cppcoro 中还是提供了诸如 async_mutex_lock 等结构。但这样的结构是为了实现协程而服务的。可以看对应的章节。</p><h2 id="主要数据结构"><a href="#主要数据结构" class="headerlink" title="主要数据结构"></a>主要数据结构</h2><h3 id="task"><a href="#task" class="headerlink" title="task"></a>task<t></t></h3><p>一段可以被异步计算的逻辑，它是被 lazily 执行的。当 await 它的时候，它开始执行。</p><p>下面给了一个读写文件统计行数的例子，用到了：</p><ol><li><code>co_await cppcoro::read_only_file::open(path);</code></li><li><code>co_await file.read(offset, buffer, sizeof(buffer));</code></li></ol><p>一个 co_await 的函数必须用到 co_await 或者 co_return，但未必会用到 co_yield。返回值的类型为 <code>task&lt;T&gt;</code>。<br>当一个返回 task<t> 的协程被调用时，一个 coroutine frame 会在必要的时候被调用，并且一些参数会被捕获到 coroutine frame 中。在 coroutine body 被执行前，协程就会挂起，然后返回给调用者。协程的返回值是一个 task<t>。</t></t></p><p>当这个 task<t> 被 co_await 的时候，coroutine body 会开始执行。这会挂起 await 的 coroutine，然后执行被 await 的那个 coroutine。</t></p><p>task<t> 对应的协程通常以 co_return 或者抛出一个异常为结束。之后，在这个线程上，caller 会被 resume。</t></p><p>如果一个协程已经计算得到了结果，那么 await 它不会导致挂起，而是直接返回结果。</p><p>如果在 await 之前，那个 task 对象就已经被销毁了，那么这个协程就不会被执行，并且析构函数会销毁被捕获的参数，并且释放被 coroutine frame 使用的内存。</p><h3 id="shared-task"><a href="#shared-task" class="headerlink" title="shared_task"></a>shared_task<t></t></h3><p>我理解是单生产者多消费者模式。</p><h3 id="generator-recursive-generator"><a href="#generator-recursive-generator" class="headerlink" title="generator / recursive_generator"></a>generator<t> / recursive_generator<t></t></t></h3><h4 id="generator"><a href="#generator" class="headerlink" title="generator"></a>generator<t></t></h4><p>用法如下所示，但是其中不能使用 co_await，也就是说必须同步地去计算并产生这些值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cppcoro::generator&lt;<span class="keyword">const</span> <span class="built_in">std</span>::<span class="keyword">uint64_t</span>&gt; fibonacci()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="keyword">uint64_t</span> a = <span class="number">0</span>, b = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    co_yield b;</span><br><span class="line">    <span class="keyword">auto</span> tmp = a;</span><br><span class="line">    a = b;</span><br><span class="line">    b += tmp;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">usage</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i : fibonacci())</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (i &gt; <span class="number">1'000'000</span>) <span class="keyword">break</span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; i &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将 fmap 应用到 recursive_generator<t> 将产生 generator<u> 而不是 recursive_generator<u>。</u></u></t></p><h4 id="recursive-generator"><a href="#recursive-generator" class="headerlink" title="recursive_generator"></a>recursive_generator<t></t></h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Lists the immediate contents of a directory.</span></span><br><span class="line">cppcoro::generator&lt;dir_entry&gt; list_directory(<span class="built_in">std</span>::filesystem::path path);</span><br><span class="line"></span><br><span class="line">cppcoro::recursive_generator&lt;dir_entry&gt; list_directory_recursive(<span class="built_in">std</span>::filesystem::path path)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; entry : list_directory(path))</span><br><span class="line">  &#123;</span><br><span class="line">    co_yield entry;</span><br><span class="line">    <span class="keyword">if</span> (entry.is_directory())</span><br><span class="line">    &#123;</span><br><span class="line">      co_yield list_directory_recursive(entry.path());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="async-generator"><a href="#async-generator" class="headerlink" title="async_generator"></a>async_generator<t></t></h3><p>如下所示，可以 co_await 了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cppcoro::async_generator&lt;<span class="keyword">int</span>&gt; ticker(<span class="keyword">int</span> count, threadpool&amp; tp)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    co_await tp.delay(<span class="built_in">std</span>::chrono::seconds(<span class="number">1</span>));</span><br><span class="line">    co_yield i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cppcoro::task&lt;&gt; consumer(threadpool&amp; tp)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">auto</span> sequence = ticker(<span class="number">10</span>, tp);</span><br><span class="line">  <span class="function"><span class="keyword">for</span> <span class="title">co_await</span><span class="params">(<span class="built_in">std</span>::<span class="keyword">uint32_t</span> i : sequence)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Tick "</span> &lt;&lt; i &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="async-mutex"><a href="#async-mutex" class="headerlink" title="async_mutex"></a>async_mutex</h3><p>co_wait 这个 async_mutex 会挂起这个协程，直到这个 mutex 被释放。</p><p>这里和 std::mutex 不同的是，async_mutex 是 lock free 的。lock 它并不会 block 当前线程，而只是挂起当前的 coroutine。</p><p>如下所示，lock_async 调用会返回一个 async_mutex_lock_operation。这个 async_mutex_lock_operation 必须要被 co_await。co_await 的返回值的类型是 void。</p><p>scoped_lock_async 调用会返回一个 async_mutex_scoped_lock_operation。同样它也需要被 co_await。co_await 返回值的类型是 async_mutex_lock。async_mutex_lock 在析构的时候会自动调用持有的 mutex 的 unlock 方法。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// &lt;cppcoro/async_mutex.hpp&gt;</span></span><br><span class="line"><span class="keyword">namespace</span> cppcoro</span><br><span class="line">&#123;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_lock</span>;</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_lock_operation</span>;</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_scoped_lock_operation</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex</span></span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    async_mutex() <span class="keyword">noexcept</span>;</span><br><span class="line">    ~async_mutex();</span><br><span class="line"></span><br><span class="line">    async_mutex(<span class="keyword">const</span> async_mutex&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    <span class="function">async_mutex&amp; <span class="title">operator</span><span class="params">(<span class="keyword">const</span> async_mutex&amp;)</span> </span>= <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">try_lock</span><span class="params">()</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function">async_mutex_lock_operation <span class="title">lock_async</span><span class="params">()</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function">async_mutex_scoped_lock_operation <span class="title">scoped_lock_async</span><span class="params">()</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_lock_operation</span></span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt; awaiter)</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_scoped_lock_operation</span></span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt; awaiter)</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    [[nodiscard]] <span class="function">async_mutex_lock <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_lock</span></span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// Takes ownership of the lock.</span></span><br><span class="line">    async_mutex_lock(async_mutex&amp; mutex, <span class="built_in">std</span>::<span class="keyword">adopt_lock_t</span>) <span class="keyword">noexcept</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Transfer ownership of the lock.</span></span><br><span class="line">    async_mutex_lock(async_mutex_lock&amp;&amp; other) <span class="keyword">noexcept</span>;</span><br><span class="line"></span><br><span class="line">    async_mutex_lock(<span class="keyword">const</span> async_mutex_lock&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    async_mutex_lock&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> async_mutex_lock&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Releases the lock by calling unlock() on the mutex.</span></span><br><span class="line">    ~async_mutex_lock();</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="sync-wait"><a href="#sync-wait" class="headerlink" title="sync_wait"></a>sync_wait</h3><p>类似于 rust tokio 的 <code>block_on</code>。</p><h3 id="when-all-ready-when-all"><a href="#when-all-ready-when-all" class="headerlink" title="when_all_ready/when_all"></a>when_all_ready/when_all</h3><p>类似于 rust tokio 的 <code>futures::join!</code>。两者比较，则 when_all_ready 的功能更强大：</p><ol><li>when_all_ready 可以等所有的协程都成功或者失败地跑完，然后分别获取每个操作的结果，它本身不会抛出异常。而 when_all 中，只要有一个 task 抛出异常，那么整个 task 就会抛出异常然后失败。</li><li>when_all_ready 的返回值是 when_all_task，需要调用 result() 获取结果。而 when_all 返回的是 void 或者 vector。</li></ol><h3 id="fmap"><a href="#fmap" class="headerlink" title="fmap"></a>fmap</h3>]]></content>
    
    
    <summary type="html">&lt;p&gt;在上一篇中，介绍了 lewissbaker 的三篇文章，实际上覆盖了 C++ 的无栈协程的实现原理，这里介绍几个常见的协程库的使用。&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 5</title>
    <link href="http://www.calvinneo.com/2024/11/23/database-paper-5/"/>
    <id>http://www.calvinneo.com/2024/11/23/database-paper-5/</id>
    <published>2024-11-23T13:33:22.000Z</published>
    <updated>2024-12-17T15:35:06.077Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章中，包含 Fast scans on key-value stores、PebblesDB、Snowflake。</p><a id="more"></a><h1 id="Fast-Scans-on-Key-Value-Stores"><a href="#Fast-Scans-on-Key-Value-Stores" class="headerlink" title="Fast Scans on Key-Value Stores"></a>Fast Scans on Key-Value Stores</h1><p><a href="https://vldb.org/pvldb/vol10/p1526-bocksrocker.pdf" target="_blank" rel="noopener">https://vldb.org/pvldb/vol10/p1526-bocksrocker.pdf</a></p><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>KVS 的扩展性能好，get/put 的吞吐量大，延迟低。但是对于复杂的分析查询中，scan 的代价比较高。因为查询类型的请求需要一个很高的 locality，以及 data 的一个 compact representation。但是，弹性的 get/put 依赖 sparse indexes。</p><p>他们做了个 Tellstore，发现它的 get put 性能不差，但是分析以及混合负载的性能很好。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>KVS 的好处，相比传统数据库，除了 abstract 中提到的，还有就是它每一次读写请求的耗时是可预测的，有助于支持 SLA。</p><blockquote><p>As a result, systems for analytical workloads provide additional access methods: They allow data to be fetched all at once (full table scan) and to push down selection predicates and projections to the storage layer. Most KVS do not have such capabilities and those that do, cannot execute scans with acceptable performance.</p></blockquote><p>下面介绍了作者的实验。是 50M 的 YCSB Q1 在四台机器上跑。Cassandra 花了 19 分钟才跑完，非常离谱。RocksDB、MemSQL 和 Kudu 的性能能接受。注意，RocksDB 是单机数据库，所以实验是用了单个机器，跑了 1/4 的数据。但是他们相比真的 realtime，也就是 subsecond 级别，还是很遥远的。<br><img src="/img/dbpaper/tellstore/1.png"></p><blockquote><p>Efficient scans require a high degree of spatial locality whereas get/put requires sparse indexes. <strong>Versioning and garbage collection</strong> are additional considerations whose implementation greatly impacts performance. This paper shows that with reasonable compromises it is possible to support both workloads as well as mixed workloads in the same KVS, <strong>without copying the data</strong>.</p></blockquote><h2 id="REQUIREMENTS"><a href="#REQUIREMENTS" class="headerlink" title="REQUIREMENTS"></a>REQUIREMENTS</h2><h3 id="SQL-over-NoSQL-Architecture"><a href="#SQL-over-NoSQL-Architecture" class="headerlink" title="SQL-over-NoSQL Architecture"></a>SQL-over-NoSQL Architecture</h3><p>下面就是作者提出的架构。Commit Manager 是用来保证 SI 的。SI 或者其他的 MVCC 实现已经成为 HTAP 的 De facto standard 因为这样 OLTP 不会和 OLAP 发生 block 或者 interfere。</p><p>下面介绍了 Commit manager 的功能，看起来类似于一个中心授时的服务，以及一个事务的仲裁机制。</p><blockquote><p>With Snapshot Isolation, the commit manager simply assigns transaction timestamps and keeps track of active, committed, and aborted transactions and, thus, rarely becomes the bottleneck of the system.</p></blockquote><p>这样的 SQL-over-NoSQL 架构的好处是提供了弹性。每一层中都可以独立地添加机器。比如可以快速扩容出一个 AP 节点用来做分析查询，然后查完了再删掉。</p><p><img src="/img/dbpaper/tellstore/2.png"></p><p>进一步精细化了这样的 SQL-over-NoSQL 需要满足的条件：</p><ul><li>Scans<br>  In addition to get/put requests, the KVS must support efficient scan operations. In order to reduce communication costs, the KVS should support selections, projections, and simple aggregates so that only the relevant data for a query are shipped from the storage to the processing layer. Furthermore, support for shared scans is a big plus for many applications [38, 50, 46].</li><li>Versioning<br>  To support Multi-Version Concurrency Control, the KVS must maintain different versions of each record and return the right version of each record depending on the timestamp of the transaction. Versioning involves garbage collection to reclaim storage occupied by old versions of records. </li><li>Batching and Asynchronous<br>  Communication To achieve high OLTP performance, it is critical that OLTP processing nodes batch several requests to the storage layer. This way, the cost of a roundtrip message from the processing to the <strong>storage layer</strong> is amortized for <strong>multiple concurrent transactions</strong> [30]. Furthermore, such batched requests must be executed in an asynchronous way so that the processing node can collect the <strong>next batch</strong> of requests while <strong>waiting for</strong> the previous batch of requests to the KVS to complete.</li></ul><h3 id="Why-is-it-Difficult"><a href="#Why-is-it-Difficult" class="headerlink" title="Why is it Difficult?"></a>Why is it Difficult?</h3><p>作者的意思是，因为上面三个条件冲突，所以很多除了 Kudu 之外的 KVS 现在都只支持点查，比如 Cassandra 或者 HBase。诸如 HBase 或者 RAMCloud 的可能还会多支持一个 Versioning，sometimes 会有 async communication。上n. All<br>these features are best supported with sparse data structures for get/put operations. When retrieving a specific version of a record, it is not important whether it is clustered and stored compactly with other records. 但是 scan 就对 data locality 和一个紧凑的表示有要求了。Locality 对于基于磁盘的扫描，或者只在内存中的扫描都很重要。具体来说，添加 scan 有下面的局部性冲突：</p><ol><li>Scan vs. Get/Put<br> 分析系统需要列存提高 locality。KVS 喜欢行存，这样就可以在不物化 records 的情况下处理点查请求。</li><li>Scan vs. Versioning<br> 这个不用多说了。</li><li>Scan vs. Batching<br> scan 和点查做 batch 没有什么好处。TP 负载需要低延迟，scan 的负载的延迟变化很大，取决于 predicate 以及要读取的列的数量。</li></ol><h2 id="DESIGN-SPACE"><a href="#DESIGN-SPACE" class="headerlink" title="DESIGN SPACE"></a>DESIGN SPACE</h2><h3 id="Where-to-Put-Updates"><a href="#Where-to-Put-Updates" class="headerlink" title="Where to Put Updates?"></a>Where to Put Updates?</h3><p>主要有三种方式：</p><ol><li>update-in-place<br> 大部分 rdbms 中使用。如果 records 是 fix-size 的，那么这个策略比较好，因为这样的 fragmentation 就比较少了。<br> 如果使用了 versioning 技巧，那么就比较 trick 了。如果 version 和 record 存在一起，那么 fragmentation 就会很大，locality 就会损失。<br> 另外一点是损失了并发性，因为更新一条记录，就需要锁住整个 page。</li><li>log-structured<br> 这个设计有两点好处：第一是没有 fragmentation，第二是没有 Concurrent 问题，因为 append 可以被非阻塞地实现。<br> 它的问题是，scan 需要读取旧的数据，以及检查它们的有效性。特别地，如果 record 很少被 update，那么 gc 就比较困难。<br> LSM 是基于 LS 的修改，它引入了阶段性的 reorg，从而提高读取的性能。</li><li>delta-main<br> 最初的设计来源于 SAP Hana。也就是使用了读优化的 main，以及写优化的 delta。</li></ol><h3 id="How-to-Arrange-Records"><a href="#How-to-Arrange-Records" class="headerlink" title="How to Arrange Records?"></a>How to Arrange Records?</h3><p>主要是行存，或者列存。<br>提到了列存中的一个变体也就是 PAX。PAX 中按照行来分 Page，但是在每个 Page 中，是按照列来存的。<br>列存对于定长的值是性能比较好的，所以目前的系统会设法避免动态长度的值。目前的系统要么禁用，要么就是存储指针，然后将它们放在一个全局堆上面。要么就是使用字典。</p><h3 id="How-to-Handle-Versions"><a href="#How-to-Handle-Versions" class="headerlink" title="How to Handle Versions?"></a>How to Handle Versions?</h3><p>MVCC 的两种方案：</p><ol><li>在同一个地方存放一个记录的所有版本<br> 通常和 update-in-palce 一起使用。<br> 创建新的版本会比较简单，但是 gc 会更加麻烦，因为要 compact 这些 page。<br> 特别地，在 LS 结构中，就需要将所有的 version 都重新拷贝到头部。</li><li>将所有的版本串成一个链表<br> 更适合 LS。<br> 但是这个指针占用额外存储。遍历这些指针会产生较多的 cache miss。<br> 好处是这个方案下，GC 比较方便，因为它相当于是对 log 做一个 truncation。另外，这个方案的 fragmentation 较少。</li></ol><h3 id="When-to-do-Garbage-Collection"><a href="#When-to-do-Garbage-Collection" class="headerlink" title="When to do Garbage Collection?"></a>When to do Garbage Collection?</h3><p>两种策略：</p><ol><li>在专门的线程中定期 gc</li><li>在 scan 的过程中 gc</li></ol><p>其中第二种做法会增加 scan 的时间开销。但是，如果扫描频繁的表，能够被及时 gc，那么也相应能提升它们后续被扫描的性能。而且，这个时候反正数据已经再被访问了，这个时候做 gc 能够避免额外访问 data 的 cache miss。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>上面几点，可以最多组成 24 个设计的变体。但是其中有很多不合理的，比如 delta-main + column-major 就比 log-structured + column-major 好。另一个例子是 log-structured + chained-version 比 log-structured + clustered-versions 要好。</p><p>The two most extreme variants are the variant based on log-structured with chained-versions in a row-major format and the variant using a delta-main structure with clustered-versions in a column-major format.</p><p>下面两节中，会分别介绍 TellStore-Log 和 TellStore-Col。</p><h2 id="TELLSTORE-LOG"><a href="#TELLSTORE-LOG" class="headerlink" title="TELLSTORE-LOG"></a>TELLSTORE-LOG</h2><p>这个设计是基于 RAMCloud 启发的，但是做出了重要的修改，以提升 scan 能力。</p><p><img src="/img/dbpaper/tellstore/f2.png"></p><h3 id="Where-to-Put-Updates-1"><a href="#Where-to-Put-Updates-1" class="headerlink" title="Where to Put Updates?"></a>Where to Put Updates?</h3><ol><li>Hash 表被用来索引 log 中的 record</li><li>The log itself is segmented into a linked-list of pages storing all key-value pairs.</li></ol><p>Memory in the log can be allocated in a lock-free way by atomically incrementing the page head pointer. 一旦一个 record 写入 log，它就是 immutable 的。因为是无锁的，所以冲突的 entry（具有相同的 key）可以被并发 append 到 log 上。一个 record 只有在它的 pointer 被成功添加到 hash table （或者被更新）之后，才被认为是 valid 的。在冲突的情况下，the record in the log will be invalidated before the data becomes immutable. Deletes are written as specially marked updates with no data. </p><p>如果 hash 表的设计是有锁了，就会是一个 contention point。很多无锁 hash table 的实现都是对某种特定访问模式的。比如，支持 resize，就会限制 lookup 和 update 的性能。TellStore 中预先分配了一个固定大小的 hash table，这个 table 被 storage node 中的所有 table 共享。这个实现使用了一个 open-addressing 算法，使用了 linear probing 机制。这样做是为了在 collision 的情况下，利用空间局部性。当然，坏处是在负载比较高的情况下，open addressing 的办法性能比较差。因此，hash bucket 中只保存 table id，record key 以及指向 record 的指针，目的是为了尽可能减少 hash 表的内存占用。</p><h3 id="How-to-Arrange-Records-1"><a href="#How-to-Arrange-Records-1" class="headerlink" title="How to Arrange Records?"></a>How to Arrange Records?</h3><p>LS 的方法总是固有地和行存绑定。为了支持快速 scan，record 必须要 self-contained。我们特别希望避免通过查找 hash table，从而去确认一个 record 是否 valid，也就是它是否被删除了，或者被 overwritten 了。TellStore-Log 为每个 table 分配了一个 log，所以这样只会 scan 到相关的 page，提高了局部性。进一步，a scan over the log is sensible to the amount of invalid records in the log, impacting the locality requirement, as we will see in Section 4.4.</p><h3 id="How-to-Handle-Versions-1"><a href="#How-to-Handle-Versions-1" class="headerlink" title="How to Handle Versions"></a>How to Handle Versions</h3><p>为了找到一个 key 的较老版本，需要维护一个 version-chain。也就是每个 reocrd 都会存一个自己的 previous pointer。另外，the timestamp of the transaction creating the record 会被存放在一个 valid-from 字段中（放在 metadata 里面）。This version chain is always strictly ordered from newest to oldest according to the snapshot timestamp, with the hash table pointing to the newest element. 给定一个 snapshot timestamp，一个 get 操作能够遍历这个 chain，从而找到第一个满足的元素。这个操作有大量的 cache miss，但是这是实现快速写入的代价。</p><p>看起来，这个设计似乎是和 self-contained 这个要求冲突的，如果只能提供 creation timestamp，那么 scan 的时候就不能确定一个 record 是否已经过期了。因此，为了避免查 hash table，就需要添加一个 valid-to timestamp 表示什么时候过期。这是一个 mutable 字段，也存放在每个 record 的 metadata 里面。当成功写入了一个对象 record 的一个新版本之后，前一个版本的 valid-to 就会被设置为新版本的 valid-from。Given a snapshot timestamp, the scan can decide if an element qualifies for inclusion in the snapshot only by comparing the two timestamps.</p><p>The hash table remains the sole point of synchronization and always points to the newest element. There is no race-condition between updating the hash table and setting the valid-to field, as Snapshot Isolation in TellStore does not guarantee visibility for inprogress transactions. </p><h3 id="When-to-do-Garbage-Collection-1"><a href="#When-to-do-Garbage-Collection-1" class="headerlink" title="When to do Garbage Collection?"></a>When to do Garbage Collection?</h3><p>scan 的性能，受到有多少过期了的 element 的影响。</p><p>对于每一个 page，根据 size 计算一个 valid rate。如果这个值低于某个特定的阈值，page 就会被 gc。也就是在下一次扫描的时候，会被重写。重写是拷贝剩余的 active 的 element 到 log 的头部。不需要的 page 会被返回给 free page pool 复用。当拷贝完新的 log head 之后，这个 key 的 version chain 的 pointer 需要被调整。也就是说，需要在 hash table 中查找这个 key，然后找到 version chain 的对应位置。显然，这个操作代价昂贵，因为空间局部性差。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>这里的主要贡献是提供了一个办法去让 log record 能够 self-contained，这样 MVCC 遍历会更快。另外，它提出 hash table 的内存使用要减少，因为即使 concurrent hash table 也是有 drawback 的。</p><h2 id="TELLSTORE-COL"><a href="#TELLSTORE-COL" class="headerlink" title="TELLSTORE-COL"></a>TELLSTORE-COL</h2><p>如下图所示，包含四个结构：</p><ol><li>一些 page 用来储存 main 的数据</li><li>两个 log 用来保存 delta，一个存 inserts 一个存 updates<br>1， 一个 hash table 用来索引数据</li></ol><p><img src="/img/dbpaper/tellstore/f3.png"></p><h3 id="Where-to-Put-Updates-2"><a href="#Where-to-Put-Updates-2" class="headerlink" title="Where to Put Updates?"></a>Where to Put Updates?</h3><p>Except for select metadata fields, main 中的数据是制度的，所有的更新会被写到一个 append-only 的 LS 存储中。不同于 TS-Log，delta 存在两个 log 里面，分别是 update-log 和 insert-log。作这个区分的好处是可以更容易从 delta 构建 main。在 index 中存了一个 flag，表示这个 pointer 指向的是 delta 还是 main。除了这个 flag 之外，index 和 TS-Log 使用了相同的 hash table。</p><p>在写之前，需要查询 index，寻找 record 的 key。如果这个 key 不存在，就插入到 insert-log。这是因为在 LS 的方法中，冲突的 entry 是可以被并发写到 log 中的。对于插入，index 部分是一个 point of synchronization，只有在将一个 pointer 插入到 index 中之后，这个 insert 才是有效的。</p><p>如果 key 是存在的，record 就会被 append 到 update-log 尾部。在 main 和 insert-log 中的 record 中都有一个可变的 newest 的字段，它保存了一个指向同一个 key 的最新被写入的元素。<br>【Q】从图中可以看出，这是在说 main 和 insert-log 中的每个 key，都会有一个指针 newest 去指向 update-log 中的一个位置，表示这个 key 中最新的数据。所以我理解这个指针的更新会有比较昂贵的开销。<br>同样，冲突的 records 可以被并发地写到这个 log中。这个 newest pointer 是 update 的 point of synchronization。</p><h3 id="How-to-Arrange-Records-2"><a href="#How-to-Arrange-Records-2" class="headerlink" title="How to Arrange Records?"></a>How to Arrange Records?</h3><p>对于两种 delta-log，它们都是以行存进行存储的。但是对于 main，则可以讨论具体的存储方式。</p><p>TS-Col 中使用一个列存，称为 ColumnMap 的方式存储 main。这个思想实际上类似 PAX。<br>如果一个 table 中的每个 field 都是 fixed size，那么就足以知道一个 record 的 first attribute 出现的位置。这个位置可以通过 page 中有多少个 record，以及每个 attribute 的 data type size 来计算出来。但是如果 fields 中有可变长度的类型，那么就不能这么简单计算了。</p><p>所以，如下图所示，除开了 Fixed Size Columns 之外，有一个 heap 用来存储所有的可变长度的字段。This heap is indexed by fixed-size metadata storing the 4-byte offset into the heap and its 4-byte prefix. While the metadata fields are stored in column-major format, the contents of the fields are stored in row-major format in the heap.</p><p>这有两个好处。首先，当物化 records 的时候，变长的 fields 已经是以行存格式存在的了，所以可以被简单拷贝到 output buffer 中。其次，在 fixed-size column-major format 中保存一个前缀，可以加快通常的基于前缀的 scan queries。这是因为我们可以根据前缀，去缩小需要选择的 tuple 的反而，减少查询 heap 的次数。</p><p><img src="/img/dbpaper/tellstore/f4.png"></p><h3 id="How-to-Handle-Versions-2"><a href="#How-to-Handle-Versions-2" class="headerlink" title="How to Handle Versions?"></a>How to Handle Versions?</h3><p>TS-Log 同样也保存了 valid-from，作为 records 的 metadata 的一部分。在 update-log 中的 records 会被从新到旧地连接起来，每个版本都会持有一个 previous pointer。在 main 和 insert-log 中会存储的 newest pointer 会指向 update-log 中的最新的元素。为了避免 loops，没有从 update-log 到 main 的 back pointer。</p><p>在一个 main page 中，同一个 key 的不同版本会被连续地从新到旧地存放在一个 column-major format 中。valid-from 时间戳，和 newest pointer 也会被转成 column-major 的格式，并且在 metadata scetion 中以 normal attributes 的形式进行存储。index 总是指向 the metadata field of the newest element in the ColumnMap or the insert log. 给定一个 snapshot timestamp，会从新到旧开始扫描 valid-from 字段，直到 a timestamp is found that is contained in the snapshot.</p><p>和之前原理相同，为了保证 record 是 self-contained 的，需要将 newest pointer 和 record 一同存储，而不是存在 hash table 中。否则，为了知道一个 new record 有没有被写入过，就必须查找 hash table 了。Records in both delta-logs only store the timestamp of the transaction that created them and as such are not self-contained. This is a trade-off between scan and garbage collection performance, as discussed in Section 5.4.</p><h3 id="When-to-do-Garbage-Collection-2"><a href="#When-to-do-Garbage-Collection-2" class="headerlink" title="When to do Garbage Collection?"></a>When to do Garbage Collection?</h3><p>GC 主要负责定期将两个 delta-logs 中的更新 merge 到 main 中。这能保障有效率的 scan 需要的局部性。所有的 main page 都是不可变的，并且通过 COW 机制去 rewrite。This is necessary in order to not interfere with concurrent access from get/put and scans, as update-in-place would require a latch on the page.</p><p>相比 TS-Log，从 delta 到 main 去 compact page 是更加昂贵的，因为涉及行转列。所以，GC 会作为一个单独的线程来运行，而不会被 piggy-back 到 scan 过程中。这个专门的线程会定期扫描 main 中每个 page 的 metadata 部分，一旦它发现一个 page 中有某个 record，它要么被 update 了（通过检查 newest 指针），要么不在被任何 active 的 snapshot 持有（通过检查 valid-from 字段），就会重写这个 page。</p><p>通过遍历 version chain，可以从 main 和 update-log 中得到这个 key 的所有的 version。 Elements with timestamp that are not contained in any active snapshot are discarded, while elements gathered from the update-log are converted to column-major format. 所有这些元素，会被从新到旧排序，然后被 append 到一个新的 main page 中。在 relocate 一个 record 之后，newest 字段会被更新，指向 new record。这样并发的 update 能够知道发生了这个 relocation。最后，GC 会扫描所有 insert-log 中的 record，将 update-log 中所有这个 key 的写入取出来，并且以列式写到 main page 中。此后，delta-logs 可以被 truncated 掉，然后这些旧的 page 会被放到 free page 池中。</p><p>通过分离 insert 和 update log，GC 只需要扫描 insert-log 从而获取所有不在 main 中的 key。当然，坏处是，它会降低 scan 的数据局部性，因为 update 会导致 scan 为了遍历 version chain 从而去从 update-log 中随机读取。这里的前提是让 GC 更加有效率，这样它能更频繁地跑，从而减少 update-log 的大小。</p><p>Page 是被 aggressively 进行 compact 的。如果一个 page 中的一个 element 变为 invalid 了，整个 page 就会被 rewrite。如果负载比较中，那么写放大就会比较大。这对 dick-based 系统影响比较大，但是 memory-based 的系统就还好。An extension to this approach would be to compact pages based on dirtiness, similar to TellStore-Log. Delaying the compaction, on the other hand, will keep a higher portion of the data in the delta-log which, in turn, will impact scan performance.</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Versioning can be achieved by clustering records of the same key together and treating their timestamp as a regular field in a column-major format.</p><h2 id="IMPLEMENTATION"><a href="#IMPLEMENTATION" class="headerlink" title="IMPLEMENTATION"></a>IMPLEMENTATION</h2><h3 id="Asynchronous-Communication"><a href="#Asynchronous-Communication" class="headerlink" title="Asynchronous Communication"></a>Asynchronous Communication</h3><p>意思是等待 storage request 被完成的时候，processing instance 不要闲置。所以用了叫 InfinIO 的这个异步通信库。 InfinIO, which was built specifically to run on top of Infiniband, employs user-level threads and callback functions through an API similar to the one provided by Boost.Asio for Ethernet communication. All requests to TellStore immediately <strong>return a future object</strong> on which the calling user-level thread can wait.<br>InfinIO then transparently <strong>batches</strong> all requests at the network layer before actually sending them to TellStore. Likewise, responses from the storage are batched together before sending them back to the processing nodes. This batching greatly improves the overall performance as it cuts down the message rate on the Infiniband link, which would otherwise become the performance bottleneck.</p><h3 id="Thread-Model"><a href="#Thread-Model" class="headerlink" title="Thread Model"></a>Thread Model</h3><p>如下所示，分为了下面几种类型的线程。<br><img src="/img/dbpaper/tellstore/tm.png"></p><p>To guarantee a consistent throughput for scans and get/put operations, TellStore only uses lock-free data structures.</p><p>有一个 scan 线程还扮演 scan coordinator 的角色。它会将队列里面的所有 scan request 组合成一个 single shared scan。 The coordinator partitions the storage engine’s set of pages and distributes them equally among the scan threads. All the scan threads (including the coordinator) then process their partition in parallel independently. 每一部分的结果会通过 RDMA 被直接写到 client 的内存中。</p><h3 id="Data-Indexing"><a href="#Data-Indexing" class="headerlink" title="Data Indexing"></a>Data Indexing</h3><p>在 TS-Log 和 TS-Col 的介绍中，讲解了使用一个 lock-free hash table 去在单个 node 中索引 records。为了在多个 nodes 中索引 keys，TS 实现了一个类似 Chord 的分布式 hash table。如何选择 hash table 是和如何支持快速 scan 正交的一个问题。</p><p>对于 range partitioning，可以使用像 Btree 或者 LSM 去在 page 内索引数据。但这会让 get/put 操作更加昂贵。为了支持 range query，Tell uses a lock-free B-tree that is solely implemented in the processing layer as described in [30].</p><h3 id="Predicate-Pushdown"><a href="#Predicate-Pushdown" class="headerlink" title="Predicate Pushdown"></a>Predicate Pushdown</h3><p><img src="/img/dbpaper/tellstore/f6.png"></p><h1 id="PebblesDB"><a href="#PebblesDB" class="headerlink" title="PebblesDB"></a>PebblesDB</h1><p><a href="https://www.cs.utexas.edu/~vijay/papers/sosp17-pebblesdb.pdf" target="_blank" rel="noopener">https://www.cs.utexas.edu/~vijay/papers/sosp17-pebblesdb.pdf</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文提出了一个 Fragmented LSM 降低 LSM 的写放大和内存开销。FLSM 引入了一个叫 guard 的概念来组织 logs，避免在同一层中 rewrite data。通过修改 HyperLevelDB 的代码，来实现 FLSM 的数据结构。测试显示，PebblesDB 能够减少 2.4-3 倍的写放大，提升写吞吐量为 6.7x。</p><h2 id="INTRODUCTION-1"><a href="#INTRODUCTION-1" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>下图是常见的 kvstore 的写放大。在测试中使用了 500M 个 kv 对，并且它们被随机 insert 或者 update。通常的思考是，减少写放大通常需要牺牲 write 或者 read 的吞吐量。在当前的低延迟、大写入的场景中，用户并不愿意牺牲任何一个。<br><img src="/img/dbpaper/pebblesdb/f1.png"></p><p>LSM 的写放大的问题主要是数据结构本生。因为 LSM 要求 sorted order，从而支持高效率的查询。但是当新的 data 被添加到 LSM 中，就需要 rewrite 既有的数据，从而导致大量的 write IO。</p><p>主要贡献：</p><ol><li>提出了 FLSM 树，将跳表和 LSM 树结合。</li><li>实现了 PebblesDB</li><li>实验结果</li></ol><h2 id="BACKGROUND"><a href="#BACKGROUND" class="headerlink" title="BACKGROUND"></a>BACKGROUND</h2><h3 id="Log-Structured-Merge-Trees"><a href="#Log-Structured-Merge-Trees" class="headerlink" title="Log-Structured Merge Trees"></a>Log-Structured Merge Trees</h3><h4 id="Write-Amplification-Root-Cause"><a href="#Write-Amplification-Root-Cause" class="headerlink" title="Write Amplification: Root Cause"></a>Write Amplification: Root Cause</h4><p>下图展示了 LSM KVStore 中的 compaction。Level 1 中最初有两个 sst。假设 Level 0 被配置为最多只能有一个 sst，当达到 limit 之后，compaction 就会发生。在 t1 时刻，添加了一个新的 sst。在 t2 时刻，触发了一个 compaction。后面的 3-6 也是同理的。在 compact 一个 sst 的时候，所有下一层中 range 和这个 sst 相交的都会被 rewrite。在这个例子中，因为 level 0 中的所有 sst 都和 level 1 中的 sst 相交，所以只要 level 0 被 compact 了，level 1 就需要被重写。在这个最坏的情况的例子中，Level 1 sstables are rewritten three times while compacting a single upper level.</p><h4 id="The-Challenge"><a href="#The-Challenge" class="headerlink" title="The Challenge"></a>The Challenge</h4><p>一个减少写放大的做法就是不去 merge sst，而是直接加 sst。但这样会导致 read 和 range query 的性能显著降低。因为：</p><ol><li>如果不 merge，那么 kvstore 中就会存在大量 sst</li><li>因为现在有多个 sst 中包含相同的 key，并且相同的 level 上有 overlap 的 key range，读操作需要访问较多的 sst</li></ol><p><img src="/img/dbpaper/pebblesdb/f2.png"></p><h2 id="FRAGMENTED-LOG-STRUCTURED-MERGE-TREES"><a href="#FRAGMENTED-LOG-STRUCTURED-MERGE-TREES" class="headerlink" title="FRAGMENTED LOG-STRUCTURED MERGE TREES"></a>FRAGMENTED LOG-STRUCTURED MERGE TREES</h2><p>目的是同时达到：低写放大、高写吞吐、好的读取性能。</p><p>FLSM 可以看做是 LSM + SkipList，以及一个新颖的可以减少写放大和增加写吞吐的压缩算法。lsm 的基础问题是 sst 会被重写多次。m. FLSM counters this by fragmenting sstables into smaller units. 现在相比重写 sst，FSLM 的 compaction 只是会将一个新的 sst fragment 去 append 到下一层中。这就保证了数据在大多数层中只会写最多一次。对于较高的层，会用一个不同的 compaction 算法。</p><p>FLSM 通过 guards 去实现这个 lauour。</p><h3 id="Guards"><a href="#Guards" class="headerlink" title="Guards"></a>Guards</h3><p>在传统的 lsm 中，每一层包含的 sst 对应的 key range 都是不相交的，也就是说每个 key 都只会在一个 sst 中出现。本文的主要观察是为了维护这个 invariant，是导致写放大的根因，因为它强迫同一层中的数据被重写。FLSM 放弃了这个 invariant，也就是每一层中可以包含多个 overlap 的 sst，也就是说一个 key 可能在多个 sst 中。为了方便从每一层中找到 key，FLSM 将 sst 组织乘了 guards。</p><p>每一层中包含多个 guards。Guards 将 key space 分成了不相交的单元。每一个 guard Gi 有一个关联的 key Ki，是从被添加到 FLSM 的 key 中选择的。层数越高，guards 越多，也就是当数据被 push 到越来越低的层的时候，guards 就会显著变多。和 skip list 一样，如果一个 key 是 i 层的 guard，那么它也是所有 level &gt; i 的层的 guard。</p><p>每一个 guard 有一系列关联的 sst。每个 sst 都是 sorted 的。如果 guard Gi 和 Ki 关联，guard Gi+1 和 Ki+1 关联，那么在 [Ki, Ki+1) 中的 sst 就会被 attach 到 Gi。每一层中比第一个 guard 小的 sst 会被一个专门的 sentinel guard 来存储。最后一个 guard Gn 会存储所有 keys 大于等于 Kn 的 sst。一层中的 guard 不会有 overlap 的 key range。</p><p>在 FLSM compaction 的实现中，the sstables of a given guard are (merge) sorted and then fragmented (partitioned), so that each child guard receives a new sstable that fits into the key range of that child guard in the next level.</p><p>下图中是一个例子。</p><ul><li>put() 会导致 key 被添加到 memtable 中。最终 memtable 会变慢，那么会被 dump 为 level 0 层的一个 sst。level 0 没有任何的 guards。</li><li>当层数变高，guards 的数量就会变大，但并不一定是指数级别的变大。</li><li>每一层都有个 sentinel guard。</li><li>在 FLSM 中的数据是被部分排序的</li></ul><p><img src="/img/dbpaper/pebblesdb/f3.png"></p><h3 id="Selecting-Guards"><a href="#Selecting-Guards" class="headerlink" title="Selecting Guards"></a>Selecting Guards</h3><h4 id="Guard-Probability"><a href="#Guard-Probability" class="headerlink" title="Guard Probability"></a>Guard Probability</h4><p>用 guard probablity 定义一个 key 是否是 guard。即 <code>gp(key, i)</code> 表示 <code>key</code> 是第 i 层的 guard 的概率。level 1 的 guard 是最少的，所以 gp 就很低。随着 level 的增高而增高。</p><p>如果 K 是第 i 层的 guard，那么它也是第 i + 1、i + 2 等的 guard。</p><h4 id="Other-schemes-for-selecting-guards"><a href="#Other-schemes-for-selecting-guards" class="headerlink" title="Other schemes for selecting guards"></a>Other schemes for selecting guards</h4><p>FLSM could potentially select new guards for each level at compaction time such that sstable partitions are minimized; however, this could introduce skew. We leave exploring alternative selection schemes for future work.</p><h3 id="Inserting-and-Deleting-Guards"><a href="#Inserting-and-Deleting-Guards" class="headerlink" title="Inserting and Deleting Guards"></a>Inserting and Deleting Guards</h3><p>guards 不是同步地被插入 FLSM 中的。因为插入 FLSM 中需要切分或者移动 sstable。如果一个 guard 被插入到了多个 level 中，那么就需要要对所有层进行处理。因此，作者将它设计为并行的。<br>当 guards 被选中，他们会被插入到一个内存中的 set 中，称为 uncommitted guards。sstable 并不会基于这些 uncommitted guards 而进行划分。<br>在下一次的 compaction cycle 中，sstable 会被旧的 guard 以及 uncommitted guard 重新划分。任何需要被 uncommitted guard 切分的 sstable 会被 compact 到下一层中。在 compaction 的最后，uncommitted guards 会被持久化到存储中，并被加到 guards 的集合中。后续的读取都会基于这个全集来做了。</p><p>在大部分的 workload 中，删除 guard 都是不必要的。一个 guard 可能因为 key 被删除了，所以变为空的。但这并不影响性能，因为 get() 会跳过这些空的 guards。当然，有两个场景删除是有用的：</p><ol><li>guard 是空的</li><li>这一层中的数据在 guard 中分布是不均匀的。此时，重新计算 guard 能够提升性能。</li></ol><p>删除 guard 这个行为也是异步做的。也有一个内存中的 set 来维护 uncommitted 的删除。删除 G 这个 guard 会导致所有属于 G 的 sst 被重新添加到 level i 的相邻分区，或者 level i+1 中。注意，从 level i 到 i + 1 的 compaction 是正常的，因为 G 依然是 level + 1 的一个 guard。</p><h3 id="FLSM-Operations"><a href="#FLSM-Operations" class="headerlink" title="FLSM Operations"></a>FLSM Operations</h3><h4 id="get"><a href="#get" class="headerlink" title="get"></a>get</h4><p>首先找 memtable，如果找不到，从 level 0 开始找。<br>这里最坏的情况是每一层都需要读一个 guard，然后这个 guard 里面的每个 sst 都需要被读取。</p><h4 id="range-query"><a href="#range-query" class="headerlink" title="range query"></a>range query</h4><p>首先需要确定每一层涉及到的 guard。对每个 sst 执行一次二分查找，找到最小的 key，后面的 key 就通过类似于 merge 的方式来处理了。</p><h4 id="put"><a href="#put" class="headerlink" title="put"></a>put</h4><p>略</p><h4 id="key-updates-and-deletions"><a href="#key-updates-and-deletions" class="headerlink" title="key updates and deletions"></a>key updates and deletions</h4><p>也是通过 sequence number 来维护版本的。</p><h4 id="compaction"><a href="#compaction" class="headerlink" title="compaction"></a>compaction</h4><p>当一个 guard 中的 <strong>sst 数量到达阈值</strong>之后，就会 compact 到下一个 level。【Q】所以看起来 compaction 的粒度是 guard 了。<br>The sstables in the guard are first (merge) sorted and then partitioned into new sstables based on the guards of the next level; the new sstables are then attached to the correct guards. For example, assume a guard at Level 1 contains keys {1, 20, 45, 101, 245}. If the next level has guards 1, 40, and 200, the sstable will be partitioned into three sstables containing {1, 20}, {45, 101}, and {245} and attached to guards 1, 40, and 200 respectively.</p><p>大多数情况，compaction 都不需要 <strong>rewrite</strong> sst。这是 FLSM 如何减少写放大的 main insight。【Q】但这里 split 一个 sst 应该也是需要重写的？新的 sst 会被简单地直接加入到下一层中的对应 guard 中。但是有两个例外：</p><ol><li>对于最高层，也就是 level 5，sst 需要在 compaction 的时候重写。显然没有更高的层可以给它继续放了。</li><li>对于次高层，也就是 level 4，FLSM will rewrite an sstable into the same level if the alternative is to merge into a large sstable in the highest level (since we cannot attach new sstables in the last level if the guard is full)<br> The exact heuristic is rewrite in second highest-level if merge causes 25× more IO.</li></ol><p>FLSM 的 compaction 是可以并行的。因为 compact 一个 guard 只涉及到下一层中的对应的 guard 们。FLSM 中选择 guards 的方法保证了 compact 一个 guard 的同时不会影响到同一层中的其他 guard。</p><h3 id="Tuning-FLSM"><a href="#Tuning-FLSM" class="headerlink" title="Tuning FLSM"></a>Tuning FLSM</h3><p>Tuning max_sstables_per_guard allows the user to tradeoff more write IO (due to more compaction) for lower read and range query latencies. Interestingly, if this parameter is set to one, FLSM behaves like LSM and obtains similar read and write performance. Thus, FLSM can be viewed as a generalization of the LSM data structure.</p><h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>get 以及范围查询，因为要检查 guard 中的所有的 sst，所以读取的延迟增加了。</p><h1 id="Snowflake"><a href="#Snowflake" class="headerlink" title="Snowflake"></a>Snowflake</h1><p><a href="https://dl.acm.org/doi/pdf/10.1145/2882903.2903741" target="_blank" rel="noopener">https://dl.acm.org/doi/pdf/10.1145/2882903.2903741</a></p><h2 id="ABSTRACT-1"><a href="#ABSTRACT-1" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>这里强调就是性价比高，性价比高的原因是弹性做得更好，比如使用了 serverless 的架构。另外，snowflake 也更云原生。</p><h2 id="INTRODUCTION-2"><a href="#INTRODUCTION-2" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>现在平台变了，上云了。上云主要就是 scalability 和 availablility 和 pay-as-you-go 的 cost model。</p><p>不仅平台变了，数据也变了。现在数据更加 schema-less 或者 semi-structured。</p><p>Hadoop 或者 Spark 这样的大数据平台缺少 much of the efficientcy and feature set of established data warehousing technology。</p><ol><li>Pure Software-as-a-Service (SaaS) Experience</li><li>Relational</li><li>Semi-structured 提供一些内置的函数和 SQL 扩展，方便对 semi-structured 的数据进行遍历、flattening、nesting。支持 JSON 和 Avro。列存以及 automatic schema discovery 的技术让这样的数据也能和关系数据一样处理起来很快。</li><li>Elastic</li><li>Highly Available</li><li>Durable</li><li>Cost-efficient</li><li>Secure</li></ol><p>SNowflake 在 AWS 上运行，但是也能够被 port 到其他的平台上。</p><h2 id="STORAGE-VERSUS-COMPUTE"><a href="#STORAGE-VERSUS-COMPUTE" class="headerlink" title="STORAGE VERSUS COMPUTE"></a>STORAGE VERSUS COMPUTE</h2><p>Share-nothing 系统能够成为主流的数仓，主要是因为 scalability 以及 commodity hardware。在这种架构下，每一个 query processor 都有自己的本地磁盘。表被水平 partition。这样的架构对 star-schema 的查询是比较好的，因为 very little bandwidth is required to join a small (broadcast) dimension table with a large (partitioned) fact table. 因为共享数据结构或者硬件之间的竞争很少，所以不需要很昂贵的硬件。</p><p>Snowflake 认为纯粹的 shared-nothing 架构将存储和计算绑定在一起，从而导致问题，场景有：</p><ol><li>Heterogeneous Workload<br> bulk loading 是高 IO 带宽，低 CPU 开销；相比复杂查询是 CPU 需求高的。这样的异构负载，但是我们的节点又是同构的。</li><li>Membership Changes<br> 这里主要负担是要 shuffle 一堆数据。<br> 可以通过 replication 来缓解这个问题。</li><li>Online Upgrade</li></ol><p>然后，云上环境这三点都是很正常的。</p><p>出于上述考虑，Snowflake 进行了存算分离。Compute 是专有硬件的 shared-nothing 架构的引擎。Storage 是在 S3 上提供的，虽然实际上任何 blob 存储都是满足要求的。为了减少网络传输，Compute node 会在本地磁盘上存储一些表的数据。</p><p>Snowflake 将这种架构称为 multi-cluster、shared-data 架构。</p><h2 id="ARCHITECTURE"><a href="#ARCHITECTURE" class="headerlink" title="ARCHITECTURE"></a>ARCHITECTURE</h2><p>Snowflake 的三层架构：</p><ol><li>Data Storage</li><li>Virtual Warehouses</li><li>Clous Services</li></ol><p><img src="/img/dbpaper/snowflake/f1.png"></p><h3 id="Data-Storage"><a href="#Data-Storage" class="headerlink" title="Data Storage"></a>Data Storage</h3><p>选择 AWS 的原因：</p><ol><li>AWS 最成熟</li><li>AWS 上的潜在用户最多</li></ol><p>第二个选择是直接使用 S3 还是用一个自己基于 HDFS 研发的自有存储服务。Snowflake 的经验是，S3 的性能会变动，但是可用性、以及 durability 是很强的。所以选择 S3，然后主要精力用来研究 VW layer 中的 local caching 和 skew resilience 技术。</p><p>S3 相比本地磁盘，延迟是高很多的，并且每一个 IO 请求的 CPU 开销也大很多，特别是使用 HTTPS 请求。但最关键的是，S3 上文件只能够被 write/overwrite in full。我们甚至无法在一个文件末尾去 append 数据。实际上我们需要在 PUT 的时候，就声明文件的大小。BTW，S3 支持读文件的一部分。</p><p>一张表被分成很多个不可变的大文件。每个文件使用 PAX 格式存储。每个表文件中包含一个 header，记录了文件中每个 column 的 offset。所以只需要下载 metadata，以及感兴趣的 columns。</p><p>Snowflake 也是用 S3 存储被 query operator 生成的临时文件，比如和 join 相关的临时结果。当然，一般这发生在本地磁盘被耗尽的情况。这样，就能处理 OOM 或者 out of disk 的情况。</p><p>Metadata，这里值 catalog 对象、事务日志、锁等，被存放在一个 KVStore 里面。这个 KVStore 属于最上层的 Cloud Service。</p><h3 id="Virtual-Warehouses"><a href="#Virtual-Warehouses" class="headerlink" title="Virtual Warehouses"></a>Virtual Warehouses</h3><p>这一层中是 EC2 集群。它们会以一个 virtual warehouse 即 VW 的抽象的方式暴露给单个用户。VW 中的单个 EC2 节点成为 worker node。用户并不会直接和 worker node 交互，也不关心 VW 具体实现的细节。实际上，会像 AWS 一样提供不同型号的 VW 的抽象供用户选择。这部分的设计实际上很 cloud native。</p><h4 id="Elasticity-and-Isolation"><a href="#Elasticity-and-Isolation" class="headerlink" title="Elasticity and Isolation"></a>Elasticity and Isolation</h4><p>在没有查询的时候，用户可以关闭所有的 VW。单个查询运行在单个 VW 上面，worker node 也不会跨 VW 共享。从好的方面来讲，这导致每个查询的 performance isolation 很好。从坏的方面来讲，利用率可能就不高了。</p><p>所以当一个新的查询被提交的时候，VW 中的全部，或者部分（如果查询比较小的话）work nodes 会各自创建一个全新的 worker process。每个 worker process 的生命周期是整个 query。</p><p>每个用户可能同时有多个 VW 在运行，每个 VW 也可能运行多个并发的查询。每个 VW 都访问同一份 shared tables。</p><blockquote><p>Shared, infinite storage means users can share and integrate all their data, one of the core principles of data warehousing.</p></blockquote><blockquote><p>Another important observation related to elasticity is that it is often possible to achieve much better performance for roughly the same price. For example, a data load which takes 15 hours on a system with 4 nodes might take only 2 hours with 32 nodes</p></blockquote><h4 id="Local-Caching-and-File-Stealing"><a href="#Local-Caching-and-File-Stealing" class="headerlink" title="Local Caching and File Stealing"></a>Local Caching and File Stealing</h4><p>每个 worker node 会在本地磁盘上存储 S3 的一些表文件的元数据，以及一些需要用到的列。这个 cache 的生命周期和 worker node 一致，并且被上面的多个 concurrent 或者 subsequent 的 worker process 共享。有一个 LRU 策略用来 evict 这些 cache。</p><p>进一步，每个查询会对需要读的表的 table id 做一致性哈希，这样访问相同表的查询都会集中到相同 worker node 上，从而减少冗余的 cache。</p><p>一致性哈希是 lazy 进行的，也就是说，当 worker nodes 配置变更时，data 不会立即被 shuffle。相反地，Snowflake 借助于 LRU cache 去最终替换 cache 的内容。这摊还掉了 the cost of replacing cache contents over multiple queries. </p><p>【Q】这里 TiFlash 是通过 Region 信息找到存有副本的实例，从而去读取对应实例的 S3 来解决问题的。</p><p>此外，还需要解决 skew 的问题，也就是一些节点会运行地显著比其他节点慢。所以有一个 file stealing 策略，当一个节点完成自己的任务后，它会尝试向它的 peer 去请求额外的文件。它会直接从 S3 下载文件，以避免给那个 peer 带来额外的进一步的负担。</p><h4 id="Execution-Engine"><a href="#Execution-Engine" class="headerlink" title="Execution Engine"></a>Execution Engine</h4><p>首先，如果能用 10 个 node 跑完的任务，就不需要用 1000 个 node 来跑了。所以尽管 scalability 很重要，但是每个节点本身的效率也是很重要的。</p><p>Snowflake 的执行引擎是 Columnar、Vectorized、Push-based 的。Vectorized 这里指的也是 late materialzation。</p><p>一些传统事务中存在的问题，在 Snowflake 中不需要处理。</p><ul><li>首先，执行的时候不需要处理事务管理，因为查询只会读取一些列不可变的文件。</li><li>然后，没有 buffer pool。因为大部分查询会扫描大量的数据。在内存中 cache 这些结果是一个很不好的实践。<br>  【Q】但是 Cache 所需要的列，特别是解压后的结果，以避免重复解压的开销是很重要的。</li></ul><h3 id="Cloud-Services"><a href="#Cloud-Services" class="headerlink" title="Cloud Services"></a>Cloud Services</h3><p>VW 是 ephemeral 的，用户特定的资源。但是 Cloud Service 层是 multi tenant 的。这一层中有 access control、query optimizer、transaction manager 以及其他的服务，它们都是常驻的，并且被所有用户共同分享。多租户能够有效地提升利用率。</p><h4 id="Query-Management-and-Optimization"><a href="#Query-Management-and-Optimization" class="headerlink" title="Query Management and Optimization"></a>Query Management and Optimization</h4><h4 id="Concurrency-Control"><a href="#Concurrency-Control" class="headerlink" title="Concurrency Control"></a>Concurrency Control</h4><p>也是基于 SI 的 ACID 事务模型。在 SI 下，所有的读看到的是事务开始的时候的一致性视图。SI 基于 MVCC 实现。MVCC 也是因为基于 S3 后，文件都得是 immutable 的。</p><h4 id="Pruning"><a href="#Pruning" class="headerlink" title="Pruning"></a>Pruning</h4><p>这里将如何做到只扫描需要的一部分数据。传统数据库中，通常使用索引做到这一点。Snowflake 不是很适合的原因是：</p><ol><li>索引很依赖随机访问，对于压缩的格式，以及 S3，都不是很友好。</li><li>维护一个索引，会增加数据的大小，以及数据被加载的时间。</li><li>用户需要显式创建索引，这个和 Snowflake 的设计精神不是很契合。</li></ol><p>一个替代的做法是 min-max 索引，也被称为 small materialized aggregates、zone maps 或者 data skipping。这个方案是对于每个 chunk，都记录了它上面的最大值和最小值。</p><p>Snowflake keeps pruning-related metadata for every individual table file. The metadata not only covers plain relational columns, but also a selection of auto-detected columns inside of semi-structured data, see Section 4.3.2.</p><p>The optimizer performs pruning not only for simple base-value predicates, but also for more complex expressions such as WEEKDAY(orderdate) IN (6, 7).</p><p>Besides this static pruning, Snowflake also performs dynamic pruning during execution. For example, as part of hash join processing, Snowflake collects statistics on the distribution of join keys in the build-side records. This information is then pushed to the probe side and used to filter and possibly skip entire files on the probe side. This is in addition to other well-known techniques such as bloom joins.</p><h2 id="FEATURE-HIGHLIGHTS"><a href="#FEATURE-HIGHLIGHTS" class="headerlink" title="FEATURE HIGHLIGHTS"></a>FEATURE HIGHLIGHTS</h2><h3 id="Pure-Software-as-a-Service-Experience"><a href="#Pure-Software-as-a-Service-Experience" class="headerlink" title="Pure Software-as-a-Service Experience"></a>Pure Software-as-a-Service Experience</h3><h3 id="Continuous-Availability"><a href="#Continuous-Availability" class="headerlink" title="Continuous Availability"></a>Continuous Availability</h3><h4 id="Fault-Resilience"><a href="#Fault-Resilience" class="headerlink" title="Fault Resilience"></a>Fault Resilience</h4><h4 id="Online-Upgrade"><a href="#Online-Upgrade" class="headerlink" title="Online Upgrade"></a>Online Upgrade</h4><h3 id="Semi-Structured-and-Schema-Less-Data"><a href="#Semi-Structured-and-Schema-Less-Data" class="headerlink" title="Semi-Structured and Schema-Less Data"></a>Semi-Structured and Schema-Less Data</h3><p>支持 VARIANT 类型。从而实现 “schema later” 模式：相比于 ETL，它把这个叫做 ELT。也就是在加载输入的时候，并不需要指定 schema，无论是从 JSON、Avro 还是 XML 格式去加载。</p><p>ELT 的好处是，如果后续数据需要被转换，就可以利用这个数据库本身来执行。Snowflake 支持基于 js 去定义 UDF。</p><h4 id="Post-relational-Operations"><a href="#Post-relational-Operations" class="headerlink" title="Post-relational Operations"></a>Post-relational Operations</h4><h4 id="Columnar-Storage-and-Processing"><a href="#Columnar-Storage-and-Processing" class="headerlink" title="Columnar Storage and Processing"></a>Columnar Storage and Processing</h4><p>As mentioned in Section 3.1, Snowflake stores data in a hybrid columnar format. When storing semi-structured data, the system automatically performs statistical analysis of the collection of documents within a single table file, to perform automatic type inference and to determine which (typed) paths are frequently common. <strong>The corresponding columns are then removed from the documents and stored separately, using the same compressed columnar format as native relational data.</strong> For these columns, Snowflake even computes materialized aggregates for use by pruning (cf. Section 3.3.3), as with plain relational data.</p><h4 id="Optimistic-Conversion"><a href="#Optimistic-Conversion" class="headerlink" title="Optimistic Conversion"></a>Optimistic Conversion</h4><p>有一些 native 的 SQL 类型，例如时间日期会在外部格式，比如 JSON 或者 XML 中以字符串的形式保存。这些值会在 write 或者 read 的时候，被重新转换成实际的类型。</p><p>如果在 read 的时候进行转换，通常会花费很多 CPU。此外，这会导致之前说的 pruning 无法执行，这特别是对日期类型。</p><p>但是在 write 的时候进行转换，会丢失信息。例如，<code>00000000010</code> 不一定表示 10，他也可能就是一个有很多前导 0 的字符串。或者，一个像日期的数实际上是电话号码。</p><p>Snowflake 会使用乐观转换的办法。也就是同时保留转换后的列，以及转换前的列。因为在读取的时候，要么读转换后的，要么读转换前的，所以不会有读两次的开销。</p><h4 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h4><h3 id="Time-Travel-and-Cloning"><a href="#Time-Travel-and-Cloning" class="headerlink" title="Time Travel and Cloning"></a>Time Travel and Cloning</h3><p>CLONE 操作就是类似于 COW 一样。</p><h3 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h3>]]></content>
    
    
    <summary type="html">&lt;p&gt;这篇文章中，包含 Fast scans on key-value stores、PebblesDB、Snowflake。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>羽毛球训练纪实</title>
    <link href="http://www.calvinneo.com/2024/11/22/badminton/"/>
    <id>http://www.calvinneo.com/2024/11/22/badminton/</id>
    <published>2024-11-22T15:07:22.000Z</published>
    <updated>2024-12-29T15:06:28.345Z</updated>
    
    <content type="html"><![CDATA[<p>记录一下一些要点</p><a id="more"></a><h1 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h1><p>主要是两点：</p><ol><li>转腰</li><li>架拍</li></ol><p>击球时先转腰，后架拍，手腕不能进一步引拍了，否则击球会不稳定。我的坏习惯是手腕进一步引拍，以增加击球力量。</p><h1 id="Day-2"><a href="#Day-2" class="headerlink" title="Day 2"></a>Day 2</h1><p>教练认为，在击球转腰的过程中，手臂不一定要完全转过来，从而贴近耳朵。这么训练的目的是增加转腰的意识。</p><p>教练认为，在跑动的时候，也要注意架拍的三点一线。否则这会导致击球的不稳定。</p><p>我觉得这里高远球最重要的还是练习转腰挥拍的连贯性。过早过晚会导致击球动作变形。也会导致击球点偏下。转腰的时候，一定要将身体完全转过来。</p><h1 id="Day-3"><a href="#Day-3" class="headerlink" title="Day 3"></a>Day 3</h1><p>几点：</p><ol><li>在击球的时候，左脚往后扭，可能是因为侧身不到位。</li><li>挥拍的时候小臂不要僵硬，而是要发力。</li><li>击球完之后，要有回收的动作。</li><li>握住球拍的时候，不能松。在击球的瞬间，需要发力。</li><li>如果是高远球，击球的位置不能太过往下压。</li><li>侧身时，从水平线上来看，左脚相比右脚要靠后，不然就转不正。</li></ol><h1 id="Day-4"><a href="#Day-4" class="headerlink" title="Day 4"></a>Day 4</h1><p>继续纠正发力时候大臂僵硬的问题。主要是：</p><ol><li>小臂在接触球的时候，需要发力。这个发力的时机比较重要，如果击球时机准确，会有很清脆的声音。</li><li>在挥拍的时候，大臂不要僵硬。比如抡大臂，将大臂甩出去，肩膀也跟着往前冲，然后头往前栽的那种感觉。</li></ol><p>介绍了一个保护膝盖的方式，也就是并腿半蹲屁股贴着墙站。</p><h1 id="Day-5"><a href="#Day-5" class="headerlink" title="Day 5"></a>Day 5</h1><p>介绍了一个跳步的击球方式：</p><ul><li>重心需要在右脚单脚上（实际上可以直接单脚站立）。</li><li>通过转髋来实现跳跃。</li><li>左脚先落地，右脚再落地，脚尖要朝前。</li></ul><p>注意，不能是扫堂腿，而应该有个跨步的动作，先左脚落地，后右脚逻辑。整个击球过程是在空中和转髋同步完成的。</p><p>通过跳步，可以实现一个新的步伐。在跳步后，右脚是朝前的，中心也在右脚而不是左脚。此时可以朝前垫一步走。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录一下一些要点&lt;/p&gt;</summary>
    
    
    
    
    <category term="运动" scheme="http://www.calvinneo.com/tags/运动/"/>
    
  </entry>
  
  <entry>
    <title>CPU Profiling 经验之谈</title>
    <link href="http://www.calvinneo.com/2024/11/21/cpu-profiling/"/>
    <id>http://www.calvinneo.com/2024/11/21/cpu-profiling/</id>
    <published>2024-11-21T15:07:22.000Z</published>
    <updated>2024-12-24T17:09:29.716Z</updated>
    
    <content type="html"><![CDATA[<p>记录了自己在执行 CPU Profiling 的时候遇到的一些经验。</p><p>相关文章：</p><ol><li><a href="/2024/08/23/monitor-alloc-in-C++/">heap profiling</a></li></ol><a id="more"></a><h1 id="Profiling-基础"><a href="#Profiling-基础" class="headerlink" title="Profiling 基础"></a>Profiling 基础</h1><p>首先，<a href="/2023/12/17/patmc/">Performance analysis and tuning on modern CPUs</a> 这本书是值得阅读的基础。但是里面讲述的很多内容，我目前还没有机会完全实践。</p><h1 id="关于线程池"><a href="#关于线程池" class="headerlink" title="关于线程池"></a>关于线程池</h1><h2 id="记录线程名"><a href="#记录线程名" class="headerlink" title="记录线程名"></a>记录线程名</h2><p>有一些方法设置线程名，包括：</p><ol><li>pthread_setname_np</li><li>prctl</li></ol><p>出于下列原因，建议线程名具有唯一性：</p><ol><li>诸如一些线程池的实际工作内容不一样，最好以数字区分。</li><li>有一些库会扩展 std::mutex，记录上锁的线程名，用来避免重复加锁。当然这个并不好，最好用线程 id。</li></ol><p>在一些很老的 C 库中，没有提供 pthread_setname_np 函数。CK 会写一个 dummy 的函数来替换，这可能导致<a href="https://github.com/pingcap/tiflash/issues/6616" target="_blank" rel="noopener">一些情况下</a>不能设置成功线程名。</p><h2 id="线程名的切换问题"><a href="#线程名的切换问题" class="headerlink" title="线程名的切换问题"></a>线程名的切换问题</h2><p>一些程序会同时记录所有线程的 CPU 用量，以及当前进程的 CPU 总用量。这两个是一致的么？至少在一个使用线程池的程序中，未必一致。</p><p>这里的原因是线程池中往往会将线程按照 <code>${task_name}_${task_id}</code> 这样重新命名，从而区分用途。而处于避免线程启动和销毁的开销，又倾向于维护一个全局常驻线程池，新开辟的线程池会先尝试从这个全局线程池中取，然后用完之后再归还。这就导致如果在这个过程中线程名字发生了从 A 到 B 的变换，则可能会看到 B 对应的指标有一个很高的 delta（比如在 grafana 中能看到一个尖峰）。原因是 <code>/proc/$pid/stat</code> 或者 <code>/proc/tasks/$tid/stat</code> 里面的信息都是从启动开始经历的时钟周期，无论是 stime 还是 utime。所以，如果一开始线程名是 A，后来被某个线程池借走了，名字变成 B，但此时 A 的数据还在。如果此时，线程被归还了，名字改为 A，那么 A 的变化率就是这段时间的 jiffies 增量除以这段时间的长度。</p><h1 id="On-CPU-和-Off-CPU-time"><a href="#On-CPU-和-Off-CPU-time" class="headerlink" title="On CPU 和 Off CPU time"></a>On CPU 和 Off CPU time</h1><p>off-CPU 例如在等待阻塞 IO、锁、page swap 等的时间。这些时间不会通过普通的火焰图被反映出来，但却是影响读取性能的一个因素。我们常常要回答问题，为什么 CPU 没有被用满，但是查询依然比较慢。</p><h2 id="使用-perf-probe-记录函数调用耗时"><a href="#使用-perf-probe-记录函数调用耗时" class="headerlink" title="使用 perf probe 记录函数调用耗时"></a>使用 perf probe 记录函数调用耗时</h2><p>该方案整理自某同事的 idea。</p><p>考虑下面的场景，我们需要查看某动态链接库 <code>/path/to/libtiflash_proxy.so</code> 中 <code>handle_pending_applies</code> 函数每次调用的耗时。此时，可以借助 <code>perf probe</code> 去打点 <code>$tok</code> 和 <code>$tok%return</code>，它们分别对应函数入口和函数出口。这里需要借助于一个 while 循环是因为函数可能有多个重载。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">perf probe --del <span class="string">'probe_libtiflash_proxy:*'</span></span><br><span class="line">BIN=/path/to/libtiflash_proxy.so</span><br><span class="line">TOKEN=handle_pending_applies</span><br><span class="line">ITER=0</span><br><span class="line">objdump <span class="variable">$BIN</span> --syms | grep <span class="variable">$TOKEN</span> | awk <span class="string">'&#123;print $6&#125;'</span> | <span class="keyword">while</span> <span class="built_in">read</span> -r tok ; <span class="keyword">do</span></span><br><span class="line">    ITER=$(expr <span class="variable">$ITER</span> + 1)</span><br><span class="line">    NAME=<span class="variable">$TOKEN</span>\_<span class="variable">$ITER</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$NAME</span>, <span class="variable">$TOKEN</span>, <span class="variable">$ITER</span>, <span class="variable">$TOKEN</span>\_<span class="variable">$ITER</span></span><br><span class="line">    perf probe -x <span class="variable">$BIN</span> --no-demangle <span class="variable">$NAME</span>=<span class="variable">$tok</span></span><br><span class="line">    perf probe -x <span class="variable">$BIN</span> --no-demangle <span class="variable">$NAME</span>=<span class="variable">$tok</span>%<span class="built_in">return</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">perf record -e probe_libtiflash_proxy:\* -aR sleep 10</span><br><span class="line">perf script -s perf-script.py</span><br></pre></td></tr></table></figure><p><a href="/asset/highconcurrency/perf-script.py">附上 perf-script.py</a></p><h1 id="关于-benchmark"><a href="#关于-benchmark" class="headerlink" title="关于 benchmark"></a>关于 benchmark</h1><h2 id="pitfall"><a href="#pitfall" class="headerlink" title="pitfall"></a>pitfall</h2><ul><li>需要多次运行</li><li>需要预热，加载缓存<br>  通常可以使用启发式的方法，等待性能收敛。</li><li>使用高精度时钟</li><li>监控系统负载</li><li>避免编译器优化</li><li>缓存影响</li><li>考虑动态内存分配如 new 或者 delete 对 benchmark 的影响，必要时使用预分配内存池</li></ul><h2 id="google-benchmark"><a href="#google-benchmark" class="headerlink" title="google benchmark"></a>google benchmark</h2><h1 id="关于死锁"><a href="#关于死锁" class="headerlink" title="关于死锁"></a>关于死锁</h1><h2 id="寻找死锁的原因"><a href="#寻找死锁的原因" class="headerlink" title="寻找死锁的原因"></a>寻找死锁的原因</h2><p>通过 gdb 可以找到对应 mutex 结构中的 owner，对应的值表示 LWP 的编号。<br>对于一些程序，可能 debug info 被优化掉了，<a href="https://stackoverflow.com/questions/76489792/how-to-identify-which-thread-holds-the-stdrecursive-mutex-by-gdb" target="_blank" rel="noopener">此时可以选择</a>：</p><ol><li>根据提示的行号，拷贝一份对应的源码到指定位置</li><li>自己编译一个同样 layout 的对象，然后 load 进去解析</li></ol><h1 id="一些工具"><a href="#一些工具" class="headerlink" title="一些工具"></a>一些工具</h1><h2 id="pstack"><a href="#pstack" class="headerlink" title="pstack"></a>pstack</h2><p>可以通过 <a href="https://gist.github.com/JaySon-Huang/e374da1fafa41a3fa30a24e135c60825" target="_blank" rel="noopener">https://gist.github.com/JaySon-Huang/e374da1fafa41a3fa30a24e135c60825</a> 去合并相同的堆栈。</p><p>如果 pstack 没有安装，可以借助于 GDB 的 <code>thread apply all bt</code> 命令。但这个命令会对屏幕输入一堆字符，不是很好看。因此可以</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set logging file mylog.txt</span><br><span class="line">set logging on</span><br></pre></td></tr></table></figure><p>或者使用命令行直接输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gdb -ex <span class="string">"thread apply all bt"</span> -batch -p <span class="variable">$PID</span></span><br></pre></td></tr></table></figure><h2 id="uprobe"><a href="#uprobe" class="headerlink" title="uprobe"></a>uprobe</h2><h2 id="func-latency-工具"><a href="#func-latency-工具" class="headerlink" title="func_latency 工具"></a>func_latency 工具</h2><p>这也是 bcc 套装里面的一个工具。</p><h2 id="PT-PERF-技术"><a href="#PT-PERF-技术" class="headerlink" title="PT_PERF 技术"></a>PT_PERF 技术</h2><p>主要是看 <a href="http://mysql.taobao.org/monthly/2024/04/02/" target="_blank" rel="noopener">mysql 内核月报</a> 和<a href="http://mysql.taobao.org/monthly/2024/04/03/" target="_blank" rel="noopener">续集</a>学的，它还给了一个<a href="http://mysql.taobao.org/monthly/2024/07/04/" target="_blank" rel="noopener">应用场景</a>。<br>这个工具的原理是 Intel CPU 的一个 Processor Trace 技术。主要特点是开销小。它记录程序控制流，特别是 branch 跳转的信息。</p><p>这个工具可以：</p><ol><li>跟踪某个函数在历史时间中执行时间的分布情况。</li><li>跟踪该函数所有子函数的执行情况，包含各自花了多久，占比如何。</li><li>跟踪 Off-CPU，参数 -o。</li><li>通过 –history=1 记录，拷贝数据到另一台机器上通过 –history=2 分析。</li><li>通过 <code>-a do_command#67108864,134217727</code> 指定对应父函数以及耗时范围，从而精准定位子函数存在的问题。</li></ol><p>需要：</p><ol><li>修改 perf_event_mlock_kb 支持更大的 trace buffer，减少 trace 数据丢失。</li><li>修改 kptr_restrict 支持追踪内核函数，如追踪 off-cpu 分析需要的 schedule 内核函数。</li></ol><p>此外对 Linux 版本也有依赖。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录了自己在执行 CPU Profiling 的时候遇到的一些经验。&lt;/p&gt;
&lt;p&gt;相关文章：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;/2024/08/23/monitor-alloc-in-C++/&quot;&gt;heap profiling&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    
    <category term="profiling" scheme="http://www.calvinneo.com/tags/profiling/"/>
    
    <category term="CPU" scheme="http://www.calvinneo.com/tags/CPU/"/>
    
    <category term="性能" scheme="http://www.calvinneo.com/tags/性能/"/>
    
    <category term="benchmark" scheme="http://www.calvinneo.com/tags/benchmark/"/>
    
  </entry>
  
  <entry>
    <title>折腾 NAS</title>
    <link href="http://www.calvinneo.com/2024/11/14/on-nas/"/>
    <id>http://www.calvinneo.com/2024/11/14/on-nas/</id>
    <published>2024-11-14T10:07:22.000Z</published>
    <updated>2024-11-14T17:44:20.863Z</updated>
    
    <content type="html"><![CDATA[<p>记录了我折腾 NAS 的相关问题和解决方案。</p><a id="more"></a><h1 id="有线-mesh"><a href="#有线-mesh" class="headerlink" title="有线 mesh"></a>有线 mesh</h1><ol><li>子路由连 lan 口</li><li>关闭 DHCP</li><li>子路由修改 wifi 名字和主路由相同</li></ol><p>在此之后，子路由会重启，然后就无法再次登录子路由的管理界面了。连着子路由，tracert 也不会显示子路由的 ip。</p><p>要做到无缝切换，需要整个过程中 ip 地址是不变的，因此主路由和副路由需要在同一个网段里面。</p><h1 id="外网访问"><a href="#外网访问" class="headerlink" title="外网访问"></a>外网访问</h1><p>为了实现快速的外网访问，有几种思路：</p><ol><li>使用一个服务器转发</li><li>类似 ZeroTier 的 VPN 方案</li><li>直接使用公网 IP</li></ol><p>对于后两种方案，需要：</p><ol><li>首先实现“光猫改桥接”，然后使用路由器拨号。这样，光猫只会负责光信号转电信号，路由器实际上是整个家庭网络的边界了。</li><li>开启路由器的 UPnP 功能。</li></ol><h2 id="ZeroTier"><a href="#ZeroTier" class="headerlink" title="ZeroTier"></a>ZeroTier</h2><h2 id="光猫改桥接"><a href="#光猫改桥接" class="headerlink" title="光猫改桥接"></a>光猫改桥接</h2><p>对于移动来说，路由器拨号的账户是手机号，密码可以打 10086 重置密码。</p><h1 id="全局梯子"><a href="#全局梯子" class="headerlink" title="全局梯子"></a>全局梯子</h1><h2 id="OpenClash"><a href="#OpenClash" class="headerlink" title="OpenClash"></a>OpenClash</h2><p><img src="/img/nas/openclash.r.png"></p><p>下面是第一个配置的截图。总共有 10 张图，修改 url 来查看其他的图。<br><img src="/img/nas/openclash.1.png"></p><p>覆写设置 -&gt; 开发者选项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">. /usr/share/openclash/ruby.sh</span><br><span class="line">. /usr/share/openclash/log.sh</span><br><span class="line">. /lib/functions.sh</span><br><span class="line"></span><br><span class="line"># This script is called by /etc/init.d/openclash</span><br><span class="line"># Add your custom overwrite scripts here, they will be take effict after the OpenClash own srcipts</span><br><span class="line"></span><br><span class="line">LOG_OUT &quot;Tip: Start Running Custom Overwrite Scripts...&quot;</span><br><span class="line">LOGTIME=$(echo $(date &quot;+%Y-%m-%d %H:%M:%S&quot;))</span><br><span class="line">LOG_FILE=&quot;/tmp/openclash.log&quot;</span><br><span class="line">CONFIG_FILE=&quot;$1&quot; #config path</span><br><span class="line"></span><br><span class="line">#Simple Demo:</span><br><span class="line">    #General Demo</span><br><span class="line">    #1--config path</span><br><span class="line">    #2--key name</span><br><span class="line">    #3--value</span><br><span class="line">    #ruby_edit &quot;$CONFIG_FILE&quot; &quot;[&apos;redir-port&apos;]&quot; &quot;7892&quot;</span><br><span class="line">    #ruby_edit &quot;$CONFIG_FILE&quot; &quot;[&apos;secret&apos;]&quot; &quot;123456&quot;</span><br><span class="line">    #ruby_edit &quot;$CONFIG_FILE&quot; &quot;[&apos;dns&apos;][&apos;enable&apos;]&quot; &quot;true&quot;</span><br><span class="line"></span><br><span class="line">    #Hash Demo</span><br><span class="line">    #1--config path</span><br><span class="line">    #2--key name</span><br><span class="line">    #3--hash type value</span><br><span class="line">    ruby_edit &quot;$CONFIG_FILE&quot; &quot;[&apos;experimental&apos;]&quot; &quot;&#123;&apos;sniff-tls-sni&apos;=&gt;true&#125;&quot;</span><br><span class="line">    #ruby_edit &quot;$CONFIG_FILE&quot; &quot;[&apos;sniffer&apos;]&quot; &quot;&#123;&apos;sniffing&apos;=&gt;[&apos;tls&apos;,&apos;http&apos;]&#125;&quot;</span><br><span class="line"></span><br><span class="line">    #Array Demo:</span><br><span class="line">    #1--config path</span><br><span class="line">    #2--key name</span><br><span class="line">    #3--position(start from 0, end with -1)</span><br><span class="line">    #4--value</span><br><span class="line">    #ruby_arr_insert &quot;$CONFIG_FILE&quot; &quot;[&apos;dns&apos;][&apos;nameserver&apos;]&quot; &quot;0&quot; &quot;114.114.114.114&quot;</span><br><span class="line"></span><br><span class="line">    #Array Add From Yaml File Demo:</span><br><span class="line">    #1--config path</span><br><span class="line">    #2--key name</span><br><span class="line">    #3--position(start from 0, end with -1)</span><br><span class="line">    #4--value file path</span><br><span class="line">    #5--value key name in #4 file</span><br><span class="line">    #ruby_arr_add_file &quot;$CONFIG_FILE&quot; &quot;[&apos;dns&apos;][&apos;fallback-filter&apos;][&apos;ipcidr&apos;]&quot; &quot;0&quot; &quot;/etc/openclash/custom/openclash_custom_fallback_filter.yaml&quot; &quot;[&apos;fallback-filter&apos;][&apos;ipcidr&apos;]&quot;</span><br><span class="line"></span><br><span class="line">#Ruby Script Demo:</span><br><span class="line">    #ruby -ryaml -rYAML -I &quot;/usr/share/openclash&quot; -E UTF-8 -e &quot;</span><br><span class="line">    #   begin</span><br><span class="line">    #      Value = YAML.load_file(&apos;$CONFIG_FILE&apos;);</span><br><span class="line">    #   rescue Exception =&gt; e</span><br><span class="line">    #      puts &apos;$&#123;LOGTIME&#125; Error: Load File Failed,【&apos; + e.message + &apos;】&apos;;</span><br><span class="line">    #   end;</span><br><span class="line"></span><br><span class="line">        #General</span><br><span class="line">    #   begin</span><br><span class="line">    #   Thread.new&#123;</span><br><span class="line">    #      Value[&apos;redir-port&apos;]=7892;</span><br><span class="line">    #      Value[&apos;tproxy-port&apos;]=7895;</span><br><span class="line">    #      Value[&apos;port&apos;]=7890;</span><br><span class="line">    #      Value[&apos;socks-port&apos;]=7891;</span><br><span class="line">    #      Value[&apos;mixed-port&apos;]=7893;</span><br><span class="line">    #   &#125;.join;</span><br><span class="line"></span><br><span class="line">    #   rescue Exception =&gt; e</span><br><span class="line">    #      puts &apos;$&#123;LOGTIME&#125; Error: Set General Failed,【&apos; + e.message + &apos;】&apos;;</span><br><span class="line">    #   ensure</span><br><span class="line">    #      File.open(&apos;$CONFIG_FILE&apos;,&apos;w&apos;) &#123;|f| YAML.dump(Value, f)&#125;;</span><br><span class="line">    #   end&quot; 2&gt;/dev/null &gt;&gt; $LOG_FILE</span><br><span class="line"></span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p>注意，和 PS5 相关的要走 DIRECT</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- DOMAIN-SUFFIX,playstation.com,DIRECT</span><br><span class="line">- DOMAIN-SUFFIX,playstation.com.hk,DIRECT</span><br><span class="line">- DOMAIN-SUFFIX,playstation.net,DIRECT</span><br><span class="line">- DOMAIN-SUFFIX,playstationnetwork.com,DIRECT</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录了我折腾 NAS 的相关问题和解决方案。&lt;/p&gt;</summary>
    
    
    
    
    <category term="硬件" scheme="http://www.calvinneo.com/tags/硬件/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 4</title>
    <link href="http://www.calvinneo.com/2024/11/13/database-paper-4/"/>
    <id>http://www.calvinneo.com/2024/11/13/database-paper-4/</id>
    <published>2024-11-13T13:33:22.000Z</published>
    <updated>2024-11-20T17:12:16.352Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章中，包含 Column Stores vs Row Stores、To BLOB or Not To BLOB: Large Object Storage in a Database or a Filesystem?、Cloud Programming Simplified: A Berkeley View on Serverless Computing。</p><a id="more"></a><h1 id="Column-Stores-vs-Row-Stores-How-Different-Are-They-Really"><a href="#Column-Stores-vs-Row-Stores-How-Different-Are-They-Really" class="headerlink" title="Column-Stores vs. Row-Stores: How Different Are They Really?"></a>Column-Stores vs. Row-Stores: How Different Are They Really?</h1><p>主要是说，列存和行存在 query execution level 和 storage level 上的不一样导致了难以用行存模拟列存。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>尝试回答下面这个问题：<br>Are these performance gains due to something fundamental about the way column-oriented DBMSs are internally architected, or would such gains also be possible in a conventional system that used a more column-oriented physical design?</p><p>下面这些技术尝试用在行存上，看能不能让它 as “column-oriented” as possible.</p><ol><li>Vertically partitioning。将表切分成一系列 two-column table，这个 table 由 (table key, attribute) 对们构成。所以只有需要的 column 会被 query 所读取。</li><li>index-only plan。创建一系列的 index，足以覆盖查询中所有被用到的 column。这样就根本不用查下层的行存表了。</li><li>用一系列物化视图，使得每个查询所需要的列，都能够有一个对应的视图，虽然这个方案要用很多的空间，但是对 row store 来说是一个 best case。</li></ol><p>论文应用了这些优化，然后以 CStore 作为基线来对比，使用 SSBM 负载。结果显示，尽管上面的这些方案都在行存中模拟了列存，但是 query processing performance 依然是很差。</p><p>下一个问题是：<br>Which of the many column-database specific optimizations proposed in the literature are most responsible for the significant performance advantage of column-stores over row-stores on warehouse workloads?<br>这里，作者列出了这些 column-database specific optimizations：</p><ol><li>延迟物化。这里还需要和下面的 block iteraton 结合起来。</li><li>Block iteration。这个技术也被称为 vectorized query processing。这里指从一个列中读到的多个 value，以一个 block 的方式从一个 operator 传到另一个。和这个相对应的是类似于 Volcano 一样的 per-tuple iterator。如果 value 是 fixed width 的，它们会被像一个 array 一样被遍历。</li><li>Column-specific 的压缩方式。例如 RLE，with direct operation on compressed data when using late-materialization plans.</li><li>作者自己还提出了一个 invisible join 的优化，能够提升延迟物化中的 join 性能。</li></ol><p>论文通过在 CStore 中移除不同的优化手段，来度量它们的作用。如果压缩可行的话，则压缩能够提供数量级的提升。延迟物化能提升三倍性能。block iteration 以及 invisible join 提升 1.5 倍性能。<br>TiFlash 的延迟物化在 chbenchmark 上除了 q10（特大查询，过滤率较低）之外提升 10% 左右。在 tpc-h 上性能提升不大，因为没有过滤率很高的条件。在 tpc-ds 这种偏向于小表上的复杂 ap 查询上的场景有限。</p><h2 id="STAR-SCHEMA-BENCHMARK"><a href="#STAR-SCHEMA-BENCHMARK" class="headerlink" title="STAR SCHEMA BENCHMARK"></a>STAR SCHEMA BENCHMARK</h2><p>这个 benchmark 是从tpch 上派生出来的。不同于 tpch，它使用了纯粹的教科书级别的星形模型。它的查询比 tpch 要少。选择它主要是因为它比 tpch 更容易实现，所以就不需要修改 CStore 就能跑。<br>Schema：这个 benchmark 只包含一张事实表，也就是 lineorder 表，它合并了 tpch 中的 lineitem 和 orders 表。</p><p><img src="/img/dbpaper/rvsc/1.png"></p><p>Queries：包含了 13 个 query，可以被分为 4 类，或者四个 flight：</p><ol><li>Flight 1 包含 3 个 queries。这些 query 的约束条件是 1 dimension attribute，以及 discount 和 quantity 列。目的是在不同折扣下计算 gain in revenue(EXTENDEDPRICE * DISCOUNT)。</li><li>Flight 2 包含 3 个 query。约束条件是 2 dimension attributes。计算在特定 region 特定 produce class 的 revenue，并且按照 product class 和 year 去 group。</li><li>Flight 3 包含 4 个 query。约束条件是 3 dimention attributes。计算特定区域的特定时间内的 revenue，按照 customernation、supplier nation 和 year 做 group。</li><li>Flight 4 包含 3 个 query。Queries restrict on three dimension columns, and compute profit (REVENUE - SUPPLYCOST) grouped by year, nation, and category for query 1; and for queries 2 and 3, region and category. The LINEORDER selectivities for the three queries are 1.6×10−2 , 4.5×10−3 , and 9.1 × 10−5 , respectively</li></ol><h2 id="ROW-ORIENTED-EXECUTION"><a href="#ROW-ORIENTED-EXECUTION" class="headerlink" title="ROW-ORIENTED EXECUTION"></a>ROW-ORIENTED EXECUTION</h2><h3 id="Vertical-Partitioning"><a href="#Vertical-Partitioning" class="headerlink" title="Vertical Partitioning"></a>Vertical Partitioning</h3><p>在实现时，需要一个措施让属于相同的 row 的 field 能够彼此连接起来。在列存中这是隐式实现的，因为所有的列中的 field 都是按照相同的顺序来存储的。在行存中，一个简单的办法是对每个表中添加一个 position 列。这样每个 column都对应一个 physical 表，第 i 个表有两个 column，第一个是逻辑表中 column i 的值，第二个是 position 列中对应的值。Queries are then rewritten to perform joins on the position attribute when fetching multiple columns from the same relation. In our implementation, by default, System X chose to use hash joins for this purpose, which proved to be expensive. For that reason, we experimented with adding clustered indices on the position column of every table, and forced System X to use index joins, but this did not improve performance – 因为索引引起的额外的 io 导致了它比 hash join 还要慢。</p><h3 id="Index-only-plans"><a href="#Index-only-plans" class="headerlink" title="Index-only plans"></a>Index-only plans</h3><p>Vertical Partitioning 有两个问题。第一个是每个 column 都需要存一个 position 列，浪费空间和磁盘带宽。第二个是大多数行存会为每个 tuple 存一个相对比较大的 header，从而进一步浪费空间。而列存几乎总是将 header 存在各自的 column 中，从而避免类似的开销。【Q】这个 header 是指的为 MVCC 服务的隐藏列么？<br>因此，现在这个设计中，base relation 会被存在一个标准的行存中，但是一个额外的、unclustered 的 B+ 树索引会被加载每个 table 的每个 column 上。<br>Index-only plan 需要数据库的额外的支持。首先对每个表，建立满足 predicate (record-id, value) 对的 list，然后如果在同一个表上有多个 predicate，则需要在内存中 merge 这些 rids-list。当这些 fields 没有 predicate，那么就可以返回这一列中所有的 (record-id, value) 对。可以看到，这样的 plan 并不需要访问磁盘上的真实 tuple。虽然这些 index 能够显式存放 rid，但是它们不会存储一份重复的 value 了。所以，它有 a lower per-tuple overhead than the vertical-partitioning approach，因为 tuple header 并没被存在 index 中。<br>容易发现，这个问题是如果一个 column 上没有 predicate，就需要扫描一遍 index 从而去提取出需要的 value。相比于 vertical partition 的扫 heap file 会更慢一点。【Q】我理解就是这时候要回表，就比较慢。<br>一个优化是建立 composite keys 的索引。例如 <code>SELECT AVG(salary) FROM emp WHERE age &gt; 40</code> 这个 query，如果建立了一个 (age, salary) 上的 composite index，就可以从这个索引中快速回答这个 query。如果我们为 age 和 salary 分别建立了索引，那么 index-only-plan 就需要首先根据 age 的索引找到所有的 record-ids，然后再去和整个 (record-id, salary) 列表去 merge，而这个就需要加载整个 salary 索引，所以就很慢了。<br>We use this optimization in our implementation by storing the primary key of each dimension table as a secondary sort attribute on the indices over the attributes of that dimension table. 这样，就可以有效访问 the primary key values of the dimension that need to be joined with the fact table. </p><h3 id="Materialized-Views"><a href="#Materialized-Views" class="headerlink" title="Materialized Views"></a>Materialized Views</h3><p>对于每个 query flight，狗仔一个 optimal set of materialized view，其中只包含所有需要的 column。我们没有 pre-join columns needed to answer queries in these views。Our objective with this strategy is to allow System X to access just the data it needs from disk, avoiding the overheads of explicitly storing record-id or positions, and storing tuple headers just once per tuple. 因此，我们期望它比其他两个方式表现更好，尽管它要求 query 的 workload 需要被提前知道。</p><h2 id="COLUMN-ORIENTED-EXECUTION"><a href="#COLUMN-ORIENTED-EXECUTION" class="headerlink" title="COLUMN-ORIENTED EXECUTION"></a>COLUMN-ORIENTED EXECUTION</h2><h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><p>压缩实际上减少了磁盘使用，但是磁盘是越来越便宜的。但是，它还能提高性能。原因是如果数据变小了，那么通过 IO 从磁盘上读取这些数据的时间也就变少了。因此，在更高的压缩率和更快的解压速度之间是一个权衡。</p><p>特别地，如果能够在压缩的数据上直接执行计算，就可以避免解压。比如，RLE 这种将重复的 value 替换为 count 和 value 的做法。</p><p>Prior work [4] concludes that the biggest difference between compression in a row-store and compression in a column-store are the cases where a column is sorted (or secondarily sorted) and there are consecutive repeats of the same value in a column. In a columnstore, it is extremely easy to summarize these value repeats and operate directly on this summary. In a row-store, the surrounding data from other attributes significantly complicates this process. Thus, in general, compression will have a larger impact on query performance if a high percentage of the columns accessed by that query have some level of order.</p><h3 id="延迟物化"><a href="#延迟物化" class="headerlink" title="延迟物化"></a>延迟物化</h3><p>优势：</p><ol><li>select 和 aggregation operator 可以不去构造某些元组。如果 executor 能在构造一个 tuple 时等待足够长的时间，就可以完全避免去构造。</li><li>如果数据被压缩，就需要在和其他 column 组合之前被解压。这样就失去了直接操作压缩数据的优势。</li><li>Cache 利用率提高了。显然，我们可以不用加载一堆东西，从而污染 Cache。</li><li>后面的 Block iteration 优化对于定长的 attribute 的优化性能更强。row store 中，只要有一个 attribute 是变长的，那么整个 tuple 就是变长的，但是在 column store 中，列是单独存放的。</li></ol><h3 id="Block-Iteration"><a href="#Block-Iteration" class="headerlink" title="Block Iteration"></a>Block Iteration</h3><p>为了处理一系列的 tuple，行存首先要遍历每个 tuple，然后提取需要的 attribute。这个提取通常需要几次函数调用。</p><p>在列存中，同一个 column 的 block 会被发送给一个 operator，所以就是一次函数调用。另外，也不需要提取 attribute 了。如果 column 是定长的，就可以以 array 的形式去遍历它。array 的形式还能实现并行处理，比如 loop-pipelining 技术。</p><h3 id="Invisible-Join"><a href="#Invisible-Join" class="headerlink" title="Invisible Join"></a>Invisible Join</h3><p>星型 schema 的 query 通常有如下的结构：通过一个或者多个 dimension table 上的 selection predicate 作为 fact table 上的约束条件。然后基于这个受约束的事实表上做一些聚合，通常是和其他的 dimention table 上的一些 attribute 去 group by。<br>因此，对于每个 selection predicate 以及每个 aggregate group 都需要执行一次 fact table 和 dimension table 的 join。<br>下面的 query 就是一个典型。传统的 plan 是 pipeline joins in order of predicate selectively。例如，如果 <code>c.region = &#39;ASIA&#39;</code> 是最 selective 的 predicate，那么根据 custkey 去 join lineorder 和 customer 两个表就会被首先执行，这样就会过滤 lineorder 表，从而只有在 ASIA 的客户留下来。在这个 join 完成后，customer 的 nation 就会被加入到这个 join 后的 customer-order 中间表中。These results are pipelined into a join with the supplier table where the <code>s.region = &#39;ASIA&#39;</code> predicate is applied and <code>s.nation</code> extracted, followed by a join with the data table and the year predicate applied. The results of these joins are then grouped and aggregated and the results sorted according to the ORDER BY clause</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> c.nation, s.nation, d.year,</span><br><span class="line">    <span class="keyword">sum</span>(lo.revenue) <span class="keyword">as</span> revenue</span><br><span class="line"><span class="keyword">FROM</span> customer <span class="keyword">AS</span> c, lineorder <span class="keyword">AS</span> lo,</span><br><span class="line">    supplier <span class="keyword">AS</span> s, dwdate <span class="keyword">AS</span> d</span><br><span class="line"><span class="keyword">WHERE</span> lo.custkey = c.custkey</span><br><span class="line">    <span class="keyword">AND</span> lo.suppkey = s.suppkey</span><br><span class="line">    <span class="keyword">AND</span> lo.orderdate = d.datekey</span><br><span class="line">    <span class="keyword">AND</span> c.region = <span class="string">'ASIA'</span></span><br><span class="line">    <span class="keyword">AND</span> s.region = <span class="string">'ASIA'</span></span><br><span class="line">    <span class="keyword">AND</span> d.year &gt;= <span class="number">1992</span> <span class="keyword">and</span> d.year &lt;= <span class="number">1997</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> c.nation, s.nation, d.year</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> d.year <span class="keyword">asc</span>, revenue <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><p>另一种做法是延迟物化的方法。In this case, a predicate is applied on the <code>c.region</code> column <code>(c.region = &#39;ASIA&#39;),</code> and the customer key of the customer table is extracted at the positions that matched this predicate. These keys are then joined with the customer key column from the fact table. join 的结果是两个 position 的集合，一个是给 fact table 的，一个是给 dimension table 的。它们表示了这两个表中各有那些 tuple 会被传给 join predicate，然后被 join。<br>一般来说，这两个 posision 集合中，最多只有一个是 sorted order，一般会是 outer table，也就是 fact table。Values from the <code>c.nation</code> column at this (out-of-order) set of positions are then extracted, along with values (using the ordered set of positions) from the other fact table columns (supplier key, order date, and revenue). Similar joins are then performed with the supplier and date tables.</p><p>上面两种方案都有缺点。第一种情况，每次 join 都需要构造一堆 tuple。第二种情况，从 dimension table group-by column 中的值是乱序被提取出来的。</p><h1 id="To-BLOB-or-Not-To-BLOB-Large-Object-Storage-in-a-Database-or-a-Filesystem"><a href="#To-BLOB-or-Not-To-BLOB-Large-Object-Storage-in-a-Database-or-a-Filesystem" class="headerlink" title="To BLOB or Not To BLOB: Large Object Storage in a Database or a Filesystem?"></a>To BLOB or Not To BLOB: Large Object Storage in a Database or a Filesystem?</h1><p>这个论文我比较感兴趣，因为不少朋友在选型的时候面临这个问题：BLOB 应该被存在 fs 里面还是 db 里面呢？<br>需要注意到，这是一篇比较早的论文，正如<a href="https://news.ycombinator.com/item?id=14550982" target="_blank" rel="noopener">文章</a>指出的，随着 SSD 的普及，WAL 和 buffer pool 带来的优势减少了，因为 random write 的性能提高了。</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>小于 256KB 的 blob，db 处理起来比较有效率，fs 对 1MB 以上的 blob 有效率。文章认为，最重要的影响因素是 storage age，也就是 deleted objects 对 live objects 的比值。当 storage age 增加时，fragmentation 就会增加。fs 研究能更好处理 fragmentation。研究中还说，只要平均大小是固定的，其分布如何并不显著影响性能。We also found that, in addition to low percentage free space, a low ratio of free space to average object size leads to fragmentation and performance degradation。</p><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="fragmentation"><a href="#fragmentation" class="headerlink" title="fragmentation"></a>fragmentation</h3><p>NTFS文件系统使用基于“band”的分配策略来管理元数据，但对于文件内容则不是。【Q】这里的 band 是不是别的里面的 stripe？<br>NTFS 通过基于运行的查找缓存来为文件流数据分配空间。这些连续的空闲簇会根据大小和卷偏移量以降序排列。NTFS 尝试从外带开始满足新的空间分配请求。如果失败，它会使用空闲空间缓存中的大范围空间。如果这些尝试都失败了，文件就会被分割。此外，当文件被删除时，分配的空间不能立即被重用；必须先提交NTFS事务日志条目，之后释放的空间才能被重新分配。总体行为是文件流数据倾向于在文件内连续分配。</p><p>对于修改一个 existing object，fs 和 db 的处理方式不同。fs 会优化 append、truncate 这个文件。inplace file update 是有效率的，但是如果要在中间插入或者删除，那么就需要重写整个文件。但是对于某些 db 而言，在一个 object 里面增删性能会比较高，如果它们和 database page 是 align 的。如果 db 使用 B 树，那么就允许插入或者删除任意大小的数据，并且它们可以在任意位置。</p><p>应用也可以自己做 fragmentation，比如视频流是 chunked 的。</p><h3 id="Safe-writes"><a href="#Safe-writes" class="headerlink" title="Safe writes"></a>Safe writes</h3><p>大部分文件系统都能够保护内部的元数据结构，比如目录或者文件名。比如当出现系统宕机或者电源故障的时候，文件系统的数据不至于破坏。但是对于文件的内容就没有类似的保证。特别地，文件系统和下层的操作系统会将写入乱序，从而提升性能。只有一些请求能够在一个 dirty shutdown 之后被完成。<br>不少桌面应用程序会选择使用一个叫 safe write 的技术，去保证当从一个 dirty shutdown 重启后，文件的内容要么是旧的，要么是新的，不会在某个中间不一致的状态。这种做法需要完全拷贝一份文件到磁盘中，哪怕大部分的内容没有发生变更。<br>safe write 的实现方法具体来说就是会创建一个临时的文件，然后写入新数据，然后 flush to disk，最后将文件重命名为原来的文件名，这样就可以同时删除掉原文件。这是因为 UNIX 系统中的 rename 是能保证原子性的。</p><p>相比之下，数据库提供了事务机制。应用可以安全的以任何方便的方式去更新数据。根据数据库的实现，相比像文件系统一样重新写入整个文件，只重写一部分更有效率。</p><p>下面是对 WAL 这个策略的介绍，不翻译了。</p><blockquote><p>The database guarantees transactional semantics by logging both metadata and data changes throughout a transaction. Once the appropriate log records have been flushed to disk, the associated changes to the database are guaranteed to complete. The log is written sequentially, and subsequent database updates can be reordered to minimize seeks. Log entries for each change must be written; but the actual database writes can be coalesced – only the last write to each page need actually occur.</p></blockquote><p>这样的坏处是要写两次数据。顺序写 WAL 类似于顺序写文件。在日志中写入的大的对象，可能导致日志需要被更频繁地截断，或者构建 checkpoint，这样 reorder 和 combine 这些 page 修改的机会少了很多。</p><h3 id="Data-centric-web-services"><a href="#Data-centric-web-services" class="headerlink" title="Data centric web services"></a>Data centric web services</h3><p>为了在 fs 和 db 之间能够“公平”对比，所以使用了 SQL Server 的 bulk-logging 模式。这个模式下，提供了事务的持久性。但是类似于 fs，它并不保证 large object 对象在一次 dirty shutdown 之后还是 consistent 的。<br>这里的 db 和 fs 实际上对 metadata 都是提供事务性的更新。会写一次 large object，并且只会写一次。不保证 large object data 是 consistent 的。</p><p>通过复制的方式去修复 corrupt 的数据。</p><h2 id="Prior-Work"><a href="#Prior-Work" class="headerlink" title="Prior Work"></a>Prior Work</h2><h3 id="Data-layout-mechanisms"><a href="#Data-layout-mechanisms" class="headerlink" title="Data layout mechanisms"></a>Data layout mechanisms</h3><p>介绍了一些不同的解决 fragmentation 的方案。</p><p>FFS：fragmentation aboiding allocation 算法对于磁盘占用在 90% 以内的是可以的。UNIX 需要保留一定的空间去做 disaster recovery，以及防止 excess fragmentation。</p><p>NTFS：当磁盘占用超过 75%，就会有一个 defragmentation 机制在跑了。后面会介绍他的一些缺点。</p><p>LFS：一个 log based fs。针对写入性能进行优化，将数据按照写入请求的 chronological order 组织写入到磁盘上。这使得写入时是顺序的，但是会产生严重的 fragmentation，如果文件被随机地进行更新。</p><p>WAFL：可以在传统以及写入优化之间进行切换。WAFL also leverages NVRAM caching for efficiency and provides access to snapshots of older versions of the filesystem contents. Rather than a direct copy-on-write of the data, WAFL metadata remaps the file blocks. A defragmentation utility is supported, but is said not to be needed until disk occupancy exceeds 90+%.</p><p>GFS（应该不是 Google FS）：使用称为 chunck 的 64MB 的块，从而部分解决了 layout 的问题。提供了一个安全的 record append 操作，它允许多个 client 同时往一个文件 append 数据。这减少了产生 fragmentation 的可能。<br>下面是说，GFS 的 record 不会跨越 chunk。如果一个 record 在当前 chunk 放不下了，剩余空间就会被填上 0，然后这个 record 会在一个新的 chunk 的头部开始写入。这会产生很多的 internal fragmentation。</p><blockquote><p>GFS records may not span chunks, which can result in internal fragmentation. If the application attempts to append a record that will not fit into the end of the current chunk, that chunk is zero padded, and the new record is allocated at the beginning of a new chunk. Records are constrained to be less than ¼ the chunk size to prevent excessive internal fragmentation. However, GFS does not explicitly attempt to address fragmentation introduced by the underlying file system, or to reduce internal fragmentation after records are allocated.</p></blockquote><h2 id="Comparing-Files-and-BLOBs"><a href="#Comparing-Files-and-BLOBs" class="headerlink" title="Comparing Files and BLOBs"></a>Comparing Files and BLOBs</h2><h3 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h3><p>7200 转的机械硬盘，SATA 口。比较老旧了。<br><img src="/img/dbpaper/blob-not-blob/1.png"></p><h3 id="File-based-storage"><a href="#File-based-storage" class="headerlink" title="File based storage"></a>File based storage</h3><p>For the filesystem based storage tests, we stored metadata such as object names and replica locations in SQL server tables. Each application object was stored in its own file. The files were placed in a single directory on an otherwise empty NTFS volume. SQL was given a dedicated log and data drive, and the NTFS volume was accessed via an SMB share.</p><p>这里还是用数据库的原因是避免实现复杂的 recovery 机制。</p><h3 id="Database-Storage"><a href="#Database-Storage" class="headerlink" title="Database Storage"></a>Database Storage</h3><p>We also used out-of-row storage for the application data so that the blobs did not decluster the metadata. Although the blob data and table information are stored in the same file group, out-of-row storage places blob data on pages that are distinct from the pages that store the other table fields. This allows the table data to be kept in cache even if the blob data does not fit in main memory.</p><h3 id="Storage-age"><a href="#Storage-age" class="headerlink" title="Storage age"></a>Storage age</h3><p>提出这个 storage age 指标，也就是曾经写入的 bytes 比上现在还在用的 bytes。这个定义的假设是 free space 是相对来说固定的。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="out-of-the-box-场景下的吞吐量"><a href="#out-of-the-box-场景下的吞吐量" class="headerlink" title="out-of-the-box 场景下的吞吐量"></a>out-of-the-box 场景下的吞吐量</h3><p>也就是一开始 bulk load 之后的 read throughput。</p><p><img src="/img/dbpaper/blob-not-blob/2.png"></p><p>写入的 throughput，SQL Server 是优于 NTFS 的。对于 512 KB 的对象，数据库是 17.8 MB/s，NTFS 是 10.1 MB/s。</p><h3 id="跑了一段时间的情况"><a href="#跑了一段时间的情况" class="headerlink" title="跑了一段时间的情况"></a>跑了一段时间的情况</h3><p>这个时候要注意 fragmentation 对性能的影响。</p><p>首先，它说 SQL Server 没有发现和缓解 fragmentation 的方案。文章上说，隔段时间，把数据从老表复制出来到新表，然后再把老表 drop 掉可以实现 fragmentation。</p><p>To measure fragmentation, we tagged each of our objects with a unique identifier and a sequence number at 1KB intervals. We also implemented a utility that looks for the locations of these markers on a raw device in a way that was robust to page headers, and other artifacts of the storage system.</p><p>下图中的 overwrites 也就是 storage age。bulk load 对应的 storage age 就是 0。<br><img src="/img/dbpaper/blob-not-blob/3.png"></p><p>下图展示了，对于非常大的，比如 10MB 的对象，SQL Server 的性能很差，它的 fragments/object 基本上是线性的。NTFS 要好很多。The best-effort attempt to allocate contiguous space actually defragments such volumes. That experiment also suggests that NTFS is indeed approaching an asymptote in Figure 3.<br><img src="/img/dbpaper/blob-not-blob/4.png"></p><p>The degradation in write performance is shown in Figure 4. In both systems, the write throughput during bulk load is much better than read throughput immediately afterward. This is not surprising, as the storage systems can simply append each new file to the end of allocated storage, avoiding seeks during bulk load. On the other hand, the read requests are randomized, and must incur the overhead of at least one seek. 在 bulk load 之后，SQL Server 的写入性能急剧下降，NTFS 的写入性能要比读取性能稍微好点。<br><img src="/img/dbpaper/blob-not-blob/5.png"></p><p>注意，不能直接比较 Figure 1 和 2 里面的写性能和读性能。因为读性能是在 fragmentation 之后度量的，写性能则是在 fragmention 这个过程中度量的平均值。</p><p>下面这个应该写错了。</p><blockquote><p>To be clear, the “storage age four”(应该是 two 吧) write performance is the average write throughput between the read measurements labeled “bulk load” and “storage age two.” Similarly, the reported write performance for storage age four reflects average write performance between storage ages two and four.</p></blockquote><h3 id="Fragmentation-effects-of-object-size-volume-capacity-and-write-request-size"><a href="#Fragmentation-effects-of-object-size-volume-capacity-and-write-request-size" class="headerlink" title="Fragmentation effects of object size, volume capacity, and write request size"></a>Fragmentation effects of object size, volume capacity, and write request size</h3><h1 id="Cloud-Programming-Simplified-A-Berkeley-View-on-Serverless-Computing"><a href="#Cloud-Programming-Simplified-A-Berkeley-View-on-Serverless-Computing" class="headerlink" title="Cloud Programming Simplified: A Berkeley View on Serverless Computing"></a>Cloud Programming Simplified: A Berkeley View on Serverless Computing</h1><p><a href="https://arxiv.org/pdf/1902.03383" target="_blank" rel="noopener">https://arxiv.org/pdf/1902.03383</a></p><h2 id="Emergence-of-Serverless-Computing"><a href="#Emergence-of-Serverless-Computing" class="headerlink" title="Emergence of Serverless Computing"></a>Emergence of Serverless Computing</h2><p><img src="/img/dbpaper/serverless/t2.png"></p><p>相比 serverful，serverless 的改变是</p><ol><li>存算分离。存储和计算被分开提供和计费。存储一般是单独的服务，计算一般是无状态的。</li><li>代码执行不需要手动管理资源分配。用户提供代码，cloud 自动提供资源。</li><li>按使用量计费，而不是按照使用资源的规格计费。</li></ol><h3 id="Contextualizing-Serverless-Computing"><a href="#Contextualizing-Serverless-Computing" class="headerlink" title="Contextualizing Serverless Computing"></a>Contextualizing Serverless Computing</h3><p>例如 CGI 这样的机制，已经有了 stateless programming model，在此之上支持了 multi-tenancy、elastic response to variable demand 和 standardized function invocation API。CGI 甚至允许直接部署源码比如 PHP 来运行。<br>作者认为，现在的 serverless 相比 CGI 这样的古早方案，有三个特点：更好的自动扩缩容、强隔离、platform flexibility、service ecosystem support。</p><p>扩缩容：AWS Lambda 能够缩容到零实例实现零费用。它的计费是 100ms 级别的，而不是之前的小时级别。<br>隔离：VM 是实现高性能安全隔离的方式。AWS Lambda 解决了 VM 启动速度比较慢，支持不了快速弹性扩缩容的问题。它维护了两个 pool，warm pool 中包含的 VM 实例只是被分配给了某个 tenant，而 active pool 中的实例已经实际运行过了，并且一直保持着，以便维护后续的服务请求。还有除了 VM 之外的隔离方案，比如容器、unikernel、library OS 和语言虚拟机。比如一些使用了浏览器的 JavaScript 沙箱技术。</p><p>认为 k8s 并不是 serverless，而是简化了 serverful computing 的技术。k8s 能提供一个短生命周期的计算环境，类似于 serverless computing，但是限制更少，例如在硬件资源、执行时间和网络通信。只需要少量改动，就可以通过 k8s 让专门为 op 涉及的程序运行在云上。相比之下，Serverless 将运维的责任完全推给了服务提供商，然后要实现 fine-grained multi-tenant multiplexing。GKE 和 EKS 应该是介于这两个中间的一个东西，它帮用户运维 k8s，但是容器还是用户来自定义的。K8s 服务和 serverless 服务的区别之一是 billing model。前者为 reserved resource 计费，后者为 per function execution duration 计费。</p><p>K8s 还会是一个 hybrid application 的好选择。也就是一个程序一部分是 op 部署的也就是在本地硬件上，另一部分是 cloud 部署的。</p><h3 id="Attractiveness-of-Serverless-Computing"><a href="#Attractiveness-of-Serverless-Computing" class="headerlink" title="Attractiveness of Serverless Computing"></a>Attractiveness of Serverless Computing</h3><p><img src="/img/dbpaper/serverless/t4.png"></p><h2 id="Limitations-of-Today’s-Serverless-Computing-Platforms"><a href="#Limitations-of-Today’s-Serverless-Computing-Platforms" class="headerlink" title="Limitations of Today’s Serverless Computing Platforms"></a>Limitations of Today’s Serverless Computing Platforms</h2><p>本节选择了五个传统的 serverful 的云计算应用，然后尝试只使用 cloud functions 来实现它们的 serverless 版本。</p><ol><li>ExCamera 实时视频编码。把编码过程中比较慢的并行化，比较快的继续串行化。</li><li>MapReduce 目前一些 Map-only 的任务被移动到 serverless 上。</li><li>Numpywren 线代。一般这样的任务是部署在超算或者高性能计算集群上的。这样的集群需要高速低延迟的网络。serverless 从历史上来讲，不太合适。但是一方面，数据科学家维护大集群很麻烦，另一方面，线代的并发又是波动很厉害的。所以这是 serverless 的机会。</li><li>Cirrus：机器学习训练。传统上使用 VM 集群处理 ML 工作流上面的不同任务，比如预处理、模型训练、参数调节。不同的这些任务所需要的资源是完全不同的。serverless 可以给每个阶段提供合适的容量。</li><li>Serverless SQLite：数据库。首先，serverless 计算没有内置的持久化存储，需要访问远程存储，带来网络开销。其次，client 需要通过网络地址连接数据库，而 serverless 的 cloud function 并没有暴露出网络。最后，很多高性能的数据库是 share-everything 的，比如共享磁盘，共享网络等，但 serverless 基本肯定是不能共享内存的。即使是 share-nothing 数据库，它们也是需要通过网络来互相访问的。</li></ol><p><img src="/img/dbpaper/serverless/22.png"></p><h3 id="Inadequete-storage-for-fine-grained-operations"><a href="#Inadequete-storage-for-fine-grained-operations" class="headerlink" title="Inadequete storage for fine-grained operations"></a>Inadequete storage for fine-grained operations</h3><p>这一章节中列出了目前云服务商提供的一些外部存储服务。</p><p>诸如 AWS S3、Azure Blob Storage 和 Google Cloud Store 这样的 long-term OSS 的访问开销以及延迟会比较大。测试中，读写小对象有 10ms 左右的延迟。</p><p>诸如 DynamoDB、Azure Cosmos 这样的 KV 数据库提供了很高的 IOPS，但是很昂贵，并且 scale up 很耗时间。</p><p>有一些 in-memory 数据库，但是它们没有容灾，也不能 autoscale。</p><p><img src="/img/dbpaper/serverless/t6.png"></p><h3 id="Lack-of-fine-grained-coordination"><a href="#Lack-of-fine-grained-coordination" class="headerlink" title="Lack of fine-grained coordination"></a>Lack of fine-grained coordination</h3><p>为了支持有状态服务，serverless 需要支持两个 task 之间的通信协调。特别是一些需要通信来保证一致性的服务。</p><p>云服务商会有一些比如 SNS 或者 SQS 的 notification 服务，但是它们的延迟很高，并且代价很大。现在的选择是要么使用一个 VM-based system 来提供通知，要不就是自己实现一套通知机制。</p><h3 id="Poor-performance-for-standard-communication-patterns"><a href="#Poor-performance-for-standard-communication-patterns" class="headerlink" title="Poor performance for standard communication patterns"></a>Poor performance for standard communication patterns</h3><p>Broadcast、aggregation 和 shuffle 是分布式系统中的通用原语。下图中比较了三种原语在 VM 以及 cloud function 两个场景下的实现。可以发现，VM-based 场景下的 remote 消息是显著少的。因为很多消息可以是本地的，或者通过其他方式进行共享。</p><p>另外，即使发消息，也可以将消息进行打包，这样两个 VM node 之间实际上只要传递一个消息。</p><p><img src="/img/dbpaper/serverless/yy.png"></p><h3 id="Predictable-Performance"><a href="#Predictable-Performance" class="headerlink" title="Predictable Performance"></a>Predictable Performance</h3><p>尽管 cloud function 的启动时间比 VM 短，但是启动新实例的代价，对于某些 app 来说会更高。三个影响 cold start 延迟的因素：</p><ol><li>启动 cloud function 的时间</li><li>启动 function 的软件环境的时间，比如 python 库的加载</li><li>用户代码中的初始化。</li></ol><p>后两者会拖累第一个。比如可能启动一个 cloud function 就不到一秒，但是加载所有的库要花十秒。</p><p>另外，使用的底层硬件对用户来说是透明的，有的时候，用户可能会被分配到更老的处理器上。这是云服务商在做调度的时候的权衡。</p><h2 id="What-Serverless-Computing-Should-Become"><a href="#What-Serverless-Computing-Should-Become" class="headerlink" title="What Serverless Computing Should Become"></a>What Serverless Computing Should Become</h2><h3 id="Abstraction-challenges"><a href="#Abstraction-challenges" class="headerlink" title="Abstraction challenges"></a>Abstraction challenges</h3><h4 id="Resource-requirements"><a href="#Resource-requirements" class="headerlink" title="Resource requirements"></a>Resource requirements</h4><p>目前可以定制的只是内存大小以及执行时间，但是对于 CPU、GPU 这些资源则不能。允许开发者进一步去指定，增加云服务提供商进行调度的难度。也需要开发者去进一步关注这些事情，这是违背 serverless 的精神的。</p><p>更好的做法是提高抽象程度，让云服务提供商去推断。云服务商可以从静态代码分析，profile 过去的 run，动态编译面向特定平台的代码这些方面去做。</p><p>要精确预计需要多少内存也是很有挑战性的工作。一些想法是整合语言运行时到 serverless 平台上，这样可以去访问这些语言的 GC 模块。</p><h4 id="Data-dependencies"><a href="#Data-dependencies" class="headerlink" title="Data dependencies"></a>Data dependencies</h4><p>很难知道各个 cloud function 在数据上的依赖关系。比如谁是谁的前序，谁依赖谁的结果这样。特别还有很多 cloud function 是 exchange 数据的，这让情况更复杂。</p><p>一种做法是供应商提供一个 API，让用户去提供一个计算图，这样就可以有更好的 placement decision，使得通信变少。</p><h3 id="System-challenges"><a href="#System-challenges" class="headerlink" title="System challenges"></a>System challenges</h3><h4 id="High-performance-affordable-transparently-provisioned-storage"><a href="#High-performance-affordable-transparently-provisioned-storage" class="headerlink" title="High-performance, affordable, transparently provisioned storage"></a>High-performance, affordable, transparently provisioned storage</h4><p>Serverless Ephemeral Storage 和 Serverless Durable Storage。</p><p>Serverless Ephemeral Storage 可以被部署在 in-memory 的分布式服务中，同时需要一个优化的网络。这样就是 microsecond 级别的延迟。还需要能够快速扩缩容。它能够透明地分配，以及释放内存。也就是当 app 挂掉或者正常退出时，它能够自动回收它使用的存储空间（当然是 in-memory）的。</p><p>诸如 RAMCloud 和 FaRM 的缺陷是，需要显式地估算要使用的 storage。他们也不提供租户之间的强资源隔离。Pocket 缺少自动扩缩容，需要预先分配空间。</p><p>可以通过 statistical multiplexing 来节省内存，也就是如果有人用不到这么多内存，就可以先挪过去给别人用了，就是超卖。即使对于同一个 app 也还是有好处的，比如说不同的服务，原来可能是部署在不同的 vm 上的，现在可能就是能运行在一个 vm 上了。当然，serverless 也还是存在 internal fragmentation 的。</p><p>Serverless Durable Storage 主要是通过一个 SSD 的分布式 store，以及一个 in-memory 的 cache 实现的。这个设计的难点是如何在有较高的 tail access distribution 的情况下达到比较低的 tail latency，考虑到内存 cache 的容量比 SSD 的容量实际上要小很多。<br>类似于 Ephemeral Storage 它也需要能够被透明而不是显式地预测内存，并且能够提供跨租户和 app 之间的隔离。不同于 Ephemeral Storage，Durable Storage 只允许显式回收存储，也就是 app 被 terminate 的时候，不应该自动回收 storage。</p><h4 id="Coordination-signaling-service"><a href="#Coordination-signaling-service" class="headerlink" title="Coordination/signaling service"></a>Coordination/signaling service</h4><p>一般使用生产者-消费者模型来实现在函数之间分享状态。这就需要当数据被生产出来时，消费者能够尽早知道。同样对生产者也是如此。这样的信号系统，需要满足 microsecond 级别的延迟、可靠的投递、支持广播或者组播。当然，因为 cloud function 并不是有独立的地址的，所以我们难以实现教科书级别的共识，或者选举机制。</p><h4 id="Minimize-startup-time"><a href="#Minimize-startup-time" class="headerlink" title="Minimize startup time"></a>Minimize startup time</h4><p>启动时间包含：</p><ol><li>调度资源</li><li>下载环境，比如 OS、库</li><li>执行每个 app 自己的启动和初始化逻辑</li></ol><p>第一部分在创建隔离环境，以及用户的 VPC 和 IAM 阶段可能有显著的延迟。哦，之前不是说这个很快的么？哦，所以最近有一些办法，比如使用 unikernel。它 preconfigure 系统到硬件上，相当于把监测硬件、分配 os 数据结构等变成静态的了。另一方面，它只包含 app 需要的驱动和系统库。</p><p>另一个解决第二部分的方式，是动态或者增量地加载 app 需要的库。</p><p>云提供商可以提供一个 signal 机制，让一个应用在自己能处理的时候，调用这个信号进行通知，然后接受负载。此外，云提供商还可以基于预测，提前启动。这种方案非常适合去处理那些和具体用户行为不相关的任务，比如启动 OS 或者加载库，这样就得到了一个可以被所有 tenant 共享的 warm pool 了。</p><h3 id="Networking-challenges"><a href="#Networking-challenges" class="headerlink" title="Networking challenges"></a>Networking challenges</h3><p>如前文介绍的，serverless 的 broadcast、agg、shuffle 操作的通信成本都比较大。解法：</p><ol><li>增加 cloud function 的核数，这样就能够合并多个 task 的通信</li><li>允许开发者显式将一些 cloud function 部署到同一个 VM 上。</li><li>让 app 开发者提供一个计算图，让 cloud provider 可以去 colocate 这些 cloud function。这个计算图，可以参考 Abstraction Challenges 的论述。</li></ol><p>前两者有点违背 serverless 精神，并且可能无法有效利用资源。</p><h3 id="Security-challenges"><a href="#Security-challenges" class="headerlink" title="Security challenges"></a>Security challenges</h3><p>暂不关注安全，略</p><h3 id="Computer-architecture-challenges"><a href="#Computer-architecture-challenges" class="headerlink" title="Computer architecture challenges"></a>Computer architecture challenges</h3><h4 id="Hardware-Heterogeneity-Pricing-and-Ease-of-Management"><a href="#Hardware-Heterogeneity-Pricing-and-Ease-of-Management" class="headerlink" title="Hardware Heterogeneity, Pricing, and Ease of Management"></a>Hardware Heterogeneity, Pricing, and Ease of Management</h4><p>现在硬件都要接近瓶颈了：</p><blockquote><p>Alas, the x86 microprocessors that dominate the cloud are barely improving in performance. In 2017, single program performance improvement only 3% [69]. Assuming the trends continue, performance won’t double for 20 years. Similarly, DRAM capacity per chip is approaching its limits; 16 Gbit DRAMs are for sale today, but it appears infeasible to build a 32 Gbit DRAM chip. A silver lining of this slow rate of change is letting providers replace older computers as they wear out with little disruption to the current serverless marketplace.</p></blockquote><p>几个方案：</p><ol><li>像 JS 或者 Python 这样的语言写的 cloud function，hardware-software co-design could lead to language-specific custom processors that run one to three orders of magnitude faster. 我不知道具体指的是啥。</li><li>DSA(Domain Specific Architectures)。比如 GPU 适用于图形，TPU 适用于机器学习。</li></ol><p>因此，serverless 需要支持一些 hardware heterogeneity：</p><ol><li>支持多种实例类型，硬件不一样，价格就不一样</li><li>可以自动选择 language-based 加速器，和 DSA。这可以通过选择不同的库，或者语言来隐式实现。例如对 CUDA 代码使用 GPU，对 Tensorflow 代码使用 TPU。</li></ol><p>对于 x86 的 SIMD 来说，Serverless 计算也面临一些 heterogeneity。但是现在 serverless 用户在 AWS Lambda 上似乎还不能够声明自己想要什么样的 CPU，并且他们的价格也是相同的。</p><h2 id="Fallacies-and-Pitfalls"><a href="#Fallacies-and-Pitfalls" class="headerlink" title="Fallacies and Pitfalls"></a>Fallacies and Pitfalls</h2><p>Fallacies 指的是谬误。一个谬误是觉得 Serverless 更贵。原因是相同内存规格的 AWS cloud function 比 AWS t3.nano 要贵 7.5 倍。</p><p>错误点：</p><ol><li>价格中包含了冗余，监控，日志等一个 t3.nano 节点享受不了的东西。</li><li>扩缩容灵活，如果不调用就不收费。</li></ol><p>Pitfall 指的是陷阱。这里说的是 Serverless 计算可能有未预期的成本。<br>这个是比较合理的担忧。解法是基于桶的定价，或者能够根据历史预测成本。</p><p>另一个 Fallacies 是采用诸如 Python 的高级语言，就很容易在不同的 Serverless 供应商之间移植 app。<br>错误点是不同的 Serverless 供应商之间的 API 不同。没有像 POSIX 一样的标准。</p><p>Pitfall： Serverless 计算的供应商锁定可能比 Serverful 计算更强。</p><p>另一个 Fallacies 是云函数无法处理需要可预测性能的 low-lentency 应用程序。<br>Serverful 能，是因为它一直是在线的。所以 Serverless 也可以做 pre-warm。</p><p>Pitfall：少有所谓的 elastic 服务能满足 serverless 计算的灵活性。</p><p>一大段话，懒得翻译了，大概就是说现在叫 elastic 的实际上还不如 serverless 呢。</p><blockquote><p>The word “elastic” is a popular term today, but it is being applied to services that do not scale nearly as well as the best serverless computing services. We are interested in services which can change their capacity rapidly, with minimal user intervention, and can potentially “scale to zero” when not in use. For example, despite its name, AWS ElastiCache only allows you to instantiate an integral number of Redis instances. Other “elastic” services require explicit capacity provisioning, with some taking many minutes to respond to changes in demand, or scaling over only a limited range. Users lose many of the benefits of serverless computing when they build applications that combine highly-elastic cloud functions with databases, search indexes, or serverful application tiers that have only limited elasticity. Without a quantitative and broadly accepted technical definition or metric—something that could aid in comparing or composing systems—“elastic” will remain an ambiguous descriptor</p></blockquote><h2 id="Summary-and-Predictions"><a href="#Summary-and-Predictions" class="headerlink" title="Summary and Predictions"></a>Summary and Predictions</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;这篇文章中，包含 Column Stores vs Row Stores、To BLOB or Not To BLOB: Large Object Storage in a Database or a Filesystem?、Cloud Programming Simplified: A Berkeley View on Serverless Computing。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 3</title>
    <link href="http://www.calvinneo.com/2024/11/10/database-paper-3/"/>
    <id>http://www.calvinneo.com/2024/11/10/database-paper-3/</id>
    <published>2024-11-10T13:33:22.000Z</published>
    <updated>2024-12-17T16:26:21.176Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章中，包含 DuckDB、BitCask、Hologres、Cockroach。</p><a id="more"></a><h1 id="DuckDB"><a href="#DuckDB" class="headerlink" title="DuckDB"></a>DuckDB</h1><p><a href="https://mytherin.github.io/papers/2019-duckdbdemo.pdf" target="_blank" rel="noopener">https://mytherin.github.io/papers/2019-duckdbdemo.pdf</a></p><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>SQLLite 的使用，显示了对 embedding 的数据库的需求。DuckDB 是一个 embedding 的 OLAP。<br><img src="/img/dbpaper/duckdb/1.png"></p><p>之前做了个 MonetDBLite，但是发现还是要专门设计一个。原因：</p><ol><li>需要高性能处理 OLAP workload，但是对 OLTP 的影响有限<ol><li>比如做 dashboard 的时候，并发的数据修改很常见。比如很多线程在用 OLTP 去修改数据，另外一些线程用 OLAP 去生成可视化。</li></ol></li><li>稳定性<ol><li>如果内置的 db 挂掉了，比如 OOM 了，它不会把宿主程序给崩掉。而是让查询 abort。</li></ol></li><li>数据库和应用程序在一个进程里面，应该利用这一点，提高数据分享和传递的效率</li><li>可移植性<ol><li>比如对 openssl 这样的库的依赖实际上是很麻烦的</li><li>一些系统调用比如 exit 应当被禁止</li></ol></li></ol><h2 id="DESIGN-AND-IMPLEMENTATION"><a href="#DESIGN-AND-IMPLEMENTATION" class="headerlink" title="DESIGN AND IMPLEMENTATION"></a>DESIGN AND IMPLEMENTATION</h2><p>Parser 从 postgql 上弄下来的。<br>Logical planner 由 binder 和 plan generator 组成。binder 将所有的 expression 关联到具体的 schema 对象，比如 table 或者 view 上。logical plan generator 将 parse tree 转成一个基本的 logical query operator，比如 scan、filter。project 等。在 planning 阶段之后，我们就有一个 type-resolved 的 logical query plan 了。<br>DuckDB 会统计已存储数据，这些统计信息回在 planning 过程中被传播，给 optimizer。<br>优化器进行 join order 优化。是通过 dynamic programming with a greedy fallback for complex join graph 来做的。It performs flattening of arbitrary subqueries。<br>DuckDB’s optimizer performs join order optimization using dynamic programming [7] with a greedy fallback for complex join graphs [11]. It performs flattening of arbitrary subqueries as described in Neumann et al. [9]. In addition, there are a set of rewrite rules that simplify the expression tree, by performing e.g. common subexpression elimination and constant folding.<br>Cardinality estimation is done using a combination of samples and HyperLogLog. The result of this process is the optimized logical plan for the query. The physical planner transforms the logical plan into the physical plan, selecting suitable implementations where applicable. For example, a scan may decide to use an existing index instead of scanning the base tables based on selectivity estimates, or switch between a hash join or merge join depending on the join predicates.</p><p>DuckDB uses a vectorized interpreted execution engine [1]. This approach was chosen over Just-in-Time compilation (JIT) of SQL queries [8] for portability reasons. JIT engines depend on massive compiler libraries (e.g. LLVM) with additional transitive dependencies.<br>DuckDB uses vectors of a fixed maximum amount of values (1024 per default). </p><ul><li>Fixedlength types such as integers are stored as native arrays. </li><li>Variable-length values such as strings are represented as a native array of pointers into a separate string heap. </li><li>NULL values are represented using a separate bit vector, which is only present if NULL values appear in the vector. <ul><li>This allows fast intersection of NULL vectors for binary vector operations and avoids redundant computation. </li></ul></li></ul><p>To avoid excessive shifting of data within the vectors when e.g. the data is filtered, the vectors may have a selection vector, which is a list of offsets into the vector stating which indices of the vector are relevant [1]. DuckDB contains an extensive library of vector operations that support the relational operators, this library expands code for all supported data types using C++ code templates.</p><p>The execution engine executes the query in a so-called “Vector Volcano” model. Query execution commences by pulling the first “chunk” of data from the root node of the physical plan. A chunk is a horizontal subset of a result set, query intermediate or base table. This node will recursively pull chunks from child nodes, eventually arriving at a scan operator which produces chunks by reading from the persistent tables. This continues until the chunk arriving at the root is empty, at which point the query is completed.</p><p>持久化的存储层中，DuckDB 使用 read-optimized DataBlocks storage layout。逻辑表被水平划分为 chunks of columns。后者被压缩到 physical blocks 中。Block 中有每个列的 min-max 索引，所以可以快速检查它们是否对查询相关。</p><h1 id="Bitcask"><a href="#Bitcask" class="headerlink" title="Bitcask"></a>Bitcask</h1><p><a href="https://arpitbhayani.me/blogs/bitcask/" target="_blank" rel="noopener">https://arpitbhayani.me/blogs/bitcask/</a><br>Datafile 是 append-only 的 log file。它里面存放了 KV pair，以及一些 meta 信息。一个 Bitcask 实例有多个 datafile，其中一个是 active 并且接受写入的，另外的只读。</p><p><img src="/img/dbpaper/bitcask/1.png"></p><p>KeyDir 是一个内存中的 hash table。它存放 bitcask 中的所有的 key，以及它们在 data file 中的 offset。这个 offset 指向了 log entry，也就是 value 在的地方。这样做方便了点查。</p><p><img src="/img/dbpaper/bitcask/2.png"></p><h2 id="Merge-and-Compaction"><a href="#Merge-and-Compaction" class="headerlink" title="Merge and Compaction"></a>Merge and Compaction</h2><p>The merge process iterates over all the immutable files in the Bitcask and produces a set of datafiles having only live and latest versions of each present key. This way the unused and non-existent keys are ignored from the newer datafiles saving a bunch of disk space. Since the record now exists in a different merged datafile and at a new offset, its entry in KeyDir needs an atomic updation.</p><h2 id="Performant-bootup"><a href="#Performant-bootup" class="headerlink" title="Performant bootup"></a>Performant bootup</h2><p>如果 Bitcask 从 crash 中重启恢复，就需要读取所有的 datafile，然后建立一个新的 KeyDir。Merging 和 Compaction 因为能 evict 陈旧的数据，所以能帮助减少要读取的数量。但是还有一个别的方式。<br>对于每个 datefile，创建一个 hint file。它持有 datafile 中从 value 之外的东西，也就是 key 和 meta。这个 hint file 其实很小，所以通过读取这个文件就可以快速创建 KeyDir 了。</p><h2 id="Weakness"><a href="#Weakness" class="headerlink" title="Weakness"></a>Weakness</h2><p>KeyDir 在内存中存放着所有 key。对系统的内存要求很高。<br>但是可以通过水平扩容的办法来解决。</p><h1 id="Hologres"><a href="#Hologres" class="headerlink" title="Hologres"></a>Hologres</h1><p>Alibaba Hologres: A Cloud-Native Service for Hybrid Serving/Analytical Processing<br><a href="https://www.vldb.org/pvldb/vol13/p3272-jiang.pdf" target="_blank" rel="noopener">https://www.vldb.org/pvldb/vol13/p3272-jiang.pdf</a></p><p>一个 TGS 包含一个 WAL，以及一系列 Tablet。一个 Tablet 如同一个 LSM 树。各自拥有一个 Memtable，Memtable 被 flush 成为 shard file。</p><p><img src="/img/dbpaper/hologres/1.png"></p><p>Single-shard Write. 在上图中，收到一个 single-shard ingestion 之后，WAL 首先分配一个 LSN。这个 LSN 是一个混合，包含了时间戳和一个自增的 seq。然后 WAL 会创建并持久化一个新的 entry。在持久化之后，write 就完成了。然后就是要写到 Memtable 里面，并且要对后续的用户可见。</p><p>Distributed Batch Write. 是个 2PC。FE 节点首先收到 batch write 请求，然后锁住所有访问到的 tablet。在每个 TGS 里面：</p><ol><li>为 batch write 分配一个 LSN。</li><li>flush 所有涉及到的 tablet 的 memtable。</li><li>loads the data as in the process of single-shard ingestion and flushes them as shard files.<br>这一步可以通过使用多个 memtable，然后并行 flush 来优化。我理解这里就是直接 ingest 成 sst。一旦完成，每个 TGS 向 FE 投票，当 FE 收到所有 TGS 的投票后，它会通知 commit 或者 abort。如果决定 commit，每个 TGS 会持久化一个 log，表示 batch write 被 commit 了。否则 batch write 会被移除。在 2PC 完成后，会去掉 tablet 上面的锁。</li></ol><p>每个 read 请求包含一个 timestamp，用来构造一个 LSN_read。它被用来 filter 掉所有应该对自己不可见的 record。比如所有 LSN 更大的 record。<br>一个 TGS 会对每个 table 维护一个 LSN_ref，保存 the LSN of the oldest version maintained for tablets in this table。LSN_ref 会被定期 update，用户可以配置这个时间，通过指定自己想要的 retaining period。在 memtable flush 和 file compaction 期间：</p><ol><li>所有 LSN 小于等于 LSN_ref 的记录</li><li>所有比 LSN_ref 大的记录会被保留</li></ol><p>目前实现中，一个 TGS 的 writer 和所有 reader 都在同一个 worker node 中。但是如果 worker node 压力大，可以 migrate 一些 TGS 出去。<br>后面可以做到 replica read。两种方式：</p><ol><li>fully-sync 的 replica，可以读到 up-to-date的数据</li><li>partically-sync 的 replica，只能读到已经被 flush 到文件系统中的数据，也就是说读不到 memtable。</li></ol><p>根据 read version，不同的读可以被 dispatch 到不同的 replica 上。但是所有的 read-only replica 都不需要实际复制这些 shard file，因为它们被存放在专门的分布式文件存储中。</p><p>有两种类型的 tablet，row 和 column。<br>row tablet 用来优化点查性能。memtable 是用 Masstree 来维护的，shard files 是 block-wise structure。shard file 包含 data block 和 index block。连续的 records 组成一个 data block，在 index block 中记录每个 data block 的 starting key，格式记录为 &lt;key, block_offset&gt;。<br>为了支持多版本，在 row tablet 中的数据会多加 del_bit 和 LSN 两列。对于同一行，memtable 和 shard file 中可能有多个记录，但是 LSN 是不同的。</p><p><img src="/img/dbpaper/hologres/2.png"></p><p>在 row tablet 里面的每一个 read 都包含一个 key，以及一个LSN_read。这个结果是通过搜索 memtable 和 shard file 完成的，两者可以并行做。所有 LSN 小于等于 LSN_read 的 key 都是candidate，然后会被按照 LSN 顺序进行 merge。如果看到 del_bit 是 1，或者找不到candidate record，就说明没找到。<br>写入包含了 key、value 和 LSN_write。删除也是一种写入，只是 del_bit 为 1。</p><p>Column tablet 被设计来辅助 column scan。它包含一个 column LSM 和一个 delete map。column LSM 树中的 value 实际上包含 value col 以及 LSN。memtable 按照 Apache Arrow 的方式来存储，records 根据 arriving order 在 memtable 中存储。row group 中的每一个 column 会被存为一个独立的 data block。同一个 column 的 data block 会被连续地存储在 shard file 中，从而优化顺序 scan。我们在 meta block 中维护每个 column 和整个 shard file 的 meta data，从而加速 large-scale data retrieving。在 meta block 中存有：</p><ol><li>每个 column 在 data block 中的唯一</li><li>每个 shard file 的压缩算法、总行数、LSN 和 key 的 range。</li></ol><p>在 index block 中存有 sorted first keys of row groups。</p><p>Thee delete map is a row tablet, where the key is the ID of a shard file (with the memory table treated as a special shard file) in the column LSM tree, and the value is a bitmap indicating which records are newly deleted at the corresponding LSN in the shard file. With the help of the delete map, column tablets can massively parallelize sequential scan as explained below.</p><p>用 LSN_read 读，会从 memtable 和所有的 shard file 中读取。在扫描一个 shard file 前，会根据 LSN_read 进行判别：</p><ol><li>如果 minimum LSN 比 LSN_read 大，那么这个 file 被 skip 掉</li><li>如果 minimum LSN 小于等于 LSN_read ，那么这整个 file 都会对这个 read 版本可见</li><li>否则，这个 file 中只有一部分可见</li></ol><p>读取：在第三种情况中，会扫描这个 file 的 LSN column，生成一个 LSN bitmap，用来决定哪些 row 是可见的。然后我们会通过 shard_file 的 ID 读取 delete map，获取哪些 row 是被删除了的。获得的 bitmap 回合 LSN bitmap 取交集，最终得到去除了 delete 和 invisible row 的最终结果。注意，不同于 row tablet，在一个 column tablet 中，每个 shard file 可以被独立读取，而不需要 consolidate 不同 level 的 shard file，因为 delete map 可以根据 LSN_read 和 shard file 的 ID 去有效率地返回哪些 row 是被删除了的。</p><p>【Q】我理解这样的话，delete map 是不是本身也要支持版本？其实另一个做法是不独立维护 version 列（这里的 LSN）列了，而是在删除的时候，直接记录 <code>pk-&gt;{deleted, LSN}</code></p><p>写入：删除操作中，会根据 key 找到我们要在哪个 shard file 中删除这个 row，以及对应的 row number。我们会在 LSN_write version 上，对这个 delete map 中进行一次插入，此时 key 是 file ID，value 是被删除了的 row number。update 操作就是先删除后插入。</p><h2 id="Hierarchical-Cache"><a href="#Hierarchical-Cache" class="headerlink" title="Hierarchical Cache"></a>Hierarchical Cache</h2><p>三层 cache 来减少 IO 和计算的开销。分别是 local disk cache、block cache 和 row cache。每个 tablet 对应了分布式系统中存储的一系列 shard file。local disk cache 用来在 local disk 也就是 SSD 中 cache shard file，从而减少 file system 中昂贵的 IO 操作。在 SSD cache 上面，有个内存中的 block cache。为了兼容行存和列存的不同的 data access pattern，将 block cache 分为行存和列存。在 block cache 上面，我们有一个内存中的 row cache，去存储最近 row tablet 中的点查的结果。</p><h2 id="QUERY-PROCESSING-amp-SCHEDULING"><a href="#QUERY-PROCESSING-amp-SCHEDULING" class="headerlink" title="QUERY PROCESSING &amp; SCHEDULING"></a>QUERY PROCESSING &amp; SCHEDULING</h2><p>收到一个 query 后，FE 中的 optimizer 会生成一个 DAG 显示的 query plan。将这个DAG 按照 shuffle boundaries 分成多个 fragment。有三种 fragment：read、write、query。一个 read 或者 write fragment 包含一个访问 table 的 operator。一个 query fragment 只包含非 read 或者 write 的 operator。一个 fragment 会随后被并行化为多个 fragment instance，这是通过 data parallel 的方式，比如一个 read 或者 write fragment instance 会在一个 TGS 中处理。<br>FE node 将 query plan 发送给 coordinator。这个 coordinator 会随后将 fragment instance 发送给 worker nodes。read write fragment instance 总是会被发送到 host 对应 TGS 的 worker node。query fragment 可以被在任何 worker node 上执行。因此，会从 load balancing 的角度进行 dispatch。locality 和 workload information 会和 storage manager 以及 resource manager 分别进行同步。<br>在 worker node 中 fragment instance 会被 map 到多个 work units 也就是 WU 中。这是 Hologres 中的基本的query 执行单位。一个 WU 可以在运行期动态地 spawn 另一个 WU。具体规则是：</p><ol><li>一个 read fragment instance 会被 map 到一个 read-sync WU 上。这个 WU 会 fetch 当前 tablet 的 version（从 metadata file 中获得的）以及一个 memtable 的只可读 snapshot，以及一个 shard file 的列表。然后 read-sync WU 会创建多个 read-apply WU，它们会并行读取 memtable，以及 shard file，并且会执行下游的任务。这个机制能够充分利用 high intra-operator parallelism，从而更好利用网络和 IO 的带宽。</li><li>一个 write fragment instance 会将所有的 non-write operator 去 map 到一个 query WU 中。后面会跟着一个 write-sync WN，它会将 log entry 持久化到 WAL 中。write-sync WU 会生成多个 write-apply WU，它们并行执行任务，其中每个 WU 会更新一个 tablet。</li><li>一个 query frament instance 会被映射到一个 query WU 上。</li></ol><p><img src="/img/dbpaper/hologres/3.png"></p><p>当并行处理多个不同用户发来的 query 的时候，WU 中的 context switch 成为 一个瓶颈。因此，Hologres 提供了一个用户态的线程，称为 execution context 即 EC。 EC 是 WU 的 resource abstraction。线程是可以 preemptively scheduled 的，但是 EC 是 cooperatively schedule 的。这样，就不涉及 system call 或者同步元语了。所以在 EC 之间的 switch 就是可以被忽略不计的了。Hologres 将 EC 作为基础的调度单位，计算资源按照 EC 来调度，一个 EC 会在被 assign 的线程上执行。</p><p>在 worker node 上，将 EC 分到多个 pool 中，从而保证隔离性以及 prioritization。EC pool 可以被分为三种类型：data-bound EC pool、query EC pool 和 background EC pool。</p><ol><li>data-bound EC pool 有两种类型，WAL EC和 tablet EC。在 TGS 中，有一个 WAL EC，和多个 tablet EC。每个 tablet RC 对应一个 tablet。WAL EC 执行 write-sync WU,tablet EC 执行 write-apply WU 和自己 tablet 上的 read-sync WU。WAL 或者 tablet EC 总是串行的处理所有的 WU，所以避免了同步措施。</li><li>在 query EC pool 中，每个 query WU 或者 read-apply WU 会被 map 到一个 query EC 上。</li><li>在 background EC pool 中，EC 会被用来 offload 昂贵的工作。比如 memtable flush 或者 shard file compaction 等。</li></ol><p>下面是一个 EC 的内部结构。<br>首先包含两个 task queue。第一个是一个 lock free 的 internal queue，包含了所有这个 EC 提交的 store task。另一个是线程安全的 submit queue，包含了其他 EC 提交的 store task。当开始 schedule 的时候，在 submit queue 中的 task 会被移动到 internal queue 中，从而可以被 lock-free schedule。在 internal queue 中的 task 总是被 FIFO 地 schedule 的。<br>在一个 EC 的生命周期中，它会在三个状态中切换，即 runnable、blocking 和 suspended。suspended 状态表示 EC 被调度，因为 task queue 都是空的。一旦往里面提交任务，EC 就会变为 runnable 状态，从而可以被调度。如果 EC 中所有的任务都 block 了，比如 IO stall 了，EC 会被换出去，然后状态变为 blocking。一旦收到新的 任务，或者 block task 返回了，它又会变成 runnable 状态。EC 可以被外部 cancel，或者 join。Cancel 会导致未完成的 task fail 掉。EC 在 join 之后，就不能接受新的任务了，然后会在已有的任务完成后 suspend 自己。EC 是在系统线程池上被 cooperatively 调度，所以线程切换开销忽略不计。</p><p>Hologres 支持联邦查询，包括从 Hive 或者 HBase 获取数据。这些其他系统会被抽象为特殊的 WU，每个会被映射为一个 EC。处于系统安全的考虑，这些抽象会在一个沙盒中被运行。</p><h1 id="Cockroach"><a href="#Cockroach" class="headerlink" title="Cockroach"></a>Cockroach</h1><p><a href="https://dl.acm.org/doi/pdf/10.1145/3318464.3386134" target="_blank" rel="noopener">https://dl.acm.org/doi/pdf/10.1145/3318464.3386134</a></p><h2 id="Intro-1"><a href="#Intro-1" class="headerlink" title="Intro"></a>Intro</h2><p>这一部分主要讲了在很多国家要求数据被存放在自己的领土上，所以用户有需求去更精细的控制数据存放的位置。也就是它提到的 Geo-distributed partitioning and replica placement。<br>然后是他们提出的实物模型。它们只支持 serializable的隔离级别。它们认为 NTP 这样的 clock sync 机制已经是足够的。CRDB 也支持云部署。</p><h2 id="SYSTEM-OVERVIEW"><a href="#SYSTEM-OVERVIEW" class="headerlink" title="SYSTEM OVERVIEW"></a>SYSTEM OVERVIEW</h2><p>CRDB 是一个 shared-nothing 模型，存算一体。</p><p>CRDB 在一个事务性 KV 层上构建了 SQL 层。</p><p>CRDB 使用range partitioning，将 key 分为大概 64MB 大小的 chunck。每个 chunck 称为 Range。Range 之间的顺序是通过一个两层的 index 结构来维护的，这个结构在 system Range 中。有一个 Distribution Layer去检查哪些 Range 需要去处理 某个 subset of query。</p><p>Range 是 64MB 的大小，因为折让在不同node 之间移动更加容易。但是它又可以让连续的数据被存放在一起。Range 可以被合并或者分裂。</p><p>CRDB 使用 Raft进行 Replication。CRDB 使用 Range level 的 lease。在 Raft Group 中的一个 replica，一般是 Raft group leader 作为 leaseholder 的角色。这是唯一一个有权力去提供 up-to-date read 或者向 Raft group leader 提交写入的节点。因为所有的写入都通过 leaseholder 进行，所以读取可以减少 network 的开销。<br>【Q】我觉得这里有一个取舍，就是 Raft log 以及 index只是被用来做replication，还是也被用来做一致性的 replica read。<br>lease 的生命周期很自然要和 leaseholder 的生命周期绑定。所以 CRDB 会从 system Range 往各个 Range 的 leaseholder 维护一个 4.5s 的 interval 的心跳。然后 lease 需要每 9s 续期一次。如果某个 replica 发信啊 leaseholder 没有存活了，就会尝试获得 lease。<br>CRDB 通过 raft 来维护 lease，具体来说，就是会通过一个特别的 lease acquision raft command去获得 lease。为了避免两个 lease 在时间上是 overlap 的，lease acquisition 操作需要包含一个在请求时被认为是 valid 的 lease。<br>下面介绍了对于短期，或者长期的 failure node 的处理模式，这里略过了。</p><p>有几种 placement 的策略：</p><ol><li>GeoPartitioned Replicas 对于需要空间局部性的数据，一个 table 可以被分成多个 partition，一个 partition 包含多个 Range。这些 partition 会被分到同一个 region 中。这使得 intra-region 的读和写很快。适合需要数据监管的需求。</li><li>GeoPartitioned Leaseholders Leaseholder 会被放在一个 region，另外的 replica 们会被放到别的 region 中。这个策略的 intra-region 读会好。同时也能承受regional failure。但是 cross region 写会比较差。</li><li>Duplicated Indexes。索引也可以被固定到指定的region 中。By duplicating indexes on a table and pinning each index’s leaseholder to a specific region, the database can serve fast local reads while retaining the ability to survive regional failures. This comes with higher write amplification and slower cross-region writes, but is useful for data that is infrequently updated or cannot be tied to specific geographies.</li></ol><h2 id="TRANSACTIONS"><a href="#TRANSACTIONS" class="headerlink" title="TRANSACTIONS"></a>TRANSACTIONS</h2><p>下面是coordinator 的角度看的事务算法。<br>在第二行中，需要发送很多的 KV 读写请求。为了减少 replicate 过程中的 write stall 现象，CRDB 主要引入了 Write Pipelining 技术以及 Parallel Commits 技术。<br>在第一行中，coordinator 会用 inflightOps 追踪所有还没被完全 replicate 的操作。<br>先介绍 Write Pipeling 优化。如果一个 op 并没有打算提交事务，那么就会通过 inflightOps 计算 op.deps，表示和这个 op 修改的 key 有 overlap 的，尚未完成的其他 op。如果这个 op 一来某个 inflight 的 op，那么就必须等待前面这个op 被 replicate 完毕，称为 pipeline stall 过程。否则，op 就可以立即被执行。所以写不同 key的多个 op 可以被 pipeline 地执行。anyway，在开始执行  op 后，会通过第8行更新 inflightOps。<br>然后，coordinator会发送一个 op 给 leaseholder 表示准备写入了，并在第 9 行处等待回复。这个回复中可能包含一个 ts，表示有另一个事务的读需要 leaseholder去调整 op.ts。这里我理解就类似于 TiKV 事务里面的  min_commit_ts 了。这个 coordinator 会尝试更新事务的时间戳。但是在这个之前，先要重新读一次 op.key，检查 value 有没有发生变化。如果变化了事务就需要失败重试，否则才能更新时间戳。<br>【Q】注意到，这里 CRDB 选择在事务提交前就往 KV 层写入数据了，在第 17 行，发现有 op.commit 的时候，才会异步通知 leaseholder 去提交事务。这和 TiKV 上现存的事务模型是不一样的。当然，后续有 pipelined txn model 用来支持大事务，这就类似于 CRDB 了。</p><p><img src="/img/dbpaper/cockroach/1.png"></p><p>下面是 Parallel Commit 的算法。下面，考虑事务提交的情况。朴素来讲，需要确保所有的 writes 都被 replica 之后，才能  commit。但是，PC 这个协议提供了一个 staging 的事务状态，which makes the true status of the ttxn conditional on whether all of its writes have been replicated. 这可以避免一轮额外的共识，因为 coordinator可以自由地 initiate the replication of the staging status in parallel with the verification of the outstading writes, which are also being replicated（第5行）. 加入两个都成功了，这个 coordinator 就可以立即 ACK 这个 txn 是 commit 的了，也就是第 15 行。在事务结束之前，coordinator 还会异步记录 txn 的状态为 explicitlyy committed。这是处于性能的考虑。</p><p>下面是 leaseholder 需要执行的算法。<br>当 leaseholder 收到 coordinator 的 op 时，它首先检查自己的 lease 是否还 valid。然后，它需要对 op 中的所有的 key 都请求 latch。特别的，对于 op.deps 中的所有的 key，也要请求 latch。这样做的目的是为了实现两个 overlap 的 concurrent 事务之间的隔离。在 line 4，它检查 op.deps 中涉及到的写入是否已经完成了。如果要执行一次写入，他还需要保证 op.ts 是比所有冲突的读要高的，也就是在 line5 和 line6 要去尝试推高 op.ts，尽可能保证 txn 不被 invalidate 掉。【Q】注意，这就对应了算法1中的更新 op.ts 的部分。特别的，这是用来处理 RW 冲突的，对于 WW 冲突，就必须要重试了。<br>上面的初始检查结束之后，line7 会根据 op 生成 coomand 和 response。这些 command 就是 Raft command，response 是给 client 的返回。如果事务还没有被提交那么就可以直接返回给 coordinator，如 line9 和 line10，随后慢慢复制。在 line11 和 line12 就是执行状态机，并写入存储层的过程。在这个写入完毕之后，就会释放 latch。在 line13-15 会回复 coordinator，这里论文说的不是很明确。<br>在 line7 中可能遇到一些复杂的情况，比如遇到了其他事务的没有提交的写入。这些写入的时间戳可能和当前事务的时间戳相当接近，所以我们无法得到一个准确的 order。下面会讨论这种情况下如何保证原子性和隔离级别的。</p><p><img src="/img/dbpaper/cockroach/2.png"></p><p>atomic commit 是通过在 commit 的时候，才让这个事务的所有 writes 可见(provisional)来实现的。CRDB 将这些 provisional values 称为 write intents。一个 intent是一个MVCC KV pair，except that it is preceded by metadata indicating that what follows is an intent. 这个 metadata 指向一个txn record，实际上是一个每个事务独有的 key，里面存着当前事务的 disposition（pending、staging、committed 或者 aborted）。这个txn record 用来原子性地改变所有 intent 的可见性，并且随着这个txn 的第一次写入，被存在在同一个 Range 中。对于 long running 事务来说，coordinator 会定期心跳处于 pending 状态的 txn record，to assure contending transactions that it is still making progress.<br>当遇到一个 intent 的时候，一个reader 会读取 intent 的txn record。如果这个record 中显示txn 被提交了，reader 会将 intent 看做是一个 regular value，并且删除 intent 的 metadata，如果 txn 被删除了，intent 会被忽略，后续会被删除。如果是 pending，表示事务还在进行，reader 就会 block 等待事务结束。如果 coordinator node 挂掉了，contending txn 会最终发现 txn record 过期了，然后将它标记为 aborted。如果 txn 在 staging 状态，表示 txn 可能已经被 committed 或者 aborted了，但是 reader 不是很确定，此时，reader 会尝试 abort 掉事务。这里的方式是尝试阻止 replicate 事务的一个 write。但如果所有的 write 都被 replicate了，那事务就是事实上被提交了，我们就会承认这次提交。</p><p>下面是和 MVCC 相关的讨论。主要是解决之前提到的 commit ts可能太过于靠近，以至于无法区分的情况。</p><p>首先是 Write-read 冲突。也就是一个read 事务可能看到一个没有提交的具有更低的 ts 的 intent。这个时候，它就需要等待这个更早对的事务完成。这个等待是通过内存中的一个队列完成的。特别的，如果这个未完成的事务更大，则可以被忽略。</p><p>然后是 Read-write 冲突。也就是一个write 事务，它要以 t_a 写入 key。如果同一个 key 上此时有一个 t_b 大于等于 t_a 的读事务，那么这个写就不能执行，而是要更新自己的 t_a 到大于 t_b 的值。</p><p>然后是 Write-Write 冲突。一个 write 事务可能看到一个 ts 更小的没有完成的 intent。这个时候，类似于第一种情况，需要等待。WW 冲突可能引起 deadlock，比如不同的事务以不同的顺序写入同一组 key。CRDB 会使用分布式死锁检测算法从而在出现循环waiter的时候，abort 掉一个 transaction。</p><p>Certain types of conflicts described above require advancing the commit timestamp of a transaction. 为了满足 serializability，read ts 也需要被 advance，从而 match commit ts。<br>【Q】没太懂为啥需要 advance read ts。<br>如果我们能够证明在 t_a 到 t_b 时间内，没有 txn 要读取的数据被修改了，那么就可以将 read ts 从 t_a 推进到 t_b。当然如果不能证明，则需要 abort 事务。<br>为了能够确认这一点，CRDB 会在 txn 的 read set 中维护 key。一个 read refresh请求会被用来检查在给定的时间段中，key 有没有被更新。对应到算法一的 line11-14。这里面包含了要扫描整个 read set，然后检查哪些 MVCC value 是在这个interval里面的。This process is equivalent to detecting the rw-antidependencies that PostgreSQL tracks for its implementation of SSI [8, 49]. Similar to PostgreSQL, our implementation may allow false positives (forcing a transaction to abort when not strictly necessary) to avoid the overhead of maintaining a full dependency graph.</p><p>Advancing the transaction’s read timestamp is also required when a scan encounters an uncertain value: a value whose timestamp makes it unclear if it falls in the reader’s past or future (see Section 4.2). In this case we also attempt to perform a refresh. Assuming it is successful, the value will now be returned by the read.</p><h3 id="Follow-reads"><a href="#Follow-reads" class="headerlink" title="Follow reads"></a>Follow reads</h3><p>通过 AS OF SYSTEM TIME 语句，允许从 Follower 副本读取过去的数据，当然事务只能是只读的。<br>一个非 leaseholder replica 在收到读取 T 时刻的请求时，需要知道没有后续的写入可以 invalidate read retroactivity。同样需要保证自己有所有必要的数据去 serve读请求。上面的这些条件表示，如果一个 follower 处理了一个 T 时刻的 follower read 请求，就不能再处理任何 T’ 小于等于 T 的 write 了。并且 Follower 必须追上 T 时刻所有可能影响 MVCC snapshot的 Raft log。<br>为此，每个 leaseholder 需要记录所有 incoming request 的 ts，并且阶段性的通告一个 closed timestamp，表示低于这个 ts 的所有写入后续都会被拒绝了。这个 ts 会通过 Raft 日志一起被复制。<br>Follower replicas use the state built up from received updates to determine if they have all the data needed to serve consistent reads at a given timestamp. For efficiency reasons the closed timestamp and the corresponding log indexes are generated at the node level (as opposed to the Range level).<br>每个 node 会记录自己和其他 node 的 latency。当一个 node 收到一个足够 old 的 ts（closed ts 通常要比当前时间晚 2s）的 read request 的时候，it forwards the request to the closest node with a replica of the data.</p><h2 id="CLOCK-SYNCHRONIZATION"><a href="#CLOCK-SYNCHRONIZATION" class="headerlink" title="CLOCK SYNCHRONIZATION"></a>CLOCK SYNCHRONIZATION</h2><p>CRDB 里面的每一个 node 都维护一个 hybrid logical clock，称为 HLC，是物理时钟和逻辑时钟的组合。逻辑时钟是基于 lamport 时钟的。同一个集群中的 HLC 允许有一个物理时间的 offset。默认值是 500ms 这是比较保守的。</p><ol><li>HLC 在 logical 部分提供了因果关系的追踪。这保护了 lease disjointness invariant 特性。也就是类似于 Spanner，对于每个 Range，每个 lease interval 都和其他的 lease interval 是 disjoint 的。This is enforced on cooperative lease handoff with causality transfer through the HLC and is enforced on non-cooperative lease acquisition through a delay equal to the maximum clock offset between lease intervals.</li><li>HLC 提供了严格的单调性，无论是否重启。这是因为在重启后，会要求等待超过 maximum clock offset 的时间，然后再处理任何请求。这个特性保证了两个有因果关系的事务，并且如果是在同一个 node 上发起的，那么它们的 ts 能够反应实时的 order。</li><li>HLC 提供了 self-stabilization，即使在存在 isolated transient clock skew fluctuation 的情况。As stated above, a node forwards its HLC upon its receipt of a network message. The effect of this is that given sufficient intra-cluster communication, HLCs across nodes tend to converge and stabilize even if their individual physical clocks diverge. This provides no strong guarantees but can mask clock synchronization errors in practice. 大概意思就是 intra-cluster 的消息比较多，所以这个时间能够最终收敛。</li></ol><p>目前，我们已经讨论了 crdb 中的事务模型是如何提供 serializable 隔离的。但是 serializability 本身并没有讲述事务是如何在按照实际发生的顺序在系统中排序的，所以要讲述 consistency level。<br>在正常情况下，crdb 支持 single-key linearizability。也就是每个对指定 key 的 operation 都 appears to take place atomically and in some total linear order consistent with the real-time ordering of those operations. 在这个一致性下，stale read anomalies 是不会发生的。对于 loosely synchronized clock 也是这样的，只要这些 clock 在配置的 max clock offset 之内。<br>注意，crdb 并不支持 strict serializability，因为没有任何保证说 the ordering of transactions touching disjoint key sets will match their ordering in real time. 在实践中，这对 application 并不是一个问题，除非有一个 external low-latency communication channel between clients that could potentially impoct activity on the DBMS。</p><p>实现 single-key linearizability 特性是通过跟踪每个 txn 的 uncertainty interval 来实现的。在这个 interval 中，两个事务的 causal ordering 是不确定的。在它被创建时，一个事务就会被提供一个临时的 commit ts。这个 commit ts 一般是 coordinator 的 local HLC，因此它的 uncertainty interval 是 [commit_ts, commit_ts + max_offset]。<br>当一个 txn 遇到一个value onn a key 并且它的 ts 比自己的临时 commit ts 要更低的时候，它就会在读的时候自然地观察到，并且在写的时候，通过一个更大的 ts 去 overwrite 掉这个 value。如果 txn 有一个完全同步的 global clock，那么这样就已经满足 single-key linearizability 了。<br>但如果没有这样的 global clock，就需要考虑 uncertainty interval 了，因为 it is possible for a transaction to receive a provisional commit timestamp up to the cluster’s max_offset earlier than a transaction that causally preceded this new transaction in real time. 当一个事务遇到一个 value onn a key 并且它的 ts 是比自己的临时 commit_ts 要高，但是又在 uncertainty interval 里面，他就<strong>需要执行一次 uncertainty restart</strong>，moving its provisional commit timestamp above the uncertain value but keeping the upper bound of its uncertainty interval fixed.</p><p>This corresponds to treating all values in a transaction’s uncertainty window as past writes. As a result, the operations on each key performed by transactions take place in an order consistent with the real time ordering of those transactions.</p><p>到此为止，我们只是考虑了遵守了配置了的 max clock offset bounds 的情况。也需要考虑如果不遵守会有什么后果。<br>对于单个 Range，通过 Raft 来保证一致性，所以不论是否有 clock skew 都是线性一致的。但是，Range lease 允许 leaseholder 不通过 raft 直接返回 read 的结果，这就复杂了。比如，多个 node 都有可能认为自己持有某个 Range 的 lease，如果没有额外的保护，这就可能导致冲突的操作。<br>CRDB 有两种方式来防止：</p><ol><li>Range lease 包含一个 start 和 end 时间戳，一个 leaseholder 不能处理 MVCC ts 高于 lease interval 的读请求，不能处理 MVCC ts 在 lease interval 之外的写请求。先前讨论过的 lease disjointness invariant 保证了每个 lease interval 都和其他的不相交。<br> 【Q】我不太清楚这的 end 时间戳和之前的 closed timestamp 是不是类似的东西。我理解至少有两点是不同的，首先，closed timestamp 会跟随 raft log 一起复制。其次，closed timestamp 是用来服务于 Follower read 的。<br> 【Q】我理解这实际上是对于任意的 write，在所有时间中，只有唯一的 leaseholder 能够处理它。</li><li>每个写到 raft log 中的 write 都包含了 Range lease 的 sequence。对于一次成功的 replication，sequence number 会被和当前 active 的 lease 放在一起检查。如果它们不匹配，写入会被拒绝。这是因为 lease 的变化本来就会被写到 Raft 日志里面，只有一个 leaseholder 才能对 Range 做出改变。即使多个 nodes 都认为自己持有一个 valid 的 lease，也改变不了这个事实。【Q】我理解就是用 Raft 的特性去保证 lease 的独一性。如果 “term” 或者 “epoch”（无论你叫它什么）不匹配，那么就不能写入。</li></ol><p>第一个方式保证了一个 incoming leaseholder 不会处理一个 write，如果它会 invalidate 一个 outgoing leaseholder 的 read。<br>第二个方式保证了一个 outgoing leaseholder 不会处理一个 write，如果他会 invalidate 一个 incoming leaseholder 的 write 或者 read。<br>加在一起，这些方式保证了即使在严重的 clock skew，甚至违背了 max clock offset bound 的情况下，CRDB 都能保证 serializable isolation。<br>【Q】我没懂这里在说什么。比如他说了 lease disjointness invariant 保证了 lease 不会相交，那为啥可能同时有两个 node 都觉得自己是 leaseholder？<br>虽然无论是否有 clock skew 都可以<strong>保证 isolation</strong>，但是超出 clock offset bounds 的 clock skew 就会<strong>破坏有因果关系的事务之间的 single-key linearizability</strong> 了。比如说，如果这些事务是从不同的 gateway nodes 中被发过来的，假如第二个 txn 的 gateway node 被分配了一个 commit_ts，它比第一个 txn 的 ts 落后超过了 max_offset，那么第一个事务所写入的值，就会在第二个事务的 uncertainty interval 之外。这就可能导致第二个事务 to read keys overlapping the write set of the first without actually observing the writes. Stale read 就是一个违反 Single Key lin 的情况，并且只有在 clock 在 offset bounds 中才能被避免。<br>【Q】这里我觉得 TiKV 得到线性一致的方式简单粗暴很多，通过禁止 leader 去乱序 apply，保证了 learner 和 leader 是看到一个顺序。然后通过 read index 得到的一个 index，就类似于“领导人完全性”的性质，只要我 apply 到了这个 index，就肯定按顺序 apply 到了所有这个 index 之前的 log 了。<br>【Q】但是，绕不开的话题还是如何识别谁是 Leader 或者 leaseholder。对于 Raft 只有一种 source of truth，就是尝试 propose 一条日志，但肯定代价太大了。但相比 CRDB 的 leaseholder，至少将 Leader 和 leaseholder 绑定提供了这么一种 source of truth。但是，TiKV 依旧需要依赖 NTP，从而确保所有节点看到的 leaseholder 的过期时间是接近的。</p><p>To reduce the likelihood of stale reads, nodes periodically measure their clock’s offset from other nodes. If any node exceeds the configured maximum offset by more than 80% compared to a majority of other nodes, it self-terminates.</p><h2 id="LESSONS-LEARNED"><a href="#LESSONS-LEARNED" class="headerlink" title="LESSONS LEARNED"></a>LESSONS LEARNED</h2><p>一些对 raft 的优化：</p><ol><li>将 heartbeat msg 从 raft group 级别的降低为 node 级别的，对于不活动的 raft group，让它 hibernate</li><li>joint consensus</li></ol><p>CRDB 原来还支持 SI 的隔离级别。但是它默认使用 SERIALIZABLE 级别因为他们认为应用开发者不应该担心 write skew anomalies。然后crdb 的实现使得 SERIALIZABLE 的惩罚也不大。<br>因为 crdb 一开始是针对 SERIALIZABLE 设计的，所以他们想是不是可以移除 write skew 检查就行了。但后面发现，唯一能够在 si 下保证 strong consistency 的是悲观锁，比如 FOR SHARE 和 FOR UPDATE。因此，CRDB 需要对任意的 row updates 引入悲观锁，甚至是 SERIALIZABLE 事务。所以，CRDB 就不再真的实现它了。<br>【Q】这里没有说的很详细。我理解他说的 consistency 应该指的是 ACID 中的 C 了吧。</p><p>早期，crdb 会在每个 replica 上进行 evaluate 操作，然后再 apply。但是考虑升级的场景，可能新旧的 replica 在 evaluate 上是不一样的，因此每个 replica 上的数据也是不一样的了。因此，现在是先 evaluate，然后 propose 的是 evaluate 这个 request 的结果，而不是这个 request 本身。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;这篇文章中，包含 DuckDB、BitCask、Hologres、Cockroach。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 2</title>
    <link href="http://www.calvinneo.com/2024/11/01/database-paper-2/"/>
    <id>http://www.calvinneo.com/2024/11/01/database-paper-2/</id>
    <published>2024-11-01T13:33:22.000Z</published>
    <updated>2024-11-06T04:15:16.150Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章中，包含 Greenplum、Aurora、Dynamo、WiscKey。</p><a id="more"></a><h1 id="Greenplum"><a href="#Greenplum" class="headerlink" title="Greenplum"></a>Greenplum</h1><p>Greenplum: A Hybrid Database for Transactional and Analytical Workloads</p><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>Greenplum 类似于 Redshift、AnalyticDB、BigQuery 这样的 PB 级别的数据仓库。相比之下，像 CRDB、Amazon RDS 这种关系型数据库主要还是在 TB 阶段。</p><p>Client 和 coordinator 交互，coordinator 将任务下发到各个 segment 上。各个 segment 并行处理，并且可能会 shuffle 一些 tuple。</p><p>DML 可以在 worker segment 上被用来修改数据。</p><p>原子性通过 2PC 保证。</p><p>并发事务通过分布式快照保证。</p><p>Greenplum 支持 append-optimized column-oriented 表。支持多种压缩算法。这些表适合用来做 bulk read 和 buld write，也就是典型的 OLAP 负载。</p><p><img src="/img/dbpaper/gp/1.png"></p><p>后面就自然演化出 HTAP 的需求，要求点查的响应要快，也要有 scalable 的 AP 能力。</p><p>GP 主要是三点：</p><ol><li>并行的 data loading，且 ACID</li><li>减少点查的响应时间</li><li>Resource Group，隔离用户在不同类型的 workload 的资源</li></ol><p>GP 以 OLAP 为第一等公民。特别是对于小事务来说，2PC 是一个巨大的惩罚。Coordinator 会被施加很重的锁，以避免 distributed deadlock，这个设计限制性太大了。</p><p>下面这张图的意思是对于一个 10s 的查询，在锁上面占用的时间的比例。随着并发度的提高，这个时间越来越不可接受。</p><p><img src="/img/dbpaper/gp/2.png"></p><p>GP 的贡献：</p><ol><li>如何从 OLAP 转换成为 HTAP</li><li>global deadlock detector<br> 作用是减少了锁的开销，优化了 TP 的响应时间。同时不牺牲 AP。</li><li>对于一个 segment 上的事务只做 1PC</li><li>前面提到的 resource control</li></ol><p>在 Relate work 中主要介绍了两种 HTAP 方案。第一种是从 OLTP 演进的，包含 Oracle Exadata、Aurora。另一种是从 NewSQL 演进的，例如 Spanner、CRDB、TiDB 和 F1。</p><h2 id="MPP-架构"><a href="#MPP-架构" class="headerlink" title="MPP 架构"></a>MPP 架构</h2><p>在整个数据库中，只有一个 coordinator segment。</p><p>一些 segment 会被作为 mirror 或者 standby（特指对 coordinator）存在，但不会参与到计算中。它们接受 WAL，并且回放。</p><p>GP 是 shared-nothing 的。使用各自的内存和 data directory，只通过 network 访问。</p><h3 id="Distributed-Plan-and-Distributed-Executor"><a href="#Distributed-Plan-and-Distributed-Executor" class="headerlink" title="Distributed Plan and Distributed Executor"></a>Distributed Plan and Distributed Executor</h3><p>作为 shared-nothing 架构，在 join 的时候就需要在 segments 之间移动 tuples。</p><p>GP 引入了 Motion plan。Motion 将 plan 切分为更小的块，称为 slice，我理解就是子计划。每个 slice 被一个 process group 执行，这一 process group 称为 gang。</p><p>With the proposed Motion plan node and gang mentioned above, Greenplum’s query plan and the executor both becomes distributed. The plan will be dispatched to each process, and based on its local context and state, each process executes its own slice of the plan to finish the query execution. The described execution is the Single Program Multiple Data technique: we dispatch the same plan to groups of processes across the cluster and different processes spawned by different segments have their own local context, states, and data.</p><p>下图的上面部分是一个分布式查询计划，下面部分是这个计划的执行流程。在例子中有两个 segment。<br>The top slice is executed by a single process on the coordinator, and other slices are executed on segments. One slice scans the table and then sends the tuples out using redistributed motion. Another slice that performs hash join will receive tuples from the motion node, scan the student table, build a hash table, compute the hash join, and finally send tuples out to the top slice.<br><img src="/img/dbpaper/gp/4.png"></p><h3 id="Distributed-Transaction-Management"><a href="#Distributed-Transaction-Management" class="headerlink" title="Distributed Transaction Management"></a>Distributed Transaction Management</h3><p>GP 中，每个 segment 实际上是一个 PostgreSQL 实例。</p><p>为了保障 ACID 特性，GP 用了 2PC 和分布式快照。</p><h3 id="Hybrid-Storage-and-Optimizer"><a href="#Hybrid-Storage-and-Optimizer" class="headerlink" title="Hybrid Storage and Optimizer"></a>Hybrid Storage and Optimizer</h3><p>GP 支持 PSQL 原生的 heap table。这个 table 是一个行存，包含固定大小的 block，以及被多个 query 共享的 cache。</p><p>GP 自己添加了两种新表：AO-row 和 AO-column。AO 表示 append-optimized。AO 的访问模式更有利于 bulk IO，也就是 AP 的工作负载。</p><p>GP 的分区是在 root table 下新建更低层级的表来做的，这里就类似于 TiDB 的方案。不同的 partition 可以存在不同的表类型中，特别地，还支持一些外部存储，比如 HDFS、S3 等。</p><h2 id="OBJECT-LOCK-OPTIMIZATION"><a href="#OBJECT-LOCK-OPTIMIZATION" class="headerlink" title="OBJECT LOCK OPTIMIZATION"></a>OBJECT LOCK OPTIMIZATION</h2><p>这是 GP 的关键。核心是通过一个算法解决分布式环境下的 global deadlock 问题。</p><p>GP 会举例子来讲解。例子中有两个 int column c1 和 c2，c1 是 distributed ke。数据分布在三个 segments 上。</p><h3 id="Locks-in-Greenplum"><a href="#Locks-in-Greenplum" class="headerlink" title="Locks in Greenplum"></a>Locks in Greenplum</h3><p>三种类型的锁：spin lock，LWLock，Object lock。</p><p>前两者是为了保护读写共享内存的，我理解实际上叫 latch 吧。主要还是聚焦 Object 锁。</p><p>和 PSQL 一样，lock mode 分为 8 个级别。</p><p><img src="/img/dbpaper/gp/t1.png"></p><p>但是 MPP 数据库和 PSQL 的锁算法是有区别的，PSQL 锁逻辑不能发现或者解决 global deadlock。更具体来说，需要增加 DML 操作的 local level，保证事务是 serially 执行的。</p><p>在 GP 的早期版本是基于 PSQL 的，在事务比较多的时候，性能很差，因为只有一个事务能够对同一个 relation 进行 update 或者 delete。</p><h3 id="Global-Deadlock-Issue"><a href="#Global-Deadlock-Issue" class="headerlink" title="Global Deadlock Issue"></a>Global Deadlock Issue</h3><p>在诸如 GP 这样的分布式系统中，DML 语句的行为如下：</p><ol><li>在 parse-analyze 阶段， the transaction locks the target relation in some mode.</li><li>在执行阶段，事务在 tuple 中写入自己的 id。This is just a way of locking tuple using the transaction lock.</li></ol><p>在 PSQL 这样的单机数据库中，第一阶段一般是 RowExclusive 锁。所以它们是能够并发的，除非它们要写的是同一个 tuple，才会有等待。</p><p>这些 lock dependencies 会被存在每个 segment 的内存中，如果死锁发生了，就可以通过内存中的信息去解决。</p><p>但是 PSQL 的 lock deadlock handler 是不够的。如下图所示</p><p><img src="/img/dbpaper/gp/6.png"></p><p>简单来说，是下面的时序关系：</p><ol><li>A 要写 segment 0 里面的一个 tuple (2, 2)，持有的是 segment 0 的锁。B 要写 segment 1 里面的一个 tuple (1, 1)，持有的是 segment 1 的锁。</li><li>B 需要写刚才 A 写的那个 tuple，因为 A 还没有 commit 或者 abort，所以 B 得等。</li><li>同理，A 要写 B 刚才写的 tuple，A 也得等。</li></ol><p>于是，segment 0 上的 B 在等 segment 1 上的 A。segment 1 上是类似的情况。无论是 segment 0 还是 1，它本地的 deadlock handler 都检测不到有 deadlock，这也就是一直在说的 global deadlock。</p><p>后面还举了一个更复杂的例子，我也不想看了。</p><p>在 GP 5 以及之前的版本，同一个 relation 上面的事务是串行执行的。并发度很差了，虽然肯定没有死锁。</p><h3 id="Global-Deadlock-Detection-Algorithm"><a href="#Global-Deadlock-Detection-Algorithm" class="headerlink" title="Global Deadlock Detection Algorithm"></a>Global Deadlock Detection Algorithm</h3><p>GDD 要点：</p><ol><li>在 coordinator segment 上启动一个 daemon</li><li>daemon 定时收集每个 segment 上的 wait-for 图</li><li>daemon 确定是否有 global deadlock 发生</li><li>daemon 使用预定义的策略解决死锁</li></ol><p>wait-for 图中，点表示事务，有向边 a -&gt; b 表示 a 在等 b。这里会引入 deg(G)(V) 和 deg(i)(V) 分别表示 V 的 global out-degree 以及 i 的 local out-degree。</p><p>从不同 segment 收到的 wait-for 信息是异步的。</p><p>GDD 算法的核心是贪心，它会尝试 remove 掉可能在后续能执行的边，那么剩下来的边上可能就会发生 global deadlock。当然，这是不够的，算法的 recall 和 accuracy 都得是 1 才行。</p><p>这个时候，算法就需要在 coordinator 上面 lock 所有的 process，然后检查剩余的 edge 是否是 valid 的。如果这个时候一些事务已经结束了，GDD 就会 abort 掉这一轮的所有信息，sleep 一段时间，然后开启下一轮。</p><p>在 global wait-for 图中，有两种边：</p><ol><li>实线边<br> 表示这个 waiting 只会在持有锁的事务结束后才会消失。<br> 比如说 when a relation lock on the target table in UPDATE 或者 DELETE 语句。<br> Such an edge can be removed only when the holding transaction is not blocked everywhere because based on the greedy rule we can suppose the hold transaction will be over and release all locks it holds.<br> 例如 Xid lock、Relation lock closed with NO_LOCK。</li><li>虚线边<br> 表示可以在事务还没结束的时候，这个锁就可能被 release 了。<br> For example, a <strong>tuple lock</strong> that is held just before modifying the content of a tuple during the execution of a low level delete or update operation. Such an edge can be removed only when the holding transaction is not blocked by others in the specific segment. This is based on the greedy rule we can suppose the hold transaction will release the locks that blocks the waiting transaction without committing or aborting.</li></ol><p>GDD 算法如下。<br>首先移除掉所有出度为 0 的 V。<br>然后扫描每个 local wait-for 图，删除掉所有指向出度为 0 的 V 的<strong>虚线</strong>边。</p><p><img src="/img/dbpaper/gp/a1.png"></p><h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h3><p>在下面的例子中，在前三步 B 会被 segment 0 上的 A 和 segment 1 上的 C 阻塞。在第四步，A 有试图 lock segment 1 上的 tuple，然后被 B 阻塞。</p><p>【Q】这里应该同时也会被 C 阻塞？</p><p>注意，这里的 A -&gt; B 是一个虚线。【Q】Why？我理解可能是事务上的第一个锁是 xid 锁，后面的是 tuple 锁。</p><p><img src="/img/dbpaper/gp/8.png"></p><p>下面是 GDD 算法：</p><ol><li>首先，C 的 global 出度是 0。因为 C 没有在等任何的事务。因此在移除掉 C 之后，得到 (b) 这张图。</li><li>发现 B 在 seg 1 上的出度是 0，所以可以移除所有指向 B 的虚线边，从而得到 (c) 这张图。</li><li>发现 A 的 global 出度是 0，移除掉 A 之后，可以得到 (d) 这张图。</li><li>GDD 报告没有死锁。</li></ol><p><img src="/img/dbpaper/gp/9.png"></p><h2 id="DISTRIBUTED-TRANSACTION-MANAGEMENT"><a href="#DISTRIBUTED-TRANSACTION-MANAGEMENT" class="headerlink" title="DISTRIBUTED TRANSACTION MANAGEMENT"></a>DISTRIBUTED TRANSACTION MANAGEMENT</h2><h1 id="Aurora"><a href="#Aurora" class="headerlink" title="Aurora"></a>Aurora</h1><p>Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases</p><h2 id="Intro-1"><a href="#Intro-1" class="headerlink" title="Intro"></a>Intro</h2><p>认为随着扩容，IO 瓶颈变成了网络。特别是在存算分离下，变成了计算层和存储层之间的网络。因为计算节点通常是并行发送请求，所以网络问题还存在木桶效应。</p><p>有一些操作是同步的，比如如果 cache miss，读线程就会等待。checkpoint 以及 dirty page write 技术能够缓解，但也会引入 stall、context switch 以及 resource contention 问题。</p><p>另外，事务提交也是另一个问题。特别是在分布式环境下的 2PC 会更加有挑战性。</p><p>Aurora 的思想是更加激进地使用 redo log。它从一个 virtualized segmented redo log 抽象上构造的 </p><blockquote><p>We use a novel service-oriented architecture with a multi-tenant scale-out storage service that abstracts a virtualized segmented redo log and is loosely coupled to a fleet of database instances. Although each instance still includes most of the components of a traditional kernel (query processor, transactions, locking, buffer cache, access methods and undo management) several functions (redo logging, durable storage, crash recovery, and backup/restore) are off-loaded to the storage service.</p></blockquote><p>三点优势：</p><ol><li>由存储服务来负责容错以及自愈，数据库就可免受存储层的影响<br> 他们说 failure in durability 可以被看做长期的 availablity 问题，一个 availablity 问题可以被看做长期的性能问题。</li><li>因为往存储写的是 redo log，所以能够大幅度减少 IOPS</li><li>将一些复杂但是重要的工作，比如 backup and redo recovery 从一次性的昂贵操作转变为连续的异步操作，并且这些操作分布在多个机器上的<br> 这实际上让 crash recovery 变得非常快，并且这还不需要依赖 checkpoint 技术，也不会影响前台的处理。</li></ol><h2 id="DURABILITY-AT-SCALE"><a href="#DURABILITY-AT-SCALE" class="headerlink" title="DURABILITY AT SCALE"></a>DURABILITY AT SCALE</h2><h3 id="Replication-and-Correlated-Failures"><a href="#Replication-and-Correlated-Failures" class="headerlink" title="Replication and Correlated Failures"></a>Replication and Correlated Failures</h3><p>这里说的 instance 应该可以理解为计算层。Aurora 说这两个的生命周期不是一致的，计算层随着上下线，扩缩容，变化更大。</p><p>假如有 V 个副本，令读操作需要 Vr 票，写操作需要 Vw 票，那么：</p><ol><li>Vr + Vw &gt; V<br> 也就是至少有一个读节点能看到最近的写入。</li><li>Vw &gt; V / 2<br> 这是在写入的时候，要避免冲突，形成多数。</li></ol><p>所以，为了容忍单个节点的故障，可以选择 V 为 3，Vr 为 2，Vw 为 2。这个类似于 Dynamo，在 <a href="/2017/09/20/distributed-system-consistency-and-consensus/">分布式一致性和分布式共识协议</a> 中也讲解了为什么 Vr + Vw &gt; V 并不足以能保证线性一致。</p><p>但是 Aurora 认为这是不够的，主要是如果一个 AZ 挂了，就会损失两个副本，这样就没有办法确认第三个副本是不是最新的了。Aurora 需要实现的是：</p><ol><li>丢失一个 AZ 不影响写入能力</li><li>丢失一个 AZ 以及一个额外节点而不影响数据恢复能力</li></ol><p>因此，它们使用了 V=6，Vr = 3，Vw=4 的模型。</p><h3 id="Segmented-Storage"><a href="#Segmented-Storage" class="headerlink" title="Segmented Storage"></a>Segmented Storage</h3><p>通过缩短 MTTR 去减少可能出现 double fault 的窗口。</p><p>主要就是将数据库氛围 10GB 的 Segment，每个 Segment 按照六副本复制，会被复制到 3 个 AZ 中，每个 AZ 两个副本。目前 Aurora 支持最大 64TB 的数据库。</p><p>10 GB 的 segment 可以在 10s 内被修复，基于一个 10Gbps 的网络。</p><h3 id="Operational-Advantages-of-Resilience"><a href="#Operational-Advantages-of-Resilience" class="headerlink" title="Operational Advantages of Resilience"></a>Operational Advantages of Resilience</h3><h2 id="THE-LOG-IS-THE-DATABASE"><a href="#THE-LOG-IS-THE-DATABASE" class="headerlink" title="THE LOG IS THE DATABASE"></a>THE LOG IS THE DATABASE</h2><h3 id="The-Burden-of-Amplified-Writes"><a href="#The-Burden-of-Amplified-Writes" class="headerlink" title="The Burden of Amplified Writes"></a>The Burden of Amplified Writes</h3><p>主要是为了维持多副本，IO 就会显著变高。IO 变高会导致系统中的同步阻塞点变多。这里提到，Chain replication 能够减少网络开销，但是链式复制引入了更多的同步。</p><p>在传统数据库中，数据被写入到 data page 中，也被写到 redo log 中。每个 redo log 包含了前像和后像之间的 diff。</p><p>下图是如果要维护一个传统的 MySQL 镜像需要进行的 replication 的数据规模。</p><p>这里 double write 指的是 MySQL 在刷脏页的时候，如果中途发生宕机，可能有一个页面只写了一般，从而丢失数据的情况。因为 redo log 记录的是 diff 而不是 page 本身的数据，所以无法通过 redo log 恢复。double write 机制是先把这些页面<strong>顺序</strong>地写到磁盘上<strong>连续</strong>的一些页中（128页 * 16K=2MB），然后再刷到实际的位置中。这样可以从第一次写的地方恢复最近一次刷脏的页面。<br><img src="/img/dbpaper/aurora/1.png"></p><p>从分布式系统角度看，这个模型是一个 4/4 write quorum，对 failure 和离群点性能更敏感。</p><h3 id="Offloading-Redo-Processing-to-Storage"><a href="#Offloading-Redo-Processing-to-Storage" class="headerlink" title="Offloading Redo Processing to Storage"></a>Offloading Redo Processing to Storage</h3><p>传统数据库中惠使用 log applicator 去将 redo log 应用到前像上从而产生后像，事务提交至少需要 redo log 被持久化。Aurora 在数据库层面，没有后台写、checkpoint、cache evection。log applicator 会被下推到存储层，从而可以后台地、异步地去生成 database page。</p><p>当然，从头开始生成的代价是昂贵的，所以我们会在后台持续物化 database page，来避免每次都重新生成。当然，这个物化是完全可选的，因为 the log is the database。</p><p>Note also that, unlike checkpointing, only pages with a long chain of modifications need to be rematerialized. Checkpointing is governed by the length of the entire redo log chain. Aurora page materialization is governed by the length of the chain for a given page.<br><img src="/img/dbpaper/aurora/3.png"></p><p>下面是一个显著的性能对比。</p><p><img src="/img/dbpaper/aurora/t1.png"></p><p>在存储层进行日志复制的工作实际上能减少 crash recovery 时间，并且消除 checkpoint、后台 data page 写入、backup 导致的 jitter。因此，提高了可用性。</p><p>原因如下。在传统数据库中，在一次 crash 之后，系统必须从最近的 checkpoint 开始回放 redo log。In Aurora, durable redo record application happens at the storage tier, continuously, asynchronously, and distributed across the fleet. Any read request for a data page may require some redo records to be applied if the page is not current. As a result, the process of crash recovery is spread across all normal foreground processing. 在数据库重启的时候，无需进行任何的操作，也没有额外的等待。</p><h3 id="Storage-Service-Design-Points"><a href="#Storage-Service-Design-Points" class="headerlink" title="Storage Service Design Points"></a>Storage Service Design Points</h3><p>Aurora 设计的信条是减少前台写入的延迟。因此，它将大部分的 storage processing 移动到了后台。</p><p>Given the natural variability between peak to average foreground requests from the storage tier, we have ample time to perform these tasks outside the foreground path. We also have the opportunity to trade CPU for disk.</p><p>例如，在存储节点忙于前台写入任务的时候，就没有必要进行 GC，除非磁盘要爆了。</p><p>在 Aurora 中，后台处理和前台处理是负相关的。而传统数据库中，后台写 page 以及 checkpoint 的操作，和前台负载是正相关的。如果引入 backlog 机制，就需要限制前台的活动，从而避免队列越积压越长。相反地，在 Aurora 中，如果一个节点积压卡死了，可以通过 4/6 Quorum 模型来轻松处理：这个节点会被标注为一个慢节点，但是不影响整个系统运行。</p><p>Let’s examine the various activities on the storage node in more detail. As seen in Figure 4, it involves the following steps: </p><ul><li>(1) receive log record and add to an in-memory queue</li><li>(2) persist record on disk and acknowledge</li><li>(3) organize records and identify gaps in the log since some batches may be lost</li><li>(4) gossip with peers to fill in gaps, (5) coalesce log records into new data pages, (6) periodically stage log and new pages to S3</li><li>(7) periodically garbage collect old versions</li><li>(8) periodically validate CRC codes on pages. </li></ul><p>注意，上述的每一步都是异步的。只有 1 和 2 属于前台写入路径中，从而可能影响到性能。</p><h2 id="THE-LOG-MARCHES-FORWARD"><a href="#THE-LOG-MARCHES-FORWARD" class="headerlink" title="THE LOG MARCHES FORWARD"></a>THE LOG MARCHES FORWARD</h2><h3 id="Solution-sketch-Asynchronous-Processing"><a href="#Solution-sketch-Asynchronous-Processing" class="headerlink" title="Solution sketch: Asynchronous Processing"></a>Solution sketch: Asynchronous Processing</h3><p>每个 log record 都有一个对应的 LSN，它是单调递增的。通过它可以避免 2PC，which is chatty and intolerant of failures。</p><p>因为每个存储节点可能缺少一些 log record，所以它们会和 PG 中的其他成员 gossip，尝试 fill the holes。</p><p>下面这个不知道具体指的是什么</p><blockquote><p>The runtime state maintained by the database lets us use single segment reads rather than quorum reads except on recovery when the state is lost and has to be rebuilt. </p></blockquote><p>The database may have multiple outstanding isolated transactions, which can complete (reach a finished and durable state) in a different order than initiated. Supposing the database crashes or reboots, the determination of whether to roll back is separate for each of these individual transactions. The logic for tracking partially completed transactions and undoing them is kept in the database engine, just as if it were writing to simple disks.<br>但是在重启后，在数据库能够访问存储前，存储服务能够执行自己的 restore 逻辑。在恢复的时候，并不是关注事务，而是关注数据库能够看到一致性的存储视图。</p><p>存储服务应决定一个最大的 LSN，称为 VCL(Volume Complete LSN)。在存储恢复过程中，所有 LSN 大于 VCL 的日志都需要被截断。数据库可以进一步标记一个 CPL(Consistency Point LSNs)从而进一步截断日志。我们定义 VDL(Volumn Durable LSN)为所有副本中最大的 CPL，并且要小于等于 VCL。然后截断 LSN 大于 VDL 的所有日志。比如，即使我们有一份完整的直到 LSN 1007 的数据，但是数据库定义了 CPL 分别是 900/1000/1100，这样的话必须 truncate 到 1000。也就是 we are complete to 1007, but only durable to 1000.</p><p>因此，完整性和持久性是不同的，CPL 可以被看做一种必须被按序 accept 的存储层事务。如果客户端不关注这些区别，就可以将所有日志标志为 CPL。在实际应用时，数据库和存储服务的交互如下：</p><ol><li>数据库层的事务被分为多个 MTR，这些 MTR 是有序的，并且必须要原子地被执行</li><li>所有的 MTR 由多个连续的 Log Record 组成</li><li>MTR 的最终的 Log Record 是一个 CPL</li></ol><p>在恢复的时候，数据库询问每个 PG 的 durable point，并用它来构造 VDL。</p><h3 id="Normal-Operation"><a href="#Normal-Operation" class="headerlink" title="Normal Operation"></a>Normal Operation</h3><h4 id="Writes"><a href="#Writes" class="headerlink" title="Writes"></a>Writes</h4><p>In the normal/forward path, as the database receives acknowledgements to establish the write quorum for each batch of log records, it advances the current VDL.</p><p>分配 LSN 的规则是不能分配比 <code>VDL+LAL</code> 还大的 LSN。VDL 就是目前的 VDL，LAL 是一个常数，称为 LSN Aoolocation Limit，目前等于 10m。这个限制让数据库不会比存储系统超前太多。这样避免当存储或者网络跟不上的时候，后台压力过大导致写入阻塞。</p><p>注意，每个 Segment 只会看到对应 PG 的一个 log record 的子集。每个 log record 会附有一个后向指针，指向这个 PG 的前一条 log record。</p><p>These backlinks can be used to track the point of completeness of the log records that have reached each segment to establish a Segment Complete LSN(SCL) that identifies the greatest LSN below which all log records of the PG have been received. The SCL is used by the storage nodes when they gossip with each other in order to find and exchange log records that they are missing. </p><h4 id="Commits"><a href="#Commits" class="headerlink" title="Commits"></a>Commits</h4><p>当客户端提交一个事务的时候，线程会记录一个 commit LSN，然后将它放到事务提交等待队列中，然后就继续其他工作。这等价于 WAL 协议：当且仅当最新的 VDL 大于等于 commit LSN 的时候，事务就提交完成了。</p><p>随着 VDL 的推进，数据库识别出这些已经提交完成了的事务，通过单独的线程将提交确认返回给正在等待的客户端。而之前说的工作线程依旧不会做这样的事情，它只是不停地 pull 其他的请求，然后处理。</p><h4 id="Reads"><a href="#Reads" class="headerlink" title="Reads"></a>Reads</h4><p>Aurora 中也有一个 buffer cache。在传统数据库中，从 buffer cache 中 evict page，如果此 page 是个脏页，那么就会先 flush，然后再在 buffer cache 中替换这个页面。Aurora 并没有这种 evect 机制，但是也保证 cache 中的数据页一定是最新的版本。Aurora 的保证是只有在 page LSN 大于等于 VDL 的时候，才会去 evict 这个 page。其中 page LSN 表示最新一次对这个 page 修改的 log record 的 LSN。这个 protocal 保证了：</p><ol><li>所有对这个 page 的修改都被持久化了</li><li>在 cache miss 的时候，只需要通过当前的 VDL 请求当前 page 的 version，就可以获得最新的 durable version</li></ol><p>大部分时候的读取都不需要 read quorum。从磁盘读取时，构造一个 read-point，表示读取时候的 VDL。The database can then select a storage node that is complete with respect to the read point, knowing that it will therefore receive an up to date version. A page that is returned by the storage node must be consistent with the expected semantics of a mini-transaction (MTR) in the database. Since the database directly manages feeding log records to storage nodes and tracking progress (i.e., the SCL of each segment), it normally knows which segment is capable of satisfying a read (the segments whose SCL is greater than the read-point)，所以可以向一个有足够数据的 segment 发送读请求。</p><p>假设数据库知道所有的 outstanding reads，他就计算任意时间点每个 PG 上的 Minimum Read Point LSN。If there are read replicas the writer gossips with them to establish the per-PG Minimum Read Point LSN across all nodes. 这些值称为 Protection Group Min Read Point LSN(PGMRPL)，代表了一个 low watermark，这个 PG 上低于这个 mark 的所有 log record 都是不必要的了。换句话说，没有 read-point 低于 PGMRPL 的 read page 请求了。因此，数据库可以 advance the materialized pages on disk by coalescing the older log records and then 安全地 GC 掉它们。</p><p>实际的并发控制协议是在数据库中执行的，就好像在使用本地存储一样。</p><h4 id="Replicas"><a href="#Replicas" class="headerlink" title="Replicas"></a>Replicas</h4><p>一个共享存储卷上可以挂一个写节点以及15个读节点。【Q】不是很清楚只能挂在一个写节点是怎么做到 Vw = 4 的。</p><p>为了减少 lag，日志流在送给存储节点的同时，也会送给所有的 read replica。【Q】这个 read replica 是啥？是不是指的一种特殊类型的只读节点？</p><p>在 reader 中，数据库会消费 log 流，如果这个 log record 指向了 buffer cache 中的一个 page，就使用 log applicator 去 apply 这个特定的 redo 操作到 cache 中。否则（也就是如果不指向的话），就丢掉这个 log record。</p><p>注意，从 writer 的角度来看 replicas 是异步地消费这些 log record 的。而 writer 在处理用户的事务提交的时候，也是不管 replica 的。因此，就需要引入两条 replica 的规则：</p><ol><li>只有 LSN 小于等于 VDL 的日志才能被 apply</li><li>属于同一个 single mini-transaction 的 log record 要被原子的 apply<br> 这样才能看到一个一致的视图</li></ol><p>在实践中，每个 replica 落后 writer 只有 20ms 左右。</p><h3 id="Recovery"><a href="#Recovery" class="headerlink" title="Recovery"></a>Recovery</h3><p>A great simplifying principle of a traditional database is that the same redo log applicator is used in the forward processing path as well as on recovery where it operates synchronously and in the foreground while the database is offline. We rely on the same principle in Aurora as well, except that the redo log applicator is decoupled from the database and operates on storage nodes, in parallel, and all the time in the background. Once the database starts up it performs volume recovery in collaboration with the storage service and as a result, an Aurora database can recover very quickly (generally under 10 seconds) even if it crashed while processing over 100,000 write statements per second.</p><h1 id="Dynamo"><a href="#Dynamo" class="headerlink" title="Dynamo"></a>Dynamo</h1><p><a href="https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf" target="_blank" rel="noopener">https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf</a></p><h2 id="Intro-2"><a href="#Intro-2" class="headerlink" title="Intro"></a>Intro</h2><p>In this environment there is a particular need for storage technologies that are always available. AWS 对可用性的要求很高。</p><blockquote><p>treats failure handling as the normal case without impacting availability or performance. </p></blockquote><p>Dynamo is used to manage the state of services that have very high reliability requirements and need tight control over the tradeoffs between availability, consistency, cost-effectiveness and performance.</p><p>Dynamo 用了一些经典的技术达到高可用性和可扩展性：</p><ol><li>一致性哈希</li><li>object versioning 实现一致性<br> 给的论文是 Lamport clock</li><li>quorum-like technique 保证一致性，以及 decentralized replica synchronization protocol</li><li>基于 gossip 的分布式 failure 检测和 membership protocol</li></ol><p>它的一个贡献是介绍如何评估不同的技术对于搭建一个高可用性的最终一致的 KV 存储的作用，以及这个系统最终的适用性。</p><h2 id="BACKGROUND"><a href="#BACKGROUND" class="headerlink" title="BACKGROUND"></a>BACKGROUND</h2><p>对关系型数据库的评论：</p><ol><li>很多需要持久化状态的服务只需要主键，不需要 rdbms 的复杂功能</li><li>rdbms 的 replication 性能有限，牺牲 availbility 换 consistency。在 scale-out 和 smart partitioning 这一款不是很好</li></ol><h3 id="System-Assumptions-and-Requirements"><a href="#System-Assumptions-and-Requirements" class="headerlink" title="System Assumptions and Requirements"></a>System Assumptions and Requirements</h3><p>查询模型：简单的主键读写。1MB 左右的 blob。没有操作跨越多个 data items。</p><p>ACID 性质：不提供任何 I 的保证，只允许 single key updates。</p><p>Efficiency：满足 SLA。</p><h3 id="Service-Level-Agreements-SLA"><a href="#Service-Level-Agreements-SLA" class="headerlink" title="Service Level Agreements (SLA)"></a>Service Level Agreements (SLA)</h3><p>To guarantee that the application can deliver its functionality in a bounded time, each and every dependency in the platform needs to deliver its functionality with even tighter bounds.</p><p>客户和提供商会签 SLA 契约，里面包含了客户期望某个 API 的 request rate distribution，以及这些条件下的 service latency。比如，某个 API 在多少 QPS 下，99.9% 的请求的耗时都在 300ms 内。</p><p>下面讲述了为什么选择 P99.9 作为 SLA 的指标，就不翻译了。这个做法是基于一个 cost-benefit analysis 得到的。</p><blockquote><p>A common approach in the industry for forming a performance oriented SLA is to describe it using average, median and expected variance. At Amazon we have found that these metrics are not good enough if the goal is to build a system where all customers have a good experience, rather than just the majority. For example if extensive personalization techniques are used then customers with longer histories require more processing which impacts performance at the high-end of the distribution. An SLA stated in terms of mean or median response times will not address the performance of this important customer segment. To address this issue, at Amazon, SLAs are expressed and measured at the 99.9th percentile of the distribution. </p></blockquote><p>Dynamo 的一个主要的设计考虑是让用户来控制系统的特性比如 consistency 和 durability，并且让服务自己去在 functionality、performance 和 const-effectiveness 之间权衡。</p><h3 id="Design-Considerations"><a href="#Design-Considerations" class="headerlink" title="Design Considerations"></a>Design Considerations</h3><p>首先提了下 CAP 理论。那么对于容易发生机器和网络故障的系统来说，可用性可以通过 optimistic replication 技术提高。这种技术需要发现并且 resolve conflict changes。这个过程包含两部分：</p><ol><li>when to resolve them</li><li>who resolves them</li></ol><h4 id="when"><a href="#when" class="headerlink" title="when"></a>when</h4><p>很多关系型数据库在写入阶段处理，这样 read 的复杂度更低。这种情况下，如果写入不能到达所有或者大多数 replica 时，会被拒绝。</p><p>另一方面，Dynamo 面向一个 “always writeable” 的 data store。所以，Dynamo 会将 conflict resolution 推到 read 阶段，让 write 不被拒绝。</p><h4 id="who"><a href="#who" class="headerlink" title="who"></a>who</h4><p>如果让 data store 来做，那么选择就很有限。一般来说，只能用诸如 last write wins 这种 simple polocy。</p><p>另一方面，因为应用程序知道 data schema，所以更加适合。比如应用程序维护了客户的购物车，在遇到冲突的时候，可以选择 “merge” 购物车的内容。</p><h4 id="另外的一些-Key-priciples"><a href="#另外的一些-Key-priciples" class="headerlink" title="另外的一些 Key priciples"></a>另外的一些 Key priciples</h4><p>Incremental scalability: Dynamo should be able to scale out one storage host(后面简称为 node) at a time.</p><p>Symmetry: 每个节点的职责应该是相同的。目的是简化系统交付和运维。</p><p>Decentralization: 在过去，集中化控制导致了 outage，我们想避免。这产生了更简单，易于扩展，并且可用性更好的系统。</p><p>Heterogeneity: 系统要能利用基础设施的异构性。比如添加了更牛逼的节点之后，系统能够适配，比如给它更多的活这样。</p><h2 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h2><h3 id="Peer-to-Peer-Systems"><a href="#Peer-to-Peer-Systems" class="headerlink" title="Peer to Peer Systems"></a>Peer to Peer Systems</h3><h3 id="Distributed-File-Systems-and-Databases"><a href="#Distributed-File-Systems-and-Databases" class="headerlink" title="Distributed File Systems and Databases"></a>Distributed File Systems and Databases</h3><h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p>Dynamo differs from the aforementioned decentralized storage systems in terms of its target requirements. </p><ol><li>First, Dynamo is targeted mainly at applications that need an “always writeable” data store where no updates are rejected due to failures or concurrent writes. This is a crucial requirement for many Amazon applications.</li><li>Second, as noted earlier, Dynamo is built for an infrastructure within a single administrative domain where all nodes are assumed to be trusted. </li><li>Third, applications that use Dynamo do not require support for hierarchical namespaces (a norm in many file systems) or complex relational schema (supported by traditional databases). </li><li>Fourth, Dynamo is built for latency sensitive applications that require at least 99.9% of read and write operations to be performed within a few hundred milliseconds. To meet these stringent latency requirements, it was imperative for us to avoid routing requests through multiple nodes (which is the typical design adopted by several distributed hash table systems such as Chord and Pastry). This is because multihop routing increases variability in response times, thereby increasing the latency at higher percentiles. Dynamo can be characterized as a zero-hop DHT, where each node maintains enough routing information locally to route a request to the appropriate node directly.</li></ol><h2 id="SYSTEM-ARCHITECTURE"><a href="#SYSTEM-ARCHITECTURE" class="headerlink" title="SYSTEM ARCHITECTURE"></a>SYSTEM ARCHITECTURE</h2><p><img src="/img/dbpaper/dynamo/t1.png"></p><h3 id="System-Interface"><a href="#System-Interface" class="headerlink" title="System Interface"></a>System Interface</h3><ol><li>get(key)<br> 返回一个对象。如果有冲突版本，就返回一个对象列表。还会返回 context，从后文来看，无论返回的是对象还是对象列表，都会返回一个 context 实例。</li><li>put(key, context, object)<br> context 对调用者透明，包含了系统元数据比如 version。</li></ol><h3 id="Partitioning-Algorithm"><a href="#Partitioning-Algorithm" class="headerlink" title="Partitioning Algorithm"></a>Partitioning Algorithm</h3><p>优化了基础的一致性哈希：每个 Dynamo 节点映射到环上的多个点。</p><p>原因是存储的硬件是异构的，厉害的人可以做更多的事情。所以 Dynamo 引入了 virtual node。一个 dynamo node 可以管理多个 virtual node。</p><p>虚拟节点的好处：</p><ol><li>If a node becomes unavailable (due to failures or routine maintenance), the load handled by this node is evenly dispersed across the remaining available nodes.</li><li>When a node becomes available again, or a new node is added to the system, the newly available node accepts a roughly equivalent amount of load from each of the other vailable nodes.</li><li>The number of virtual nodes that a node is responsible can decided based on its capacity, accounting for heterogeneity in the physical infrastructure.</li></ol><h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>每个 key k 会被分配到一个 coordinator node 上。coordinator 不仅会自己存储 key，而且会将它们复制到顺时方向的后 N-1 的 node 上。所以，每个 node 实际要存储 N 个 node 上的数据。比如下图中的 node D 需要存储 (A, D] 上的数据。</p><p><img src="/img/dbpaper/dynamo/rep.png"></p><p>对于每一个 key，它被存储在多个 node 上，这些 node 形成一个 preference list。Section 4.8 会讲到如何维护这个表，现在需要知道的是为了处理 node failure 的情况，这个列表里面可能存放超过 N 个 node。</p><p>另外，使用 virtual node 的时候，可能根本没有 N 个 dynamo node 存储这 N 个 virtual node。比如一个 dynamo node 上存了几个 virtual node。【Q】我觉得也太扯了，一个 key 在同一个机器上存几份，即使是集群比较早期的状态，意义何在？Dynamo 也意识到了这个问题。为了避免这个问题，preference list 在选择节点的时候会跳过一些位置，确保 list 里面的节点在不同的物理节点上。</p><h3 id="Data-Versioning"><a href="#Data-Versioning" class="headerlink" title="Data Versioning"></a>Data Versioning</h3><p>一个 put() 可能在被 apply 到所有 node 之前就返回给 caller 了。这会导致后续的 get() 操作返回一个比较旧的 object。 如果没有网络问题，那么传递更新的耗时是有个上限的，但如果服务器宕机了，或者网络分区，那么更新就不能够及时到达所有的 replica。</p><p>很多应用程序是能够容忍这个 inconsistency 的。比如对于 shopping cart 来说，如果最新的版本没有拿到，并且客户又是基于一个旧版本进行的修改，那么这个修改依旧是有意义的，并且要被保留。当然这种保留并不是去覆盖，而更可能是 merge。注意，无论是添加到购物车，还是从购物车删除，对于 Dynamo 而言都是 put 操作。</p><p>Dynamo 将所有修改视为一个新的 immutable 的版本。也就是说允许一个对象在同一时间有多个版本。一般情况下，新版本跟随旧版本，此时系统能够知道谁是 authoritative version，我们称之为 syntactic reconciliation。但是 version branching 可能发生，比如 concurrent update 的时候出现了 failure。在这种情况下，系统不能处理，client 需要 reconcile，从而将多个 branch 坍缩回单个 version，称为 semantic reconciliation。比如 merge 购物车这样。当然，</p><p>Dynamo 使用向量时钟。一个向量时钟是一个 (node, counter) 列表。一个向量时钟和每个 object 的每个版本相关联。可以通过向量时钟判断两个 version 之间的因果性。如果在第一个 object 上的 vector clock 都不大于第二个 clock，那么第一个就是第二个的祖先。否则，就是冲突状态，需要 reconciliation。 这样 “add to cart” 操作就永远不会被丢掉，但是 deleted items can resurface.</p><p>It is important to understand that certain failure modes can potentially result in the system having not just two but several versions of the same data. Updates in the presence of network partitions and node failures can potentially result in an object having distinct version sub-histories, which the system will need to reconcile in the future. This requires us to design applications that explicitly acknowledge the possibility of multiple versions of the same data (in order to never lose any updates).  </p><p>Dynamo 中，如果 client 需要更新一个 object，就需要指定基于哪个 version 更新。这是通过从上一次 read 时候获得的 context 得到的。在处理一个 read 请求时，如果 Dynamo 可以访问多个 branch，并且不能 syntactically reconciled，就会返回所有叶子节点上的对象，以及对应的 version information。使用这个 context 的 update 会被认为是已经 reconcil 了 divergent 的 version，并且所有的 branch 都坍缩回到一个单一的 version。</p><p>下面是一个 demo。Sx、Sy、Sz 都是节点。</p><ol><li>Sx 处理写入，会自增自己的 seq，然后用它来创建数据的 vector clock，因此系统中有了对象 D1 以及关联的时钟 [(Sx, 1)]</li><li>现在 client 又更新了对象，假如说又是 Sx 来处理了，那么系统中就有了 D2 和它的关联时钟 [(Sx, 2)]<br> 注意，D2 “decendant” 了 D1，所以 overwrite 了 D1，当然有的 replica 可能认为 D1 还在，也就是没见到 D2。</li><li>不如假设此时 client 又更新了，这时候 Sy 来处理了。此时得到 D3 和 [(Sx, 2), (Sy, 1)]<br> 显然这里 Sy 知道了 D2 的存在。</li><li>假设后续<strong>另一个</strong> client 读到了 D2，然后进行了更新，由 Sz 来处理。得到了 D4 和 [(Sx, 2), (Sz, 1)]。</li></ol><p>此时，一个能看到 D1 和 D2 的 node，在收到 D4 和它的时钟之后，可以发现 D1 和 D2 是可以被覆盖的。但是如果一个节点只看到了 D3，在收到 D4 之后会发现 D3 和 D4 之间没有因果关系。这个时候，两个数据都要保留，然后给 client 在下一次读的时候做 semantic reconciliation。</p><p>假设某个 client 同时读到了 D3 和 D4，此时 context 是 [(Sx, 2), (Sy, 1), (Sz, 1)]。如果这个 client 执行了 reconciliation，并且 Sx coordinate 了这个 write（也就是 client 处理完是 Sx 负责的写入），Sx 就会更新自己的 seq，所以新的 D5 的 clock 就是 [(Sx, 3), (Sy, 1), (Sz, 1)].</p><p><img src="/img/dbpaper/dynamo/3.png"></p><p>Vector clock 的一个问题是它可能会变大，特别是有很多 server 对同一个 object 操作的时候。但是在实践中并不经常发生，因为写入通常是由 preference list 里面的 top N nodes 中的某一个处理的。在网络分区的时候，可能是某个不在 top N nodes 里面的节点处理，从而导致 vector clock 列表变长。在这种情况下，Dynamo 有一个 truncation scheme: 对于每个 (node, counter) 对，记录一个 Timestamp，表示上一次这个 node 更新的时间。当这个 vector clock 中的 (node, pair) 对的数量超过一个阈值，比如 10 的时候，最老的 pair 就会被移动出去。</p><p>当然这个会导致 reconciliation 的时候的一些不便利的情况，比如 decendant relationship 就不能被准确推断出来。但反正生产环境也没发现有这个问题。</p><h3 id="Execution-of-get-and-put-operations"><a href="#Execution-of-get-and-put-operations" class="headerlink" title="Execution of get () and put () operations"></a>Execution of get () and put () operations</h3><p>Dynamo 的任何 storage 节点都可以接受 client 的 get 和 put 请求。有两种选择 node 的方式：</p><ol><li>通过一个通用的 load balancer</li><li>如果 client 知道 partition 的信息，就可以直接请求 coordinator node</li></ol><p>第一种方式不需要了解 Dynamo 的实现，第二种可以避免额外一次的转发。</p><p>处理读写操作的节点是 coordinator。通常是 preference list 里面 top N nodes 的第一个。</p><p>读和写会涉及 preference list 中的前 N 个健康的 node。如果有 node 处于 failure 或者网络分区状态，那么 preference list 上更低 rank 的 node 就会被访问。</p><p>Dynamo 使用 RWN 协议来管理一致性。</p><h3 id="Handling-Failures-Hinted-Handoff"><a href="#Handling-Failures-Hinted-Handoff" class="headerlink" title="Handling Failures: Hinted Handoff"></a>Handling Failures: Hinted Handoff</h3><p>介绍了 Sloppy Quorum 的方案。虽然所有的读写都需要在使用 preference list 上的 top N 健康 nodes。但是它们并不一定是顺着一致性哈希那个环来的 N 个。</p><p>Consider the example of Dynamo configuration given in Figure 2 with N=3. In this example, if node A is temporarily down or unreachable during a write operation then a replica that would normally have lived on A will now be sent to node D. This is done to maintain the desired availability and durability guarantees. The replica sent to D will have a hint in its metadata that suggests which node was the intended recipient of the replica (in this case A). Nodes that receive hinted replicas will keep them in a separate local database that is scanned periodically. Upon detecting that A has recovered, D will attempt to deliver the replica to A. Once the transfer succeeds, D may delete the object from its local store without decreasing the total number of replicas in the system. </p><p>Dynamo 通过 Hinted Handoff 摆正即使有节点临时故障，读写请求也不会 fail。</p><h3 id="Handling-permanent-failures-Replica-synchronization"><a href="#Handling-permanent-failures-Replica-synchronization" class="headerlink" title="Handling permanent failures: Replica synchronization"></a>Handling permanent failures: Replica synchronization</h3><p>一些场景中，当 hinted 副本移交回原 node 之前，这个副本就不可用了，这影响持久性。Dynamo 使用一个 anti-entropy 的 replica synchronization protocol 去做到这一点。</p><p>Dynamo 使用 Merkle tree 去发现不一致。这棵树是有关哈希值的，叶子节点是每个 key 的哈希值。上层的节点是它们各自孩子的哈希值。Merkle 树可以独立检查每个分支，而不需要下载整棵树下来。</p><p>Merkle 树还能帮助减少传递的数据量。这是因为它的性质，比如如果两个树的 root 上存的 hash 是相等的，那么两棵树就是相等的。因此，就不需要传输这些数据了。如果不相等，就继续往下比较，看看是哪里的问题。</p><p>Dynamo 对 Merkle 树的具体用法是，每个 node 上为每一段 key-range（对于一个 virtual node 的范围）维护一棵独立的树。因此，node 之间是可以比较 key range 的。</p><p>当有成员变更的时候，有些 key-range 可能会变，因此对应的 Merkle tree 要重新计算。</p><h3 id="Membership-and-Failure-Detection"><a href="#Membership-and-Failure-Detection" class="headerlink" title="Membership and Failure Detection"></a>Membership and Failure Detection</h3><h4 id="Ring-Membership"><a href="#Ring-Membership" class="headerlink" title="Ring Membership"></a>Ring Membership</h4><p>管理员通过命令行或者 Web UI 的方式发起一个 membership change 命令。这个命令也会被写入 Dymano 的存储。所有的成员变动会形成历史记录。Dynamo 使用 gossip 算法来 propagate 成员变动消息，维护一份最终一致视图。</p><p>当一个 node 启动时，它会扫描一致性哈希空间中的 virtual nodes 称为 token，它会选出一些，然后 maps nodes to their respective token sets.</p><p>这个 mapping 信息是存在磁盘上的，一开始只有本地的节点，以及 token set。节点和 token set 的映射是在和 membeiship change 一起 reconcil 的。因此，partitioning 和 placement 信息也会被 propagate，让每个 storage node 都了解 token range 信息。因此，每个 node 都能把读写请求 forward 到正确的节点集合中。</p><h4 id="External-Discovery"><a href="#External-Discovery" class="headerlink" title="External Discovery"></a>External Discovery</h4><p>上述的机制可能导致暂时的逻辑分裂。</p><p>比如管理员先添加了 node A，然后立即添加了 node B，这个时候 A 和 B 都是哈希环的成员，但是却不能立即感知到对方。</p><p>因此 Dynamo 加入了种子节点，这些节点是通过外部的机制直接指定的，对所有的节点都是可知的。因为最终所有的 node 都会和种子节点通信，因此逻辑分裂是不太可能的。</p><p>种子节点可以通过静态文件，或者配置服务来获得。</p><h4 id="Failure-Detection"><a href="#Failure-Detection" class="headerlink" title="Failure Detection"></a>Failure Detection</h4><p>如果用户的请求是持续发过来的，node A 就能够快速发现 node B 不能响应了，当 B 开始无法回复一个 message 的时候。</p><p>In the absence of client requests to drive traffic between two nodes, neither node really needs to know whether the other is reachable and responsive.</p><p>Dynamo 早期有一个 decentralized failure detector 去维护一个 globally consistent view of failure state。但后面发现，explicit node join and leave 方案下，就不再需要这个 global view 了。这是因为通过这个机制，node 就能知道哪些 node 永久上线或者下线了。对于临时的 node failure，当哪个节点连不上的时候，就会独自发现了。</p><h3 id="Adding-Removing-Storage-Nodes"><a href="#Adding-Removing-Storage-Nodes" class="headerlink" title="Adding/Removing Storage Nodes"></a>Adding/Removing Storage Nodes</h3><p>当一个新的 node 比如 X 被加入到系统之后，它被分配一系列 token。这些 token 在 ring 上是散落分布的。此时，对于每个 token，有小于等于 N 个 node 已经在管理这 token 对应的 key-range 了。这些 node 中有一些就不会再管理了，要把 key-range 转给 X。</p><p>比如，X 加入 A 和 B 中间，这样 X 就会处理 (F, G], (G, A] 和 (A, X] 之间的 key 了。结果 B、C、D 节点就不需要负责对应的 range 了。Therefore, nodes B, C, and D will offer to and upon confirmation from X transfer the appropriate set of keys. When a node is removed from the system, the reallocation of keys happens in a reverse process.<br><img src="/img/dbpaper/dynamo/rep.png"></p><p>通过在 source 和 destination 之间增加一个  confirmation round，可以避免 destination node 不会收到 duplicate transfers。</p><h2 id="IMPLEMENTATION"><a href="#IMPLEMENTATION" class="headerlink" title="IMPLEMENTATION"></a>IMPLEMENTATION</h2><p>前面略。主要介绍下 write coordination。</p><p>如前面所说，write 请求会被某个 top N nodes 来 coordinate。尽管我们希望去选择 first node，从而将所有的 write 都写到同一个地方，但这会导致不平衡的 load distribution。因为请求本身就不一定是均匀分布的。因此，preference list 中 top N 的任意节点都是可以被返回的。特别地，因为每个 write 请求通常是在一个 read 请求之后的，所以 write 的 coordinator 通常会选择上一次 read 中回复最快的那个 node。</p><p>这样的优化还能使得下一次读取的时候，这个节点更容易被选中，提高了 read-your-writes 一致性的概率。</p><h2 id="EXPERIENCES-amp-LESSONS-LEARNED"><a href="#EXPERIENCES-amp-LESSONS-LEARNED" class="headerlink" title="EXPERIENCES &amp; LESSONS LEARNED"></a>EXPERIENCES &amp; LESSONS LEARNED</h2><p>Dynamo 的最大优势是客户可以通过调节 N、R、W 来达到期望的性能、可用性和持久性等级。</p><p>AWS 最常用的 Dynamo 集群是 (3, 2, 2) 的。</p><h3 id="Balancing-Performance-and-Durability"><a href="#Balancing-Performance-and-Durability" class="headerlink" title="Balancing Performance and Durability"></a>Balancing Performance and Durability</h3><p>Since Dynamo is run on standard commodity hardware components that have far less I/O throughput than high-end enterprise servers, providing consistently high performance for read and write operations is a non-trivial task. The involvement of multiple storage nodes in read and write operations makes it even more challenging, since the performance of these operations is limited by the slowest of the R or W replicas.</p><p>在一些场景下，用户愿意牺牲持久性去换取更高的性能。此时，每个 storage node 可以维护一个 object buffer。每个操作会先存在 buffer 中，然后通过一个 writer 线程去写入到 storage 里面。这个优化可以将峰值流量期间的 P99.9 下降到原来的 1/5，并且只需要一个存放 1000 个对象的缓存即可。从图中还能看到，write buffering 能够对 P99.9 进行平滑。</p><p>当然，这种情况下，只需要一个节点挂掉，那么对应缓存里面的没有落盘的数据就消失了。To reduce the durability risk, the write operation is refined to have the coordinator choose one out of the N replicas to perform a “durable write”. Since the coordinator waits only for W responses, the performance of the write operation is not affected by the performance of the durable write operation performed by a single replica. </p><p><img src="/img/dbpaper/dynamo/5.png"></p><p>【Q】这里的意思我理解照样是写 W 个结果就返回了，写盘的那个节点很慢，但是我们不一定需要它成为那 W 个中的一个，我理解是这样。</p><h3 id="Ensuring-Uniform-Load-distribution"><a href="#Ensuring-Uniform-Load-distribution" class="headerlink" title="Ensuring Uniform Load distribution"></a>Ensuring Uniform Load distribution</h3><h3 id="Divergent-Versions-When-and-How-Many"><a href="#Divergent-Versions-When-and-How-Many" class="headerlink" title="Divergent Versions: When and How Many?"></a>Divergent Versions: When and How Many?</h3><p>从实验上来看，导致版本分叉增多的原因并不是故障，而是并发写数量的增加。</p><h3 id="Client-driven-or-Server-driven-Coordination"><a href="#Client-driven-or-Server-driven-Coordination" class="headerlink" title="Client-driven or Server-driven Coordination"></a>Client-driven or Server-driven Coordination</h3><p>每个 Dynamo 节点都可以充当 read coordinator，但是只有 preference list 中的 node 才能当 write coordinator。这是因为这些 node 可以生成一个 version stamp，从而 causally subsumes the version that has been updated by the write request. 特别地，如果 Dynamo 的 versioning scheme 是基于物理时钟的，那么任何的节点都可以 coordinate 一个写入请求了。当然我个人理解就需要要原子钟那一套了。</p><p>另一种 request coordination 的方式是将 state machine 移动到 client node 上。客户端阶段性请求一个 Dynamo 节点，获取 membership 状态。这样的好处是能减少一跳。另一个重要的优势是，不再需要一个 load balancer 去均匀分发客户的负载了。</p><p>这个方案的劣势是 membership 不一定是最新鲜的。</p><h3 id="Balancing-background-vs-foreground-tasks"><a href="#Balancing-background-vs-foreground-tasks" class="headerlink" title="Balancing background vs. foreground tasks"></a>Balancing background vs. foreground tasks</h3><p>To this end, the background tasks were integrated with an <strong>admission control mechanism</strong>. Each of the background tasks uses this controller to reserve runtime slices of the resource (e.g. database), shared across all background tasks. A feedback mechanism based on the monitored performance of the foreground tasks is employed to change the number of slices that are available to the background tasks.</p><p>The admission controller constantly monitors the behavior of resource accesses while executing a “foreground” put/get operation. Monitored aspects include latencies for disk operations, failed database accesses due to lock-contention and transaction timeouts, and request queue wait times. This information is used to check whether the percentiles of latencies (or failures) in a given trailing time window are close to a desired threshold. For example, the background controller checks to see how close the 99th percentile database read latency (over the last 60 seconds) is to a preset threshold (say 50ms). The controller uses such comparisons to assess the resource availability for the foreground operations. Subsequently, it decides on how many time slices will be available to background tasks, thereby using the feedback loop to limit the intrusiveness of the background activities. Note that a similar problem of managing background tasks has been studied in [4]. </p><h1 id="Wisckey"><a href="#Wisckey" class="headerlink" title="Wisckey"></a>Wisckey</h1><p><a href="https://dl.acm.org/doi/pdf/10.1145/3033273" target="_blank" rel="noopener">https://dl.acm.org/doi/pdf/10.1145/3033273</a></p><h2 id="Intro-3"><a href="#Intro-3" class="headerlink" title="Intro"></a>Intro</h2><p>LSM 相对于其他索引结构的优点是它为写操作提供了顺序访问。B 树上的更新可能包含很多随机写入，在 HDD 和 SDD 上的效率都不高。</p><p>为了支持有效率的查询，LSM 需要在后台进行 compaction，让 key-value 对们是 sorted 的。因此这带来了 50x 甚至更高的写放大。</p><p>在 HDD 上，随机 IO 比顺序 IO 慢了 100 倍，因此 performing additional sequential reads and writes to continually sort keys and enable efficient lookups represents an excellent tradeoff.</p><p>SSD 和 HDD 存在不同：</p><ol><li>SDD 上顺序写和随机写的差异不如 HDD 那么大<br> 因此，执行大量的顺序 IO，从而避免后续的随机 IO，可能会浪费不少带宽</li><li>SSD 的 internal parallelism 很高</li><li>SSD 会因为反复写入磨损，LSM 的写放大会降低寿命</li></ol><p>WiscKey 被设计来解决 SSD 上的这些问题。WiscKey 是键值分离的，键在 LSM 树上保持有序，Value 单独存在一个 log 中。换句话说，WiscKey 解耦了 key sorting 和 GC，而 LevelDB 将它们打包在了一起。这减少了在 sort 的时候移动 value 的写放大。特别地，这也减少了 LSM 树的大小，减少了 device read 的数量，也能让 lookup 的时候 cache 的效果更好。</p><p>这存在一些挑战：</p><ol><li>range query 的性能会收到影响，因为 value 不再是有序存储的了<br> 在 <a href="https://docs.pingcap.com/zh/tidb/stable/titan-overview" target="_blank" rel="noopener">Titan</a> 的评测中，可以从 scan100 和 scan1000 中明显看到这一点。特别是小行宽、扫描行数多的情况下，Titan 劣势明显。<br> WiscKey 的方案是利用了 SSD 的冗余的 internal parallellism。</li><li>WiscKey 需要 GC 去回收 invalid 的 value<br> 它提出了一个轻量级的 online GC。它只需要顺序的 IO，对前台影响很有限。</li><li>Key value 分离让 crash consistency 更有挑战性<br> WiscKey 利用了现代文件存储中的一个特性，也就是 append 操作永远不会在崩溃的时候产生垃圾数据。</li></ol><h2 id="BACKGROUND-AND-MOTIVATION"><a href="#BACKGROUND-AND-MOTIVATION" class="headerlink" title="BACKGROUND AND MOTIVATION"></a>BACKGROUND AND MOTIVATION</h2><h3 id="LSM"><a href="#LSM" class="headerlink" title="LSM"></a>LSM</h3><h3 id="LevelDB"><a href="#LevelDB" class="headerlink" title="LevelDB"></a>LevelDB</h3><h3 id="Write-and-Read-Amplification"><a href="#Write-and-Read-Amplification" class="headerlink" title="Write and Read Amplification"></a>Write and Read Amplification</h3><p>Write (read) amplification is defined as the ratio between the amount of data written to (read from) the underlying storage device and the amount of data requested by the user.</p><p>LSM 写放大高的原因是从 Li-1 层合并到 Li 层的时候，LevelDB 最坏情况下要读取 Li 层的全部 10 个文件，并在排序后重新写回 Li 层，从而产生 10 倍的写放大。</p><p>LSM 中存在两种读放大：</p><ol><li>读一个 KV 的时候，LSM 可能要查询多个层级<br> Tier 层的 8 个文件加上 Leveled 层每一级的一个文件，总共可以是 14 个 SST 文件最多</li><li>在 SST 中查找 KV，要读取多个元数据块<br> 包含 index block + bloom-filter block + data block。<br> 例如，查找 1KB 的键值对，要读 16KB 的 index block，4KB 的 bloomfilter 和 4KB 的 data block，总共 24KB。</li></ol><p>两个开销加起来，读放大能到 336。更小的 KV 会产生更高的读放大。</p><p>如下图所示：</p><ol><li>写放大随着数据库大小增加的原因是从低 level 到高 level 压缩会多次写入。因为高 level 被 compact 了，文件平均数通常小于最坏情况的 10 个，因此没有达到最劣的情况</li><li>对于大数据来说，如果读取涉及到多个 SST 文件，而内存又不够存储所有的 SST 文件的 index block 和 bloom-filter，那么每次读取都会造成开销。</li></ol><p><img src="/img/dbpaper/wisckey/1.png"></p><p>It should be noted that the high write and read amplifications are a justified tradeoff for hard drives. As an example, for a given hard drive with a 10ms seek latency and a 100MB/s throughput, the approximate time required to access a random 1K of data is 10ms, while that for the next sequential block is about 10μs—the ratio between random and sequential latency is 1,000:1. Hence, compared to alternative data structures such as B-trees that require random write accesses, a sequential-write-only scheme with write amplification less than 1,000 will be faster on a hard drive. On the other hand, the read amplification for LSM-trees is still comparable to B-trees. For example, considering a B-tree with a height of five and a block size of 4KB, a random lookup for a 1KB key-value pair would require accessing six blocks, resulting in a read amplification of 24. </p><h3 id="Fast-Storage-Hardware"><a href="#Fast-Storage-Hardware" class="headerlink" title="Fast Storage Hardware"></a>Fast Storage Hardware</h3><p>不同于 HDD，相比于顺序读取，随机读取性能在 SSD 上的表现更好。特别是如果随机读取是并发被执行的话，对于某些 workload 来说，总的 throughput 甚至能接近顺序存储。<br><img src="/img/dbpaper/wisckey/5.png"></p><h2 id="WISCKEY"><a href="#WISCKEY" class="headerlink" title="WISCKEY"></a>WISCKEY</h2><p>复读了一遍 intro。</p><h3 id="Design-Goals"><a href="#Design-Goals" class="headerlink" title="Design Goals"></a>Design Goals</h3><p>WiscKey 是一个单机的 persistent KV Store，从 LevelDB derive 出来。提供了类似 LevelDB 的 Put、Get、Delete 和 Scan 接口。</p><p>设计的主要目标：</p><ol><li>Low write amplification<br> 避免浪费带宽、减少寿命。</li><li>Low read amplification<br> 避免降低吞吐、低效缓存。</li><li>SSD optimized</li><li>Feature-rich API</li><li>Realistic key-value sizes</li></ol><h3 id="Key-Value-Separation"><a href="#Key-Value-Separation" class="headerlink" title="Key-Value Separation"></a>Key-Value Separation</h3><p>对于一个有 16Bytes 大小的 key，1KB 大小的 value，key 写放大 10，value 写放大 1 的 WiscKey 来说，总的写放大是 <code>(10 * 16 + 1024) / (16 + 1024) = 1.14</code>。</p><p>WiscKey 较小的读放大能提高性能。虽然需要一次额外的 IO 去取 value，但是因为 WiscKey 上的 LSM 要更小，所以一次查询可能只会搜更少的 SST 文件。进一步的，LSM 的一部分甚至可以被缓存在内存里面，因此一次查询可能只需要一个随机读用来取回 value。</p><p>WiscKey 的架构如下所示。<br><img src="/img/dbpaper/wisckey/6.png"></p><p>当用户写入 KV 的时候，value 首先被写入 vLog，然后 key 被加入 LSM，附带上 value 在 vLog 上的信息 <code>&lt;vLog-offset, value-size&gt;</code>。删除一个 key 只需要在 LSM 上删除就行了。在 vLog 中的 value 会在稍后被 GC 掉。</p><p>在读取时，首先读取 LSM 的地址，然后到 vLog 里面找 value。</p><h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h3><h4 id="Parallel-Range-Query"><a href="#Parallel-Range-Query" class="headerlink" title="Parallel Range Query"></a>Parallel Range Query</h4><p>为了使 scan 更高效，WiscKey 需要利用 SSD 的并行 IO 特性去 prefetch vLog 中的 value。</p><p>如果 user 请求一个 range 查询，Scan 会返回一个迭代器。WiscKey 会跟踪这个 range query 的 access pattern。一旦它开始请求一个 contiguous sequence of KV pairs，WiscKey 会开始顺序地从 LSM 读取一系列 key。因此，对应的 value 地址会被添加到队列里面，多个线程会从 vLog 中并行地获取这些 value。</p><h4 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h4><p>在 LSM 的 compaction 中，WiscKey 不会同时回收 value。</p><p>一个简单的从 vLog 回收的方式是，首先扫描 LSM 拿到所有有效的 value 地址，然后 vLog 中没有被 LSM 引用的 value 就会被回收掉。显然这个方式很重，最关键的是，它只能适用于 offline 的场景。</p><p>WiscKey 的方案需要引入一个小的 data layout 变动。在存储 value 的时候，同时也要存储对应的 key。也就是 <code>&lt;key size, value size, key, value&gt;</code>。</p><p>WiscKey 的思路是让 valid 的值在 vLog 中处于一个连续的区段内。在这个区段的一端，也就是 head 的位置，是新的 value 被 append 的地方。在这个 range 的另一端，也就是 tail 的位置，是 GC 开始释放空间的位置。只有在 head 和 tail 之间包含了 valid 的 value 的部分，才可能在查询中被访问。<br><img src="/img/dbpaper/wisckey/7.png"></p><p>在 GC 时，WiscKey 首先会从 tail 读取一个 chunk，比如几个 MB 的 KV 对，然后会查询 LSM 树，看这些 key 是否被删除了。然后 WiscKey 会将 valid 的 key 添加回 head 位置。最后，它更新 tail 的位置，并释放空间。</p><p>为了避免 GC 过程中丢失数据，WiscKey 需要保证新 append 的 valid 的 value 和新的 tail 首先被 persist，然后才能真的去 free 掉 space。WiscKey 的方案是：</p><ol><li>在 appending the valid values to the vLog 之后，GC 会调用一次 fsync</li><li>将这些新的 value 的地址和当前的 tail 同步地写入 LSM 中<br> tail 在 LSM 中存放的格式是 <code>&lt;tail-marker, tail-vLog-offset&gt;</code>。</li><li>最后，在 vLog 中回收空间</li></ol><h4 id="Crash-Consistency"><a href="#Crash-Consistency" class="headerlink" title="Crash Consistency"></a>Crash Consistency</h4><p>WiscKey 保证了和 LSM 树同样的 crash guarantee，原因是利用了现代文件系统的一个特性。考虑一个文件包含了 <code>b1 b2 b3 ... bn</code> 这样的序列，然后后续 append 了 <code>bn+1 bn+2 bn+3 ... bn+m</code> 这些序列。如果发生了 crash，恢复后，会看到 <code>b1 b2 b3 ... bn bn+1 bn+2 bn+3 ... bn+x</code> 这样的序列，并且 x 是小于 m 的。也就是说，实际被添加的只可能是前缀，不可能是某个随机字节，或者多出来添加某些序列。进一步又可以推论，如果 X 在 vLog 中因为 crash 丢失了，那么所有在 X 之后被添加的也会丢失。</p><p>如果 key 在系统 crash 的时候丢失了，如果是 LSM 里面找不到的情况，会按照 LSM 的模式来处理。即使 value 已经被写进去了 vLog，它也可以在随后被 GC 掉。但是如果 LSM 中能找到key，就需要额外步骤。首先 WiscKey 会查询 value 的地址是否在 vLog 的有效范围，也就是 head 到 tail 这个区间内。如果不在，就说明 value 在系统崩溃中丢失了，从 LSM 中删除 key，并且通知用户 key 不存在。</p><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><h4 id="Value-log-Write-Buffer"><a href="#Value-log-Write-Buffer" class="headerlink" title="Value-log Write Buffer"></a>Value-log Write Buffer</h4><h4 id="Optimizing-the-LSM-Tree-Log"><a href="#Optimizing-the-LSM-Tree-Log" class="headerlink" title="Optimizing the LSM-Tree Log"></a>Optimizing the LSM-Tree Log</h4><p>LSM 的 log 中存放了 key 和 value。WiscKey 中 LSM 的 log 只存 key 和 value 的地址。进一步地，vLog 也会记录被插入了的 key，从而更好支持 GC。</p><p>如果在 key 在被持久化到 LSM 之前 crash 了，它们可以从 vLog 中被扫描从而恢复。但简便的做法需要扫描全部的 vLog 才能会的结果。为了减少这一点开销，WiscKey 会定期在 LSM 中记录 vLog 的 head：<code>&lt;head-marker, head-vLog-offset&gt;</code>。【Q】这里可以对比看下记录 head 和 tail 的不同原因。当一个数据库被打开之后，WiscKey 会从最新的 head 开始扫描 vLog，直到 tail。因为 head 被存储在了 LSM 树里面，所以 LSM 就 inherently 能够保证被插入 LSM 的 key 可以按照插入的顺序恢复，从而满足 crash consistency。</p><p>因此，从 WiscKey 中移除 LSM 的 WAL 是一个安全的优化。</p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><h4 id="空间放大"><a href="#空间放大" class="headerlink" title="空间放大"></a>空间放大</h4><p><img src="/img/dbpaper/wisckey/19.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;这篇文章中，包含 Greenplum、Aurora、Dynamo、WiscKey。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>2024 挪威冰岛西班牙</title>
    <link href="http://www.calvinneo.com/2024/10/11/2024_norway_iceland_spain/"/>
    <id>http://www.calvinneo.com/2024/10/11/2024_norway_iceland_spain/</id>
    <published>2024-10-11T01:23:25.000Z</published>
    <updated>2024-11-12T08:49:34.270Z</updated>
    
    <content type="html"><![CDATA[<p>OSLO -&gt; BERGEN -&gt; ICELAND -&gt; BACELONA</p><a id="more"></a><h1 id="挪威"><a href="#挪威" class="headerlink" title="挪威"></a>挪威</h1><h2 id="D0-奥斯陆"><a href="#D0-奥斯陆" class="headerlink" title="D0 奥斯陆"></a>D0 奥斯陆</h2><p>到了奥斯陆，看了下 vy 发现末班车只有不到一个小时了，而现在行李还没拿，以为要来不及了。没想到这里贼方便，行李转盘5分钟就取到了，然后出门就是火车站。我们甚至在倒数第二辆 vy 发车之后一分钟买到了它的票。担心没赶上这车就不能坐了，于是问了个路人小姐姐。路人说她虽然没有试验过，但这是列车公司的错误，导致我们买到了已经出发的列车，因此他们不应该因为这个事情去为难我们。后面我们又问了旁边 flytoget 站台上的工作人员，她和我说只要在某个时间区间范围内乘坐就行了，我们只需要赶上末班车就行。<br>于是上了个厕所就早早下到了站台上。</p><p>宾馆就在车站对面。这个时候路上只有不多的行人了，火车站广场边有一群滑板男孩。这边人过马路是真的不看红绿灯，红灯会亮两盏都拦不住他们。</p><p>我们只需要出示 passport 就可以入住了。这个酒店没有 self service 的 laundry 了。这个房间特别奇葩，一进门右转就是一段下楼的阶梯，上面的玄关连我的大箱子都放不下。<br>这里床是两个小窗拼成的双人床，被子也是一个人一个。窗户对着街道，被用白色塑料布全封住了，但这样还是有不少的噪音。</p><p>这里的水一股苦杏仁味，所以我们没怎么喝。卫生间的墙上贴着告示，说要我们刷牙的时候关水龙头，可以节约多少多少水。</p><h2 id="D1-奥斯陆"><a href="#D1-奥斯陆" class="headerlink" title="D1 奥斯陆"></a>D1 奥斯陆</h2><p>今天在奥斯陆 city walk，顺便逛逛各个场馆。<br>我们的餐厅是有早饭的，并且品种相当丰富，我觉得应该是在西班牙前最丰富的了，取餐区也特别大。</p><p>吃完早饭，打算先逛大教堂，但是大教堂没开门，于是就先买点东西吧。我们买了点巧克力和鱼子酱，完了发现旁边的药妆店还没开门。Anyway，最后我们买了点护肤品，但是很遗憾忘了要退税票了。然后我们就跑去喝 oslo 那边有名的咖啡，我点了个 flat white，我对象点了个那边有特色的咖啡。结果我的 flat white 平平无奇，我对象的咖啡挺好喝的，不过冰块占了很大一部分。我们还点了两个甜点，甜甜圈一样的里面有蛋液，挺香的，另外一个肉桂卷也很好吃，但是太甜了。吃完了刚好可以逛大教堂，这个教堂不是很大，我们很快就出来了。接下来去市政厅，中间路过了奥斯陆的中央公园，以及挪威的皇宫。奥斯陆市政厅在海边，那边游客是比较多的，我们需要排队过一个安检通道才能进去。这边是很多挪威人结婚来的地方，我们遇到了先前在马路上的一对穿着似乎是民族传统服饰结婚的一对情侣，进去之后，在大台阶上，还有另一对情侣也在拍照片。市政厅里面主要是壁画很好看，另外还能看到奥斯陆市议会的房间。</p><p>看完之后，就往奥斯陆美术馆走了，但中途对象发现太阳帽丢了，这可是她赖以生存的宝贝，于是就去市政厅找。结果刚过了安检通道就出来了，看来人家安检员早就在等她了，一眼认出，还和她 say goodbye 了。</p><p>奥斯陆美术馆需要将包和外套都存放在地下室里面的 locker 里面。奥斯陆美术馆会给一个简易的导览地图，上面列出了一些很奇怪的作品。美术馆包含三层楼，很多个房间。这些房间是通过一个两位数阿拉伯数字来标号的，没有一个特别好的一笔画线路，所以瞎逛是 OK 的。</p><p>美术馆有个露台是很值得打卡的地方，景色优美，但是风吹有点冷。露台旁边有一个青砖小屋，好像什么当地野人住的一样。</p><p>从美术馆出来，沿着海边走，打算去吃大众点评上排名第一的餐馆。挪威是真的不爱挂自己的国旗，一路上看到了各种旗子，单单没看到挪威的。餐馆需要排队，但是如果愿意坐在外面，就可以少排队很久。那为啥不坐在外面享受太阳呢？我们点了生蚝、牛舌、鱼汤以及 fish &amp; chips，总的来讲都挺好吃的。生蚝比较小，比较腥，但是它的那个酸溜溜的调味汁很爽口，我们渴了一天，所以很喜欢。鱼汤里面还有其他海鲜，鱼肉好像是大块的三文鱼，吃起来很鲜嫩，但是不是很腥。汤是奶油汤，但不是很腻。fish &amp; chips 意外得很好吃，鱼比较大，也很嫩，外面炸的不是特别腻。总的来说这边菜还是比较清淡新鲜爽口的。</p><p>吃完饭，就走路去奥斯陆歌剧院和蒙克美术馆了，它们都在海滨。我们穿过 oslo 火车站就能走到。拍歌剧院最好的角度是在海湾的对面，需要小走一段路。我惊讶地发现居然这个天气还有人下海游泳。</p><p>尽管奥斯陆歌剧院的内部除了大厅是不给上的，但是它的屋顶是可以上的，我觉得是一个玩滑板的好地方，但是我去的时候没有人在玩。据说奥斯陆专门立法规定在屋顶上玩滑板出了事情的话是责任自负的。在歌剧院屋顶上可以看到海湾，以及奥斯陆城区的建筑，包括大教堂。近处是一些比较现代的建筑，例如德勤的楼。尽管如此，因为屋顶不是特别的高，所以更好的角度是蒙克美术馆，尽管美术馆会隔着一层玻璃反光。</p><p>奥斯陆歌剧院是个很好的地方，因为它不仅有厕所，里面的 cafe 还能提供免费水。相比之下，蒙克美术馆里面的免费水在我们想去打的时候，人家就说他们关门了，打不到。进入蒙克美术馆同样是需要存东西的，然后会乘坐扶梯直接上到4楼。蒙克的呐喊有三张在这里，每个半小时展出一张。更高的楼层上有陈列蒙克的超大画幅的画作，蒙克的版画等。在版画馆中，我们还可以尝试亲手拓印一些蒙克的画作。再往上的楼层就很抽象了，有一层在播放很神秘的音乐，还有一层在展示北欧的现代艺术。有个蒙克实验室，但是目前还不开门，很遗憾。在顶层，我们可以看到夕阳西下的风景，并俯瞰整个奥斯陆的湾区。</p><h2 id="D2-奥斯陆-弗洛姆"><a href="#D2-奥斯陆-弗洛姆" class="headerlink" title="D2 奥斯陆 - 弗洛姆"></a>D2 奥斯陆 - 弗洛姆</h2><p>早上起来发现昨天买的巧克力放在暖气片上都化掉了。加上发圈也掉了，于是紧急到旁边的 24 小时超市重新买了点。那些化掉的巧克力后面发现状况并不是那么严重，并且我们自己也吃了不少。</p><p>前往 oslo 火车站开启挪威缩影。我们乘坐的火车是前往明天的目的地 Bergen 的，但我们需要在中间站 Myrdal 下车，乘坐 Flam 的高山小火车去 Flam，然后第二天再在 Flam 乘船。事实证明这一段路程是很艰苦的，并且很缺水。我中途去买了一瓶水，居然花了不到五十块钱，这也太贵了。火车会从 oslo 往南先开到 dremen，然后往西北绕回去开到 honefoss，最后到达 Myrdal。这趟火车推荐坐在左侧，虽然在一开始会在右侧看到一片大湖，但在从 Finse 开始，左边会看到雪山和大湖，其实更漂亮。当然，想拍照片的话就比较难，因为路上会经过很多隧道。</p><p>我们的火车是晚点的，但实际上 Flam 的火车会等一会。我们提前了一会就在车门口边等待，被旁边的女士叫住说不要挡到厕所里面的人出来。然后我们就聊开了，这个人也去过中国，然后她就说中国火车站很挤，大家不得不在下车前就挤在出口 blabla，大家看来都不太喜欢这一点。</p><p>攻略上会建议 Flam 小火车坐在 7 还是 8 号车厢，但这是不必要的，因为经过那个瀑布的时候火车会停下来让我们下车看几分钟。而关键的是坐到靠窗的位置，因为从 Myrdal 到 Flam 的下坡路，能够在很短时间内看到深切的峡谷，以及下面的河流或者草地。并且即使坐靠窗，我们还是得站起来，才能从窗户打开的小缝中看到风景。火车玻璃太脏了。</p><p>不知道是不是枯水季的缘故，那个瀑布看起来着实不怎么样。比较有意思的是，瀑布上还有个人在放着音乐跳舞。</p><p>相比于瀑布，我们身边的那个外国小姐姐似乎更想要看到 black church，在一上车就往我们这边的方向凑，希望能找到它。我们的小火车最终要达到 Flam 的时候，她兴奋地喊叫，说看到了这个教堂，我们顺着她手指的方向也看到了。它被一圈墓碑包裹着。</p><p>Flam 面对一个小海湾，这个海湾中停了一艘特别大的游轮，游轮的烟囱还一直在冒烟。第二天走的时候，游轮还在，我怀疑它是不是一直搁浅在这里当做酒店用的。</p><p>在弗洛姆的酒店我觉得是非常好看的，无论是从外立面，还是里面的装饰而言。吸引我的是它靠门的一个斗柜，看着特别有年代感。然后是它的窗户，正好对着 Flam 的海湾，特别好看。卫生间是上个世纪的风格，浴缸，镀金的莲蓬头，温度需要手动调节 Cool 和 Hot 的比例。马桶圈也是木头的，和小时候的类似，上面还顶了个水箱。甚至在我们 check in 的时候，它居然有 laundry room，但进去之后发现它只有一台烘干机和两台洗衣机，我果断放弃了洗衣服的念头。</p><p>我们放完行李，就准备出去走走。到了游客中心，发现有一个比较好的项目是一个观景台，可以看到峡湾。很遗憾的是，三点半和四点半的车票都各自只剩下一张了。我们在前台咨询，他们建议我去 el-tour.no 这个网站上看看，说这是另外一家公司，也许它还有票。但是我试了下，发现它好像也是 sold out 状态，我甚至看不到出发时间。剩下来的方式，就是去租一个 e-car 开过去，我们考虑是山路，就放弃了这个想法。最终决定去 Flam culture park 看看。</p><p>走到最后也没看到 culture park 是什么样子，因此决定还是去 black church 吧。实际上这段路也很好走，路上没有什么特别波澜壮阔的风景，这里特指 hiking 指南上列出的一些瀑布都不是很壮观。这边的气候很舒服，适合徒步。下午的阳光不是很刺眼，照在近处的青山和远处的雪山上呈现不同的色彩。草地很绿，很多牛、马，但主要还是羊在吃草。路上是各种羊屎，我对象基本上都能准确命中。走到 black church 还是挺远的，但是路上风景还是不错的，也能看到附近村民的生活。比如回去的路上看到有人就下班开车到家了，隔壁的老爷爷摘了个树上的苹果，还分给邻居吃。</p><p>酒店前台，我们问了路书上推荐的那家餐厅，酒店说只有餐厅自己对应的酒店才能预定，因此我们只能自己去排队了。点了两个啤酒，我的那个好像叫 honey 啥的，比较酸。我对象的颜色深一点，比较类似于黑啤。这个餐厅让我想到那种小酒馆，一楼除了吧台之外就是一张张桌子，大家端着酒在聊天。中间有一个圆形的坑，在边缘安装了座椅，坑的中央放了个火炉，这样大家可以围着火炉坐着聊天。招待我们的是一个非常 E 的老外，长得好像那种披发下来的骑士，当然肯定是没穿戴甲胄的。他和我们说要排 40min 多，然后就在本子的第二行写下了 LUO。我们很快发现这是一个比较尴尬的事情，因为他说等他大声喊（然后我不得不在一片嘈杂声中大声喊出我的姓的正确读法）到的时候，我们就跟着他上二楼。</p><p>只点了几个菜，因为据说这家店分量很大。有一个品酒套餐挺好的，因为我们已经喝过酒了，所以可以去掉酒，还便宜点。里面包含了好几样小菜，包含我想尝试的鹿肉。</p><p>吃完饭出来，天还没有完全黑。走出来路过纪念商店也没有关门，这商店牌子上居然还有中文。</p><h2 id="D3-弗诺姆-卑尔根"><a href="#D3-弗诺姆-卑尔根" class="headerlink" title="D3 弗诺姆 - 卑尔根"></a>D3 弗诺姆 - 卑尔根</h2><p>早上不到七点就下到二楼吃早饭了。从四楼到二楼走的是一个木质的台阶，我觉得非常有感觉。二楼有几张座位是靠着酒店的玻璃屋顶的，于是一边吃就可以一边看远处的晨光越来越亮。他们家有不少奶酪，我都尝了下还不错。我对象觉得都很腥。我还尝了下羊奶，感觉没啥感觉。倒是那个长得像山楂水的还挺好喝的。这边的 porriage 也挺好吃。</p><p>这一路上遇到了不少人，昨天看到的不少人，比如一个台湾的大叔。我们也遇到了不少人后面也见到了，比如上船的时候唯一排在我们前面的深圳过来的三姐妹，她们在前面说要怎么怎么坐，我们就在后面偷听，然后跟着她们学。我们选择的是船尾的那几个沙发，但是进门的时候需要放行李，所以我放的时候，另一个人就得去把位置占了。确实视野是比较好的，但松恩峡湾最好的还是站在船前进的那一面看，而这就需要出去吹冷风了。</p><p>船舱里看到一个阿姨，在凑着拍，于是我邀请她坐在我位置上拍。结果她说自己也是中国人过来的，好像是找了个当地的导游。她说这边的很多瀑布是有水的，但是最近好像是枯水季，就都不是很壮观。然后她又用英语和她的同伴介绍中国三峡，说这边让她想到了三峡。她还说她的向导的哥哥就是这峡湾半边山的主人，因为挪威这边很多东西是私有的，并且只传给男性长子，所以他哥哥就得继承。但这却不是件好事，因为政府会强制所有者投入资金去保护这些地方，而对应的，这些山又不是很赚钱。他哥哥说已经赔了三百万克朗进去了，现在特别想换职业去打渔，那才挣钱。</p><p>我们船的客舱在底层，内饰相当的舒服，有很软和深的沙发。中间还有个小吧台，这是十分必要的。从前进方向可以出去直面寒风，然后从船舷的两侧可以走到船尾一个更高的平台上，然后从这个平台又可以往前进方向走，最终走到客舱的屋顶上。太冷了，对象买了杯热可可，发现那边居然是自助结账。</p><p>船开了一个半小时，我看左边好像是一个水湾这个时候船开始往右边停靠，难道已经到终点了么？转念一想，这水堆积在那里怎么流出来呢？果然，那边是一个很小的村子，几个人从船上下来，大家朝他们挥手致意，然后船就往那个水湾开了过去，然后水湾就慢慢朝远处延伸，我们仍有一段路要走。</p><p>这时候我们就走在了雪山之间，两侧的岩壁很陡峭，可以看到植被很明显的分层现象，直到最终的雪顶。</p><p>卑尔根真的是很小的城。我们先去吃了鱼饼，那感觉是一个非常重要的路口，因为后面我们去各种地方都会看到这个鱼饼店。这个鱼饼感觉就和老家的鱼圆一个感觉，但不是市面上买的那种比较清淡的鱼圆，而是我外婆烧的那种味道浓厚一点的。然后就去吃了热狗，热狗店就在卑尔根的缆车旁边，所以我们就去买了缆车票。但随后我们发现还没到五点，而卑尔根可能要七点多才日落，所以就打算先出去晃下。</p><p>我急着上厕所，就去人字屋旁边有个城堡那边上免费厕所。看起来那是卑尔根大公住过的城堡，并且是可以进去的，我们计划明天也许能过来看看。后面我们在人字屋那边花了很长时间拍照，然后重新赶到了缆车那边。这个时候人就比较多了，我们前面有两组四五个人没有选择进入即将出发的缆车，而是希望能够等到下一趟。这样可以坐到最下面的车厢的最前面，从而看到最好的风景。我们也就跟着等，当然下一趟列车第一排的位置也是轮不到我们的。于是我就突发奇想问前面的貌似是印度来的小哥我坐到台阶上会不会影响到他们。他们说请不要坐在这，然后又热情地把我招呼下来，说那是个玩笑。</p><p>到了山顶，接近六点了。我们赶快找那个商店买卑尔根的冰箱贴，结果到了发现门打不开。绕到侧面发现里面灯亮着，又绕到正门，发现里面有两个人在收拾东西，顿感不妙。招呼了下，她们打开门，果然下班了。气氛突然变得比较难受，因为我对象认为只有这个商店才有可移动的缆车的冰箱贴，但我坚持认为这种工业制品不至于只有一个地方有。在随后的五分钟，我们贴着窗玻璃左右走动来回观察，但即使这样，也没看到店里那里有我们想要的冰箱贴。我觉得这种工业化的制品不可能只在山顶一个地方有，但是我对象不相信，很沮丧。</p><p>无论如何，只能在山顶逛逛，等日落了。这个山顶还是比较大的，上面有好几家餐厅，有一个餐厅位于高处，外面是一个瞭望台。从瞭望台往缆车方向走有一个信标，上面特地用乌克兰国旗标注了基辅的方位和距离。瞭望台的另一个方向往前走就是很多山羊放养的地方，这些山羊都被打了特殊的标记用来识别。山羊都很懒，趴在地上不怎么运动，它们似乎已经习惯了游客和它们合照了。</p><p>从山顶下来我们就没有特地选择缆车的位置，但天也确实比较晚了。下来之后，发现大部分商铺都关门了，我们可能明天才能找哪些店有冰箱贴了。</p><h2 id="D4-卑尔根-雷克雅未克"><a href="#D4-卑尔根-雷克雅未克" class="headerlink" title="D4 卑尔根 - 雷克雅未克"></a>D4 卑尔根 - 雷克雅未克</h2><p>卑尔根机场十分小，进去之后就一个厅，从一头到另一头估计两三分钟就能走到。我们的冰岛航空似乎是严格按照 2h 提前值机的，所以虽然队已经排有点长了，但柜台一个工作人员都没有。我们在最左边的一号柜台站着，成为靓丽的风景线。</p><p>我的箱子重 21.9 KG，感觉很快就要爆了，这还是我已经把羽绒服啥的穿上的情况，看来去冰岛要抓紧时间吃点东西了。</p><p>卑尔根机场的巧克力最后还有一包了。</p><h1 id="冰岛"><a href="#冰岛" class="headerlink" title="冰岛"></a>冰岛</h1><h2 id="D0-雷克雅未克"><a href="#D0-雷克雅未克" class="headerlink" title="D0 雷克雅未克"></a>D0 雷克雅未克</h2><p>从卑尔根飞雷克雅未克的飞机依旧是很满的，感觉这边上客率真的很牛。到了 KEF 发现机场是一团阴湿的雾气，要我说就像伏地魔来了的感觉。我们还必须要坐摆渡车才能到机场，非常折腾。到了机场发现它似乎很乱，排队上飞机的人把我们到达的走廊挤得只剩一半的宽度了。我们走了比较远才遇到一个厕所，但里面的设施是非常干净整洁的，也是北欧一直给我的印象。</p><p>我们需要出机场，才能走到专门去租车公司那里的摆渡车乘坐点。我们的 Alamo 公司是在摆渡车的最后一站，进去之后发现他们生意有点好啊，里面已经有了不少人在等待了。我们需要取号，排在我们前面的是四个中国留子，有一个人看起来英文比较好，并且也来过一次冰岛，所以他在讲解什么是 pre paid fuel，大概就是先付一箱油的钱，这样回来的时候就可以不用加满油了，然后租车公司会给你一个折扣。然后大家就开始算至少油表要干到多少才不赔钱。不一会，他们就被一个很健谈的大叔叫过去了，大叔非常热情，讲解了大概有十分钟至少，我们很希望他能帮我们办租车，这样驾照问题应该能被 cover 住。但显然他们花了很长时间，所以不一会一个小姐姐上任并叫到了我们的号。</p><p>租车的过程异常顺利，我们担心的不少东西基本没有发生。租车公司只是检查了下驾照复印件就同意加上了 secondary driver，但是她也强调，只是对他们是 OK 的，但是警察不一定。她祝愿我们好好开车，不要被警察抓到。租车公司是非常贴心的，他们会给你一个小册子，里面记录了很多关键的内容，包括汽车加什么油。一般来说，都是汽油车，加绿色的 95 号汽油。她还建议我们下一个 safe travel 软件，因为只有它是及时更新路况的。</p><p>开回来的路上，发现 google 地图的驾驶导航功能没有很明显的超速提醒，也没有摄像头提醒，于是我对象找了半天，下了另外一个叫 weez 的软件。不过它也好不到哪里去，至少在离开冰岛的时候我还没有根据它的提示去判断超速。另外，我们汽车的仪表盘倒是很智能，会告诉你当前路段的限速是多少。</p><p>一路开过去，一路上基本没有任何红绿灯，有交叉口的地方都是用的环岛来替代的。但虽然说是环岛，基本另一条道路都是很窄的，去往某个村庄，或者人迹罕至的某个地方的路，很少有车会去那里。</p><p>我们大概五点一刻出发的，当时是多云微雨。我感觉我在开往世界末日。旁边都是黄草，远处是很低的乌云，仿佛笼罩着什么山，我想肯定是某个火山吧。开了一段，公路会经过海边，这个时候我第一次看到了城镇，我想那可能就是雷克雅维克了。后面的路感觉起伏更大一点，我感觉在上坡和下坡。再往前开，环岛变多了。后面开始有小型的立交桥，路也从单车道变成双车道，再变成高速公路那样子。这里立交桥还是挺有意思的，下了高速，就是一个上坡，坡上一个红绿灯，很多车都在那边等开到别的路上。最后，我们似乎到了这一条高速的尽头，需要在一个由红绿灯管控的路口左转，这是我第一次看到红绿灯。</p><p>开到了希尔顿，它的停车场已经快停满了，我们好不容易才找到一个车位。</p><h2 id="D1-斯奈山半岛"><a href="#D1-斯奈山半岛" class="headerlink" title="D1 斯奈山半岛"></a>D1 斯奈山半岛</h2><p>早上从雷克雅未克的希尔顿出发，就往草帽山走。</p><p>这边开车给我造成了相当的困扰。首先是路比较窄，在离开雷克雅维克不久，所谓的一号公路就变回了双向两车道了。我的车又比较大，我总觉得我不是太靠左就是太靠右。野外的限速是 90，但会车的时候感觉一股气流从身边掀过，如果遇上了大车，那可能方向盘都吃劲。于是我总是躲着靠右边开，但总容易开到路肩上，轮胎声音都不一样了。天气也是一个原因，比如在某个地方，我甚至看到远处有个像龙卷风一样的东西，我很担心自己是不是要走那边走。但真的开到那边时，发现只是一团雾气了。所幸有素质的司机占了绝大部分，我只遇到一个开着脏兮兮面包车的司机在超我车之后迅速并线，感觉就是擦着我的车过去的。在这个事件过去不久，就遇到了传说中冰岛个位数数量的测速摄像头之一，我当时正在控制车速，突然发现前面有一个灰色箱子，并且正在朝我迅速靠近。测速摄像头！我赶快一脚刹车下去，速度瞬间往 40 走了。但我距离摄像头太近了，不知道有没有拍到。</p><p>海豹沙滩是此行的最东边了，下车的时候风非常冷，还带点小雨星。我们要先走到收费亭那边交费，然后再往下走到沙滩上。这个沙滩特别地脏和腥臭，上面堆满了海带或者鱿鱼带子一类的东西。海豹是不会上岸的，它们会在离岸边十几米左右的地方露着一个头泡着水，或者一个猛子扎进去游泳。</p><p>这个小镇中似乎只有一个酒店，一个餐厅，还有几家咖啡馆。这个小镇是邻着海湾和悬崖的，也算是一个景点了。我们的酒店只有一排房子，显得非常小，穿过门厅就是餐厅，过了餐厅就是客房。这边没有房卡只有钥匙。给我们准备了一盘巧克力。</p><p>晚上出门打算寻找极光，发现餐厅和门厅里面一个人都没有，门厅里面的猫也不知所踪，这场景不得不说有点害怕，加上四周又很安静，我觉得很有恐怖片的感觉。推开大门，外面风特别大和冷，还下着雨，看来今天晚上是没有极光了。</p><h2 id="D2-黄金圈"><a href="#D2-黄金圈" class="headerlink" title="D2 黄金圈"></a>D2 黄金圈</h2><p>早上从海德纳尔弗斯的酒店起来时候天还没亮。这家餐厅是有早餐的，种类相比挪威的要少一点，毕竟它的备餐桌也很小。这边的煮鸡蛋是冷的，让人很遗憾。</p><p>出门的时候还是要死人的天气，走到一半阴雨绵绵。我们到一家 N1 加油站加油，里面一个人都没有。</p><p>但不知何时起，太阳就当空高照，冰岛瞬间就不一样了。在路上，我甚至能拍到几十公里外雷克雅未克的大教堂。</p><p>我们的第一站是辛格韦德利国家公园，但风景在离开一号公路走到 36 号公路的时候就开始了。当时还下了一点小雨，我们以为又到了之前那种阴森的环境中。但不一会，之前一直见到的黄草、绿苔藓的景色就消失了，现在眼前多了很多红色以及绿色的植物，就连草也变成了更加明亮的黄色。它们组合在一起，就形成了三原色，让这片区域生机勃勃。再过了一会，就看到了一片大湖，可能就是辛格韦德利湖了。我们要绕半圈这个湖，到它的另一侧，也就是国家公园，沿途有几个观景点，都是用来看湖的，我们没有过多停留。</p><p>到了国家公园，映入眼帘的是很现代化的游客中心，以及冰岛国旗。相比挪威，冰岛人更喜欢悬挂自己的国旗。后面了解到，这个公园比较大，有很多个停车场，游客中心所在的停车场是在一片高地上，旁边就是一个观景台，可以看到后面我们要游览的大部分地方。站在观景台上往下看，根本不知道这些是啥，感觉就像一片湿地或者滩涂，往右边延伸就是辛格韦德利湖了，不恰当的很像千岛菜花。在这片滩涂中，有很多行人在 hiking，我们很疑惑这边有啥好走的？高地的两边都可以往下走，我们看到左边是有人上来，右边也就是靠着观景台的那一边大部分人在往下走，于是觉得这是一个环状线，跟着往右下去了。实际上这个公园非常乱，最后要走不少回头路。</p><p>往下走两侧是峡谷，峡谷两侧的岩壁非常不同。左边高大陡峭，整体很光滑，但是岩面也很多，在一些缝隙之中长了不少草。右边就低并且平缓很多，岩面有更多的向外的凸出，上面长满了青苔。听说这公园和裂缝有关，难道这一边是美洲的，一边是欧洲的？右边还有一些小路，可以往里走一小段，看的是之前看过的滩涂的风景，没有什么意思。回归到大路上往下走，坡度比较大。到达前方，是一面冰岛国旗，后来才知道，这里是冰岛唯一一个文化遗产，因为世界上第一个国会阿尔廷就是在这里形成的。再往下走，就到了滩涂上了。我们对它并不是很感兴趣，就继续沿着路往前走，这时候会路过第二个停车场和厕所。</p><p>住的 selfoss 的酒店相比昨天的显得特别现代感，也有好几层楼，并且它就靠着 1 号公路。可惜它的后院停车位比较少，我们应该是抢到了最后一个停车位。我们向酒店询问极光叫醒服务，她秒懂并指着桌上的一个本子，上面已经密密麻麻登记了很多房号。她说如果有极光的话，在酒店的后院就能看到。我们的房间在三楼，望北，但可惜路对面还是有建筑和树木遮挡，并不能直接看到海。</p><p>小猪超市在 selfoss 的另一端，但是酒店旁边有个 K 记超市，所以我们去逛了下。 冰岛的物价并不是很离谱，树莓和蓝莓都不是很贵，我们还买了一些薯片和酸奶。</p><p>夜里又是定了闹钟起来。走下楼发现前台值班换成了一个光头男，他在电脑前面点一堆表格一样的东西。我们问他极光的事情，他说这个谁也不知道，至少酒店外面是看不到的。我们从后院出门，在小镇四周绕了一圈，也没有看到，就会宾馆准备睡觉。这个时候遇到一车人，他们似乎是刚追完极光回来。里面一个妹子说他们追到了，并给我们看了照片。她说是在 selfoss 南边的荒地里面追到的，但现在可能不一定有了。但我们决定一试，把车开出酒店，发现路边都停满了车，万一我们没追到极光回来又丢了车位，那就可太惨了。</p><p>我们开了十分钟来到南边的田地里，找了个“停车场”（实际那不是停车场，只是丁字路口方便转弯多修的一块路肩）停下。车子的左侧应该是西方，是万里晴空，可以看到除了猎户之外的其他很多星星，以及银河。车子的右侧也是什么都没有，只能看到一团雾气包裹着白色。我们花了几分钟才意识到这可能就是极光，在群里一问才知道，极光不强的时候就是白色的，用手机拍是绿色的。这里我尝试用了 iPhone 的长曝光 3s，发现确实是绿色的，边缘还带点黄。但肉眼看，最多只有淡绿色。如果不开长曝光，拍出来就是一团黑。在半夜两点左右的时候，我们迎来了一波比较强烈的极光，尽管颜色还不是呈现绿色，但它们有了形状。在 20 分钟之后，这些形状又消散，变回了一团雾气。我们等到三点不到就回去了。</p><p>到了宾馆，只剩下了残疾人车位和电动车车位，不过宾馆说电动车车位也是可以停的。</p><h2 id="D3-维克"><a href="#D3-维克" class="headerlink" title="D3 维克"></a>D3 维克</h2><p>selfoss 酒店的早餐比前一天丰盛很多，取餐区也能围成一个圈了。他们家的土豆胡萝卜豇豆大乱炖、洋葱炒啥的，以及臭鱼烂虾挺好吃的。</p><p>第一站塞里雅兰瀑布开了一个小时就到了，但太阳还是非常晒。</p><p>第二站是斯科加瀑布。这个瀑布比塞里雅兰要大不少，但是人也非常多。我们到的时候停车场已经满了，被带到旁边一个停车的地方，离瀑布有点远。但尽管如此，瀑布还是远远就能看到。我们顺着左侧瀑布流成的小溪往前走。</p><p>在右边有个阶梯可以爬到顶上，非常高。爬上去后，还可以往前走很远。</p><p>拍了不少照片，还是很难找好角度，身体全湿透了。打算去找路书上说的贼好吃的炸鱼薯条，却发现路边的餐车今天似乎没开。旁边有几家店，装修还是比较豪华的，进去也没发现有特别好吃的，就走了。出来还白嫖了一趟厕所，因为外面的要钱。</p><p>从黑沙滩回来还有一阵，我们打算先去 Orkan 加油，顺便去旁边的 K 记超市买点东西。我们把车停在 K 超市东边的停产场上，一下车，这海上刮来的风就把车门咵地扯开了。很是后怕，因为租车保险是不赔车门被挂飞了的。相比下，这个超市就很 nice 了，它是 ice wear 和 K 记的结合体。我赶快去上了个厕所，黑沙滩可把我憋坏了。在 ice wear 店里面我看到了小红书里面讲的廉价版火山石冰块，它看起来一点不像火山石，而更像大理石地砖给切开得到的东西。外面的木头盒子也特别廉价，我就没有买。</p><p>check in 的时候说他们的 hot tap 坏了，我们以为是没有热水，后来才发现他说的可能是那个桑拿房坏掉了，我们洗澡是有热水的。这个酒店的钥匙特别古怪，非常的大。我们住的九号房间离 reception 不是很远。</p><p>到酒店坐了一阵觉得没啥意思，就打算出发去 yoda 洞。</p><p>晚上九点半起来去宾馆门口看了下，发现风特别大，还有点小雨，觉得又没戏了，就回去睡觉。晚上十点半再起来，发现地图上居然又橙色区域了，而维克碰巧在云区的边缘。我对象就像开车往 selfoss 方向走，比如开到塞里雅兰可能也就一个小时。十点五十左右，我在小红书上找到一个塞里雅兰瀑布附近看到极光的妹子，她说那边刚才确实是大爆发，但是现在已经没了。</p><p>一路上我在用手机追踪极光，在某个方向上，确实可以看到一团云雾一样的极光，但是不成形状。我们大概开到斯科加瀑布那里拐进去停在路边，发现那边也有一些追极光的人。</p><p>开车回来路上发现一直在松的左眼镜片掉下来了，吓我一跳。最终发现原来是某个螺丝掉了。于是我打算用晾衣绳系一下。没想到后面在放杯子的地方重新找到了这个螺丝，也是运气好。</p><p>另外，这一天也是多灾多难的，因为我的小米手表的胶水干掉了，表盘也掉下来了。</p><p>路过维克镇已经过了12点了，路上居然遇到了警察在查酒驾。果然要求出示驾照，我们只好说晚上出来追极光，in a hurry，驾照忘在酒店了，但是有电子驾照。警察说 it’s OK with me，但是法律要求要随身带驾照的，然后就做了酒驾测试。结尾我对象还问了句你们这么晚还要出来工作么，他说是的。</p><h2 id="D4-冰川徒步、冰河湖游船"><a href="#D4-冰川徒步、冰河湖游船" class="headerlink" title="D4 冰川徒步、冰河湖游船"></a>D4 冰川徒步、冰河湖游船</h2><p>今天起得特别早，但我们还是混到了大概六点五十，于是决定不如就去简单吃点早饭。这个宾馆的早饭还是不错的，特别是它的臭鱼烂虾，有一种味精超标的鲜，以及一溜溜酸味。但是既不腥也不臭。</p><p>据说是昨天的风沙太大了，所以昨天的冰川徒步改到了今天上午十点，也就是我们的场子。结果上来看，我们是一个大团队坐了一辆大巴车，然后被分成三个小团队，一个小团队有十来个人这样，估计体验上会比较差。实际上体验还好，可能是我们攀爬的冰川本来就是比较简单的，因此没有人出现什么状况。此外，向导会有很多时间讲解，并且也会让我们排队拍照，所以冰川上不是特别乱。</p><p>我们早早就到了，这个时候，9.30 的人还在排队上厕所准备入场。这个厕所比较简陋，里面没有卫生纸。因为人很多，厕所只有两个，所以要排非常长的队。所以，它实际上对徒步完之后的游客不是很友好，我们最后是到冰河湖上的厕所。冰川徒步必须穿 boots，其他的什么鞋子都不行，包括我的护踝也不管用。</p><p>大巴车只能停在距离冰川很远的地方，我们需要走一段不到半个小时的有苔藓覆盖的路，然后走到一片湖前面。再往前就是一片煤灰一样的地，然后是陡峭的和煤灰一样的坡，以及坡上面的白色冰川。我的鞋带中间还开了，进了不少沙子，特别难受。在这里大团队被分成了三个小组，我们的领队是一个妹子。在这里我们停留了许久，学习如何穿戴冰爪。首先她带领我们一步步穿上右边的脚，然后我们就自己把左脚给穿上，最后一个个给她检查。我们大概花了至少二十分钟在上面，直到导游脱下了她的防寒服放到包里，我暗叫不好，估计穿多了。</p><p>在真正看到蓝冰洞和白色冰川前，我们要爬一个陡峭的像煤灰一样的坡，向导说其实这个已经是冰川了。我用爪子挠了下地面，发现“煤灰”下面是灰黑色的冰块。因为人特别多，所以我们在蓝冰洞门口要排队，这个时候赶紧脱掉衣服了。今天是晴天，方才在集合点的时候，太阳还没晒到，因此特别冷，我穿了两条单裤和一条棉毛裤，上面是羊毛衫和羽绒冲锋衣。而实际上冰川上太阳一直晒着，就会特别热，我把羊毛衫脱掉了。相比之下腿晒不到，还是可以忍受的。</p><p>我们的第一站就是蓝冰洞，这是一个特别小的蓝冰洞，一两分钟就可以穿过去了。但是里面的冰是特别的蓝，还能看到气泡。冰洞是先往下的，然后陡然向上。旁边有锁链供我们搀扶。</p><p>出了蓝冰洞，就到了肉眼可见的冰川上了，到处是白白的一片，在强大的阳光的照耀下，非常刺眼，我的墨镜起到了非常大的作用。</p><p>从冰河湖游船上下来，就疯狂往羽毛大峡谷赶路。因为纬度比较高，羽毛大峡谷那里日落比冰河湖要晚个几分钟，但我们依旧是在日落之后一刻钟才到达羽毛大峡谷，距离 last light 只有半个多小时了。所幸最后还是赶上了，然后就是往坡上冲刺。但令人宽慰的是这个时候还有不少人在往上面走。因为我们是十月份去的，这个时候草基本已经枯黄了，水位也不是很足，所以感觉上没有图片看到的那么惊艳。但羽毛大峡谷比斯科加瀑布上游的河流要崎岖狭窄很多，两侧的崖壁的形态也更加夸张。还有很多嶙峋的石柱在河道中间升起，像是被侵蚀出来的一样。</p><p>尽管羽毛大峡谷的正经停车场那条路封了，我们实际上是往左走岔道下到的另一个停车场，但这也不影响要交费。好在大峡谷上坡的地方修了个厕所，旁边就有个交费的亭子，不然用那个 parka 软件就非常麻烦了。回程的路上，我们甚至可以看到一队青年男女刚刚上山，我们怀疑是专门露营看极光的。不过我可不敢在这种地方露营，因为开回 1 号公路的时候，我相信我看到了一头狼在旁边的旷野上走路。</p><p>晚上住在黑沙滩酒店，它离黑沙滩贼近，风也贼大，我们黑漆马虎地开了好一段没灯的路才到那里。它的规模很大，散落在黑沙滩上有很多个小房子，我们被分在 46 号。理论上是可以直接开车到房间门口的，但因为车位满了，所以只能拖着大箱子走了很远。<br>房间的门很简陋，看起来像卫生间的门一样，但进去发现是非常豪华。首先它居然有一套厨房，并且厨房里面的餐具、微波炉、冰箱、咖啡机都是全的，虽然唯独缺了烧水壶。然后它有一个露台，在露台上就可以看极光。<br>我们很快就看到的极光，大家都很开心。对面的小房子里面的学生们开心地吼了出来，我对象也开心地撞到了玻璃门。这比我们在 selfoss 看到的极光要强很多了，它横跨整个天空，并且有了很明显的绿色。在十点左右，它甚至有一部分在缓慢地动。因为今天的 KP 是 7，所以我们期望后续有极光盛宴，但实际上十点半左右极光就消散了，并且维克出现在了 Aurora 软件的绿带之外。<br>晚上定了无数个闹钟，醒来很多次，发现基本都是这个卵样了。后续发现今天的绿带非常地小，感觉完全配不上 KP 7。感觉刚才我们看到的极光也就是在北面的，后面极光带往北再移动维克就彻底看不到了。甚至早上看到在加拿大时候的极光带也是特别小，看来果然 max possible KP 不等于实际的 KP。</p><h2 id="D5-雷克雅未克"><a href="#D5-雷克雅未克" class="headerlink" title="D5 雷克雅未克"></a>D5 雷克雅未克</h2><p>我们大概十点半出点头就到了雷克雅未克的大教堂，这次我们停在了靠近正面的停车场，很不幸，后来发现这里似乎要交费。更加不幸的是，当我们想要登塔的时候，门被拦住了，里面准备做弥撒于是就不让进了。我们后面还有观鲸，于是只能退而求其次，去 city walk。吃了个叫 braud 的面包，旁边的 reykjavik roasters 点了两杯咖啡，然后我们就往湖那边走。白天的托宁湖确实不是那么阴间了，白天鹅和鸭子还是在打架或者抢食。</p><p>大概十二点一刻左右，我们就到了观鲸那边的停车场，然后走到那个红房子里面取票。剩下来的时间就是在码头上等待，我们是第二组到的。</p><p>趁着他们争论的间隙，我问了向导几个问题，顺便缓解尴尬。我问这些鲸鱼都是有名字的么，向导说 humpback whale 是有的，但是 minke whale 太多太小了，所以就没有。那是如何认出来的呢？向导给我看了下她的照片，原来是可以从尾部的花纹认出来。另外它们的背鳍也不太一样。所以看鲸鱼真的要带大炮过去，不然很难拍清楚鲸鱼长什么样子。</p><p>看完鲸鱼立马往教堂赶。最后居然赶上了。</p><p>我们很早就从雷克往 KEF 开了，目的是抓紧时间赶紧洗完车，还完车，然后出去看极光，顺便可能可以在 KEF 镇上看看日落。实际上当我们开到 KEF 镇上那个自称为 self host 的 N1 加油站时，发现它的洗车关门了。墙上写了一行字，说是搬到了某个别的地方。于是只能去小红书上搜了下，说有个两个 b 打头字母的地方可以自助洗车，但首先要去 olis 加油站买洗车币。我们开到了附近一个 ob，但是它关门了。看起来不得不去更远的那个 olis 了。但路上我们决定先经过那个很两个 b 打头的地方看看是怎么回事。谢天谢地那里还是开着的，并且有四个库房可以洗车，有两个黑哥哥似乎在洗出租车，我上去问了下。他们说就是在那个两个 roundabout 之外的 ob 有洗车币卖，我们只要买 20 分钟就行了。我们看了下隔壁的库房，里面一个枪头还在滴水，看起来也可以白嫖一下？无论如何，还是多一事不如少一事去那家店买了。看起来这个 olis 和 ob 两个牌子似乎是一家的，我进去买了 2 个十分钟的洗车币，居然要 120 rmb 这样，也太贵了，有点后悔。</p><p>重新回到那里，天已经黑了。我担心别的可能是坏的，所以开到黑哥哥原来用的库房，下来投币，发现这个洗车贼高端。它有四个旋钮，1 会从喷枪里面喷出汽油一样的东西，用来去污垢，2 会从高压水枪里面喷出肥皂水清洁，3 是会从一个拖把里面喷水，可以刷脚垫啥的，4 是清水或者可以打蜡。这一套流程下来，10分钟确实不够用。</p><p>又回去 N1 加油，把汽油滴到了我的衣服上，这个味道好冲，我不禁有点担心明天安检能不能过了。</p><h2 id="D6-KEF"><a href="#D6-KEF" class="headerlink" title="D6 KEF"></a>D6 KEF</h2><p>KEF 机场真的是离谱。</p><p>排到二楼才能看到刷登机牌的地方。我们通过时发现几个人没法刷登机牌再走人工通道，等到转过弯排队安检时又遇到了他们。他们正在和一个貌似是台湾人争论，他们说他们的飞机很早就 last call 了，希望能去 front desk 去问问。但是台湾人认为是在插队，很严厉地拒绝。在经过我的时候，我让他们从我前面进入队列，并且和对向的白人小姐姐沟通，让他们绕过围栏插了过去。后续这帮人往前走，激起了另一组白人以及原来台湾人的讨伐。</p><p>过安检，果然我们的包又被分到了要人工检查的那一边了。安检人员拿着我的 ipad 仔细瞧了瞧，贴了下爆炸物检测纸就放我走了。我担心的没有发生。过了安检就是免税店，那里没有我要的火山石冰块。问了工作人员，他们非常热心，还给我出来指方向。但是他们的口音确实比较重，我模糊中只能听到是 “something rocks” 这家店。所以只能跟着小红书上面的印象，往 C 口走。</p><h1 id="西班牙"><a href="#西班牙" class="headerlink" title="西班牙"></a>西班牙</h1><h2 id="D0"><a href="#D0" class="headerlink" title="D0"></a>D0</h2><p>巴塞罗那的天气比我想象中还要热。</p><h2 id="D1-巴塞罗那"><a href="#D1-巴塞罗那" class="headerlink" title="D1 巴塞罗那"></a>D1 巴塞罗那</h2><p>我的那个酒看着像巧克力或者中药，喝起来是酸甜的，但是也带着一股药草味。</p><h2 id="D2-巴塞罗那"><a href="#D2-巴塞罗那" class="headerlink" title="D2 巴塞罗那"></a>D2 巴塞罗那</h2><h2 id="D3-巴塞罗那"><a href="#D3-巴塞罗那" class="headerlink" title="D3 巴塞罗那"></a>D3 巴塞罗那</h2><p>巴塞罗那机场的退税要方便一些了。只需要在一台机器上扫描一个退税单，就可以登记所有的退税单了。然后就可以去旁边的柜台办理。有两个选择，一个是获得一个 coupon，但是只能在机场免税店里面购买，另一个是直接获得欧元现金。我选择了现金，这个还是比较合理的，因为后面发现免税店里面其实没有什么可以买的。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;OSLO -&amp;gt; BERGEN -&amp;gt; ICELAND -&amp;gt; BACELONA&lt;/p&gt;</summary>
    
    
    
    
    <category term="游记" scheme="http://www.calvinneo.com/tags/游记/"/>
    
  </entry>
  
  <entry>
    <title>C++ 内存监控方案</title>
    <link href="http://www.calvinneo.com/2024/08/23/monitor-alloc-in-C++/"/>
    <id>http://www.calvinneo.com/2024/08/23/monitor-alloc-in-C++/</id>
    <published>2024-08-23T01:23:25.000Z</published>
    <updated>2024-12-19T16:32:23.312Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 C++ 上的内存监控方案。</p><p>默认使用 jemalloc。</p><a id="more"></a><h1 id="MemoryTracker"><a href="#MemoryTracker" class="headerlink" title="MemoryTracker"></a>MemoryTracker</h1><p>原理是每次分配内存的时候，manually 去向⼀个 MemoryTracker 注册。下层级的 Tracker 和上层级的 Tracker ⼀起组成树状结构。</p><h1 id="prof-dump"><a href="#prof-dump" class="headerlink" title="prof.dump"></a>prof.dump</h1><p>可以定期通过 prof.dump 的方式 dump 下堆文件。<br>需要配置 MALLOC_CONF 为 <code>prof:true</code>，否则会报错 Resource temporarily unavailable。可以设置 <code>prof.activate:false</code> 避免在不需要 profile 的时候，产生开销。</p><p>注意，<code>prof:true</code> 是不可以运行期修改的。但是 <code>prof.activate</code> 是可以的。</p><h2 id="有关-dl-iterate-phdr-的死锁"><a href="#有关-dl-iterate-phdr-的死锁" class="headerlink" title="有关 dl_iterate_phdr 的死锁"></a>有关 dl_iterate_phdr 的死锁</h2><p>在 <a href="https://github.com/tikv/pprof-rs/pull/85/files#diff-65a1ed4903a387e1d45937ab46e839563c38fc24dc6be2c8e7ae021621c3b0da" target="_blank" rel="noopener">Rust</a> 中因为 <code>Backtrace::new()</code> 会调用 <code>dl_iterate_phdr</code>，而这个函数会调用 mutex。如果一个 signal 在获得这个锁之后过来，就会死锁。在 tikv 中，很容易就会调用到 <code>Backtrace</code>，特别是在有错误的时候。在 <code>_Unwind_Backtrace</code> 中，也会调用这个锁。对应的 libunwind 的 <a href="https://github.com/libunwind/libunwind/issues/16" target="_blank" rel="noopener">issue</a>。</p><p>解决方案是在 prof-rs 中禁用掉 <code>[&quot;libc&quot;, &quot;libgcc&quot;, &quot;pthread&quot;, &quot;vdso&quot;]</code> 这几个库的 unwind。</p><h2 id="有关-dwarf-下-prof-变慢"><a href="#有关-dwarf-下-prof-变慢" class="headerlink" title="有关 dwarf 下 prof 变慢"></a>有关 dwarf 下 prof 变慢</h2><p>【这里几个图在我的破 QQ 文档里面我就懒得放了】<br>事情的起因是无论是手动调用 profile 还是自动进行的 continuous profiling，预期 10s 的 profile 时，实际会花一分钟左右，从而将 status_server 线程卡住而无法处理 prometheus 的 http 请求。<br>经过加日志断点，发现时间主要花在生成火焰图上，耗时约 40s。<br>观察生成火焰图的火焰图，发现花费大量时间在 miniz_oxide 上。<br>后面发现这个错误在 frame pointer 上不存在。当然 frame pointer 上有 bug，所以我们对于 x86 统一换成了 dwarf。另外，如果我们将 TiFlash 的压缩 debug section 去掉，耗时也会显著减少。这个是在 cmake/tiflash_linux_post_install.cmake 里面 –compress-debug-sections=zlib-gnu 来清理的。但去掉之后，binary 大小是原来的三倍，所以去掉也不是长久之计。<br>去掉之后发现是 addr2line 耗时比较多。这里发现有个 do_rallocx 函数，对应了 Report::pprof 中将符号入栈的操作。它花了不少时间。<br>这从而也启发到我同事，说可以比较下 dwarf 拿到 backtrace 和 frame pointer 的栈的深度。可能 dwarf 拿到的栈会深很多（比如 inline 的函数可能能拿到），所以从地址转换成符号花的时间更长。这个比较下来，实际上两个栈差不多大。<br>然后同事发现，在 <a href="https://github.com/tikv/pprof-rs/blob/1f4ef0991dc780ed11dc17954a38d0a3abd59c61/src/report.rs#L72" target="_blank" rel="noopener">https://github.com/tikv/pprof-rs/blob/1f4ef0991dc780ed11dc17954a38d0a3abd59c61/src/report.rs#L72</a> 处一个循环耗时很高，循坏一千多次花费四十多秒。<br>进而进入 Frames::from 中，这里根据 dwarf(即 bracktrace-rs) 或者 framepointer 实现，会选择不同的 Frame 实现。而在 backtrace 中的 resolve_frame 中会先读 mapping_for_lib，这是个 cache，如果 cache 不够才会读别的。<br>这里我怀疑可能是因为 dwarf 里面 symbol 比较多，然后 cache 被 evict 掉了。<br>根因应该是 dwarf 的 backtrace 深度比较深，涉及的 so 会更多，而 backtrace-rs 里 lib cache 最多只有4个，所以 dwarf cache miss 会比较频繁，需要不断地对 so 的 debug_section 解压缩和 addr2line。<a href="https://github.com/rust-lang/backtrace-rs/issues/499%E3%80%82" target="_blank" rel="noopener">https://github.com/rust-lang/backtrace-rs/issues/499。</a></p><p>发现其实如果用 addr2line 去读 heap，耗时也会很长，感觉还是和 binary 的压缩有关。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root      986545  1.8  0.1 520308 515644 pts/32  S+   17:39   0:16 perl ./jeprof --add_lib bin/tiflash/libtiflash_proxy.so --add_lib bin/tiflash/libgmssld.so.3 --svg bin/tiflash/tiflash jeprof.910766.14.i14.heap</span><br><span class="line">root      988390  0.0  0.0   7120  3460 pts/32   S+   17:40   0:00 sh -c addr2line -f -C -e 。。。/libtiflash_proxy.so -i &lt;/tmp/jeprof986545.sym</span><br></pre></td></tr></table></figure><p>另外，binutils 也要升级，不然会出 invalid or unhandled FORM value 0x25 错误。</p><h1 id="Jemalloc-allocatedptr"><a href="#Jemalloc-allocatedptr" class="headerlink" title="Jemalloc allocatedptr"></a>Jemalloc allocatedptr</h1><p>这个方案要求感知线程的创建和销毁，在对应的时候，通过 <code>thread.allocatedp</code> 和 <code>thread.deallocatedp</code> 来注册。这样就可以知道每个线程分配或者释放了多少内存。<br>该⽅案能够很好看到内存分配和释放的速率和增量，例如如果观察到 allocated 斜率⼤幅增加，则说明该线程最近在⾼速分配内存。但难以判断某个线程到底 own 了多少内存，原因是：</p><ol><li>⼀个线程可能释放另⼀个线程分配的内存。例如同一个模块中线程 bg-1 分配的内存可能被另⼀个线程 bg-2 释放。</li><li>Rust 的 move 语义和协程机制会加剧这个问题。</li></ol><p>其实 allocatedp 这个调用是成对的，还有一个 <code>thread.allocated</code> 可以立即返回当前的 caller thread 分配了多少内存。而 <code>thread.allocatedp</code> 可以返回一个指针，解引用这个指针可以返回对应线程当前分配了多少内存。通过 allocatedp 可以避免频繁的 mallctl 调用，也可以实现从其他线程进行观测。但其中比较困难的一点就是如何监测线程的启动和释放，从而判断对应的指针是否能够被读取。一种做法是包装线程池的 API，在每个线程启动和释放的时候加上 hook。</p><p>此外，这种方式对于 Rust 程序会有一些问题：</p><ol><li>Rust 的移动语义会导致一些线程分配的内存会被另一个线程释放<br> 比如返回一个 T : Send 给另一个线程作为 Result。通常在需要使用线程池进行处理的逻辑中。</li><li>协程跑在 executor 上面，难以分清辨认出具体的用途</li></ol><h1 id="Jemalloc-Arena"><a href="#Jemalloc-Arena" class="headerlink" title="Jemalloc Arena"></a>Jemalloc Arena</h1><p>该⽅案可以看做是对 allocatedptr 的补充。通过 <code>arena.create</code> 创建一个 arena，通过 thread.arena 绑定⼀个线程到某个 arena，则可以通过该 arena 获知该线程 own 了多少内存，所以这是看存量的⼯具。<br>但线程 own 多少内存，并不等于某个模块占⽤了多少内存。原因：</p><ol><li>内存的 ownership 会在平⾏的模块之间转移。例如 P 模块分配出来的内存，可能会被转移给 S 模块。所以即便能够看到 S 线程池对应的 arena 的占⽤上升，也难以判断是 S 模块的原因，还是 P 转移过来的内存。</li><li>上级模块从同线程中调⽤下级模块，⽆法区分出上级和下级分别消耗了多少内存。</li></ol><p>这个⽅案有下述的缺点：</p><ol><li>我们更需要找内存增⻓的根因，知道内存都在哪些 arena ⾥⾯未必是⾜够的。</li><li>一些使用线程池的模块中的内存分配⼤致满⾜“⾃⼰⽤⾃⼰弃”的 pattern，因此可以通过减法来算出存量。因此，“Jemalloc Arena” 相⽐ “Jemalloc allocatedptr” 的⽅案的作⽤不是很⼤</li></ol><p>可以使用 mallocx 为某个模块指定对应的 arena。TiKV 的 <a href="https://github.com/tikv/tikv/pull/16255" target="_blank" rel="noopener">benchmark</a> 展示这不会产生很明显的 overhead。</p><h1 id="thread-local-memory-tracker"><a href="#thread-local-memory-tracker" class="headerlink" title="thread_local memory tracker"></a>thread_local memory tracker</h1><p>来⾃ Doris 的 Memtracker ⽅案。<br>该⽅案可以作为 “Jemalloc allocatedptr” ⽅案的补充。对于“上级模块从同线程中调⽤下级模块”的情况，可以使⽤⼀个 thread_local 变量记录栈中的⼀部分的内存开销。如下所⽰ kvs_page_mem 这个 thread_local 变量记录了 thread 1 中从 KVStore 调⽤到 PageStorage ⼀部分的开销。因此再结合 “Jemalloc allocatedptr” ⽅案本⾝的数据，就可以区分开来 PageStorage 产⽣<br>的内存（如新建⽴的 PageDirectoy）和调⽤链路上其他的内存，如 KVStore 和 PageStorage 中缓存的其他内容。<br>thread_local 的信息会被定时地上报给全局的 tracker，并由 tracker 做聚合后上报给 Prometheus。<br>也可以直接复⽤当前的逻辑，由 tracker 直接做聚合，但这样就需要⼀个全局的 hook 去线程启动的事件。</p><p><img src="/img/monitor-memory/11.png"></p><p>缺点：</p><ol><li>只能根据调⽤链路细化，不能追踪某个组件占据了多少内存。</li></ol><h1 id="Jemalloc-mallocx"><a href="#Jemalloc-mallocx" class="headerlink" title="Jemalloc mallocx"></a>Jemalloc mallocx</h1><p>通过 MALLOCX_ARENA flag，可以在 mallocx 的时候指定从某个 arena 分配。因此对于模块 A 可以替换它的所有 malloc 为 mallocx，从⽽实现追踪该模块的内存分配。<br>C++ 中内存管理层级和⽅式都很多，不能通过简单替换 mallocx 才能做到按组件统计。</p><h1 id="C-的堆内存管理层级"><a href="#C-的堆内存管理层级" class="headerlink" title="C++ 的堆内存管理层级"></a>C++ 的堆内存管理层级</h1><p><img src="/img/monitor-memory/heap-hire.png"></p><h1 id="C-Custom-Allocator"><a href="#C-Custom-Allocator" class="headerlink" title="C++ Custom Allocator"></a>C++ Custom Allocator</h1><p>对于 stl 中的 container 类型提供，指⽰如何构造 <code>Container&lt;T, CustomAllocator&lt;T&gt;&gt;</code> 。因为⼤部分内存的占⽤都是通过 C++ 的容器对⼀些基本类型组合产⽣的，因此通过指定⾃⼰的 allocator 可以达到较⾼的覆盖率。<br>缺点：</p><ol><li>只对 stl 起作⽤，custom class 需要⾃⼰适配，并且会传染。</li><li>Stl 的接⼝也不同，诸如 std::map、std::vector 需要提供⼀个额外的参数。⽽ std::make_shared<br>需要被 std::allocated_shared 代替。修改成本⽐较⼤。</li><li>Allocator 是有类型的，所以不同 allocator 的容器之间不能简单实现互操作，除⾮使⽤ pmr。</li></ol><h2 id="pmr"><a href="#pmr" class="headerlink" title="pmr"></a>pmr</h2><p>需要⽤ std::pmr 下⾯的容器，同样具有传染性。</p><h1 id="C-Custom-global-operator-new"><a href="#C-Custom-global-operator-new" class="headerlink" title="C++ Custom global operator new"></a>C++ Custom global operator new</h1><p>可以通过下⾯实现⼀些类似 “thread_local memory tracker” 的功能，避免掉⼿动埋点。</p><ol><li>在 new 或者 delete 中调⽤ backtrace 获得前⼀帧，判断组件来源</li><li>设法 inline 这些 operator，然后给需要监控的 <code>__FUNCTION__</code> 加上特定的前缀</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> __attribute__((always_inline)) <span class="function"><span class="keyword">void</span> *<span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="keyword">size_t</span> size)</span></span></span><br><span class="line"><span class="function"><span class="title">noexcept</span><span class="params">(<span class="literal">false</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> wrap_malloc(size, __FILE__, __LINE__, __FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">inline</span> __attribute__((always_inline)) <span class="keyword">void</span> *<span class="keyword">operator</span> <span class="keyword">new</span>[](<span class="keyword">size_t</span> size)</span><br><span class="line"><span class="keyword">noexcept</span>(<span class="literal">false</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> wrap_malloc(size, __FILE__, __LINE__, __FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">inline</span> __attribute__((always_inline)) <span class="function"><span class="keyword">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="keyword">void</span> *ptr)</span> <span class="keyword">noexcept</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    wrap_free(ptr, __FILE__, __LINE__, __FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">inline</span> __attribute__((always_inline)) <span class="keyword">void</span> <span class="keyword">operator</span> <span class="keyword">delete</span>[](<span class="keyword">void</span> *ptr)</span><br><span class="line"><span class="keyword">noexcept</span> &#123;</span><br><span class="line">    wrap_free(ptr, __FILE__, __LINE__, __FUNCTION__);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>缺点：</p><ol><li>在 critical path 上，打击范围太⼴。C++ 实践中不太推荐这么做。</li></ol><h1 id="C-Custom-class-operator-new"><a href="#C-Custom-class-operator-new" class="headerlink" title="C++ Custom class operator new"></a>C++ Custom class operator new</h1><p>相⽐ global operator new 的⽅案，class operator new 的时候已经知道了对象的类型，所以打击范围不⼴。我们可以仅仅针对某些对象统计。<br>缺点：</p><ol><li>只能追踪通过 new 分配的内存。栈内存⼀般较⼩，所以这⼀点不是问题。</li><li>在对象内部再通过 new 分配的动态内存⽆法被追踪。也就意味着</li></ol><p>std::vector::push_back 、 std::make_shared 和 new T[] 这样的主⼒内存分配点⽆法被跟踪。<br>因此，基于这样的⽅案，需要在某个 T 提供⼀个 size() ⽅法，然后 hook 住 T 的 operator new，从⽽给到关于 T 的总内存占⽤的统计。例如对 Block 和 VersionedPageEntries 提供统计。<br>缺点：</p><ol><li>std::make_shared 直接调⽤ ::new，因此对此没有作⽤</li></ol><h1 id="我的一些实践"><a href="#我的一些实践" class="headerlink" title="我的一些实践"></a>我的一些实践</h1><h2 id="TiFlash-的-heap-profiling"><a href="#TiFlash-的-heap-profiling" class="headerlink" title="TiFlash 的 heap profiling"></a>TiFlash 的 heap profiling</h2><p>提供了几种方案：</p><ol><li><p>heap_activate、heap_deactivate<br> 这个接口会启动一个线程定期调用 prof.dump。后续可以通过 heap_list 获取所有的 heap 文件，然后 curl 命令下载某个文件到本地。</p></li><li><p>set_prof_active、set_prof_inactive<br> 这个接口只会操作 <code>prof.activate</code>。用户需要手动在某个时候触发 prof.dump。这是因为只要 activate 了，就会开始记录堆分配的情况，不触发 prof.dump 这样就可以避免产生较多的文件，从而污染客户的环境。</p></li><li><p>heap、symbol<br> 这个接口最为灵活，因为它支持 jeprof 从外部环境访问这个接口，从而避免访问用户的机器，或者 binary。</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//go:embed jeprof.in</span></span><br><span class="line"><span class="keyword">var</span> jeprof <span class="keyword">string</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fetch</span><span class="params">()</span></span> &#123;</span><br><span class="line">    cmd := exec.Command(<span class="string">"perl"</span>, <span class="string">"/dev/stdin"</span>, <span class="string">"--raw"</span>, scheme+<span class="string">"://"</span>+op.ip+<span class="string">":"</span>+strconv.Itoa(op.port)+op.path) </span><br><span class="line">    cmd.Stdin = strings.NewReader(jeprof)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 注意，这种方式一般要持续开启 <code>prof.activate</code>。因为临时开启，则收集的时间过于短暂，可能无法生成有信息的报告。</p></li></ol><p>另外，注意在 jeprof.in 中使用 llvm-addrline，不然可能会出现 0x25 的报错，并且生成的 svg 图有缺失。</p><h2 id="TiFlash-的-continuous-profiling"><a href="#TiFlash-的-continuous-profiling" class="headerlink" title="TiFlash 的 continuous profiling"></a>TiFlash 的 continuous profiling</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍 C++ 上的内存监控方案。&lt;/p&gt;
&lt;p&gt;默认使用 jemalloc。&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
    <category term="内存管理" scheme="http://www.calvinneo.com/tags/内存管理/"/>
    
    <category term="profiling" scheme="http://www.calvinneo.com/tags/profiling/"/>
    
  </entry>
  
  <entry>
    <title>系列拼装模型攻略</title>
    <link href="http://www.calvinneo.com/2024/06/17/ugears-rockr-etc/"/>
    <id>http://www.calvinneo.com/2024/06/17/ugears-rockr-etc/</id>
    <published>2024-06-17T03:57:20.000Z</published>
    <updated>2024-12-19T16:44:49.020Z</updated>
    
    <content type="html"><![CDATA[<p>记录 rokr、ugears 等拼装模型的过程和经验。</p><a id="more"></a><h1 id="Rokr-视界地球仪"><a href="#Rokr-视界地球仪" class="headerlink" title="Rokr 视界地球仪"></a>Rokr 视界地球仪</h1><h1 id="Rokr-夜城"><a href="#Rokr-夜城" class="headerlink" title="Rokr 夜城"></a>Rokr 夜城</h1><p>感觉是买到了劣等品，插轴套的时候非常困难，好几个轴套甚至都被我弄崩开了。</p><h1 id="Rokr-留声机"><a href="#Rokr-留声机" class="headerlink" title="Rokr 留声机"></a>Rokr 留声机</h1><p>留声机的大叶片的贴合很困难。官方视频都无法做到完全贴合。</p><h1 id="Rokr-蒸汽火车头"><a href="#Rokr-蒸汽火车头" class="headerlink" title="Rokr 蒸汽火车头"></a>Rokr 蒸汽火车头</h1><h1 id="盗版-Ugears-首饰盒"><a href="#盗版-Ugears-首饰盒" class="headerlink" title="盗版 Ugears 首饰盒"></a>盗版 Ugears 首饰盒</h1><p>零件公差太大，无法实现自动开合。</p><h1 id="盗版-Ugears-风琴"><a href="#盗版-Ugears-风琴" class="headerlink" title="盗版 Ugears 风琴"></a>盗版 Ugears 风琴</h1><p>零件公差太大，无法实现按压回弹。</p><h1 id="Rokr-放映机"><a href="#Rokr-放映机" class="headerlink" title="Rokr 放映机"></a>Rokr 放映机</h1><h1 id="Rokr-时之恒摆钟"><a href="#Rokr-时之恒摆钟" class="headerlink" title="Rokr 时之恒摆钟"></a>Rokr 时之恒摆钟</h1><p>部分轴的冗余不是很高，容易脱落。<br>打蜡和打磨一定要充分，不然很难拧得动最下层的动力齿轮。我觉得它的齿轮组有点太多了。</p><h1 id="Rokr-星辰之恋"><a href="#Rokr-星辰之恋" class="headerlink" title="Rokr 星辰之恋"></a>Rokr 星辰之恋</h1><h1 id="Rokr-转转杯"><a href="#Rokr-转转杯" class="headerlink" title="Rokr 转转杯"></a>Rokr 转转杯</h1><p>那几个柱子要注意，很容易短。而且也很容易组装错。</p><h1 id="Rokr-望远镜"><a href="#Rokr-望远镜" class="headerlink" title="Rokr 望远镜"></a>Rokr 望远镜</h1><p>拼成镜头的板子比较容易松动啊。</p><h1 id="Rokr-摩托车"><a href="#Rokr-摩托车" class="headerlink" title="Rokr 摩托车"></a>Rokr 摩托车</h1><p>零件非常多，但是拼装起来很有意思。</p><h1 id="Rokr-小吉他"><a href="#Rokr-小吉他" class="headerlink" title="Rokr 小吉他"></a>Rokr 小吉他</h1><h1 id="Rokr-露营车"><a href="#Rokr-露营车" class="headerlink" title="Rokr 露营车"></a>Rokr 露营车</h1><h1 id="Roke-维多利亚台灯"><a href="#Roke-维多利亚台灯" class="headerlink" title="Roke 维多利亚台灯"></a>Roke 维多利亚台灯</h1><h1 id="Rokr-时间胶囊"><a href="#Rokr-时间胶囊" class="headerlink" title="Rokr 时间胶囊"></a>Rokr 时间胶囊</h1><p>胶水很拉胯，可以考虑双面胶。<br>另外亚克力零件比较脆。</p><h1 id="乐放-天空之城"><a href="#乐放-天空之城" class="headerlink" title="乐放 天空之城"></a>乐放 天空之城</h1><p>在安装的时候，要记一下上发条的方向，不然装好之后，弄错方向的话可能会把别的部分给拆下来。</p><h1 id="Rokr-钢琴"><a href="#Rokr-钢琴" class="headerlink" title="Rokr 钢琴"></a>Rokr 钢琴</h1><h1 id="Rokr-印画工坊"><a href="#Rokr-印画工坊" class="headerlink" title="Rokr 印画工坊"></a>Rokr 印画工坊</h1><p>注意把手安装时的角度，以及方向。特别是红圈处的零件只能有一个，如果有三个说明装反了。这样就按压不了，而是往上抬了。<br><img src="/img/modules-wood/yhgf.jpg"></p><h1 id="Rokr-大提琴"><a href="#Rokr-大提琴" class="headerlink" title="Rokr 大提琴"></a>Rokr 大提琴</h1><h1 id="Rokr-逐梦之翼"><a href="#Rokr-逐梦之翼" class="headerlink" title="Rokr 逐梦之翼"></a>Rokr 逐梦之翼</h1><p>注意飞机的前后上下。</p><h1 id="Rokr-猫头鹰钟"><a href="#Rokr-猫头鹰钟" class="headerlink" title="Rokr 猫头鹰钟"></a>Rokr 猫头鹰钟</h1><p>和时之恒钟摆一样，转发条得用大力，所以齿轮间的磨合要充分打磨和上蜡。<br>定时组件的发条最好预置比较紧，这样每次上发条不要转很久。上发条出现咔咔声是正常的。<br>部分轴套较短。</p><h1 id="Rokr-降落伞"><a href="#Rokr-降落伞" class="headerlink" title="Rokr 降落伞"></a>Rokr 降落伞</h1><h1 id="Rokr-小猫头鹰"><a href="#Rokr-小猫头鹰" class="headerlink" title="Rokr 小猫头鹰"></a>Rokr 小猫头鹰</h1><h1 id="Rokr-电动恐龙"><a href="#Rokr-电动恐龙" class="headerlink" title="Rokr 电动恐龙"></a>Rokr 电动恐龙</h1><h1 id="Rokr-飞艇"><a href="#Rokr-飞艇" class="headerlink" title="Rokr 飞艇"></a>Rokr 飞艇</h1><h1 id="Rolife-摩天轮"><a href="#Rolife-摩天轮" class="headerlink" title="Rolife 摩天轮"></a>Rolife 摩天轮</h1><p>注意摩天轮有几个扇形。<br>注意摩天轮外部轴套的安装顺序。老版本会很松动。</p><h1 id="Rokr-挂钟"><a href="#Rokr-挂钟" class="headerlink" title="Rokr 挂钟"></a>Rokr 挂钟</h1><p>安装四个齿轮组的时候需要特别比对。对轴两端各插什么东西需要注意。</p><p>那个挂钩特别不牢靠，我的直接掉下来了。</p><h1 id="Rolife-假日花房"><a href="#Rolife-假日花房" class="headerlink" title="Rolife 假日花房"></a>Rolife 假日花房</h1><p>要大量用到胶水，体验比较差。</p><h1 id="Ugears-钢片琴键"><a href="#Ugears-钢片琴键" class="headerlink" title="Ugears 钢片琴键"></a>Ugears 钢片琴键</h1><p>安装编谱器的时候需要注意，两侧的木轴套的内径是不一样的。不要强行按压。</p><p>在安装键盘 CDEFGAB 以及它下面的支架时，需要辨别方向。否则会导致后面的皮筋勾不住。</p><h1 id="Ugears-曲率仪"><a href="#Ugears-曲率仪" class="headerlink" title="Ugears 曲率仪"></a>Ugears 曲率仪</h1><h1 id="Rokr-基地"><a href="#Rokr-基地" class="headerlink" title="Rokr 基地"></a>Rokr 基地</h1><h1 id="Ugears-三球仪"><a href="#Ugears-三球仪" class="headerlink" title="Ugears 三球仪"></a>Ugears 三球仪</h1><p>c3 组件是地球公转系统的重要组成部分，这个组件很容易出现卡壳。这种情况下，无论如何上蜡和打磨，最好的结果也是组装完成后可以逆时针（朝自己）摇动把手，但公转不会起作用，且间歇性咔咔作响。此外，顺时针转动把手，或者世界逆时针转动 c3 都会卡壳。因此对 c3 组件需要充分调试：</p><ol><li>顺时针转动 c1，则 c3 可以流畅运行。</li><li>将 c6 和 c5 组装完成后，手动顺时针转动 c1，系统可以流畅运行。</li><li>将公转系统安装上去之后转动把手，可以流畅运行。<br> 如下所示可以单独拆出公转部分<br> <img src="/img/modules-wood/solar-system.png"><br> 以及地月系统<br> <img src="/img/modules-wood/the-earth.png"></li></ol><p>这里的关键在于 50 这个偏心组件必须牢牢被安装在轴上。如果它松动了，则 c3 的齿轮会倾斜，从而导致系统无法工作。因此建议用 502 胶水涂抹 50 内侧，让它变紧。或者必要时直接粘上去。</p><h1 id="Ugears-魁地奇球场"><a href="#Ugears-魁地奇球场" class="headerlink" title="Ugears 魁地奇球场"></a>Ugears 魁地奇球场</h1><p>计分器有问题，不知道怎么回事。<br>另外，球在掉下去之后，下方的轨道会被上面的板挡到。</p><h1 id="Rokr-巧克力工厂"><a href="#Rokr-巧克力工厂" class="headerlink" title="Rokr 巧克力工厂"></a>Rokr 巧克力工厂</h1><p>上面攒球的地方容易卡住。</p><h1 id="Rokr-秘境花园八音盒"><a href="#Rokr-秘境花园八音盒" class="headerlink" title="Rokr 秘境花园八音盒"></a>Rokr 秘境花园八音盒</h1><p>感觉设计不是很好，上面那个圆盘子很容易弹出来。</p><h1 id="Ugears-金色飞贼"><a href="#Ugears-金色飞贼" class="headerlink" title="Ugears 金色飞贼"></a>Ugears 金色飞贼</h1><p>绳子打结的方式任意即可，不一定需要按照那个手册里面的，因为也看不懂。尽量线头不要很大。<br>后面，绳子尽量要多收到飞贼里面，这样发条能拉更紧。</p><h1 id="Rokr-空中飞椅"><a href="#Rokr-空中飞椅" class="headerlink" title="Rokr 空中飞椅"></a>Rokr 空中飞椅</h1><p>C 开头的很多插销很啰嗦，尽量别装错。</p><h1 id="Rokr-史密斯-M60"><a href="#Rokr-史密斯-M60" class="headerlink" title="Rokr 史密斯 M60"></a>Rokr 史密斯 M60</h1><p>在没有装皮筋的时候，扣动扳机，左轮是不一定会转动的。</p><h1 id="Ugears-密码箱"><a href="#Ugears-密码箱" class="headerlink" title="Ugears 密码箱"></a>Ugears 密码箱</h1><p>那个垫的木条一点用都没有，反而会让底盘的零件卡不进去甚至变形。<br>12和13打蜡重要，要检查两边的12应该能够同步升起来。<br>58和59看起来一点用都没有。<br>60的正面、61的全部，包括正反面都需要打磨打蜡，涉及到盖子开起来是否流畅。<br>零件总体很紧，需要用锤子敲。</p><h1 id="乐放-水母"><a href="#乐放-水母" class="headerlink" title="乐放 水母"></a>乐放 水母</h1><p>他家的东西依旧很松。<br>水母的螺旋尾巴，最好用胶水加固下。<br>装好中间的大圆盘之后，检查一下转动发条，杆子和三个齿轮能不能动。<br>三个小鱼卡子很紧，但一定要完全按进去。</p><h1 id="ugears-天空守望者"><a href="#ugears-天空守望者" class="headerlink" title="ugears 天空守望者"></a>ugears 天空守望者</h1><p>注意上大发条的时候，lock 要按下去卡住，不然发条会突然松开，很吓人。lock 在安装的时候一定要仔细上蜡，不然很难拉出来。<br>138 和 139 不能装反。</p><p>注意，127 是一个非常关键的零件。</p><p>注意，摆动的部件卡住，并一定是因为中间没有打蜡。需要注意，底座、环、以及陀飞轮内部的齿轮都要打蜡。我是通过有一次发现陀飞轮的盘子在转，但是它和底座没有发生相对位移才得到的这个结论。在此之后，我的陀飞轮时间就能轻松到 4-5 min 了。</p><h1 id="Rokr-礼物工厂"><a href="#Rokr-礼物工厂" class="headerlink" title="Rokr 礼物工厂"></a>Rokr 礼物工厂</h1>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录 rokr、ugears 等拼装模型的过程和经验。&lt;/p&gt;</summary>
    
    
    
    
    <category term="游戏" scheme="http://www.calvinneo.com/tags/游戏/"/>
    
    <category term="拼装模型" scheme="http://www.calvinneo.com/tags/拼装模型/"/>
    
  </entry>
  
  <entry>
    <title>C++ 的 allocator 机制</title>
    <link href="http://www.calvinneo.com/2024/05/30/C++-allocator/"/>
    <id>http://www.calvinneo.com/2024/05/30/C++-allocator/</id>
    <published>2024-05-30T14:34:20.000Z</published>
    <updated>2024-05-30T17:45:59.929Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 C++ 的 allocator 机制</p><a id="more"></a><h1 id="allocator-的实现"><a href="#allocator-的实现" class="headerlink" title="allocator 的实现"></a>allocator 的实现</h1><p>默认的 allocator 的实现如下所示。可以发现这是基于 malloc 的。</p><p>因此，诸如 jemalloc 的内存管理机制对 C++ 同样是有作用的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdlib&gt; // for std::malloc and std::free</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;new&gt;     // for std::bad_alloc</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">allocator</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">using</span> value_type = T;</span><br><span class="line"></span><br><span class="line">    allocator() <span class="keyword">noexcept</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> U&gt;</span><br><span class="line">    allocator(<span class="keyword">const</span> allocator&lt;U&gt;&amp;) <span class="keyword">noexcept</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">T* <span class="title">allocate</span><span class="params">(<span class="built_in">std</span>::<span class="keyword">size_t</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (n &gt; <span class="built_in">std</span>::<span class="keyword">size_t</span>(<span class="number">-1</span>) / <span class="keyword">sizeof</span>(T))</span><br><span class="line">            <span class="keyword">throw</span> <span class="built_in">std</span>::bad_alloc();</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">auto</span> p = <span class="keyword">static_cast</span>&lt;T*&gt;(<span class="built_in">std</span>::<span class="built_in">malloc</span>(n * <span class="keyword">sizeof</span>(T))))</span><br><span class="line">            <span class="keyword">return</span> p;</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">std</span>::bad_alloc();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">deallocate</span><span class="params">(T* p, <span class="built_in">std</span>::<span class="keyword">size_t</span>)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">free</span>(p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span><br><span class="line"><span class="keyword">bool</span> <span class="keyword">operator</span>==(<span class="keyword">const</span> allocator&lt;T&gt;&amp;, <span class="keyword">const</span> allocator&lt;U&gt;&amp;) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span><br><span class="line"><span class="keyword">bool</span> <span class="keyword">operator</span>!=(<span class="keyword">const</span> allocator&lt;T&gt;&amp;, <span class="keyword">const</span> allocator&lt;U&gt;&amp;) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125; <span class="comment">// namespace std</span></span><br></pre></td></tr></table></figure><h1 id="std-pmr"><a href="#std-pmr" class="headerlink" title="std::pmr"></a>std::pmr</h1><p>Polymorphic Memory Resources 解决了什么问题？</p><ol><li>简化 custom allocator 的实现<br> 主要提供了 std::pmr::memory_resource 和 std::pmr::polymorphic_allocator。</li><li>动态类型<br> std::pmr::polymorphic_allocator 允许动态修改 allocator 的策略，而不需要修改 container 的代码。</li><li>提供了一些预定义的策略<br> std::pmr::monotonic_buffer_resource 是最简单的分配器。<br> std::pmr::unsynchronized_pool_resource 是基于 pool 的分配器。</li><li>可以跨多个 container 和 components 统一管理内存分配方案</li></ol><p>如下所示，需要用 <code>std::pmr</code> 下面的 container</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory_resource&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Create a buffer for monotonic_buffer_resource</span></span><br><span class="line">    <span class="keyword">char</span> buffer[<span class="number">1024</span>];</span><br><span class="line">    <span class="built_in">std</span>::pmr::monotonic_buffer_resource pool&#123;buffer, <span class="keyword">sizeof</span>(buffer)&#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Create a vector using the custom memory resource</span></span><br><span class="line">    <span class="built_in">std</span>::pmr::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec&#123;&amp;pool&#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Use the vector as usual</span></span><br><span class="line">    vec.push_back(<span class="number">1</span>);</span><br><span class="line">    vec.push_back(<span class="number">2</span>);</span><br><span class="line">    vec.push_back(<span class="number">3</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Memory-Trace-的讨论"><a href="#Memory-Trace-的讨论" class="headerlink" title="Memory Trace 的讨论"></a>Memory Trace 的讨论</h1><h2 id="operator-new-和自定义-allocator-的区别"><a href="#operator-new-和自定义-allocator-的区别" class="headerlink" title="operator new 和自定义 allocator 的区别"></a>operator new 和自定义 allocator 的区别</h2><p>In C++, both custom allocators and custom operator new play roles in managing memory allocation, but they serve different purposes and operate at different levels of abstraction.</p><p>Custom Allocator:</p><p>A custom allocator typically refers to a class that provides an interface for allocating and deallocating memory.<br>It’s a more general-purpose mechanism that can be used not only for dynamic memory allocation but also for other types of memory management, like managing memory pools or implementing specialized allocation strategies.<br>Custom allocators are often used with standard library containers like std::vector, std::map, etc., allowing you to customize how memory is allocated and deallocated for these containers.<br>Custom allocators are used through allocators traits like std::allocator_traits and can be customized for specific needs.</p><p>Custom operator new:<br>operator new is a language-level function used for dynamic memory allocation in C++. It’s responsible for allocating memory for objects.<br>Customizing operator new typically involves overloading it or providing a replacement function. This allows you to intercept and customize memory allocation behavior for individual types or globally.<br>This approach is more specific and low-level compared to custom allocators. It directly affects how memory is allocated for individual objects.<br>Custom operator new is often used when you need to apply specific allocation strategies or track memory usage at the level of individual objects rather than at the container level.<br>In summary, custom allocators offer a more flexible and higher-level approach to memory management, suitable for container classes and general-purpose memory management, while custom operator new provides a more direct and low-level means of customizing memory allocation behavior for individual objects.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍 C++ 的 allocator 机制&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
    <category term="Linux" scheme="http://www.calvinneo.com/tags/Linux/"/>
    
    <category term="并行计算" scheme="http://www.calvinneo.com/tags/并行计算/"/>
    
    <category term="多线程" scheme="http://www.calvinneo.com/tags/多线程/"/>
    
    <category term="atomic" scheme="http://www.calvinneo.com/tags/atomic/"/>
    
  </entry>
  
  <entry>
    <title>C++ Coroutine 介绍的翻译</title>
    <link href="http://www.calvinneo.com/2024/05/26/C++-coroutine/"/>
    <id>http://www.calvinneo.com/2024/05/26/C++-coroutine/</id>
    <published>2024-05-26T07:46:32.000Z</published>
    <updated>2024-12-09T16:47:29.816Z</updated>
    
    <content type="html"><![CDATA[<p>翻译 <a href="https://lewissbaker.github.io/" target="_blank" rel="noopener">lewissbaker</a> 的三篇文章。</p><a id="more"></a><h1 id="Coroutine-Theory"><a href="#Coroutine-Theory" class="headerlink" title="Coroutine Theory"></a>Coroutine Theory</h1><p>暂略</p><h1 id="Understanding-operator-co-await"><a href="#Understanding-operator-co-await" class="headerlink" title="Understanding operator co_await"></a>Understanding operator co_await</h1><p><a href="https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await" target="_blank" rel="noopener">https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await</a></p><p>有两个接口需要定义，Promise 和 Awaiter。</p><p>Promist 接口定义了 coroutine 自己的行为，例如 coroutine 被调用的时候应该做什么，应该返回什么，并且定义 co_await 或者 co_yield 在 coroutine 中的行为。</p><p>Awaitable 接口定义了 co_await 的语义。当我们 co_await 一个对象时，这个 co_await 会被转化为一系列调用，负责挂起当前的 coroutine，执行一些帮助它后续被重新调度起来的命令，以及一些在 resume 之后生成 co_await 返回值的命令。</p><h2 id="Awaiters-and-Awaitables-Explaining-operator-co-await"><a href="#Awaiters-and-Awaitables-Explaining-operator-co-await" class="headerlink" title="Awaiters and Awaitables: Explaining operator co_await"></a>Awaiters and Awaitables: Explaining operator co_await</h2><h3 id="Awaitable"><a href="#Awaitable" class="headerlink" title="Awaitable"></a>Awaitable</h3><p>如果一个类型支持 <code>co_await &lt;expr&gt;</code>，它就是一个 Awaitable 类型。</p><p>Promise 类型可以通过 await_transform 方法去修改 co_await 的 expr。下面将没有实现 await_transform 的类型称为 Normally Awaitable。将实现了 await_transform 的称为 Contextually Awaitable，此时这个类型只支持在一些特定类型的 coroutine 中被调用。</p><h3 id="Awaiter"><a href="#Awaiter" class="headerlink" title="Awaiter"></a>Awaiter</h3><p>一个 Awaiter 类型需要实现三个方法：await_ready, await_suspend 和 await_resume，它们加在一起组成了 co_await。</p><p>一个类型可以既是 Awaiter 又是 Awaitable。</p><h2 id="获取-Awaiter"><a href="#获取-Awaiter" class="headerlink" title="获取 Awaiter"></a>获取 Awaiter</h2><p>假设这个 awaiting coroutine 的 promise 对象的类型是 P，并且这个 <code>promise</code> 是对当前 coroutine 中的 P 实例的左值引用。</p><p>如果 P 有一个 await_transform 方法，那么 <code>expr</code> 就会被首先传给 <code>promise.await_transform(&lt;expr&gt;)</code>，以获得对应的 Awaitable 对象。否则，<code>expr</code> 的结果就会直接被作为 Awaitable 对象。不妨令为 <code>awaitable</code>。</p><p>Then, if the Awaitable object, awaitable, has an applicable operator co_await() overload then this is called to obtain the Awaiter object. Otherwise the object, awaitable, is used as the awaiter object.<br>然后，如果这个 Awaitable 对象 <code>awaitable</code> 有一个 <code>operator co_await()</code>，那么就可以通过调用它来获得一个 Awaiter 对象。否则就会直接使用 awaitable 作为 Awaiter 对象。</p><p>上面说的内容可以通过下面的代码来理解。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> P, <span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">decltype</span>(<span class="keyword">auto</span>) get_awaitable(P&amp; promise, T&amp;&amp; expr)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(has_any_await_transform_member_v&lt;P&gt;)</span></span></span><br><span class="line">    return promise.await_transform(static_cast&lt;T&amp;&amp;&gt;(expr));</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;T&amp;&amp;&gt;(expr);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Awaitable&gt;</span><br><span class="line"><span class="keyword">decltype</span>(<span class="keyword">auto</span>) get_awaiter(Awaitable&amp;&amp; awaitable)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(has_member_operator_co_await_v&lt;Awaitable&gt;)</span></span></span><br><span class="line">    return static_cast&lt;Awaitable&amp;&amp;&gt;(awaitable).operator co_await();</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> <span class="keyword">constexpr</span> (has_non_member_operator_co_await_v&lt;Awaitable&amp;&amp;&gt;)</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">operator</span> co_await(<span class="keyword">static_cast</span>&lt;Awaitable&amp;&amp;&gt;(awaitable));</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;Awaitable&amp;&amp;&gt;(awaitable);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【Q】为什么要区分 Awaiter 和 Awaitable 呢？</p><h2 id="Awaiting-the-Awaiter"><a href="#Awaiting-the-Awaiter" class="headerlink" title="Awaiting the Awaiter"></a>Awaiting the Awaiter</h2><p><code>co_await &lt;expr&gt;</code> 这个调用可以被转换成如下的形式。</p><p>注意，下面说的 caller 我理解就是 coroutine 的 caller。而 resumer 指的是 coroutine 在被重新调度执行后的“caller”。</p><p>await_suspend 有两个版本：</p><ol><li>返回 void 的版本<br> 在 await_suspend 调用返回后，会无条件将执行权转移给 caller 或者 resumer。</li><li>返回 bool 的版本<br> 允许有条件地立即 resume 这个 coroutine，而不是将执行权转移给 caller 或者 resumer。<br> 一般来说，如果这个 awaiter 需要执行的异步操作在一些情况下可能同步地完成，那么就可以在 await_suspend 中返回 false，让 coroutine 立即 resume 从而执行后面的逻辑。</li></ol><p>在 <code>&lt;suspend-coroutine&gt;</code> 处，编译期会生成一些代码，保存当前 coroutine 的状态以便后续恢复。比如存储 <code>&lt;resume-point&gt;</code> 的位置，以及将当前寄存器的状态保存在内存中等。</p><p>那么在 <code>&lt;suspend-coroutine&gt;</code> 之后就可以认为这个 coroutine 已经被 suspend 了。所以可以在 await_suspend 调用中首先可以观察到被挂起的 coroutine。此后，它可以被 resume 或者被 destroy。</p><p>await_suspend 还需要负责在 coroutine 的异步操作被完成后重新 resume 或者 destroy 掉这个 coroutine。</p><p>如果这个 coroutine 的异步操作是被同步完成的，就可以通过 await_ready 调用避免掉 <code>&lt;suspend-coroutine&gt;</code> 挂起 coroutine 的开销。<br>【Q】那么它和返回 bool 的 await_suspend 的区别是啥呢？感觉前者是给你决定要不要，后者是告诉你实际发生了什么。</p><p>在 <code>&lt;return-to-caller-or-resumer&gt;</code> 处，执行权会被重新转移给 caller 或者 resumer。此时会 popping the local stack frame but keeping the coroutine frame alive。</p><p>【Q】什么是 coroutine frame 呢？从下文可知，coroutine_handle 是一个 coroutine frame 的句柄，用来对它进行操作。可是它本体是啥呢？在<a href="https://lewissbaker.github.io/2017/09/25/coroutine-theory" target="_blank" rel="noopener">前文</a>中有介绍：</p><blockquote><p>The ‘coroutine frame’ holds part of the coroutine’s activation frame that persists while the coroutine is suspended and the ‘stack frame’ part only exists while the coroutine is executing and is freed when the coroutine suspends and transfers execution back to the caller/resumer.</p></blockquote><p>如果被挂起的 coroutine 最终是被 resume 的话，会在 <code>&lt;resume-point&gt;</code> 点被继续执行。</p><p>await_resume 调用的返回值会成为 co_await 的返回值。注意 await_resume 同样可能抛出异常，此时这个异常会被传播到 co_await 之外。</p><p>Note that if an exception propagates out of the await_suspend() call then the coroutine is automatically resumed and the exception propagates out of the co_await expression without calling await_resume().</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">co_await (T expr)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">auto</span>&amp;&amp; value = &lt;expr&gt;;</span><br><span class="line">  <span class="keyword">auto</span>&amp;&amp; awaitable = get_awaitable(promise, <span class="keyword">static_cast</span>&lt;<span class="keyword">decltype</span>(value)&gt;(value));</span><br><span class="line">  <span class="keyword">auto</span>&amp;&amp; awaiter = get_awaiter(<span class="keyword">static_cast</span>&lt;<span class="keyword">decltype</span>(awaitable)&gt;(awaitable));</span><br><span class="line">  <span class="keyword">if</span> (!awaiter.await_ready())</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">handle_t</span> = <span class="built_in">std</span>::experimental::coroutine_handle&lt;P&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">await_suspend_result_t</span> =</span><br><span class="line">      <span class="keyword">decltype</span>(awaiter.await_suspend(<span class="keyword">handle_t</span>::from_promise(p)));</span><br><span class="line"></span><br><span class="line">    &lt;suspend-coroutine&gt;</span><br><span class="line">    <span class="comment">// 此后可以认为该 coroutine 已经被 suspend 了</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// await_suspend 会处理诸如 rescheduling 的事情</span></span><br><span class="line">    <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(<span class="built_in">std</span>::is_void_v&lt;<span class="keyword">await_suspend_result_t</span>&gt;)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      awaiter.await_suspend(<span class="keyword">handle_t</span>::from_promise(p));</span><br><span class="line">      &lt;<span class="keyword">return</span>-to-caller-<span class="keyword">or</span>-resumer&gt;</span><br><span class="line">      <span class="comment">// 此后，执行权交还给 caller 或者 resumer</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">static_assert</span>(</span><br><span class="line">         <span class="built_in">std</span>::is_same_v&lt;<span class="keyword">await_suspend_result_t</span>, <span class="keyword">bool</span>&gt;,</span><br><span class="line">         <span class="string">"await_suspend() must return 'void' or 'bool'."</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (awaiter.await_suspend(<span class="keyword">handle_t</span>::from_promise(p)))</span><br><span class="line">      &#123;</span><br><span class="line">        &lt;<span class="keyword">return</span>-to-caller-<span class="keyword">or</span>-resumer&gt;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &lt;resume-point&gt;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> awaiter.await_resume();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Coroutine-Handles"><a href="#Coroutine-Handles" class="headerlink" title="Coroutine Handles"></a>Coroutine Handles</h2><p>在上文中，一个 <code>coroutine_handle&lt;P&gt;</code> 类型的对象会被传给 await_suspend，作为 await_suspend 的参数。这个类型是对 coroutine frame 的一个非 owning 的句柄。可以通过它来 resume 或者 destroy。同时，还可以用它来访问 coroutine 的 promise 对象。</p><p>coroutine_handle 有类似下面的结构</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>::experimental</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Promise&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_handle</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span>&lt;&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_handle</span>&lt;void&gt;</span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">done</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">resume</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span>* <span class="title">address</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> coroutine_handle <span class="title">from_address</span><span class="params">(<span class="keyword">void</span>* address)</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Promise&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_handle</span> :</span> coroutine_handle&lt;<span class="keyword">void</span>&gt;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="function">Promise&amp; <span class="title">promise</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> coroutine_handle <span class="title">from_promise</span><span class="params">(Promise&amp; promise)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> coroutine_handle <span class="title">from_address</span><span class="params">(<span class="keyword">void</span>* address)</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>resume<br> 当异步动作完成，需要 resume 这个 coroutine 的时候，应该调用 resume 方法。此时会在 <code>&lt;resume-point&gt;</code> 继续执行 coroutine。<br> 对 resume 本身的调用会在 coroutine 下一次碰到 <code>&lt;return-to-caller-or-resumer&gt;</code> 的时候返回。</li><li>destroy<br> 会销毁当前的 coroutine feame。<br> 一般来说不需要调用这个方法，除非是库的作者在实现 promise 类型的时候。<br> 一般来说，coroutine frame 会被调用 coroutine 时返回的 RAII 类型所持有。所以需要避免 double-destruction bug。</li><li>promise<br> 返回 coroutine 的 promise 对象的引用。<br> 对于大多数 Normally Awaitable 类型，应当使用 <code>coroutine_handle&lt;void&gt;</code> 作为 await_suspend 的参数，而不是 <code>coroutine_handle&lt;Promise&gt;</code>。<br> <code>coroutine_handle&lt;P&gt;::from_promise(P&amp; promise)</code> 这个函数可以由 coroutine promise 对象的引用来<strong>重新构造</strong> coroutine_handle。注意必须要保证 P 和 coroutine frame 使用的 concrete promise type 是一致的。也就是说如果创建 <code>coroutine_handle&lt;Base&gt;</code>，但是实际的 promise type 是 Derived 会导致 UB。</li><li>address/from_address<br> 将一个 coroutine handle 和 void* 指针进行互相转化。它的目的主要是和 C 语言的接口交互。<br> 但一般来说，在实现时经常发现还需要打包发送其他上下文，所以一般来说会将 <code>coroutine_handle</code> 放到一个结构中，并返回结构的指针。</li></ol><h2 id="Synchronisation-free-async-code"><a href="#Synchronisation-free-async-code" class="headerlink" title="Synchronisation-free async code"></a>Synchronisation-free async code</h2><p>co_await 的一个作用是可以在 coroutine 被 suspend 之后，和被 caller/resumer 重新获得执行权之前的这段时间中执行代码。</p><p>也就是说，Awaiter 对象会在 coroutine 被 suspend 之后启动一个 async 操作，将 <code>coroutine_handle</code> 传给这个 async 操作，让它能在完成后去 resume 之前的 coroutine。注意这个 coroutine 可能是在另一个线程中被 resume 了。整个过程中并不需要任何的同步开销。</p><p>举个例子，一段代码在线程 A 中执行，使用 coroutine 去做一个异步读，那么 Awaiter 可以在 await_suspend 中启动这个异步读，而这个异步读是在线程 B 中被实际处理的。但线程 A 和线程 B 之间是没有任何同步开销的。比如没有通过条件变量或者 channel 进行等待。如下面所示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Time     Thread A                           Thread B</span><br><span class="line">  |      --------                           --------</span><br><span class="line">  |      ....                               Call OS - Wait for I/O event</span><br><span class="line">  |      Call await_ready()                    |</span><br><span class="line">  |      &lt;supend-point&gt;                        |</span><br><span class="line">  |      Call await_suspend(handle)            |</span><br><span class="line">  |        Store handle in operation           |</span><br><span class="line">  V        Start AsyncFileRead ---+            V</span><br><span class="line">                                  +-----&gt;   &lt;AsyncFileRead Completion Event&gt;</span><br><span class="line">                                            Load coroutine_handle from operation</span><br><span class="line">                                            Call handle.resume()</span><br><span class="line">                                              &lt;resume-point&gt;</span><br><span class="line">                                              Call to await_resume()</span><br><span class="line">                                              execution continues....</span><br><span class="line">           Call to AsyncFileRead returns</span><br><span class="line">         Call to await_suspend() returns</span><br><span class="line">         &lt;return-to-caller/resumer&gt;</span><br></pre></td></tr></table></figure><p>在上面的伪代码中还需要注意：</p><ol><li>如果异步任务把 <code>coroutine_handle</code> 传给了另一个线程，那么这个线程就可能在 await_suspend 返回之前就 resume 这个 coroutine。这样，就会和 await_suspend 方法剩下来的部分竞争。</li><li>当 resume 一个 coroutine 的时候，首先需要调用 await_resume 去获得异步任务的结果。一般与此同时会立即析构掉 Awaiter 对象（可以看看上面的 demo）。因为 Awaiter 对象实际上就是 await_suspend 的 this 指针，所以 coroutine 可能会在 await_suspend 调用之前就 destruct 掉 coroutine 和 promise 对象。</li></ol><p>因此，在 await_suspend 方法中，一旦 coroutine 可以在另一个线程上并发地 resume，就需要保证不会再去访问 this 或者 coroutine 的 promise() 对象了，因为它们可能都被销毁了。实际上，当 coroutine 已经 scheduled for resumption 的时候，唯一能安全访问的只有 await_suspend 中的本地变量了。</p><h2 id="Comparison-to-Stackful-Coroutines"><a href="#Comparison-to-Stackful-Coroutines" class="headerlink" title="Comparison to Stackful Coroutines"></a>Comparison to Stackful Coroutines</h2><p>和诸如 win32 的 fiber 或者 boost::context 这样的有栈协程相比：<br>在很多有栈协程中，suspend 操作通常会伴随着 resume 另一个 coroutine，从而组合成为一个 context-switch 操作。而这个操作会导致没有机会再 suspend 当前 coroutine 之后，以及将执行权转移到另一个 coroutine 之前执行一些逻辑。<br>而这就意味着如果需要实现一个类似的 async-file-read 操作，就需要在 suspend 这个 coroutine 之前就开启这个操作。因此这个操作可能就会在当前 coroutine 被 suspend 之前，就在另一个线程中被执行完了，而当前 coroutine 因此又要被 resume。这就在这两个线程之间引入了 race。而如上所述，C++ 的 coroutine 不需要在线程 A 和线程 B 之间引入同步机制。</p><p>There are probably ways around this by using a trampoline context that can start the operation on behalf of the initiating context after the initiating context has been suspended. However this would require extra infrastructure and an extra context-switch to make it work and it’s possible that the overhead this introduces would be greater than the cost of the synchronisation it’s trying to avoid.</p><h2 id="Avoiding-memory-allocations"><a href="#Avoiding-memory-allocations" class="headerlink" title="Avoiding memory allocations"></a>Avoiding memory allocations</h2><p>async 操作需要分配一些内存。比如在 win32 io 函数接口中，需要分配一个 OVERLAPPED 结构，这个结构需要在操作完成之后才会被释放。因此这样的结构必须要分配在堆上，并且每个 async 操作都需要 allocate 一次。因此在这里可以使用一个对象池来优化。</p><p>但是在 C++ 的 coroutine 中，可以避免堆内存分配，因为 local variable 在 coroutine 被 suspend 的时候会在 coroutine frame 里面，从而肯定是存活的。</p><p>将 per-operation state 存放在 Awaiter 对象中，可以白嫖 coroutine frame，从而延续到至少是 co_await expression 的 lifetime。一旦这个 operation 完成，coroutine 就会 resume，然后 Awaiter 对象就会被销毁。</p><p>当然，coroutine frame 本身还是会在堆上分配的，但是，一旦它被分配，是可以被用来执行很多个 async 操作的。这就好像是一个 arena memory allocator 一样，编译期可以在编译期计算出 local variable 的大小，然后就可以一次性分配出来了。</p><p>【Q】没太明白为啥 coroutine frame 是可以被复用的。我理解应该是指的可以 co_await 很多次。</p><h2 id="An-example-Implementing-a-simple-thread-synchronisation-primitive"><a href="#An-example-Implementing-a-simple-thread-synchronisation-primitive" class="headerlink" title="An example: Implementing a simple thread-synchronisation primitive"></a>An example: Implementing a simple thread-synchronisation primitive</h2><p>下面是一个简单的多生产者-多消费者模型。如果 set 已经被调用过了，那么后续的 consumer 就不会 suspend 了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">T value;</span><br><span class="line">async_manual_reset_event event;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A single call to produce a value</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">producer</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  value = some_long_running_computation();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Publish the value by setting the event.</span></span><br><span class="line">  event.<span class="built_in">set</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Supports multiple concurrent consumers</span></span><br><span class="line">task&lt;&gt; consumer()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// Wait until the event is signalled by call to event.set()</span></span><br><span class="line">  <span class="comment">// in the producer() function.</span></span><br><span class="line">  co_await event;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Now it's safe to consume 'value'</span></span><br><span class="line">  <span class="comment">// This is guaranteed to 'happen after' assignment to 'value'</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; value &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的设计就是用一个 <code>std::atomic&lt;void*&gt;</code> 指针。它要么指向 this，说明已经 set 了；要么指向一个链表的表头，表示正在 suspend 的链表。</p><p>在这里，我们也实现了上面提到的节省内存分配的方案，将链表的 node 分配在 awaiter 对象里面，而 awaiter 对象在 coroutine frame 上面。</p><p>总而言之，代码如下所示。它支持 co_await，所以是个 Awaitable 类型。co_await 操作符返回一个 awaiter 也就是后面要实现的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">async_manual_reset_event</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">  async_manual_reset_event(<span class="keyword">bool</span> initiallySet = <span class="literal">false</span>) <span class="keyword">noexcept</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// No copying/moving</span></span><br><span class="line">  async_manual_reset_event(<span class="keyword">const</span> async_manual_reset_event&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  async_manual_reset_event(async_manual_reset_event&amp;&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  async_manual_reset_event&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> async_manual_reset_event&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  async_manual_reset_event&amp; <span class="keyword">operator</span>=(async_manual_reset_event&amp;&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">is_set</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">awaiter</span>;</span></span><br><span class="line">  <span class="function">awaiter <span class="keyword">operator</span> <span class="title">co_await</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set</span><span class="params">()</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">reset</span><span class="params">()</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"></span><br><span class="line">  <span class="keyword">friend</span> <span class="class"><span class="keyword">struct</span> <span class="title">awaiter</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// - 'this' =&gt; set state</span></span><br><span class="line">  <span class="comment">// - otherwise =&gt; not set, head of linked list of awaiter*.</span></span><br><span class="line">  <span class="keyword">mutable</span> <span class="built_in">std</span>::atomic&lt;<span class="keyword">void</span>*&gt; m_state;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个 awaiter 如下所示:</p><ol><li>首先，它要持有一个 Awaitable 对象的指针，这是因为它要知道自己是要 await 什么东西。</li><li>然后，它还要扮演一个在 awaiter 链表里面的一个节点的角色，所以它应该能访问自己后面的那个 awaiter。</li><li>然后，它还要存储 coroutine_handle 对象，这样当 await_suspend 被调用后，它能知道如何去 resume coroutine。因为我们没 await_transform 啥的，所以这里 coroutine_handle 对象就是 <code>coroutine_handle&lt;void&gt;</code>。</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">async_manual_reset_event</span>:</span>:awaiter</span><br><span class="line">&#123;</span><br><span class="line">  awaiter(<span class="keyword">const</span> async_manual_reset_event&amp; event) <span class="keyword">noexcept</span></span><br><span class="line">  : m_event(event)</span><br><span class="line">  &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt; awaitingCoroutine)</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> async_manual_reset_event&amp; m_event;</span><br><span class="line">  <span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt; m_awaitingCoroutine;</span><br><span class="line">  awaiter* m_next;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>await_ready 要做的就是如果已经 set 了，就不再 suspend。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> async_manual_reset_event::awaiter::await_ready() <span class="keyword">const</span> <span class="keyword">noexcept</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">return</span> m_event.is_set();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>await_suspend 最为重要：</p><ol><li>首先，它要保存 coroutine_handle，从而后续可以调用 <code>coroutine_handle.resume()</code> 方法。</li><li>然后，就要将 awaiter 放到链表里面<br> 将链表头的指针即 m_state 设置为 this。注意，这里的 this 是 awaiter；而 oldValue 是 async_manual_reset_event，即 Awaitable。<br> 如果添加成功，就返回 true，表示不会立即 resume 这个 coroutine。否则，就返回 false，表示可以立即 resume。这也回答了之前的一个【Q】，也就是 await_suspend 和 await_ready 的返回值到底作用有什么不同。</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> async_manual_reset_event::awaiter::await_suspend(</span><br><span class="line">  <span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt; awaitingCoroutine) <span class="keyword">noexcept</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// Special m_state value that indicates the event is in the 'set' state.</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">void</span>* <span class="keyword">const</span> setState = &amp;m_event;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Remember the handle of the awaiting coroutine.</span></span><br><span class="line">  m_awaitingCoroutine = awaitingCoroutine;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Try to atomically push this awaiter onto the front of the list.</span></span><br><span class="line">  <span class="keyword">void</span>* oldValue = m_event.m_state.load(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// Resume immediately if already in 'set' state.</span></span><br><span class="line">    <span class="keyword">if</span> (oldValue == setState) <span class="keyword">return</span> <span class="literal">false</span>; </span><br><span class="line"></span><br><span class="line">    <span class="comment">// Update linked list to point at current head.</span></span><br><span class="line">    m_next = <span class="keyword">static_cast</span>&lt;awaiter*&gt;(oldValue);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Finally, try to swap the old list head, inserting this awaiter</span></span><br><span class="line">    <span class="comment">// as the new list head.</span></span><br><span class="line">  &#125; <span class="keyword">while</span> (!m_event.m_state.compare_exchange_weak(</span><br><span class="line">             oldValue,</span><br><span class="line">             <span class="keyword">this</span>,</span><br><span class="line">             <span class="built_in">std</span>::memory_order_release,</span><br><span class="line">             <span class="built_in">std</span>::memory_order_acquire));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Successfully enqueued. Remain suspended.</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【Q】这里 await_resume 起到了什么作用，为啥它是空的？</p><h2 id="Filling-out-the-rest-of-the-event-class"><a href="#Filling-out-the-rest-of-the-event-class" class="headerlink" title="Filling out the rest of the event class"></a>Filling out the rest of the event class</h2><p>如果是 set 状态，则改为 nullptr。所以 m_state 有三种情况：</p><ol><li>nullptr<br> 没有 set，但是也没有 awaiter 在等</li><li>oldValue<br> set 了</li><li>其他<br> 有 awaiter 在等，并且指向了链表头</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> async_manual_reset_event::reset() <span class="keyword">noexcept</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">void</span>* oldValue = <span class="keyword">this</span>;</span><br><span class="line">  m_state.compare_exchange_strong(oldValue, <span class="literal">nullptr</span>, <span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面是 set 操作。其实有点类似于 CV。实际上的行为就是对所有的 waiter 调用 <code>coroutine_handle.resume()</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> async_manual_reset_event::<span class="built_in">set</span>() <span class="keyword">noexcept</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// Needs to be 'release' so that subsequent 'co_await' has</span></span><br><span class="line">  <span class="comment">// visibility of our prior writes.</span></span><br><span class="line">  <span class="comment">// Needs to be 'acquire' so that we have visibility of prior</span></span><br><span class="line">  <span class="comment">// writes by awaiting coroutines.</span></span><br><span class="line">  <span class="keyword">void</span>* oldValue = m_state.exchange(<span class="keyword">this</span>, <span class="built_in">std</span>::memory_order_acq_rel);</span><br><span class="line">  <span class="keyword">if</span> (oldValue != <span class="keyword">this</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// Wasn't already in 'set' state.</span></span><br><span class="line">    <span class="comment">// Treat old value as head of a linked-list of waiters</span></span><br><span class="line">    <span class="comment">// which we have now acquired and need to resume.</span></span><br><span class="line">    <span class="keyword">auto</span>* waiters = <span class="keyword">static_cast</span>&lt;awaiter*&gt;(oldValue);</span><br><span class="line">    <span class="keyword">while</span> (waiters != <span class="literal">nullptr</span>)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// Read m_next before resuming the coroutine as resuming</span></span><br><span class="line">      <span class="comment">// the coroutine will likely destroy the awaiter object.</span></span><br><span class="line">      <span class="keyword">auto</span>* next = waiters-&gt;m_next;</span><br><span class="line">      waiters-&gt;m_awaitingCoroutine.resume();</span><br><span class="line">      waiters = next;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【Q】这里的 awaiter 都是在什么地方被析构的呢？我理解这里的 awaiter 都是 local variable，生命周期等同于 co_await 的 <code>&lt;expr&gt;</code>。可以看到，co_await 返回的就是这个 awaiter。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">async_manual_reset_event::awaiter</span><br><span class="line">async_manual_reset_event::<span class="function"><span class="keyword">operator</span> <span class="title">co_await</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> awaiter&#123; *<span class="keyword">this</span> &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="https://godbolt.org/g/Ad47tH" target="_blank" rel="noopener">https://godbolt.org/g/Ad47tH</a> 是源码</p><h1 id="Understanding-the-promise-type"><a href="#Understanding-the-promise-type" class="headerlink" title="Understanding the promise type"></a>Understanding the promise type</h1><p><a href="https://lewissbaker.github.io/2018/09/05/understanding-the-promise-type" target="_blank" rel="noopener">https://lewissbaker.github.io/2018/09/05/understanding-the-promise-type</a></p><h2 id="Coroutine-Concepts"><a href="#Coroutine-Concepts" class="headerlink" title="Coroutine Concepts"></a>Coroutine Concepts</h2><p>Promise 接口用来自定义 coroutine 自己的行为，比如它被调用的时候，或者它返回（无论是正常值还是异常）的时候。</p><h2 id="Promise-objects"><a href="#Promise-objects" class="headerlink" title="Promise objects"></a>Promise objects</h2><p>字如其名，Promise 确实有类似 <code>std::promise</code> 的作用，但是它的功能更为衍生，实际上应该将它理解为一个 coroutine state controller。</p><p>比如，写了一个 coroutine function，编译器会转换成下面的形式，其中 <code>&lt;body-statements&gt;</code> 是函数体。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  co_await promise.initial_suspend();</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    &lt;body-statements&gt;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">catch</span> (...)</span><br><span class="line">  &#123;</span><br><span class="line">    promise.unhandled_exception();</span><br><span class="line">  &#125;</span><br><span class="line">FinalSuspend:</span><br><span class="line">  co_await promise.final_suspend();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当 coroutine 被调用的时候，会：</p><ol><li>【可选】用 operator new 分配一个 coroutine frame。<br> 【Q】为什么这里是可选的？见下文。</li><li>将 parameter 拷贝到 coroutine frame 里面。</li><li>调用 P 的构造函数创建 promise 对象。</li><li>调用 <code>promise.get_return_object()</code> 方法会得到一个东西，可以在第一次 suspend 的时候返回给 caller。这个东西被保存为 local variable。<br> 我理解这个东西，也就是后面会看到的 <code>task</code> 就是 “Coroutine 本身”。特别地：<ul><li><code>task</code> 里面会持有一个 std::coroutine_handle 对象。</li><li><code>task</code> 里面会支持 co_await 操作符，也就是说它是一个 Awaitable 对象。</li><li>promise 对象的类型就是 <code>task::promise_type</code>。</li></ul></li><li>调用 <code>promise.initial_suspend()</code>，并 <code>co_await</code> 结果。</li><li>当 co_await <code>promise.initial_suspend()</code> resume（这里同样可能不挂起直接返回），coroutine 开始执行 <code>&lt;body-statements&gt;</code>。</li></ol><p>在 co_return 被执行的时候，会：</p><ol><li>调用 <code>promise.return_void()</code> 或者 <code>promise.return_value(&lt;expr&gt;)</code>。</li><li>销毁所有的自动变量。</li><li>调用 <code>promise.final_suspend()</code>，并且 co_await 结果。</li></ol><p>特别地，如果 <code>&lt;body-statements&gt;</code> 抛出异常，则：</p><ol><li>捕获这个异常，并调用 <code>promise.unhandled_exception()</code>。</li><li>调用 <code>promise.final_suspend()</code>，并且 co_await 结果。</li></ol><p>一旦 execution propagates outside of the coroutine body，那么 coroutine frame 就会被销毁。此时：</p><ol><li>调用 promise 对象的析构函数。</li><li>调用 parameter 的析构函数。</li><li>【可选】调用 operator delete 释放内存。</li><li>将执行权交还给 resumer 或者 caller。</li></ol><p>当第一次执行到 <code>&lt;return-to-caller-or-resumer&gt;</code> 的时候，或者 coroutine 没有执行到这个点就完成了，那么这个 coroutine 要么是 suspend 了，要么是 destroy 了。此时这之前通过调用 <code>promise.get_return_object()</code> 得到的 return-object 会被直接返回给 caller。回顾下，这里的 <code>&lt;return-to-caller-or-resumer&gt;</code> 是在 <code>co_await</code> 中，执行完 <code>await_suspend</code> 之后的点。</p><h2 id="Allocating-a-coroutine-frame"><a href="#Allocating-a-coroutine-frame" class="headerlink" title="Allocating a coroutine frame"></a>Allocating a coroutine frame</h2><p>First, the compiler generates a call to operator new to allocate memory for the coroutine frame.</p><p>If the promise type, P, defines a custom operator new method then that is called, otherwise the global operator new is called.</p><p>要点：</p><ol><li>operator new 分配的大小并不是 sizeof(P)，而是整个 coroutine frame 的大小，这个是由编译器计算的。包含了 parameter，promise 对象，local variables 以及其他的一些用来存储 coroutine state 的结构。我理解之前我们白嫖的也是这一段的空间。</li><li>编译期可以省略这个 operator new，而直接在 caller 的 stack-frame 或者 coroutine-frame 中分配，当：<ul><li>可以断定 coroutine frame 的生命周期是小于 caller 的。</li><li>并且编译期可以在调用的时候就能看到整个 coroutine frame 需要的大小。<br>目前 Coroutine TS 并没有 guarantee 任何的 elision 的情况，所以我们要处理分配 coroutine frame 的时候出现 std::bad_alloc 的情况。这里有一些异常处理相关的问题，一般我们就直接 terminate 掉了。但如果 promise 对象支持静态的 <code>P::get_return_object_on_allocation_failure()</code> 函数，则可以不抛出异常。</li></ul></li></ol><h3 id="Customising-coroutine-frame-memory-allocation"><a href="#Customising-coroutine-frame-memory-allocation" class="headerlink" title="Customising coroutine frame memory allocation"></a>Customising coroutine frame memory allocation</h3><p>Your promise type can define an overload of operator new() that will be called instead of global-scope operator new if the compiler needs to allocate memory for a coroutine frame that uses your promise type.</p><p>For example:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">my_promise_type</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span>* <span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="built_in">std</span>::<span class="keyword">size_t</span> size)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">void</span>* ptr = my_custom_allocate(size);</span><br><span class="line">    <span class="keyword">if</span> (!ptr) <span class="keyword">throw</span> <span class="built_in">std</span>::bad_alloc&#123;&#125;;</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="keyword">void</span>* ptr, <span class="built_in">std</span>::<span class="keyword">size_t</span> size)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    my_custom_free(ptr, size);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>同样，也可以提供一个 custom allocator。如下所示，可以提供一个重载版本的 <code>P::operator new()</code>，它额外接受诸如 allocator 这样的参数，这样就可以在 new 的时候调用 <code>allocator.allocate()</code> 来分配内存了。</p><p>这里有个问题，coroutine frame 中存储的 parameter 在 <code>operator delete</code> 之前就已经被析构了，那如何获得 allocator 呢？所以，为了能在 <code>operator delete</code> 中调用 <code>allocator.deallocate()</code>，我们要将 allocator 存在 <code>allocatorOffset</code> 上面。</p><p>简而言之，就是在创建 my_promise_type 之前分配空间的时候，多分配一部分空间，用来存放对应的 allocator。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> ALLOCATOR&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">my_promise_type</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span>... ARGS&gt;</span><br><span class="line">  <span class="function"><span class="keyword">void</span>* <span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="built_in">std</span>::<span class="keyword">size_t</span> sz, <span class="built_in">std</span>::<span class="keyword">allocator_arg_t</span>, ALLOCATOR&amp; allocator, ARGS&amp;... args)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="comment">// Round up sz to next multiple of ALLOCATOR alignment</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="keyword">size_t</span> allocatorOffset =</span><br><span class="line">      (sz + <span class="keyword">alignof</span>(ALLOCATOR) - <span class="number">1u</span>) &amp; ~(<span class="keyword">alignof</span>(ALLOCATOR) - <span class="number">1u</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Call onto allocator to allocate space for coroutine frame.</span></span><br><span class="line">    <span class="keyword">void</span>* ptr = allocator.allocate(allocatorOffset + <span class="keyword">sizeof</span>(ALLOCATOR));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Take a copy of the allocator (assuming noexcept copy constructor here)</span></span><br><span class="line">    <span class="keyword">new</span> (((<span class="keyword">char</span>*)ptr) + allocatorOffset) ALLOCATOR(allocator);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="keyword">void</span>* ptr, <span class="built_in">std</span>::<span class="keyword">size_t</span> sz)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="keyword">size_t</span> allocatorOffset =</span><br><span class="line">      (sz + <span class="keyword">alignof</span>(ALLOCATOR) - <span class="number">1u</span>) &amp; ~(<span class="keyword">alignof</span>(ALLOCATOR) - <span class="number">1u</span>);</span><br><span class="line"></span><br><span class="line">    ALLOCATOR&amp; allocator = *<span class="keyword">reinterpret_cast</span>&lt;ALLOCATOR*&gt;(</span><br><span class="line">      ((<span class="keyword">char</span>*)ptr) + allocatorOffset);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Move allocator to local variable first so it isn't freeing its</span></span><br><span class="line">    <span class="comment">// own memory from underneath itself.</span></span><br><span class="line">    <span class="comment">// Assuming allocator move-constructor is noexcept here.</span></span><br><span class="line">    ALLOCATOR allocatorCopy = <span class="built_in">std</span>::move(allocator);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// But don't forget to destruct allocator object in coroutine frame</span></span><br><span class="line">    allocator.~ALLOCATOR();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Finally, free the memory using the allocator.</span></span><br><span class="line">    allocatorCopy.deallocate(ptr, allocatorOffset + <span class="keyword">sizeof</span>(ALLOCATOR));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>To hook up the custom <code>my_promise_type</code> to be used for coroutines that pass <code>std::allocator_arg</code> as the first parameter, you need to specialise the <code>coroutine_traits</code> class (see section on coroutine_traits below for more details).</p><p>For example:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>::experimental</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> ALLOCATOR, <span class="keyword">typename</span>... ARGS&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_traits</span>&lt;my_return_type, std::allocator_arg_t, ALLOCATOR, ARGS...&gt;</span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">    <span class="keyword">using</span> promise_type = my_promise_type&lt;ALLOCATOR&gt;;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Note that even if you customise the memory allocation strategy for a coroutine, the compiler is still allowed to elide the call to your memory allocator.</p><h2 id="Copying-parameters-to-the-coroutine-frame"><a href="#Copying-parameters-to-the-coroutine-frame" class="headerlink" title="Copying parameters to the coroutine frame"></a>Copying parameters to the coroutine frame</h2><p>The coroutine needs to copy any parameters passed to the coroutine function by the original caller into the coroutine frame so that they remain valid after the coroutine is suspended.</p><p>复制 parameter 到 coroutine frame 的目的是保证了 coroutine 被 suspend 之后，这些东西都还在。</p><ol><li>如果是 by value 的复制，那么会调用 move-ctor。</li><li>如果是 by reference 的复制，无论是左值还是右值，那么只有引用本身会被复制，指向的对象是不会的。</li></ol><p>对于只有 trivial destructor 的 parameter，编译器可以 elide 掉 copy，如果这个 parameter 在某个可达的 <code>&lt;return-to-caller-or-resumer&gt;</code> 之后就不再被访问了。</p><p>C++ 中用完美转发会比较多，这在 coroutine 中经常会导致 UB。原因就是传入了 reference。</p><p>If any of the parameter copy/move constructors throws an exception then any parameters already constructed are destructed, the coroutine frame is freed and the exception propagates back out to the caller.</p><h2 id="Constructing-the-promise-object"><a href="#Constructing-the-promise-object" class="headerlink" title="Constructing the promise object"></a>Constructing the promise object</h2><p>先复制 parameter 再构造 promise 的原因是允许 promise 对象可以基于复制后的 parameter 构建。</p><p>First, the compiler checks to see if there is an overload of the promise constructor that can accept lvalue references to each of the copied parameters. If the compiler finds such an overload then the compiler generates a call to that constructor overload. If it does not find such an overload then the compiler falls back to generating a call to the promise type’s default constructor.</p><p>这个听起来挺神奇的，好像是既支持“默认”的 aggregate initialization，又支持 default initialization。</p><blockquote><p>Note that the ability for the promise constructor to “peek” at the parameters was a relatively recent change to the Coroutines TS, being adopted in N4723 at the Jacksonville 2018 meeting. See P0914R1 for the proposal. Thus it may not be supported by some older versions of Clang or MSVC.</p></blockquote><p>If the promise constructor throws an exception then the parameter copies are destructed and the coroutine frame freed during stack unwinding before the exception propagates out to the caller.</p><h2 id="Obtaining-the-return-object"><a href="#Obtaining-the-return-object" class="headerlink" title="Obtaining the return object"></a>Obtaining the return object</h2><p>The first thing a coroutine does with the promise object is obtain the return-object by calling promise.get_return_object().</p><p>在 coroutine 被建立后，首先是调用 <code>promise.get_return_object()</code> 获取 return-object。return-object 后续会被返回给 coroutine 的 caller。如前文所说，返回的时间点是第一次 suspend，或者 coroutine 完成了。</p><p>执行大抵如下。注意，在 “Coroutine Handles” 这一节中介绍了，可以通过 from_promise 从 promise 重新构建出 coroutine_handle。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Pretend there's a compiler-generated structure called 'coroutine_frame'</span></span><br><span class="line"><span class="comment">// that holds all of the state needed for the coroutine. It's constructor</span></span><br><span class="line"><span class="comment">// takes a copy of parameters and default-constructs a promise object.</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">coroutine_frame</span> &#123;</span> ... &#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">T <span class="title">some_coroutine</span><span class="params">(P param)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">auto</span>* f = <span class="keyword">new</span> coroutine_frame(<span class="built_in">std</span>::forward&lt;P&gt;(param));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> returnObject = f-&gt;promise.get_return_object();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Start execution of the coroutine body by resuming it.</span></span><br><span class="line">  <span class="comment">// This call will return when:</span></span><br><span class="line">  <span class="comment">// 1. the coroutine gets to the first suspend-point</span></span><br><span class="line">  <span class="comment">// 2. or when the coroutine runs to completion.</span></span><br><span class="line">  coroutine_handle&lt;<span class="keyword">decltype</span>(f-&gt;promise)&gt;::from_promise(f-&gt;promise).resume();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Then the return object is returned to the caller.</span></span><br><span class="line">  <span class="keyword">return</span> returnObject;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，必须要在执行 coroutine body 之前就获取 return-object。这因为 coroutine frame 以及它持有的 promise 对象可能在 <code>coroutine_handle::resume()</code> 返回前就被销毁掉。也就是说，在 resume() 返回前，程序可能处于 suspend 状态的，我理解后续这个 coroutine 就可能被直接销毁掉了。</p><p>销毁未必发生在 caller 的线程上。因此，在开始执行 coroutine body 之后调用 <code>get_return_object()</code> 是不安全的。</p><h2 id="The-initial-suspend-point"><a href="#The-initial-suspend-point" class="headerlink" title="The initial-suspend point"></a>The initial-suspend point</h2><p>The next thing the coroutine executes once the coroutine frame has been initialised and the return object has been obtained is execute the statement <code>co_await promise.initial_suspend()</code>;</p><p>执行 <code>co_await promise.initial_suspend()</code>，实际上允许 <code>promise_type</code> 也就是之前提到的 P 的作者，可以控制 coroutine 到底是立即执行，还是先 suspend 等调度。这有点类似于 std::async 里面相同参数的意思了。</p><p>如果在 initial suspend 点选择 suspend 的话，后续可以被 resume 或者被 destroy。</p><p><code>co_await promise.initial_suspend()</code> 的结果被丢弃，所以实现上可以从 <code>await_resume</code> 返回 void。</p><p>注意1：<code>initial_suspend()</code> 这个调用并没有被 try-catch 块环绕，也就是说这里发生的异常，更准确说是在它的 <code>&lt;return-to-caller-or-resumer&gt;</code> 之前的异常会在销毁 coroutine frame 和 return-object 之后被直接抛给 caller。</p><p>注意2：如果 return-object 中有某个 RAII 语义，能够在它被销毁的时候销毁 coroutine frame，那么就需要保证 <code>co_await promise.initial_suspend()</code> 不会抛出异常，否则会发生 double free 的问题。当然也有提案说要去修改这个行为。</p><p>但实际上因为大部分 coroutine 的 <code>initial_suspend()</code> 只会返回都是 noexcept 的 suspend_never 或者 suspend_always，所以这不是个问题。</p><h2 id="Returning-to-the-caller"><a href="#Returning-to-the-caller" class="headerlink" title="Returning to the caller"></a>Returning to the caller</h2><p>当 coroutine 执行到第一个 <code>&lt;return-to-caller-or-resumer&gt;</code> 点（如果没有这个点就是执行完成）的时候，从 get_return_object 获取的 return-object 会被返回给 caller。</p><p>注意，return-object 的类型不一定是 coroutine function 的 return type。可以进行隐式转换。</p><h2 id="Returning-from-the-coroutine-using-co-return"><a href="#Returning-from-the-coroutine-using-co-return" class="headerlink" title="Returning from the coroutine using co_return"></a>Returning from the coroutine using co_return</h2><p>co_return 会被转化为:</p><ol><li><code>promise.return_void()</code><br><code>co_return &lt;expr&gt; </code></li><li><code>promise.return_value(&lt;expr&gt;)</code><br> 如果 expr 的类型是 void，则 <code>&lt;expr&gt;; promise.return_void();</code>。<br> 如果 expr 的类型不是 void，则 <code>promise.return_value(&lt;expr&gt;);</code></li></ol><p>Note that if execution runs off the end of a coroutine without a <code>co_return</code> statement then this is equivalent to having a <code>co_return</code>; at the end of the function body. In this case, if the <code>promise_type</code> does not have a <code>return_void()</code> method then the behaviour is undefined.</p><p>If either the evaluation of <expr> or the call to <code>promise.return_void()</code> or <code>promise.return_value()</code> throws an exception then the exception still propagates to <code>promise.unhandled_exception()</code>.</expr></p><h2 id="Handling-exceptions-that-propagate-out-of-the-coroutine-body"><a href="#Handling-exceptions-that-propagate-out-of-the-coroutine-body" class="headerlink" title="Handling exceptions that propagate out of the coroutine body"></a>Handling exceptions that propagate out of the coroutine body</h2><h2 id="The-final-suspend-point"><a href="#The-final-suspend-point" class="headerlink" title="The final-suspend point"></a>The final-suspend point</h2><p>final_suspend 的调用发生在 <code>return_void()</code>、<code>return_value()</code> 和 <code>unhandled_exception()</code> 之后。也发生在所有的 local variable 都被销毁之后。</p><p>This allows the coroutine to execute some logic, such as publishing a result, signalling completion or resuming a continuation. It also allows the coroutine to optionally suspend immediately before execution of the coroutine runs to completion and the coroutine frame is destroyed.</p><p>在 final_suspend 点 resume 一个 coroutine 是 UB 的，对于这个状态的 coroutine 只可以调用 destroy。</p><p>The rationale for this limitation, according to Gor Nishanov, is that this provides several optimisation opportunities for the compiler due to the reduction in the number of suspend states that need to be represented by the coroutine and a potential reduction in the number of branches required.</p><p>尽管可以在 final_suspend 处不 suspend，但建议是尽量 suspend。因为这可以强迫你在 coroutine 外面调用 destroy（一般是通过某种 RAII 机制）。这样编译器就能够更容易确定 coroutine frame 的 lifetime 是被 caller 的 lifetime 覆盖了的，从而就可以执行之前说的 elide 掉 coroutine frame 内存分配的优化。</p><h2 id="How-the-compiler-chooses-the-promise-type"><a href="#How-the-compiler-chooses-the-promise-type" class="headerlink" title="How the compiler chooses the promise type"></a>How the compiler chooses the promise type</h2><p>编译期可以自动推导 promise_type。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">task&lt;<span class="keyword">float</span>&gt; foo(<span class="built_in">std</span>::<span class="built_in">string</span> x, <span class="keyword">bool</span> flag);</span><br><span class="line">--&gt;</span><br><span class="line"><span class="keyword">typename</span> coroutine_traits&lt;task&lt;<span class="keyword">float</span>&gt;, <span class="built_in">std</span>::<span class="built_in">string</span>, <span class="keyword">bool</span>&gt;::promise_type;</span><br><span class="line"></span><br><span class="line">task&lt;<span class="keyword">void</span>&gt; my_class::method1(<span class="keyword">int</span> x) <span class="keyword">const</span>;</span><br><span class="line">--&gt;</span><br><span class="line"><span class="keyword">typename</span> coroutine_traits&lt;task&lt;<span class="keyword">void</span>&gt;, <span class="keyword">const</span> my_class&amp;, <span class="keyword">int</span>&gt;::promise_type;</span><br><span class="line"></span><br><span class="line">task&lt;foo&gt; my_class::method2() &amp;&amp;;</span><br><span class="line">--&gt;</span><br><span class="line"><span class="keyword">typename</span> coroutine_traits&lt;task&lt;foo&gt;, my_class&amp;&amp;&gt;::promise_type;</span><br></pre></td></tr></table></figure><p>可以自定义 promise_type</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>::experimental</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span>... ARGS&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_traits</span>&lt;std::optional&lt;T&gt;, ARGS...&gt;</span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">    <span class="keyword">using</span> promise_type = optional_promise&lt;T&gt;;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Identifying-a-specific-coroutine-activation-frame"><a href="#Identifying-a-specific-coroutine-activation-frame" class="headerlink" title="Identifying a specific coroutine activation frame"></a>Identifying a specific coroutine activation frame</h2><p>介绍 coroutine_handle 这个类型。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>::experimental</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Promise = <span class="keyword">void</span>&gt;</span><br><span class="line">  struct coroutine_handle;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Type-erased coroutine handle. Can refer to any kind of coroutine.</span></span><br><span class="line">  <span class="comment">// Doesn't allow access to the promise object.</span></span><br><span class="line">  <span class="keyword">template</span>&lt;&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_handle</span>&lt;void&gt;</span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">    <span class="comment">// Constructs to the null handle.</span></span><br><span class="line">    <span class="function"><span class="keyword">constexpr</span> <span class="title">coroutine_handle</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Convert to/from a void* for passing into C-style interop functions.</span></span><br><span class="line">    <span class="function"><span class="keyword">constexpr</span> <span class="keyword">void</span>* <span class="title">address</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">constexpr</span> coroutine_handle <span class="title">from_address</span><span class="params">(<span class="keyword">void</span>* addr)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Query if the handle is non-null.</span></span><br><span class="line">    <span class="function"><span class="keyword">constexpr</span> <span class="keyword">explicit</span> <span class="keyword">operator</span> <span class="title">bool</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Query if the coroutine is suspended at the final_suspend point.</span></span><br><span class="line">    <span class="comment">// Undefined behaviour if coroutine is not currently suspended.</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">done</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Resume/Destroy the suspended coroutine</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">resume</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Coroutine handle for coroutines with a known promise type.</span></span><br><span class="line">  <span class="comment">// Template argument must exactly match coroutine's promise type.</span></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Promise&gt;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">coroutine_handle</span> :</span> coroutine_handle&lt;&gt;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">using</span> coroutine_handle&lt;&gt;::coroutine_handle;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">constexpr</span> coroutine_handle <span class="title">from_address</span><span class="params">(<span class="keyword">void</span>* addr)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Access to the coroutine's promise object.</span></span><br><span class="line">    <span class="function">Promise&amp; <span class="title">promise</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// You can reconstruct the coroutine handle from the promise object.</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> coroutine_handle <span class="title">from_promise</span><span class="params">(Promise&amp; promise)</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它可以由两个方式获得：</p><ol><li>await_suspend 的参数<br> 这类似于 CPS 的方式。</li><li>通过 promise 从 from_promise 构造</li></ol><p>coroutine_handle 并不是 RAII 的，需要调用 destroy 去释放它。这样设计是为了减少 overhead。</p><p>You should generally try to use higher-level types that provide the RAII semantics for coroutines, such as those provided by cppcoro (shameless plug), or write your own higher-level types that encapsulate the lifetime of the coroutine frame for your coroutine type.</p><h2 id="Customising-the-behaviour-of-co-await"><a href="#Customising-the-behaviour-of-co-await" class="headerlink" title="Customising the behaviour of co_await"></a>Customising the behaviour of co_await</h2><p>promise 类型可以可选地自定义 co_await 表达式的行为。<br>只需要定义这个类型的 <code>await_transform()</code> 方法，编译器就能够将所有的 <code>co_await &lt;expr&gt;</code> 转换为 <code>co_await promise.await_transform(&lt;expr&gt;)</code>。</p><p>为什么要提供这个功能呢？</p><h3 id="原因1"><a href="#原因1" class="headerlink" title="原因1"></a>原因1</h3><p>因为有些类型不是 awaitable 的，所以要提供这个转换。</p><p>For example, a promise type for coroutines with a <code>std::optional&lt;T&gt;</code> return-type might provide an <code>await_transform()</code> overload that takes a <code>std::optional&lt;U&gt;</code> and that returns an awaitable type that either returns a value of type U or suspends the coroutine if the awaited value contains <code>nullopt</code>.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">optional_promise</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> U&gt;</span><br><span class="line">  <span class="function"><span class="keyword">auto</span> <span class="title">await_transform</span><span class="params">(<span class="built_in">std</span>::optional&lt;U&gt;&amp; value)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">awaiter</span></span></span><br><span class="line"><span class="class">    &#123;</span></span><br><span class="line">      <span class="built_in">std</span>::optional&lt;U&gt;&amp; value;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">      explicit awaiter(std::optional&lt;U&gt;&amp; x) noexcept : value(x) &#123;&#125;</span><br><span class="line">      <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> value.has_value(); &#125;</span><br><span class="line">      <span class="function"><span class="keyword">void</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt;)</span> <span class="keyword">noexcept</span> </span>&#123;&#125;</span><br><span class="line">      <span class="function">U&amp; <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> *value; &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">return</span> awaiter&#123; value &#125;;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="原因2"><a href="#原因2" class="headerlink" title="原因2"></a>原因2</h3><p>It lets you disallow awaiting on certain types by declaring <code>await_transform</code> overloads as deleted.</p><p>For example, a promise type for <code>std::generator&lt;T&gt;</code> return-type might declare a deleted <code>await_transform()</code> template member function that accepts any type. This basically disables use of co_await within the coroutine.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">generator_promise</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Disable any use of co_await within this type of coroutine.</span></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> U&gt;</span><br><span class="line">  <span class="built_in">std</span>::experimental::<span class="function">suspend_never <span class="title">await_transform</span><span class="params">(U&amp;&amp;)</span> </span>= <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="原因3"><a href="#原因3" class="headerlink" title="原因3"></a>原因3</h3><p>It lets you adapt and change the behaviour of normally awaitable values.</p><p>For example, you could define a type of coroutine that ensured that the coroutine always resumed from every co_await expression on an associated executor by wrapping the awaitable in a resume_on() operator (see cppcoro::resume_on()).</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> Executor&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">executor_task_promise</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  Executor executor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Awaitable&gt;</span><br><span class="line">  <span class="function"><span class="keyword">auto</span> <span class="title">await_transform</span><span class="params">(Awaitable&amp;&amp; awaitable)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">using</span> cppcoro::resume_on;</span><br><span class="line">    <span class="keyword">return</span> resume_on(<span class="keyword">this</span>-&gt;executor, <span class="built_in">std</span>::forward&lt;Awaitable&gt;(awaitable));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>As a final word on <code>await_transform()</code>, it’s important to note that if the promise type defines any <code>await_transform()</code> members then this triggers the compiler to transform all <code>co_await</code> expressions to call promise.await_transform(). 所以，如果只是希望对某些类型定制 co_await 行为，最好为 <code>await_transform()</code> 提供一个只 forward argument 的重载。</p><h2 id="Customising-the-behaviour-of-co-yield"><a href="#Customising-the-behaviour-of-co-yield" class="headerlink" title="Customising the behaviour of co_yield"></a>Customising the behaviour of co_yield</h2><p>编译器会把 <code>co_yield &lt;expr&gt;</code> 转换为 <code>co_await promise.yield_value(&lt;expr&gt;)</code>。因此 promise 对象可以定制 <code>yield_value</code> 方法。</p><p>如果编译器没有定制这个方法，该方法不会有默认的行为。所以需要显式提供这样的方法，promise 类型才能支持 co_yield。</p><p>如下所示，对一个 generator 类型提供了 yield_value 方法。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">generator_promise</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  T* valuePtr;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::experimental::<span class="function">suspend_always <span class="title">yield_value</span><span class="params">(T&amp; value)</span> <span class="keyword">noexcept</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="comment">// Stash the address of the yielded value and then return an awaitable</span></span><br><span class="line">    <span class="comment">// that will cause the coroutine to suspend at the co_yield expression.</span></span><br><span class="line">    <span class="comment">// Execution will then return from the call to coroutine_handle&lt;&gt;::resume()</span></span><br><span class="line">    <span class="comment">// inside either generator&lt;T&gt;::begin() or generator&lt;T&gt;::iterator::operator++().</span></span><br><span class="line">    valuePtr = <span class="built_in">std</span>::addressof(value);</span><br><span class="line">    <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h1 id="Understanding-Symmetric-Transfer"><a href="#Understanding-Symmetric-Transfer" class="headerlink" title="Understanding Symmetric Transfer"></a>Understanding Symmetric Transfer</h1><p><a href="https://lewissbaker.github.io/2020/05/11/understanding_symmetric_transfer" target="_blank" rel="noopener">https://lewissbaker.github.io/2020/05/11/understanding_symmetric_transfer</a></p><p>在 Coroutine TS 刚开始被提出的时候，有一个限制，会导致轻易的 stack-overflow。为了避免它，就需要在 <code>task&lt;T&gt;</code> 类型中引入额外的同步开销。</p><p>在 2018 年，引入了一个 symmetric transfer 的特性，使得我们可以挂起一个 Coroutine，并 Resume 另一个，但是不会消耗栈空间了。</p><h2 id="First-some-background-on-how-a-task-coroutine-works"><a href="#First-some-background-on-how-a-task-coroutine-works" class="headerlink" title="First some background on how a task coroutine works"></a>First some background on how a task coroutine works</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">task <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  co_return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">task <span class="title">bar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">co_await <span class="title">foo</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不放展开看看 <code>bar()</code> 在 <code>co_await foo()</code> 的时候都发生了什么：</p><ol><li>调用 foo 需要有下面几步<br> 为 coroutine frame 分配寻出空间。<br> 将参数复制到 coroutine frame 里面。在当前 case 里面没有参数，所以就是一个空操作。<br> 在 coroutine frame 里面构造 promise object。<br> 调用 <code>promise.get_return_object()</code> 获得 foo() 的返回值。这个过程中会产生被返回的 task 对象，并使用 std::coroutine_handle 创建它。如前所述，std::coroutine_handle 持有刚创建的 coroutine frame 的引用。<br> 在 initial-suspend point 挂起 coroutine 的执行。<br> 返回 task 对象给到 bar()。</li><li>后面，bar() 会执行 co_await<br> <code>bar()</code> 会被挂起，然后调用由 <code>foo()</code> 返回的 task 对象上的 <code>await_suspend()</code> 方法。会把指向 bar 的 coroutine frame 的 <code>std::coroutine_handle</code> 传给该方法。<br> 在 <code>await_suspend()</code> 中，会存储 bar() 的 <code>std::coroutine_handle</code> 到 foo 的 promise 对象中【A】，然后通过调用 <code>foo</code> 的 <code>std::coroutine_handle</code> 的 resume 方法去 resume foo() 的执行。</li><li>foo() 会同步地执行。</li><li>foo() 会在 final-suspend point 挂起，然后 resume bar。这是根据被存在 promise 对象中的 std::coroutine_handle 来找到的，见【A】步骤。</li><li>bar() 会 resume，继续执行，并最终到达 co_await 语句处，并调用临时 task 对象的析构函数。</li><li>task 对象执行析构。因为这个 task 对象是 foo() 返回的，所以它会调用 foo() 的 coroutine handle 上的 <code>.destroy()</code> 方法，这样就会销毁 coroutine frame，包括 promise 对象和之前复制了的参数之内。</li></ol><h2 id="Outline-of-a-task-implementation"><a href="#Outline-of-a-task-implementation" class="headerlink" title="Outline of a task implementation"></a>Outline of a task implementation</h2><p>下面可以看下如果不支持 symmetric transfer，task 类应该如何被实现。可以看出 task 是一个 Awaitable。</p><p>A task has exclusive ownership of the <code>std::coroutine_handle</code> that corresponds to the coroutine frame created during the invocation of the coroutine. The task object is an RAII object that ensures that <code>.destroy()</code> is called on the <code>std::coroutine_handle</code> when the task object goes out of scope.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">task</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">promise_type</span> &#123;</span> <span class="comment">/* see below */</span> &#125;;</span><br><span class="line"></span><br><span class="line">  task(task&amp;&amp; t) <span class="keyword">noexcept</span></span><br><span class="line">  : coro_(<span class="built_in">std</span>::exchange(t.coro_, &#123;&#125;))</span><br><span class="line">  &#123;&#125;</span><br><span class="line"></span><br><span class="line">  ~task() &#123;</span><br><span class="line">    <span class="keyword">if</span> (coro_)</span><br><span class="line">      coro_.destroy();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">awaiter</span> &#123;</span> <span class="comment">/* see below */</span> &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function">awaiter <span class="keyword">operator</span> <span class="title">co_await</span><span class="params">()</span> &amp;&amp; <span class="keyword">noexcept</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">task</span><span class="params">(<span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; h)</span> <span class="keyword">noexcept</span></span></span><br><span class="line">  : coro_(h)</span><br><span class="line">  &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; coro_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>下面会展开讲解 promise_type 和 awaiter 的实现。</p><h2 id="Implementing-task-promise-type"><a href="#Implementing-task-promise-type" class="headerlink" title="Implementing task::promise_type"></a>Implementing task::promise_type</h2><p>promise_type 会定义在 coroutine frame 中创建的 Promise 对象的类型。</p><p>首先，需要实现 <code>get_return_object()</code> 去构造将来要被返回的 task 对象。这个对象的初始化需要借助于 <code>std::coroutine_handle</code>。</p><p>这里是根据 <code>from_promise</code> 从 Promise 对象中重新构造出了 <code>std::coroutine_handle</code>。这是获得 <code>std::coroutine_handle</code> 的一种方法，另一种方法是 <code>await_suspend</code> 参数，前文中提到过。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">task</span>:</span>:promise_type &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function">task <span class="title">get_return_object</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> task&#123;<span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt;::from_promise(*<span class="keyword">this</span>)&#125;;</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>后面，这个 coroutine 需要在 initial-suspend point 挂起，这样在 task 被 await 的时候，我们可以 resume 它。这样 lazy 的处理有下面几点好处：</p><ol><li>It means that we can attach the continuation’s <code>std::coroutine_handle</code> before starting execution of the coroutine. This means we don’t need to use thread-synchronisation to arbitrate the race between attaching the continuation later and the coroutine running to completion.<br> 我理解这里讲的是和“Comparison to Stackful Coroutines”这一章节中类似的问题。</li><li>It means that the task destructor can unconditionally destroy the coroutine frame - we don’t need to worry about whether the coroutine is potentially executing on another thread since the coroutine will not start executing until we await it, and while it is executing the calling coroutine is suspended and so won’t attempt to call the task destructor until the coroutine finishes executing.<br> 这里说的是 task 的析构函数可以不加判断地直接销毁掉 coroutine frame。也就是说，并不需要担心 coroutine 是否此时还在另一个线程上执行。实际上我们只有在 await 它的时候，coroutine 才会开始执行。而这个时候，调用方 coroutine 已经被挂起了，直到 coroutine 执行完成后，都不会再调用 task 的 destructor 了。<br> 所以这让编译器更容易把分配 coroutine frame 的操作 inline 到 caller 的 frame 里面。我理解就是“Allocating a coroutine frame”里面讲的东西。<br> See P0981R0 to read more about the Heap Allocation eLision Optimisation (HALO).</li><li>It also improves the exception-safety of your coroutine code. If you don’t immediately <code>co_await</code> the returned task and do something else that can throw an exception that causes the stack to unwind and the task destructor to run then we can safely destroy the coroutine since we know it hasn’t started yet. We aren’t left with the difficult choice between detaching, potentially leaving dangling references, blocking in the destructor, terminating or undefined-behaviour.<br> 这也能提高异常安全性。</li></ol><p>为了让 coroutine 能够 initially suspend，需要定义一个返回 <code>suspend_always</code> 的 <code>initial_suspend</code> 方法。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  <span class="built_in">std</span>::<span class="function">suspend_always <span class="title">initial_suspend</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>然后，定义 <code>return_void()</code> 方法。这是在执行 <code>co_return</code> 的时候，或者执行到 coroutine 末尾的时候被调用的。这个方法并不会做什么事情，只是让编译器知道 <code>co_return;</code> 对于当前的 coroutine 类型是合法的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">return_void</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>We also need to add an <code>unhandled_exception()</code> method that is called if an exception escapes the body of the coroutine. For our purposes we can just treat the task coroutine bodies as noexcept and call <code>std::terminate()</code> if this happens.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">unhandled_exception</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::terminate();</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>最后，还需要 coroutine 能在 final-suspend point 被 suspend 住，然后 resume its Continuation。在当前的 case 中 continuation 就是在 awaiting 的 coroutine，在 <code>task::awaiter::await_suspend</code> 的时候被设置的。</p><p>【Q】“resume its Continuation” 中的 Continuation 指的是什么？这里我理解应该就是 loop_synchronously 里面循环的下一次迭代。可以在 Stack 图中看到 continuation 具体指向哪里的。</p><p>因此，需要在 promise 中引入一个成员，去持有 continuation 的 <code>std::coroutine_handle</code>，不然如何调用对应的 <code>.resume()</code> 方法呢？</p><p>还需要定义 <code>final_suspend()</code> 方法来返回一个 awaitable 对象也就是 final_awaiter，让它在当前 coroutine 被挂起后，去 resume 这个 continuation。</p><p>注意，需要再当前 coroutine 被 suspend 之后，才能 resume continuation。这是因为 continuation 可能立即就会调用 task 的析构函数，从而间接调用 coroutine frame 的 <code>.destroy()</code> 方法。<code>.destroy()</code> 方法只对 suspended 的 coroutine 生效。</p><p>The compiler inserts code to evaluate the statement <code>co_await promise.final_suspend();</code> at the closing curly brace.</p><p>需要注意，在调用 <code>final_suspend</code> 的时候，coroutine 还没有进入 suspend 状态。需要等到返回的 awaitable 对象上的 await_suspend() 方法被调用之后，coroutine 才被 suspend。关于这个我觉得可以参考之前讲的 <code>&lt;return-to-caller-or-resumer&gt;</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">final_awaiter</span> &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; h)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">      <span class="comment">// The coroutine is now suspended at the final-suspend point.</span></span><br><span class="line">      <span class="comment">// Lookup its continuation in the promise and resume it.</span></span><br><span class="line">      h.promise().continuation.resume();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;&#125;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function">final_awaiter <span class="title">final_suspend</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>【Q】为啥这里定义一个 <code>final_awaiter</code>，而不是直接用 std::suspend_always。<br>首先，<code>suspend_always</code> 和 <code>suspend_never</code> 的实现上分别定义了<code> await_ready()</code> 方法始终返回 false 或者 true。<code>await_suspend</code> 或者 <code>await_resume</code> 方法都是空实现。而这里是希望 <code>final_awaiter</code> 的 <code>await_suspend</code> 能去 resume continuation。</p><h2 id="Implementing-task-operator-co-await"><a href="#Implementing-task-operator-co-await" class="headerlink" title="Implementing task::operator co_await()"></a>Implementing task::operator co_await()</h2><p>co_await 会返回一个 awaiter 对象，这个对象需要支持 <code>await_ready()</code>、<code>await_suspend()</code> 和 <code>await_resume()</code>。</p><p>下面就是 awaiter 的简单实现。注意，一旦一个 coroutine 被 suspend 了，就需要保存 coroutine handle 到 promise 对象中。这样后续可以调用 std::coroutine_handle 中的 resume() 方法去执行这个 task。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">task</span>:</span>:awaiter &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Store the continuation in the task's promise so that the final_suspend()</span></span><br><span class="line">    <span class="comment">// knows to resume this coroutine when the task completes.</span></span><br><span class="line">    coro_.promise().continuation = continuation;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Then we resume the task's coroutine, which is currently suspended</span></span><br><span class="line">    <span class="comment">// at the initial-suspend-point (ie. at the open curly brace).</span></span><br><span class="line">    coro_.resume();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">awaiter</span><span class="params">(<span class="built_in">std</span>::coroutine_handle&lt;task::promise_type&gt; h)</span> <span class="keyword">noexcept</span></span></span><br><span class="line">  : coro_(h)</span><br><span class="line">  &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::coroutine_handle&lt;task::promise_type&gt; coro_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">task::awaiter task::<span class="function"><span class="keyword">operator</span> <span class="title">co_await</span><span class="params">()</span> &amp;&amp; <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> awaiter&#123;coro_&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>作者给出了一个可编译的 demo 在 <a href="https://godbolt.org/z/-Kw6Nf%E3%80%82" target="_blank" rel="noopener">https://godbolt.org/z/-Kw6Nf。</a></p><h2 id="The-stack-overflow-problem"><a href="#The-stack-overflow-problem" class="headerlink" title="The stack-overflow problem"></a>The stack-overflow problem</h2><p>考虑下面的代码，如果 count 足够大，程序就会爆栈。例如 <a href="https://godbolt.org/z/gy5Q8q" target="_blank" rel="noopener">https://godbolt.org/z/gy5Q8q</a> 中展示了当 count 是 1000000 的时候，程序就爆栈了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">task <span class="title">completes_synchronously</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  co_return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">task <span class="title">loop_synchronously</span><span class="params">(<span class="keyword">int</span> count)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; ++i) &#123;</span><br><span class="line">    <span class="function">co_await <span class="title">completes_synchronously</span><span class="params">()</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是因为当 loop_synchronously() 开始执行时，有一个其他 coroutine 正在 <code>co_await</code> 的自己返回的 task，也就是在 <code>co_await loop_synchronously()</code>。因此，它会 suspend 正在 awating 的 coroutine，然后调用 <code>task::awaiter::await_suspend()</code>。如前文介绍，<code>await_suspend</code> 会负责调用对应 task 的<code> std::coroutine_handle</code> 的 <code>resume()</code> 方法。</p><p>Thus the stack will look something like this when loop_synchronously() starts.</p><p>我理解这里倒数第二底层的 task::awaiter::await_suspend 是由于这个其他 coroutine 在 await 从而产生的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">           Stack                                                   Heap</span><br><span class="line">+------------------------------+  &lt;-- top of stack   +--------------------------+</span><br><span class="line">| loop_synchronously$resume    | active coroutine -&gt; | loop_synchronously frame |</span><br><span class="line">+------------------------------+                     | +----------------------+ |</span><br><span class="line">| coroutine_handle::resume     |                     | | task::promise        | |</span><br><span class="line">+------------------------------+                     | | - continuation --.   | |</span><br><span class="line">| task::awaiter::await_suspend |                     | +------------------|---+ |</span><br><span class="line">+------------------------------+                     | ...                |     |</span><br><span class="line">| awaiting_coroutine$resume    |                     +--------------------|-----+</span><br><span class="line">+------------------------------+                                          V</span><br><span class="line">|  ....                        |                     +--------------------------+</span><br><span class="line">+------------------------------+                     | awaiting_coroutine frame |</span><br><span class="line">                                                     |                          |</span><br><span class="line">                                                     +--------------------------+</span><br></pre></td></tr></table></figure><p>这里的 <code>$resume</code> 后缀用来表示 coroutine 中的用户自定义逻辑。</p><p>然后，当 <code>loop_synchronously()</code> 去 <code>co_await</code> 从 <code>completes_synchronously()</code> 返回的 task 对象时，当前的 coroutine 会被 suspend，然后会调用 <code>task::awaiter::await_suspend()</code>。await_suspend() 方法会调用 <code>completes_synchronously()</code> 的 coroutine handle 上的 <code>.resume()</code> 方法。</p><p>这会 resume <code>completes_synchronously()</code> coroutine。这个 coroutine 会 synchronously 地运行结束，然后在 final-suspend point 被 suspend。然后它会调用 <code>task::promise::final_awaiter::await_suspend()</code>，然后最终调用 <code>loop_synchronously()</code> 这个 coroutine 的 coroutine handle 上的 <code>.resume()</code> 方法。</p><p>如果我们在 <code>loop_synchronously()</code> coroutine 被 resume 之后，它返回的临时的 task 被销毁之前，检查调用栈，就可以看到下面的情况。</p><p>这里的 final_awaiter 也就是 promise 对象的 final_suspend() 方法返回的内容。根据之前的说明，它是在 final-suspend point 之后 resume continuation 的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">           Stack                                                   Heap</span><br><span class="line">+-------------------------------+ &lt;-- top of stack</span><br><span class="line">| loop_synchronously$resume     | active coroutine -.</span><br><span class="line">+-------------------------------+                   |</span><br><span class="line">| coroutine_handle::resume      |            .------&apos;</span><br><span class="line">+-------------------------------+            |</span><br><span class="line">| final_awaiter::await_suspend  |            |</span><br><span class="line">+-------------------------------+            |  +--------------------------+ &lt;-.</span><br><span class="line">| completes_synchronously$resume|            |  | completes_synchronously  |   |</span><br><span class="line">+-------------------------------+            |  | frame                    |   |</span><br><span class="line">| coroutine_handle::resume      |            |  +--------------------------+   |</span><br><span class="line">+-------------------------------+            &apos;---.                             |</span><br><span class="line">| task::awaiter::await_suspend  |                V                             |</span><br><span class="line">+-------------------------------+ &lt;-- prev top  +--------------------------+   |</span><br><span class="line">| loop_synchronously$resume     |     of stack  | loop_synchronously frame |   |</span><br><span class="line">+-------------------------------+               | +----------------------+ |   |</span><br><span class="line">| coroutine_handle::resume      |               | | task::promise        | |   |</span><br><span class="line">+-------------------------------+               | | - continuation --.   | |   |</span><br><span class="line">| task::awaiter::await_suspend  |               | +------------------|---+ |   |</span><br><span class="line">+-------------------------------+               | - task temporary --|---------&apos;</span><br><span class="line">| awaiting_coroutine$resume     |               +--------------------|-----+</span><br><span class="line">+-------------------------------+                                    V</span><br><span class="line">|  ....                         |               +--------------------------+</span><br><span class="line">+-------------------------------+               | awaiting_coroutine frame |</span><br><span class="line">                                                |                          |</span><br><span class="line">                                                +--------------------------+</span><br></pre></td></tr></table></figure><p>然后，就会调用 task 的析构函数，摧毁 <code>completes_synchronously()</code> 的 coroutine frame。然后就会进行新一轮的循环，创建新的 completes_synchronously() 的 coroutine frame，然后 resume。</p><p>最终结果是，<code>loop_synchronously()</code> 和 <code>completes_synchronously()</code> 会递归地互相调用彼此。每次调用都会消耗一点栈空间，直到最后栈爆掉了。</p><p>Writing loops in coroutines built this way makes it very easy to write functions that perform unbounded recursion without looking like they are doing any recursion.</p><p>So, what would the solution look like under the original Coroutines TS design?</p><h2 id="The-Coroutines-TS-solution"><a href="#The-Coroutines-TS-solution" class="headerlink" title="The Coroutines TS solution"></a>The Coroutines TS solution</h2><p>TS 的解决方案是使用返回 bool 的版本的 await_suspend，根据的原理是<br>In the Coroutines TS there is also a version of await_suspend() that returns bool - if it returns true then the coroutine is suspended and execution returns to the caller of resume(), otherwise if it returns false then the coroutine is immediately resumed, but this time without consuming any additional stack-space.</p><p>具体来说，做出下面的修改：</p><ol><li>Inside the <code>task::awaiter::await_suspend()</code> method you can start executing the coroutine by calling <code>.resume()</code>. Then when the call to <code>.resume()</code> returns, check whether the coroutine has run to completion or not. If it has run to completion then we can return false, which indicates the awaiting coroutine should immediately resume, or we can return true, indicating that execution should return to the caller of <code>std::coroutine_handle::resume()</code>.</li><li>Inside <code>task::promise_type::final_awaiter::await_suspend()</code>, which is run when the coroutine runs to completion, we need to check whether the awaiting coroutine has (or will) return true from <code>task::awaiter::await_suspend()</code> and if so then resume it by calling .resume(). Otherwise, we need to avoid resuming the coroutine and notify task::awaiter::await_suspend() that it needs to return false.</li></ol><p>从下面的代码来看，awaiter::await_suspend 和 final_awaiter::await_suspend 中都会尝试设置 promise.ready 为 true。但是：</p><ol><li>在 awaiter::await_suspend 中如果发现 promise.ready 原来是 false，说明还没结束，则要返回 true 去挂起，并且返回给 <code>std::coroutine_handle::resume()</code> 的调用方。如果原来是 true，说明执行完了，就返回 false，则可以立即 resume。</li><li>在 final_awaiter::await_suspend 中如果发现 promise.ready 原来是 true，说明【Q】</li></ol><blockquote><p>There is an added complication, however, in that it’s possible for a coroutine to start executing on the current thread then suspend and later resume and run to completion on a different thread before the call to .resume() returns. Thus, we need to be able to resolve the potential race between part 1 and part 2 above happening concurrently.</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">task</span>:</span>:promise_type &#123;</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation;</span><br><span class="line">  <span class="built_in">std</span>::atomic&lt;<span class="keyword">bool</span>&gt; ready = <span class="literal">false</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">bool</span> task::awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  promise_type&amp; promise = coro_.promise();</span><br><span class="line">  promise.continuation = continuation;</span><br><span class="line">  coro_.resume();</span><br><span class="line">  <span class="keyword">return</span> !promise.ready.exchange(<span class="literal">true</span>, <span class="built_in">std</span>::memory_order_acq_rel);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> task::promise_type::final_awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; h) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  promise_type&amp; promise = h.promise();</span><br><span class="line">  <span class="keyword">if</span> (promise.ready.exchange(<span class="literal">true</span>, <span class="built_in">std</span>::memory_order_acq_rel)) &#123;</span><br><span class="line">    <span class="comment">// The coroutine did not complete synchronously, resume it here.</span></span><br><span class="line">    promise.continuation.resume();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改后的代码在 <a href="https://godbolt.org/z/7fm8Za%E3%80%82" target="_blank" rel="noopener">https://godbolt.org/z/7fm8Za。</a></p><h2 id="The-problems"><a href="#The-problems" class="headerlink" title="The problems"></a>The problems</h2><p>上面的方案依然存在问题：</p><ol><li>依赖原子操作<br> 第一次是在调用者在 suspend awaiting coroutine 的时候。<br> 第二次是在被调用者即将完成执行的时候。</li><li>引入额外的分支操作。</li></ol><p>最后一个最严重的问题是，被挂起的 coroutine 在被 resume 后，被哪个线程执行是不确定的。比如考虑下面的代码</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cppcoro::static_thread_pool tp;</span><br><span class="line"></span><br><span class="line"><span class="function">task <span class="title">foo</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"foo1 "</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">  <span class="comment">// Suspend coroutine and reschedule onto thread-pool thread.</span></span><br><span class="line">  co_await tp.schedule();</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"foo2 "</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">task <span class="title">bar</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"bar1 "</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">  <span class="function">co_await <span class="title">foo</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"bar2"</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在原始的实现中，可能的输出如下。这是因为我们保证在 the code that runs after <code>co_await foo()</code> would run inline on the same thread that foo() completed on.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bar1 1234</span><br><span class="line">foo1 1234</span><br><span class="line">foo2 3456</span><br><span class="line">bar2 3456</span><br></pre></td></tr></table></figure><p>但是因为使用了原子变量，就可能 foo 的 completion 和 bar 的 suspension 之间有 race（我理解就是上面的两个 await_suspend 会竞争地设置 promise.ready 吧）。那么在一些情况下，<code>co_await foo()</code> might run on the original thread that bar() started executing on. 如下所示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bar1 1234</span><br><span class="line">foo1 1234</span><br><span class="line">foo2 3456</span><br><span class="line">bar2 1234</span><br></pre></td></tr></table></figure><p>这对一些场景下是存在问题的。比如 <code>via</code> 这个函数可以指定一个 Scheduler 去运行某个 Awaitable。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Awaitable, <span class="keyword">typename</span> Scheduler&gt;</span><br><span class="line">task&lt;<span class="keyword">await_result_t</span>&lt;Awaitable&gt;&gt; via(Awaitable a, Scheduler s)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">auto</span> result = co_await <span class="built_in">std</span>::move(a);</span><br><span class="line">  co_await s.schedule();</span><br><span class="line">  co_return result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">task&lt;T&gt; get_value();</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">consume</span><span class="params">(<span class="keyword">const</span> T&amp;)</span></span>;</span><br><span class="line"></span><br><span class="line">task&lt;<span class="keyword">void</span>&gt; consumer(static_thread_pool::scheduler s)</span><br><span class="line">&#123;</span><br><span class="line">  T result = co_await via(get_value(), s);</span><br><span class="line">  consume(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但像现在这样的话，<code>consume()</code> 可能在 s 上执行，但也有可能在 whatever thread the consumer() coroutine started execution on 上被执行。</p><h2 id="Enter-“symmetric-transfer”"><a href="#Enter-“symmetric-transfer”" class="headerlink" title="Enter “symmetric transfer”"></a>Enter “symmetric transfer”</h2><p>This paper proposed two key changes:</p><ol><li>Allow returning a <code>std::coroutine_handle&lt;T&gt;</code> from await_suspend() as a way of indicating that execution should be symmetrically transferred to the coroutine identified by the returned handle.</li><li>Add a std::experimental::noop_coroutine() function that returns a special std::coroutine_handle that can be returned from await_suspend() to suspend the current coroutine and return from the call to .resume() instead of transferring execution to another coroutine.</li></ol><p>首先，什么是 symmetric transfer？简单来说，像函数调用，返回那样的就是 asymmetric transfer，因为有明确的调用者和被调用者。具体到 coroutine 场景中，当 A 调用 <code>.resume()</code> 方法去 resume 一个 coroutine 的时候，这个 A 还在 stack 上，尽管 resumed coroutine 正在被执行。当这个 coroutine 后面挂起，并调用 <code>await_suspend</code> 返回 void（无条件 suspend）或者 true（条件 suspend），那么对 <code>.resume()</code> 的调用就返回了。</p><p>每次我们通过 .resume() 方法去 resume 一个 coroutine 的时候，都会创建一个新的 frame。<br>但如果通过 symmetric transfer，我们就只是 suspend 某个 coroutine，resume 另一个 coroutine。这两个 coroutine 之间没有任何的调用者或者被调用者的关系。当一个 coroutine 被 suspend 后，它可以将 execution 给到任意的被 suspend 的coroutine，甚至包括自己，并且在自己被 suspend 之后，也不需要把 execution 还给之前的 coroutine。</p><p>Let’s look at what the compiler lowers a co_await expression to when the awaiter makes use of symmetric-transfer:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="keyword">decltype</span>(<span class="keyword">auto</span>) value = &lt;expr&gt;;</span><br><span class="line">  <span class="keyword">decltype</span>(<span class="keyword">auto</span>) awaitable =</span><br><span class="line">      get_awaitable(promise, <span class="keyword">static_cast</span>&lt;<span class="keyword">decltype</span>(value)&amp;&amp;&gt;(value));</span><br><span class="line">  <span class="keyword">decltype</span>(<span class="keyword">auto</span>) awaiter =</span><br><span class="line">      get_awaiter(<span class="keyword">static_cast</span>&lt;<span class="keyword">decltype</span>(awaitable)&amp;&amp;&gt;(awaitable));</span><br><span class="line">  <span class="keyword">if</span> (!awaiter.await_ready())</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">handle_t</span> = <span class="built_in">std</span>::coroutine_handle&lt;P&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//&lt;suspend-coroutine&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> h = awaiter.await_suspend(<span class="keyword">handle_t</span>::from_promise(p));</span><br><span class="line">    h.resume();</span><br><span class="line">    <span class="comment">//&lt;return-to-caller-or-resumer&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//&lt;resume-point&gt;</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> awaiter.await_resume();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Let’s zoom in on the key part that differs from other co_await forms:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> h = awaiter.await_suspend(<span class="keyword">handle_t</span>::from_promise(p));</span><br><span class="line">h.resume();</span><br><span class="line"><span class="comment">//&lt;return-to-caller-or-resumer&gt;</span></span><br></pre></td></tr></table></figure><p>Once the coroutine state-machine is lowered (a topic for another post), the <code>&lt;return-to-caller-or-resumer&gt;</code> part basically becomes a return; statement which causes the call to .resume() that last resumed the coroutine to return to its caller.</p><p>This means that we have the situation where we have a call to another function with the same signature, <code>std::coroutine_handle::resume()</code>, followed by a return; from the current function which is itself the body of a <code>std::coroutine_handle::resume()</code> call.</p><p>Some compilers, when optimisations are enabled, are able to apply an optimisation that turns calls to other functions the tail-position (ie. just before returning) into tail-calls as long as some conditions are met.</p><p>It just so happens that this kind of tail-call optimisation is exactly the kind of thing we want to be able to do to avoid the stack-overflow problem we were encountering before. But instead of being at the mercy of the optimiser as to whether or not the tail-call transformation is perfromed, we want to be able to guarantee that the tail-call transformation occurs, even when optimisations are not enabled.</p><p>But first let’s dig into what we mean by tail-calls.</p><h2 id="Tail-calls"><a href="#Tail-calls" class="headerlink" title="Tail-calls"></a>Tail-calls</h2><p>Tail-call 指的是当前的 stack frame 被在调用前就被弹出了，然后当前函数的返回地址变为了被调用者的返回地址。比如，被调用者会直接返回给调用者的调用者。</p><p>在 X86 架构上，编译器会首先弹出当前的栈帧，然后用一个 jmp 指令去跳转到被调用的函数的 entry-point。而不是使用一个 call 指令，然后在返回后再弹出当前 stack-frame。</p><p>This optimisation is generally only possible to do in limited circumstances, however. In particular, it requires that:</p><ol><li>the calling convention supports tail-calls and is the same for the caller and callee;</li><li>the return-type is the same;</li><li>there are no non-trivial destructors that need to be run after the call before returning to the caller; and</li><li>the call is not inside a try/catch block.</li></ol><p>The shape of the symmetric-transfer form of co_await has actually been designed specifically to allow coroutines to satisfy all of these requirements. Let’s look at them individually.</p><ol><li><p>Calling convention<br> 当编译器 lowers 一个 coroutine 到机器码的时候，它实际上将 coroutine 分为了两部分。第一部分是 ramp，它会分配并初始化 coroutine 帧。第二部分是 body，它包含了从用户自定义的 coroutine body 生成的状态机。<br> The function signature of the coroutine (and thus any user-specified calling-convention) affects only the ramp part, whereas the body part is under the control of the compiler and is never directly called by any user-code - only by the ramp function and by <code>std::coroutine_handle::resume()</code>.<br> The calling-convention of the coroutine body part is not user-visible and is entirely up to the compiler and thus it can choose an appropriate calling convention that supports tail-calls and that is used by all coroutine bodies.</p></li><li><p>Return type is the same<br> “调用方” coroutine 和“被调用方” coroutine 的 .resume() 方法的返回值都是 void。</p></li><li><p>No non-trivial destructors<br> 在执行 tail-call 时，需要能够在调用目标函数之前就释放当前的 stack frame。而这需要所有在栈上分配的对象的生命周期都在调用前完成。<br> Normally, this would be problematic as soon as there are any objects with non-trivial destructors in-scope as the lifetime of those objects would not yet have ended and those objects would have been allocated on the stack.<br> 但是，当一个 coroutine 被 suspend 之后，它实际上会将需要续命的对象放到 coroutine frame 里面，而不是直接分配在 stack 上。<br> 对于真正的 local variable，也就是那些 lifetime 并不会跨越 suspend-point 的 variable，它们是会被分配在栈上的。但是它们的 lifetime 在 coroutine suspend 之前就已经结束了，并且对应的析构函数也已经被调用了。<br> 所以不会存在有 stack-allocated objects，它们的 non-trivial destructor 需要在 tail-call 返回之后被执行。</p></li><li><p>Call not inside a try/catch block<br> 这里比较 tricky 的一点是每个 coroutine 都会有一个隐式的 try/catch block，来包裹其中的用户自定义的部分。<br> 类似下面这，F 就是用户自定义的部分。</p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  promise_type promise;</span><br><span class="line">  co_await promise.initial_suspend();</span><br><span class="line">  <span class="keyword">try</span> &#123; F; &#125;</span><br><span class="line">  <span class="keyword">catch</span> (...) &#123; promise.unhandled_exception(); &#125;</span><br><span class="line">final_suspend:</span><br><span class="line">  co_await promise.final_suspend();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 所以，每个用户自定义的 co_await 表达式（除了 initial_suspend 和 final_suspend 的）会被 try catch 包裹。<br> However, implementations work around this by actually executing the call to .resume() outside of the context of the try-block.</p></li></ol><p>So we see that coroutines performing a symmetric-transfer generally satisfy all of the requirements for being able to perform a tail-call. The compiler guarantees that this will always be a tail-call, regardless of whether optimisations are enabled or not.</p><p>This means that by using the std::coroutine_handle-returning flavour of await_suspend() we can suspend the current coroutine and transfer execution to another coroutine without consuming extra stack-space.</p><p>This allows us to write coroutines that mutually and recursively resume each other to an arbitrary depth without fear of overflowing the stack.</p><p>This is exactly what we need to fix our task implementation.</p><h2 id="task-revisited"><a href="#task-revisited" class="headerlink" title="task revisited"></a>task revisited</h2><p>So with the new “symmetric transfer” capability under our belt let’s go back and fix our task type implementation.</p><p>To do this we need to make changes to the two await_suspend() methods in our implementation:</p><ol><li>First so that when we await the task that we perform a symmetric-transfer to resume the task’s coroutine.</li><li>Second so that when the task’s coroutine completes that it performs a symmetric transfer to resume the awaiting coroutine.</li></ol><p>To address the await direction we need to change the task::awaiter method from this:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> task::awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  <span class="comment">// Store the continuation in the task's promise so that the final_suspend()</span></span><br><span class="line">  <span class="comment">// knows to resume this coroutine when the task completes.</span></span><br><span class="line">  coro_.promise().continuation = continuation;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Then we resume the task's coroutine, which is currently suspended</span></span><br><span class="line">  <span class="comment">// at the initial-suspend-point (ie. at the open curly brace).</span></span><br><span class="line">  coro_.resume();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会变成</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::coroutine_handle&lt;&gt; task::awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;&gt; continuation) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  <span class="comment">// Store the continuation in the task's promise so that the final_suspend()</span></span><br><span class="line">  <span class="comment">// knows to resume this coroutine when the task completes.</span></span><br><span class="line">  coro_.promise().continuation = continuation;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Then we tail-resume the task's coroutine, which is currently suspended</span></span><br><span class="line">  <span class="comment">// at the initial-suspend-point (ie. at the open curly brace), by returning</span></span><br><span class="line">  <span class="comment">// its handle from await_suspend().</span></span><br><span class="line">  <span class="keyword">return</span> coro_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>And to address the return-path we need to update the task::promise_type::final_awaiter method from this:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> task::promise_type::final_awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; h) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  <span class="comment">// The coroutine is now suspended at the final-suspend point.</span></span><br><span class="line">  <span class="comment">// Lookup its continuation in the promise and resume it.</span></span><br><span class="line">  h.promise().continuation.resume();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会变成</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::coroutine_handle&lt;&gt; task::promise_type::final_awaiter::await_suspend(</span><br><span class="line">    <span class="built_in">std</span>::coroutine_handle&lt;promise_type&gt; h) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">  <span class="comment">// The coroutine is now suspended at the final-suspend point.</span></span><br><span class="line">  <span class="comment">// Lookup its continuation in the promise and resume it symmetrically.</span></span><br><span class="line">  <span class="keyword">return</span> h.promise().continuation;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>And now we have a task implementation that doesn’t suffer from the stack-overflow problem that the void-returning await_suspend flavour had and that doesn’t have the non-deterministic resumption context problem of the bool-returning await_suspend flavour had.</p><h2 id="Visualising-the-stack"><a href="#Visualising-the-stack" class="headerlink" title="Visualising the stack"></a>Visualising the stack</h2><p>这是之前的例子</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">task <span class="title">completes_synchronously</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  co_return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">task <span class="title">loop_synchronously</span><span class="params">(<span class="keyword">int</span> count)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; ++i) &#123;</span><br><span class="line">    <span class="function">co_await <span class="title">completes_synchronously</span><span class="params">()</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在，在 loop_synchronously() 第一次被执行的时候，可能是因为有些其他的 coroutine 去 co_await 了它。这是通过 symmetric transfer 来实现的，所以栈类似下面。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">           Stack                                                Heap</span><br><span class="line">+---------------------------+  &lt;-- top of stack   +--------------------------+</span><br><span class="line">| loop_synchronously$resume | active coroutine -&gt; | loop_synchronously frame |</span><br><span class="line">+---------------------------+                     | +----------------------+ |</span><br><span class="line">| coroutine_handle::resume  |                     | | task::promise        | |</span><br><span class="line">+---------------------------+                     | | - continuation --.   | |</span><br><span class="line">|     ...                   |                     | +------------------|---+ |</span><br><span class="line">+---------------------------+                     | ...                |     |</span><br><span class="line">                                                  +--------------------|-----+</span><br><span class="line">                                                                       V</span><br><span class="line">                                                  +--------------------------+</span><br><span class="line">                                                  | awaiting_coroutine frame |</span><br><span class="line">                                                  |                          |</span><br><span class="line">                                                  +--------------------------+</span><br></pre></td></tr></table></figure><p>然后，执行 <code>co_await completes_synchronously()</code> 的时候，又会触发一次 symmetric transfer 到 completes_synchronously。</p><p>It does this by:</p><ol><li>调用 <code>task::operator co_await()</code>，获得一个 task::awaiter 对象</li><li>suspend，然后调用 <code>task::awaiter::await_suspend()</code>。它的 symmetric transfer 的版本会返回 <code>coroutine_handle</code> of the <code>completes_synchronously</code> coroutine.</li><li>执行一次 tail-call 或者说 jump 去到 <code>completes_synchronously</code> coroutine。这会弹出 <code>loop_synchronously</code> 的 frame，然后再 activate <code>completes_synchronously</code> 的 frame.</li></ol><p>If we now look at the stack just after <code>completes_synchronously</code> is resumed it will now look like this:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">              Stack                                          Heap</span><br><span class="line">                                            .-&gt; +--------------------------+ &lt;-.</span><br><span class="line">                                            |   | completes_synchronously  |   |</span><br><span class="line">                                            |   | frame                    |   |</span><br><span class="line">                                            |   | +----------------------+ |   |</span><br><span class="line">                                            |   | | task::promise        | |   |</span><br><span class="line">                                            |   | | - continuation --.   | |   |</span><br><span class="line">                                            |   | +------------------|---+ |   |</span><br><span class="line">                                            `-, +--------------------|-----+   |</span><br><span class="line">                                              |                      V         |</span><br><span class="line">+-------------------------------+ &lt;-- top of  | +--------------------------+   |</span><br><span class="line">| completes_synchronously$resume|     stack   | | loop_synchronously frame |   |</span><br><span class="line">+-------------------------------+ active -----&apos; | +----------------------+ |   |</span><br><span class="line">| coroutine_handle::resume      | coroutine     | | task::promise        | |   |</span><br><span class="line">+-------------------------------+               | | - continuation --.   | |   |</span><br><span class="line">|     ...                       |               | +------------------|---+ |   |</span><br><span class="line">+-------------------------------+               | task temporary     |     |   |</span><br><span class="line">                                                | - coro_       -----|---------`</span><br><span class="line">                                                +--------------------|-----+</span><br><span class="line">                                                                     V</span><br><span class="line">                                                +--------------------------+</span><br><span class="line">                                                | awaiting_coroutine frame |</span><br><span class="line">                                                |                          |</span><br><span class="line">                                                +--------------------------+</span><br></pre></td></tr></table></figure><p>注意，stack-frame 的数量没有变多。</p><p>在 completes_synchronously 完成之后，当遇到右花括号的时候，会执行 <code>co_await promise.final_suspend()</code>。</p><p>这会导致 coroutine 被挂起，并且调用 <code>final_awaiter::await_suspend()</code>，从而返回 continuation 的 std::coroutine_handle，实际上就指向的 loop_synchronously。这之后会做一个 symmetric transfer/tail-call 去 resume loop_synchronously。</p><p>If we look at the stack just after loop_synchronously is resumed then it will look something like this:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">           Stack                                                   Heap</span><br><span class="line">                                                   +--------------------------+ &lt;-.</span><br><span class="line">                                                   | completes_synchronously  |   |</span><br><span class="line">                                                   | frame                    |   |</span><br><span class="line">                                                   | +----------------------+ |   |</span><br><span class="line">                                                   | | task::promise        | |   |</span><br><span class="line">                                                   | | - continuation --.   | |   |</span><br><span class="line">                                                   | +------------------|---+ |   |</span><br><span class="line">                                                   +--------------------|-----+   |</span><br><span class="line">                                                                        V         |</span><br><span class="line">+----------------------------+  &lt;-- top of stack   +--------------------------+   |</span><br><span class="line">| loop_synchronously$resume  | active coroutine -&gt; | loop_synchronously frame |   |</span><br><span class="line">+----------------------------+                     | +----------------------+ |   |</span><br><span class="line">| coroutine_handle::resume() |                     | | task::promise        | |   |</span><br><span class="line">+----------------------------+                     | | - continuation --.   | |   |</span><br><span class="line">|     ...                    |                     | +------------------|---+ |   |</span><br><span class="line">+----------------------------+                     | task temporary     |     |   |</span><br><span class="line">                                                   | - coro_       -----|---------`</span><br><span class="line">                                                   +--------------------|-----+</span><br><span class="line">                                                                        V</span><br><span class="line">                                                   +--------------------------+</span><br><span class="line">                                                   | awaiting_coroutine frame |</span><br><span class="line">                                                   |                          |</span><br><span class="line">                                                   +--------------------------+</span><br></pre></td></tr></table></figure><p>loop_synchronously 在 resume 之后要做的第一件事，是调用临时的 task 对象的析构函数。这会销毁 coroutine-frame，释放它的内存，并产生下面：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">           Stack                                                   Heap</span><br><span class="line">+---------------------------+  &lt;-- top of stack   +--------------------------+</span><br><span class="line">| loop_synchronously$resume | active coroutine -&gt; | loop_synchronously frame |</span><br><span class="line">+---------------------------+                     | +----------------------+ |</span><br><span class="line">| coroutine_handle::resume  |                     | | task::promise        | |</span><br><span class="line">+---------------------------+                     | | - continuation --.   | |</span><br><span class="line">|     ...                   |                     | +------------------|---+ |</span><br><span class="line">+---------------------------+                     | ...                |     |</span><br><span class="line">                                                  +--------------------|-----+</span><br><span class="line">                                                                       V</span><br><span class="line">                                                  +--------------------------+</span><br><span class="line">                                                  | awaiting_coroutine frame |</span><br><span class="line">                                                  |                          |</span><br><span class="line">                                                  +--------------------------+</span><br></pre></td></tr></table></figure><p>We are now back to executing the <code>loop_synchronously</code> coroutine and we now have the same number of stack-frames and coroutine-frames as we started, and will do so each time we go around the loop.</p><p>Thus we can perform as many iterations of the loop as we want and will only use a constant amount of storage space.</p><p>For a full example of the symmetric-transfer version of the task type see the following Compiler Explorer link: <a href="https://godbolt.org/z/9baieF" target="_blank" rel="noopener">https://godbolt.org/z/9baieF</a>.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;翻译 &lt;a href=&quot;https://lewissbaker.github.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;lewissbaker&lt;/a&gt; 的三篇文章。&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Rust 的 Borrow Checker</title>
    <link href="http://www.calvinneo.com/2024/04/07/rust-borrow-checker/"/>
    <id>http://www.calvinneo.com/2024/04/07/rust-borrow-checker/</id>
    <published>2024-04-07T07:46:32.000Z</published>
    <updated>2024-07-15T09:44:29.134Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 Rust 的 Borrow Checker 的原理。</p><a id="more"></a><h1 id="前期知识：High-level-Compiler-Architecture"><a href="#前期知识：High-level-Compiler-Architecture" class="headerlink" title="前期知识：High-level Compiler Architecture"></a>前期知识：High-level Compiler Architecture</h1><h2 id="Queries-demand-driven-compilation"><a href="#Queries-demand-driven-compilation" class="headerlink" title="Queries: demand-driven compilation"></a>Queries: demand-driven compilation</h2><p>正在从 pass-based 转变为 demand-driven 模式：</p><blockquote><p>Instead of entirely independent passes (parsing, type-checking, etc.), a set of function-like queries compute information about the input source. For example, there is a query called <code>type_of</code> that, given the <code>DefId</code> of some item, will compute the type of that item and return it to you.</p></blockquote><p>上面的这些 query 是可以被记忆化的，所以在第一次被计算后，剩余的查询就可以从一个 hash table 中被检索出来。这对 Incremental Computation 是非常友好的。</p><p>最终，we want the entire compiler control-flow to be query driven. 也就是对于每个 crate，会运行一个 top-level 的 query 即 <code>compile</code>。这会链式地触发后续的各种计算，比如:</p><ul><li>The compile query might demand to get a list of codegen-units，比如需要被 LLVM 编译的模块列表</li><li>但为了计算这些 codegen-units 就需要使用一个 subquery 计算 Rust 源码中定义的 module 列表</li><li>这个 subquery 就需要触发 HIR 的计算</li><li>This keeps going further and further back until we wind up doing the actual parsing.</li></ul><h3 id="How-the-compiler-executes-a-query"><a href="#How-the-compiler-executes-a-query" class="headerlink" title="How the compiler executes a query"></a>How the compiler executes a query</h3><h3 id="Providers"><a href="#Providers" class="headerlink" title="Providers"></a>Providers</h3><p>If, however, the query is not in the cache, then the compiler will try to find a suitable provider. A provider is a function that has been defined and linked into the compiler somewhere that contains the code to compute the result of the query.</p><h3 id="How-providers-are-setup"><a href="#How-providers-are-setup" class="headerlink" title="How providers are setup"></a>How providers are setup</h3><h2 id="Memory-Management-in-Rustc"><a href="#Memory-Management-in-Rustc" class="headerlink" title="Memory Management in Rustc"></a>Memory Management in Rustc</h2><h1 id="前期知识：Source-Code-Representation"><a href="#前期知识：Source-Code-Representation" class="headerlink" title="前期知识：Source Code Representation"></a>前期知识：Source Code Representation</h1><h2 id="Intermediate-representations-综述"><a href="#Intermediate-representations-综述" class="headerlink" title="Intermediate representations 综述"></a>Intermediate representations 综述</h2><p>Instead most compilers, including rustc, build some sort of IR out of the source code which is easier to analyze. rustc has a few IRs, each optimized for different purposes:</p><ul><li>Token stream: the lexer produces a stream of tokens directly from the source code. This stream of tokens is easier for the parser to deal with than raw text.</li><li>Abstract Syntax Tree (AST): the abstract syntax tree is built from the stream of tokens produced by the lexer. It represents pretty much exactly what the user wrote. It helps to do some syntactic sanity checking (e.g. checking that a type is expected where the user wrote one).</li><li>High-level IR (HIR): This is a sort of desugared AST. It’s still close to what the user wrote syntactically, but it includes some implicit things such as some elided lifetimes, etc. This IR is amenable to type checking.</li><li>Typed HIR (THIR) formerly High-level Abstract IR (HAIR): This is an intermediate between HIR and MIR. It is like the HIR but it is fully typed and a bit more desugared，比如方法调用和隐式解引用都会被显式化. As a result, it is easier to lower to MIR from THIR than from HIR.</li><li>Middle-level IR (MIR): This IR is basically a Control-Flow Graph (CFG). A CFG is a type of diagram that shows the basic blocks of a program and how control flow can go between them. Likewise, MIR also has a bunch of basic blocks with simple typed statements inside them (e.g. assignment, simple computations, etc) and control flow edges to other basic blocks (e.g., calls, dropping values). MIR is used for borrow checking and other important dataflow-based checks, such as checking for uninitialized values. It is also used for a series of optimizations and for constant evaluation (via MIRI). Because MIR is still generic, we can do a lot of analyses here more efficiently than after monomorphization.</li><li>LLVM-IR: This is the standard form of all input to the LLVM compiler. LLVM-IR is a sort of typed assembly language with lots of annotations. It’s a standard format that is used by all compilers that use LLVM (e.g. the clang C compiler also outputs LLVM-IR). LLVM-IR is designed to be easy for other compilers to emit and also rich enough for LLVM to run a bunch of optimizations on it.</li></ul><h2 id="HIR"><a href="#HIR" class="headerlink" title="HIR"></a>HIR</h2><p>HIR – “High-Level Intermediate Representation”，是编译期友好的 AST。只会进行 parse、宏展开和 name resolution 的转化。<br>可以通过第一行的语句得到 HIR 表示，通过第二行的语句得到更为接近原文的 HIR 表示。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cargo rustc -- -Z unpretty=hir-tree</span><br><span class="line">cargo rustc -- -Z unpretty=hir</span><br></pre></td></tr></table></figure><h3 id="HIR-Bodies"><a href="#HIR-Bodies" class="headerlink" title="HIR Bodies"></a>HIR Bodies</h3><p>A <code>rustc_hir::Body</code> represents some kind of executable code, such as the body of a function/closure or the definition of a constant. Bodies are associated with an owner, which is typically some kind of item (e.g. an <code>fn()</code> or <code>const</code>), but could also be a closure expression (e.g. <code>|x, y| x + y</code>). You can use the HIR map to find the body associated with a given def-id (maybe_body_owned_by) or to find the owner of a body (body_owner_def_id).</p><h2 id="THIR"><a href="#THIR" class="headerlink" title="THIR"></a>THIR</h2><p>THIR 也就是 Typed High-Level Intermediate Representation，从前叫 “High-Level Abstract IR。它在 type checking 后生成，被用来构造 MIR，exhaustiveness checking，以及 unsafety checking。</p><p>THIR 在 HIR 更下层。在 type checking 完成后，就能填入所有的 type。HIR 具有下面的特性：</p><ol><li>类似于 MIR，THIR 只表示 “bodies”。其中包含 function bodies，const initializers 等。换句话说，THIR 中没有 struct 或者 trait 的表示。</li><li>THIR 的 body 只是临时被存储，并且在不需要的时候就会被 drop 掉。对应的，HIR 的会存储到编译过程的结束。</li><li>THIR 会有更多的 desugar。比如 automatic references and dereferences 会变得显式。method calls 和 overloaded operators 会转换为 plain function call。Destruction scopes 会显式。<br> 这个我理解是因为 THIR 中已经没有 struct 了。</li><li>Statements、expressions、match arms 会分开存储。</li></ol><p>The THIR lives in <code>rustc_mir_build::thir</code>. To construct a <code>thir::Expr</code>, you can use the <code>thir_body</code> function, passing in the memory arena where the THIR will be allocated. Dropping this arena will result in the THIR being destroyed, which is useful to keep peak memory in check. Having a THIR representation of all bodies of a crate in memory at the same time would be very heavy.</p><p>You can get a debug representation of the THIR by passing the <code>-Zunpretty=thir-tree</code> flag to rustc.</p><p>下面的代码</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> x = <span class="number">1</span> + <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对应的 THIR</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line">Thir &#123;</span><br><span class="line">    // no match arms</span><br><span class="line">    arms: [],</span><br><span class="line">    exprs: [</span><br><span class="line">        // expression 0, a literal with a value of 1</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:13: 2:14 (#0),</span><br><span class="line">            kind: Literal &#123;</span><br><span class="line">                lit: Spanned &#123;</span><br><span class="line">                    node: Int(</span><br><span class="line">                        1,</span><br><span class="line">                        Unsuffixed,</span><br><span class="line">                    ),</span><br><span class="line">                    span: oneplustwo.rs:2:13: 2:14 (#0),</span><br><span class="line">                &#125;,</span><br><span class="line">                neg: false,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 1, scope surrounding literal 1</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:13: 2:14 (#0),</span><br><span class="line">            kind: Scope &#123;</span><br><span class="line">                // reference to expression 0 above</span><br><span class="line">                region_scope: Node(3),</span><br><span class="line">                lint_level: Explicit(</span><br><span class="line">                    HirId &#123;</span><br><span class="line">                        owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                        local_id: 3,</span><br><span class="line">                    &#125;,</span><br><span class="line">                ),</span><br><span class="line">                value: e0,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 2, literal 2</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:17: 2:18 (#0),</span><br><span class="line">            kind: Literal &#123;</span><br><span class="line">                lit: Spanned &#123;</span><br><span class="line">                    node: Int(</span><br><span class="line">                        2,</span><br><span class="line">                        Unsuffixed,</span><br><span class="line">                    ),</span><br><span class="line">                    span: oneplustwo.rs:2:17: 2:18 (#0),</span><br><span class="line">                &#125;,</span><br><span class="line">                neg: false,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 3, scope surrounding literal 2</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:17: 2:18 (#0),</span><br><span class="line">            kind: Scope &#123;</span><br><span class="line">                region_scope: Node(4),</span><br><span class="line">                lint_level: Explicit(</span><br><span class="line">                    HirId &#123;</span><br><span class="line">                        owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                        local_id: 4,</span><br><span class="line">                    &#125;,</span><br><span class="line">                ),</span><br><span class="line">                // reference to expression 2 above</span><br><span class="line">                value: e2,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 4, represents 1 + 2</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:13: 2:18 (#0),</span><br><span class="line">            kind: Binary &#123;</span><br><span class="line">                op: Add,</span><br><span class="line">                // references to scopes surronding literals above</span><br><span class="line">                lhs: e1,</span><br><span class="line">                rhs: e3,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 5, scope surronding expression 4</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: i32,</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(1),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:2:13: 2:18 (#0),</span><br><span class="line">            kind: Scope &#123;</span><br><span class="line">                region_scope: Node(5),</span><br><span class="line">                lint_level: Explicit(</span><br><span class="line">                    HirId &#123;</span><br><span class="line">                        owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                        local_id: 5,</span><br><span class="line">                    &#125;,</span><br><span class="line">                ),</span><br><span class="line">                value: e4,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 6, block around statement</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: (),</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(9),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:1:11: 3:2 (#0),</span><br><span class="line">            kind: Block &#123;</span><br><span class="line">                body: Block &#123;</span><br><span class="line">                    targeted_by_break: false,</span><br><span class="line">                    region_scope: Node(8),</span><br><span class="line">                    opt_destruction_scope: None,</span><br><span class="line">                    span: oneplustwo.rs:1:11: 3:2 (#0),</span><br><span class="line">                    // reference to statement 0 below</span><br><span class="line">                    stmts: [</span><br><span class="line">                        s0,</span><br><span class="line">                    ],</span><br><span class="line">                    expr: None,</span><br><span class="line">                    safety_mode: Safe,</span><br><span class="line">                &#125;,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // expression 7, scope around block in expression 6</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: (),</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(9),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:1:11: 3:2 (#0),</span><br><span class="line">            kind: Scope &#123;</span><br><span class="line">                region_scope: Node(9),</span><br><span class="line">                lint_level: Explicit(</span><br><span class="line">                    HirId &#123;</span><br><span class="line">                        owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                        local_id: 9,</span><br><span class="line">                    &#125;,</span><br><span class="line">                ),</span><br><span class="line">                value: e6,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        // destruction scope around expression 7</span><br><span class="line">        Expr &#123;</span><br><span class="line">            ty: (),</span><br><span class="line">            temp_lifetime: Some(</span><br><span class="line">                Node(9),</span><br><span class="line">            ),</span><br><span class="line">            span: oneplustwo.rs:1:11: 3:2 (#0),</span><br><span class="line">            kind: Scope &#123;</span><br><span class="line">                region_scope: Destruction(9),</span><br><span class="line">                lint_level: Inherited,</span><br><span class="line">                value: e7,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    ],</span><br><span class="line">    stmts: [</span><br><span class="line">        // let statement</span><br><span class="line">        Stmt &#123;</span><br><span class="line">            kind: Let &#123;</span><br><span class="line">                remainder_scope: Remainder &#123; block: 8, first_statement_index: 0&#125;,</span><br><span class="line">                init_scope: Node(1),</span><br><span class="line">                pattern: Pat &#123;</span><br><span class="line">                    ty: i32,</span><br><span class="line">                    span: oneplustwo.rs:2:9: 2:10 (#0),</span><br><span class="line">                    kind: Binding &#123;</span><br><span class="line">                        mutability: Not,</span><br><span class="line">                        name: &quot;x&quot;,</span><br><span class="line">                        mode: ByValue,</span><br><span class="line">                        var: LocalVarId(</span><br><span class="line">                            HirId &#123;</span><br><span class="line">                                owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                                local_id: 7,</span><br><span class="line">                            &#125;,</span><br><span class="line">                        ),</span><br><span class="line">                        ty: i32,</span><br><span class="line">                        subpattern: None,</span><br><span class="line">                        is_primary: true,</span><br><span class="line">                    &#125;,</span><br><span class="line">                &#125;,</span><br><span class="line">                initializer: Some(</span><br><span class="line">                    e5,</span><br><span class="line">                ),</span><br><span class="line">                else_block: None,</span><br><span class="line">                lint_level: Explicit(</span><br><span class="line">                    HirId &#123;</span><br><span class="line">                        owner: DefId(0:3 ~ oneplustwo[6932]::main),</span><br><span class="line">                        local_id: 6,</span><br><span class="line">                    &#125;,</span><br><span class="line">                ),</span><br><span class="line">            &#125;,</span><br><span class="line">            opt_destruction_scope: Some(</span><br><span class="line">                Destruction(1),</span><br><span class="line">            ),</span><br><span class="line">        &#125;,</span><br><span class="line">    ],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Control-flow-Graph-CFG"><a href="#Control-flow-Graph-CFG" class="headerlink" title="Control-flow Graph (CFG)"></a>Control-flow Graph (CFG)</h2><p>A control-flow graph is structured as a set of basic blocks connected by edges. The key idea of a basic block is that it is a set of statements that execute “together” – that is, whenever you branch to a basic block, you start at the first statement and then execute all the remainder. Only at the end of the block is there the possibility of branching to more than one place (in MIR, we call that final statement the terminator):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bb0: &#123;</span><br><span class="line">    statement0;</span><br><span class="line">    statement1;</span><br><span class="line">    statement2;</span><br><span class="line">    ...</span><br><span class="line">    terminator;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>总而言之，basic block 是一个执行的整体。在 block 内部，不会有 branching。可以参考 <a href="/2023/12/17/patmc/">Basic block placement</a> 这个章节。</p><h2 id="MIR"><a href="#MIR" class="headerlink" title="MIR"></a>MIR</h2><p>MIR is Rust’s Mid-level Intermediate Representation. It is constructed from HIR. MIR was introduced in RFC 1211. It is a radically simplified form of Rust that is used for certain flow-sensitive safety checks – notably the borrow checker! – and also for optimization and code generation.</p><h3 id="Key-MIR-vocabulary"><a href="#Key-MIR-vocabulary" class="headerlink" title="Key MIR vocabulary"></a>Key MIR vocabulary</h3><p>This section introduces the key concepts of MIR, summarized here:</p><ul><li>Basic blocks<br>  见上文对 Basic block 的说明。</li><li>Locals<br>  Memory locations allocated on the stack (conceptually, at least), such as function arguments, local variables, and temporaries.<br>  These are identified by an index, written with a leading underscore, like <code>_1</code>. There is also a special “local” (<code>_0</code>) allocated to store the return value.</li><li>Places: expressions that identify a location in memory, like <code>_1</code> or <code>_1.f</code>.</li><li>Rvalues: expressions that produce a value. The “R” stands for the fact that these are the “right-hand side” of an assignment.<ul><li>Operands: the arguments to an rvalue, which can either be a constant (like 22) or a place (like <code>_1</code>).</li></ul></li></ul><p>Some statements like StorageLive are removed in optimization. This happens because the compiler notices the value is never accessed in the code. 可以通过 <code>rustc [filename].rs -Z mir-opt-level=0 --emit mir</code> 显示没有被优化过的 MIR。</p><h3 id="一个样例"><a href="#一个样例" class="headerlink" title="一个样例"></a>一个样例</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> vec = <span class="built_in">Vec</span>::new();</span><br><span class="line">    vec.push(<span class="number">1</span>);</span><br><span class="line">    vec.push(<span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面是 MIR</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">// WARNING: This output format is intended for human consumers only</span><br><span class="line">// and is subject to change without notice. Knock yourself out.</span><br><span class="line">fn main() -&gt; () &#123;</span><br><span class="line">    let mut _0: ();                      // return place in scope 0 at main.rs:1:11: 1:11</span><br><span class="line">    let mut _1: std::vec::Vec&lt;i32&gt;;      // in scope 0 at main.rs:2:9: 2:16</span><br><span class="line">    let _2: ();                          // in scope 0 at main.rs:3:5: 3:16</span><br><span class="line">    let mut _3: &amp;mut std::vec::Vec&lt;i32&gt;; // in scope 0 at main.rs:3:5: 3:16</span><br><span class="line">    let _4: ();                          // in scope 0 at main.rs:4:5: 4:16</span><br><span class="line">    let mut _5: &amp;mut std::vec::Vec&lt;i32&gt;; // in scope 0 at main.rs:4:5: 4:16</span><br><span class="line">    scope 1 &#123;</span><br><span class="line">        debug vec =&gt; _1;                 // in scope 1 at main.rs:2:9: 2:16</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb0: &#123;</span><br><span class="line">        StorageLive(_1);                 // scope 0 at main.rs:2:9: 2:16</span><br><span class="line">        _1 = Vec::&lt;i32&gt;::new() -&gt; bb1;   // scope 0 at main.rs:2:19: 2:29</span><br><span class="line">                                         // mir::Constant</span><br><span class="line">                                         // + span: main.rs:2:19: 2:27</span><br><span class="line">                                         // + user_ty: UserType(0)</span><br><span class="line">                                         // + literal: Const &#123; ty: fn() -&gt; Vec&lt;i32&gt; &#123;Vec::&lt;i32&gt;::new&#125;, val: Value(&lt;ZST&gt;) &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb1: &#123;</span><br><span class="line">        StorageLive(_2);                 // scope 1 at main.rs:3:5: 3:16</span><br><span class="line">        StorageLive(_3);                 // scope 1 at main.rs:3:5: 3:16</span><br><span class="line">        _3 = &amp;mut _1;                    // scope 1 at main.rs:3:5: 3:16</span><br><span class="line">        _2 = Vec::&lt;i32&gt;::push(move _3, const 1_i32) -&gt; [return: bb2, unwind: bb5]; // scope 1 at main.rs:3:5: 3:16</span><br><span class="line">                                         // mir::Constant</span><br><span class="line">                                         // + span: main.rs:3:9: 3:13</span><br><span class="line">                                         // + literal: Const &#123; ty: for&lt;&apos;a&gt; fn(&amp;&apos;a mut Vec&lt;i32&gt;, i32) &#123;Vec::&lt;i32&gt;::push&#125;, val: Value(&lt;ZST&gt;) &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb2: &#123;</span><br><span class="line">        StorageDead(_3);                 // scope 1 at main.rs:3:15: 3:16</span><br><span class="line">        StorageDead(_2);                 // scope 1 at main.rs:3:16: 3:17</span><br><span class="line">        StorageLive(_4);                 // scope 1 at main.rs:4:5: 4:16</span><br><span class="line">        StorageLive(_5);                 // scope 1 at main.rs:4:5: 4:16</span><br><span class="line">        _5 = &amp;mut _1;                    // scope 1 at main.rs:4:5: 4:16</span><br><span class="line">        _4 = Vec::&lt;i32&gt;::push(move _5, const 2_i32) -&gt; [return: bb3, unwind: bb5]; // scope 1 at main.rs:4:5: 4:16</span><br><span class="line">                                         // mir::Constant</span><br><span class="line">                                         // + span: main.rs:4:9: 4:13</span><br><span class="line">                                         // + literal: Const &#123; ty: for&lt;&apos;a&gt; fn(&amp;&apos;a mut Vec&lt;i32&gt;, i32) &#123;Vec::&lt;i32&gt;::push&#125;, val: Value(&lt;ZST&gt;) &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb3: &#123;</span><br><span class="line">        StorageDead(_5);                 // scope 1 at main.rs:4:15: 4:16</span><br><span class="line">        StorageDead(_4);                 // scope 1 at main.rs:4:16: 4:17</span><br><span class="line">        _0 = const ();                   // scope 0 at main.rs:1:11: 5:2</span><br><span class="line">        drop(_1) -&gt; [return: bb4, unwind: bb6]; // scope 0 at main.rs:5:1: 5:2</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb4: &#123;</span><br><span class="line">        StorageDead(_1);                 // scope 0 at main.rs:5:1: 5:2</span><br><span class="line">        return;                          // scope 0 at main.rs:5:2: 5:2</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb5 (cleanup): &#123;</span><br><span class="line">        drop(_1) -&gt; bb6;                 // scope 0 at main.rs:5:1: 5:2</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bb6 (cleanup): &#123;</span><br><span class="line">        resume;                          // scope 0 at main.rs:1:1: 5:2</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>debug vec =&gt; _1;</code> 提供了 debug 信息。</p><p><code>StorageLive(_1);</code> 表示 variable <code>_1</code> is “live” 的，也就是稍后还会被使用，直到遇到一个 <code>StorageDead(_1)</code>。这些标记被 LLVM 来分配栈空间。</p><p><code>&lt;Place&gt; = &lt;Rvalue&gt;</code> 这样的是赋值语句。</p><ol><li>A place is an expression like <code>_3</code>, <code>_3.f</code> or <code>*_3</code> – it denotes a location in memory.</li><li>An Rvalue is an expression that creates a value: in this case, the rvalue is a mutable borrow expression, which looks like <code>&amp;mut &lt;Place&gt;</code>. So we can kind of define a grammar for rvalues like so: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;Rvalue&gt;  = &amp; (mut)? &lt;Place&gt;</span><br><span class="line">      | &lt;Operand&gt; + &lt;Operand&gt;</span><br><span class="line">      | &lt;Operand&gt; - &lt;Operand&gt;</span><br><span class="line">      | ...</span><br><span class="line"></span><br><span class="line">&lt;Operand&gt; = Constant</span><br><span class="line">          | copy Place</span><br><span class="line">          | move Place</span><br></pre></td></tr></table></figure></li></ol><p>When you use a place, we indicate whether we are copying it (which requires that the place have a type T where T: Copy) or moving it (which works for a place of any type).</p><h1 id="有关-Rust-的类型系统及其-Analysis"><a href="#有关-Rust-的类型系统及其-Analysis" class="headerlink" title="有关 Rust 的类型系统及其 Analysis"></a>有关 Rust 的类型系统及其 Analysis</h1><h2 id="ty-模块"><a href="#ty-模块" class="headerlink" title="ty 模块"></a>ty 模块</h2><h3 id="ty-Ty"><a href="#ty-Ty" class="headerlink" title="ty::Ty"></a>ty::Ty</h3><p>The specific Ty we are referring to is <code>rustc_middle::ty::Ty</code> (and not <code>rustc_hir::Ty</code>). The distinction is important, so we will discuss it first before going into the details of <code>ty::Ty</code>.</p><p>In contrast, <code>ty::Ty</code> represents the semantics of a type, that is, the meaning of what the user wrote. For example, <code>rustc_hir::Ty</code> would record the fact that a user used the name <code>u32</code> twice in their program, but the <code>ty::Ty</code> would record the fact that both usages refer to the same type.</p><h4 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h4><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">foo</span></span>(x: <span class="built_in">u32</span>) → <span class="built_in">u32</span> &#123; x &#125;</span><br></pre></td></tr></table></figure><p>In this function, we see that <code>u32</code> appears twice. We know that that is the same type, i.e. the function takes an argument and returns an argument of the same type, but from the point of view of the HIR, there would be two distinct type instances because these are occurring in two different places in the program. That is, they have two different Spans (locations).</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">foo</span></span>(x: &amp;<span class="built_in">u32</span>) -&gt; &amp;<span class="built_in">u32</span></span><br></pre></td></tr></table></figure><p>进一步的，HIR 可能会丢弃一些信息。比如 <code>&amp;u32</code> 是一个 incomplete 的类型，因为它还缺少一个 lifetime。但我们并不需要写这些 lifetime，因为一些 elision rules 的缘故。其最终的表示类似于 <code>fn foo&lt;&#39;a&gt;(x: &amp;&#39;a u32) -&gt; &amp;&#39;a u32</code>。</p><p>在 HIR 级别，这样的表示并没有被生成，所以我们可以说类型是 incomplete 的。但是在 <code>ty::Ty</code> 级别，这些信息会被补足，所以现在类型是 complete 了。进一步的，对于每一个类型，只会有一个 <code>ty::Ty</code>。比如一个 u32 的 <code>ty::Ty</code> 会在整个程序中都被 share。这不同于 <code>rustc_hir::Ty</code>。</p><h3 id="Order"><a href="#Order" class="headerlink" title="Order"></a>Order</h3><p>HIR is built directly from the AST, so it happens before any <code>ty::Ty</code> is produced. After HIR is built, some basic type inference and type checking is done. During the type inference, we figure out what the <code>ty::Ty</code> of everything is and we also check if the type of something is ambiguous. The <code>ty::Ty</code> is then used for type checking while making sure everything has the expected type. </p><p>The <code>hir_ty_lowering</code> module is where the code responsible for lowering a <code>rustc_hir::Ty</code> to a <code>ty::Ty</code> is located. The main routine used is <code>lower_ty</code>.</p><h3 id="How-semantics-drive-the-two-instances-of-Ty"><a href="#How-semantics-drive-the-two-instances-of-Ty" class="headerlink" title="How semantics drive the two instances of Ty"></a>How semantics drive the two instances of Ty</h3><p>从类型推断的观点来说，HIR 去对类型进行更少的假设。我们假设两个类型是不同的，除非随后它们被证明是相同的。换句话说，知道的越少，假设就越少。</p><p>考虑 <code>fn foo&lt;T&gt;(x: T) -&gt; u32</code>. 考虑调用了 <code>foo::&lt;u32&gt;(0)</code>. 此时，T 和 u32 最终都是同一个类型，所以最终使用同一个 <code>ty::Ty</code>，但 rustc_hir::Ty 还是不同的。当然这个例子有点过于简单了，因为在 type checking 的时候，会 check the function generically and would still have a T distinct from u32。在后续的 code generation 的时候，才会进行 monomorphized，也就是对于泛型函数的每个版本生成对应的替换掉泛型变量的函数。</p><h3 id="ty-Ty-implementation"><a href="#ty-Ty-implementation" class="headerlink" title="ty::Ty implementation"></a>ty::Ty implementation</h3><p><code>rustc_middle::ty::Ty</code> is actually a wrapper around <code>Interned&lt;WithCachedTypeInfo&lt;TyKind&gt;&gt;</code>. Interned 可以忽略，它还起到一个指针的作用，反正解引用也可以被折叠。<code>TyKind</code> is a big enum with variants to represent many different Rust types，比如原始类型、引用、ADT、泛型以及 lifetime 等。 <code>WithCachedTypeInfo</code> has a few cached values like flags and <code>outer_exclusive_binder</code>. They are convenient hacks for efficiency and summarize information about the type that we may want to know, but they don’t come into the picture as much here. </p><h3 id="Allocating-and-working-with-types"><a href="#Allocating-and-working-with-types" class="headerlink" title="Allocating and working with types"></a>Allocating and working with types</h3><p>To allocate a new type, you can use the various new_* methods defined on Ty. These have names that correspond mostly to the various kinds of types. For example:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> array_ty = Ty::new_array_with_const_len(tcx, ty, count);</span><br></pre></td></tr></table></figure><p>类似的方法返回一个 <code>Ty&lt;&#39;tcx&gt;</code>。注意获得的 lifetime 是 tctx 所访问的哪个 arena 的 lifetime。Types are always canonicalized and interned (so we never allocate exactly the same type twice).</p><h3 id="Comparing-types"><a href="#Comparing-types" class="headerlink" title="Comparing types"></a>Comparing types</h3><h3 id="ty-TyKind-Variants"><a href="#ty-TyKind-Variants" class="headerlink" title="ty::TyKind Variants"></a>ty::TyKind Variants</h3><h3 id="ADTs-Representation"><a href="#ADTs-Representation" class="headerlink" title="ADTs Representation"></a>ADTs Representation</h3><h2 id="Bound-vars-and-parameters"><a href="#Bound-vars-and-parameters" class="headerlink" title="Bound vars and parameters"></a>Bound vars and parameters</h2><h2 id="Type-inference"><a href="#Type-inference" class="headerlink" title="Type inference"></a>Type inference</h2><p>下面代码中的 <code>things</code> 的类型被推断为 <code>Vec&lt;&amp;str&gt;</code>，因为我们往 things 中加入了 <code>&amp;str</code>。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> things = <span class="built_in">vec!</span>[];</span><br><span class="line">    things.push(<span class="string">"thing"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The type inference is based on the standard Hindley-Milner (HM) type inference algorithm, but extended in various way to accommodate subtyping, region inference, and higher-ranked types.</p><h3 id="Inference-variables"><a href="#Inference-variables" class="headerlink" title="Inference variables"></a>Inference variables</h3><p>inference context 的主要目的是容纳一系列的 inference variable。这些表示那些具体值还没有被确定的 type 或者 region。这些值会在 type-checking 的时候被计算得到。</p><p>如果了解 HM 类型系统或者像 Prolog 的逻辑语言就能理解类似的概念。</p><p>All told, the inference context stores five kinds of inference variables (as of March 2023):</p><p>inference context 存放 5 种 inference variable：</p><ul><li>Type variables, which come in three varieties:<ul><li>General type variables (the most common). These can be unified with any type.</li><li>Integral type variables, which can only be unified with an integral type, and arise from an integer literal expression like <code>22</code>.</li><li>Float type variables, which can only be unified with a float type, and arise from a float literal expression like <code>22.0</code>.</li></ul></li><li>Region variables, which represent lifetimes, and arise all over the place.</li><li>Const variables, which represent constants.</li></ul><p>All the type variables work in much the same way: you can create a new type variable, and what you get is <code>Ty&lt;&#39;tcx&gt;</code> representing an unresolved type <code>?T</code>. Then later you can apply the various operations that the inferencer supports, such as equality or subtyping, and it will possibly instantiate (or bind) that <code>?T</code> to a specific value as a result.</p><p>对于 Region variable 情况不同，会在稍后 Region constraints 中讨论。</p><h3 id="补充说明：lexical-region-和-non-lexical-region"><a href="#补充说明：lexical-region-和-non-lexical-region" class="headerlink" title="补充说明：lexical region 和 non-lexical region"></a>补充说明：lexical region 和 non-lexical region</h3><p><a href="https://stackoverflow.com/questions/50251487/what-are-non-lexical-lifetimes" target="_blank" rel="noopener">如下所示</a>，在 non-lexical lifetime 出现之前，下面的代码会编译失败。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> scores = <span class="built_in">vec!</span>[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line">    <span class="keyword">let</span> score = &amp;scores[<span class="number">0</span>];</span><br><span class="line">    scores.push(<span class="number">4</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译报错如下，当然我发现现如今的 rust 已经无法复现了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">error[E0502]: cannot borrow `scores` as mutable because it is also borrowed as immutable</span><br><span class="line"> --&gt; src/main.rs:4:5</span><br><span class="line">  |</span><br><span class="line">3 |     let score = &amp;scores[0];</span><br><span class="line">  |                  ------ immutable borrow occurs here</span><br><span class="line">4 |     scores.push(4);</span><br><span class="line">  |     ^^^^^^ mutable borrow occurs here</span><br><span class="line">5 | &#125;</span><br><span class="line">  | - immutable borrow ends here</span><br></pre></td></tr></table></figure><p>这里报错的原因是 score 是通过 <a href="https://en.wikipedia.org/wiki/Scope_(computer_science)#Lexical_scoping" target="_blank" rel="noopener">lexical</a> 的方式 borrow 的 scores 的。</p><h3 id="Region-constraints"><a href="#Region-constraints" class="headerlink" title="Region constraints"></a>Region constraints</h3><p>Regions are inferenced somewhat differently from types. Rather than eagerly unifying things, we simply collect constraints as we go, but make (almost) no attempt to solve regions. These constraints have the form of an “outlives” constraint:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">'a</span>: <span class="symbol">'b</span></span><br></pre></td></tr></table></figure><p>实际上这个代码将 <code>&#39;a</code> 和 <code>&#39;b</code> 视作了 subregion 的关系，但实际上是一个意思</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">'b</span> &lt;= <span class="symbol">'a</span></span><br></pre></td></tr></table></figure><p>(There are various other kinds of constraints, such as “verifys”; see the <code>region_constraints</code> module for details.)</p><p>但是依然有一个常见，我们会做一些 eager unification。也就是如果有一个 equality constraint between two regions，如</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">'a</span> = <span class="symbol">'b</span></span><br></pre></td></tr></table></figure><p>那么我们就会将这个事实记录在一个 unification table 中。可以使用 <code>opportunistic_resolve_var</code> to convert <code>&#39;b</code> to <code>&#39;a</code>，或者反过来也可以. This is sometimes needed to ensure termination of fixed-point algorithms.</p><h3 id="Solving-region-constraints"><a href="#Solving-region-constraints" class="headerlink" title="Solving region constraints"></a>Solving region constraints</h3><p>Region constraints are only solved at the very end of typechecking, once all other constraints are known and all other obligations have been proven. There are two ways to solve region constraints right now: lexical and non-lexical. Eventually there will only be one.</p><p>An exception here is the leak-check which is used during trait solving and relies on region constraints containing higher-ranked regions. Region constraints in the root universe (i.e. not arising from a <code>for&lt;&#39;a&gt;</code>) must not influence the trait system, as these regions are all erased during codegen.</p><p>To solve lexical region constraints, you invoke <code>resolve_regions_and_report_errors</code>. This “closes” the region constraint process and invokes the <code>lexical_region_resolve</code> code. Once this is done, any further attempt to equate or create a subtyping relationship will yield an ICE.</p><p>The NLL solver (actually, the MIR type-checker) does things slightly differently. It uses canonical queries for trait solving which use <code>take_and_reset_region_constraints</code> at the end. This extracts all of the outlives constraints added during the canonical query. This is required as the NLL solver must not only know what regions outlive each other, but also where. Finally, the NLL solver invokes <code>take_region_var_origins</code>, providing all region variables to the solver.</p><h3 id="Lexical-region-resolution"><a href="#Lexical-region-resolution" class="headerlink" title="Lexical region resolution"></a>Lexical region resolution</h3><p>Lexical region resolution is done by initially assigning each region variable to an empty value. We then process each outlives constraint repeatedly, growing region variables until a fixed-point is reached. Region variables can be grown using a least-upper-bound relation on the region lattice in a fairly straightforward fashion.</p><p><a href="https://internals.rust-lang.org/t/how-does-region-inference-work/7511/3" target="_blank" rel="noopener">https://internals.rust-lang.org/t/how-does-region-inference-work/7511/3</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Constraints | Ordering | Region-lattice </span><br><span class="line">------------|----------|--------------</span><br><span class="line">  &apos;a:&apos;b+&apos;c  | &apos;a &lt;= &apos;b |      &apos;d      Join, LUB (Most Specific Supertype)</span><br><span class="line">  &apos;b:&apos;d     | &apos;a &lt;= &apos;c |      / \     </span><br><span class="line">  &apos;c:&apos;d     | &apos;b &lt;= &apos;d |    &apos;b  &apos;c    </span><br><span class="line">  &apos;d        | &apos;c &lt;= &apos;d |      \ /     </span><br><span class="line">            |          |      &apos;a      Meet, GLB (Most Common Subtype)</span><br></pre></td></tr></table></figure><h1 id="有关-Borrow-checker"><a href="#有关-Borrow-checker" class="headerlink" title="有关 Borrow checker"></a>有关 Borrow checker</h1><p>The borrow checker operates on the MIR. An older implementation operated on the HIR. Doing borrow checking on MIR has several advantages:</p><ol><li>The MIR is far less complex than the HIR; the radical desugaring helps prevent bugs in the borrow checker. (If you’re curious, you can see a list of bugs that the MIR-based borrow checker fixes here.)</li><li>Even more importantly, using the MIR enables “non-lexical lifetimes”, which are regions derived from the control-flow graph.</li></ol><h2 id="Tracking-moves-and-initialization"><a href="#Tracking-moves-and-initialization" class="headerlink" title="Tracking moves and initialization"></a>Tracking moves and initialization</h2><p>其作用如下，检查哪些变量是 uninitialized 的状态。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">foo</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> a: (<span class="built_in">Vec</span>&lt;<span class="built_in">u32</span>&gt;, <span class="built_in">Vec</span>&lt;<span class="built_in">u32</span>&gt;) = (<span class="built_in">vec!</span>[<span class="number">22</span>], <span class="built_in">vec!</span>[<span class="number">44</span>]);</span><br><span class="line">    <span class="comment">// a.0 and a.1 are both initialized</span></span><br><span class="line">    <span class="keyword">let</span> b = a.<span class="number">0</span>; <span class="comment">// moves a.0</span></span><br><span class="line">    <span class="comment">// a.0 is not initialized, but a.1 still is</span></span><br><span class="line">    <span class="keyword">let</span> c = a.<span class="number">0</span>; <span class="comment">// ERROR</span></span><br><span class="line">    <span class="keyword">let</span> d = a.<span class="number">1</span>; <span class="comment">// OK</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为 Rust 现在允许只 move 一个 field 比如 <code>a.0</code> 了，所以 trace local variable 是不够的。Rust 根据 move path 为粒度去 trace。<br>A <a href="https://doc.rust-lang.org/nightly/nightly-rustc/rustc_mir_dataflow/move_paths/struct.MovePath.html" target="_blank" rel="noopener">MovePath</a> represents some location that the user can initialize, move, etc. So e.g. there is a move-path representing the local variable a, and there is a move-path representing a.0. Move paths roughly correspond to the concept of a Place from MIR, but they are indexed in ways that enable us to do move analysis more efficiently.</p><p>所有的 <code>MovePath</code> 存储在一个 vector 中，我们通过 <code>MovePathIndex</code> 去访问。</p><p>One of the first things we do in the MIR borrow check is to construct the set of move paths. This is done as part of the <code>MoveData::gather_moves</code> function. This function uses a MIR visitor called <code>Gatherer</code> to walk the MIR and look at how each <code>Place</code> within is accessed. For each such <code>Place</code>, it constructs a corresponding <code>MovePathIndex</code>. It also records when/where that particular move path is moved/initialized, but we’ll get to that in a later section.</p><p>We don’t actually create a move-path for every <code>Place</code> that gets used. In particular, if it is illegal to move from a <code>Place</code>, then there is no need for a <code>MovePathIndex</code>. Some examples:</p><ul><li>You cannot move from a static variable, so we do not create a <code>MovePathIndex</code> for static variables.</li><li>You cannot move an individual element of an array, so if we have e.g. <code>foo: [String; 3]</code>, there would be no move-path for <code>foo[1]</code>.</li><li>You cannot move from inside of a borrowed reference, so if we have e.g. <code>foo: &amp;String</code>, there would be no move-path for <code>*foo</code>.</li></ul><p>These rules are enforced by the <code>move_path_for</code> function, which converts a <code>Place</code> into a <code>MovePathIndex</code>。在诸如上面的错误的场景下，返回错误 <code>Err</code>。这也说明了我们并不需要 track 这些 <code>Place</code> 是否已经 initialized 了，从而减少了开销.</p><p>If you have a <code>Place</code> and you would like to convert it to a <code>MovePathIndex</code>, you can do that using the <code>MovePathLookup</code> structure found in the <code>rev_lookup</code> field of <code>MoveData</code>. There are two different methods:</p><ol><li><code>find_local</code>, which takes a <code>mir::Local</code> representing a local variable. This is the easier method, because we always create a <code>MovePathIndex</code> for every local variable.</li><li><code>find</code>, 可以处理任意的 <code>Place</code>。所以，只会返回一个 <code>LookupResult</code>，表示最近的 path。例如对 <code>foo[1]</code> 返回 <code>foo</code>。</li></ol><p>As we noted above, move-paths are stored in a big vector and referenced via their <code>MovePathIndex</code>. 但是在这个 vector 中，它们也被构建为一棵树。例如 if you have the <code>MovePathIndex</code> for <code>a.b.c</code>, you can go to its parent move-path <code>a.b</code>. 也可以遍历所有的 child path。比如对于 <code>a.b</code>, you might iterate to find the path <code>a.b.c</code> (here you are iterating just over the paths that are <strong>actually referenced</strong> in the source, not all <strong>possible</strong> paths that could have been referenced). These references are used for example in the <code>find_in_move_path_or_its_descendants</code> function, which determines whether a move-path (e.g., <code>a.b</code>) or any child of that move-path (e.g.,<code>a.b.c</code>) matches a given predicate.</p><h2 id="The-MIR-type-check"><a href="#The-MIR-type-check" class="headerlink" title="The MIR type-check"></a>The MIR type-check</h2><p>A key component of the borrow check is the MIR type-check. This check walks the MIR and does a complete “type check” – the same kind you might find in any other language. In the process of doing this type-check, we also uncover the region constraints that apply to the program.</p><h3 id="User-types"><a href="#User-types" class="headerlink" title="User types"></a>User types</h3><p>在 MIR type check 的开始，we replace all regions in the body with new unconstrained regions. However, this would cause us to accept the following program:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">foo</span></span>&lt;<span class="symbol">'a</span>&gt;(x: &amp;<span class="symbol">'a</span> <span class="built_in">u32</span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> y: &amp;<span class="symbol">'static</span> <span class="built_in">u32</span> = x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>By erasing the lifetimes in the type of <code>y</code> we no longer know that it is supposed to be <code>&#39;static</code>, ignoring the intentions of the user.</p><p>To deal with this we remember all places where the user explicitly mentioned a type during HIR type-check as <code>CanonicalUserTypeAnnotations</code>.</p><p>There are two different annotations we care about:</p><ol><li>Explicit type ascriptions, 比如 <code>let y: &amp;&#39;static u32</code> 会产生 <code>UserType::Ty(&amp;&#39;static u32)</code>.</li><li>Explicit generic arguments, 比如 <code>x.foo&lt;&amp;&#39;a u32, Vec&lt;String&gt;&gt;</code> 会产生 <code>UserType::TypeOf(foo_def_id, [&amp;&#39;a u32, Vec&lt;String&gt;])</code>.</li></ol><h2 id="Drop-Check"><a href="#Drop-Check" class="headerlink" title="Drop Check"></a>Drop Check</h2><h3 id="Implicit-drop"><a href="#Implicit-drop" class="headerlink" title="Implicit drop"></a>Implicit drop</h3><p>通常，只要 local 被使用，就必须要 local 的 type 是 well-formed 的。This includes proving the where-bounds of the local and also requires all regions used by it to be live.</p><p>唯一的特例是在 value go out of scope 的时候，隐式 drop 掉 value，这不需要 value 是 live 的。<br>如下所示，x 在注释处已经 out of scope 了，并且这是在指向 y 的引用被 invalidate 之后。也就是说在 drop <code>x</code> 的时候，它的类型不是 well-formed 的。但这是个特例，实际上也是唯一 drop value 操作不需要访问任何 dead region 的情况。We check this by requiring the type of the value to be drop-live. The requirements for which are computed in fn <code>dropck_outlives</code>.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> x = <span class="built_in">vec!</span>[];</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">let</span> y = <span class="built_in">String</span>::from(<span class="string">"I am temporary"</span>);</span><br><span class="line">        x.push(&amp;y);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// `x` goes out of scope here, after the reference to `y`</span></span><br><span class="line">    <span class="comment">// is invalidated. This means that while dropping `x` its type</span></span><br><span class="line">    <span class="comment">// is not well-formed as it contain regions which are not live.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="How-values-are-dropped"><a href="#How-values-are-dropped" class="headerlink" title="How values are dropped"></a>How values are dropped</h3><p>At its core, a value of type T is dropped by executing its “drop glue”. Drop glue is compiler generated and first calls<code> &lt;T as Drop&gt;::drop</code> and then recursively calls the drop glue of any recursively owned values.</p><ul><li>If T has an explicit Drop impl, call <code>&lt;T as Drop&gt;::drop</code>.</li><li>Regardless of whether <code>T</code> implements <code>Drop</code>, recurse into all values owned by T:<ul><li>references, raw pointers, function pointers, function items, trait objects1, and scalars do not own anything.<br>  对于 trait object，可以认为它有一个内置的 Drop 实现，该实现会直接调用 vtable 中的 <code>drop_in_place</code>。这个 Drop 实现需要所有它所有的 generic parameter 都是 alive 的。</li><li>tuples, slices, and arrays consider their elements to be owned. For arrays of length zero we do not own any value of the element type.</li><li>all fields (of all variants) of ADTs are considered owned. We consider all variants for enums.<br>  The exception here is <code>ManuallyDrop&lt;U&gt;</code> which is not considered to own U.<br>  <code>PhantomData&lt;U&gt;</code> also does not own anything.</li><li>closures and generators own their captured upvars.</li></ul></li></ul><p>可以通过 <code>fn Ty::needs_drop</code> 判断是否一个类型是否有 drop glue。</p><h3 id="Partially-dropping-a-local"><a href="#Partially-dropping-a-local" class="headerlink" title="Partially dropping a local"></a>Partially dropping a local</h3><p>如果一个 type 没有实现 Drop，就可以在 drop 掉剩下的成员前 move 掉一些其他的成员。此时，只有那些没有被 move 的成员会被触发 drop glue。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">PrintOnDrop</span></span>&lt;<span class="symbol">'a</span>&gt;(&amp;<span class="symbol">'a</span> <span class="built_in">str</span>);</span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">'a</span>&gt; <span class="built_in">Drop</span> <span class="keyword">for</span> PrintOnDrop&lt;<span class="symbol">'_</span>&gt; &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">drop</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">"&#123;&#125;"</span>, <span class="keyword">self</span>.<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> x = (PrintOnDrop(<span class="string">"third"</span>), PrintOnDrop(<span class="string">"first"</span>));</span><br><span class="line">    <span class="built_in">drop</span>(x.<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">"second"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是如果遇到下面的代码，则会报错 <code>cannot move out of type Tup&lt;&#39;_&gt;, which implements the Drop trait</code>。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Tup</span></span>&lt;<span class="symbol">'a</span>&gt; &#123;</span><br><span class="line">    a: PrintOnDrop&lt;<span class="symbol">'a</span>&gt;,</span><br><span class="line">    b: PrintOnDrop&lt;<span class="symbol">'a</span>&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">'a</span>&gt; <span class="built_in">Drop</span> <span class="keyword">for</span> Tup&lt;<span class="symbol">'a</span>&gt; &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">drop</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> x = Tup&#123;a: PrintOnDrop(<span class="string">"third"</span>), b: PrintOnDrop(<span class="string">"first"</span>)&#125;;</span><br><span class="line">    <span class="built_in">drop</span>(x.b);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">"second"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>During MIR building we assume that a local may get dropped whenever it goes out of scope as long as its type needs drop.<br>Computing the exact drop glue for a variable happens after borrowck in the <code>ElaborateDrops</code> pass. 也就是说，即使 local 中的一些成员之前已经被 drop 了，dropck 依然需要这些 value 是 alive 的。</p><p>如下所示，完全 move 了 local 的情况下也是这样。<code>x</code> borrow 了 temp，然后被 drop 了。但依然会有下面的报错。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> x;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">let</span> temp = <span class="built_in">String</span>::from(<span class="string">"I am temporary"</span>);</span><br><span class="line">        x = PrintOnDrop(&amp;temp);</span><br><span class="line">        <span class="built_in">drop</span>(x);</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="comment">//~ ERROR `temp` dropped here while still borrowed</span></span><br></pre></td></tr></table></figure><h3 id="dropck-outlives"><a href="#dropck-outlives" class="headerlink" title="dropck_outlives"></a>dropck_outlives</h3><p>There are two distinct “liveness” computations that we perform:</p><ul><li>a value v is use-live at location L if it may be “used” later; a use here is basically anything that is not a drop</li><li>a value v is drop-live at location L if it maybe dropped later</li></ul><p>When things are <code>use-live</code>, their entire type must be valid at L.<br>When they are <code>drop-live</code>, all regions that are required by dropck must be valid at L. The values dropped in the MIR are places.</p><h2 id="Region-inference-Non-Lexical-Lifetime-NLL"><a href="#Region-inference-Non-Lexical-Lifetime-NLL" class="headerlink" title="Region inference (Non-Lexical Lifetime, NLL)"></a>Region inference (Non-Lexical Lifetime, NLL)</h2><p>The MIR-based region checking code is located in the <code>rustc_mir::borrow_check</code> module.</p><p>The MIR-based region analysis consists of two major functions:</p><ul><li><code>replace_regions_in_mir</code>, invoked first, has two jobs:<ul><li>First, it finds the set of regions that appear within the signature of the function (e.g., <code>&#39;a</code> in <code>fn foo&lt;&#39;a&gt;(&amp;&#39;a u32) { ... }</code>). These are called the “universal” or “free” regions – in particular, they are the regions that appear free in the function body.</li><li>Second, it replaces all the regions from the function body with fresh inference variables. This is because (presently) those regions are the results of lexical region inference and hence are not of much interest. The intention is that – eventually – they will be “erased regions” (i.e., no information at all), since we won’t be doing lexical region inference at all.</li></ul></li><li><code>compute_regions</code>, invoked second: this is given as argument the results of move analysis. It has the job of computing values for all the inference variables that <code>replace_regions_in_mir</code> introduced.<ul><li>To do that, it first runs the MIR type checker. This is basically a normal type-checker but specialized to MIR, which is much simpler than full Rust, of course. Running the MIR type checker will however create various constraints between region variables, indicating their potential values and relationships to one another.</li><li>After this, we perform constraint propagation by creating a <code>RegionInferenceContext</code> and invoking its solve method.</li><li>The NLL RFC also includes fairly thorough (and hopefully readable) coverage.</li></ul></li></ul><h2 id="Universal-regions"><a href="#Universal-regions" class="headerlink" title="Universal regions"></a>Universal regions</h2><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://rustc-dev-guide.rust-lang.org/appendix/background.html" target="_blank" rel="noopener">https://rustc-dev-guide.rust-lang.org/appendix/background.html</a><br> 编译器的一些基础知识。</li><li><a href="https://rustc-dev-guide.rust-lang.org/hir.html" target="_blank" rel="noopener">https://rustc-dev-guide.rust-lang.org/hir.html</a><br> HIR。</li><li><a href="https://rustc-dev-guide.rust-lang.org/thir.html" target="_blank" rel="noopener">https://rustc-dev-guide.rust-lang.org/thir.html</a><br> THIR。</li><li><a href="https://rustc-dev-guide.rust-lang.org/ty.html" target="_blank" rel="noopener">https://rustc-dev-guide.rust-lang.org/ty.html</a><br> 关于 rust 类型系统的介绍。</li><li><a href="https://blog.logrocket.com/introducing-the-rust-borrow-checker/" target="_blank" rel="noopener">https://blog.logrocket.com/introducing-the-rust-borrow-checker/</a></li><li><a href="https://rustc-dev-guide.rust-lang.org/borrow_check.html" target="_blank" rel="noopener">https://rustc-dev-guide.rust-lang.org/borrow_check.html</a><br> Rust Compiler Development Guide 上的讲解</li><li><a href="https://www.zybuluo.com/darwin-yuan/note/424724" target="_blank" rel="noopener">https://www.zybuluo.com/darwin-yuan/note/424724</a><br> Hindley-Milner类型系统</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍 Rust 的 Borrow Checker 的原理。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Rust" scheme="http://www.calvinneo.com/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 1</title>
    <link href="http://www.calvinneo.com/2024/03/08/database-paper-1/"/>
    <id>http://www.calvinneo.com/2024/03/08/database-paper-1/</id>
    <published>2024-03-08T13:33:22.000Z</published>
    <updated>2024-11-04T03:54:04.609Z</updated>
    
    <content type="html"><![CDATA[<p>在比较早的时候，我使用腾讯文档记录一些数据库的论文。但我越来越无法忍受腾讯文档的 bug 等不便利。因此我打算将这些文章转移到博客中，即使它们中的部分的完成度并不是很高。</p><p>这篇文章中，包含 CStore、Kudu、Masstree 和 Ceph。</p><a id="more"></a><h1 id="CStore"><a href="#CStore" class="headerlink" title="CStore"></a>CStore</h1><p>C-Store 引入了一个混合架构，包括一个针对频繁插入和更新优化的写存储组件 WS 和一个针对查询性能优化的读存储组件 RS。这也是 TiFlash 列存的 Delta Merge 架构的来源。</p><p>按照 projection 存储，一个 projection 对应了一个表的一个或者几个列。<br>每个 projection 有自己独立的 sort key。不同的 projection 之间，用 join indexes 来维护它们的对应关系。<br>每个 projection 会水平分区为多个 segment，每个 segment 有自己的一个 sid。<br>每个 segment 分为 RS 和 WS。storage key 用来表示在 segment 上的一行。定义 storage key：</p><ol><li>在 RS 上，直接按序存储，通过遍历获得 index</li><li>在 WS 上，每次插入获取一个 storage key，大于 RS 上的最大值</li></ol><p>从上面看到，(sid, storage key) 可以唯一索引一个 key，它可能在 RS 上，也可能在 WS 上。</p><p>在 WS 上，projection 上的每一列用 B tree 来存，是按照 storage key 来排序的。所以还要额外维护 sort key -&gt; projection key 的映射关系。<br>【Q】为什么 WS 上也不按照 storage key 自增来处理呢？这样就不需要一个 B tree 了啊。这是因为同一个 Segment 中不同列里具有相同 SK 的数据属于同一个 Logical Tuple，所以实际上是做不到递增的。为什么要这样设计呢？原因是 join indexes 就可以只维护每个 projection 上每一行到 (sid, storage key) 的映射关系就行了。如<a href="https://zhuanlan.zhihu.com/p/656631833" target="_blank" rel="noopener">下图</a>所示</p><p><img src="/img/dbpaper/cstore/joinindex.png"></p><p>从实现上来讲，当一个 tuple 到 WS 的时候，为它分配一个 storage key 也是很自然的。<br>对于只读查询来说，如果允许其读取过去任意时间的快照（其实就是 Time Travel Query），代价是非常大的。C-Store 维护了一个高水位（High Water Mark，HWM）和一个低水位（Low Water Mark，LWM），这两个水位其实对应了只读查询可读取的时间范围的上限和下限。</p><p>CStore 的 MVCC 是以 epoch 为单位的。epoch 的粒度应该是比较大的。我们可以读 epoch e 上的事务，当 epoch e 上的所有事务都被提交完毕。</p><p>RS 的存储有优化：<br>1.排序列+Cardinality 较少：run length 编码<br>2.排序列+Cardinality 较多：bitmap 编码<br>3.非排序列+Cardinality较少：delta encoding<br>4.非排序列+Cardinality较多：正常存储</p><h1 id="Kudu"><a href="#Kudu" class="headerlink" title="Kudu"></a>Kudu</h1><p><a href="https://kudu.apache.org/kudu.pdf" target="_blank" rel="noopener">https://kudu.apache.org/kudu.pdf</a></p><p>Hadoop 系统中的结构化数据的两种存储方式：</p><ol><li>静态数据<br> 使用 Avro 行存或者 Parquet 列存来存储，但它们对 UPDATE 单条记录，或者随机访问并不友好。</li><li>可变数据<br> 存在 semi-structed 仓库中，类似 HBase 或者 Cassandra。<br> 这些存储有很低的读写延迟，但是相比静态数据，其顺序读写的带宽不高，从而不适用于 OLAP 或者机器学习。</li></ol><p>一种折衷的方案是像 Cloudera 的一些用户一样，数据和修改流式写入 HBase，再定期导出为 HDFS 上的 Parquet 文件。但这样的架构会有以下问题：</p><ol><li>应用端要写复杂的代码维护两套系统。</li><li>要跨系统维护一致性的备份、安全策略、监控。</li><li>更新进入 HBase 到最终能被查询到的延时可能很久。</li><li>实际场景中经常有要修改已经持久化到 HDFS 的文件的需求，包括迟来的数据，或者修正之前的数据。文件重写是高开销的，还可能要人工介入。</li></ol><p>Kudu 从一开始就想要 high-throughput sequential-access storage systems(HDFS) 的好处，也想要 low-latency random-access systems(such as HBase or Cassandra) 的好处。Kudu 是选择成为一个 happy medium 选择。In particular, Kudu offers a simple API for row-level inserts, updates, and deletes, while providing table scans at throughputs similar to Parquet, a commonly-used columnar format for static data.</p><h2 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h2><h3 id="Write"><a href="#Write" class="headerlink" title="Write"></a>Write</h3><h3 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h3><p>Kudu 只提供一个 Scan 操作。Scan 操作支持两种 predicate：comparisons between a column and a constant value,<br>and composite primary key ranges。</p><p>用户可以为一个 scan 指定 projection。因为 Kudu 的盘上存储是列存，所以指定 projection 能够显著提高效率。</p><h3 id="Consistency-Model"><a href="#Consistency-Model" class="headerlink" title="Consistency Model"></a>Consistency Model</h3><p>The default consistency mode is snapshot consistency. 这里应该说的类似 Snapshot Isolation 吧。<br>A scan is guaranteed to yield a snapshot with no anomalies in which causality would be violated.<br>As such, it also guarantees read-your-writes consistency from a single client.</p><h3 id="Timestamp"><a href="#Timestamp" class="headerlink" title="Timestamp"></a>Timestamp</h3><p>不像 HBase 或者 Cassandra 一样将时间戳作为 first-class 的对象。</p><h2 id="Partitioning"><a href="#Partitioning" class="headerlink" title="Partitioning"></a>Partitioning</h2><p>类似于大多数的水平分布的数据库系统，Kudu 里面的 table 也是 partition 的，Kudu 和 Bigtable 都把它们称作 horizontal partitions tablets。每个 row 会被映射到一个 partition 上。对于需要吞吐量的大表，Kudu 推荐一个机器上有 10-100 个 tablet，每个 tablet 可以有 10GB 大小。</p><p>Bigtable 只提供 key-range 形式的分区，Cassandra 基本只会使用 hash 分区，Kudu 同时支持两种分区方式。</p><p>The partition schema is made up of zero or more hash-partitioning rules followed by an optional range-partitioning rule:</p><ol><li>Hash Partition 将 tuple 中的某些 column 连接起来组成 binary key，然后计算这个串的 hash 值。<br> 比如 <code>DISTRIBUTE BY HASH(hostname, ts) INTO 16 BUCKETS</code> 会将指定的这些列连接起来，然后计算结果的 hash，并 mod 下 bucket 的总数。</li><li>Range Partition 将 tuple 中的某些 column 连接起来组成 binary key，然后用 order-preserving encoding 来确定所处的 range。</li></ol><h2 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h2><p>Kudu 的 Leader 会负责用本地的 Lock Manager 去串行化 Concurrent 的操作，选择对应的 MVCC 时间戳，并且 propose 到 Raft 上。Raft 层复制的是每个 tablet 的逻辑日志，比如 insert、update、delete 等。<br>Kudu 说 there is no restriction that the leader must write an operation to its local log before it may be committed，所以能够保障很好的延迟。这里指的应该是 Raft 的 commit，也就是说只要有 quorum 的节点持久化日志就行，Leader 未必要持久化对应的日志，其实也是对 Raft 的优化。<br>此外，它还列出了两点和 Raft 有关的优化，这里略过。</p><p>再次强调，Kudu 并不是复制 tablet 的物理日志，而是 operation log。它的目的是在各个 Replica 之间解耦，从而得到下面的好处：</p><ol><li>避免所有的 replica 同时经历物理层的开销较大的操作，比如 flush 或者 compaction。这可以降低 client 在写入时感受到的 tail latency。后续还可以实现 speculative read requests，从而减少读的 tail latency。<br> 当然，我觉得这也有坏处，例如各个 Replica 之间的 Snapshot 不太好做了。实际上也是 TiKV 做的时候面临的取舍。</li><li>有机会及时发现某个 replica 被 corrupt 了，从而即使进行修复。</li></ol><p>针对 Raft 的成员变更，主要引入了 Pre Voter，我理解类似于 Learner 追进度的方式来保证不损失可用性。</p><h2 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h2><p>这里讲述的 Kudu 的 root service 的实现。主要包括的功能有：<br>1.作为 catalog manager，记录所有的 table 和 tablet，以及对应的元信息，比如 schema、replication level 等。处理 DDL。<br>2.作为 cluster coordinator，记录存活的 server，并进行 rebalance。<br>3.作为 tablet directory，记录每个 tablet 在哪些 server 上分布。</p><p>所以 Master 的工作量还是蛮大的，既要管理数据库的 schema，又要管理集群，又要管理数据分区。</p><h3 id="catalog-manager"><a href="#catalog-manager" class="headerlink" title="catalog manager"></a>catalog manager</h3><p>Master 会管理一个专有的 tablet。它会在内部将 catalog information 写到这个 tablet 里面，同时也会有一个 full write-through 的 cache 在内存里面。Kudu 并不担心占用太多内存，如果后面确实占用了，就把它放到一个 paged cache 里面。</p><p>The catalog table maintains a small amount of state for each table in the system. In particular, it keeps the current version of the table schema, the state of the table (creating, running, deleting, etc), and the set of tablets which comprise the table. </p><ol><li>first writing a table record to the catalog table indicating a CREATING state</li><li>Asynchronously, it selects tablet servers to host tablet replicas, creates the Master-side tablet metadata</li><li>Sends asynchronous requests to create the replicas on the tablet servers<br> a. If the replica creation fails or times out on a majority of replicas, the tablet can be safely deleted and a new tablet created with a new set of replicas.<br> b. If the Master fails in the middle of this operation, the table record indicates that a roll-forward is necessary and the master can resume where it left off.</li></ol><p>对于 delete 或者 change，会先 propogate 到相关的 tablet server，然后 Master 再写自己的存储。</p><p>A similar approach is used for other operations such as schema changes and deletion, where the Master ensures that the change is propagated to the relevant tablet servers before writing the new state to its own storage. 对于所有的情况，Master 发往 tablet server 的消息都是幂等的，这样在故障重启的时候，可以被重复发送。</p><p>因为 catalog 表也是存放在专有的 tablet 里面的，所以 Master 也会用 Raft 去复制持久化的状态，到 backup master 上。目前，backup master 只是作为 Raft follower，不处理 client 请求。当当选后，会扫描 catalog 表，加载内存中的 cache，并开始作为 active master 存在。</p><h3 id="cluster-coordinator"><a href="#cluster-coordinator" class="headerlink" title="cluster coordinator"></a>cluster coordinator</h3><p>每个 tablet 会记录所有 Master 节点的地址。启动之后会开始向这些 master 不断汇报自己上面的 tablet。第一次汇报是全量，后面的是增量。<br>Kudu 有个关键设计，就是尽管 Master 是 catalog 的 source of truth，但是它只是集群状态的 observer。集群中的 tablet server 会提供比如 tablet replica 的位置信息、Raft 相关、schema version 等信息。tablet 的相关变化也是通过 raft log 记录的。因此 Master 可以借助于 raft log 的 index 去比较 tablet state 的新旧。<br>Tablet server 承担了更多的责任，每个 tablet 的 Leader replica 负责检查有没有 crash 的 follower。发现后会发起配置变更将这个 follower 移除，并在配置变更完成后通知 Master。Master 负责选择新 replica 所在的 server，然后让 Leader replica 发起新的一轮配置变更。</p><h3 id="tablet-directory"><a href="#tablet-directory" class="headerlink" title="tablet directory"></a>tablet directory</h3><p>client 会直接请求 Master 询问 tablet 的位置信息，也会缓存很多最近的信息。当缓存的信息陈旧，则会被拒绝，此时需要重新联系 Master 要最新的 Leader。<br>Master 会将所有的 table partition range 存在内存中，所以请求变多，回复依然还是比较快。即使 tablet directory 变成瓶颈，Kudu 也可以返回陈旧的 location 信息。这里原因是客户端会失败，从而重试。所以论文中说 this portion of the Master can be trivially partitioned and replicated across any number of machines. 我理解是可以从 Master 的其他副本读，但这里实际上的瓶颈不应该是内存么？</p><h2 id="Tablet-storage"><a href="#Tablet-storage" class="headerlink" title="Tablet storage"></a>Tablet storage</h2><h3 id="RowSets"><a href="#RowSets" class="headerlink" title="RowSets"></a>RowSets</h3><p>Tablet 的下层结构是 RowSets。分为 DiskRowSets 和 MemRowSets。RowSets 的 range 可能重复，但如果一个 row 存在，那么一定只在一个 RowSets 中。<br>一个 Tablet 只有一个 MemRowSet。这一部分包括 flush 无需赘述。</p><h4 id="MemRowSets"><a href="#MemRowSets" class="headerlink" title="MemRowSets"></a>MemRowSets</h4><p>MemRowSets 是一个类似 Mass tree 的 B 树。但有一些优化：</p><ol><li>不支持从树上删除元素。Kudu 也是通过 MVCC 来逻辑删除。</li><li>同样也不支持任意地 inplace 地修改树上的 record<br> 作为代替，允许不改变值大小的修改，这样方便进行 CAS 操作。<br> 允许 CAS 的目的是方便构建下面提到的链表。</li><li>We link together leaf nodes with a next pointer, as in the B+-tree. This improves our sequential scan performance, a critical operation.<br> 链表一般被用来链接 B+ 树的叶子节点，从而提高扫表效率。</li><li>并不完全实现 trie of trees，而是只使用一棵树。因为并不需要考虑极端的随机访问。</li></ol><p>为了提高扫描性能，使用更大的 internal 和 leaf 节点大小，到 256 bytes 大小。</p><p>MemRowSets 是行存，因为内存结构，所以性能也是可以接受的。为了在行存下依然能够提高 throughput，Kudu 使用 SSE2 memory prefetch 指令，去 prefetch one leaf node ahead of our scanner。他还会 JIT-compile record projection operations。这些做法对性能提升很高。</p><p>最终插入到 B-tree 里面的 key 会根据每行的 PK，使用 order-preserving encoding 编码，从而只需要 memcmp 就可以实现比较。因此，在树上遍历会更加快。因为 MemRowSet 本来也是 sorted 的，所以也能提供有效率的扫描。</p><h4 id="DiskRowSet"><a href="#DiskRowSet" class="headerlink" title="DiskRowSet"></a>DiskRowSet</h4><p>DiskRowSet 被分成若干个 32MB 大小的文件，目的是确保它不会太大，从而支持后面要将的 Incremental compaction。</p><p>一个 DiskRowSet 被分成两部分，base data 和 delta store：</p><h5 id="base-data"><a href="#base-data" class="headerlink" title="base data"></a>base data</h5><p>base data 是列存。<br>每个 Column 被单独存储。它们按照连续的 block 的方式被写入磁盘。一个 Column 本身被分成很多个小 page 来存储，从而保障随机读。有一个 B 树索引用来根据 row 的 offset 来查找它所在的 page。<br>Column page 的编码支持字典，bitshuffle 等格式。可以指定进一步的压缩方法。</p><p>除了 flush 指定的那些 Column 之外，还会写一个 PK 索引列，用来存储每个 PK 的编码后的 PK（应该就是前面说的 order-preserving encoding）。<br>还会存储 Bloom filter。</p><h5 id="delta-store"><a href="#delta-store" class="headerlink" title="delta store"></a>delta store</h5><p>因为列存在 encode 之后就难以 inplace 更新了，所以更新和删除通过 delta store 来记录。</p><p>delta store 可以是 DeltaMemStores 或者 DeltaFile：</p><ol><li>DeltaMemStore 是一个和上面一样的 B 树。</li><li>DeltaFile 是一个二进制编码的 column block。</li></ol><p>delta store维护了 (row offset, timestamp) tuple 到 RowChangeList 的映射。其中 row offset 就是一个 row 在 row set 中的 index。timestamp 就是 MVCC 时间戳。RowChangeList 表示对一个 row 的变更，是一个二进制编码的 list。<br>在处理 update 时，首先查找 PK 列，然后可以通过它的 B 树索引来获得对应行所处的 page。然后通过查找这个 page 可以获得对应的 row 在整个 DiskRowSet 中的 offset。然后就可以根据这个索引插入一条更新的数据了。</p><p>因为 Delta Store 是以 row-offset 作为主键，所以相比于 Primary key 这个过程会更快。这就是为什么插入时要费那么多功夫去获取 row-offset，可以理解为 Kudu 在 Insert/Read 的性能平衡中更倾向于优化 Read 性能。</p><h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><h3 id="Delta-Compaction"><a href="#Delta-Compaction" class="headerlink" title="Delta Compaction"></a>Delta Compaction</h3><p>因为 delta 并不是列存，所以当有很多 delta 被 apply 到 base data 的时候，scan tablet 的速度就会变慢。因此 Kudu 的 background maintenance manager 会定期扫描，寻找有大量 delta 的 DiskRowSets，然后调度一个 delta compaction operation，将这些 delta 数据 merge 到 base data 列中。</p><p>In particular, the delta compaction operation identifies the common case where the majority of deltas only apply to a subset of columns: for example, it is common for a SQL batch operation to update just one column out of a wide table. In this case, the delta compaction will only rewrite that single column, avoiding IO on the other unmodified columns.</p><h3 id="RowSet-Compaction"><a href="#RowSet-Compaction" class="headerlink" title="RowSet Compaction"></a>RowSet Compaction</h3><p>Kudu 也会定期将不同的 DiskRowSets 压缩到一起，这称为 RowSet compaction。这个过程会执行一个 keybased merge of two or more DiskRowSets，产生一个有序的 row 的流。然后就不听 next 这个流，从而写回到 DiskRowSet 里面。这里写回的 DiskRowSet 同样是 32MB 的大小。</p><p>RowSet compaction has two goals:</p><ol><li>We take this opportunity to remove deleted rows.</li><li>This process reduces the number of DiskRowSets that overlap in key range. By reducing the amount by which RowSets overlap, we reduce the number of RowSets which are expected to contain a randomly selected key in the tablet. This value acts as an upper bound for the number of Bloom filter lookups, and thus disk seeks, expected to service a write operation within the table.</li></ol><h3 id="Scheduling-maintainance"><a href="#Scheduling-maintainance" class="headerlink" title="Scheduling maintainance"></a>Scheduling maintainance</h3><ol><li>如果 insert 负担变重，则调度偏向于处理“flush”，也就是将 MemRowSets 写成 DiskRowSets。</li><li>如果 insert 负担减轻，则偏向于处理 rowset compaction 或者 delta compaction。</li><li>Because the maintenance threads are always running small units of work, the operations can react quickly to changes in workload behavior. For example, when insertion workload increases, the scheduler quickly reacts and flushes in-memory stores to disk. When the insertion workload reduces, the server performs compactions in the background to increase performance for future writes. This provides smooth transitions in performance, making it easier for developers and operators to perform capacity planning and estimate the latency profile of their workloads.</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/137243163" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/137243163</a></li></ol><h1 id="Masstree"><a href="#Masstree" class="headerlink" title="Masstree"></a>Masstree</h1><h2 id="Intros"><a href="#Intros" class="headerlink" title="Intros"></a>Intros</h2><p>这里首先强调了，尽管可以 scale out，但是单机的性能依然很重要。然后 This paper presents Masstree, a storage system specialized for key-value data in which all data fits in memory, but must persist across server restarts. Within these constraints, Masstree aims to provide a flexible storage model.<br>它的 key 的长度是任意的，支持 range 查询。很多 key 可以共享前缀，从而提高性能。对于比较大的 value 也有优化。它使用了一些 OLFIT 和 rcu 的办法来处理并发：</p><ol><li>查询不使用锁或者 interlock 指令，所以它不会 invalidate shared cache line，并且和大多数 insert 和 update 是平行的。</li><li>update 只会锁相关的 tree node，树的其他部分不受影响。</li></ol><p>Masstree 中所有的 core 都使用一棵树，从而避免 load imbalances that can occur in partitioned designs。相比于其他的将一棵树分开存储的设计，能够彻底解决 imbalance 的问题。<br>这棵树是 a trie-like concatenation of B+-trees。对 long common key prefixes 特别友好，遥遥领先。查询耗时主要由 total DRAM fetch time of successive nodes during tree descent 来决定。因此，Masstree 使用一个较大的 fanout 从而减少树的深度。同时 fetch 多个 nodes，从而 overlap fetch latencies。另外还会精心设计 cache line 以减少每个 node 需要的 data。</p><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p>几点挑战：</p><ol><li>Masstree must efficiently support many key distributions, including variable-length binary keys where many keys might have long common prefixes.</li><li>for high performance and scalability, Masstree must allow fine-grained concurrent access, and its get operations must never dirty shared cache lines by writing shared data structures. </li><li>Masstree’s layout must support prefetching and collocate important information on small numbers of cache lines.<br>其中 2 和 3 就是 Masstree 的 cache craftiness，即缓存友好性。</li></ol><p>Masstree 是一个 trie 树，trie 树的每个节点是一个 B+ 树。trie 树的 fanout 是 2^64，也就是 8 个 bytes。通过 trie 的目的是利用 long key 的 shared prefix。通过 B+ 树 是支持 short key，以及 fine-grained concurrency。B+ 树的 fanout 是中等的，所以能有效利用内存。</p><p><img src="/img/dbpaper/masstree/1.png"></p><p>每个 B+ 树都会有至少一个 border node 也就是图中的矩形节点，以及 0 个或多个 interior node 也就是图中的圆形节点。border node 中按照传统的 B+ 树的方式组织 leaf nodes 也就是图中的五角星节点。可以看到 B+ 树的 border node 用来连接到下一层的 trie node，也就是一棵新的 B+ 树上。<br>Masstree 用一种比较 lazy 的方式去生成更深的层：</p><ol><li>Keys shorter than 8h+8 bytes are stored at layer ≤ h.</li><li>Any keys stored in the same layer h tree have the same 8h-byte prefix.</li><li>When two keys share a prefix, they are stored at least as deep as the shared prefix.</li></ol><p>Masstree creates layers as needed (as is usual for tries). Key insertion prefers to use existing trees; new trees are created only when insertion would otherwise violate an invariant. 比如 “01234567AB” 会被存在 root layer 中，直到插入一个 “01234567XY” 之后会产生一个新的 layer。新的 layer 中会有一个 B+ 树，其中存放 AB 和 XY。</p><p>复杂度分析</p><ol><li>查询复杂度和 B 树相同。对于 B 树，需要检查 O(log n) 个 nodes，进行 O(log n) 次比较。假设 key 的长度是 O(l)，所以总的比较开销是 O(l logn)。Masstree 要在 O(l) 层中比较，每层比较的开销是 O(log n)，所以总的代价也是 O(l logn)。但如果有公共前缀那么 Masstree 的代价就是 O(l + log n) 了。</li><li>Masstree’s range queries have higher worst-case complexity than in a B+-tree, since they must traverse multiple layers of tree.</li></ol><h2 id="Layout"><a href="#Layout" class="headerlink" title="Layout"></a>Layout</h2><p>Figure 2 展示了节点的定义。这里面大量的 15 说明这里使用了 fanout 为 15 的 B+ 树。<code>node *child[16]</code> 中的 node 既可以是 border node，也可以是 interior node。<br>所有的 Border node 被链接，从而能够实现快速 remove 和 getrange 操作。keyslice 用 64 位 integer 数组表示字符串，相当于是 <code>64 * ceil(n / 8)</code> 代替 <code>8*n</code>，这能提高 13-19% 的效率。后面讲如何处理 ‘\0’。然后，A single tree can store at most 10 keys with the same slice, namely keys with lengths 0 through 8 plus either one key with length &gt; 8 or a link to a deeper trie layer. 这个也好理解，因为如果有第二个 key 的话，比如上面的 01234567XY，就必须分裂了。我们保证所有 slice 相同的 key 会存在同一个 border node 中。这个设计简化了 interior node，它不必包含 key 的长度。也简化了并发操作的复杂度，带来的一点代价就是在节点分裂时需要做一些检查。</p><p>下面讲如何维护 border node 上的 suffix，这些 suffix 最多有 15 个。这里的做法是自适应地 inline 存，或者放在单独的内存块上面。目的是节省内存。总而言之这一块讲得是比较模糊的。</p><p>Masstree prefetches all of a tree node’s cache lines in parallel before using the node, so the entire node can be used after a single DRAM latency. Up to a point, this allows larger tree nodes to be fetched in the same amount of time as smaller ones; larger nodes have wider fanout and thus reduce tree height.</p><h3 id="Nonconcurrent-modification"><a href="#Nonconcurrent-modification" class="headerlink" title="Nonconcurrent modification"></a>Nonconcurrent modification</h3><h3 id="Concurrency-overview"><a href="#Concurrency-overview" class="headerlink" title="Concurrency overview"></a>Concurrency overview</h3><p>主要包含细粒度的锁，以及 optimistic concurrency control。<br>细粒度的锁指的是 update 操作只需要 local lock。OCC 指的是读操作并不需要锁，也不会写全局的共享内存。这里应该指的是引用计数之类的东西，会导致 reader 竞争 read lock。<br>因为 reader 并不会 block 并发的 write 操作。所以可能会读到中间数据。因此，writer 在写之前会将一个 dirty 位标记。在写完之后，再自增 version。Reader 会在读取这节点前记录 version，并在读取后再次比较 version 和 dirty 位。<br>这里，根据更新的种类是 insert 还是 split，会更新 version 中的不同区域。version 的 layout 如下所示。</p><p><img src="/img/dbpaper/masstree/3.png"></p><p>The biggest challenge in preserving correctness is concurrent splits and removes, which can shift responsibility for a key away from a subtree even as a reader traverses that subtree.</p><h2 id="Writer–writer-coordination"><a href="#Writer–writer-coordination" class="headerlink" title="Writer–writer coordination"></a>Writer–writer coordination</h2><p>通过自旋锁来维护，这个锁在 version 里面的 locked 位上。<br>但是节点上的一些字段是被其他节点的锁来保护的，比如：</p><ol><li>parent 指针收到父节点的锁保护</li><li>border node 的 prev指针受到左边 sibling 的保护<br>这能减少 split 操作的时候需要 acquire 的锁的数量。比如当某个中间节点 split 的时候它不需要子节点的锁，就可以替他们修改 parent 指针了。<br>但尽管如此，当节点 n 分裂的时候，还是需要：</li><li>n 自己的锁<br> a.目的是避免被并发修改。</li><li>n 的新的 sibling 的锁<br> a. 从后面来看，这里指的就是获取新分裂出来的 n’ 的锁。n’ 的 prev 是 n。<br> b. 要不要获取分裂前的 prev 的锁，防止 prev 同时分裂？</li><li>n 的 parent 的锁<br> a. 防止父节点被其他线程分裂，从而让新分出来的节点 attach 错了 parent。<br> b. 从后文来看，更重要的原因是便于因为 parent 可能也满了，所以需要同时分裂 parent。</li></ol><h3 id="Writer–reader-coordination"><a href="#Writer–reader-coordination" class="headerlink" title="Writer–reader coordination"></a>Writer–reader coordination</h3><p>基本上就是对之前的 OCC 的一些展开的论述。<br>这里说了，universal 的 before-and-after version 检查能够让 reader 发现任何并发的 split，但也会影响性能。有一些性能优化措施，比如让某些操作比如 update，实际上可以避免更新 version。</p><h4 id="Update"><a href="#Update" class="headerlink" title="Update"></a>Update</h4><p>主要将通过对齐 version 的 alignment，让对它的写是原子的。<br>所以 update 操作不需要更新 version。</p><p>Update 操作时，writer 不能直接把旧的值删除掉，因为此时可能还有 reader 在读。这个是通过 RCU 来解决的。其实这里类似的方法还有 hazard pointer 等。</p><h4 id="Border-inserts"><a href="#Border-inserts" class="headerlink" title="Border inserts"></a>Border inserts</h4><p>阅读本章前，可以回顾下 Figure2 的 <code>keyslice</code> 实现。<br>Border nodes 结构中的 permulation 字段是一个 <code>uint64_t</code>，其最低的 4 个 bit 组成 <code>uint4_t</code> 用来表示 key 的数量。因为 B+ 树的 fanout 是 15，所以正好。高 60 个 bit 组成了 <code>uint4_t[15]</code>，用来索引每一个 key 的实际位置。<br>在插入时，会加载 permutation，并且重新组织 permutation 字段，匀出一个没有使用的 slot，存储正确的插入位置。<br>这个操作大部分时候需要一个 compiler fence，在一些机器上需要在写 kv 和写 permutation 中间加一个 memory fence。</p><h4 id="New-layers"><a href="#New-layers" class="headerlink" title="New layers"></a>New layers</h4><p>在阅读本章前，可以先看下 Figure2 的 <code>link_or_value</code> 的实现。<br>插入 k1 到某个 border node，如果发现其中还有个冲突的 k2（这里冲突的含义看前面），那么就创建一个新的 border node 即 <code>n&#39;</code>。将 k2 插入 <code>n&#39;</code> 上的合适的 keyrange 上，并且将 k2 在 n 中的 value 替换成一个 pointer，这个 pointer 指向 next_layer 这一棵新的 B+ 树。然后，它可以解锁 n，并且继续插入 k1。此时 k1 会插入到新层的 <code>n&#39;</code> 上。</p><p>这里的过程只涉及到一个 key，也就是 k1，所以并不需要更新 n 的 version 或者 permutation。我们回顾上文，会比较明白为什么之前这么设计了。</p><p>这个场景下需要注意的点是，reader 需要区分 value 和 pointer。因为 pointer 和 layermarker 是分别存放的。首先 writer 要把 key 标记为 UNSTABLE 状态，然后 reader 检查到这个标记的时候就会 retry。然后 writer 会写入 layer pointer 指针，最后把 key 标记为 LAYER。<br>这里的 UNSTABLE 或者 LAYER 啥的，根据上文，是由 keylen 这个字段来区分的。</p><h4 id="Splits"><a href="#Splits" class="headerlink" title="Splits"></a>Splits</h4><p>Split 相比非 Split 操作，需要将一些 key 移动到另一个 node 中。所以 get 操作很容易就会丢掉这些被转移了的 key。所以，writer 需要去更新 version 里面的 split 字段。</p><p>Split 操作用了 hand-over-hand locking。这个实际上就是同时持有 cur 和 next 的 lock。在 Masstree 里面就是较低层的节点被 lock，并且被 mark 为 splitting。然后依次再更高层上在做同样的工作。这里认为 root 是最高的层。<br>不妨考虑下面的场景，B 需要分裂出一个 B’ 新节点。其中虚线箭头表示要被迁移到 B’ 上的 pointer。</p><p><img src="/img/dbpaper/masstree/split.png"></p><p>行为如下：</p><ol><li>B 和 B’ 都被标注为 splitting</li><li>包含 X 在内的孩子们被转移到 B’ 上</li><li>锁 A，并且标记为 inserting</li><li>将 B’ 插入到 A</li><li>将 A、B 和 B’ 都解锁，这里指掉那些 flag 状态。增加 A 的 vinsert，以及 B 和 B’ 的 vsplit</li></ol><p>下面需要假设一个并发的 findborder(X) 操作，它尝试从 node A 开始寻找某个 key 所在的 border 节点。下面要证明这个操作要么会找到 X，要么就会重试。<br>首先，假设找到了 B’，那么它就可以找到已经被移动到 B’ 的 X，但这个时候 B’ 还没有被链接到 A 上，也就是说 B’ 还没有被 publish。<br>反过来，假设找到了 B。并且因为在 handle-over-hand validation 中，先加载 child 的 version，再double check parent 的 verison，所以我们在将 A 设置为 inserting 之前就已经记录下 B 的 version 了。我们还可以推断 B 的 version 是在 step1 之前被记录的，这是因为如果发现 B 在 splitting 状态，那么就会重试。这样的话就有两个可能：<br>1.如果在 step1 前，findborder 就完成了，那么就肯定能读到 X。<br>2.否则，B.version ⊕ v 这个操作就会失败，因为看到了 B的 splitting 状态。这个 splitting 状态需要到 step5 才会被清理，但这个时候 vsplit 又会变了。这里还需要注意，vsplit 和 splitting 都是在 verison 上的，所以这个更新无疑是原子的。</p><p><img src="/img/dbpaper/masstree/6.png"></p><p>reader 处理 split 和 insert 的方式是不同的。insert 会在当前节点 retry，而 split 需要从 root 开始retry。<br>这里，因为 B 树的 fanout 是比较大的，并且这一块代码没什么锁，跑起来应该挺快，这也意味着并发的 split 实际上并不常见。在测试中，每 10^6 个请求中才有一个因为并发 split 从而需要从 root 开始 retry。相比之下，并发 insert 就会频繁很多，而它们也很容易在本地被处理，这也是为什么 masstree 将两个分开存储的原因。</p><h4 id="get"><a href="#get" class="headerlink" title="get"></a>get</h4><p><img src="/img/dbpaper/masstree/7.png"></p><p>Border node 因为彼此之间有 link，所以可以借助于 link 来处理 split。这里的规则是总是把右边部分分出去创建新 node。<br>Masstree 还有下面的规定：<br>1.B+ 树中的第一个 node 是 border node。他不会删除，除非整棵树都被删掉了。它始终是整棵树中最小的节点。<br>2.每个 border node 管理区间 [lowkey(n), highkey(n))。Split 或者 delete 操作可能修改右区间，但是不会修改左区间。<br>所以，get操作可以始终通过和下一个 border node 的 lowkey 比较来找到自己要找的 node。</p><h4 id="Remove"><a href="#Remove" class="headerlink" title="Remove"></a>Remove</h4><p>首先回忆之前的 border insert，在里面并没有更新 vinsert。在这里的场景中我们会介绍和 remove 操作组合起来的时候，因为 remove 也不修改 version 所以可能出现错误。我理解这有点像像是 ABA 问题。<br>考虑下面的场景，get 操作和 remove 操作重叠了，所以 remove 操作不能 gc 掉 k1 和 v1，不然就影响了 reader。这里应该是对应了前面的 RCU？<br>相应的，remove 操作是修改 permutation。但如果后续有一个 put操作，刚好把 key 也放到了 i 上。这就会导致 get 返回 v2 了。所以当已经删除了的 slot 被重用的时候，也要更新 vinsert。</p><p><img src="/img/dbpaper/masstree/remove.png"></p><h1 id="Ceph"><a href="#Ceph" class="headerlink" title="Ceph"></a>Ceph</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>目前有一些依赖对象存储的设计，其中对象存储设备，即 object storage device 也被称作 OSD，元数据服务器即 metadata server，也被称作 MDS。现在并不是读 block 了，而是读更大的 named objects，并且这些 object 的大小也未必要相同。底层的 block 分配由设备处理。Clients typically interact with a metadata server (MDS) to perform metadata operations (open, rename), while communicating directly with OSDs to perform file I/O (reads and writes), significantly improving overall scalability.<br>这样的架构依然不能解决 MDS 本身的扩展性，元数据没有做 partition。在设计上依旧依赖 allocation lists 和 inode tables，并且不愿意下推一些决策给 OSD。<br>Ceph 的设计基于的假设是 PB 级的存储实际上是动态的：</p><ol><li>大的系统是基于增量构建出来的</li><li>节点 failure 是通常情况</li><li>workload 的强度和特征总是在变化</li></ol><p>Ceph 将 file allocation tables 替换称为 generating function，从而解耦数据和元数据，这个函数也就是后面的 <strong>CRUSH 函数</strong>。这样 Ceph 就能同时考虑 OSD 了，具体优化的场景包括：</p><ol><li>data access 的 distribution</li><li>update serialization，这里指的应该是维护各个 update 操作之间的关系</li><li>failure detection</li><li>recovery<br>Ceph 用了一个分布式元数据集群来提高元数据访问的 scalability。</li></ol><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Ceph 对 scalability 的要求包括几个方面：</p><ol><li>整个系统的 capacity 和 throughput</li><li>每个 client 的性能</li><li>每个目录和文件的性能<br> 这里包括大量并发读写同一个文件，或者读写同一个目录。</li></ol><p><img src="/img/dbpaper/ceph/1.png"></p><h3 id="Decoupled-Data-and-Metadata"><a href="#Decoupled-Data-and-Metadata" class="headerlink" title="Decoupled Data and Metadata"></a>Decoupled Data and Metadata</h3><p>元数据相关的工作包括 open、rename 等。<br>对象存储一直以来都是将底层 block 的分配权给各个设备处理的，并且它们也已经将 per-file block list 替换为更短的 object list。但是 Ceph 直接去掉了 allocation list。为了替代，文件中的数据被分成一系列固定命名规则(predictably named)的对象，并且通过一个 CRUSH 函数被映射到具体的设备中。这有个显然的好处，就是组成一个文件的所有对象的名字和位置可以被计算得到，而不需要从某个中心化的地方查询了。</p><h3 id="Dynamic-Distributed-Metadata-Management"><a href="#Dynamic-Distributed-Metadata-Management" class="headerlink" title="Dynamic Distributed Metadata Management"></a>Dynamic Distributed Metadata Management</h3><p>Ceph utilizes a novel metadata cluster architecture based on Dynamic Subtree Partitioning.<br>这个算法可以将维护目录树的任务分发给很多个 MDS 来处理。我理解就是一种 partition 策略帮助减轻单个 MDS 节点的负担。</p><h3 id="Reliable-Autonomic-Distributed-Object-Storage"><a href="#Reliable-Autonomic-Distributed-Object-Storage" class="headerlink" title="Reliable Autonomic Distributed Object Storage"></a>Reliable Autonomic Distributed Object Storage</h3><p>OSD来处理数据迁移、replication、failure detection 和 failure recovery。对于 MSD 来说，它们好像就是一个单节点的存储。</p><h2 id="Client-Operation"><a href="#Client-Operation" class="headerlink" title="Client Operation"></a>Client Operation</h2><h3 id="File-IO-and-capabilities"><a href="#File-IO-and-capabilities" class="headerlink" title="File IO and capabilities"></a>File IO and capabilities</h3><p>当进程需要打开文件时，client 会发送一个请求给 MDS 服务器，后者遍历自己的目录层级，然后将文件名翻译成 inode。如果一切顺利， MDS 会返回诸如 inode 等信息。并且还会包含 striping strategy，这里指的是文件是条带化存储的，一个文件可以对应到若干 object 上。<br>客户端的 capability 分为 read、cache read、write 和 buffer write。后续也会支持管控。<br>Ceph 的 striping strategy 中为了避免 file allocation metadata，object name 只包含 inode number 和 stripe number。然后就借助于 CRUSH 去将它们映射到 OSD 上。比如说，只要一个 client 知道 inode number、layout 和 file size，它就可以定位到文件对应的所有对象。</p><h3 id="Client-Synchronization"><a href="#Client-Synchronization" class="headerlink" title="Client Synchronization"></a>Client Synchronization</h3><p>POSIX semantics sensibly require that reads reflect any data previously written, and that writes are atomic. 这里我理解就是强一致性。<br>如果有读写或者写写冲突，那么 MDS 就会撤回之前发出的 read caching 和 write buffereing 的 capacity，强制同步 IO。也就是说，所有应用的读和写都会被 block，直到被 OSD 确认。这样 update serialization 和 synchronization 的负担被转移给了 OSD。<br>当写请求跨越 object 的边界的时候，会向所有对象对应的 OSD 请求各自的锁，然后提交 write 并释放锁。Object locks are similarly used to mask latency for large writes by acquiring locks and flushing data asynchronously.</p><p>当然，同步 IO 对特别是小读写请求的影响比较大，因为每次都会请求一次 OSD。在一些情况下，可以选择更松的一致性要求。当然，性能和一致性是一组 tradeoff。<br>Ceph 支持一些 POSIX IO 的 HPC 接口，比如 O_LAZY flag，也就是放松了 coherency 要求。但是，HPC 程序自己会去控制一致性。这是因为一些应用可能只是让不同的线程写同一个文件的不同部分，这样就和一致性不冲突。<br>还有两个高级功能，lazyio_propagate 能够 flush 一个 range 到 object store 上。lazyio_ synchronize will ensure that the effects of previous propagations are reflected in any subsequent reads.</p><h3 id="Namespace-Operations"><a href="#Namespace-Operations" class="headerlink" title="Namespace Operations"></a>Namespace Operations</h3><p>Namespace Operations 诸如 readdir、unlink、chmod 之类的由 MDS 处理。<br>For simplicity, no metadata locks or leases are issued to clients. For HPC workloads in particular, callbacks offer minimal upside at a high potential cost in complexity.</p><p>Ceph 会对一些最常见的 metadata 访问场景进行优化，比如 readir 后面接一系列 stat 这个场景是 performance killer，Ceph 会选择在 readdir 的时候就直接取回来缓存。因为中间某个文件的属性可能变更了，访问缓存可能会牺牲一点 coherence，但性能提升很大。<br>对此的另一个优化手段是在 stat 被触发时，MDS 撤回所有的 write capacity，让所有的写暂停。然后获取所有的 writer 上的最新文件大小和 mtime，选择其中的最大的值返回。<br>当然，如果只有一个 writer，那么就可以直接从 writing client 取到正确的值，从而就不需要上面的过程了。<br>Applications for which coherent behavior is unnecesssary-victims of a POSIX interface that doesn’t align with their needs-can use <code>statlite</code>, which takes a bit mask specifying which inode fields are not required to be coherent. 这里不太看得懂。</p><h2 id="Dynamically-Distributed-Metadata"><a href="#Dynamically-Distributed-Metadata" class="headerlink" title="Dynamically Distributed Metadata"></a>Dynamically Distributed Metadata</h2><p>Metadata operation 通常占据了近乎一半的文件系统开销，并且处在 critical path 上。Metadata management also presents a critical scaling challenge in distributed file systems: although capacity and aggregate I/O rates can scale almost arbitrarily with the addition of more storage devices, metadata operations involve a greater degree of interdependence that makes scalable consistency and coherence management more difficult.</p><p>Ceph 的上的 metadata 很小，基本只包含 file name 和 inode。对象名通过 inode 构建出来，并且通过 CRUSH 来分布到不同的 OSD 上。这简化了 metadata workload，并且让 Ceph 管理能力和文件的大小无关。<br>此外，Ceph 还要减少和 metadata 相关的 IO 次数。它使用了一个 two-tiered storage strategy，并且通过 Dynamic Subtree Partitioning 最大化 locality，并且提高 cache efficiency。</p><h3 id="Metatada-storage"><a href="#Metatada-storage" class="headerlink" title="Metatada storage"></a>Metatada storage</h3><p>MDS 使用 journal 来持久化。每个 journal 有几百兆，可以 absorb repetitive metadata updates。journer 被 lazy 和流式地地写入 OSD 集群。<br>这个设计有几点好处，但说得有点模糊。<br>This strategy provides the best of both worlds: streaming updates to disk in an efficient (sequential) fashion, and a vastly reduced re-write workload, allowing the long-term on-disk storage layout to be optimized for future read access. In particular, inodes are embedded directly within directories, allowing the MDS to prefetch entire directories with a single OSD read request and exploit the high degree of directory locality present in most workloads [22]. Each directory’s content is written to the OSD cluster using the same striping and distribution strategy as metadata journals and file data. Inode numbers are allocated in ranges to metadata servers and considered immutable in our prototype, although in the future they could be trivially reclaimed on file deletion. An auxiliary anchor table [28] keeps the rare inode with multiple hard links globally addressable by inode number-all without encumbering the overwhelmingly common case of singly-linked files with an enormous, sparsely populated and cumbersome inode table.</p><h3 id="Dynamic-Subtree-Partitioning"><a href="#Dynamic-Subtree-Partitioning" class="headerlink" title="Dynamic Subtree Partitioning"></a>Dynamic Subtree Partitioning</h3><p>SOTA 的方案包括静态子树切割，或者动态地基于 hash 来做。哈希的方案会破坏元数据的 locality，也会破坏 prefetch 的可能性。<br>Ceph 的 Dynamic Subtree Partitioning 首先是引入了 hierachy。然后通过 counters with an exponential time decay 维护元数据的 popularity。这个 popularity 会向上往树根处传播，从而 MDS 可以得到一棵反映负载分布的权重树。MDS 可以通过迁移子树的方式来实现负载均衡。这个负载均衡可以只在内存中进行，从而减少对 coherence lock 或者 client capability 的影响。The resulting subtree-based partition is kept coarse to minimize prefix replication overhead and to preserve locality. 不太明白这里说的 prefix replication 是什么。</p><p>在 replication 的时候，inode 的内容被分为三块：security、file 和 immutable。security、file 两个组会被使用单独的 FSM 管理。其目的是减少 lock contention。这里也不太明白说的是什么。</p><h3 id="Traffic-control"><a href="#Traffic-control" class="headerlink" title="Traffic control"></a>Traffic control</h3><p>尽管做了 partition，但是还是会存在 hotspot 或者 flash crowds(瞬时拥堵)的问题，比如很多个客户端同时访问同一个文件或者目录。Ceph 会根据 popularity 来决定是否将 hotspot 进行分散，同时也会想办法避免损失 locality：<br>1.读取压力比较大的目录会设有多个 replica 来分散负载。如果一个目录不 popular，那么他就不会被创建其他的 replica。<br>2.写入压力比较大的目录中的文件会被 hash 到不同的节点上。这会牺牲目录的 locality，但负载是均衡的。写入会直接被 direct 到 authority 节点上。</p><h2 id="Distributed-Object-Storage"><a href="#Distributed-Object-Storage" class="headerlink" title="Distributed Object Storage"></a>Distributed Object Storage</h2><p>让 OSD 处理注入 replicate 之类的工作，让 Ceph 的 RADOS 取得在容量和聚合能力上的线性伸缩。</p><h3 id="CRUSH"><a href="#CRUSH" class="headerlink" title="CRUSH"></a>CRUSH</h3><p>首先Ceph 会把对象映射到不同的 PG 里面。这是通过一个简单的哈希函数实现的。<br>然后通过 CRUSH 也就是 Controlled Replication Under Scalable Hashing 函数将 PG 映射到 OSD。</p><p><img src="/img/dbpaper/ceph/3.png"></p><p>那么定位一个对象就只需要知道 PG 和一个 OSD cluster map。因为这个 map 不会很频繁变化，或者变化也是只其中一小部分，比如上下线节点，所以会元数据也不会被动来动去。<br>OSD cluster map 是分层的描述，比如可以分为 shelf、rack cabinet、row of cabinet。<br>CRUSH 会根据 placement rule 将 PG 映射到 OSD。<br>OSD cluster map 还包含 down 或者 inactive 机器的列表，以及一个 version 号。所有对 OSD 的请求都会带上 version 号。</p><h3 id="Replication-1"><a href="#Replication-1" class="headerlink" title="Replication"></a>Replication</h3><p>Replication 的粒度是 PG。<br>Primary 会确保所有的 replica 都被写完之后，再回复 client。</p><h3 id="Data-safety"><a href="#Data-safety" class="headerlink" title="Data safety"></a>Data safety</h3><p>RADOS 解耦了 sync 和 safety。他的意思是共享存储有两个作用，第一个是同步，也就是让一个更新尽快对其他 client 可见。第二个是可靠性，也就是持久化。<br>所以，当所有的 OSD 写完 in-memory buffer cache 之后，primary OSD 就会给 client 回复一个 ack，表示 sync 结束了。<br>之后，当数据被落盘之后，primary OSD 还会再回复一个 commit 给客户端，表示数据 safe 了。</p><h3 id="故障检测"><a href="#故障检测" class="headerlink" title="故障检测"></a>故障检测</h3><p>主要是分为两个阶段。短暂的无响应会被标记为 down，此时会移交 primary。长期的无响应会被标记为 out，会派其他的 OSD 来接管。这么做的目的也是为了减少数据的搬运。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在比较早的时候，我使用腾讯文档记录一些数据库的论文。但我越来越无法忍受腾讯文档的 bug 等不便利。因此我打算将这些文章转移到博客中，即使它们中的部分的完成度并不是很高。&lt;/p&gt;
&lt;p&gt;这篇文章中，包含 CStore、Kudu、Masstree 和 Ceph。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>通用架构设计归纳</title>
    <link href="http://www.calvinneo.com/2024/02/24/common-arch-design/"/>
    <id>http://www.calvinneo.com/2024/02/24/common-arch-design/</id>
    <published>2024-02-24T04:34:22.000Z</published>
    <updated>2024-12-17T14:50:31.822Z</updated>
    
    <content type="html"><![CDATA[<p>介绍软件工程领域一些通用的设计方案。</p><a id="more"></a><h1 id="Lease"><a href="#Lease" class="headerlink" title="Lease"></a>Lease</h1><p>通过 Lease 可以解决或者缓解下面的一些问题：</p><ol><li>减少 invalidation 检查的开销</li><li>减少惊群带来的大量无效计算<br> 例如在选举模型中，在 lease 期间，voter 就不会发起投票驱逐 leader，即使它们暂时联系不上 leader。</li></ol><h1 id="Backoff"><a href="#Backoff" class="headerlink" title="Backoff"></a>Backoff</h1><h1 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h1><h2 id="Cache-miss"><a href="#Cache-miss" class="headerlink" title="Cache miss"></a>Cache miss</h2><p>Cache miss 往往和随机读有关。</p><h2 id="Flyweight-Pattern"><a href="#Flyweight-Pattern" class="headerlink" title="Flyweight Pattern"></a>Flyweight Pattern</h2><h1 id="Amortize"><a href="#Amortize" class="headerlink" title="Amortize"></a>Amortize</h1><h1 id="Batching"><a href="#Batching" class="headerlink" title="Batching"></a>Batching</h1><h1 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h1><h1 id="Locality"><a href="#Locality" class="headerlink" title="Locality"></a>Locality</h1><h1 id="分层和打洞"><a href="#分层和打洞" class="headerlink" title="分层和打洞"></a>分层和打洞</h1><h1 id="Parallel"><a href="#Parallel" class="headerlink" title="Parallel"></a>Parallel</h1><p>这个策略包含了数据并行和模型并行。前者分割数据，每一个并行单元处理一部分数据；后者分割代码，每个并行单元处理一部分逻辑。</p><h2 id="SIMD"><a href="#SIMD" class="headerlink" title="SIMD"></a>SIMD</h2><h2 id="机器学习中的模型并行"><a href="#机器学习中的模型并行" class="headerlink" title="机器学习中的模型并行"></a>机器学习中的模型并行</h2><p>机器学习中的模型，其实也是一部分数据。例如神经网络中，它可能就是表示权值的矩阵。如果这个模型比较大，则它对应的矩阵可以被切分。<br>注意，这种情况下，子模型之间存在依赖关系，所以需要同步和通信。</p><h1 id="Provision"><a href="#Provision" class="headerlink" title="Provision"></a>Provision</h1><p>这个思路会尝试预测资源的使用，从而提前分配，以一个较小的预测失误的代价，获取预测成功的大幅性能提升。</p><h2 id="Prefetch"><a href="#Prefetch" class="headerlink" title="Prefetch"></a>Prefetch</h2><p>包含：</p><ol><li>prefetch 数据</li><li>prefetch 代码，也就是 branch prefiction</li></ol><h2 id="Warm-up"><a href="#Warm-up" class="headerlink" title="Warm-up"></a>Warm-up</h2><h1 id="Ordering"><a href="#Ordering" class="headerlink" title="Ordering"></a>Ordering</h1><h2 id="Partial-Ordering"><a href="#Partial-Ordering" class="headerlink" title="Partial Ordering"></a>Partial Ordering</h2><p>通常面临这样的场景，很多个命令构成了全序关系，但其实它们可以被拆成多组彼此 concurrent 的偏序关系：</p><ol><li>在 NewSQL 的事务层+共识层的架构中，将 <code>(start_ts, commit_ts)</code> 的事务拆到多个共识组中，多个共识组之间可以并发 apply。对于共识组中不相交的事务，可以通过并行 apply 继续提高并发度。</li><li>CPU 中的 superscalar 技术<br> 不相关的指令可以乱序执行。</li></ol><h2 id="Pipeline-1"><a href="#Pipeline-1" class="headerlink" title="Pipeline"></a>Pipeline</h2><p>Pipeline 可以作为一个 first-class 的优化类型了。但是我觉得它也是一个 Ordering 的优化。</p><h2 id="Parallel-1"><a href="#Parallel-1" class="headerlink" title="Parallel"></a>Parallel</h2><h1 id="重放"><a href="#重放" class="headerlink" title="重放"></a>重放</h1><h2 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h2><p>我们往往在异步线程中预处理一些对象，并最后将它们 link 到主干上，或者从主干上 unlink 对象，并最后 gc 掉。如果这中间发生重启，那么这些对象就会游离在存储中。如何区分被 unlink 但尚未被回收的对象，和刚被创建但还没有被 link 的对象呢？这里的通用思路是在重启后对比主干和存储中的对象，所有不出现在主干中的对象就需要被删掉。然后依赖重放来解决第一种情况。</p><h1 id="Trade-off"><a href="#Trade-off" class="headerlink" title="Trade off"></a>Trade off</h1><p>Trade off 的思路是权衡两个方案 A 或者 B，在它们各自的好处和坏处中取得一个妥协。</p><h2 id="质量和速度"><a href="#质量和速度" class="headerlink" title="质量和速度"></a>质量和速度</h2><ol><li>向量搜索中的 ANN</li><li>机器学习中的量化</li><li>图像处理中的有损压缩</li></ol><h2 id="熵和它的代价"><a href="#熵和它的代价" class="headerlink" title="熵和它的代价"></a>熵和它的代价</h2><ol><li>存储系统中，如果追求低熵，那么就会产生资源消耗。例如 LSM 中的写放大是提升系统的 Ordering。</li></ol><h2 id="读和写"><a href="#读和写" class="headerlink" title="读和写"></a>读和写</h2><p>读优化和写优化的 trade off 是非常常见的。</p><h2 id="锁和非锁"><a href="#锁和非锁" class="headerlink" title="锁和非锁"></a>锁和非锁</h2><p>锁意味着串行逻辑，通常用来避免写写冲突。<br>非锁的方案往往涉及多个版本：</p><ol><li>CAS 的方案本质上是异步完成新版本的构建，再原子替换上去。它并不是避免冲突，而是在冲突时退出。</li><li>MVCC 的方案本质上是让读不会阻塞写，解决读写冲突。</li></ol><p>类似的思想出现很多：</p><ol><li>TiDB 中使用乐观锁或者悲观锁处理写写冲突，通过 MVCC 处理读写冲突。</li><li>Masstree 中使用锁解决写写冲突，引入版本号解决读写冲突。</li><li>Snapshot Isolation 中，读不会被写影响。</li></ol><h2 id="存储和计算"><a href="#存储和计算" class="headerlink" title="存储和计算"></a>存储和计算</h2><p>例如，可以存一部分中间结果，从而减少重新计算的开销。包含：</p><ol><li>动态规划类算法</li></ol><h2 id="对特定访问模式的优化"><a href="#对特定访问模式的优化" class="headerlink" title="对特定访问模式的优化"></a>对特定访问模式的优化</h2><h2 id="Eager-vs-Lazy"><a href="#Eager-vs-Lazy" class="headerlink" title="Eager vs Lazy"></a>Eager vs Lazy</h2><h3 id="COW"><a href="#COW" class="headerlink" title="COW"></a>COW</h3><p>C++ 中 COW 字符串最初被用来优化内存使用，以及减少不必要的复制。它也被认为是读多写少场景下的一种优化策略。但是它后续被废弃了，原因是它在多线程中的表现不佳。</p><h1 id="转移代价"><a href="#转移代价" class="headerlink" title="转移代价"></a>转移代价</h1><p>相比于 trade off，另一种思路是将代价转移。此时，接纳方案 A 和 B 的大部分的好处，承担第三个方案/操作 C 的代价，使得 A + B + C 的开销小于单独的 A 或者 B。</p><h2 id="一些算法的例子"><a href="#一些算法的例子" class="headerlink" title="一些算法的例子"></a>一些算法的例子</h2><h3 id="LRU-cache"><a href="#LRU-cache" class="headerlink" title="LRU cache"></a>LRU cache</h3><p>它使用了双向链表来支持的插入和删除，以及排序；然后又引入了 hash table 来支持快速的查询。它的操作 C 是去维护两个数据结构。而维护链表和 hash 表的代价要比单独使用一个，然后接受另一个的代价要低很多。</p><h3 id="雪花算法"><a href="#雪花算法" class="headerlink" title="雪花算法"></a>雪花算法</h3><h2 id="分离读优化和写优化"><a href="#分离读优化和写优化" class="headerlink" title="分离读优化和写优化"></a>分离读优化和写优化</h2><h2 id="分离冷数据和热数据"><a href="#分离冷数据和热数据" class="headerlink" title="分离冷数据和热数据"></a>分离冷数据和热数据</h2><h2 id="Scale-out"><a href="#Scale-out" class="headerlink" title="Scale out"></a>Scale out</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍软件工程领域一些通用的设计方案。&lt;/p&gt;</summary>
    
    
    
    
    <category term="分布式" scheme="http://www.calvinneo.com/tags/分布式/"/>
    
    <category term="arch" scheme="http://www.calvinneo.com/tags/arch/"/>
    
  </entry>
  
</feed>
