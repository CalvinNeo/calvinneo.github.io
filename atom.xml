<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Calvin&#39;s Marbles</title>
  
  
  <link href="http://www.calvinneo.com/atom.xml" rel="self"/>
  
  <link href="http://www.calvinneo.com/"/>
  <updated>2025-02-16T14:09:52.549Z</updated>
  <id>http://www.calvinneo.com/</id>
  
  <author>
    <name>Calvin Neo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Excerpt from Yes Minister</title>
    <link href="http://www.calvinneo.com/2025/02/15/from-ym/"/>
    <id>http://www.calvinneo.com/2025/02/15/from-ym/</id>
    <published>2025-02-15T15:42:32.000Z</published>
    <updated>2025-02-16T14:09:52.549Z</updated>
    
    <content type="html"><![CDATA[<p>The novel of Yes Minister. Including metaphors, grammar issues and funny paragraphs.</p><a id="more"></a><h1 id="Editor’s-Note"><a href="#Editor’s-Note" class="headerlink" title="Editor’s Note"></a>Editor’s Note</h1><blockquote><p>Years of political training and experience had taught Hacker to use twenty words where one would do, to dictate millions of words where mere thousands would suffice, and to use language to blur and fudge issues and events so that they became incomprehensible to others. Incomprehensibility can be a haven for some politicians, for therein lies temporary safety.</p></blockquote><blockquote><p>But his natural gift for the misuse of language, though invaluable to an active politician, was not an asset to a would-be author.</p></blockquote><h1 id="OPEN-GOVERMENT"><a href="#OPEN-GOVERMENT" class="headerlink" title="OPEN GOVERMENT"></a>OPEN GOVERMENT</h1><p>电视剧中增加了一段误接 BBC 采访电话的剧情，我觉得挺棒的。</p><blockquote><p>‘Then why don’t you marry him?’ she asked. ‘I now pronounce you man and political adviser. Whom politics has joined let no wife put asunder.’</p></blockquote><h1 id="THE-OFFICIAL-VISIT"><a href="#THE-OFFICIAL-VISIT" class="headerlink" title="THE OFFICIAL VISIT"></a>THE OFFICIAL VISIT</h1><blockquote><p>‘Shall we scramble?’ he said.<br>‘Where to?’ I said, then felt rather foolosh as I realised what he was talking about. Then I relised it was another of Bernards’s draft suggestions: what’s the point of scrambling a phonw conversation about something that’s just been on the television news?</p></blockquote><p>scramble 既有匍匐前进、攀登的意思，也有干扰无线电，使得只有特殊的人才能够听到通话的意思。</p><blockquote><p>And if the new president is Marxist-backed, who better to win him over to our side than Her Majesty?</p></blockquote><p>如果新总统背后有马克思主义支持，还有谁比陛下更能说服他站到我们这边呢？</p><blockquote><p>there was one 747 that belonged to nine different African airlines in one month. They called it the mumbo-jumbo.</p></blockquote><h1 id="THE-ECONOMY-DRIVE"><a href="#THE-ECONOMY-DRIVE" class="headerlink" title="THE ECONOMY DRIVE"></a>THE ECONOMY DRIVE</h1><blockquote><p>I was forced to move on to the next two white elephants.</p></blockquote><p>我被迫继续处理接下来的那两个烫手山芋。</p><blockquote><p>‘Government buildings do not need fire fafety clearance’<br>‘Why?’<br>‘Perhaps,’ Humphrey offered, ‘because Her Majesty’s Civil Servants are not easily inflamed.’</p></blockquote><blockquote><p>Frank chimed in eagerly, ‘Yes, that would get rid of ninety civil servants at a stroke.’<br>‘Or indeed,’ said Sir Humphrey, ‘at a strike.’</p></blockquote><p>后面还有经典的 smile at 和 smile on。</p><h1 id="BIG-BROTHER"><a href="#BIG-BROTHER" class="headerlink" title="BIG BROTHER"></a>BIG BROTHER</h1><blockquote><p>The local party, the constituency, my family, all of them are proud of me for getting into the Cabinet – yet they are all resentful that I have less time to spend on them and are keen to remind me that I’m nothing special, just their local MP, and that I mustn’t get ‘too big for my boots’. They manage both to grovel and patronise me simultaneously. It’s hard to know how to handle it.</p></blockquote><blockquote><p>And he assumes, rightly, that the Minister has too much else to do. [The whole process is called Creative Inertia – Ed.]</p></blockquote><blockquote><p>He also warned me of the ‘Three Varieties of Civil Service Silence’, which would be  Humphrey’s last resort if completely cornered:<br>The silence when they do not want to tell you the facts: Discreet Silence.<br>The silence when they do not intend to take any action: Stubborn Silence.<br>The silence when you catch them out and they haven’t a leg to stand on. They imply that they could vindicate themselves completely if only they were free to tell all, but they are too honourable to do so: Courageous Silence.</p></blockquote><blockquote><p>I explained to her that the Opposition aren’t really the opposition. They’re just called the Opposition. But, in fact, they are the opposition in exile. The Civil Service are the opposition in residence.</p></blockquote><blockquote><p>In the second place, if there had been investigations, which there haven’t or not necessarily, or I am not at liberty to say if there have, there would have been a project team which, had it existed, on which I cannot comment, would now be disbanded if it had existed and the members returned to their original departments, had there indeed been any such members.</p></blockquote><p>经典虚拟语气。</p><blockquote><p>But they’ve convinced me that they can. Indeed my Permanant Secretary is staking his reputation on it. And, if not, heads will roll.</p></blockquote><p>Hacker 对媒体的了解，经典的媒体逼宫战术。在后面的交通总管一事中，也被 PM 用来赶鸭子上架。</p><h1 id="THE-WRITING-ON-THE-WALL"><a href="#THE-WRITING-ON-THE-WALL" class="headerlink" title="THE WRITING ON THE WALL"></a>THE WRITING ON THE WALL</h1><blockquote><p>Woe betide any Minister who lifts the phone to try to sort out a foreign trade deal, for instance.</p></blockquote><p>Woe betide 在一起表示 XXX 样就会倒霉。Betide 的意思是降临。</p><blockquote><p>‘With respect, Minister,’ countered Sir Humphrey (untruthfully), ‘how do you know it says the opposite if it is totally unintelligible?’</p></blockquote><p>这次是 Humphrey 而不是 Bernard 来挑逻辑问题。</p><blockquote><p>Hacker was beginning to understand Civil Service code language. Other examples are:<br>‘I think we have to be very careful.’ Translation: We are not going to do this.<br>‘Have you thought through all the implications?’ Translation: You are not going to do this.<br>‘It is a slightly puzzling decision.’ Translation: Idiotic!<br>‘Not entirely straightforward.’ Translation: Criminal.<br>‘With the greatest possible respect, Minister . . .’ Translation: Minister, that is the silliest idea I’ve ever heard</p></blockquote><p>这是 Editor 的总结，我觉得很有趣。</p><blockquote><p>If a purely hypothetical Minister were to be unhappy with a departmental draft of evidence to a committee, and if the hypothetical Minister were to be planning to replace it with his own hypothetical draft worked out with his own political advisers at his party HQ, and if this Minister was planning to bring in his own draft so close to the final date for evidence that there would be no time to redraft it, and if the hypothetical Private Secretary were to be aware of this hypothetical draft – in confidence – should the hypothetical Private Secretary pass on the information to the Perm. Sec. of the hypothetical Department?</p></blockquote><p>经典虚拟语气片段。</p><blockquote><p>‘We shall always support you as your standard-bearer, Minister but not as your pall-bearer.’</p></blockquote><blockquote><p>‘If you must do this damn silly thing,’ he said, ‘don’t do it in this damn silly way.’</p></blockquote><p>Humphrey 难得的两次很直的话。</p><blockquote><p>Bernard assured me that I didn’t really need to know much about the proposal because his information on the grapevine, through the Private Office network, was that the proposal would go through on the nod.</p></blockquote><p>为啥 grapevine 还有小道消息的意思？</p><blockquote><p>Donald Hughes, rubbing salt in the wound, apparently described it as ‘approbation, elevation and castration, all in one stroke’. It seems he suggested that I should take the title Lord Hacker of Kamikaze.</p></blockquote><blockquote><p>I told Humphrey I was appalled.<br>‘You’re appalled?’ he said. ‘I’m appalled.’<br>Bernard said he was appalled, too. And, there’s no doubt about it, the situation is appalling.</p></blockquote><blockquote><p>Industrial Harmony. That means strikes.</p></blockquote><p>这里 Editor 有个注解，挺有趣的。</p><blockquote><p>You’ll probably spend the rest of your career in the Vehicle Licensing Centre in Swansea.</p></blockquote><p>对 Swansea 很有敌意啊。</p><blockquote><p>Then Humphrey proposed that we work together on this. This was a novel suggestion, to say the least.</p></blockquote><blockquote><p>‘I’m awfully sorry to quibble again, Minister, but you can’t actually stop things before they start,’ intervened Bernard, the wet-hen-in-chief. He’s really useless in a crisis.</p></blockquote><blockquote><p>‘Same reason,’ came the reply. ‘It’s just like the United Nations. The more members it has, the more arguments you can stir up, and the more futile and impotent it becomes.’</p></blockquote><p>感觉很有洞见。</p><blockquote><p>Then I had an idea. I suddenly realised that Martin will be on my side. I can’t imagine why I didn’t think of it before. He’s Foreign Secretary – and, to my certain knowledge, Martin is genuinely pro Europe. (Humphrey calls him ‘naïf’). Also I ran his campaign against the PM, and he only stands to lose if I’m squeezed out.</p></blockquote><blockquote><p>I agreed, and remarked that this Europass thing is the worst disaster to befall the government since I was made a member of the Cabinet. [We don’t think that Hacker actually meant what he seems to be saying here Ed.]</p></blockquote><blockquote><p>It’s awarded to the statesman who has made the biggest contribution to European unity since Napoleon. [That’s if you don’t count Hitler – Ed.]</p></blockquote><p>这几段 Editor 的注解都很有趣。</p><blockquote><p>when you’ve got them by the balls, their hearts and minds will follow.</p></blockquote><h1 id="THE-RIGHT-TO-KNOW"><a href="#THE-RIGHT-TO-KNOW" class="headerlink" title="THE RIGHT TO KNOW"></a>THE RIGHT TO KNOW</h1><blockquote><p>Sir Humphrey replied that I need not look far – Private Secretaries who could not occupy their Ministers were a threatened species.</p></blockquote><blockquote><p>‘Almost anything can be attacked as a loss of amenity and almost anything can be defended as not a significant loss of amenity. One must appreciate the significance of significant.’</p></blockquote><blockquote><p>Humphrey suggested I look inside them. I did, and to my utter astonishment I saw that there were a handful of signatures in each book, about a hundred altogether at the most. A very cunning ploy – a press photo of a petition of six fat books is so much more impressive than a list of names on a sheet of Basildon Bond.</p></blockquote><blockquote><p>Those civil servants are always kowtowing to Daddy, but they never take any real notice of him.</p></blockquote><p>Kowtow 就是中文的磕头。</p><blockquote><p>She told me she’d been out with the trots. I was momentarily sympathetic and suggested she saw the doctor. Then I realised she meant the Trotskyites. I’d been slow on the uptake because I didn’t know she was a Trotskyite. Last time we talked she’d been a Maoist.</p></blockquote><blockquote><p>I noted that Lucy was giving out the press release at five p.m. Very professional. Misses the evening papers, which not too many people read, and therefore makes all the dailies. She’s learned something from being a politician’s daughter.</p></blockquote><h1 id="JOBS-FOR-THE-BOYS"><a href="#JOBS-FOR-THE-BOYS" class="headerlink" title="JOBS FOR THE BOYS"></a>JOBS FOR THE BOYS</h1><blockquote><p>you scratch my back, I’ll scratch yours.</p></blockquote><h1 id="THE-COMPASSIONATE-SOCIETY"><a href="#THE-COMPASSIONATE-SOCIETY" class="headerlink" title="THE COMPASSIONATE SOCIETY"></a>THE COMPASSIONATE SOCIETY</h1><p>比较好奇为什么 DAA 会为医院的铺张浪费负责？</p><blockquote><p>I informed Bernard that most of our journalists are so amateur that they would have grave difficulty in finding out that today is Thursday.<br>‘It’s actually Wednesday, Minister,’ he said.</p></blockquote><blockquote><p>Sir Humphrey preferred to write in margins where possible, but, if not possible, simulated margins made him feel perfectly comfortable.</p></blockquote><blockquote><p>We can infer from this note that Mr Bernard Woolley – as he then was – mentioned the matter of St Edward’s Hospital to Sir Humphrey, although when we challenged Sir Bernard – as he now is – on this point he had no recollection of doing so – Ed.</p></blockquote><h1 id="THE-DEATH-LIST"><a href="#THE-DEATH-LIST" class="headerlink" title="THE DEATH LIST"></a>THE DEATH LIST</h1><h1 id="DOING-THE-HONOURS"><a href="#DOING-THE-HONOURS" class="headerlink" title="DOING THE HONOURS"></a>DOING THE HONOURS</h1><p>比较好奇为什么 DAA 会管到教育的事情？</p><blockquote><p>Chat over the port and walnuts</p></blockquote><p>通常用来描述一种轻松的社交场合，人们在享用波特酒（port）和核桃（walnuts）时进行闲聊。</p><blockquote><p>He explained that home students were to be avoided at all costs! Anything but home students.</p></blockquote><blockquote><p>Sir William Guthrie, OM, FRS, FBA, Ph.D, MC, MA (Oxon)<br>Group Captain Christopher Venables, DSC, MA<br>Sir Humphrey Appleby, KCB, MVO, MA (Oxon)<br>Bernard Woolley, MA (Cantab)<br>The Rt Hon. James Hacker, PC, MP, BSc. (Econ)<br>Sir Arnold Robinson, GCMG, CVO, MA (Oxon)</p></blockquote><p>Cantab 指的是剑桥。</p><blockquote><p>In fact, the only time a civil servant is known to have refused a knighthood was in 1496. This was because he already had one.</p></blockquote><blockquote><p>Just as incomes policies have always been manipulated by those that control them: for instance, the 1975 Pay Policy provided exemptions for Civil Service increments and lawyers’ fees. Needless to say, the policy was drafted by civil servants and parliamentary draftsmen, i.e. lawyers.</p></blockquote><blockquote><p>Quis custodiet ipsos custodes?</p></blockquote><blockquote><p>And how did the civil servants get away with creating these remarkably favourable terms of service for themselves? Simply by keeping a low profile. They have somehow managed to make people feel that discussing the matter at all is in rather poor taste.</p></blockquote><p>很有趣的观察，“保持低调”，“讨论这些并不得体”。</p><blockquote><p>Cut no ice with me<br>俗语，表示 XX 对我没用。</p></blockquote><blockquote><p>The penny dropped<br>俗语，表示某人终于明白了某件事情或某人突然明白了之前不明白的事情。</p></blockquote><blockquote><p>‘There is no reason,’ he said, stabbing the air with his finger, ‘to change a system which has worked well in the past.’<br>‘But it hasn’t,’ I said.<br>‘We have to give the present system a fair trial,’ he stated. This seemed quite reasonable on the face of it. But I reminded him that the Most Noble Order of the Garter was founded in 1348 by King Edward III. ‘Surely it must be getting towards the end of its trial period?’ I said.<br>So Humphrey tried a new tack. He said that to block honours pending economies might create a dangerous precedent. What he means by ‘dangerous precedent’ is that if we do the right thing now, then we might be forced to do the right thing again next time. And on that reasoning nothing should ever be done at all.</p></blockquote><blockquote><p>‘As you know,’ he said, ‘the letters JB are the highest honour in the Commonwealth.’<br>I didn’t know.<br>Humphrey eagerly explained. ‘Jailed by the British. Gandhi, Nkrumah, Makarios, Ben-Gurion, Kenyatta, Nehru, Mugabe – the list of world leaders is endless and contains several of our students.’</p></blockquote><blockquote><p>although the Cabinet Secretary is theoretically primus inter pares he is in reality very much primus. It seems that all Permanent Secretaries are equal but some are more equal than others.</p></blockquote><blockquote><p>thin end of the wedge</p></blockquote><blockquote><p>Perhaps Appleby is not an absolutely first-rank candidate to succeed one as Cabinet Secretary. Not really able in every department. Might do better in a less arduous job, such as chairman of a clearing bank or as an EEC official.</p></blockquote><blockquote><p>‘Of course,’ said Bernard, ‘but it’s years and years since the Department of Transport had a Permanent Secretary from Cambridge.’<br>好像只有 Bernard 是剑桥的。</p></blockquote><h1 id="THE-GREASY-POLE"><a href="#THE-GREASY-POLE" class="headerlink" title="THE GREASY POLE"></a>THE GREASY POLE</h1><p>“The Greasy Pole” is an idiomatic expression used to describe the difficult and often slippery route to advancement in one’s career or profession. It is particularly used in contexts where success is hard to achieve and the path to the top is fraught with challenges and obstacles</p><blockquote><p>‘Simple, Minister,’ he explained. ‘It means “with” or “after”, or sometimes “beyond” – it’s from the Greek, you know.’<br>[Like all Permanent Secretaries, Sir Humphrey Appleby was a generalist. Most of them studied classics, history, PPE or modern languages. Of course you might expect the Permanent Secretary at the Department of Administrative Affairs to have a degree in business administration, but of course you would be wrong – Ed.]<br>Then he went on to explain that metadioxin means ‘with’ or ‘after’ dioxin, depending on whether it’s with the accusative or the genitive: with the accusative it’s ‘beyond’ or ‘after’, with the genitive it’s ‘with’ as in Latin, where the ablative is used for words needing a sense of with to precede them.<br>Bernard added – speaking for the first time in the whole meeting – that of course there is no ablative in Greek, as I would doubtless recall.<br>I told him I recalled no such thing, and later today he wrote me a little memo, explaining all the above Greek and Latin grammar.</p></blockquote><blockquote><p>‘Well,’ he said eventually, ‘inert means that . . . it’s not . . . ert.’</p></blockquote><blockquote><p>I searched desperately for an analogy, ‘It’s like Littler and Hitler,’ I explained. ‘We’re not saying that you’re like Hitler because your name sounds similar.’</p></blockquote><h1 id="THE-BED-OF-NAILS"><a href="#THE-BED-OF-NAILS" class="headerlink" title="THE BED OF NAILS"></a>THE BED OF NAILS</h1><p>如坐针毡还有的表述是：On Tenterhooks</p><h1 id="常见单词"><a href="#常见单词" class="headerlink" title="常见单词"></a>常见单词</h1><ul><li><p>repercussion 坏的影响，恶果</p></li><li><p>mirthless 沉闷的，忧郁的</p></li><li><p>scrupulous 小心谨慎的</p></li><li><p>quid pro quo 等价交换</p></li><li><p>dither 发抖，踌躇，犹豫</p></li><li><p>procrastinate 拖延，耽搁</p></li><li><p>indictment 控告</p></li><li><p>ingratiate 讨好，谄媚</p></li><li><p>scathing 严厉的</p></li><li><p>pompous 浮夸的</p></li><li><p>precipitate 仓促行事，沉淀物（化学）</p></li><li><p>devolve 被移交，转让</p></li><li><p>hotchpotch 杂烩</p></li><li><p>unison 一致行动（做事或者说话）</p></li><li><p>fortuitous 幸运的</p></li><li><p>complacent 得意自满的</p></li><li><p>reiterate 重申</p></li><li><p>approbate 许可</p></li><li><p>subsume 将 XX 包括之内，归入</p></li><li><p>brittle 易碎的，脆弱的，容易生气的</p></li><li><p>conscientious 勤奋的</p></li><li><p>impasse 绝境</p></li><li><p>brusquely 唐突地</p></li><li><p>groveling 卑躬屈膝的</p></li><li><p>chip away at 一点点地削弱，从 XX 中抽去实质性的东西，架空</p></li><li><p>patronise</p></li><li><p>dossier 卷宗</p></li><li><p>sensationalism 耸人听闻，哗众取宠，通常形容报道或者文章</p></li><li><p>overwrought 神经紧张的</p></li><li><p>blithe 愉快的</p></li><li><p>cinder 炉渣，灰烬。可以参考下 Cinderella</p></li><li><p>anarchy 无政府状态</p></li><li><p>barter 物物交换，讨价还价</p></li><li><p>ludicrous 荒唐可笑的</p></li><li><p>jumbo 庞然大物</p></li><li><p>berserk</p></li><li><p>rhetorical 修辞的</p></li><li><p>prose 单调乏味的</p></li><li><p>sycophancy 溜须拍马</p></li><li><p>condescendingly 居高临下地</p></li><li><p>bickering 争吵</p></li><li><p>calibre 才干，能力</p></li><li><p>tautology 重言（逻辑学）</p></li><li><p>lachrymose 爱哭的，容易悲伤的</p></li><li><p>flummoxed 困惑的、不知所措的、被难住的</p></li><li><p>rave 热烈地谈论或书写某事，通常是因为非常喜欢或赞赏；也可以指因愤怒、疯狂或生病而语无伦次地说话。</p></li><li><p>guffawed 大声笑或狂笑</p></li><li><p>emanate 散发，发出</p></li><li><p>feign 假装</p></li><li><p>analogy 类比，比喻</p></li><li><p>Tore him off a strip 严厉地斥责他</p></li><li><p>stem the flow </p></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;The novel of Yes Minister. Including metaphors, grammar issues and funny paragraphs.&lt;/p&gt;</summary>
    
    
    
    
    <category term="文学" scheme="http://www.calvinneo.com/tags/文学/"/>
    
  </entry>
  
  <entry>
    <title>磁盘上的数据结构</title>
    <link href="http://www.calvinneo.com/2025/02/09/data-structure-on-disk/"/>
    <id>http://www.calvinneo.com/2025/02/09/data-structure-on-disk/</id>
    <published>2025-02-09T12:57:20.000Z</published>
    <updated>2025-02-09T13:51:53.569Z</updated>
    
    <content type="html"><![CDATA[<p>如题。</p><a id="more"></a><h1 id="设计要点"><a href="#设计要点" class="headerlink" title="设计要点"></a>设计要点</h1><h2 id="序列化和反序列化-serde"><a href="#序列化和反序列化-serde" class="headerlink" title="序列化和反序列化(serde)"></a>序列化和反序列化(serde)</h2><p>这里的要点，并不只局限在类似于 protobuf 的库上，而是在设计存储格式的时候，都会考虑的问题。</p><p>需要关注的 feature：</p><ul><li>对于 blob 的支持<br>  解析是否需要占用大量内存？</li><li>读取部分数据<br>  是否需要解压/解码全部结构，才能读取到该数据呢？</li><li>兼容性<br>  新旧版本应该能够处理彼此的数据。例如：<ul><li>旧版本能够忽略新增的字段，对于后续被删除的字段，也会保留其编号。</li><li>新版本对于旧消息中缺失的字段能补上默认值，或者填入 null。</li></ul></li><li>类型的 cast<br>  例如支持从 bool 升级为 enum 或者 int。</li><li>压缩性能</li><li>编码和解码的速度、CPU 开销、内存开销</li><li>是否可以自描述？一般出于空间考虑，这都是不包含的。</li></ul><h2 id="磁盘上的数据结构"><a href="#磁盘上的数据结构" class="headerlink" title="磁盘上的数据结构"></a>磁盘上的数据结构</h2><ul><li>磁盘 IO 的单位</li><li>完整性校验</li><li>尽可能减少 IO 次数</li><li>是否多个文件或者多级文件？</li><li>是否分开存储 meta 和 data？先写 meta 还是先写 data？</li></ul><h1 id="常见格式"><a href="#常见格式" class="headerlink" title="常见格式"></a>常见格式</h1><h2 id="Parquet"><a href="#Parquet" class="headerlink" title="Parquet"></a>Parquet</h2><p>假设一个表中有 N 列，它们被分入了 M 个 row groups 中。那么每个 row groups 中的一个 Column 称为一个 Column Chunk。</p><p>文件的 metadata 包含了每个 Column Chunk 的开始位置。为了能够一趟写完文件，所以最后才会写入 metadata。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">4-byte magic number &quot;PAR1&quot;</span><br><span class="line">&lt;Column 1 Chunk 1&gt;</span><br><span class="line">&lt;Column 2 Chunk 1&gt;</span><br><span class="line">...</span><br><span class="line">&lt;Column N Chunk 1&gt;</span><br><span class="line">&lt;Column 1 Chunk 2&gt;</span><br><span class="line">&lt;Column 2 Chunk 2&gt;</span><br><span class="line">...</span><br><span class="line">&lt;Column N Chunk 2&gt;</span><br><span class="line">...</span><br><span class="line">&lt;Column 1 Chunk M&gt;</span><br><span class="line">&lt;Column 2 Chunk M&gt;</span><br><span class="line">...</span><br><span class="line">&lt;Column N Chunk M&gt;</span><br><span class="line">File Metadata</span><br><span class="line">4-byte length in bytes of file metadata (little endian)</span><br><span class="line">4-byte magic number &quot;PAR1&quot;</span><br></pre></td></tr></table></figure><p>在读取时，首先需要读取 metadata，从而定位到所有要读取的 Column Chunks。这些 Column Chunk 稍后可以被顺序读取出来。</p><p>Parquet 的格式的设计思想是将 metadata 和 data 分开，这使得可以将 Column 们分入到不同的文件中。于此同时，有一个单独的 metadata 文件去索引多个 parquet 文件。</p><blockquote><p>从下面的图片中可以看到，Parquet 文件实际上是自包含的，也就是说单个 Parquet 文件已经包含完整的数据和元数据，无需依赖外部元数据文件。像 Spark 之类的系统确实会创建一个全局的 metadata 文件，但它的作用就是方便快速的索引。</p></blockquote><p><img src="/img/disk-struct/parquet.gif"></p><p>因为 metadata 在 parquet 文件的 Footer 处，所以需要先读取文件的倒数第5到8字节，得到它的大小，然后再往前 seek 这个大小解析出 metadata 部分。</p><p>Parquet 是使用 Thrift 协议解析序列化的。它和 protobuf 其实差不多，不过 Thrift 自带了 RPC。</p><h3 id="Types"><a href="#Types" class="headerlink" title="Types"></a>Types</h3><p>Parquet 会在 Column Chunk 层面保存 min max 值。</p><h3 id="Nested-Encoding"><a href="#Nested-Encoding" class="headerlink" title="Nested Encoding"></a>Nested Encoding</h3><p>关于 Dremel 格式，可以看 <a href="https://paper-notes.zhjwpku.com/datalayout/dremel.html%E3%80%82" target="_blank" rel="noopener">https://paper-notes.zhjwpku.com/datalayout/dremel.html。</a></p><blockquote><p>To encode nested columns, Parquet uses the Dremel encoding with definition and repetition levels. Definition levels specify how many optional fields in the path for the column are defined. Repetition levels specify at what repeated field in the path has the value repeated. The max definition and repetition levels can be computed from the schema (i.e. how much nesting there is). This defines the maximum number of bits required to store the levels (levels are defined for all values in the column).</p></blockquote><p>Two encodings for the levels are supported BIT_PACKED and RLE. Only RLE is now used as it supersedes BIT_PACKED.</p><h3 id="Column-chunks"><a href="#Column-chunks" class="headerlink" title="Column chunks"></a>Column chunks</h3><h3 id="错误恢复"><a href="#错误恢复" class="headerlink" title="错误恢复"></a>错误恢复</h3><p>如果文件的 metadata 丢失了，那么文件损坏。如果 Column 的 metadata 丢失了，那么这个 Column Chunk 就损坏了。但是这个 Column 在其他 row group 中的部分是 OK 的。如果 page header 丢失了，那 chunk 中剩余的 page 就丢失了。如果 page 中的 data 损坏了，那么这个 page 就丢失了。</p><p>因此，如果 row group 设置的比较小，那么文件可能在 resilient 上更好。但是，这会 file metadata 更大。如果在写入 metadata 的时候出现问题，那么所有写入的数据都丢失了。一个做法是每写 N 个 row group，就写一次 metadata。每个 metadata 都是 cumulative 的，并且包含了写到现在所有的 row group。</p><blockquote><p>Combining this with the strategy used for rc or avro files using sync markers, a reader could recover partially written files.</p></blockquote><h2 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h2><h2 id="LevelDB-RocksDB-的-WAL"><a href="#LevelDB-RocksDB-的-WAL" class="headerlink" title="LevelDB/RocksDB 的 WAL"></a>LevelDB/RocksDB 的 WAL</h2><p>见 <a href="/2021/04/23/leveldb-wal/">LevelDB 之 WAL</a></p><h2 id="Dremel"><a href="#Dremel" class="headerlink" title="Dremel"></a>Dremel</h2><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://parquet.apache.org/docs/file-format/" target="_blank" rel="noopener">https://parquet.apache.org/docs/file-format/</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;如题。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="Parquet" scheme="http://www.calvinneo.com/tags/Parquet/"/>
    
  </entry>
  
  <entry>
    <title>形式谬误和非形式谬误</title>
    <link href="http://www.calvinneo.com/2025/02/09/logical-fallacies/"/>
    <id>http://www.calvinneo.com/2025/02/09/logical-fallacies/</id>
    <published>2025-02-09T03:57:20.000Z</published>
    <updated>2025-02-15T12:38:48.994Z</updated>
    
    <content type="html"><![CDATA[<p>介绍下常见的形式谬误和非形式谬误。</p><a id="more"></a><h1 id="非形式谬误"><a href="#非形式谬误" class="headerlink" title="非形式谬误"></a>非形式谬误</h1><h2 id="不相干的谬误"><a href="#不相干的谬误" class="headerlink" title="不相干的谬误"></a>不相干的谬误</h2><p>不相干的谬误(fallacies of relevance)或分散注意力的谬误(fallacies of distraction)是指论证的前提和结论毫无逻辑关联的不当推理方式，这种情况又称不相干的结论(irrelevant conclusion)或制造伪冒理据。</p><p>亦有人将提出与原来的争议主题毫无关联的主张或论证归类为不相干的谬误，这种情况也称作歪曲论题(ignoratio elenchi)或制造伪冒论题。</p><h3 id="稻草人论证"><a href="#稻草人论证" class="headerlink" title="稻草人论证"></a>稻草人论证</h3><p>曲解对方的论点，针对曲解后的论点（替身稻草人）攻击，再宣称已推翻对方论点。</p><blockquote><p>除了把小孩关起来以外，显然还有许多方法让孩童出门而不在大街上乱跑，因而前者无法推理出后者。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：我认为孩童不应该往大街上乱跑。</span><br><span class="line">乙：把小孩关起来，不让他们呼吸新鲜空气，那真是太愚蠢了。</span><br></pre></td></tr></table></figure><blockquote><p>甲把“支持性交易合法化”曲解成“买春过”，然而两者并无必然关系。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：你支持性交易合法化吗？</span><br><span class="line">乙：支持啊。</span><br><span class="line">甲：你果然买春过！</span><br></pre></td></tr></table></figure><h3 id="红鲱鱼"><a href="#红鲱鱼" class="headerlink" title="红鲱鱼"></a>红鲱鱼</h3><p>转移话题。</p><blockquote><p>甲是要讨论酒驾，但是乙却引入超速这个不直接相关的议题，是引入红鲱鱼的做法。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：酒驾会撞死人，而且是可以避免的，而且现在大家都知道酒驾的危害，所以我认为，酒驾应该比照故意杀人处罚。</span><br><span class="line">乙：开快车一样会撞死人，一样是可以避免的，其危害大家也知道，我们应该多讨论超速的危害及处罚！</span><br></pre></td></tr></table></figure><h3 id="诉诸言论自由"><a href="#诉诸言论自由" class="headerlink" title="诉诸言论自由"></a>诉诸言论自由</h3><blockquote><p>有发表意见的权利和意见是否正确可取是不相干的。因此自己有权发表意见并不是支持自己意见正确的恰当理据。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：现在已经很多人穷得买不起房子了，政府还打算课征奢侈税，根本是不管大家死活！</span><br><span class="line">乙：你弄错了，房地产奢侈税只有买房二年内卖掉才需要缴纳，这会让许多炒房的人有所顾忌，有助于降低房价；穷人买房是为了自用，几乎不必缴奢侈税。因此奢侈税是对穷人大有帮助的。</span><br><span class="line">甲：我有权发表意见，请尊重我说话的权利！</span><br></pre></td></tr></table></figure><h2 id="不充分的谬误"><a href="#不充分的谬误" class="headerlink" title="不充分的谬误"></a>不充分的谬误</h2><p>不充分的谬误是指论证的前提虽与结论相干，但前提不能充分支持结论的现象。也就是说，即使所有前提都为真，也不能确保结论为真。</p><h3 id="逆偶例谬误"><a href="#逆偶例谬误" class="headerlink" title="逆偶例谬误"></a>逆偶例谬误</h3><p>基于某个例外的存在，而否定一般性的通则。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">爸爸抽烟抽了四十年都没得肺癌，因此抽烟不会导致肺癌。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">宫崎勤是宅男，又犯下连续强奸杀害女童的罪行，可见动漫是坏东西。</span><br></pre></td></tr></table></figure><h3 id="合成谬误和分割谬误"><a href="#合成谬误和分割谬误" class="headerlink" title="合成谬误和分割谬误"></a>合成谬误和分割谬误</h3><p>合成谬误指的是因为整体中的某些部分具有某性质，从而认为整体本身具备该性质，这是一种以偏概全。</p><p>分割谬误与之相反。</p><p>下面的是合成谬误的例子。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">人体由细胞组成，而细胞是看不见的，因此人体是看不见的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我的论文每一个论点是无懈可击的，因此整篇论文都是无懈可击的。</span><br></pre></td></tr></table></figure><p>下面的是分割谬误的例子。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">宇宙已存在一百亿年，宇宙是由分子组成的，因此宇宙中的每个分子都已存在一百亿年。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">朝鲜是是世界最穷的国家之一，因此朝鲜的每个人都很穷。</span><br></pre></td></tr></table></figure><h3 id="偏差样本（统计）"><a href="#偏差样本（统计）" class="headerlink" title="偏差样本（统计）"></a>偏差样本（统计）</h3><p>根据缺乏代表性的样本（统计方法）推论出一般性的结论。</p><blockquote><p>注意区分朝鲜-朝鲜人，和美国人-美洲人之间的关系。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">美国人很有钱，可见美洲人很有钱。</span><br></pre></td></tr></table></figure><blockquote><p>长期失业的可能有多种原因，未必和大学有关。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">他是重点大学热门科系毕业的，结果还是长期失业，可见念好大学没有用。</span><br></pre></td></tr></table></figure><h3 id="诉诸可能-把合理当正确"><a href="#诉诸可能-把合理当正确" class="headerlink" title="诉诸可能/把合理当正确"></a>诉诸可能/把合理当正确</h3><p>基于一件事有可能或相当可能是真的，就把它当作确定是真的。当思考或决策忽略了其他可能性，把一种合理的、可能的推测当做正确的、必然的真相，就不是恰当的推理。</p><p>此类谬误中，将“一定”改为“可能”，那么逻辑往往正确。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">网络上很多黑客，你上网不装防火墙，你的电脑一定会被黑客入侵的！</span><br></pre></td></tr></table></figure><blockquote><p>小华在侦讯时的表现可作为怀疑小华涉案的线索，但不应据此咬定他必有涉案。<br>不应该认定试图为嫌疑犯辩护的律师都是昧著良心做事。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">小华在侦讯时结结巴巴、言词反复，还数度说谎，这就是他涉入了这起大规模诈欺案的明确证据！</span><br><span class="line">辩护律师找一堆理由帮小华这种恶徒脱罪，真是毫无良心！</span><br></pre></td></tr></table></figure><h3 id="布佛氏论证（诉诸为何相信）"><a href="#布佛氏论证（诉诸为何相信）" class="headerlink" title="布佛氏论证（诉诸为何相信）"></a>布佛氏论证（诉诸为何相信）</h3><p>假定某观点是错的，由此出发解释为什么许多人会相信它，然后断定该观点是错误的。</p><blockquote><p>人们可以有合理的理由怀疑奶茶可能不含鲜奶，但不能据此断定某杯奶茶一定不含鲜奶或一定含有鲜奶。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">奶茶里不需要加入鲜奶，只要加入奶精就可以模拟出鲜奶的味道，因此这杯奶茶一定不含鲜奶。</span><br></pre></td></tr></table></figure><blockquote><p>人们有合理的理由可以怀疑小华可能用诈术，但这不表示小华一定使用诈术，也不表示小华没有使用诈术。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">魔术师可以表演出徒手打碎十块瓦片的诈术，所以小华之前打碎二块瓦片一定不是真的。</span><br></pre></td></tr></table></figure><h3 id="鬼祟谬误（阴谋论）"><a href="#鬼祟谬误（阴谋论）" class="headerlink" title="鬼祟谬误（阴谋论）"></a>鬼祟谬误（阴谋论）</h3><p>断定某些事情一定是某些心怀不轨的团体在背后操作导致。</p><h3 id="单方论证（采樱桃谬误）"><a href="#单方论证（采樱桃谬误）" class="headerlink" title="单方论证（采樱桃谬误）"></a>单方论证（采樱桃谬误）</h3><p>引用貌似证实特定立场的个别案例或数据，而忽略可能与该立场相矛盾的相关和类似案例或数据的重要部分的行为。</p><h3 id="不完整的比较"><a href="#不完整的比较" class="headerlink" title="不完整的比较"></a>不完整的比较</h3><p>透过不完整而难以驳斥的断言证成观点。然而，正因为其不完整，因而也无法有效证成观点。</p><blockquote><p>这是不完整的断言，较完整的断言应该像：“甲公司的产品比乙公司的产品较便宜。”“甲公司的产品销售量比乙公司的产品高。”</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">甲公司的产品比乙公司的产品更好。</span><br></pre></td></tr></table></figure><h3 id="不一致的比较"><a href="#不一致的比较" class="headerlink" title="不一致的比较"></a>不一致的比较</h3><p>将对不同对象采用不同基准作出的比较，并列作为理据证成某主张。这种谬误有时是出于对运用比较数据的概念模糊，是无意而成的。但也有刻意以此为宣传手法，或于辩论中借此误导他人以求胜出。</p><p>例子比如雷军对比法。</p><blockquote><p>可能甲公司的产品功能较乙公司的少，而价格却比丙公司的高，因此即使该陈述为真实，亦不足以使“甲公司的产品最好”此一结论成立</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">甲公司的产品比乙公司的更便宜，比丙公司的更多功能。</span><br></pre></td></tr></table></figure><h3 id="涅槃谬误（完美主义谬误）-权宜主义谬误"><a href="#涅槃谬误（完美主义谬误）-权宜主义谬误" class="headerlink" title="涅槃谬误（完美主义谬误）/权宜主义谬误"></a>涅槃谬误（完美主义谬误）/权宜主义谬误</h3><p>涅槃谬误：因为这做法不完美，所以这做法便没用。</p><p>权宜主义谬误：基于某方案目的很重要而无视方案的一切缺陷。</p><p>权宜主义谬误包括</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">偷窃是错的，不能不处罚，我主张偷窃者唯一死刑！</span><br></pre></td></tr></table></figure><p>特别地，两个谬误可以并存，如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">有做总比没做好，再吵就干脆啥都不做</span><br></pre></td></tr></table></figure><p>或者</p><blockquote><p>涅槃谬误在“死刑”上，权宜主义谬误在“废除死刑”上</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">死刑不可避免会冤狱错杀，而且死刑对谋杀并无更强的吓阻效果，所以即使多数民意反对废除死刑，政府也应该尽速废除死刑</span><br></pre></td></tr></table></figure><h3 id="偶例谬误"><a href="#偶例谬误" class="headerlink" title="偶例谬误"></a>偶例谬误</h3><p>和先前的逆偶例谬误相反，基于某个通则的存在，而否定例外的存在或正当性，即不恰当地以一个普遍原则来解释一个特殊事例。</p><p>当在三段论中应用经验法则的时候忽略了特例，就会出现有效的推论但是得出谬误的结论。</p><blockquote><p>可以思考下这个命题的逆偶例谬误如何阐述。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">超速是不对的，所以救护车不应该超速。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">鸟会飞，驼鸟是鸟，所以驼鸟会飞。</span><br></pre></td></tr></table></figure><h3 id="区群谬误（生态谬误、层次谬误）"><a href="#区群谬误（生态谬误、层次谬误）" class="headerlink" title="区群谬误（生态谬误、层次谬误）"></a>区群谬误（生态谬误、层次谬误）</h3><p>和以偏概全相反，区群谬误是一种以全概偏，如果仅基于群体的统计数据就对其下属的个体性质作出推论，就是犯了区群谬误。</p><p>个人感觉有点类似于偏差样本，或者合成谬误。但是合成谬误并不依赖统计数据，而偏差样本中又不存在整体-个体的关系。这个问题感觉还可以被拓展为辛普森悖论。</p><p>区群谬误的相反情况为化约主义（还原论）。</p><blockquote><p>因为统计结果只是对两城的平均智商作比较，乙城个别市民智商可能比甲城的个别市民高；在极端情况下，两城之中智商最高的一位市民可能生活在乙城。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一项研究发现甲城市民的智商平均比乙城市民高，因此认为在两个城市各自随机抽取一个市民，甲城那位市民的智商都会比乙城的那位高</span><br></pre></td></tr></table></figure><blockquote><p>事实上，贫穷才是癌症的风险因素，区群谬误带来相反的结论。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">假设甲城和乙城都各有相同人数的富人和穷人，富人都住在山上，而穷人都住在排放致癌物的工厂附近，故此在两个城市的穷人癌症发病率都比富人高很多倍。在甲城的都是高增值高污染工业，故此在甲城无论是富人和穷人的平均工资都比乙城高，但同时甲城穷人的癌症发病率也因此比乙城高。</span><br><span class="line"></span><br><span class="line">一位教授希望找出癌症的风险因素，他在国家统计刊物找到甲城和乙城的癌症发病率和工资中位数，发现工资中位数较高的甲城有更高的癌症发病率，得出高收入是癌症风险因素的结论。</span><br></pre></td></tr></table></figure><h3 id="懒于归纳（诉诸巧合）"><a href="#懒于归纳（诉诸巧合）" class="headerlink" title="懒于归纳（诉诸巧合）"></a>懒于归纳（诉诸巧合）</h3><p>主张一切统计性、归纳性的结论都不可取。特点是尽管证据显示甲导致乙，但论者依旧主张乙是因为其他事情导致的。</p><p>相反的谬误是草率归纳。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：你们拉面店的服务生千濑在第一个月就打破了五十个盘子，而有强烈的证据显示这是因为她动作笨拙所致，为了整个店的业绩着想，应该对她加强训练。</span><br><span class="line">乙：千濑很可爱，大家都喜欢她！这一切都只是巧合罢了！</span><br></pre></td></tr></table></figure><h2 id="不充分的谬误-因果谬误"><a href="#不充分的谬误-因果谬误" class="headerlink" title="不充分的谬误 - 因果谬误"></a>不充分的谬误 - 因果谬误</h2><p>统计学上很容易发现两个事件 corelate，并不能很好地推断彼此之间的因果关系。</p><h3 id="相关不蕴涵因果（与此故因此、相关不代表因果）"><a href="#相关不蕴涵因果（与此故因此、相关不代表因果）" class="headerlink" title="相关不蕴涵因果（与此故因此、相关不代表因果）"></a>相关不蕴涵因果（与此故因此、相关不代表因果）</h3><p>若两个事件有明显的相关时（即当一件事出现，另一件事也出现），不一定表示两者之间有因果关系。这个实际上是一个很大的范畴，下面列出的其他因果谬误，可能都同样犯有相关不蕴涵因果的问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">统计研究发现，冰淇淋销量最高的时候，就是公共泳池的溺水事故发生得最多的时候。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明感冒后吃了些感冒药，后来就发烧了。一定是这感冒药让他恶化的！</span><br></pre></td></tr></table></figure><blockquote><p>这里同时也犯下了复合结果的谬误。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小华因为发高烧不退，于是发生了脑膜炎。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明上次比赛打棒球的成绩奇差无比，教练把他骂一顿以后，这次比赛的成绩就进步了。因此，责骂可以提升小明打棒球的成绩。</span><br></pre></td></tr></table></figure><h3 id="后此谬误（后此故因此、巧合关系）"><a href="#后此谬误（后此故因此、巧合关系）" class="headerlink" title="后此谬误（后此故因此、巧合关系）"></a>后此谬误（后此故因此、巧合关系）</h3><p>指这样一种不正确的推理：如果 A 事件先于 B 事件发生，A 事件则是 B 事件的原因。</p><blockquote><p>发烧可能是感冒本身造成，未必是感冒药造成的。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明感冒了，他吃了一些感冒药，然后他发烧了。所以，一定是这感冒药让他发烧的。</span><br></pre></td></tr></table></figure><h3 id="倒果为因"><a href="#倒果为因" class="headerlink" title="倒果为因"></a>倒果为因</h3><blockquote><p>事实也有可能是：被迫担任苦力才肌肉发达。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">清末的苦力肌肉较发达，可见肌肉较发达的人比较喜欢担任苦力。</span><br></pre></td></tr></table></figure><blockquote><p>事实也有可能是：盲人由于依听力过活，听力开发后变得比一般人更敏锐。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">盲人的听力比明眼人好，可见听力好的人容易失明。</span><br></pre></td></tr></table></figure><blockquote><p>事实也有可能是：人民对政府有所不满，才会有反政府团体的出现。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">就是因为有这些唯恐天下不乱的反政府团体，人民内部才会有反政府的声音的。</span><br></pre></td></tr></table></figure><h3 id="单因谬误"><a href="#单因谬误" class="headerlink" title="单因谬误"></a>单因谬误</h3><p>认定某事由一个单独原因造成，而未考虑可能是由许多原因共同导致，即复合原因（complex cause）。</p><blockquote><p>考试成绩差除了可能天天玩游戏机而排挤读书时间以外，可能还有其他原因。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明考试成绩那么差，一定是因为他天天玩游戏机的关系。</span><br></pre></td></tr></table></figure><blockquote><p>妹喜、妲己和褒姒这三位美女，未必是这些夏商周这三个朝代灭亡的主要原因，甚至美女的存在根本就不是原因。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">作为臣子的我曾听说：贤能的士人，是国家的珍宝、而美女则是国家的祸害。例如夏朝因妺喜而灭亡、商朝因妲己而灭亡、周朝因褒姒而灭亡。《吴越春秋》</span><br></pre></td></tr></table></figure><h3 id="复合结果"><a href="#复合结果" class="headerlink" title="复合结果"></a>复合结果</h3><p>当某些原因导致多个结果时，在多个结果之间建立因果关联。</p><p>我认为这个算是“相关不蕴涵因果”的一种特殊形式。因为“当某些原因导致多个结果”时，那么这多个结果肯定是 corelate 的。</p><blockquote><p>即使房子没被炮火所毁，小明一家人仍可能因为“国家发生战乱”而从北部逃到南部。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">国家发生战乱，小明一家人因为房子被炮火所毁而从北部逃到南部。</span><br></pre></td></tr></table></figure><blockquote><p>即使没有“发高烧不退”（比如吃了很多退烧药），小华仍可能因为“细菌感染没妥善控制”造成“脑膜炎”。<br>注意，也同时犯下了相关不蕴涵因果谬误。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小华因为发高烧不退，于是发生了脑膜炎。</span><br></pre></td></tr></table></figure><h3 id="无足轻重"><a href="#无足轻重" class="headerlink" title="无足轻重"></a>无足轻重</h3><p>将真实但不重要的原因作为论证基础，却遗漏了重要的主因。</p><blockquote><p>导致空气质量变差的主因可能是交通工具或工厂排放的废气，烧纸钱虽也会影响空气，然而对空气质量的影响与交通工具或工厂排放的废气相比甚微。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">烧纸钱使空气质量每况愈下，所以政府应该不许民众再烧了。</span><br></pre></td></tr></table></figure><blockquote><p>电脑开一夜对全球变暖的影响甚微。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">你电脑开一夜没关，所以你是造成全球变暖的凶手。</span><br></pre></td></tr></table></figure><blockquote><p>有理由认为了解和传播凶杀案资讯的重要性超过这些情绪反应所带来的问题，因此以“引发情绪”为由叫人不要转载凶杀案的资讯并不恰当。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在面对凶杀案时呼吁人们“请不要转载任何的图片、电视画面，毕竟这些都会制造无谓的恐慌与难过”。</span><br></pre></td></tr></table></figure><h3 id="回归谬误"><a href="#回归谬误" class="headerlink" title="回归谬误"></a>回归谬误</h3><p>因未考虑统计学上随机起落的回归现象，造成不恰当的因果推论。</p><blockquote><p>发烧二天后，即使不吃药也很可能自行好转，不能就此认定是药物的效果。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明前天发烧，今天吃了退烧药，小明烧退是退烧药的效果。</span><br></pre></td></tr></table></figure><blockquote><p>也是相关不蕴涵因果。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明上次打棒球的成绩奇差无比，教练把他骂一顿以后，这次比赛的成绩就进步了。因此，责骂可以提升小明打棒球的成绩。</span><br></pre></td></tr></table></figure><h3 id="滑坡谬误"><a href="#滑坡谬误" class="headerlink" title="滑坡谬误"></a>滑坡谬误</h3><p>从形式逻辑上是属于假言三段论，使用连串的因果推论，却夸大了每个环节中的因果强度，将“可能性”转化为“必然性”，从而得到不合理的结论 ，然而事实不一定会按照线性推论而发生，而有其他的可能性。</p><blockquote><p>小华今天借十元，不表示他明天就会借一百元。就算小华今天借一百元，也不表示明天就会借一千元。就算小华借一千元甚至一万元，也不表示乙就会破产，因为乙有权选择不借。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：小华临时打电话没钱，为什么你不愿意借他十元呢？</span><br><span class="line">乙：如果我借了，他明天又会跟我借一百元，接下来就借一千元、一万元，我岂不破产？</span><br></pre></td></tr></table></figure><blockquote><p>公司损失也不表示公司会赚不到钱，就算公司赚不到钱也不表示公司就要裁员，就算公司裁员也不表示被裁员的人会没工作，就算被裁员的人没工作也不表示会为了生计无恶不作。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">员工偷懒公司便会损失，公司赚不到钱就要裁员，被裁员的人会没工作，没工作的人为了生计就会无恶不作。因此，上班偷懒是非常严重的罪恶。</span><br></pre></td></tr></table></figure><h2 id="不当预设的谬误"><a href="#不当预设的谬误" class="headerlink" title="不当预设的谬误"></a>不当预设的谬误</h2><h3 id="乞题（窃取论点）"><a href="#乞题（窃取论点）" class="headerlink" title="乞题（窃取论点）"></a>乞题（窃取论点）</h3><p>在论证时把不该视为理所当然的命题预设为理所当然，这是一种不当预设的非形式谬误。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明有罪，因为小明有罪。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">男人体力最好，因为女人体力没那么好。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">桌上有一块蛋糕，大宝切了二分之一留给自己，然后给二宝和三宝各四分之一。</span><br><span class="line"></span><br><span class="line">二宝和三宝：不公平！你凭什么拿比较多？</span><br><span class="line">大宝：因为我比较聪明。</span><br><span class="line">二宝和三宝：凭什么说你比较聪明？</span><br><span class="line">大宝：因为我拿到比较多的蛋糕。</span><br></pre></td></tr></table></figure><p>下面是三段论中的乞题</p><blockquote><p>论证预设了“上帝拥有一切美德”，但是“一切美德”中又包含了“仁爱”，所以实际上就是在预设“上帝是仁爱的”。但“上帝拥有一切美德”这个是不确定需要证明的。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">上帝是仁爱的，因为上帝拥有一切美德。</span><br></pre></td></tr></table></figure><blockquote><p>这里的乞题是预设了“美国人都很有钱”</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">美籍教师彼得很有钱，因为美国人都很有钱。</span><br></pre></td></tr></table></figure><blockquote><p>本例的前提“合理的法律和司法判决和个人感受无关”这点相当可疑、需要证明。因为有理由认为，对当事人主观感受的同理心在司法正义的实现中至为重要。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我认为，如果我家人被杀，那么司法该怎么判，和我个人的感受无关。</span><br></pre></td></tr></table></figure><blockquote><p>考虑未明言的隐藏前提，本例论证可分析为：</p><ul><li>汤姆必须找到好工作（隐藏前提）</li><li>汤姆必须减少花在玩乐和社团活动的时间，才能读好书（隐藏前提）</li><li>汤姆不读好书以后一定会找不到好工作（前提）</li><li>因此，汤姆必须减少花在玩乐和社团活动的时间（结论）</li></ul></blockquote><blockquote><p>然而这些前提都可能有争议，在特定情境下可能会是不当的，例如，如果汤姆显然不擅长读书，但非常擅长演戏，且正有星探尝试挖掘，“汤姆不读好书以后一定会找不到好工作”可能是不当预设；如果汤姆是读书天才，“汤姆必须减少花在玩乐和社团活动的时间，才能读好书”可能是不当预设；如果汤姆的价值观就是没有好工作也无所谓，“汤姆必须找到好工作”便是不当预设（需要提供理由说服汤姆接受）。此类情境下这样的论证便有乞题之虞。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">妈妈对汤姆说：你不读好书以后一定会找不到好工作，因此你必须减少花在玩乐和社团活动的时间！</span><br></pre></td></tr></table></figure><h3 id="循环论证"><a href="#循环论证" class="headerlink" title="循环论证"></a>循环论证</h3><p>直接的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">小明有罪，因为他有罪。</span><br></pre></td></tr></table></figure><p>间接的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：小明是音乐神童，因为他很懂音乐。</span><br><span class="line">乙：怎么知道小明很懂音乐？</span><br><span class="line">甲：因为小明是音乐神童</span><br></pre></td></tr></table></figure><p>更为复杂的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：大雄是卖国贼，因为他替胖虎这个间谍辩护！</span><br><span class="line">乙：怎么知道胖虎是间谍？</span><br><span class="line">甲：因为大雄这个卖国贼替他辩护。</span><br></pre></td></tr></table></figure><h3 id="既定观点用词、诉诸情感"><a href="#既定观点用词、诉诸情感" class="headerlink" title="既定观点用词、诉诸情感"></a>既定观点用词、诉诸情感</h3><p>既定观点词语</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">公元前209年，陈胜和吴广发动大泽乡起义，建立张楚政权，反抗暴秦苛政</span><br></pre></td></tr></table></figure><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="双管问题（一题多问）"><a href="#双管问题（一题多问）" class="headerlink" title="双管问题（一题多问）"></a>双管问题（一题多问）</h3><p>指在一个问题以合取（且）或析取（或）等方式组合多个子问题，却只允许简单的答案。</p><blockquote><p>有多个可能性：小明是职业选手，但不厉害；小明不是职业选手，但很厉害；小明不是职业选手，也不厉害。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：小明是不是厉害的职业选手？</span><br><span class="line">乙：不是。</span><br><span class="line">甲：哦，所以小明是不厉害的职业选手</span><br></pre></td></tr></table></figure><blockquote><p>投反对票的人可能认为：应加入世界金融组织，且不应改善经济；不应加入世界金融组织，且应改善经济；不应加入世界金融组织，且不应改善经济。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">公投题目：“是否赞成我国加入世界金融组织以改善经济？”</span><br><span class="line">投票结果，反对票多于赞成票。</span><br><span class="line">评论者：“多数民众认为没有改善经济的需要。”</span><br></pre></td></tr></table></figure><h3 id="两难推理（非黑即白、伪二分法）"><a href="#两难推理（非黑即白、伪二分法）" class="headerlink" title="两难推理（非黑即白、伪二分法）"></a>两难推理（非黑即白、伪二分法）</h3><h3 id="否认对立"><a href="#否认对立" class="headerlink" title="否认对立"></a>否认对立</h3><p>当某人在需要从两个相互排斥的陈述中作出选择的情况下，没有选择其中一个，而是引入了第三个选择时，这个谬误可能会发生。这通常是为了分散注意力，而使得自己不必在可能两个选项之间做出选择。</p><p>有点类似于“不相干的谬误”，更类似于打岔。</p><blockquote><p>人们期望得到“是”或“不是”的答案，而这也是这种问题的唯一可接受的答案；但乙却通过提供第三个答案选项来转移问题，使原来的问题没有得到回答。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：你杀了路人甲吗？</span><br><span class="line">乙：我和他打过架。</span><br></pre></td></tr></table></figure><h3 id="打压对立"><a href="#打压对立" class="headerlink" title="打压对立"></a>打压对立</h3><p>借由修改对立概念的定义，使对立概念难以发生，藉以宣称某概念的普遍性</p><blockquote><p>此例将“快”的外延缩小，使“快”难以发生，而且“快”是一个相对概念，车子没有比战斗喷射机快，不等没有比其他多数车辆快。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">甲：我的车可以跑很快。</span><br><span class="line">乙：它能比战斗喷射机快吗？我想不行，所以它并不快。</span><br></pre></td></tr></table></figure><h3 id="诉诸纯洁（没有真正的苏格兰人）"><a href="#诉诸纯洁（没有真正的苏格兰人）" class="headerlink" title="诉诸纯洁（没有真正的苏格兰人）"></a>诉诸纯洁（没有真正的苏格兰人）</h3><p>在普遍宣称遇到反例时，提出理想的标准为其辩护。</p><blockquote><p>此例“真正的苏格兰人”有歧义，一为甲自行的定义，二为通俗的理解。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">甲：没有苏格兰人会在粥里加糖。</span><br><span class="line">乙：我是苏格兰人，我会在粥里加糖啊。</span><br><span class="line">甲：好吧，“真正的”苏格兰人不会在粥里加糖。</span><br></pre></td></tr></table></figure><h1 id="常见逻辑错误辨析"><a href="#常见逻辑错误辨析" class="headerlink" title="常见逻辑错误辨析"></a>常见逻辑错误辨析</h1><h2 id="劝学"><a href="#劝学" class="headerlink" title="劝学"></a>劝学</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">蟹六跪而二螯，非蛇鳝之穴无可寄托者，用心躁也。</span><br></pre></td></tr></table></figure><ul><li>倒果为因<br>  “蟹六跪而二螯”可能是它为了寄生而进化的结果。</li><li>以偏概全<br>  这篇《劝学》的观点是“用心一”能够取得成功，但这是以偏概全的。决定是否成功的因素是多种多样的。</li><li>类比失当<br>  用动物本能现象论证人类主观能动性问题，两类事物本质不同（生物学现象 vs 主观意志），导致类比失效。<br>  具体来说，这里发生了拟人化谬误。</li></ul><h2 id="一则知乎上的评论"><a href="#一则知乎上的评论" class="headerlink" title="一则知乎上的评论"></a>一则知乎上的评论</h2><p>以下分别为原文和修复语法错误之后的文字</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">觉得6千少的可以走人，现在不是封建社会，而不是为了私欲核爆公司领导隐私，企图把作为领导也好朋友也好全都拖累。何况小李到现在都还在林身边工作，小李都能一直干，那证明奖金少不了。</span><br><span class="line"></span><br><span class="line">觉得6千工资少的可以走人，而不是为了私欲核爆公司领导隐私，企图把领导和好朋友全都拖累。何况小李到现在都还在林身边工作，小李都能一直干，那证明奖金少不了。</span><br></pre></td></tr></table></figure><ul><li>诉诸情感、既定观点用词<br>  “为了私欲核爆公司领导隐私，企图把领导和好朋友全都拖累”这种表述试图通过激发读者的道德情感来影响判断，而不是基于事实和逻辑进行论证。<br>  它并没有根据具体的事实或逻辑依据来证明某人的行为是否合理。</li><li>类比失当、诉诸权威<br>  具体表现：“小李都能一直干，那证明奖金少不了”。<ul><li>这里将小李的情况错误地类比为其他人的处境。小李能够一直工作并获得奖金，不能直接证明其他人也会有同样的待遇。这种类比忽略了个体差异和其他可能影响奖金的因素，如工作表现、公司政策变化等。</li><li>暗示小李的选择是权威的。这种表述试图通过小李的行为来证明某种观点的正确性，而没有考虑小李的行为是否合理或是否适用于其他人。它依赖于小李的权威性，而不是基于事实和逻辑的论证。</li></ul></li><li>滑坡谬误<br>  暗示核爆公司领导隐私，会拖累好朋友。然而，核爆领导隐私并不一定会拖累好朋友。<br>  这种说法假设了一个极端的负面后果，而没有提供任何证据或逻辑链条来支持这种后果的必然性。</li><li>因果谬误<br>  暗示领导是因为被“核爆公司领导隐私”而被拖累的。这种观点<strong>可能</strong>错误地将因果关系颠倒了。<br>  比如，如果曝光的是一件丑闻，那么它本身的存在才是损害领导形象的根本原因，而不是揭露的行为。揭露丑闻的人只是让公众知晓了这一问题，从而促使解决问题，防止类似事件再次发生。</li><li>单因谬误<br>  具体表现：“小李都能一直干，那证明奖金少不了”。<br>  这种说法忽略了其他可能影响奖金的因素。仅仅因为小李能够一直工作并获得奖金，就认为其他人也会有同样的待遇。</li><li>不当关联<br>  “觉得6千工资少”、“走人”、“为了私欲”、“核爆公司领导隐私”之间并没有必然的逻辑联系：<ul><li>“觉得6千工资少”可能只是生活所迫，而并非“为了私欲”。</li><li>“核爆公司领导隐私”并不一定是“为了私欲”，可能是出于主张公道而一时冲动。</li></ul></li><li>双管问题<br>  “走人”、“核爆公司领导隐私”并不是互斥关系，可以两个都做，也可以两个都不做，或者只做其中一个。</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://zh.wikipedia.org/wiki/Category:%E9%9D%9E%E5%BD%A2%E5%BC%8F%E8%AC%AC%E8%AA%A4" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Category:%E9%9D%9E%E5%BD%A2%E5%BC%8F%E8%AC%AC%E8%AA%A4</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍下常见的形式谬误和非形式谬误。&lt;/p&gt;</summary>
    
    
    
    
    <category term="逻辑" scheme="http://www.calvinneo.com/tags/逻辑/"/>
    
  </entry>
  
  <entry>
    <title>Raft learner</title>
    <link href="http://www.calvinneo.com/2025/01/19/raft-learner/"/>
    <id>http://www.calvinneo.com/2025/01/19/raft-learner/</id>
    <published>2025-01-19T10:07:22.000Z</published>
    <updated>2025-01-19T09:23:48.868Z</updated>
    
    <content type="html"><![CDATA[<p>TiFlash 的整个 replication 机制建立在 Raft learner 协议之上。</p><p>在本文中介绍 Raft learner 相关的 case 以及优化，主要包括：</p><ul><li>涉及 Learner 的活性问题</li><li>Learner Snapshot</li><li>Learner Read<ul><li>作为前置，还会说明 Leader 的 Lease Read</li><li>作为直接的扩展，还会说明 Stale Read</li></ul></li></ul><a id="more"></a><p>本文大部分是从 <a href="/2023/07/22/tikv-tidb-thought/">关于 TiKV、TiDB、TiFlash 的一些思考</a>中取出的，并进行了扩展。</p><h1 id="Learner-的总体作用"><a href="#Learner-的总体作用" class="headerlink" title="Learner 的总体作用"></a>Learner 的总体作用</h1><ul><li>新增的 Voter 节点以 Learner 角色先追进度</li><li>观测 Raft Group 中的数据变更</li><li>支持 Replica Read</li></ul><h1 id="Learner-peer"><a href="#Learner-peer" class="headerlink" title="Learner peer"></a>Learner peer</h1><h2 id="活性"><a href="#活性" class="headerlink" title="活性"></a>活性</h2><h3 id="Add-Learner"><a href="#Add-Learner" class="headerlink" title="Add Learner"></a>Add Learner</h3><p>Raft 中添加一个 Learner 并不需要经过该 Learner。我引入了一些<a href="https://github.com/pingcap/tidb-engine-ext/blob/raftstore-proxy/proxy_tests/proxy/v1_specific/region_ext.rs" target="_blank" rel="noopener">测试</a>来描述相关的行为。</p><p>但是，如果 Learner peer 始终不 ready，则它会变为 pending-peer 甚至 down-peer。</p><h3 id="Orphan-Learner"><a href="#Orphan-Learner" class="headerlink" title="Orphan Learner"></a>Orphan Learner</h3><p>Learner 尽管在 Raft Group 中，但不参与投票。所以当 Voter 节点因为 Region 被销毁（通常因为 merge）全部被销毁后，Learner 节点就无法找到 Leader 节点。对于 Voter 节点来说，这种情况它可以发起选举，然后发现其他节点上的 Tombstone 标记，从而确认 Region 已经被摧毁了。但因为 Learner 不参与投票，所以是无法发现这种情况的，从而僵死。</p><p>上述的卡死在之前需要等待 2h 之后触发存活性检查才会被发现，后续会发送一个 Tombstone 消息从而执行 gc peer 的操作。否则，就需要人工将僵死的 Region peer 设置为 Tombstone 状态。因此，后续进行了优化，将 Tombstone 消息的发送间隔调小。</p><p>Learner 可能因为多种原因导致丢失 Leader，从而变为孤儿节点：</p><ol><li>在 Region 销毁的场景如 CommitMerge，target region 的 Voter 至少可以在 Leader 销毁之后，因为超时触发选举，从而启动自毁。而 Learner 则不行，会 miss leader 然后卡死<br> 特别地，CommitMerge 本身对 Source Peer 也会有检查，这里还可能造成连环等待。比如如果在等待 Source 追数据，就会 Yield 为 WaitMergeSource。如果卡在 CommitMerge 上，那么后续的 RemovePeer 也无法执行。</li><li>在 ConfChange 中，如果删除了某个 Learner，但又没有能够将该日志复制给 Learner，那么稍后 Learner 就不会得到 Leader 的任何消息，从而一样卡死。</li><li>在 BatchSplit 中，如果新 Split 出来的 Region 在 TiFlash apply BatchSplit 命令前就在所有 Voter 节点中被删除的话，后续 TiFlash 节点即使 apply 完 BatchSplit，也无法再收到任何日志，因为 Leader peer 已经不存在了。</li></ol><h2 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h2><p>Raft Log GC 也需要 respect Learner 的进度，原因：</p><ul><li>诸如 TiFlash 这样的引擎，底层存储非 Rocksdb，因此不能直接 ingest。因此对 Raft Snapshot 进行转换存在大量 CPU 开销。并且，Snapshot 本身被用来 bootstrap 一个 Region peer，所以在它被处理完之前，无法处理后续的 append。因此，异步转换 Snapshot 的收益不是特别大，不如后续引入 Remote Decoder 去 offload 一部分开销。</li><li>进一步，如果 Snapshot 处理时间过长，则可能超过下一轮的 Raft Log GC，导致需要处理新一轮的 Snapshot，由此往复，该副本始终无法追齐进度。</li></ul><h3 id="Follower-Replication-和-Follower-Snapshot"><a href="#Follower-Replication-和-Follower-Snapshot" class="headerlink" title="Follower Replication 和 Follower Snapshot"></a>Follower Replication 和 Follower Snapshot</h3><p>Follower Snapshot 的好处有：</p><ol><li>因为是有处于一个 Zone 的 Follower 发送 Snapshot，所以可能更快。并且跨 Zone 流量也少</li><li>减少 Leader 的负担</li></ol><p>TiFlash 做了 Learner Snapshot，相比 Follower Snapshot，它甚至是一个异构的 Snapshot。CRDB 做了类似的工作，称为 <a href="https://www.cockroachlabs.com/docs/stable/architecture/replication-layer" target="_blank" rel="noopener">Delegate Snapshot</a>。TiKV 目前还不支持。</p><h1 id="Lease-read"><a href="#Lease-read" class="headerlink" title="Lease read"></a>Lease read</h1><p>为了讲明白 Learner Read，首先需要了解 Leader 的 Lease read，因此就在这里一起讨论了。</p><h2 id="Why-Lease？"><a href="#Why-Lease？" class="headerlink" title="Why Lease？"></a>Why Lease？</h2><p>如果没有 lease，那么 Raft 集群中读取要么就是提交一条新的日志，要么就是去询问所有的节点，从而确认自己依旧是 leader。lease 的作用是保证一段时间中，只有某个节点可能是 leader。</p><p>lease 的主要实现问题是，不同节点上的时间不一定一致，也就是可能出现 clock drift。</p><h2 id="是否有单独的-Lease-Leader？"><a href="#是否有单独的-Lease-Leader？" class="headerlink" title="是否有单独的 Lease Leader？"></a>是否有单独的 Lease Leader？</h2><p>CRDB 的实现中，有单独的 lease leader，而 TiKV 的 lease leader 一定是 raft leader。因此就形成了一些区别：</p><ol><li>在时钟依赖上，TiKV 依赖 NTP，CRDB 依赖 HLC。</li><li>在“谁操作读”上，TiKV 通过 Raft Leader 来读，crdb 通过 lease leader 来读。</li></ol><h2 id="Lease-绑定-node-还是-raft-group？"><a href="#Lease-绑定-node-还是-raft-group？" class="headerlink" title="Lease 绑定 node 还是 raft group？"></a>Lease 绑定 node 还是 raft group？</h2><p><a href="https://www.cockroachlabs.com/docs/stable/architecture/replication-layer#epoch-based-leases-table-data" target="_blank" rel="noopener">CRDB</a> 将 Lease 和机器绑定而不是和 Data Range 绑定，从而减少网络开销。它的做法是每个 Data Range 的 “Leader” 会去维护一个 meta 表（也是一个 Data Range）上的 liveness 记录。我理解是以一个比较低的频率去更新 liveness 记录，因为<strong>如果不是节点挂了下线，或者是重新调度到当前 Raft Leader 的节点上</strong>这两种情况，Raft Leader 就还是同一个，那么就完全没有必要续期。而 TiKV 的绑定方式则必须要求 Lease 是比 Election Timeout 要短的。</p><p>当某个 node 宕掉之后，CRDB 还是要重新选出一个新的 Lease Leader，而这个<a href="https://www.cockroachlabs.com/docs/stable/architecture/replication-layer#how-leases-are-transferred-from-a-dead-node" target="_blank" rel="noopener">依旧是通过 Raft 选举来实现的</a>。</p><p>当然，对于 meta 表，就不能像上面那样去做了。否则会导致循环依赖。对于 meta 表自己的 Lease，是通过 expiration time 来维护的。此时：</p><ol><li>如果一个节点依旧能够不停地 propose，那么它就能够一直续期 lease</li><li>否则，下一个尝试对这个 range 读写的 node 会成为 leader</li></ol><h1 id="Learner-read"><a href="#Learner-read" class="headerlink" title="Learner read"></a>Learner read</h1><h2 id="关于读"><a href="#关于读" class="headerlink" title="关于读"></a>关于读</h2><p>Raft 的一个问题就是读的时候无论是 Leader 还是 Follower 都需要 Read Index。比如，对 Leader 而言，它需要问 quorum 自己当前是否还是 Leader。TiKV 一般 Leader Read 提供两种方案，第一种是 read_local，也就是 Leader 节点上 lease 读，另一种是 read_index，也就是在不确定自己是否还是 Leader 的时候，进行 ReadIndex。</p><h2 id="Follower-Read"><a href="#Follower-Read" class="headerlink" title="Follower Read"></a>Follower Read</h2><p>TiDB 支持<a href="https://docs.pingcap.com/zh/tidb/stable/follower-read" target="_blank" rel="noopener">多种读取方式</a>，例如最近 Peer、Leader、Follower、Learner、自适应等多种模式，这些依赖于 Follower Read，在这之前都需要从 Raft Leader 读取。</p><p>不同于 ParallelRaft 和 MultiPaxos 的部分实现，TiKV 会串行地 apply raft log。</p><ol><li>这样的好处是，更容易通过 Read Index 实现 Follower Read 了。TiKV 在这一点上行得通，主要还是因为它的数据和 Raft Group 绑定的缘故。也就是以 scheduler 为代价来实现 Partitioning，从而减少各个 Raft Group 的压力。</li><li>这样的坏处是，引入了更强的全序关系。因为我们实现共识层的目的是服务上层的事务层，而事务层本身就允许并行事务以任意的顺序被提交，所以在共识层排成强序，实际上是多余的。当然，Partitioning 分成多个 Raft Group 能减少这部分的强序关系的数量。</li></ol><p>总的来说，TiKV 实现的 Follower Read，是通常被称作 <a href="https://www.cockroachlabs.com/docs/v23.2/follower-reads" target="_blank" rel="noopener">Strong Follower Read</a> 的类型。</p><h2 id="Non-stale-Read"><a href="#Non-stale-Read" class="headerlink" title="Non-stale Read"></a>Non-stale Read</h2><p>从共识层上来讲，强一致或者说线性一致有明确的定义。<a href="https://www.cockroachlabs.com/docs/v23.2/architecture/transaction-layer" target="_blank" rel="noopener">CRDB</a>将其“推广”到事务层之上，也就是归结到所谓的 non-stale 读上。因为 CRDB 只有 leaseholder 也就是所谓的 Leader 能服务读请求。不过还是推广到有 Follower Read 的场景下。此时，在任意的节点上：</p><ol><li>在 SERIALIZABLE 下，读事务应该能看到在<strong>它之前</strong>已经提交了的所有的写事务。这里的“<strong>它之前</strong>”我理解取决于如何给事务排序，但至少要在事务的第一个读之前。比如 Percolator 模型中就是 start_ts。</li><li>在 RC 级别上，事务中的每一个读语句能看到在<strong>它之前</strong>已经提交了的所有的写事务。</li></ol><h2 id="Stale-Read"><a href="#Stale-Read" class="headerlink" title="Stale Read"></a>Stale Read</h2><p>Stale Read 的作用是让读请求被分配到任一节点上，从而避免某热点机器，或者跨数据中心的 read index 请求产生的延迟。</p><p>这样的事务只能服务读，并且 staleness 也是需要被严格控制的。</p><p>Stale Read 是读 ts 时间点上所有已提交事务的旧数据。因为读不到最新的写入，所以不是强一致的。但它仍然保持有<a href="https://docs.pingcap.com/zh/tidb/stable/stale-read" target="_blank" rel="noopener">全局事务记录一致性</a>，并且不破坏隔离级别。我理解可能就是所谓的 Time travel query。</p><p>一般提供两种：</p><ol><li>精确时间戳</li><li>有界时间<br> 在给定的时间范围内选择一个合适的时间戳，该时间戳能保证所访问的副本上不存在开始于这个时间戳之前且还没有提交的相关事务，即能保证所访问的可用副本上执行读取操作而且不会被阻塞。<br> 因此这样的读取方式能提高可用性。</li></ol><p>使用 Stale Read 需要 NTP 的支持。</p><p>所以它并不是“弱一致读”，无论从哪一个节点返回的结果都是一致的，不会出现 A 返回 1000 笔记录，而 B 返回 1111 笔记录的情况。</p><h2 id="Learner-Read"><a href="#Learner-Read" class="headerlink" title="Learner Read"></a>Learner Read</h2><p>不同于 Follower，Learner 不是 Voter，没有选举功能。所以 Learner Read 和 Follower Read 有不同。<br>Learner Read 在 TiFlash 场景下更为丰富，在 TiFlash 章节讨论。</p><h3 id="Learner-Read-和-commit-ts"><a href="#Learner-Read-和-commit-ts" class="headerlink" title="Learner Read 和 commit_ts"></a>Learner Read 和 commit_ts</h3><p>即使有在 read index 的时候推进 max ts 的机制，依然会发生在收到 Leader 关于带有 read_ts 的 Read Index 请求的回复后，在 Wait Index 超过返回的 applied_index 之后，看到具有更小的 commit_ts 的提交。但这种情况并不会导致问题，因为在 applied_index 之前，我们至少可以看到对应的锁。</p><p>比如 read_ts 是 10，返回了 applied_index 是 1000。那么在 apply 到 1001 时，可能它对应了一个 commit_ts 为 5 的事务。这里可以参考<a href="/2025/01/18/percolator-2/">我对并发事务的讨论</a>。</p><h2 id="Read-index"><a href="#Read-index" class="headerlink" title="Read index"></a>Read index</h2><p>TiFlash 自己给自己发送一个 ReadIndex Command，后者会触发一个 ReadIndex Message。为什么要这么做呢？因为走 ReadIndex Command 的链路才是完整的，否则会丢掉包括要求 Concurrency manager 推高 max_ts 的部分。</p><ol><li>对 Leader，会检查 Lease 并续约，之后再 Read</li><li>对 Follower，会推动 Raft 发送 RaftIndex 类型的 RaftMessage 给 Leader。这个 RaftMessage 包含一个 raft_cmdpb::ReadIndexRequest 作为 entry.data。</li></ol><p>在处理 ReadIndex RaftMessage 时候，会推进 maxts 并且返回 memlock。</p><p>具体来说：</p><ol><li>根据 read tso 和 range 构造一个 kvrpcpb::ReadIndexRequest</li><li>ReadIndex 接受这个 kvrpcpb::ReadIndexRequest</li><li>创建一个 raft_cmdpb::Request<br> 其类型为 CmdType::ReadIndex。将 kvrpcpb::ReadIndexRequest 中的数据移动到 raft_cmdpb::Request 中。</li><li>通过 RaftRouter 发送这个请求，并等待回调。</li></ol><p>这里 ReadIndexRequest 中传入的 start_ts 会间接推高 min_commit_ts。其原理是一个事务涉及多个 key，则这些 key 依次 prewrite 的时候，后面 prewrite 的 key 的 min_commit_ts 会因为 max_ts 变得更高，尽管前面 key 的 min_commit_ts 是一直不变的。最终事务提交的 ts 是所有的 key 的 min_commit_ts 取最大。</p><h3 id="Batch-read-index"><a href="#Batch-read-index" class="headerlink" title="Batch read index"></a>Batch read index</h3><ol><li>在同一个查询中，如果一个 Region 上已经被做过 read index，则复用</li><li>在同一个 Region 上的每个 Read index 请求前，首先查询历史记录，看看是否有对应 ts 的记录可以复用</li><li>同一个 Region 上的多个 Read index 请求组成一个 batch，用其中的最大的 ts 去请求 TiKV leader。如果发现有 memlock，则返回这个 lock。这说明这个 ts 上有 lock，而其他的 ts 则不确定需要重试。如果返回没有 lock 则使用最大的 index 来重试</li></ol><p>注意，没有 memlock 并不代表没有 lock。一个 key 上是否有 lock，还需要读 lock cf 来判断。memlock 的引入是 Async Commit 导致的。memlock 指的是在某个短暂阶段，事务层上有一些锁在内存中，还没有写到 raftstore。</p><h2 id="Remote-Read-机制"><a href="#Remote-Read-机制" class="headerlink" title="Remote Read 机制"></a>Remote Read 机制</h2><p>TiFlash 中存在 Remote Read 机制，在 BatchCop 的 prepare 阶段，会分析哪些 Region 是可以本地读的，哪些 Region 是需要从其他 TiFlash 读的。在存算分离版本的 TiFlash 中，CN 通常都需要进行 Remote Read 从对应的 WN 读取最新的数据。</p><p>在 Remote Read 的过程中，也会触发 Resolve Lock 机制，从而推动 TiKV 去判断事务提交与否。这个通常对应了 Cop 请求的发送和处理。Remote Read 请求可能最终还是发送给自己。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;TiFlash 的整个 replication 机制建立在 Raft learner 协议之上。&lt;/p&gt;
&lt;p&gt;在本文中介绍 Raft learner 相关的 case 以及优化，主要包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;涉及 Learner 的活性问题&lt;/li&gt;
&lt;li&gt;Learner Snapshot&lt;/li&gt;
&lt;li&gt;Learner Read&lt;ul&gt;
&lt;li&gt;作为前置，还会说明 Leader 的 Lease Read&lt;/li&gt;
&lt;li&gt;作为直接的扩展，还会说明 Stale Read&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="raft" scheme="http://www.calvinneo.com/tags/raft/"/>
    
    <category term="一致性" scheme="http://www.calvinneo.com/tags/一致性/"/>
    
  </entry>
  
  <entry>
    <title>TiFlash 的快速新建副本(FAP)特性</title>
    <link href="http://www.calvinneo.com/2025/01/19/on-fap/"/>
    <id>http://www.calvinneo.com/2025/01/19/on-fap/</id>
    <published>2025-01-19T03:57:20.000Z</published>
    <updated>2025-02-09T07:51:46.606Z</updated>
    
    <content type="html"><![CDATA[<p>目前 FAP 特性在 TiDB Serverless 上已经发布，减少了新建副本的 CPU 和内存开销，提高了吞吐量。在大部分情况下，还能</p><a id="more"></a><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><ol><li>复用 TiFlash 行转列的结果。减少 TiKV 生成、传输和 TiFlash 接收、转换 Snapshot 的开销。<br> 在测试中，发现能够减少 96% 的 CPU 开销和 20% 的内存开销。<br> 如果提升调度的 limiter，能够大幅提高吞吐量，体现为添加副本总时间的减少。但该增长不是线性的，也取决于 TiFlash 侧线程池的大小，以及串行 ingest 的开销。<br> 需要注意，因为 Region 和 Raft Group 绑定，导致 FAP 必须等待 apply Confchange 之后的 Checkpoint，所以对于单个小 Region 来说，可能要花费更长的时间来处理。<br> 目前，TiFlash 上会有一些自建索引，FAP 也会避免这些自建索引被重复构建。</li><li>利用如 S3 的特性，减少跨 Region 通信。</li><li>提高副本迁移，特别是单副本迁移的效率。</li><li>在扩容场景下，新节点可能因为处理全量 Snapshot 更慢，导致进度落后，从而进一步触发全量 Snapshot。此时新机器无法处理被 dispatch 过来的请求。</li></ol><h2 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h2><h3 id="实现内容"><a href="#实现内容" class="headerlink" title="实现内容"></a>实现内容</h3><ol><li>使用 PageStorage 替换 RaftEngine。这样使得 Raft、KVStore 和 DeltaTree 数据都一起被存到同一个 checkpoint 里面，保证原子性和一致性。</li><li>副本选择和由 Learner 管理的副本创建。用来快速扩容的 TiFlash Checkpoint，必须要比扩容对应的 confchange log entry 要新。这是因为 TiKV 通过一个 Snapshot 来帮助新 node 追日志，而这个 Snapshot 必然在 confchange 后产生。如果接受一个更早的 Checkpoint，那么就要确保 raft 能够给新 peer 发送 confchange 前的日志。即使能，这也意味着新 peer 要处理添加自己的 confchange cmd。即使通过忽略等方案处理，那么在这之前的 batch split cmd 就需要伪装成生成 Checkpoint 的那个 peer，并将这个 region 重新切开（涉及一些行转列和写盘）。而如果与此同时，batch split 得到的某个 split 的最新版本又通过正常途径调度过来，并且在 apply snapshot，那么这里就可能产生 region overlap 导致的数据问题。可以看出，因为违反了 TiKV 的约束，所以产生了很多的潜在问题。</li><li>注入数据。需要注意，原有的 TiKV 的通过 Snapshot 初始化副本的流程需要重新走一遍。</li><li>对旧版本数据的清理。</li></ol><h3 id="Learner-Snapshot"><a href="#Learner-Snapshot" class="headerlink" title="Learner Snapshot"></a>Learner Snapshot</h3><p>这个 feature 类似于 Learner Snapshot，其实后续我们也希望在 TiKV 实现 Learner Snapshot。目前方案的原因是：</p><ol><li>TiKV 主要需要该 Feature 来避免跨地区的 Snapshot 复制，而 TiFlash 需要该 Feature 实现异构的 Snapshot，侧重点上有所不同。</li><li>该 feature 需要在 TiKV 或者 PD 等组件中实现一定的调度机制。所以 FAP 实际可以视为一个部分的实现，后续有可能进行推广。届时 FAP 的 phase 1 过程就有可能被移动到 prehandle snapshot 中处理了。</li><li>Follower Snapshot 有可能会失败，例如 Follower 节点实际上做不了该 Snapshot。此时 Snapshot 依然会由 Leader 来处理。目前 TiKV 的模型还不支持这种模式。</li></ol><h3 id="从-FAP-的-fallback"><a href="#从-FAP-的-fallback" class="headerlink" title="从 FAP 的 fallback"></a>从 FAP 的 fallback</h3><p>FAP 可以实现从 FAP Snapshot 到 Regular Snapshot 的 fallback。具体来说，如果构建失败后，FAP 就会退出，此时对 MsgAppend 的屏蔽就会被去掉，从而走到 Regular Snapshot 的逻辑中。而 FAP Snapshot 在构建完后，会发送一个 meta 等同于 Regular Snapshot 的 Snapshot，只是不包含数据而已。在 Prehandle Snapshot 的逻辑中，会先检查是否存在 FAP Snapshot 并且它的 <code>(snapshot_index, snapshot_term)</code> 是否 meta 中匹配。如果不匹配，说明这是后来的一个 Regular Snapshot，需要覆盖 FAP Snapshot。如果匹配，那么无论这个 Snapshot 是否包含数据，都是和 FAP Snapshot 等价的。</p><h3 id="pitfall"><a href="#pitfall" class="headerlink" title="pitfall"></a>pitfall</h3><p>FAP 的复杂的点：</p><ul><li>如果一个 FAP Snapshot 已经被发送了，那么就需要等待它被处理完毕</li><li>如果需要发送 msgAppend 时候，Leader 的日志被 truncate 掉了，那么就需要直接发送 msgSnapshot</li><li>如果收到一个 msgSnapshot，需要判断它是 Leader 发过来的要直接被屏蔽的 msgSnapshot，还是 FAP 自己的 snapshot。这里的办法就是如果 FAP snapshot 发出去了，那么无论是哪一种 Snapshot，都不再拒绝了。在 prehandle 的时候，会比较 FAP snapshot 的 (index, term) 和 Raft Snapshot 的 (index, term)，只要不一致，就 abort 掉 FAP snapshot 的处理并清理掉。</li><li>使用 <code>inited_or_fallback</code> 维护一个内存中的状态，如果 fallback，或者 apply snapshot，或者看到 <code>RegionChangeEvent::Create</code> 事件，或者通过 <code>is_initialized</code> 读取 meta 信息检查到副本在 raftstore 中已经创建了，则跳过 fap。特别是最后一点很重要，因为 <code>apply_snapshot</code> 这个函数调用和 Proxy 是异步的，所以 <code>apply_snapshot</code> 之后，<code>is_initialized</code> 返回 true 表示 snapshot 已经 apply 了，只等待 ingest 数据。这个时候，就需要将 <code>inited_or_fallback</code> 设置为 true 才行，不然会导致 fap snapshot 覆盖。但因为我们在 <code>apply_snapshot</code> 的时候没有 hook，所以只能随时检测。</li></ul><h2 id="FAP-对-UniPS-的改造"><a href="#FAP-对-UniPS-的改造" class="headerlink" title="FAP 对 UniPS 的改造"></a>FAP 对 UniPS 的改造</h2><ol><li>Checkpoint 中不仅需要上传 Stable 数据，也要上传 Delta 和 Raft Log 数据<br> 原因是必须要上传对应的 Raft Meta 数据才能构建出副本。由此，必须要上传 KVStore 和 Delta 层。此时唯一的可选项就是 applied_index 之后的没有被 apply 的日志了。目前是同样选择上传的，原因是代价可控。并且上传了 Raft Log 后，能够避免新建立的副本从 TiKV Leader 处继续下载这些 Log，从而造成新一轮的落后。<br> 理论上，上传 Delta 数据后，CN 可以从 S3 去读取这些 Delta 数据，从而避免重复请求 WN。我们现在没有做主要是发现 Delta 层的数据流处理没有给 TiFlash 产生太大的性能开销。<br> 在上传 Raft Log 和 Meta 数据后，甚至可以在 CN 上处理 Learner Read 强一致读。但这可能得不偿失，因为读 S3 的开销可能更大。并且我们还是要在 CN 上实现一套 Read Index 的。<br> 相比之下 Snowflake 将事务层移动到 Cloud Service 层上，从而使得可以直接从 S3 读存储层。但可能它们的写入场景应该没有 TiFlash 频繁。</li><li>S3 文件的读写<br> 过去 UniPS 使用了 Lazy 的方式处理 FAP 添加得到的 Page，在 write 的时候只是记录远程的 Page 在 S3 blob file 中的 offset 和 size，在第一次读取的时候，才将这些 Page 下载下来。但在上传 Delta 和 Raft 数据后，需要处理的 Page 数量明显变多了。如果对于每一个 Page 调用一次 GetObject API 花费几十到几百毫秒下载，代价对于可能有几万 Page 的 Region 来说是无法承受的。<br> 这里通过 Prefetch + Reuse 的方式可以优化掉存在顺序读的部分，而顺序读的场景是占大多数的。因为上传 Checkpoint 的时候，会对所有的 Page 按照 PageID 的顺序进行 Compaction，以避免 S3 的空间放大。因此只要按照 page id 的顺序遍历，实际上就是顺序读写 blob file，就可以用上优化。<br> 对于零散的小写入，我们是利用了操作系统的 page cache 来避免大量小 io。</li><li>S3 文件的锁<br> 为了避免 FAP 引用的 blob file 被 GC，引入了 S3 文件锁。这里的做法是对于每一个 blob file，都可能存在多个 <code>${data_file_name}.lock_${store_id}</code> 文件，表示这个 blob file 被哪些 store 引用。只有一个 blob file 上没有关联 lock 文件的时候，才会清理掉。</li></ol><h1 id="个人感悟"><a href="#个人感悟" class="headerlink" title="个人感悟"></a>个人感悟</h1><h2 id="兼容性"><a href="#兼容性" class="headerlink" title="兼容性"></a>兼容性</h2><p>FAP 的兼容问题，主要是在自己构造 FAP Snapshot 上。因为构造 Snapshot 的逻辑只有 TiKV Leader 上有。</p><h2 id="上线"><a href="#上线" class="headerlink" title="上线"></a>上线</h2><p>上线过程中的逃逸路径的设计非常重要。在 TiFlash 存算分离上线的过程中，使用了双写的方式来避免影响生产环境。在一个月确认稳定后，正式开启这个特性。</p><p>FAP 的场景下，采用的方法是只对一个 TiFlash replica 开启 FAP 特性。并且我们在 CN 上增加了一个 blocklist 功能，如果这个节点因为 FAP 损坏，则可以立即设置 blocklist 将它屏蔽。此时，至少还有一个节点可以服务。而在过去，一个节点如果宕机，其实在它上面的查询会死掉，从而影响可用性。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;目前 FAP 特性在 TiDB Serverless 上已经发布，减少了新建副本的 CPU 和内存开销，提高了吞吐量。在大部分情况下，还能&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>关于 Percolator 的进一步论述</title>
    <link href="http://www.calvinneo.com/2025/01/18/percolator-2/"/>
    <id>http://www.calvinneo.com/2025/01/18/percolator-2/</id>
    <published>2025-01-18T03:57:20.000Z</published>
    <updated>2025-01-18T16:59:15.825Z</updated>
    
    <content type="html"><![CDATA[<p>将 <a href="/2023/07/22/tikv-tidb-thought/">关于 TiKV、TiDB、TiFlash 的一些思考</a>中关于 Percolator 事务的部分独立出来。</p><a id="more"></a><h1 id="Percolator-的性能优化"><a href="#Percolator-的性能优化" class="headerlink" title="Percolator 的性能优化"></a>Percolator 的性能优化</h1><h2 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h2><p>Percolator 主要定义了事务提交模型，因此有一些不够完备的地方：</p><ul><li>对于提交前的行为没有作规定<ul><li>Modify Set 的储存方式</li><li>Snapshot Isolation Read 的实现方式，当然 SI Read 一般都是在 Snapshot 上基于 MVCC 实现的</li></ul></li><li>对于悲观事务的支持</li></ul><p>在性能上，也有一些缺点：</p><ul><li>依赖一个 BigTable 类似的一致性 KVStore 作为底座。容易产生跨节点的分布式事务。这种情况下，Percolator 也是 2PC 的，任何一个参与节点的 failure 或者 jitter 都会影响事务提交的性能。</li><li>乐观事务，回滚开销大。</li><li>依赖一个全局单点生成时间戳为事务定序。</li></ul><h2 id="加锁的时机"><a href="#加锁的时机" class="headerlink" title="加锁的时机"></a>加锁的时机</h2><p>无论是悲观锁还是乐观锁，都面临加锁时机的选取。</p><p>在提交时加锁存在下面的问题：</p><ol><li>乐观锁的问题</li><li>因为整个事务需要缓存在内存中，所以大事务面临 OOM</li></ol><p>在 DML 时加锁存在下面的问题：</p><ol><li>每写一个 key 都要和 TiKV 通讯一次</li><li>多次对同一个 key 的 prewrite 无法确认先后（网络可能被任意延迟）</li><li>对 TiFlash 而言，因为列需要按照 commit_ts 排序，所以最好等到 commit 之后再行转列，而 DML 加锁意味着 DML 阶段 prewrite，那么在 DML 阶段就可以行转列了</li></ol><h2 id="Percolator-事务和共识层乱序"><a href="#Percolator-事务和共识层乱序" class="headerlink" title="Percolator 事务和共识层乱序"></a>Percolator 事务和共识层乱序</h2><p>在什么程度上共识层可以乱序呢？我的结论是：</p><ol><li>跨 Region 情况下会破坏线性一致读，并且从事务层修正的难度比较大，可能引入很长的等待</li><li>单 Region 上，如果保证 Lock 和 Write 的全局序，但只在发现事务 A 的第一个 commit 的时候，将事务相关的所有的 Default 写入，这种情况应该是可以的。对于较为基础的 case 我有 tla 证明<br> 根据具体实现，需要落盘 Default 和 Lock 是一起的，比如先落盘 Lock 再落盘 Default。可以不用原子落盘两个 cf。</li></ol><h2 id="Async-Commit"><a href="#Async-Commit" class="headerlink" title="Async Commit"></a>Async Commit</h2><p>Async Commit 的核心思想是：</p><ul><li>在 Prewrite 阶段完成后，不需要等待所有键都被确认提交。</li><li>Primary Key 的提交操作即被视为事务完成，其它 Secondary Key 的提交可以异步完成。</li></ul><p>这使得事务提交延迟主要取决于 Prewrite 的耗时，而不是整个 2PC 流程。</p><p>实现方式是在每个 key 的 lock 中声明一个 min_commit_ts，表示事务不会在这个之前提交。后续的读取可能会继续推高 min_commit_ts。当事务提交时，需要选择所有 min_commit_ts 中最大的一个作为 commit_ts。</p><p>因此，在这个优化后，不同事务的 commit_ts 可能相同，但是 start_ts 依然是不相同的。</p><h2 id="Bypass-lock-机制"><a href="#Bypass-lock-机制" class="headerlink" title="Bypass lock 机制"></a>Bypass lock 机制</h2><p>这是 Learner read 层的优化。<br>TiFlash 存在 remote read 的机制。在第一次遇到 lock 的时候，会由 client-c 去 resolve lock。此时，会有几种情况：</p><ol><li>事务已经 commit 了，并且 commit_ts 大于 read_ts</li><li>事务还没有 commit，但是 min_commit_ts 大于 read_ts</li><li>其他情况</li></ol><p>对于第一、二种情况，我们不应该读到这个锁对应的数据。它们都保证了事务已经或者最终要以高于 read_ts 的 ts 来提交。因此，既然这个 lock 对应的写入是不需要对 read_ts 的读可见的，因此在下一次读的时候，就可以 bypass 掉这个 lock，而不需要等待它们的 commit 了。</p><h2 id="Read-through-lock-机制"><a href="#Read-through-lock-机制" class="headerlink" title="Read through lock 机制"></a>Read through lock 机制</h2><p>这是一个事务层的优化。<br>Read through lock 特性指的是当确定某个事务可以被 commit 的时候，跳过 resolve lock 的过程，而直接读。而这锁最终会被下一次写同一个 key 的时候 resolve。<br>具体做法是，它首先是事务上一个 secondary key 的锁，我们在通过 secondary lock 去查询 PK 的 lock 的时候，会发现 PK 上的事务提交了。因此，这个事务一定是提交了的，所以可以 read through lock。<br>这个“lazy”地 resolve lock 的方式也被用在了大事务的支持上。</p><h1 id="基于共识层之上的事务"><a href="#基于共识层之上的事务" class="headerlink" title="基于共识层之上的事务"></a>基于共识层之上的事务</h1><h2 id="事务的“序”"><a href="#事务的“序”" class="headerlink" title="事务的“序”"></a>事务的“序”</h2><h3 id="几个问题"><a href="#几个问题" class="headerlink" title="几个问题"></a>几个问题</h3><p>不妨考虑几个问题：</p><ul><li>是不是 start_ts 越大的事务，体现在 log index 上更大？commit_ts 呢？</li><li>两个事务可以有相同的 start_ts 么？</li><li>两个事务可以有相同的 commit_ts 么？</li><li>假设一个事务 [ST1, CT1] 准备提交了，它可以看到另一个事务 [ST2, ?]，并且 ST2 小于 ST1。请问此时它是否可以立即提交？</li></ul><p>答案：</p><ul><li>不一定<br>  参考下面的双重定序</li><li>不可以</li><li>可以<br>  比如 Async Commit 特性就会产生这样的现象。</li><li>不能<br>  参考“一个两难问题”</li></ul><h3 id="一个两难问题"><a href="#一个两难问题" class="headerlink" title="一个两难问题"></a>一个两难问题</h3><blockquote><p>假设一个事务 [ST1, CT1] 准备提交了，它可以看到另一个事务 [ST2, ?]，并且 ST2 小于 ST1。请问此时它是否可以立即提交？</p></blockquote><p>答案是不行，因为不知道 ST2 这个事务的 Commit TS 是多少。在一个异步系统中，这个消息总是可以被任意延迟的。</p><p>在 Percolator 中的解决方式是：ST2 意味着会读到一个 Lock，所以 ST1 这个事务要先 Resolve Lock。</p><p>这个问题，就展现了事务序和共识序之间的相互关联。这就如同之前全序广播中论述的一样，核心是能够确保消息被不重不漏地编号，例如 TCP 的 seq 一样。共识系统通过日志的全序性来保障了这一点。</p><h3 id="共识层和事务层的关系"><a href="#共识层和事务层的关系" class="headerlink" title="共识层和事务层的关系"></a>共识层和事务层的关系</h3><p>Percolator 事务提交模型中，commit_ts(R) &lt; start_ts(T) 的事务 R 对事务 T 可⻅。不满⾜该关系的事务为并发事务，并发事务如果访问相同的 key 将会导致其中⼀个事务会碰到 Lock ⽽回滚。因此，Percolator 本质上是一个 2PL 协议，因为一个事务会在 Prewrite 阶段尝试获得自己所有需要的锁。start_ts 此时被用来决议这些锁的 order。</p><p>Raft 的 Read Index 模型中，一个读请求需要等到 applied_index 大于等于 read_index 时，才能读取数据。<strong>但并不保证是否能读到 <code>applied_index = x + 1</code> 时的数据</strong>。实际上无论是否读到，都不违背强一致读的原则。因为如果一个读 A 能读到 applied_index = x + 1，而另一个读 B happen after 读 A，那么读 B 一定会读到 <code>applied_index &gt;= x + 1</code> 的数据。</p><p>TiKV 的共识层在事务层之下。在事务 Commit 之前的很多数据也会被复制到多数节点上，这产生了一些写放大。但也需要注意其带来的好处：</p><ol><li>共识层实际为 Percolator 提供了类似 BigTable 的一致性存储保障。<br> 首先提供了外部一致性。<br> 然后提供了 PUT default/PUT lock 和 PUT write/DEL lock 的原子性写入。<br> 当然，这里要先读后写，可能会有 Write Skew。</li><li>共识层本身也可以作为一个 Raw KV 对外服务。</li><li>共识层参与定序。这个在后面介绍。</li><li>多个 Raft Group 组成的共识层提高了并发能力。</li><li>Lock 的存在性和⼀致性由该⾏所处的 Raft Group 保障。</li><li>事务提交后，会写⼊ Write 并删除 Lock，其原⼦性由 Raft Write Batch 保障。</li><li>共识层提供了全序广播语义。<br> “在 xx 之前，一定不会有别的 Lock 和 Write 了”</li></ol><p>当然这也存在一个 argue 点，因为 Raft Log 本身也是 total order 的。虽然我们目前不是全局一个 Raft Group 的，但看起来会有一些冗余，在后面会讨论。<br>特别地，在 CDC 服务和 TiFlash 中，实际上不会处理未 Commit 的数据。</p><h4 id="双重定序"><a href="#双重定序" class="headerlink" title="双重定序"></a>双重定序</h4><p>事务层的实现中，为了满足隔离性，通常会给事务分配 id 来表示相互依赖的事务之间的偏序关系。TiDB 中使用了 TSO，Spanner 中使用了 TrueTime，CRDB 中使用了 HLC。<br>共识层的实现中，为了实现容灾和高可用，使用共识算法在各个 RSM 之间复制日志，这些日志为全序关系，RSM 可以应用这个全序关系确保线性一致。</p><p>事务层生成 TSO 和共识层生成 Log 两个行为：</p><ol><li>不是原子的</li><li>也不构成全序关系<br> 实际上也没必要，两个不相交的事务按照事务序本来可以并行 Commit 的，但因为要写到共识层，必须又要排出一个全序关系来。</li><li>甚至一个事务的 commit_ts （相比某个特定事务）更小，而 index 更大<br> 下面会展示这种情况，并详细阐述。</li></ol><p>总而言之：</p><ul><li>Percolator 协议保证了事务层能够生成一个特定的排序，并且按照它的二阶段方式写入到共识层</li><li>共识层保证了所有的副本都会应用该特定排序</li></ul><h4 id="共识层为事务层提供帮助"><a href="#共识层为事务层提供帮助" class="headerlink" title="共识层为事务层提供帮助"></a>共识层为事务层提供帮助</h4><p>目前 TiKV 通过一个 pd 分配一个全局的 tso 来作为事务的 start_ts 和 commit_ts，所以它们之间彼此构成全序关系。当然，实际上不同的事务可能具有同一个 commit_ts，但这并不影响下面的讨论。通过 start_ts 和 commit_ts 可以构建有依赖的事务之间偏序关系，也可以用来判断事务是否是 concurrent 的。如果在单个节点上串行地 commit 这些事务，则面临问题：</p><ol><li>整个系统毫无并行度<br> 这个应该算是 MultiRaft 的一个 bonus，正如后面讲的，如果没有 MultiRaft，同样可以做 partitioning。<br> 因此，TiKV 在多个线性一致的存储(Region)上储存这些事务，它保证了每个事务在每个 Region 上都遵循了 start_ts 和 commit_ts 所 imply 的顺序，也 Percolator 那一套。这样尽管各个 Region 之间是并发的了，但只要 Region 内遵循这个 order 就行了。<blockquote><p>当然，这个切分也未必是按照 Region 来，比如 CDC 会使用表来切分。无论按照哪种方式来切分，我觉得一个实现的要点是每个 shard 在调度上是不可以再分的了。比如一个 Region 的一部分数据在 store 1 上，另一部分数据在 store 2 上，这样做实际上会导致无论在 store 1 和 store 2 上都很难独立构建出该 Region 上数据的全序关系，比如 store 1 如果不和 store 2 交互，那么就很难知道 store 2 上还有没有 happen before 它的事务了。比如说，如果两个 store 上 apply 这个 Region 的 log 的进度不一样。</p></blockquote></li><li>如何判断某个 tso 之前还有没有其他 Lock 或者 Write？<br> 因此，读事务会在取得 start_ts 后，再通过 ReadIndex 请求一下 Region Leader 上的 commit_index。那么假设在这之前 Region 上有写入任意的 Lock 或者 Write，都能被 ReadIndex 扫到。这样就保证了读事务能看到 start_ts 之前的所有修改。至于 start_ts 之后的也有 Lock 可以帮忙。<br> 同样考虑一个<a href="/2017/09/20/transaction/">Snapshot Isolation(SI)/一个两难问题</a>，这里不再详细展开具体内容。但 ReadIndex 提供了一个保证，就是截止到 read_index，这个 Region 上到底有没有 Write，是很确定的。我理解这实际上就是一种全序广播了。破坏这种全序广播可能会有严重后果，比如如果将 Write 乱序到 Lock 前面，则违反了 Percolator 事务的约束。我们实际上也没办法很好的处理，在“跨 Region 提交事务”中，就构造出了这样的场景。</li></ol><p>此外，对于并发事务，共识层也会对它们之间排出一个串行的顺序，比如两个并发的事务不能同时 Commit，而要等到 Log 按序 apply 而这可能有点过强。诸如 ParallelRaft 或者 MultiPaxos 的算法允许并行 apply，可以解决此问题，但会导致 Leader 和 Follower 之间的 apply order 难以统一，从而无法实现 Follower Read。</p><h4 id="共识层对并发事务的乱序"><a href="#共识层对并发事务的乱序" class="headerlink" title="共识层对并发事务的乱序"></a>共识层对并发事务的乱序</h4><p>刚才说过，共识层未必会按照事务序写入。这也很容易理解，因为取 start_ts 和 commit_ts 和真正写共识层不是原子的。<br>TiKV 事务在读取时，需要同时接收事务层和共识层的定序。为了满⾜线性⼀致读，需要⾸先带上 start_ts，发送⼀个 ReadIndexRequest 给对应的 Region，求出⼀个 applied_index。在实际实现中，start_ts 并⽆作⽤。<br>如下所示，Key a 和 Key b 属于两个事务。在事务提交前，可以看到或者得到的保证是：</p><ol><li>start_ts(a) &lt; commit_ts(a)</li><li>start_ts(b) &lt; commit_ts(b)</li><li>start_ts(a) &lt; start_ts(b)</li><li>并且这两个是并发事务，也就是说 commit_ts(a) &gt; start_ts(b)</li></ol><p>共识层的序至少保证了同一个 key 的 prewrite 在 commit 前面。</p><p>不妨假设 commit_ts 分别为 4 和 6，然后再假如以 (read_ts=7, read_index=202) 读取，如下所示。</p><ol><li>Key a：(start_ts: 1, applied_index: 100), (commit_ts: 4, applied_index: 210）</li><li>Key b：(start_ts: 3, applied_index: 101), (commit_ts: 6, applied_index: 200)</li></ol><p>从事务层上讲，Key a 和 Key b 的写入对 read_ts=7 的读取事务可见，从共识层上讲 applied_index 等于 read_index，或者超过它的的任意时刻都可以读了。因此，此时可能读到一个锁和 Key b（刚好 apply 到 read_index），或者读到 Key a 和 Key b（apply 超过 read_index 很多，比如到 211 了）。前者需要 ResolveLock，实际上导致以新的 read_index 来重新读取。</p><p>反过来讲，如果共识层给出下面的顺序，我们看到了中间的 a 或者 b 上有锁。因为这两个事务是并发事务，所以这也是 OK 的</p><ol><li>Key a：(start_ts: 1, applied_index: 100), (commit_ts: 4, applied_index: 200）</li><li>Key b：(start_ts: 3, applied_index: 101), (commit_ts: 6, applied_index: 210)</li></ol><p><img src="/img/ti-arch-thought/consensus_order_txn_order.png"></p><p>可以看到，尽管将事务拆到了 N 个线性一致的存储上执行，并且这些存储可能对并发事务任意定序，但最终读到的结果还是满足了线性一致，以及事务隔离层的要求的。</p><h4 id="并发事务的共识序"><a href="#并发事务的共识序" class="headerlink" title="并发事务的共识序"></a>并发事务的共识序</h4><p>并发事务 1 和 2，假设 start_ts1 &lt; start_ts2 &lt; commit_ts1 &lt; commit_ts2，那么两个事务彼此不可见，或者说是并发事务。假设这两个事务写入同一个 region，那么在 raft log entry 层面，完全可以出现 commit_ts1 对应的 raft log 的 index 更靠后，而 commit_ts2 对应的更靠前。比如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">index 10: Put Write CF commit_ts2</span><br><span class="line">index 11: Put Write CF commit_ts1</span><br></pre></td></tr></table></figure><h4 id="跨-Region-提交事务？"><a href="#跨-Region-提交事务？" class="headerlink" title="跨 Region 提交事务？"></a>跨 Region 提交事务？</h4><blockquote><p>能不能在看到第一个 write 记录时“提交”该事务的所有 key？</p></blockquote><p>这里的“提交”指的是写入下层存储，比如将 Default 写过去，但并不包含删除 Lock 等。</p><p>现在比如考虑两个事务，假设 a 在一个 region r1，b 和 c 在另一个 region r2 让：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">commit a(applied_index@r1=100), commit b(applied_index@r2=300), commit_ts=4</span><br><span class="line">                                commit c(applied_index@r2=200), commit_ts=1</span><br></pre></td></tr></table></figure><p>从事务层上来看，一定有读事务能看到 c，或者 a、b、c。现在如果看到 a 提交了，能不能跑到 b 的 region 上把 b 也提交了呢？我认为是不可以的，因为从共识层上来说，b 在 c 的后面被 commit 的，如果用 (start_ts &gt; 4, read_index = 250) 去读的话，可能读到 lock b，甚至可能连 lock b 也还没被写入，当然也有可能读到 b。但如果我们在 apply a 的 write 记录的时候发现了 a 被 write 了，就直接写 b 的 write 记录，那么就导致 b 一定在 c 前面就能被读到，实际上违反了共识层的序。</p><p>具体来说，不妨考虑 client 先后从 Learner 和 Leader 读：</p><ol><li>在 Learner 上，它使用 read_index = 250 读，但是因为 commit a 已经被 apply 的原因，所以它一定读到了 commit b。<br> 当然细究下来，因为 lock + default 是原子的，所以实际上 write 无法被正确执行。但这就是 orphan write key 的问题，之前在处理 multi rocks 的时候就解过，我觉得很复杂。在这个场景下，我觉得免不了要去进行等待。在异步系统中的等待，我觉得可以理解为是一种活性问题。</li><li>在 Leader 上，此时 Leader apply 到了 260，所以此时 Leader 上一定没有 commit b，这导致它读不到 commit b。</li></ol><p>这里线性一致读就被破坏了。反之，如果按共识序 commit，则不会有这种情况。具体就不展开了。</p><h4 id="单-Region-上提交事务？"><a href="#单-Region-上提交事务？" class="headerlink" title="单 Region 上提交事务？"></a>单 Region 上提交事务？</h4><blockquote><p>限定事务只在一个 Region 中发生，能不能在看到第一个 write 记录时“提交”该事务的所有 key？</p></blockquote><p>上述场景在单 Region 上无法构造，原因是单 Region 是串行的。</p><p>尽管“在看到第一个 write 记录时‘提交’该事务的所有 key”可能相当于让一部分 Write 被乱序，但这种乱序不是直接去把 Write 挪到 Lock 之前。比如说，因为 Percolator 的特性，单 Region 上的某个事务的 Prewrite 一定都在 Commit 前面。因此，就算在看到第一个 Write 时候，将该事务的所有 Default 都提前写到下层存储，也不至于提前到某个 Lock 前面。这样被写的 Key 始终有 Lock 保护，直到看到它对应的 Write。</p><p>而在多 Region 中不同 Region 可以说是完全异步的（不考虑 Split 等），那我就可以构造一个无比提前的 Write，让它失去 Lock 的保护。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;将 &lt;a href=&quot;/2023/07/22/tikv-tidb-thought/&quot;&gt;关于 TiKV、TiDB、TiFlash 的一些思考&lt;/a&gt;中关于 Percolator 事务的部分独立出来。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>TiKV 的资源管理模型</title>
    <link href="http://www.calvinneo.com/2025/01/12/tikv-resource-management/"/>
    <id>http://www.calvinneo.com/2025/01/12/tikv-resource-management/</id>
    <published>2025-01-12T03:57:20.000Z</published>
    <updated>2025-01-19T09:32:27.533Z</updated>
    
    <content type="html"><![CDATA[<p>介绍下 TiKV 的资源管理模型。</p><a id="more"></a><h1 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h1><p>TiKV 的内存包含下面的部分：</p><ul><li><p>Entry cache<br>  主要包含 cache 和 trace 两部分。</p><ul><li>cache 主要包含了 proposed 之后的 entry，可以看做是 raft-engine 的缓存。这个缓存可以被 leader 用来 append entries。</li><li>trace 主要包含了会被发送给 Apply 类，用来 apply 的 CachedEntries 对象。在 apply 结束后就可以被删除掉。</li></ul></li><li><p>Block cache</p></li><li><p>Raft Message<br>  主要是收到的 Raft Message 的占用内存。</p></li><li><p>Raft Entry<br>  主要是收到的 Raft Entry 占用的内存。Raft Message 被 step 之后，对应的内存就会给到 Raft Entry。</p></li><li><p>Peer FSM<br>  主要是和 Raft 的复制直接相关的。</p>  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">PeerMemoryTrace</span></span> &#123;</span><br><span class="line">    <span class="comment">/// `ReadOnly` memory usage in Raft groups.</span></span><br><span class="line">    <span class="keyword">pub</span> read_only: <span class="built_in">usize</span>,</span><br><span class="line">    <span class="comment">/// `Progress` memory usage in Raft groups.</span></span><br><span class="line">    <span class="keyword">pub</span> progress: <span class="built_in">usize</span>,</span><br><span class="line">    <span class="comment">/// `Proposal` memory usage for peers.</span></span><br><span class="line">    <span class="keyword">pub</span> proposals: <span class="built_in">usize</span>,</span><br><span class="line">    <span class="keyword">pub</span> rest: <span class="built_in">usize</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Apply FSM<br>  这里主要包括等待 apply 的 cmd 以及对应的 entry。</p></li><li><p>Coprocessor</p></li></ul><p>TiKV 默认的内存分配方案</p><ul><li>系统内存的 75% 作为 high water 水位<ul><li>Block cache 占用 45%</li><li>Write buffer 占用 20%</li></ul></li><li>剩下来的 25% 是留给操作系统的 Page Cache</li></ul><p>因为用户可以仅指定 Block cache 或者 write buffer 的期望大小，所以在计算 high water 的时候，会换算出各自的 high water 水位，选择其中的较大值。这个较大值不会大于内存的总大小，但可能大于 75%，这个时候会输出一个警告。</p><p>TiKV 使用 <code>procinfo::pid::statm_self()</code> 获取当前的系统内存。当超过 high water 后，有两个行动</p><ul><li>reject msg append<br>  计算 Raft Message + Raft Entry + Entry cache + Apply FSM 超过 reject_messages_on_memory_ratio 就会拒绝 raft message。</li><li>evict entry cache</li></ul><h1 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h1>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍下 TiKV 的资源管理模型。&lt;/p&gt;</summary>
    
    
    
    
    <category term="内存管理" scheme="http://www.calvinneo.com/tags/内存管理/"/>
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>桌游品鉴</title>
    <link href="http://www.calvinneo.com/2025/01/11/board-game/"/>
    <id>http://www.calvinneo.com/2025/01/11/board-game/</id>
    <published>2025-01-11T15:07:22.000Z</published>
    <updated>2025-02-09T04:40:57.094Z</updated>
    
    <content type="html"><![CDATA[<p>介绍玩过的一些桌游。大概是按照结识的顺序来的。</p><a id="more"></a><h1 id="桌游机制分类"><a href="#桌游机制分类" class="headerlink" title="桌游机制分类"></a>桌游机制分类</h1><h2 id="卡牌构筑"><a href="#卡牌构筑" class="headerlink" title="卡牌构筑"></a>卡牌构筑</h2><h2 id="工人放置"><a href="#工人放置" class="headerlink" title="工人放置"></a>工人放置</h2><h2 id="板图放置"><a href="#板图放置" class="headerlink" title="板图放置"></a>板图放置</h2><h2 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h2><h2 id="骰子驱动"><a href="#骰子驱动" class="headerlink" title="骰子驱动"></a>骰子驱动</h2><h2 id="拍卖"><a href="#拍卖" class="headerlink" title="拍卖"></a>拍卖</h2><h1 id="早期桌游"><a href="#早期桌游" class="headerlink" title="早期桌游"></a>早期桌游</h1><h2 id="UNO"><a href="#UNO" class="headerlink" title="UNO"></a>UNO</h2><p>UNO 村规很多，玩之前一定要说清楚。</p><h2 id="卡卡颂"><a href="#卡卡颂" class="headerlink" title="卡卡颂"></a>卡卡颂</h2><p>上本科开始玩的，当时是和菡姐、cjw 他们一起玩，算是桌游启蒙了。</p><h2 id="谁是大老板"><a href="#谁是大老板" class="headerlink" title="谁是大老板"></a>谁是大老板</h2><h2 id="璀璨宝石（宝石商人）"><a href="#璀璨宝石（宝石商人）" class="headerlink" title="璀璨宝石（宝石商人）"></a>璀璨宝石（宝石商人）</h2><p>应该是第一轻策德式了，经典入门。</p><h2 id="香料之路"><a href="#香料之路" class="headerlink" title="香料之路"></a>香料之路</h2><p>卡牌构筑的游戏。买香料，升级香料，最后用香料换巨人，比谁分数多。</p><h2 id="富饶之城"><a href="#富饶之城" class="headerlink" title="富饶之城"></a>富饶之城</h2><p>在早期是非常受欢迎的多人桌游。小偷非常关键。商人和建筑师很容易被搞。</p><h2 id="猜狐狸（帕瓦仪式）"><a href="#猜狐狸（帕瓦仪式）" class="headerlink" title="猜狐狸（帕瓦仪式）"></a>猜狐狸（帕瓦仪式）</h2><h2 id="僵尸商场"><a href="#僵尸商场" class="headerlink" title="僵尸商场"></a>僵尸商场</h2><p>交朋友的游戏。</p><h2 id="逃离亚特兰蒂斯"><a href="#逃离亚特兰蒂斯" class="headerlink" title="逃离亚特兰蒂斯"></a>逃离亚特兰蒂斯</h2><p>交朋友的游戏+1。</p><h2 id="大富翁世界之旅"><a href="#大富翁世界之旅" class="headerlink" title="大富翁世界之旅"></a>大富翁世界之旅</h2><h2 id="山屋惊魂（山中小屋）"><a href="#山屋惊魂（山中小屋）" class="headerlink" title="山屋惊魂（山中小屋）"></a>山屋惊魂（山中小屋）</h2><h2 id="逻辑对决"><a href="#逻辑对决" class="headerlink" title="逻辑对决"></a>逻辑对决</h2><p>两个人一个人拿一个草稿纸在那边吭哧吭哧算，看谁先算出来对手都是什么数字。大师买过一个，后面送给别人了。</p><h2 id="达芬奇密码"><a href="#达芬奇密码" class="headerlink" title="达芬奇密码"></a>达芬奇密码</h2><p>每个人摸一张牌，然后猜别人的是什么数字。白板是关键。</p><h2 id="画物语（只言片语）"><a href="#画物语（只言片语）" class="headerlink" title="画物语（只言片语）"></a>画物语（只言片语）</h2><h2 id="印加宝藏"><a href="#印加宝藏" class="headerlink" title="印加宝藏"></a>印加宝藏</h2><p>赌狗游戏。超过三个同样的就爆炸。</p><h2 id="卡坦岛"><a href="#卡坦岛" class="headerlink" title="卡坦岛"></a>卡坦岛</h2><p>首先推荐取消玩家之间交换资源的规定，让游戏更偏向于策略性，为此可以适当增加手牌上限，方便屯牌。</p><p>这个游戏不太适合人多，例如无扩展的 4 人或者有扩展的 6 人，因为抢不到码头，或者村庄点体验会很差，但卡坦岛又耗时比较长。</p><p>我觉得设计上有点瑕疵的是，资源的重要性明显有偏向。例如</p><ul><li>小麦会被用在抽卡、建村庄、升级上，属于全局最重要的资源。</li><li>树木和砖头被用在修路、建村庄上，属于前期必争资源。但这两个后期基本没有用。</li><li>羊被用在建村庄和抽卡上。</li><li>石头被用在升级和抽卡上。</li></ul><p>所以最优解一定是占有木头或者砖头的港口，占有最优势的麦田。</p><h2 id="犯人在跳舞"><a href="#犯人在跳舞" class="headerlink" title="犯人在跳舞"></a>犯人在跳舞</h2><h2 id="情书"><a href="#情书" class="headerlink" title="情书"></a>情书</h2><h2 id="电力公司"><a href="#电力公司" class="headerlink" title="电力公司"></a>电力公司</h2><p>一直在村。直到 25 年春节来了个 3 人，才发现这个游戏可以通过先后手卡资源、轮次卡到发不了电。</p><h2 id="瘟疫危机"><a href="#瘟疫危机" class="headerlink" title="瘟疫危机"></a>瘟疫危机</h2><p>合作游戏，有次亚特兰蒂斯玩之后腰子只愿意玩这个了。</p><h2 id="宇航员"><a href="#宇航员" class="headerlink" title="宇航员"></a>宇航员</h2><p>合作游戏，不适合小黑。</p><h2 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h2><h2 id="展翅翱翔"><a href="#展翅翱翔" class="headerlink" title="展翅翱翔"></a>展翅翱翔</h2><p>大师买过的，贡献了骰塔。</p><h1 id="毕业后分界线"><a href="#毕业后分界线" class="headerlink" title="=== 毕业后分界线 ==="></a>=== 毕业后分界线 ===</h1><p>主要是过年搞。</p><h2 id="谍报风云"><a href="#谍报风云" class="headerlink" title="谍报风云"></a>谍报风云</h2><h2 id="揭秘希特勒"><a href="#揭秘希特勒" class="headerlink" title="揭秘希特勒"></a>揭秘希特勒</h2><h2 id="柯尔特快车"><a href="#柯尔特快车" class="headerlink" title="柯尔特快车"></a>柯尔特快车</h2><p>打枪打拳的。</p><h2 id="牛头王"><a href="#牛头王" class="headerlink" title="牛头王"></a>牛头王</h2><p>聚会第一游戏了。特别是人多的时候，根本算不过来。</p><h2 id="小白世纪"><a href="#小白世纪" class="headerlink" title="小白世纪"></a>小白世纪</h2><h2 id="盛唐园林"><a href="#盛唐园林" class="headerlink" title="盛唐园林"></a>盛唐园林</h2><h2 id="怒海求生"><a href="#怒海求生" class="headerlink" title="怒海求生"></a>怒海求生</h2><p>划船神游。</p><h2 id="大搜查"><a href="#大搜查" class="headerlink" title="大搜查"></a>大搜查</h2><p>桌游模拟器玩的。</p><h2 id="战争之匣"><a href="#战争之匣" class="headerlink" title="战争之匣"></a>战争之匣</h2><p>在桌游模拟器玩的。</p><h2 id="冷战热斗"><a href="#冷战热斗" class="headerlink" title="冷战热斗"></a>冷战热斗</h2><p>和大师在桌游模拟器上玩的。</p><h2 id="诈赌巫师"><a href="#诈赌巫师" class="headerlink" title="诈赌巫师"></a>诈赌巫师</h2><p>换裁判的、修改压注的卡最为牛逼。</p><h2 id="昆虫棋"><a href="#昆虫棋" class="headerlink" title="昆虫棋"></a>昆虫棋</h2><p>和大师网上 pk 的，后来我买了个和我对象玩，基本一直输，可玩性比较差。</p><h2 id="2023-悠嘻分界线"><a href="#2023-悠嘻分界线" class="headerlink" title="=== 2023 悠嘻分界线 ==="></a>=== 2023 悠嘻分界线 ===</h2><p>2023 年秋天左右，开始定期在悠嘻搞桌游。第一次搞了个包厢，喊了 zjx，可惜后面他不来了。但是后面小黑加入，所以桌游能够搞起来。</p><h2 id="出包魔法师"><a href="#出包魔法师" class="headerlink" title="出包魔法师"></a>出包魔法师</h2><p>猜自己面前的是什么。思路：</p><ul><li>勇于猜重复项</li><li>根据别人的猜测情况，必要时勇于猜 1-3</li><li>猜 4 成功的话收益很高，优先猜 4 猫头鹰</li><li>必要时再连猜，因为猜完要补牌从而亏信息（自己补牌别人能看到，相当于人家赚了），因此每次猜要尽可能猜完</li></ul><h2 id="滑板之夏"><a href="#滑板之夏" class="headerlink" title="滑板之夏"></a>滑板之夏</h2><p>也是个赌狗游戏。滑板一开始在 0 位置，不停抽牌，会对位置进行减或者加。</p><h2 id="皂单全收"><a href="#皂单全收" class="headerlink" title="皂单全收"></a>皂单全收</h2><h2 id="农场主"><a href="#农场主" class="headerlink" title="农场主"></a>农场主</h2><h2 id="星际卡坦"><a href="#星际卡坦" class="headerlink" title="星际卡坦"></a>星际卡坦</h2><p>在呦西玩了一把，它是纯英文的。我觉得比卡坦岛，不是特别卡人了。</p><h2 id="现代艺术"><a href="#现代艺术" class="headerlink" title="现代艺术"></a>现代艺术</h2><h2 id="骆驼大赛"><a href="#骆驼大赛" class="headerlink" title="骆驼大赛"></a>骆驼大赛</h2><p>抢放那个板很重要。</p><p>骆驼大赛需要推理的情形比较少，轮次比较好算。</p><h2 id="马尼拉"><a href="#马尼拉" class="headerlink" title="马尼拉"></a>马尼拉</h2><p>划船不用桨，叫我老船长。感觉越早当船长越划算。</p><h2 id="骰子街"><a href="#骰子街" class="headerlink" title="骰子街"></a>骰子街</h2><p>开火车站，然后还是玩一个骰子蹭别人。</p><h2 id="花砖物语"><a href="#花砖物语" class="headerlink" title="花砖物语"></a>花砖物语</h2><p>经典德式。高手们还剩两三个盘子的时候就开始算轮次了。</p><h2 id="暑假日记"><a href="#暑假日记" class="headerlink" title="暑假日记"></a>暑假日记</h2><h2 id="拉斯维加斯"><a href="#拉斯维加斯" class="headerlink" title="拉斯维加斯"></a>拉斯维加斯</h2><p>在性感哥那里玩的赌狗游戏。</p><h2 id="勃艮第城堡"><a href="#勃艮第城堡" class="headerlink" title="勃艮第城堡"></a>勃艮第城堡</h2><p>感觉是简化版的动物园。</p><h2 id="爆珠发明"><a href="#爆珠发明" class="headerlink" title="爆珠发明"></a>爆珠发明</h2><p>一个老早就知道的，类似于璀璨宝石的游戏。不过那个骰塔不太好，老卡壳。</p><h2 id="地产达人（拍卖）"><a href="#地产达人（拍卖）" class="headerlink" title="地产达人（拍卖）"></a>地产达人（拍卖）</h2><p>先拍一轮工厂，然后通过工厂生产一轮东西。最后是剩下的钱加上工厂赚的钱。</p><h2 id="沙丘"><a href="#沙丘" class="headerlink" title="沙丘"></a>沙丘</h2><p>23 年开始玩的，基本都是小黑赢。24 年上半年玩的比较多，然后琥珀赢比较多。</p><p>感觉沙丘人数多少会直接影响工人放置会不会被卡。另外打仗很重要。</p><h2 id="重塑火星"><a href="#重塑火星" class="headerlink" title="重塑火星"></a>重塑火星</h2><p>阅读量惊人。</p><h2 id="熵增猫"><a href="#熵增猫" class="headerlink" title="熵增猫"></a>熵增猫</h2><p>往上叠纸的。</p><h2 id="卡斯卡迪亚"><a href="#卡斯卡迪亚" class="headerlink" title="卡斯卡迪亚"></a>卡斯卡迪亚</h2><p>一开始在桌游模拟器玩的。</p><h1 id="2024-悠嘻分界线"><a href="#2024-悠嘻分界线" class="headerlink" title="=== 2024 悠嘻分界线 ==="></a>=== 2024 悠嘻分界线 ===</h1><h2 id="方鸟"><a href="#方鸟" class="headerlink" title="方鸟"></a>方鸟</h2><p>这是 2024 跨年夜玩的。</p><h2 id="方舟动物园"><a href="#方舟动物园" class="headerlink" title="方舟动物园"></a>方舟动物园</h2><p>这是 2024 跨年夜玩的。拉格朗日老板强烈安利。</p><h2 id="赌命大赛"><a href="#赌命大赛" class="headerlink" title="赌命大赛"></a>赌命大赛</h2><p>比较吸引我的一点是里面有质疑的环节。</p><h2 id="RA"><a href="#RA" class="headerlink" title="RA"></a>RA</h2><p>这是 2024 跨年夜玩的。</p><h2 id="CABO"><a href="#CABO" class="headerlink" title="CABO"></a>CABO</h2><p>这是 2024 跨年夜玩的。这个游戏应该是年度最佳毛线了。</p><h2 id="爆炸猫"><a href="#爆炸猫" class="headerlink" title="爆炸猫"></a>爆炸猫</h2><p>简单的毛线。</p><h2 id="幽港迷城"><a href="#幽港迷城" class="headerlink" title="幽港迷城"></a>幽港迷城</h2><h2 id="德国蟑螂"><a href="#德国蟑螂" class="headerlink" title="德国蟑螂"></a>德国蟑螂</h2><p>诈骗游戏。</p><h2 id="斯凯岛"><a href="#斯凯岛" class="headerlink" title="斯凯岛"></a>斯凯岛</h2><p>一个人每轮三块板，三选二出价，别人可以买，否则自己就按出价买走。</p><h2 id="加拿大棋"><a href="#加拿大棋" class="headerlink" title="加拿大棋"></a>加拿大棋</h2><p>有点类似冰壶。</p><p>有一次桌游店搞活动，我去和店主搞了一把。我两次直接打到圆心里面，结果一把就赢了店主，给我免单了 15 块钱。</p><h2 id="伊斯坦堡"><a href="#伊斯坦堡" class="headerlink" title="伊斯坦堡"></a>伊斯坦堡</h2><p>不停在各个区块走，然后每次停都要下一个蛋，直到走回来。</p><h2 id="骷髅牌"><a href="#骷髅牌" class="headerlink" title="骷髅牌"></a>骷髅牌</h2><p>比谁能咋呼，小黑每次都是假的。</p><h2 id="王权骰铸"><a href="#王权骰铸" class="headerlink" title="王权骰铸"></a>王权骰铸</h2><p>纯赌狗打架游戏。</p><h2 id="璀璨宝石宝可梦"><a href="#璀璨宝石宝可梦" class="headerlink" title="璀璨宝石宝可梦"></a>璀璨宝石宝可梦</h2><p>和原版的高分流完全不一样了。这个是 18 分模式，拿两蛋卡，以及一费卡很重要。</p><h2 id="战国时代"><a href="#战国时代" class="headerlink" title="战国时代"></a>战国时代</h2><p>投骰子的赌狗游戏。大家都喜欢无脑莽春日山城。我记得大师有一次靠着欧皇城极限反杀。</p><h2 id="大宋百商图"><a href="#大宋百商图" class="headerlink" title="大宋百商图"></a>大宋百商图</h2><p>小黑买的游戏。我觉得可以靠删卡流获胜。我赢过几次，倒是靠的那个一下赚 6 分建筑的获胜的。</p><h2 id="串好啦"><a href="#串好啦" class="headerlink" title="串好啦"></a>串好啦</h2><p>垃圾游戏，小黑喜欢玩。</p><h2 id="王者神抽"><a href="#王者神抽" class="headerlink" title="王者神抽"></a>王者神抽</h2><p>鱼钩船锚的。感觉是升级版的印加宝藏。</p><h2 id="L-计划"><a href="#L-计划" class="headerlink" title="L 计划"></a>L 计划</h2><p>很有意思的游戏。</p><h2 id="历史奇旅"><a href="#历史奇旅" class="headerlink" title="历史奇旅"></a>历史奇旅</h2><p>很多年份牌，从公元前到公元后。玩家需要按照时间顺序打出年份牌，这个牌组越长，得分越高。</p><h2 id="猫岛"><a href="#猫岛" class="headerlink" title="猫岛"></a>猫岛</h2><p>任务卡得分很多，选择好的任务卡很重要。</p><p>多买点猫很重要，因为无论是空格子，还是完成任务都需要猫的绝对数量。</p><h2 id="以色列麻将（拉密）"><a href="#以色列麻将（拉密）" class="headerlink" title="以色列麻将（拉密）"></a>以色列麻将（拉密）</h2><h2 id="奥丁的盛宴"><a href="#奥丁的盛宴" class="headerlink" title="奥丁的盛宴"></a>奥丁的盛宴</h2><p>很容易作弊。</p><h2 id="纽约动物园"><a href="#纽约动物园" class="headerlink" title="纽约动物园"></a>纽约动物园</h2><h2 id="星露谷物语"><a href="#星露谷物语" class="headerlink" title="星露谷物语"></a>星露谷物语</h2><p>挺无聊的。</p><h2 id="疯狂建筑师"><a href="#疯狂建筑师" class="headerlink" title="疯狂建筑师"></a>疯狂建筑师</h2><p>用棍子越大越高，谁掉下来谁就把掉地上的棍子全吃掉。</p><h2 id="苍翠之星"><a href="#苍翠之星" class="headerlink" title="苍翠之星"></a>苍翠之星</h2><p>挺有创意的游戏。太阳绕一圈，春夏秋冬，计分四次。感觉挺考验统筹能力。</p><h2 id="盖亚计划"><a href="#盖亚计划" class="headerlink" title="盖亚计划"></a>盖亚计划</h2><p>和呦西老板开了轮。后面自己也玩了几把，把把村规，但是很好玩。</p><h2 id="神秘大地"><a href="#神秘大地" class="headerlink" title="神秘大地"></a>神秘大地</h2><p>在大师家玩的比较多，是大创的简化版本。</p><h2 id="异世界公会长"><a href="#异世界公会长" class="headerlink" title="异世界公会长"></a>异世界公会长</h2><p>在大师家玩的。</p><h2 id="永恒之谷"><a href="#永恒之谷" class="headerlink" title="永恒之谷"></a>永恒之谷</h2><p>越到最后约说书，卡牌效果太多了。</p><h2 id="骰子镇"><a href="#骰子镇" class="headerlink" title="骰子镇"></a>骰子镇</h2><p>小黑快乐游戏。</p><h2 id="圣家族大教堂"><a href="#圣家族大教堂" class="headerlink" title="圣家族大教堂"></a>圣家族大教堂</h2><p>从巴塞罗那回来，刚好就玩了这个。</p><h2 id="尖塔奇兵"><a href="#尖塔奇兵" class="headerlink" title="尖塔奇兵"></a>尖塔奇兵</h2><p>忘了怎么玩的了。</p><h2 id="时空神探"><a href="#时空神探" class="headerlink" title="时空神探"></a>时空神探</h2><p>挺有创意的破案游戏。</p><h2 id="迷失代码"><a href="#迷失代码" class="headerlink" title="迷失代码"></a>迷失代码</h2><p>有点像出包魔法师一样，但是这次是猜自己面前六个数字的总和。每次按顺序在桌子中间选择一个轮盘，轮盘越大，域越大越容易猜中，但是得分越低。</p><h2 id="疯狂诡宅"><a href="#疯狂诡宅" class="headerlink" title="疯狂诡宅"></a>疯狂诡宅</h2><h2 id="口袋密室"><a href="#口袋密室" class="headerlink" title="口袋密室"></a>口袋密室</h2><p>非常无厘头的解谜。</p><h2 id="Bohnanza-Das-Wurfelspiel"><a href="#Bohnanza-Das-Wurfelspiel" class="headerlink" title="Bohnanza: Das Würfelspiel"></a>Bohnanza: Das Würfelspiel</h2><p>挺好玩的骰子游戏，实际上是种豆得金的骰子版，去掉了扯皮的交易环节。但买不到。</p><h2 id="神偷大盗"><a href="#神偷大盗" class="headerlink" title="神偷大盗"></a>神偷大盗</h2><h2 id="自然和弦"><a href="#自然和弦" class="headerlink" title="自然和弦"></a>自然和弦</h2><h2 id="开除"><a href="#开除" class="headerlink" title="开除"></a>开除</h2><p>不太平衡的游戏。有个办公用品卡，还是喝酒的好像特别强。</p><h1 id="2025-分割线"><a href="#2025-分割线" class="headerlink" title="=== 2025 分割线 ==="></a>=== 2025 分割线 ===</h1><h2 id="拼布艺术"><a href="#拼布艺术" class="headerlink" title="拼布艺术"></a>拼布艺术</h2><p>没拼完的要扣 2 分 不是一分。</p><h2 id="驭龙狂奔渡渡鸟"><a href="#驭龙狂奔渡渡鸟" class="headerlink" title="驭龙狂奔渡渡鸟"></a>驭龙狂奔渡渡鸟</h2><p>桌上篮球。</p><h2 id="英雄领域"><a href="#英雄领域" class="headerlink" title="英雄领域"></a>英雄领域</h2><h2 id="方格游戏（角斗士棋）"><a href="#方格游戏（角斗士棋）" class="headerlink" title="方格游戏（角斗士棋）"></a>方格游戏（角斗士棋）</h2><p>有点类似于围棋，前期出去占地盘很重要。类似于 1x1 和 1x2 的棋子的作用很关键，它们可以用来在被围住的情况下搭桥逃出来。</p><h2 id="客人来之前"><a href="#客人来之前" class="headerlink" title="客人来之前"></a>客人来之前</h2><h2 id="马戏星探"><a href="#马戏星探" class="headerlink" title="马戏星探"></a>马戏星探</h2><p>一个重要的规则是发完牌之后，是不能自己理牌的。唯一能做的就是选择使用顶部的数字还是底部的数字。</p><h2 id="糟了个糕"><a href="#糟了个糕" class="headerlink" title="糟了个糕"></a>糟了个糕</h2><p>第一个棋子如果能优先走到绿区，并领先对手一个回合，那么很有可能能够嫖到高分绿板。</p><p>但是，走得太快并不一定很好。比如在后方你和别人为了一个反转板块或者高加分的板块而熬鹰，但是因为前面棋子动不了了，就不得不放弃熬鹰动这个棋子。</p><p>有一个棋子在比较靠后的位置挺重要的。</p><h2 id="种豆得金"><a href="#种豆得金" class="headerlink" title="种豆得金"></a>种豆得金</h2><p>本来是想要买 Bohnanza: Das Würfelspiel 的，但是买不到。这个也挺好玩的，核心的点是要通过交易把自己手牌中不要的豆给别人，让手牌更加规整。</p><h2 id="脑洞量表"><a href="#脑洞量表" class="headerlink" title="脑洞量表"></a>脑洞量表</h2><p>没买，用小程序玩的。</p><h2 id="瞎掰王"><a href="#瞎掰王" class="headerlink" title="瞎掰王"></a>瞎掰王</h2><p>春节玩了下。感觉容易放不开，编故事时间比较短，但是老实人总是担心自己说的不够全面。其实这个游戏是允许并且希望老实人忘词的。</p><h2 id="疯狂飞行棋"><a href="#疯狂飞行棋" class="headerlink" title="疯狂飞行棋"></a>疯狂飞行棋</h2><p>觉得不太平衡。我抽了一张场景牌，禁止其他玩家骰子为1的行为。然后中盘有成功把四个飞机叠起来了。最后，又抽了张到了终极轨道就能直接移动的牌。所以赢得非常快。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍玩过的一些桌游。大概是按照结识的顺序来的。&lt;/p&gt;</summary>
    
    
    
    
    <category term="游戏" scheme="http://www.calvinneo.com/tags/游戏/"/>
    
  </entry>
  
  <entry>
    <title>Full text search(FTS) 技术调研</title>
    <link href="http://www.calvinneo.com/2025/01/11/fts/"/>
    <id>http://www.calvinneo.com/2025/01/11/fts/</id>
    <published>2025-01-11T03:57:20.000Z</published>
    <updated>2025-01-18T11:12:46.305Z</updated>
    
    <content type="html"><![CDATA[<p>主要介绍 FTS 的一些实现。</p><a id="more"></a><h1 id="分词技术"><a href="#分词技术" class="headerlink" title="分词技术"></a>分词技术</h1><h2 id="ngram"><a href="#ngram" class="headerlink" title="ngram"></a>ngram</h2><h1 id="字典结构"><a href="#字典结构" class="headerlink" title="字典结构"></a>字典结构</h1><h2 id="ngram-bloomfilter"><a href="#ngram-bloomfilter" class="headerlink" title="ngram bloomfilter"></a>ngram bloomfilter</h2><ul><li>生成 N-gram： 将一个输入字符串生成所有可能的 N-gram。</li><li>存储到布隆过滤器： 对每个 N-gram 使用多个哈希函数，将其存储到布隆过滤器中。</li></ul><p>查询： 对查询的字符串生成对应的 N-gram，逐个检查它们是否存在于布隆过滤器中。</p><ul><li>如果布隆过滤器判定所有 N-gram 存在，说明可能是匹配。</li><li>如果至少有一个 N-gram 不存在，可以确定不匹配。</li></ul><p>缺点：</p><ul><li>存在 FP</li><li>不支持删除</li></ul><h2 id="BTree"><a href="#BTree" class="headerlink" title="BTree"></a>BTree</h2><h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><h2 id="KV-结构"><a href="#KV-结构" class="headerlink" title="KV 结构"></a>KV 结构</h2><p>存储分词后的倒排索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&quot;OceanBase&quot; -&gt; [Doc1, Doc2]</span><br><span class="line">&quot;is&quot; -&gt; [Doc1]</span><br><span class="line">&quot;a&quot; -&gt; [Doc1]</span><br><span class="line">&quot;distributed&quot; -&gt; [Doc1]</span><br><span class="line">&quot;supports&quot; -&gt; [Doc2]</span><br><span class="line">&quot;full-text&quot; -&gt; [Doc2]</span><br><span class="line">&quot;search&quot; -&gt; [Doc2]</span><br></pre></td></tr></table></figure><h2 id="FST-Finite-State-Transducer"><a href="#FST-Finite-State-Transducer" class="headerlink" title="FST(Finite-State Transducer)"></a>FST(Finite-State Transducer)</h2><p>FST 是一种 Trie 树的结构。</p><h2 id="MultiValue-Index"><a href="#MultiValue-Index" class="headerlink" title="MultiValue Index"></a>MultiValue Index</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;主要介绍 FTS 的一些实现。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
  </entry>
  
  <entry>
    <title>jemalloc 的实现</title>
    <link href="http://www.calvinneo.com/2025/01/03/jemalloc-impl/"/>
    <id>http://www.calvinneo.com/2025/01/03/jemalloc-impl/</id>
    <published>2025-01-03T06:06:10.000Z</published>
    <updated>2025-01-21T13:38:34.523Z</updated>
    
    <content type="html"><![CDATA[<p>介绍下 jemalloc 的实现。目前的实现和 4.5 及之前的实现还是有比较大的差别的。因此代码主要是看的 4.5，并介绍了下 5.2.1 的几个重要的变化。</p><a id="more"></a><h1 id="设计理念"><a href="#设计理念" class="headerlink" title="设计理念"></a>设计理念</h1><ul><li>最大化内存分配和释放的性能</li><li>减少内部碎片和外部碎片</li><li>减少线程之间的竞争和 false sharing</li><li>支持 heap profiling</li></ul><h1 id="实现理念"><a href="#实现理念" class="headerlink" title="实现理念"></a>实现理念</h1><h2 id="基本情况"><a href="#基本情况" class="headerlink" title="基本情况"></a>基本情况</h2><p>jemalloc 中定义了一系列 size classes，这是通过 size_classes.h 生成的。从小到大可以进行编号，例如大小在 0 到 8 之间的就是 0 号，8 到 16 之间的就是 1 号。size2index 和 index2size 可以实现转换。</p><p>基于内存大小，把申请的内存分为三类：</p><ul><li>Small 的 size 小于 page 大小，为 8/16/32 bytes 等。会返回某个 run 中的一个 region。</li><li>Large 以 page 为单位，小于 chunk 的大小。会返回一个 run。</li><li>Huge 会使用多个 chunk。<br>  所以 Huge 是按照 chunk 对齐的，这通常被用来区分一个地址是否属于 Huge。</li></ul><p>因为 tcache 的存在，内存分配可能和上述相比有更多的优化。</p><p>名词解释：</p><ul><li>page 指的是操作系统的 page，一般是 4KB。mmap 系统调用分配内存以 page 为单位，但分配的内存未必是按照 page size 对齐的，所以可能要多分配一些出来，然后 trim。</li><li>chunk 指的是 jemalloc 向 OS 申请内存的最小单位。它一定是 page size 的倍数。默认是 2MiB。</li><li>run：一个 chunk 分成多个<strong>不同大小</strong>的 run。</li><li>region：一个 run 分成多个<strong>相同大小</strong>的 region。Small 对象的内存分配和释放就是标记某个 region 被使用。</li><li>bin：由 bin 管理存储同一种大小的 Small 对象（也就是说同一种 size class）的多个 run。</li></ul><h2 id="chuck-的基本设计"><a href="#chuck-的基本设计" class="headerlink" title="chuck 的基本设计"></a>chuck 的基本设计</h2><p>arena_chunk_s 的结构如下所示：</p><ul><li>extent_node_t 的 node</li><li>arena_chunk_map_bits_t 即 arena_chunk_map_bits_s 类型的 map_bits<br>  包含了 chunk 中除了 header 使用的 page 之外的所有 page 的元信息。</li><li>arena_chunk_map_misc_t 即 arena_chunk_map_misc_s<br>  记录了各个 run 的元信息。<br>  这个结构并没有在 arena_chunk_s 中被表示出来。应该是 C 语言的问题。</li><li>pages，也就是 payload</li></ul><p>这个 map_bits 的长度实际上等于 map_bias，是在 arena_boot 中计算的。这个计算有个神奇的 <code>for (i &lt; 3)</code> 循环，将在后面介绍。</p><p>arena_chunk_map_bits_t 是一个 size_t。它如何设置，取决于 page 是 run 的第一个、中间的、普通的 page。以及 run 的类型是未分配、small 和 large。容易推断出，一个 run 至少对应一个 page。</p><p>在初始化时还会设置：</p><ul><li>arena_maxrun 等于 chunk 的大小减去 header 的大小。</li><li>large_maxclass：Large 类型的 class 的最大的大小。</li></ul><h2 id="run-的基本设计"><a href="#run-的基本设计" class="headerlink" title="run 的基本设计"></a>run 的基本设计</h2><p>arena_chunk_map_misc_t 是 run 的元信息，前面提到，它也是存在 chunk 的 header 中，而不会有自己单独的 run header。</p><p>ph_link 有两个互斥的用途：</p><ul><li>在 arena_s 中的 runs_avail 堆，用来管理 arena 中所有可用的 run</li><li>在 arena_bin_s 中的 runs 堆，用来管理分配给某个 bin 的 run</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">arena_chunk_map_misc_s</span> &#123;</span></span><br><span class="line">    phn(<span class="keyword">arena_chunk_map_misc_t</span>)     ph_link;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">union</span> &#123;</span><br><span class="line">        <span class="comment">/* Linkage for list of dirty runs. */</span></span><br><span class="line">        <span class="keyword">arena_runs_dirty_link_t</span>     rd;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Profile counters, used for large object runs. */</span></span><br><span class="line">        <span class="keyword">union</span> &#123;</span><br><span class="line">            <span class="keyword">void</span>            *prof_tctx_pun;</span><br><span class="line">            <span class="keyword">prof_tctx_t</span>     *prof_tctx;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Small region run metadata. */</span></span><br><span class="line">        <span class="keyword">arena_run_t</span>         run;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>通过 arena_run_split_small 函数，可以将 run 分解，得到对应 size 的一系列 run，并交给对应的 bin 管理。</p><p>通过 arena_run_coalesce 函数，run 在释放时也可以被前后合并。</p><p>对于 Small 结构，有 arena_run_t 结构用来维护</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">arena_run_s</span> &#123;</span></span><br><span class="line">    <span class="keyword">szind_t</span>     binind;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">unsigned</span>    nfree;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">bitmap_t</span>    bitmap[BITMAP_GROUPS_MAX];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="bin-的基本设计"><a href="#bin-的基本设计" class="headerlink" title="bin 的基本设计"></a>bin 的基本设计</h2><p>runs_avail 是一个数组，数组长度等于 runs_avail_nclasses。分配给 bin 的 run 会从 arena_s 的 runs_avail 中删除，移动到 arena_bin_s 管理。其中，runcur 记录目前正在被用来分配的 run。runs 记录目前非空、非满的 run。此外：</p><ul><li>空的 bin 不会被任何结构记录，因为这个时候内存都已经分配给用户了，用户理应通过 free 来释放内存。</li><li>满的 bin 会被会收到 runs_avail 中</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">arena_bin_s</span> &#123;</span></span><br><span class="line">    <span class="keyword">malloc_mutex_t</span>      lock;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">arena_run_t</span>     *runcur;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">arena_run_heap_t</span>    runs;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Bin statistics. */</span></span><br><span class="line">    <span class="keyword">malloc_bin_stats_t</span>  stats;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>为什么 run 被记录在 arena 而不是 chunk 中呢？</p><h2 id="free"><a href="#free" class="headerlink" title="free"></a>free</h2><p>这里定义 pageind 为</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pageind = ((<span class="keyword">uintptr_t</span>)ptr - (<span class="keyword">uintptr_t</span>)chunk) &gt;&gt; LG_PAGE;</span><br></pre></td></tr></table></figure><h3 id="5-2-1"><a href="#5-2-1" class="headerlink" title="5.2.1"></a>5.2.1</h3><p>首先需要区分 Huge、Large 和 Small：</p><ul><li>Huge 可以判断是否和 chunk 大小也就是 2MiB 对齐。</li><li>Large 可以通过 page 对应的 map_bits 和 CHUNK_MAP_LARGE 做 and 来实现。</li></ul><p>Small 比较麻烦，因为还需要找到对应的 region。</p><p>在 arena_dalloc_small 中处理，主要是调用 arena_dalloc_bin，然后调用 arena_decay_tick。</p><p>步骤是：</p><ul><li>找到对应的 run page offset，也就是 <code>pppppppp pppppppp ppp</code>。也就是这个 region 对应的 run 的第一个 page。</li><li>然后获得这个 run 的 misc 数据。目的是找到 run 对应的 bin 是哪个。</li><li>对对应的 bin 加锁，执行 arena_dalloc_bin_locked_impl。在 4.2.1 中这个函数有一些重复计算的地方不知道为啥。这个函数主要调用 arena_run_reg_dalloc，后面还有一些对 bin 是否为空的判断。</li></ul><p><code>arena_run_reg_dalloc</code> 的有效过程是：</p><ul><li>arena_run_regind 获得 region id</li><li><code>bitmap_unset(run-&gt;bitmap, &amp;bin_info-&gt;bitmap_info, regind);</code> 标记这个 region 被释放。</li></ul><h2 id="purge"><a href="#purge" class="headerlink" title="purge"></a>purge</h2><h3 id="muzzy-和-dirty"><a href="#muzzy-和-dirty" class="headerlink" title="muzzy 和 dirty"></a>muzzy 和 dirty</h3><p>purge 分为 2 个阶段：</p><ul><li>active -&gt; dirty<br>  变为 dirty 后，heap profiling 是无法看到的。但是 RSS 依然较高。</li><li>dirty -&gt; muzzy<br>  调用 madvise(MADV_FREE)</li><li>muzzy -&gt; cleaned<br>  调用 madvise(MADV_DONTNEED)</li></ul><h3 id="何时-purge"><a href="#何时-purge" class="headerlink" title="何时 purge"></a>何时 purge</h3><p>有两个 ctl，对应了 <code>arena.$i.{purtge,decay}</code> 命令，相关<a href="https://jemalloc.net/jemalloc.3.html" target="_blank" rel="noopener">文档</a>：</p><ul><li>arena_i_purge_ctl<br>  Purge all unused dirty pages for arena <code>&lt;i&gt;</code>, or for all arenas if <code>&lt;i&gt;</code> equals MALLCTL_ARENAS_ALL.</li><li>arena_i_decay_ctl<br>  Trigger decay-based purging of unused dirty/muzzy pages for arena <code>&lt;i&gt;</code>, or for all arenas if <code>&lt;i&gt;</code> equals MALLCTL_ARENAS_ALL.<br>  The proportion of unused dirty/muzzy pages to be purged depends on the current time; see opt.dirty_decay_ms and opt.muzy_decay_ms for details.</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">ctl_named_node_t</span> arena_i_node[] = &#123;</span><br><span class="line">    &#123;NAME(<span class="string">"purge"</span>),     CTL(arena_i_purge)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"decay"</span>),     CTL(arena_i_decay)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"reset"</span>),     CTL(arena_i_reset)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"dss"</span>),       CTL(arena_i_dss)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"lg_dirty_mult"</span>), CTL(arena_i_lg_dirty_mult)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"decay_time"</span>),    CTL(arena_i_decay_time)&#125;,</span><br><span class="line">    &#123;NAME(<span class="string">"chunk_hooks"</span>),   CTL(arena_i_chunk_hooks)&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>purge 和 decay 的区别，是 <code>arena_purge</code> 的 <code>all</code> 参数。实际上导致了调用的是 <code>arena_purge_to_limit(ndirty_limit=0)</code> 还是 <code>arena_maybe_purge</code>。</p><p>arena_maybe_purge 分为两种模式，受到 opt_purge 管理：</p><ul><li>purge_mode_ratio<br>  purge 更少的 page，直到满足 arena-&gt;ndirty &lt;= ndirty_limit。<br>  这个应该是对应了 lazy 模式。</li><li>purge_mode_decay<br>  purge 尽可能多的 page，但是不违背 arena-&gt;ndirty &gt;= ndirty_limit。<br>  这实际上是默认值。decay 实际上是基于时间的管理。</li></ul><p>实际上这里 ndirty_limit 就是能够容忍的最多的 dirty page 的数量。</p><p>看看默认的 purge_mode_decay 模式，首先要检查下结构 <code>arena_decay_s</code>：</p><ul><li>time<br>  Approximate time in seconds from the creation of a set of unused dirty pages until an equivalent set of unused dirty pages is purged and/or reused.<br>  产生的 dirty pages 会在 decay_time 时间后全部 purge。默认是 10s。</li><li>interval<br>  time / SMOOTHSTEP_NSTEPS。相当于分这么多组去 decay，而不是一次性搞完，从而避免每次占用较多的资源。<br>  SMOOTHSTEP_NSTEPS 等于 200。</li><li>epoch<br>  Time at which the current decay interval logically started.<br>  We do not actually advance to a new epoch until sometime after it starts because of scheduling and computation delays, and it is even possible to completely skip epochs.<br>  In all cases, during epoch advancement we merge all relevant activity into the most recently recorded epoch.<br>  结合 interval 和 deadline 的理解就是 epoch 理论上就是不断自增 interval，但实际上什么时候开始是不确定的，甚至可能跳过某些 epoch。每个 epoch 开始的时候会处理之前的所有工作。</li><li>deadline<br>  Deadline for current epoch.<br>  This is the sum of interval and per epoch jitter. 实际上就是 <code>[epoch + interval, epoch + 2*interval)</code>。<br>  Epochs always advance by precise multiples of interval, but we but we randomize the deadline to reduce the likelihood of arenas purging in lockstep.</li><li>ndirty<br>  epoch 开始的时候 dirty page 的数量。</li><li>backlog<br>  Trailing log of how many unused dirty pages were generated during each of the past SMOOTHSTEP_NSTEPS decay epochs, where the last element is the most recent epoch. Corresponding epoch times are relative to epoch.</li></ul><blockquote><p>因为在 purge 的过程中，会有新的 dirty page 产生，所以将整个 purge 划分为 SMOOTHSTEP_NSTEPS 组，每组分别负责 interval 时间内产生的 dirty page 的回收，每组能保留的 dirty pages 数量根据 Smootherstep 曲线，总的能保留的 dirty page 数量为 200 组的叠加，超出的会 purge。</p></blockquote><p>实现在 arena_maybe_purge_decay：</p><ul><li>arena_decay_deadline_reached 检查 <code>decay.deadline</code> 是否已经到达</li><li>arena_decay_epoch_advance<ul><li>arena_decay_epoch_advance_helper</li><li>arena_decay_epoch_advance_purge<br>  计算出 ndirty_limit。调用 arena_purge_to_limit(ndirty_limit)，更新 decay.dirty。</li></ul></li></ul><h3 id="Smooth-steps-曲线"><a href="#Smooth-steps-曲线" class="headerlink" title="Smooth steps 曲线"></a>Smooth steps 曲线</h3><p>SMOOTHSTEP 是一个表：</p><ul><li>x 从 0.005 开始递增到 1.000</li><li>y 是对应 x 取值时，smooth step 函数的值。对于 jemalloc 的场景，就是在 x 的时刻，需要回收大概多少的内存了</li><li>h 是 y 乘上 <code>2 ** SMOOTHSTEP_BFP</code> 的结果，这样转成整数计算方便很多</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SMOOTHSTEP_VARIANT  <span class="meta-string">"smoother"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SMOOTHSTEP_NSTEPS   200</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SMOOTHSTEP_BFP      24</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SMOOTHSTEP \</span></span><br><span class="line"> <span class="comment">/* STEP(step, h,                            x,     y) */</span> \</span><br><span class="line">    STEP(   <span class="number">1</span>, UINT64_C(<span class="number">0x0000000000000014</span>), <span class="number">0.005</span>, <span class="number">0.000001240643750</span>) \</span><br><span class="line">    STEP(   <span class="number">2</span>, UINT64_C(<span class="number">0x00000000000000a5</span>), <span class="number">0.010</span>, <span class="number">0.000009850600000</span>) \</span><br></pre></td></tr></table></figure><p>这个 SMOOTHSTEP 宏是计算机生成的，但也可以手算，结果如下。可以看到 20 和 0x14 相等。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ dc</span><br><span class="line">&gt; 5 k 2 24 ^ 0.000001240643750 * p</span><br><span class="line">20.814548172800000</span><br></pre></td></tr></table></figure><h3 id="5-2-1-版本的-purge-和-decay"><a href="#5-2-1-版本的-purge-和-decay" class="headerlink" title="5.2.1 版本的 purge 和 decay"></a>5.2.1 版本的 purge 和 decay</h3><p>在 4.5 中，使用 dirty_time。到了 5.2.1 中，就变成了 dirty_decay_ms 和 muzzy_decay_ms 了，但值还是一样的。</p><p>这个<a href="https://github.com/CalvinNeo/jemalloc/tree/debug" target="_blank" rel="noopener">基于 5.2.1 的分支</a>上有我的一些调试记录。</p><p>这里，有个结论是 5.2.1 上如果不开启 background thread 特性，那么指定 dirty_decay_ms 为非 0 值，则可能起不到预期的回收 dirty 页面的效果。我也在 tiflash 这个 binary 上进行了测试，验证过：</p><ul><li>关闭 background thread，但是开启 dirty_decay_ms，则后续手动 purge 仍有内存释放</li><li>开启 background thread，且开启 dirty_decau_ms，则内存会被回收，稍后手动 purge 不会进一步释放内存</li></ul><p>原因是回收的逻辑大概如下：</p><ul><li>如果 decay_ms 为 0，则在 arena_maybe_decay 中会直接调用 arena_decay_to_limit 去 purge。这实际上是会 purge 最多 current_npages。</li><li>否则判断是否到达这个 epoch 的 deadline<ul><li>如果是，则调用 arena_decay_epoch_advance<br>  在这个函数中，会判断是否开启 background thread 特性。<br>  如果关闭，会调用 arena_decay_try_purge，这也是 background thread 关闭后唯一释放内存的路径。如果开启，则只有当前线程是 background thread 的时候才会调用 arena_decay_try_purge。<br>  如果 purge，会 purge 最多 current_npages。</li><li>如果否，则只有当前线程是 background thread 的时候，才会调用 arena_decay_try_purge。purge 最多 arena_decay_backlog_npages_limit。</li></ul></li></ul><p>从上述逻辑发现，只要 background thread 特性被关闭，则 arena_maybe_decay 即使被调用，也不会有渐进的 decay。</p><p>再往上的调用关系：</p><ul><li>arena_decay_ms_set 和 arena_decay_impl 会调用 arena_maybe_decay。</li><li>arena_decay_dirty 和 arena_decay_muzzy 会调用 arena_decay_impl。<ul><li>arena_extents_dirty_dalloc 和 arena_decay 会调用 arena_decay_dirty。</li></ul></li></ul><p>我在 test.cpp 中做了实验。在 free 的时候，会调用 arena_extents_dirty_dalloc。而 arena_decay 在下面被调用：</p><ul><li>arena_decay_ticks</li><li>background_work_sleep_once</li><li>ctl 方法 arena_i_decay</li><li>ctl 方法 arena_i_destroy_ctl</li><li>tcache_destroy</li></ul><h3 id="4-5-如何-purge"><a href="#4-5-如何-purge" class="headerlink" title="4.5 如何 purge"></a>4.5 如何 purge</h3><p>这里以 4.5 的 arena_purge_to_limit 来讲解。</p><p>首先介绍两个结构 rd_link 和 cc_link。它们就是我们要清理的对象，都是 qr 结构的链表。</p><p>rd_link 对应了要回收的 run，cc_link 对应了要回收的 chunk。容易想到，run 和 chunk 的回收方式可能是不一样的，chunk 可能最终会被通过 munmap 返回给系统。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">arena_runs_dirty_link_s</span> &#123;</span></span><br><span class="line">    qr(<span class="keyword">arena_runs_dirty_link_t</span>) rd_link;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">extent_node_s</span> &#123;</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">/* Linkage for arena's runs_dirty and chunks_cache rings. */</span></span><br><span class="line">    <span class="keyword">arena_runs_dirty_link_t</span> rd;</span><br><span class="line">    qr(<span class="keyword">extent_node_t</span>)   cc_link;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>代码如下，可以看到，它将要释放的 chunk 和 run 分别放到 purge_chunks_sentinel 和 purge_runs_sentinel 中进行管理。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">arena_purge_to_limit(<span class="keyword">tsdn_t</span> *tsdn, <span class="keyword">arena_t</span> *arena, <span class="keyword">size_t</span> ndirty_limit)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">chunk_hooks_t</span> chunk_hooks = chunk_hooks_get(tsdn, arena);</span><br><span class="line">    <span class="keyword">size_t</span> npurge, npurged;</span><br><span class="line">    <span class="keyword">arena_runs_dirty_link_t</span> purge_runs_sentinel;</span><br><span class="line">    <span class="keyword">extent_node_t</span> purge_chunks_sentinel;</span><br><span class="line"></span><br><span class="line">    arena-&gt;purging = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Calls to arena_dirty_count() are disabled even for debug builds</span></span><br><span class="line"><span class="comment">     * because overhead grows nonlinearly as memory usage increases.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">false</span> &amp;&amp; config_debug) &#123;</span><br><span class="line">        <span class="keyword">size_t</span> ndirty = arena_dirty_count(arena);</span><br><span class="line">        assert(ndirty == arena-&gt;ndirty);</span><br><span class="line">    &#125;</span><br><span class="line">    assert(opt_purge != purge_mode_ratio || (arena-&gt;nactive &gt;&gt;</span><br><span class="line">        arena-&gt;lg_dirty_mult) &lt; arena-&gt;ndirty || ndirty_limit == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    qr_new(&amp;purge_runs_sentinel, rd_link);</span><br><span class="line">    extent_node_dirty_linkage_init(&amp;purge_chunks_sentinel);</span><br><span class="line"></span><br><span class="line">    npurge = arena_stash_dirty(tsdn, arena, &amp;chunk_hooks, ndirty_limit,</span><br><span class="line">        &amp;purge_runs_sentinel, &amp;purge_chunks_sentinel);</span><br><span class="line">    <span class="keyword">if</span> (npurge == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">goto</span> label_return;</span><br><span class="line">    npurged = arena_purge_stashed(tsdn, arena, &amp;chunk_hooks,</span><br><span class="line">        &amp;purge_runs_sentinel, &amp;purge_chunks_sentinel);</span><br><span class="line">    assert(npurged == npurge);</span><br><span class="line">    arena_unstash_purged(tsdn, arena, &amp;chunk_hooks, &amp;purge_runs_sentinel,</span><br><span class="line">        &amp;purge_chunks_sentinel);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config_stats)</span><br><span class="line">        arena-&gt;stats.npurge++;</span><br><span class="line"></span><br><span class="line">label_return:</span><br><span class="line">    arena-&gt;purging = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的脉络是：</p><ul><li>extent_node_dirty_linkage_init</li><li>arena_stash_dirty</li><li>arena_purge_stashed</li><li>arena_unstash_purged 是真正的释放过程</li></ul><h4 id="chunk-的释放策略"><a href="#chunk-的释放策略" class="headerlink" title="chunk 的释放策略"></a>chunk 的释放策略</h4><p>调用 chunk_dalloc_wrapper，这里面对 chunk_hooks 有个判断，默认是走 chunk_dalloc_default_impl。最终实际上会调用 mummap。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">bool</span></span><br><span class="line">chunk_dalloc_default_impl(<span class="keyword">void</span> *chunk, <span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!have_dss || !chunk_in_dss(chunk))</span><br><span class="line">        <span class="keyword">return</span> (chunk_dalloc_mmap(chunk, size));</span><br><span class="line">    <span class="keyword">return</span> (<span class="literal">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">bool</span></span><br><span class="line">chunk_dalloc_mmap(<span class="keyword">void</span> *chunk, <span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config_munmap)</span><br><span class="line">        pages_unmap(chunk, size);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (!config_munmap);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span></span><br><span class="line">pages_unmap(<span class="keyword">void</span> *addr, <span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> _WIN32</span></span><br><span class="line">    <span class="keyword">if</span> (VirtualFree(addr, <span class="number">0</span>, MEM_RELEASE) == <span class="number">0</span>)</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="keyword">if</span> (munmap(addr, size) == <span class="number">-1</span>)</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    &#123;</span><br><span class="line">...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="run-的释放策略"><a href="#run-的释放策略" class="headerlink" title="run 的释放策略"></a>run 的释放策略</h4><p>调用 arena_run_dalloc。</p><ul><li>如果释放这个 run 导致 chunk 闲置，则调用 arena_chunk_dalloc。这个函数最终可能会走到 arena_maybe_purge，从而导致 chunk 被回收</li><li>如果这个 run 是 dirty bit 被 set 了，则调用 arena_maybe_purge</li></ul><h3 id="5-2-1-如何-purge"><a href="#5-2-1-如何-purge" class="headerlink" title="5.2.1 如何 purge"></a>5.2.1 如何 purge</h3><h2 id="tcache"><a href="#tcache" class="headerlink" title="tcache"></a>tcache</h2><p>tcache 的主要目标是优化多线程下内存分配性能：</p><ul><li>减少锁争用：通过缓存内存块，线程可以在自己的本地缓存中处理分配和释放操作，避免频繁访问共享的全局 arena 数据结构</li><li>提高分配速度：小对象的内存分配和释放可以直接从 tcache 完成</li><li>降低内存碎片化</li></ul><h3 id="tsd"><a href="#tsd" class="headerlink" title="tsd"></a>tsd</h3><p>tsd 的主要作用是避免线程之间的资源竞争。每个线程可以有自己独立的一份分配器状态。tsd 的实现依赖于线程局部存储（Thread-Local Storage，TLS）。tsd 中就包含了 tcache 结构。tsdn 和 tsd 的区别是 tsdn 是 nullable 的。</p><p>“分配器状态”中包含 <code>tsd_state_t</code> 以及 MALLOC_TSD 中的项目。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">tsd_s</span> &#123;</span></span><br><span class="line">    <span class="keyword">tsd_state_t</span> state;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> O(n, t)                             \</span></span><br><span class="line">    t       n;</span><br><span class="line">MALLOC_TSD</span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> O</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>MALLOC_TSD 中的项目有</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MALLOC_TSD                          \</span></span><br><span class="line"><span class="comment">/*  O(name,         type) */</span>                \</span><br><span class="line">    O(tcache,           <span class="keyword">tcache_t</span> *)             \</span><br><span class="line">    O(thread_allocated,     <span class="keyword">uint64_t</span>)               \</span><br><span class="line">    O(thread_deallocated,   <span class="keyword">uint64_t</span>)               \</span><br><span class="line">    O(prof_tdata,       <span class="keyword">prof_tdata_t</span> *)             \</span><br><span class="line">    O(iarena,           <span class="keyword">arena_t</span> *)              \</span><br><span class="line">    O(arena,            <span class="keyword">arena_t</span> *)              \</span><br><span class="line">    O(arenas_tdata,     <span class="keyword">arena_tdata_t</span> *)            \</span><br><span class="line">    O(narenas_tdata,        <span class="keyword">unsigned</span>)               \</span><br><span class="line">    O(arenas_tdata_bypass,  <span class="keyword">bool</span>)                   \</span><br><span class="line">    O(tcache_enabled,       <span class="keyword">tcache_enabled_t</span>)           \</span><br><span class="line">    O(quarantine,       <span class="keyword">quarantine_t</span> *)             \</span><br><span class="line">    O(witnesses,        <span class="keyword">witness_list_t</span>)             \</span><br><span class="line">    O(witness_fork,     <span class="keyword">bool</span>)                   \</span><br></pre></td></tr></table></figure><h3 id="tcache-alloc-small"><a href="#tcache-alloc-small" class="headerlink" title="tcache_alloc_small"></a>tcache_alloc_small</h3><p>以 small 对象为例，尝试分配。</p><p>首先通过 tcache_alloc_easy 从对应的 bin 中选择尝试分配。如果失败，则要调用 arena_tcache_fill_small 从 arena 中申请整块 run 进行分配，run 剩余部分也归这个 tcache。</p><p>首先了解下结构</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">tcache_bin_s</span> &#123;</span></span><br><span class="line">    <span class="keyword">tcache_bin_stats_t</span> tstats;</span><br><span class="line">    <span class="keyword">int</span>     low_water;  <span class="comment">/* Min # cached since last GC. */</span></span><br><span class="line">    <span class="keyword">unsigned</span>    lg_fill_div;    <span class="comment">/* Fill (ncached_max &gt;&gt; lg_fill_div). */</span></span><br><span class="line">    <span class="keyword">unsigned</span>    ncached;    <span class="comment">/* # of cached objects. */</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * To make use of adjacent cacheline prefetch, the items in the avail</span></span><br><span class="line"><span class="comment">     * stack goes to higher address for newer allocations.  avail points</span></span><br><span class="line"><span class="comment">     * just above the available space, which means that</span></span><br><span class="line"><span class="comment">     * avail[-ncached, ... -1] are available items and the lowest item will</span></span><br><span class="line"><span class="comment">     * be allocated first.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">void</span>        **avail;    <span class="comment">/* Stack of available objects. */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>在 full 的时候，需要分配 ncached_max &gt;&gt; lg_fill_div 到 avail 结构中。lg_fill_div 是一个从 1 开始动态调整的值。对于 small 分配，ncached_max 是 TCACHE_NSLOTS_SMALL_MIN = 20。</p><p>arena_tcache_fill_small 的实现就是调用 arena_run_reg_alloc 在 run 中分配。如果没有 run，或者 run 用完了，就 arena_bin_malloc_hard。这个函数也会设置 runcur，所以后续的调用能够使用。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span></span><br><span class="line">arena_tcache_fill_small(<span class="keyword">tsdn_t</span> *tsdn, <span class="keyword">arena_t</span> *arena, <span class="keyword">tcache_bin_t</span> *tbin,</span><br><span class="line">    <span class="keyword">szind_t</span> binind, <span class="keyword">uint64_t</span> prof_accumbytes)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> i, nfill;</span><br><span class="line">    <span class="keyword">arena_bin_t</span> *bin;</span><br><span class="line"></span><br><span class="line">    assert(tbin-&gt;ncached == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config_prof &amp;&amp; arena_prof_accum(tsdn, arena, prof_accumbytes))</span><br><span class="line">        prof_idump(tsdn);</span><br><span class="line">    bin = &amp;arena-&gt;bins[binind];</span><br><span class="line">    malloc_mutex_lock(tsdn, &amp;bin-&gt;lock);</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>, nfill = (tcache_bin_info[binind].ncached_max &gt;&gt;</span><br><span class="line">        tbin-&gt;lg_fill_div); i &lt; nfill; i++) &#123;</span><br><span class="line">        <span class="keyword">arena_run_t</span> *run;</span><br><span class="line">        <span class="keyword">void</span> *ptr;</span><br><span class="line">        <span class="keyword">if</span> ((run = bin-&gt;runcur) != <span class="literal">NULL</span> &amp;&amp; run-&gt;nfree &gt; <span class="number">0</span>)</span><br><span class="line">            ptr = arena_run_reg_alloc(run, &amp;arena_bin_info[binind]);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            ptr = arena_bin_malloc_hard(tsdn, arena, bin);</span><br><span class="line">        <span class="keyword">if</span> (ptr == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * OOM.  tbin-&gt;avail isn't yet filled down to its first</span></span><br><span class="line"><span class="comment">             * element, so the successful allocations (if any) must</span></span><br><span class="line"><span class="comment">             * be moved just before tbin-&gt;avail before bailing out.</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                memmove(tbin-&gt;avail - i, tbin-&gt;avail - nfill,</span><br><span class="line">                    i * <span class="keyword">sizeof</span>(<span class="keyword">void</span> *));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (config_fill &amp;&amp; unlikely(opt_junk_alloc)) &#123;</span><br><span class="line">            arena_alloc_junk_small(ptr, &amp;arena_bin_info[binind],</span><br><span class="line">                <span class="literal">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* Insert such that low regions get used first. */</span></span><br><span class="line">        *(tbin-&gt;avail - nfill + i) = ptr;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (config_stats) &#123;</span><br><span class="line">        bin-&gt;stats.nmalloc += i;</span><br><span class="line">        bin-&gt;stats.nrequests += tbin-&gt;tstats.nrequests;</span><br><span class="line">        bin-&gt;stats.curregs += i;</span><br><span class="line">        bin-&gt;stats.nfills++;</span><br><span class="line">        tbin-&gt;tstats.nrequests = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    malloc_mutex_unlock(tsdn, &amp;bin-&gt;lock);</span><br><span class="line">    tbin-&gt;ncached = i;</span><br><span class="line">    arena_decay_tick(tsdn, arena);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="DSS-Dynamic-Storage-Segments"><a href="#DSS-Dynamic-Storage-Segments" class="headerlink" title="DSS(Dynamic Storage Segments)"></a>DSS(Dynamic Storage Segments)</h2><h2 id="malloc-的简单流程"><a href="#malloc-的简单流程" class="headerlink" title="malloc 的简单流程"></a>malloc 的简单流程</h2><p>主要是调用 ialloc_body。这里 usize 是对应的 size class 的最小值，即 index2size。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">JEMALLOC_EXPORT JEMALLOC_ALLOCATOR JEMALLOC_RESTRICT_RETURN</span><br><span class="line"><span class="keyword">void</span> JEMALLOC_NOTHROW *</span><br><span class="line">JEMALLOC_ATTR(<span class="built_in">malloc</span>) JEMALLOC_ALLOC_SIZE(<span class="number">1</span>)</span><br><span class="line">je_malloc(<span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">void</span> *ret;</span><br><span class="line">    <span class="keyword">tsdn_t</span> *tsdn;</span><br><span class="line">    <span class="keyword">size_t</span> <span class="function">usize <span class="title">JEMALLOC_CC_SILENCE_INIT</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (size == <span class="number">0</span>)</span><br><span class="line">        size = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (likely(!malloc_slow)) &#123;</span><br><span class="line">        ret = ialloc_body(size, <span class="literal">false</span>, &amp;tsdn, &amp;usize, <span class="literal">false</span>);</span><br><span class="line">        ialloc_post_check(ret, tsdn, usize, <span class="string">"malloc"</span>, <span class="literal">true</span>, <span class="literal">false</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        ret = ialloc_body(size, <span class="literal">false</span>, &amp;tsdn, &amp;usize, <span class="literal">true</span>);</span><br><span class="line">        ialloc_post_check(ret, tsdn, usize, <span class="string">"malloc"</span>, <span class="literal">true</span>, <span class="literal">true</span>);</span><br><span class="line">        UTRACE(<span class="number">0</span>, size, ret);</span><br><span class="line">        JEMALLOC_VALGRIND_MALLOC(ret != <span class="literal">NULL</span>, tsdn, ret, usize, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (ret);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ialloc_body 最终通过 ialloc -&gt; iallocztm 走到 arena_malloc。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">JEMALLOC_ALWAYS_INLINE_C <span class="keyword">void</span> *</span><br><span class="line">ialloc_body(<span class="keyword">size_t</span> size, <span class="keyword">bool</span> zero, <span class="keyword">tsdn_t</span> **tsdn, <span class="keyword">size_t</span> *usize,</span><br><span class="line">    <span class="keyword">bool</span> slow_path)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">tsd_t</span> *tsd;</span><br><span class="line">    <span class="keyword">szind_t</span> ind;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (slow_path &amp;&amp; unlikely(malloc_init())) &#123;</span><br><span class="line">        *tsdn = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tsd = tsd_fetch();</span><br><span class="line">    *tsdn = tsd_tsdn(tsd);</span><br><span class="line">    witness_assert_lockless(tsd_tsdn(tsd));</span><br><span class="line"></span><br><span class="line">    ind = size2index(size);</span><br><span class="line">    <span class="keyword">if</span> (unlikely(ind &gt;= NSIZES))</span><br><span class="line">        <span class="keyword">return</span> (<span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config_stats || (config_prof &amp;&amp; opt_prof) || (slow_path &amp;&amp;</span><br><span class="line">        config_valgrind &amp;&amp; unlikely(in_valgrind))) &#123;</span><br><span class="line">        *usize = index2size(ind);</span><br><span class="line">        assert(*usize &gt; <span class="number">0</span> &amp;&amp; *usize &lt;= HUGE_MAXCLASS);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config_prof &amp;&amp; opt_prof)</span><br><span class="line">        <span class="keyword">return</span> (ialloc_prof(tsd, *usize, ind, zero, slow_path));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (ialloc(tsd, size, ind, zero, slow_path));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>arena_malloc 中，如果开启了 tcache，就尝试从 tcache 去分配。否则，直接通过 arena_malloc_hard 从 arena 分配。所以在 4.5 中，大部分情况下的 small 和 large 都是通过 tcache 走的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">JEMALLOC_ALWAYS_INLINE <span class="keyword">void</span> *</span><br><span class="line">arena_malloc(<span class="keyword">tsdn_t</span> *tsdn, <span class="keyword">arena_t</span> *arena, <span class="keyword">size_t</span> size, <span class="keyword">szind_t</span> ind, <span class="keyword">bool</span> zero,</span><br><span class="line">    <span class="keyword">tcache_t</span> *tcache, <span class="keyword">bool</span> slow_path)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    assert(!tsdn_null(tsdn) || tcache == <span class="literal">NULL</span>);</span><br><span class="line">    assert(size != <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (likely(tcache != <span class="literal">NULL</span>)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (likely(size &lt;= SMALL_MAXCLASS)) &#123;</span><br><span class="line">            <span class="keyword">return</span> (tcache_alloc_small(tsdn_tsd(tsdn), arena,</span><br><span class="line">                tcache, size, ind, zero, slow_path));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (likely(size &lt;= tcache_maxclass)) &#123;</span><br><span class="line">            <span class="keyword">return</span> (tcache_alloc_large(tsdn_tsd(tsdn), arena,</span><br><span class="line">                tcache, size, ind, zero, slow_path));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* (size &gt; tcache_maxclass) case falls through. */</span></span><br><span class="line">        assert(size &gt; tcache_maxclass);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (arena_malloc_hard(tsdn, arena, size, ind, zero));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="从实现分析设计理念"><a href="#从实现分析设计理念" class="headerlink" title="从实现分析设计理念"></a>从实现分析设计理念</h1><h2 id="最大化内存分配和释放的性能"><a href="#最大化内存分配和释放的性能" class="headerlink" title="最大化内存分配和释放的性能"></a>最大化内存分配和释放的性能</h2><p>主要体现在：</p><ul><li>避免大量的向系统申请内存的动作</li><li>快速定位可以被用来分配的内存</li></ul><p>快速定位上：</p><ul><li>给定任意地址 ptr，通过 CHUNK_ADDR2BASE 就可以找到对应的 chunk 的地址，进而就可以找到对应的几个元信息。诸如 map_bias 的是全局变量，所以也能在常数时间中计算得到 bits 和 mics 的偏移。</li><li>通过 ptr 和 chunk 的地址 c，就可以通过 <code>((uintptr_t)ptr - (uintptr_t)chunk)&gt;&gt;LG_PAGE</code> 算出 page id。</li></ul><p>chunk 的分配上：</p><ul><li>使用红黑树缓存之前已经分配，但是目前空闲的 chunk。使用两种红黑树来支持两种排序方式：size、address 和 address。</li><li>使用 spare 缓存最近空闲的 chunk，减少对红黑树的访问。</li><li>使用 retain 缓存之前已经分配，但是目前被释放了的 chunk。</li></ul><h2 id="减少内部碎片和外部碎片"><a href="#减少内部碎片和外部碎片" class="headerlink" title="减少内部碎片和外部碎片"></a>减少内部碎片和外部碎片</h2><p>chunk 的各个 page 和各个 run 的元信息都放在了 chunk 头部，减少了内部碎片。</p><h2 id="减少线程之间的竞争"><a href="#减少线程之间的竞争" class="headerlink" title="减少线程之间的竞争"></a>减少线程之间的竞争</h2><p>jemalloc 会创建多个 arena，每个线程由一个 arena 负责。默认创建 CPU * 4 数量的 arena。在每个 arena 中使用 nthreads 记录负责的线程数量。</p><p>每个线程分配内存时，会基于下面的逻辑选择 arena：</p><ul><li>若 nthreads==0 已创建的 arena，则选择该 arena</li><li>若还有未创建的 arena，则选择新创建一个 arena</li><li>选择 nthreads 最少的 arena</li></ul><h1 id="后续版本的一些优化"><a href="#后续版本的一些优化" class="headerlink" title="后续版本的一些优化"></a>后续版本的一些优化</h1><h2 id="background-thread"><a href="#background-thread" class="headerlink" title="background thread"></a>background thread</h2><p>线程名是 <code>jemalloc_bg_thd</code>。</p><h2 id="opt-retain"><a href="#opt-retain" class="headerlink" title="opt_retain"></a>opt_retain</h2><p>主要是在 dealloc 的时候要不要调用 pages_unmap。</p><p>在 5.2.1 中引入了 opt_retain。如果开启了 opt_retain，那么进行 munmap 可能还会导致 rss 无法快速释放。原因是 purge 的时候可能使用 MADV_FREE。【Q】但实际我好像没观察到这一部分影响有多大。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span></span><br><span class="line">pages_purge_lazy(<span class="keyword">void</span> *addr, <span class="keyword">size_t</span> size) &#123;</span><br><span class="line">    assert(ALIGNMENT_ADDR2BASE(addr, os_page) == addr);</span><br><span class="line">    assert(PAGE_CEILING(size) == size);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!pages_can_purge_lazy) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!pages_can_purge_lazy_runtime) &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Built with lazy purge enabled, but detected it was not</span></span><br><span class="line"><span class="comment">         * supported on the current system.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> _WIN32</span></span><br><span class="line">    VirtualAlloc(addr, size, MEM_RESET, PAGE_READWRITE);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(JEMALLOC_PURGE_MADVISE_FREE)</span></span><br><span class="line">    <span class="keyword">return</span> (madvise(addr, size,</span><br><span class="line">#  ifdef MADV_FREE</span><br><span class="line">        MADV_FREE</span><br><span class="line">#  <span class="keyword">else</span></span><br><span class="line">        JEMALLOC_MADV_FREE</span><br><span class="line">#  endif</span><br><span class="line">        ) != <span class="number">0</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(JEMALLOC_PURGE_MADVISE_DONTNEED) &amp;&amp; \</span></span><br><span class="line">    !defined(JEMALLOC_PURGE_MADVISE_DONTNEED_ZEROS)</span><br><span class="line">    <span class="keyword">return</span> (madvise(addr, size, MADV_DONTNEED) != <span class="number">0</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    not_reached();</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="一些写法"><a href="#一些写法" class="headerlink" title="一些写法"></a>一些写法</h1><h2 id="计算-map-bias"><a href="#计算-map-bias" class="headerlink" title="计算 map_bias"></a>计算 map_bias</h2><p>在 arena_boot 中计算。</p><p>变量常量介绍：</p><ul><li>chunk_npages 表示 chunk 中 page 的总数。</li><li>LG_PAGE：一个 page 是 2 ** LG_PAGE 这么大。</li></ul><p>每次迭代算出一个 header_size，并向上取整计算 header 需要多少 page 存放。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">map_bias = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">size_t</span> header_size = offsetof(<span class="keyword">arena_chunk_t</span>, map_bits) +</span><br><span class="line">        ( ( <span class="keyword">sizeof</span>(<span class="keyword">arena_chunk_map_bits_t</span>) +</span><br><span class="line">            <span class="keyword">sizeof</span>(<span class="keyword">arena_chunk_map_misc_t</span>) ) * (chunk_npages-map_bias) );</span><br><span class="line">    map_bias = (header_size + PAGE_MASK) &gt;&gt; LG_PAGE;</span><br><span class="line">&#125;</span><br><span class="line">assert(map_bias &gt; <span class="number">0</span>);</span><br></pre></td></tr></table></figure><p>随便取几个值跑下这个算法，可以看出，第二个迭代中，实际分配的 header 的大小 allocated_header_size 可能小于真实需要的 header 大小 real_payload_header_size。如果 bits_size + misc_size 越大，那么这个效应越明显。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> bits_size = <span class="number">4</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> misc_size = <span class="number">128</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> fixed_head = <span class="number">1024</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> chunk_npages = <span class="number">4096</span>;</span><br><span class="line">    <span class="keyword">int</span> map_bias = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">size_t</span> header_size = fixed_head +</span><br><span class="line">            ( ( bits_size +</span><br><span class="line">                misc_size ) * (chunk_npages-map_bias) );</span><br><span class="line">        map_bias = (header_size + <span class="number">4096</span>) &gt;&gt; <span class="number">12</span>;</span><br><span class="line">        <span class="keyword">int</span> allocated_header_size = map_bias * <span class="number">4096</span>;</span><br><span class="line">        <span class="keyword">int</span> real_payload_header_size = (bits_size + misc_size) * (chunk_npages-map_bias) + fixed_head;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"map_bias %u payload %u header_size %u real_payload_header_size %u allocated_header_size %u\n"</span>, map_bias, chunk_npages-map_bias, header_size, real_payload_header_size, allocated_header_size);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">map_bias <span class="number">133</span> payload <span class="number">3963</span> header_size <span class="number">541696</span> real_payload_header_size <span class="number">524140</span> allocated_header_size <span class="number">544768</span></span><br><span class="line">map_bias <span class="number">128</span> payload <span class="number">3968</span> header_size <span class="number">524140</span> real_payload_header_size <span class="number">524800</span> allocated_header_size <span class="number">524288</span></span><br><span class="line">map_bias <span class="number">129</span> payload <span class="number">3967</span> header_size <span class="number">524800</span> real_payload_header_size <span class="number">524668</span> allocated_header_size <span class="number">528384</span></span><br></pre></td></tr></table></figure><p>可见：</p><ul><li>第一个迭代假设每个 page 都有一个 map_bit 和 map_misc，这种情况下算出来的 map_bias 偏大，payload 就少了。</li><li>第二个迭代因为 payload 少了，所以 header 就会偏小。</li></ul><h1 id="一些结构"><a href="#一些结构" class="headerlink" title="一些结构"></a>一些结构</h1><h2 id="qr"><a href="#qr" class="headerlink" title="qr"></a>qr</h2><p>是一个 deque，或者 List 的实现。</p><h2 id="rb"><a href="#rb" class="headerlink" title="rb"></a>rb</h2><p>提供了红黑树相关的方法，例如 <code>_remove</code> 等。</p><p>红黑树被广泛使用，例如：</p><ul><li>extent_tree_szad_</li><li>extent_tree_ad_</li></ul><h2 id="extent"><a href="#extent" class="headerlink" title="extent"></a>extent</h2><p>extent 是一个基于红黑树的，用来分配内存的结构。</p><p>一般调用类似 <code>extent_tree_szad_remove</code> 的方法，表示从 extent 中分配一块内存。此时，会从 extent 的 szad 中删除对应内存的标记信息。</p><h2 id="bitmap"><a href="#bitmap" class="headerlink" title="bitmap"></a>bitmap</h2><p>bitmap 中记录了一些比较有趣的实现。比如 <code>USE_TREE</code> 提出了一个有意思的结构。</p><p>bitmap 初始都是 1，set 一个位会将它变为 0。然后有一系列的比如 full、get、set、unset 之类的方法。包括 sfu 这个方法可以查询第一个 bit 0 的位置，然后将其设置为 1。</p><h2 id="phn"><a href="#phn" class="headerlink" title="phn"></a>phn</h2><p>这是一个堆的实现。</p><h2 id="base"><a href="#base" class="headerlink" title="base"></a>base</h2><p>这是 base allocator，是 jemalloc 初始化时候使用的一个低级分配方式。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> *</span><br><span class="line">base_alloc(<span class="keyword">tsdn_t</span> *tsdn, <span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line">...</span><br><span class="line">    usize = s2u(csize);</span><br><span class="line">    extent_node_init(&amp;key, <span class="literal">NULL</span>, <span class="literal">NULL</span>, usize, <span class="literal">false</span>, <span class="literal">false</span>);</span><br><span class="line">    malloc_mutex_lock(tsdn, &amp;base_mtx);</span><br><span class="line">    node = extent_tree_szad_nsearch(&amp;base_avail_szad, &amp;key);</span><br><span class="line">    <span class="keyword">if</span> (node != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="comment">/* Use existing space. */</span></span><br><span class="line">        extent_tree_szad_remove(&amp;base_avail_szad, node);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/* Try to allocate more space. */</span></span><br><span class="line">        node = base_chunk_alloc(tsdn, csize);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h1 id="一些知识"><a href="#一些知识" class="headerlink" title="一些知识"></a>一些知识</h1><h2 id="Linux-的-overcommit-机制"><a href="#Linux-的-overcommit-机制" class="headerlink" title="Linux 的 overcommit 机制"></a>Linux 的 overcommit 机制</h2><h2 id="madvise"><a href="#madvise" class="headerlink" title="madvise"></a>madvise</h2><ul><li>MADV_NORMAL<br>  默认行为，内核根据普通访问模式处理页面。</li><li>MADV_RANDOM<br>  随机访问，可能减少 prefetch 操作。</li><li>MADV_SEQUENTIAL<br>  顺序访问，可以增加 prefetch。</li><li>MADV_WILLNEED<br>  表示该内存区域将在未来使用，内核可以提前加载到内存。</li><li>MADV_DONTNEED / MADV_FREE / munmap<br>  三个都是释放内存。后面详细描述。</li><li>MADV_REMOVE<br>  从文件映射中移除内存区域，释放物理内存，同时在映射的文件中移除相应内容（需要文件映射）。</li><li>MADV_DONTFORK<br>  子进程不会继承该内存区域。</li><li>MADV_DOFORK</li><li>MADV_MERGEABLE<br>  启用内存合并（KSM，Kernel Samepage Merging），允许内核将具有相同内容的内存页面合并以节省内存。</li><li>MADV_UNMERGEABLE</li><li>MADV_HUGEPAGE<br>  HugePages</li><li>MADV_NOHUGEPAGE</li><li>MADV_SOFT_OFFLINE<br>  将指定区域中的坏内存页标记为不可用，但不杀死当前进程。</li><li>MADV_HWPOISON<br>  强制将页面标记为硬件错误（仅管理员权限可用）。</li></ul><p>三个释放内存：</p><ul><li>munmap<br>  即时释放物理内存(RSS)以及虚拟地址。</li><li>MADV_DONTNEED<br>  即时释放物理内存(RSS)。保留虚拟地址。</li><li>MADV_FREE<br>  延迟释放。</li></ul><h1 id="一些方法"><a href="#一些方法" class="headerlink" title="一些方法"></a>一些方法</h1><h2 id="如何-debug"><a href="#如何-debug" class="headerlink" title="如何 debug"></a>如何 debug</h2><p>指定 log 这个隐藏 conf，就可以打印日志</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> MALLOC_CONF=<span class="string">"log:."</span></span><br></pre></td></tr></table></figure><p>在需要的地方可以使用</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOG(<span class="string">"module_name"</span>, <span class="string">"formatter"</span>, ...)</span><br></pre></td></tr></table></figure><p>然后可以指定 <code>log:module_name</code>，从而只打印自己想要的一部分日志。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://youjiali1995.github.io/allocator/jemalloc/" target="_blank" rel="noopener">https://youjiali1995.github.io/allocator/jemalloc/</a><br>  基于 4.5 之前的版本</li><li><a href="https://yaoguais.github.io/article/jemalloc/structures.html" target="_blank" rel="noopener">https://yaoguais.github.io/article/jemalloc/structures.html</a></li><li><a href="https://github.com/leebaok/jemalloc-4.2.1-readcode/blob/readcode/readcode/more.md" target="_blank" rel="noopener">https://github.com/leebaok/jemalloc-4.2.1-readcode/blob/readcode/readcode/more.md</a></li><li><a href="https://youjiali1995.github.io/allocator/jemalloc-purge/" target="_blank" rel="noopener">https://youjiali1995.github.io/allocator/jemalloc-purge/</a><br>  5.0.1 版本 purge 的改进</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍下 jemalloc 的实现。目前的实现和 4.5 及之前的实现还是有比较大的差别的。因此代码主要是看的 4.5，并介绍了下 5.2.1 的几个重要的变化。&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
    <category term="内存管理" scheme="http://www.calvinneo.com/tags/内存管理/"/>
    
  </entry>
  
  <entry>
    <title>RocksDB 的 Compaction 策略</title>
    <link href="http://www.calvinneo.com/2024/12/29/rocksdb-compaction/"/>
    <id>http://www.calvinneo.com/2024/12/29/rocksdb-compaction/</id>
    <published>2024-12-29T13:33:22.000Z</published>
    <updated>2024-12-29T17:19:28.296Z</updated>
    
    <content type="html"><![CDATA[<p>如题。</p><a id="more"></a><h1 id="Level-Compaction"><a href="#Level-Compaction" class="headerlink" title="Level Compaction"></a>Level Compaction</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="Compaction-的条件"><a href="#Compaction-的条件" class="headerlink" title="Compaction 的条件"></a>Compaction 的条件</h3><ul><li>当 L0 层的数量达到 level0_file_num_compaction_trigger 后，触发从 L0 到 L1 的 Compaction。<br>  这个值一般是 4，设的较大对写友好，但是读会需要在 L0 扫多个 pass，从而降低读的性能。</li><li>这可能导致 L1 的大小超出限制，此时会选出至少 1 个 L1 层的 SST，和 L2 层合并。</li></ul><p>注意，WAL 切换时不会直接触发 compaction，但是 WAL 切换会导致 MemTable 刷新，并生成新的 SST 文件，这可能间接影响 compaction 的触发条件。</p><h3 id="Parallel-Compaction"><a href="#Parallel-Compaction" class="headerlink" title="Parallel Compaction"></a>Parallel Compaction</h3><ul><li>L1 层往下的 Compaction 是可以并行的</li><li>L0 -&gt; L1 的 Compaction 默认不是并行的，但是有一个 subcompaction-based parallelization 特性。这个时候，一个文件可能会被按照 range 切分，从而和 L1 层的多个文件一同 compact。<br>  <img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/subcompaction.png"></li></ul><h3 id="Pick-Compaction"><a href="#Pick-Compaction" class="headerlink" title="Pick Compaction"></a>Pick Compaction</h3><p>当多个 Level 都满足 Compaction 的条件，则需要计算一个 score，触发最大的 score 对应的那一层：</p><ul><li>对于非 L0，这个得分是当前 size 除以 target size。如果这一层某些文件正在被 compact，那么它们不会被计算在当前 size 内。</li><li>对于 L0，得分是两个的较大者<ul><li>当前 file 的数量，除以 level0_file_num_compaction_trigger</li><li>当前 file 的总大小，除以 max_bytes_for_level_base</li></ul></li></ul><h3 id="Compaction-的条件-1"><a href="#Compaction-的条件-1" class="headerlink" title="Compaction 的条件"></a>Compaction 的条件</h3><ul><li>L0 文件数量超过限制<br>  level0_file_num_compaction_trigger</li><li>层级总大小超过限制<br>  max_bytes_for_level_base</li><li>待压缩数据量超出限制<br>  soft/hard_pending_compaction_bytes_limit</li><li>单个文件大小超过限制<br>  target_file_size_base</li><li>层级间文件重叠</li><li>L0 compaction</li><li>手动触发</li><li>level_compaction_dynamic_level_bytes</li><li>冷数据</li></ul><h3 id="为什么-RocksDB-没有-seek-compaction？"><a href="#为什么-RocksDB-没有-seek-compaction？" class="headerlink" title="为什么 RocksDB 没有 seek compaction？"></a>为什么 RocksDB 没有 seek compaction？</h3><p>首先，RocksDB 有一个 patch，如果一个文件已经被 cache 了，那么就不应该被计算 seek compaction 的惩罚。</p><p><a href="https://github.com/facebook/rocksdb/commit/c1bb32e1ba9da94d9e40af692f60c2c0420685cd" target="_blank" rel="noopener">https://github.com/facebook/rocksdb/commit/c1bb32e1ba9da94d9e40af692f60c2c0420685cd</a></p><blockquote><p>In the current code, a Get() call can trigger compaction if it has to look at more than one file. This causes unnecessary compaction because looking at more than one file is a penalty only if the file is not yet in the cache. Also, th current code counts these files before the bloom filter check is applied.<br>This patch counts a ‘seek’ only if the file fails the bloom filter check and has to read in data block(s) from the storage.</p></blockquote><p>然后发现，<a href="https://wangxuemin.github.io/2016/10/16/leveldb%E7%9A%84seek_compaction/" target="_blank" rel="noopener">改进之后 seek compaction 就较少被触发了</a>，于是为了减少代码复杂度，就被移除了。</p><h2 id="Choose-Level-Compaction-Files"><a href="#Choose-Level-Compaction-Files" class="headerlink" title="Choose Level Compaction Files"></a>Choose Level Compaction Files</h2><p>介绍 Level Compaction 是如何选择 Compact 哪些文件的。</p><h2 id="level-compaction-dynamic-level-bytes"><a href="#level-compaction-dynamic-level-bytes" class="headerlink" title="level_compaction_dynamic_level_bytes"></a>level_compaction_dynamic_level_bytes</h2><p>level_compaction_dynamic_level_bytes 允许 RocksDB 在运行时动态调整每个 Level 的大小，而不是像现在这样使用 10 倍的关系。</p><p>如果 max_bytes_for_level_base 为 false，那么 L1 的大小是 max_bytes_for_level_base，后面每一层都是之前的 max_bytes_for_level_multiplier * max_bytes_for_level_multiplier_additional[n] 倍。</p><p>如果 level_compaction_dynamic_level_bytes 为 true，那么每一层的大小是动态调整的。此时，最下面一层的大小是它的实际大小，然后第 n-1 层的大小是第 n 层的大小除以 max_bytes_for_level_multiplier。如果一层的大小小于 max_bytes_for_level_base / max_bytes_for_level_multiplier，那么我们就不会启用这一层。因此，整个 LSM 结构好像是从最下面一层往上构建的，也就是说 base_level 默认从 1 变成 6，然后逐级向下调整。</p><p><img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/dynamic_level.png"> </p><p>可以简单推演下，当 L6 达到一定阈值后，base_level 会下降到 L5，然后 L0 会直接被 compact 到 L5。当 L5 达到阈值之后，会被 Compact 到 L6，此时 L6 的大小变大，从而推动 L5 的阈值也变大。如此渐进达成收敛，最终 L5 的阈值增大到一定程度后，会产生 L4 来。</p><p>在开启这个选项之后，compaction score 的逻辑也要进行调整。在计算 Ln 的 store 时，现在得 <code>Ln size / (Ln target size + total_downcompact_bytes)</code>。相比之前，加上了一个 total_downcompact_bytes 项。这个项是从 L0 到 Ln-1 一直 compact 到 Ln 所预计需要的总的字节数。如果写入负载更大，那么 compaction debt 更大。这样，更高层的 total_downcompact_bytes 会更大，那么较低的层会被优先 compact。【Q】这段逻辑比较复杂，可能后续需要看看源码。</p><h1 id="Intra-L0-Compaction"><a href="#Intra-L0-Compaction" class="headerlink" title="Intra-L0 Compaction"></a>Intra-L0 Compaction</h1><p>有点类似于 TiFlash 中的 delta compaction。</p><h1 id="FIFO-Compaction"><a href="#FIFO-Compaction" class="headerlink" title="FIFO Compaction"></a>FIFO Compaction</h1><p>实际上是一个很简单的策略。它实际上是定期删除老数据，所以适合时序数据。注意，这种情况下，数据可能被删除。</p><p>在 FIFO Compaction 中，所有的文件都在 level 0。当总大小超过 <code>CompactionOptionsFIFO::max_table_files_size)</code> 之后，就删除最老的 SST。因此写放大是 1，当然，其实还要考虑 WAL 的写放大。</p><p>因为都在 Level 0，所以 FIFO 下 level 0 可能有很多 sst，从而让读取速度变得很慢。这种情况下，建议使用更多的 Bloom bits 从而减少 Bloom filter 的假阳性问题。</p><p>通过设定 <code>CompactionOptionsFIFO.allow_compaction = true</code> 可以拿最少 <code>level0_file_num_compaction_trigger</code> 个文件，将它们 Compaction 到一起。选取的顺序是从新到旧。</p><p>Compact 的逻辑如下面的例子所示。因为 FIFO 中不存在所谓的版本问题了，所以 Compact 的目的就是让多个 SST 文件变成一个有序的大的 SST 文件。</p><blockquote><p>For example, if level0_file_num_compaction_trigger = 8 and every flushed file is 100MB. Then as soon as there is 8 files, they are compacted to one 800MB file. And after we have 8 new 100MB files, they are compacted in the second 800MB, and so on. Eventually we’ll have a list of 800MB files and no more than 8 100MB files.</p></blockquote><p>Compaction 的执行条件：定期检查数据库大小是否超过 <code>compaction_options_fifo.max_table_files_size</code>，如果超过了，就一次 drop 一个最老的文件，直到重新满足大小限制。</p><h2 id="with-TTL"><a href="#with-TTL" class="headerlink" title="with TTL"></a>with TTL</h2><p>现在并不是数据库大小超过某个 size 才 compaction 了。而是直接删除 ttl 比某个值旧的所有 SST 文件。</p><h1 id="Universal-Compaction"><a href="#Universal-Compaction" class="headerlink" title="Universal Compaction"></a>Universal Compaction</h1><h1 id="Remote-Compaction"><a href="#Remote-Compaction" class="headerlink" title="Remote Compaction"></a>Remote Compaction</h1><p><img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/remote_compaction_overview.png"></p><p>从下面的调用图中可以看出，Compaction 命令同样是由 Primary 发出的，但是实际上是由 Compaction worker 执行的。</p><p><img src="https://github.com/facebook/rocksdb/raw/gh-pages-old/pictures/remote_compaction_interface.png"></p><ol><li><p>Schedule<br>The first step is primary DB triggers the compaction, instead of running the compaction locally, it sends the compaction information to a callback in CompactionService. The user needs to implement the CompactionService::Schedule(), which sends the compaction information to a remote process to schedule the compaction.</p></li><li><p>Compact<br>On the remote Compaction Worker side, it needs to run DB::OpenAndCompact() with the compaction information sent from the primary. Based on the compaction information, <strong>the worker opens the DB in read-only mode</strong> and runs the compaction. <strong>The compaction worker cannot change the LSM tree</strong>, it outputs the compaction result to a <strong>temporary location</strong> that the user needs to set.</p></li><li><p>Return Result<br>Once the compaction is done, the compaction result needs to be sent back to primary, which includes the metadata about the compacted SSTs and some internal information. The same as scheduling, the user needs to implement the communication between primary and compaction workers.</p></li><li><p>Install &amp; Purge<br>The primary is waiting for the result by callback CompactionService::Wait(). The result should be passed to that API and return function call. After that, the primary will install the result by renaming the result SST files in the temporary workplace to the LSM files. Then the compaction input files will be purged. As RocksDB is renaming the result SST files, make sure the temporary workplace and the DB are on the same file system. If not, the user needs to copy the file to the DB file system before returning the Wait() call.</p></li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://github.com/facebook/rocksdb/wiki/" target="_blank" rel="noopener">https://github.com/facebook/rocksdb/wiki/</a><br> RocksDB Wiki</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;如题。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="leveldb" scheme="http://www.calvinneo.com/tags/leveldb/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 6</title>
    <link href="http://www.calvinneo.com/2024/12/25/database-paper-6/"/>
    <id>http://www.calvinneo.com/2024/12/25/database-paper-6/</id>
    <published>2024-12-25T13:33:22.000Z</published>
    <updated>2025-02-09T15:09:29.764Z</updated>
    
    <content type="html"><![CDATA[<p>本部分开始为最新的学习笔记。包含 PolarDB Serverless、Monkey: Optimal Navigable Key-Value Store。</p><a id="more"></a><h1 id="PolarDB-Serverless-A-Cloud-Native-Database-for-Disaggregated-Data-Centers"><a href="#PolarDB-Serverless-A-Cloud-Native-Database-for-Disaggregated-Data-Centers" class="headerlink" title="PolarDB Serverless: A Cloud Native Database for Disaggregated Data Centers"></a>PolarDB Serverless: A Cloud Native Database for Disaggregated Data Centers</h1><p><a href="https://users.cs.utah.edu/~lifeifei/papers/polardbserverless-sigmod21.pdf" target="_blank" rel="noopener">https://users.cs.utah.edu/~lifeifei/papers/polardbserverless-sigmod21.pdf</a></p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>大概有三种 cloud 数据库的架构：</p><ol><li>monolithic</li><li>virtual machine with remote disk</li><li>shared storage</li></ol><p>后两种也被统称为存算分离的架构。</p><p>存算一体的架构缺点：</p><ul><li>将 db 分配到对应的机器类似于解决 bin-packing 问题</li><li>难以满足客户的灵活的资源需要</li><li>资源之间没法独立地进行恢复</li></ul><p>下面两种存算分离的架构：CPU 和内存同样存在 bin-packing 的问题，内存开销大。</p><p><img src="/img/dbpaper/polardb-serverless/f1.png"></p><p>因此 PolarDB Serverless 共享了内存。</p><p>和 Aurora、HyperScale 以及 PolarDB 一样，它有一个 RW 的主节点，以及多个 read only replica。它也可以通过提出的 disaggregation 架构支持多个 RW 主节点，但不在这个论文中讨论。</p><p>一些挑战：</p><ul><li>引入共享内存后，事务的正确性。<ul><li>read after write 不会在节点间丢失修改 -&gt; cache invalidation</li><li>RW 节点在 split 或者 merge 一个 B+Tree 的时候，其他的 RO 节点不能看到一个不一致的 B 树 -&gt; global page latch</li><li>不能脏读 -&gt; 在不同的 database node 间同步 read view</li></ul></li></ul><ul><li>网络延迟<ul><li>使用 RDMA CAS 技术提优化 global latch 的获取</li><li>page materialization offloading 技术将 dirty page 从 remote memory 中驱逐，而不是将它们 flush 到存储中</li></ul></li></ul><h2 id="BACKGROUND"><a href="#BACKGROUND" class="headerlink" title="BACKGROUND"></a>BACKGROUND</h2><h3 id="PolarDB"><a href="#PolarDB" class="headerlink" title="PolarDB"></a>PolarDB</h3><p>介绍了 PolarFS。</p><p>RW 和 RO 节点通过 redo log 同步内存状态。通过 LSN 实现一致性，其执行流程是：</p><ol><li>将所有的 redo log flush 到 PolarFS 中</li><li>提交事务</li><li>RW 异步广播消息：read log 以及最新的 LSN 即 LSN_rw。</li><li>当 ROi 收到 RW 的消息后，从 PolarFS 上拉取所有的 redo log，将它们 apply 到 buffer pool 中的 buffered page 里面</li><li>ROi 此时就和 RW 完成了已同步</li><li>ROi 将自己的 LSN_ro 发送给 RW</li><li>RW 可以在后台将 read log 去 truncate 到所有的 LSN_roi 的最小值</li><li>ROi可以处理 LSN_roi 之前的读取，提供 SI 隔离级别</li></ol><p>假设某个 ROk 落后了，比方说落后超过 1M，这样的节点会被发现，并且被踢出集群。</p><p><img src="/img/dbpaper/polardb-serverless/f2.png"></p><h3 id="Disaggregated-Data-Centers"><a href="#Disaggregated-Data-Centers" class="headerlink" title="Disaggregated Data Centers"></a>Disaggregated Data Centers</h3><p><img src="/img/dbpaper/polardb-serverless/f3.png"></p><p>在 disaggregation 架构下，一个数据库实例所需要的计算、内存和存储资源将被分配到同一个 PoD 下面。不同的 db instance 则看见恶意分配到不同的 PoD 下面。计算和内存资源会被尽可能分配到同一个 ToR 下面。</p><p>一台机器有两个 RDMA NIC，他们会被连接到两个 ToR 交换机上面，从而避免网络连接失效。一个 leaf switch group 由多个 leaf switch 组成。ToR switch 连接到 leaf switch 上。</p><h3 id="Serverless-Databases"><a href="#Serverless-Databases" class="headerlink" title="Serverless Databases"></a>Serverless Databases</h3><p>pay-as-you-go model。</p><p>一个 ACU 包含了 2GiB 的内存以及对应的虚拟处理器。这个设定 fixes the resource ratio。比如，分析数据库可能需要更多的内存，而不是 CPU，因为它们可能要 cache 大量的数据。对应的，事务数据库需要大量的 CPU 去处理业务的尖峰。而一个小内存，只要能满足 cache hit，那也是足够的了。</p><h2 id="DESIGN"><a href="#DESIGN" class="headerlink" title="DESIGN"></a>DESIGN</h2><h3 id="Disaggregated-Memory"><a href="#Disaggregated-Memory" class="headerlink" title="Disaggregated Memory"></a>Disaggregated Memory</h3><h4 id="Remote-Memory-Access-Interface"><a href="#Remote-Memory-Access-Interface" class="headerlink" title="Remote Memory Access Interface"></a>Remote Memory Access Interface</h4><p>这里内存也是按照 Page 来组织的。一个 PageID 可以表示为 <code>(space, page_no)</code>。使用 page_register 和 page_unregister 去做类似 RC 一样的内存管理。page_read 从 remote memory pool 拉数据到 local cache。page_write 将 page 从 local cache 写到 remote memory pool。page_invalidate 被 RW 调用，用来将所有 RO 的 local cache 上的 page 设置为无效。</p><h4 id="Remote-Memory-Management"><a href="#Remote-Memory-Management" class="headerlink" title="Remote Memory Management"></a>Remote Memory Management</h4><p>内存分配的单位是 slab，一个 slab 是 1Gb。</p><h5 id="Page-Array-PA"><a href="#Page-Array-PA" class="headerlink" title="Page Array(PA)"></a>Page Array(PA)</h5><p>一个 slab 被一个 PA 结构实现。一个 PA 是一个连续的内存，包含 16KB page 的 array。PA 中的 page 可以被 remote node 通过 RDMA 直接访问，因为他们在启动的时候就已经被注册到 RDMA NIC 上了。</p><p>一个 memory node 也被称为一个 slab node。一个 slab node 管理多个 slab。一个实例可以对应到多个 slab node 上，其中第一个 slab node 称为 home node。home node 中有一些 instance 级别的元数据。</p><h5 id="Page-Address-Table-PAT"><a href="#Page-Address-Table-PAT" class="headerlink" title="Page Address Table (PAT)"></a>Page Address Table (PAT)</h5><p>PAT is a hash table that records the location (slab node id and physical memory address) and reference count of each page. 也就是前面 page_register 和 page_unregister 所操作的东西。</p><p>【Q】这个结构保存在哪里？</p><h5 id="Page-Invalidation-Bitmap-PIB"><a href="#Page-Invalidation-Bitmap-PIB" class="headerlink" title="Page Invalidation Bitmap (PIB)"></a>Page Invalidation Bitmap (PIB)</h5><p>PIB is a bitmap. For each entry in the PAT table, there is an invalidation bit in PIB. Value 0 indicates that the copy of the page in the memory pool is of the latest version, while value 1 means that the RW node has updated the page in its local cache and haven’t written it back to the remote memory pool yet. There is also a local PIB on each RO node, indicating whether each page in the RO node’s local cache is outdated.</p><h3 id="Page-Materialization-Offloading"><a href="#Page-Materialization-Offloading" class="headerlink" title="Page Materialization Offloading"></a>Page Materialization Offloading</h3><p>Aurora 提出 log is database 的理论。将 redo log 看做是增量的 page 修改。Socrates 进一步地，将 log 从 storage 分离。Log 被存在 XLOG 服务中，然后被异步地发送到一系列 page server 中，每一个 page server 负责一个 database partition，独立地重放日志，生成 page 并处理 GetPage@LSN 请求。</p><p>PolarDB 类似于 Socrates，将 PolarFS 设计为分别存放 log 和 page 到两个 chunck 中。redo log 首先被持久化到 log chunkc 中，然后被异步地发送到 page chunck 中。在 page chunck 中，logs 被 apply，从而更新 page。不同于 Socrates，为了重用 PolarFS，log 只会被发送到 page chunk 的 leader 节点，这个节点会物化 page，然后将 update 通过 ParallelRaft 通知给其他的 replica。This method adds additional latency to the ApplyLog operation due to the replication cost. However, it is not a critical issue because ApplyLog is an asynchronous operation not in the critical path. Moreover, since the replicated state machine guarantees data consistency between page chunks, there is no need for an extra gossip protocol among storage nodes like in Aurora.</p><p><img src="/img/dbpaper/polardb-serverless/7.png"></p><h1 id="Monkey-Optimal-Navigable-Key-Value-Store"><a href="#Monkey-Optimal-Navigable-Key-Value-Store" class="headerlink" title="Monkey: Optimal Navigable Key-Value Store"></a>Monkey: Optimal Navigable Key-Value Store</h1><p><a href="https://nivdayan.github.io/monkeykeyvaluestore.pdf" target="_blank" rel="noopener">https://nivdayan.github.io/monkeykeyvaluestore.pdf</a></p><p>个人觉得一篇很好的文章，介绍了 LSM 的 design space。</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Bloom filter 的 FP 率，和最坏情况下的查询开销成正比。</p><blockquote><p>The insight is that worst-case lookup cost is proportional to the sum of the false positive rates of the Bloom filters across all levels of the LSM-tree.</p></blockquote><p>对于不同的层，引入不同的 bloomfilter 的大小。</p><blockquote><p>Monkey allocates memory to filters across different levels so as to minimize this sum.</p></blockquote><p>设计了一个调优工具。感觉类似 《Fast Scans on Key-Value Stores》里面的思路。</p><blockquote><p>Furthermore, we map the LSM-tree design space onto a closed-form model that enables co-tuning the merge policy, the buffer size and the filters’ false positive rates to trade among lookup cost, update cost and/or main memory, depending on the workload (proportion oflookups and updates), the dataset (number and size of entries), and the underlying hardware (main memory available, disk vs. flash). We show how to use this model to answer what-if design questions about how changes in environmental parameters impact performance and how to adapt the various LSM-tree design elements accordingly.</p></blockquote><h2 id="INTRODUCTION-1"><a href="#INTRODUCTION-1" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><blockquote><p>The intuition is that any given amount of main memory allocated to Bloom filters of larger runs brings only a relatively minor benefit in terms of how much it can decrease their false positive rates (to save I/Os). On the contrary, the same amount of memory can have a higher impact in reducing the false positive rate for smaller runs. </p></blockquote><p>调研 Pareto curve 基于内存容量和工作负载，去寻找到查询和更新开销的平衡点。</p><blockquote><p>The second key point in Monkey is navigating the Pareto curve to find the optimal balance between lookup cost and update cost under a given main memory budget and application workload (lookup over update ratio). </p></blockquote><h2 id="BACKGROUND-1"><a href="#BACKGROUND-1" class="headerlink" title="BACKGROUND"></a>BACKGROUND</h2><h3 id="Buffering-Updates"><a href="#Buffering-Updates" class="headerlink" title="Buffering Updates"></a>Buffering Updates</h3><p>首先是下面这张图。</p><p>$M_{buffer}$ 等于 $ P \times B \ times E$。E 是 entry 的大小，B 是一个 disk page 中有多少个 entry，P 是内存中有多少个 disk page 用于 buffer。</p><p>$ N \times \frac{T-1}{T} $ 是怎么来的呢？其实是个等比数列求和</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1 + T + T^2 + ... + T^(L-1) + T^L = N</span><br></pre></td></tr></table></figure><p>套一下公式，然后取 <code>T^L-1</code> 直接约等于 <code>T^L</code>，即可得到结果。</p><p><img src="/img/dbpaper/monkey/f2.png"></p><p>然后，得到另一个 L 关于 T 的公式。</p><p><img src="/img/dbpaper/monkey/e1.png"></p><p>其中，T 是有一个上限的取值，即 $ \frac{N \times E}{M_{buffer}} $。取这个上限时，L 会退化到 1。因为整个数据库才 $ N \times E $ 这么大，挨个按照 tiered 逻辑 dump 下来就是公式这么多个，然后 T 等于它，那么这一层永远将将好填满。</p><h3 id="Merge-Operations"><a href="#Merge-Operations" class="headerlink" title="Merge Operations"></a>Merge Operations</h3><blockquote><p>The essential difference is that a leveled LSM-tree merges runs more greedily and therefore gives a tighter bound on the overall number of runs that a lookup has to probe, but this comes at the expense of a higher amortized update cost. </p></blockquote><p><img src="/img/dbpaper/monkey/f3.png"></p><h3 id="Lookups"><a href="#Lookups" class="headerlink" title="Lookups"></a>Lookups</h3><p>查询从 buffer 开始，从低层往高层走。一旦找到第一个满足要求的就可以立即返回，因为层数越往下，数据是越旧的。</p><blockquote><p>A point lookup starts from the buffer and traverses the levels from lowest to highest (and the runs within those levels from youngest to oldest in the case of tiering). When it finds the first matching entry it terminates. There is no need to look further because entries with the same key at older runs are superseded.</p></blockquote><ul><li>查找一个不存在的值代价可能很高，因为会检查所有 level 中的所有 run</li><li>范围查询需要 sort merge 一系列 run，然后丢掉被 override 掉的数据</li></ul><h3 id="Probing-a-Run"><a href="#Probing-a-Run" class="headerlink" title="Probing a Run"></a>Probing a Run</h3><p>在 1996 年最老的 LSM 设计中，每个 run 是被存储为压缩的 B 树的。</p><blockquote><p>Over the past two decades, however, main memory has become cheaper, so modern designs simply store an array of fence pointers in main memory with min/max information for every disk page of every run.<br>Maintaining a flat array structure is much simpler and leads to good search performance in memory (binary search as each run is sorted).</p></blockquote><p>查询的时候，</p><ul><li>如果是点查，那么就先二分 fencing pointers，然后找到对应的 page</li><li>如果是扫表，也还是二分到对应的 page，然后从这个 page 往后读取</li></ul><p>所以，如果只需要 <code>O(1)</code> 的 disk IO，那么 pointers 的内存大概是 <code>O(N / B)</code>。</p><blockquote><p>For example, with 16 KB disk pages and 4 byte pointers, the fence pointers are smaller by ≈ 4 orders of magnitude than the raw data size. Stated formally, we denote the amount of main memory occupied by the fence pointers as $M_{pointers}$, and we assume throughout this work that $M_{pointers}$ is <code>O(N / B)</code> thereby guaranteeing that probing a run takes <code>O(1)</code> disk I/O for point lookups.</p></blockquote><h3 id="Bloom-Filters"><a href="#Bloom-Filters" class="headerlink" title="Bloom Filters"></a>Bloom Filters</h3><p>FPR 即假阳性率，和 entry 的数量正相关，和 bloom filter 的内存占用负相关。如下面公式所示，其中 entries 表示一个 run 中的 entry 的数量，bits 表示内存中用作这个 run 的 Bloomfilter 的大小。</p><p><img src="/img/dbpaper/monkey/e2.png"></p><p>具体算法可以看<a href="/2017/11/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%80%E6%98%93%E5%A4%8D%E4%B9%A0/#:~:text=%E6%B5%81%E6%95%B0%E6%8D%AE%E5%8F%96%E6%A0%B7-,Bloom%20Filter,-%E6%88%91%E8%AE%B0%E5%BE%97%E4%B9%8B%E5%89%8D">我的文章</a>。</p><p>因为如果出现假阳性，则需要去下一个 sst 文件（tiered）或者下一层（leveled）中去找下一个 run。因此假阳性率实际上就关系到找一个 key 要有多少次 disk IO，从而直接影响到性能。</p><p>Rocksdb 中普遍使用 10 bits 给 Bloomfilter，则假阳性率在 1%。</p><h3 id="Cost-Analysis"><a href="#Cost-Analysis" class="headerlink" title="Cost Analysis"></a>Cost Analysis</h3><p>如何度量最坏情况呢？</p><ul><li>对于 update，度量 amortized worst-case I/O cost，主要和 update 之后的 merge 操作有关</li><li>对于 lookup，度量 zero-result average worst-case I/O cost。原因是它很常见，并且它的 IO overhead 确实很大</li></ul><p>对于最坏情况：</p><ul><li>Tierd<ul><li>Lookup 的 IO 正比于 L、T、FPR 三者乘积</li><li>Update 的 IO 正比于 L / B</li></ul></li><li>Leveled<ul><li>Lookup 的 IO 正比于 L、FPR 二者乘积</li><li>Update 的 IO 正比于 T * L / B</li></ul></li></ul><p>下面这张表中，从 Log 到 Sorted Array，数据越来越有序，但付出的整理的代价也越来越大。<br><img src="/img/dbpaper/monkey/f4-1.png"></p><p>它的计算过程在下面这段话中，其中 $O(e^{-\frac{M_{buffers}}{N}})$ 就是上面的 FPR。其中 $M_{buffers}$ 和 bits 成正比，$N$ 和<br><img src="/img/dbpaper/monkey/f4-2.png"></p><h2 id="LSM-TREE-DESIGN-SPACE"><a href="#LSM-TREE-DESIGN-SPACE" class="headerlink" title="LSM-TREE DESIGN SPACE"></a>LSM-TREE DESIGN SPACE</h2><blockquote><p>The design space of LSM trees spans everything between a write-optimized log to a read-optimized sorted array.</p></blockquote><h3 id="Tuning-the-Merge-Policy-and-Size-Ratio"><a href="#Tuning-the-Merge-Policy-and-Size-Ratio" class="headerlink" title="Tuning the Merge Policy and Size Ratio"></a>Tuning the Merge Policy and Size Ratio</h3><p>Figure 4 是一个很有趣的图。虚线部分是 Tiering 策略的 update 和 lookup 开销随着 T 变化的情况。可以看到，Tiering 策略总体是偏向于写优化的，它读写最优的点，即 T = 2 的时候，也将将才和 Leveling 策略打平。</p><p><img src="/img/dbpaper/monkey/f4.png"></p><p>设置 T 为 2，那么 tiering 和 leveling 这两种策略的更新查找开销是相同的。</p><blockquote><p>The first insight about the design space is that when the size ratio T is set to 2, the complexities of lookup and update costs for tiering and leveling become identical.</p></blockquote><p>特别地，当 T 为 1，则总层数 L 为 1。也就是说这个 LSM 树会退化为 log。</p><blockquote><p>We did not plot the curve to scale, and in reality the markers are much closer to the graph’s origin. However, the shape of the curve and its limits are accurate.</p></blockquote><h3 id="Tuning-Main-Memory-Allocation"><a href="#Tuning-Main-Memory-Allocation" class="headerlink" title="Tuning Main Memory Allocation"></a>Tuning Main Memory Allocation</h3><blockquote><p>The limits of the curve in Figure 4 are determined by the allocation of main memory among the<br>filters $M_{filters}$ and the buffer $M_{buffer}$.</p></blockquote><h3 id="Design-space-contentions"><a href="#Design-space-contentions" class="headerlink" title="Design space contentions"></a>Design space contentions</h3><ol><li>如何将总共 $M_{filters}$ 这么多内存分配给所有的 Bloomfilter？</li><li>如何在 buffer 和 filter 之间分配内存？<br> 例如，根据 Figure 4，如果分配在 buffer 上的内存变多，那么 lookup 和 update 的 cost 就会变低，但是会同时提高 Bloomfilter 的 FP 率，从而又实际上提高了 lookup 的 cost。</li><li>如何调节 size ratio 也就是 T 和 merge policy？</li></ol><h3 id="The-State-of-the-Art"><a href="#The-State-of-the-Art" class="headerlink" title="The State of the Art"></a>The State of the Art</h3><blockquote><p>All LSM-tree based key-value stores that we know of apply static and suboptimal decisions regarding the above contentions. The Bloom filters are all tuned the same, the Buffer size relative to the Bloom filters size is static, and the size ratio and merge policy are also static</p></blockquote><h2 id="MONKEY"><a href="#MONKEY" class="headerlink" title="MONKEY"></a>MONKEY</h2><h3 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h3><p><img src="/img/dbpaper/monkey/f5.png"></p><h4 id="Design-Knobs"><a href="#Design-Knobs" class="headerlink" title="Design Knobs"></a>Design Knobs</h4><p>Those knobs comprise:</p><ul><li>the size ratio among levels T<br>the merge policy (leveling vs. tiering)</li><li>the false positive rates p1…pL assigned to Bloom filters across different levels</li><li>the allocation of main memory M between the buffer $M_{buffer}$ and the filters $M_{filters}$.</li></ul><h4 id="Minimizing-Lookup-Cost"><a href="#Minimizing-Lookup-Cost" class="headerlink" title="Minimizing Lookup Cost"></a>Minimizing Lookup Cost</h4><p>主要是调整了各层的布隆过滤器的 FPR。</p><h4 id="Performance-Prediction"><a href="#Performance-Prediction" class="headerlink" title="Performance Prediction"></a>Performance Prediction</h4><h4 id="Auto-tuning"><a href="#Auto-tuning" class="headerlink" title="Auto tuning"></a>Auto tuning</h4><ul><li>在 4.3 中，用了渐进分析的办法</li><li>在 4.4 中，定义了最坏情况的吞吐，使用了<ul><li>查找和更新开销</li><li>查找和更新的比例</li><li>在持久化存储中读取和写入的开销</li></ul></li></ul><h3 id="Minimizing-Lookup-Cost-1"><a href="#Minimizing-Lookup-Cost-1" class="headerlink" title="Minimizing Lookup Cost"></a>Minimizing Lookup Cost</h3><p>定义 R 是一个返回 0 结果集的点查的 IO 开销，也就是最坏的情况。</p><ul><li><p>We first show that R is equal to the sum of the false positive rates (FPRs) of all Bloom filters.</p></li><li><p>We then show how to tune the Bloom filters’ FPRs across different levels to minimize this sum, subject to a constraint on the overall amount of main memory $M_{filters}$.</p></li><li><p>We assume a fixed entry size E throughout this section</p></li><li><p>in Appendix C we give a iterative optimization algorithm that quickly finds the optimal FPR assignment even when the entry size is variable or changes over time.</p></li></ul><h4 id="Modeling-Average-Worst-Case-Lookup-Cost"><a href="#Modeling-Average-Worst-Case-Lookup-Cost" class="headerlink" title="Modeling Average Worst-Case Lookup Cost"></a>Modeling Average Worst-Case Lookup Cost</h4><p>要扫描的 run 数，对应了所有 Bloomfilter 的 FPR 之和。如下所示，其中 pi 表示每一层的 FPR。</p><p><img src="/img/dbpaper/monkey/e3.png"></p><h4 id="Modeling-Main-Memory-Footprint"><a href="#Modeling-Main-Memory-Footprint" class="headerlink" title="Modeling Main Memory Footprint"></a>Modeling Main Memory Footprint</h4><p>可以重写上面 FPR 的公式，得到 bits 和 FPR 的关系。</p><p>然后，从上面式子，可以根据每一层的 FPR 即 pi，推导出 $M_{filter}$ 的内存占用。</p><p>下面式子的红色框中，通过总的 entry 数量 N 推导出每一层 entry 的数量。因此，求和中的每一项，是每一层的 Bloomfilter 占用的内存。</p><p><img src="/img/dbpaper/monkey/e4.png"></p><h4 id="Minimizing-Lookup-Cost-with-Monkey"><a href="#Minimizing-Lookup-Cost-with-Monkey" class="headerlink" title="Minimizing Lookup Cost with Monkey"></a>Minimizing Lookup Cost with Monkey</h4>]]></content>
    
    
    <summary type="html">&lt;p&gt;本部分开始为最新的学习笔记。包含 PolarDB Serverless、Monkey: Optimal Navigable Key-Value Store。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>数据库中的压缩技术</title>
    <link href="http://www.calvinneo.com/2024/12/21/db-compression/"/>
    <id>http://www.calvinneo.com/2024/12/21/db-compression/</id>
    <published>2024-12-21T13:33:22.000Z</published>
    <updated>2024-12-19T16:50:13.852Z</updated>
    
    <content type="html"><![CDATA[<p>主要包含了数据库中的压缩技术。</p><a id="more"></a><h1 id="常见的编码"><a href="#常见的编码" class="headerlink" title="常见的编码"></a>常见的编码</h1><h2 id="Dictionary-Encoding"><a href="#Dictionary-Encoding" class="headerlink" title="Dictionary Encoding"></a>Dictionary Encoding</h2><h2 id="Run-Length-Encoding-RLE"><a href="#Run-Length-Encoding-RLE" class="headerlink" title="Run-Length Encoding, RLE"></a>Run-Length Encoding, RLE</h2><p>重复出现的数字用重复次数代替。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">AAAAABB</span><br><span class="line">==&gt;</span><br><span class="line">A5B2</span><br></pre></td></tr></table></figure><h2 id="Bitmap-Encoding"><a href="#Bitmap-Encoding" class="headerlink" title="Bitmap Encoding"></a>Bitmap Encoding</h2><p>在布尔类型等 low cardinality 数据列中效率好。对位操作很友好。</p><h2 id="Delta-Encoding"><a href="#Delta-Encoding" class="headerlink" title="Delta Encoding"></a>Delta Encoding</h2><p>计算连续值之间的差值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">9999 10000 9998</span><br><span class="line">==&gt;</span><br><span class="line">9999 +1 -2</span><br></pre></td></tr></table></figure><h2 id="ZigZag-Encoding"><a href="#ZigZag-Encoding" class="headerlink" title="ZigZag Encoding"></a>ZigZag Encoding</h2><p>主要解决负数的补码前导零太多影响压缩的问题。</p><h2 id="Prefix-Encoding-Huffman-Encoding"><a href="#Prefix-Encoding-Huffman-Encoding" class="headerlink" title="Prefix Encoding / Huffman Encoding"></a>Prefix Encoding / Huffman Encoding</h2><p>使用短编码表示高频数据，长编码表示低频数据。</p><h1 id="常见的压缩算法"><a href="#常见的压缩算法" class="headerlink" title="常见的压缩算法"></a>常见的压缩算法</h1><h2 id="LZ4"><a href="#LZ4" class="headerlink" title="LZ4"></a>LZ4</h2><h2 id="LZMA-Lempel-Ziv-Markov-Chain-Algorithm"><a href="#LZMA-Lempel-Ziv-Markov-Chain-Algorithm" class="headerlink" title="LZMA(Lempel-Ziv-Markov Chain Algorithm)"></a>LZMA(Lempel-Ziv-Markov Chain Algorithm)</h2><h2 id="Zstd"><a href="#Zstd" class="headerlink" title="Zstd"></a>Zstd</h2><h2 id="Snappy"><a href="#Snappy" class="headerlink" title="Snappy"></a>Snappy</h2><h2 id="Zlib"><a href="#Zlib" class="headerlink" title="Zlib"></a>Zlib</h2><h2 id="GZip"><a href="#GZip" class="headerlink" title="GZip"></a>GZip</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;主要包含了数据库中的压缩技术。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>Branch prediction 和 Branch target prediction</title>
    <link href="http://www.calvinneo.com/2024/12/19/bp-and-btp/"/>
    <id>http://www.calvinneo.com/2024/12/19/bp-and-btp/</id>
    <published>2024-12-19T07:57:20.000Z</published>
    <updated>2024-12-24T15:14:13.927Z</updated>
    
    <content type="html"><![CDATA[<p>假如 predicate 的概率是未知的，抑或 predicate 只会被设置一次，那么下面那种写法的性能更好呢？</p><ol><li><p>Branch prediction</p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dispatch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (predicate)</span><br><span class="line">        logicA();</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        logicB();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Branch target prediction</p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fp = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_fp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (predicate)</span><br><span class="line">        fp = logicA;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        fp = logicB;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dispatch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    fp();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><a id="more"></a><h1 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h1><blockquote><p>Branch prediction is predicting whether or not the branch will be taken. Branch target prediction is prediction where the branch is going to.</p></blockquote><p>Branch prediction 指的是预测是否选择这个分支。Branch target prediction 是预测这个分支走到哪里。从汇编角度来说，Branch prediction 指的是要不要 <code>test</code> 然后 <code>je</code>。Branch target prediction 指的是 <code>jmp</code> 到一个 <code>$12345</code> 还是一个 <code>$eax</code>。</p><ol><li>Unconditional branch, fixed target<ul><li>无限循环</li><li>goto</li><li>break、continue</li><li>非虚函数调用</li></ul></li><li>Unconditional branch, variable target<ul><li><strong>从函数返回</strong></li><li>虚函数调用</li><li>Function pointer call</li><li>switch 语句：如果被编译为 jump table</li></ul></li><li>Conditional branch, fixed target<ul><li>if</li><li>switch 语句：如果被编译为 if</li><li>带 condition 的 loop</li><li><code>&amp;&amp;</code> 和 <code>||</code> 操作符</li><li><code>?:</code> 这个三目运算符</li></ul></li><li>Conditional branch, variable target<br> 这个情况通常不会发生。但作为优化，编译器可能合成出一个来。比如下面的这个可能被编译成一个 conditional indirect jump，比如 <code>jne *%eax</code>。 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (condition) &#123; obj-&gt;VirtualFunctionCall(); &#125;</span><br></pre></td></tr></table></figure></li></ol><p>一般 variable target 跳转无法内联的成本也要考虑在内。</p><h1 id="Branch-Target-Buffer"><a href="#Branch-Target-Buffer" class="headerlink" title="Branch Target Buffer"></a>Branch Target Buffer</h1><p>对于当前 PC 通过 BTB 预测下一条 PC 是什么。如果预测错了，BTB 的对应条目会被更新。一个 naive 的 BTB 需要和程序本身一样大了。</p><p>所以，BTB 也是一个 LRU 一样的东西。只是 cache 住最可能需要被预测的指令。并且，BTB 的 “key” 也不需要整个 PC，而是 PC 的低几位。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://stackoverflow.com/questions/21608874/branch-prediction-vs-branch-target-prediction" target="_blank" rel="noopener">https://stackoverflow.com/questions/21608874/branch-prediction-vs-branch-target-prediction</a></li><li><a href="https://en.wikipedia.org/wiki/Branch_target_predictor" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Branch_target_predictor</a></li><li><a href="https://stackoverflow.com/questions/32290875/branch-prediction-and-branch-target-prediction-optimization" target="_blank" rel="noopener">https://stackoverflow.com/questions/32290875/branch-prediction-and-branch-target-prediction-optimization</a></li><li><a href="https://one2bla.me/cs6290/lesson4/branch-target-buffer.html" target="_blank" rel="noopener">https://one2bla.me/cs6290/lesson4/branch-target-buffer.html</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;假如 predicate 的概率是未知的，抑或 predicate 只会被设置一次，那么下面那种写法的性能更好呢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Branch prediction&lt;/p&gt;
 &lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;dispatch&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (predicate)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        logicA();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        logicB();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Branch target prediction&lt;/p&gt;
 &lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;fp = &lt;span class=&quot;literal&quot;&gt;nullptr&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;set_fp&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (predicate)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fp = logicA;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fp = logicB;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;dispatch&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    fp();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    
    <category term="profiling" scheme="http://www.calvinneo.com/tags/profiling/"/>
    
    <category term="CPU" scheme="http://www.calvinneo.com/tags/CPU/"/>
    
    <category term="性能" scheme="http://www.calvinneo.com/tags/性能/"/>
    
  </entry>
  
  <entry>
    <title>C++ 协程的使用</title>
    <link href="http://www.calvinneo.com/2024/12/01/C++-coroutine-usage/"/>
    <id>http://www.calvinneo.com/2024/12/01/C++-coroutine-usage/</id>
    <published>2024-12-01T15:07:22.000Z</published>
    <updated>2025-01-18T13:16:35.167Z</updated>
    
    <content type="html"><![CDATA[<p>在上一篇中，介绍了 lewissbaker 的三篇文章，实际上覆盖了 C++ 的无栈协程的实现原理，这里介绍几个常见的协程库的使用。</p><a id="more"></a><h1 id="cppcoro"><a href="#cppcoro" class="headerlink" title="cppcoro"></a>cppcoro</h1><p><a href="https://github.com/lewissbaker/cppcoro" target="_blank" rel="noopener">https://github.com/lewissbaker/cppcoro</a></p><h2 id="修改既有代码"><a href="#修改既有代码" class="headerlink" title="修改既有代码"></a>修改既有代码</h2><h3 id="io"><a href="#io" class="headerlink" title="io"></a>io</h3><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>协程调度的核心思想是避免阻塞线程，而 std::mutex 的同步原语通常会导致线程阻塞。因此，需要用 <code>cppcoro::async_mutex</code> 进行替换。</p><p>注意 std::unique_lock 等这样的锁结构并不是同步原语。它的实现中，没有包含线程上下文切换的部分。而相关的逻辑，实际上是通过调用 std::muex 的 lock 和 unlock 函数来实现的。</p><p>尽管如此，cppcoro 中还是提供了诸如 async_mutex_lock 等结构。但这样的结构是为了实现协程而服务的。可以看对应的章节。</p><h2 id="主要数据结构"><a href="#主要数据结构" class="headerlink" title="主要数据结构"></a>主要数据结构</h2><h3 id="task"><a href="#task" class="headerlink" title="task"></a>task<t></t></h3><p>一段可以被异步计算的逻辑，它是被 lazily 执行的。当 await 它的时候，它开始执行。</p><p>下面给了一个读写文件统计行数的例子，用到了：</p><ol><li><code>co_await cppcoro::read_only_file::open(path);</code></li><li><code>co_await file.read(offset, buffer, sizeof(buffer));</code></li></ol><p>一个 co_await 的函数必须用到 co_await 或者 co_return，但未必会用到 co_yield。返回值的类型为 <code>task&lt;T&gt;</code>。<br>当一个返回 <code>task&lt;T&gt;</code> 的协程被调用时，一个 coroutine frame 会在必要的时候被调用，并且一些参数会被捕获到 coroutine frame 中。在 coroutine body 被执行前，协程就会挂起，然后返回给调用者。协程的返回值是一个 <code>task&lt;T&gt;</code>。</p><p>当这个<code> task&lt;T&gt;</code> 被 co_await 的时候，coroutine body 会开始执行。这会挂起 await 的 coroutine，然后执行被 await 的那个 coroutine。</p><p><code>task&lt;T&gt;</code> 对应的协程通常以 co_return 或者抛出一个异常为结束。之后，在这个线程上，caller 会被 resume。</p><p>如果一个协程已经计算得到了结果，那么 await 它不会导致挂起，而是直接返回结果。</p><p>如果在 await 之前，那个 task 对象就已经被销毁了，那么这个协程就不会被执行，并且析构函数会销毁被捕获的参数，并且释放被 coroutine frame 使用的内存。</p><h3 id="shared-task"><a href="#shared-task" class="headerlink" title="shared_task"></a>shared_task<t></t></h3><p>我理解是单生产者多消费者模式。</p><h3 id="generator-recursive-generator"><a href="#generator-recursive-generator" class="headerlink" title="generator / recursive_generator"></a>generator<t> / recursive_generator<t></t></t></h3><h4 id="generator"><a href="#generator" class="headerlink" title="generator"></a>generator<t></t></h4><p>用法如下所示，但是其中不能使用 co_await，也就是说必须同步地去计算并产生这些值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cppcoro::generator&lt;<span class="keyword">const</span> <span class="built_in">std</span>::<span class="keyword">uint64_t</span>&gt; fibonacci()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="keyword">uint64_t</span> a = <span class="number">0</span>, b = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    co_yield b;</span><br><span class="line">    <span class="keyword">auto</span> tmp = a;</span><br><span class="line">    a = b;</span><br><span class="line">    b += tmp;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">usage</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i : fibonacci())</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (i &gt; <span class="number">1'000'000</span>) <span class="keyword">break</span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; i &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将 fmap 应用到 recursive_generator<t> 将产生 generator<u> 而不是 recursive_generator<u>。</u></u></t></p><h4 id="recursive-generator"><a href="#recursive-generator" class="headerlink" title="recursive_generator"></a>recursive_generator<t></t></h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Lists the immediate contents of a directory.</span></span><br><span class="line">cppcoro::generator&lt;dir_entry&gt; list_directory(<span class="built_in">std</span>::filesystem::path path);</span><br><span class="line"></span><br><span class="line">cppcoro::recursive_generator&lt;dir_entry&gt; list_directory_recursive(<span class="built_in">std</span>::filesystem::path path)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; entry : list_directory(path))</span><br><span class="line">  &#123;</span><br><span class="line">    co_yield entry;</span><br><span class="line">    <span class="keyword">if</span> (entry.is_directory())</span><br><span class="line">    &#123;</span><br><span class="line">      co_yield list_directory_recursive(entry.path());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="async-generator"><a href="#async-generator" class="headerlink" title="async_generator"></a>async_generator<t></t></h3><p>如下所示，可以 co_await 了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cppcoro::async_generator&lt;<span class="keyword">int</span>&gt; ticker(<span class="keyword">int</span> count, threadpool&amp; tp)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    co_await tp.delay(<span class="built_in">std</span>::chrono::seconds(<span class="number">1</span>));</span><br><span class="line">    co_yield i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cppcoro::task&lt;&gt; consumer(threadpool&amp; tp)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">auto</span> sequence = ticker(<span class="number">10</span>, tp);</span><br><span class="line">  <span class="function"><span class="keyword">for</span> <span class="title">co_await</span><span class="params">(<span class="built_in">std</span>::<span class="keyword">uint32_t</span> i : sequence)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Tick "</span> &lt;&lt; i &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="async-mutex"><a href="#async-mutex" class="headerlink" title="async_mutex"></a>async_mutex</h3><p>co_wait 这个 async_mutex 会挂起这个协程，直到这个 mutex 被释放。</p><p>这里和 std::mutex 不同的是，async_mutex 是 lock free 的。lock 它并不会 block 当前线程，而只是挂起当前的 coroutine。</p><p>如下所示，lock_async 调用会返回一个 async_mutex_lock_operation。这个 async_mutex_lock_operation 必须要被 co_await。co_await 的返回值的类型是 void。</p><p>scoped_lock_async 调用会返回一个 async_mutex_scoped_lock_operation。同样它也需要被 co_await。co_await 返回值的类型是 async_mutex_lock。async_mutex_lock 在析构的时候会自动调用持有的 mutex 的 unlock 方法。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// &lt;cppcoro/async_mutex.hpp&gt;</span></span><br><span class="line"><span class="keyword">namespace</span> cppcoro</span><br><span class="line">&#123;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_lock</span>;</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_lock_operation</span>;</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_scoped_lock_operation</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex</span></span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    async_mutex() <span class="keyword">noexcept</span>;</span><br><span class="line">    ~async_mutex();</span><br><span class="line"></span><br><span class="line">    async_mutex(<span class="keyword">const</span> async_mutex&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    <span class="function">async_mutex&amp; <span class="title">operator</span><span class="params">(<span class="keyword">const</span> async_mutex&amp;)</span> </span>= <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">try_lock</span><span class="params">()</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function">async_mutex_lock_operation <span class="title">lock_async</span><span class="params">()</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function">async_mutex_scoped_lock_operation <span class="title">scoped_lock_async</span><span class="params">()</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_lock_operation</span></span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt; awaiter)</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_scoped_lock_operation</span></span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">await_ready</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">await_suspend</span><span class="params">(<span class="built_in">std</span>::experimental::coroutine_handle&lt;&gt; awaiter)</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">    [[nodiscard]] <span class="function">async_mutex_lock <span class="title">await_resume</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">async_mutex_lock</span></span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// Takes ownership of the lock.</span></span><br><span class="line">    async_mutex_lock(async_mutex&amp; mutex, <span class="built_in">std</span>::<span class="keyword">adopt_lock_t</span>) <span class="keyword">noexcept</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Transfer ownership of the lock.</span></span><br><span class="line">    async_mutex_lock(async_mutex_lock&amp;&amp; other) <span class="keyword">noexcept</span>;</span><br><span class="line"></span><br><span class="line">    async_mutex_lock(<span class="keyword">const</span> async_mutex_lock&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    async_mutex_lock&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> async_mutex_lock&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Releases the lock by calling unlock() on the mutex.</span></span><br><span class="line">    ~async_mutex_lock();</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="sync-wait"><a href="#sync-wait" class="headerlink" title="sync_wait"></a>sync_wait</h3><p>类似于 rust tokio 的 <code>block_on</code>。</p><h3 id="when-all-ready-when-all"><a href="#when-all-ready-when-all" class="headerlink" title="when_all_ready/when_all"></a>when_all_ready/when_all</h3><p>类似于 rust tokio 的 <code>futures::join!</code>。两者比较，则 when_all_ready 的功能更强大：</p><ol><li>when_all_ready 可以等所有的协程都成功或者失败地跑完，然后分别获取每个操作的结果，它本身不会抛出异常。而 when_all 中，只要有一个 task 抛出异常，那么整个 task 就会抛出异常然后失败。</li><li>when_all_ready 的返回值是 when_all_task，需要调用 result() 获取结果。而 when_all 返回的是 void 或者 vector。</li></ol><h3 id="fmap"><a href="#fmap" class="headerlink" title="fmap"></a>fmap</h3>]]></content>
    
    
    <summary type="html">&lt;p&gt;在上一篇中，介绍了 lewissbaker 的三篇文章，实际上覆盖了 C++ 的无栈协程的实现原理，这里介绍几个常见的协程库的使用。&lt;/p&gt;</summary>
    
    
    
    
    <category term="C++" scheme="http://www.calvinneo.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 5</title>
    <link href="http://www.calvinneo.com/2024/11/23/database-paper-5/"/>
    <id>http://www.calvinneo.com/2024/11/23/database-paper-5/</id>
    <published>2024-11-23T13:33:22.000Z</published>
    <updated>2025-01-18T17:21:50.351Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章中，包含 Fast scans on key-value stores、PebblesDB、Snowflake。</p><a id="more"></a><h1 id="Fast-Scans-on-Key-Value-Stores"><a href="#Fast-Scans-on-Key-Value-Stores" class="headerlink" title="Fast Scans on Key-Value Stores"></a>Fast Scans on Key-Value Stores</h1><p><a href="https://vldb.org/pvldb/vol10/p1526-bocksrocker.pdf" target="_blank" rel="noopener">https://vldb.org/pvldb/vol10/p1526-bocksrocker.pdf</a></p><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>KVS 的扩展性能好，get/put 的吞吐量大，延迟低。但是对于复杂的分析查询中，scan 的代价比较高。因为查询类型的请求需要一个很高的 locality，以及 data 的一个 compact representation。但是，弹性的 get/put 依赖 sparse indexes。</p><p>他们做了个 Tellstore，发现它的 get put 性能不差，但是分析以及混合负载的性能很好。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>KVS 的好处，相比传统数据库，除了 abstract 中提到的，还有就是它每一次读写请求的耗时是可预测的，有助于支持 SLA。</p><blockquote><p>As a result, systems for analytical workloads provide additional access methods: They allow data to be fetched all at once (full table scan) and to push down selection predicates and projections to the storage layer. Most KVS do not have such capabilities and those that do, cannot execute scans with acceptable performance.</p></blockquote><p>下面介绍了作者的实验。是 50M 的 YCSB Q1 在四台机器上跑。Cassandra 花了 19 分钟才跑完，非常离谱。RocksDB、MemSQL 和 Kudu 的性能能接受。注意，RocksDB 是单机数据库，所以实验是用了单个机器，跑了 1/4 的数据。但是他们相比真的 realtime，也就是 subsecond 级别，还是很遥远的。<br><img src="/img/dbpaper/tellstore/1.png"></p><blockquote><p>Efficient scans require a high degree of spatial locality whereas get/put requires sparse indexes. <strong>Versioning and garbage collection</strong> are additional considerations whose implementation greatly impacts performance. This paper shows that with reasonable compromises it is possible to support both workloads as well as mixed workloads in the same KVS, <strong>without copying the data</strong>.</p></blockquote><h2 id="REQUIREMENTS"><a href="#REQUIREMENTS" class="headerlink" title="REQUIREMENTS"></a>REQUIREMENTS</h2><h3 id="SQL-over-NoSQL-Architecture"><a href="#SQL-over-NoSQL-Architecture" class="headerlink" title="SQL-over-NoSQL Architecture"></a>SQL-over-NoSQL Architecture</h3><p>下面就是作者提出的架构。Commit Manager 是用来保证 SI 的。SI 或者其他的 MVCC 实现已经成为 HTAP 的 De facto standard 因为这样 OLTP 不会和 OLAP 发生 block 或者 interfere。</p><p>下面介绍了 Commit manager 的功能，看起来类似于一个中心授时的服务，以及一个事务的仲裁机制。</p><blockquote><p>With Snapshot Isolation, the commit manager simply assigns transaction timestamps and keeps track of active, committed, and aborted transactions and, thus, rarely becomes the bottleneck of the system.</p></blockquote><p>这样的 SQL-over-NoSQL 架构的好处是提供了弹性。每一层中都可以独立地添加机器。比如可以快速扩容出一个 AP 节点用来做分析查询，然后查完了再删掉。</p><p><img src="/img/dbpaper/tellstore/2.png"></p><p>进一步精细化了这样的 SQL-over-NoSQL 需要满足的条件：</p><ul><li>Scans<br>  In addition to get/put requests, the KVS must support efficient scan operations. In order to reduce communication costs, the KVS should support selections, projections, and simple aggregates so that only the relevant data for a query are shipped from the storage to the processing layer. Furthermore, support for shared scans is a big plus for many applications [38, 50, 46].</li><li>Versioning<br>  To support Multi-Version Concurrency Control, the KVS must maintain different versions of each record and return the right version of each record depending on the timestamp of the transaction. Versioning involves garbage collection to reclaim storage occupied by old versions of records. </li><li>Batching and Asynchronous<br>  Communication To achieve high OLTP performance, it is critical that OLTP processing nodes batch several requests to the storage layer. This way, the cost of a roundtrip message from the processing to the <strong>storage layer</strong> is amortized for <strong>multiple concurrent transactions</strong> [30]. Furthermore, such batched requests must be executed in an asynchronous way so that the processing node can collect the <strong>next batch</strong> of requests while <strong>waiting for</strong> the previous batch of requests to the KVS to complete.</li></ul><h3 id="Why-is-it-Difficult"><a href="#Why-is-it-Difficult" class="headerlink" title="Why is it Difficult?"></a>Why is it Difficult?</h3><p>作者的意思是，因为上面三个条件冲突，所以很多除了 Kudu 之外的 KVS 现在都只支持点查，比如 Cassandra 或者 HBase。诸如 HBase 或者 RAMCloud 的可能还会多支持一个 Versioning，sometimes 会有 async communication。上n. All<br>these features are best supported with sparse data structures for get/put operations. When retrieving a specific version of a record, it is not important whether it is clustered and stored compactly with other records. 但是 scan 就对 data locality 和一个紧凑的表示有要求了。Locality 对于基于磁盘的扫描，或者只在内存中的扫描都很重要。具体来说，添加 scan 有下面的局部性冲突：</p><ol><li>Scan vs. Get/Put<br> 分析系统需要列存提高 locality。KVS 喜欢行存，这样就可以在不物化 records 的情况下处理点查请求。</li><li>Scan vs. Versioning<br> 这个不用多说了。</li><li>Scan vs. Batching<br> scan 和点查做 batch 没有什么好处。TP 负载需要低延迟，scan 的负载的延迟变化很大，取决于 predicate 以及要读取的列的数量。</li></ol><h2 id="DESIGN-SPACE"><a href="#DESIGN-SPACE" class="headerlink" title="DESIGN SPACE"></a>DESIGN SPACE</h2><h3 id="Where-to-Put-Updates"><a href="#Where-to-Put-Updates" class="headerlink" title="Where to Put Updates?"></a>Where to Put Updates?</h3><p>主要有三种方式：</p><ol><li>update-in-place<br> 大部分 rdbms 中使用。如果 records 是 fix-size 的，那么这个策略比较好，因为这样的 fragmentation 就比较少了。<br> 如果使用了 versioning 技巧，那么就比较 trick 了。如果 version 和 record 存在一起，那么 fragmentation 就会很大，locality 就会损失。<br> 另外一点是损失了并发性，因为更新一条记录，就需要锁住整个 page。</li><li>log-structured<br> 这个设计有两点好处：第一是没有 fragmentation，第二是没有 Concurrent 问题，因为 append 可以被非阻塞地实现。<br> 它的问题是，scan 需要读取旧的数据，以及检查它们的有效性。特别地，如果 record 很少被 update，那么 gc 就比较困难。<br> LSM 是基于 LS 的修改，它引入了阶段性的 reorg，从而提高读取的性能。</li><li>delta-main<br> 最初的设计来源于 SAP Hana。也就是使用了读优化的 main，以及写优化的 delta。</li></ol><h3 id="How-to-Arrange-Records"><a href="#How-to-Arrange-Records" class="headerlink" title="How to Arrange Records?"></a>How to Arrange Records?</h3><p>主要是行存，或者列存。<br>提到了列存中的一个变体也就是 PAX。PAX 中按照行来分 Page，但是在每个 Page 中，是按照列来存的。<br>列存对于定长的值是性能比较好的，所以目前的系统会设法避免动态长度的值。目前的系统要么禁用，要么就是存储指针，然后将它们放在一个全局堆上面。要么就是使用字典。</p><h3 id="How-to-Handle-Versions"><a href="#How-to-Handle-Versions" class="headerlink" title="How to Handle Versions?"></a>How to Handle Versions?</h3><p>MVCC 的两种方案：</p><ol><li>在同一个地方存放一个记录的所有版本<br> 通常和 update-in-palce 一起使用。<br> 创建新的版本会比较简单，但是 gc 会更加麻烦，因为要 compact 这些 page。<br> 特别地，在 LS 结构中，就需要将所有的 version 都重新拷贝到头部。</li><li>将所有的版本串成一个链表<br> 更适合 LS。<br> 但是这个指针占用额外存储。遍历这些指针会产生较多的 cache miss。<br> 好处是这个方案下，GC 比较方便，因为它相当于是对 log 做一个 truncation。另外，这个方案的 fragmentation 较少。</li></ol><h3 id="When-to-do-Garbage-Collection"><a href="#When-to-do-Garbage-Collection" class="headerlink" title="When to do Garbage Collection?"></a>When to do Garbage Collection?</h3><p>两种策略：</p><ol><li>在专门的线程中定期 gc</li><li>在 scan 的过程中 gc</li></ol><p>其中第二种做法会增加 scan 的时间开销。但是，如果扫描频繁的表，能够被及时 gc，那么也相应能提升它们后续被扫描的性能。而且，这个时候反正数据已经再被访问了，这个时候做 gc 能够避免额外访问 data 的 cache miss。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>上面几点，可以最多组成 24 个设计的变体。但是其中有很多不合理的，比如 delta-main + column-major 就比 log-structured + column-major 好。另一个例子是 log-structured + chained-version 比 log-structured + clustered-versions 要好。</p><p>The two most extreme variants are the variant based on log-structured with chained-versions in a row-major format and the variant using a delta-main structure with clustered-versions in a column-major format.</p><p>下面两节中，会分别介绍 TellStore-Log 和 TellStore-Col。</p><h2 id="TELLSTORE-LOG"><a href="#TELLSTORE-LOG" class="headerlink" title="TELLSTORE-LOG"></a>TELLSTORE-LOG</h2><p>这个设计是基于 RAMCloud 启发的，但是做出了重要的修改，以提升 scan 能力。</p><p><img src="/img/dbpaper/tellstore/f2.png"></p><h3 id="Where-to-Put-Updates-1"><a href="#Where-to-Put-Updates-1" class="headerlink" title="Where to Put Updates?"></a>Where to Put Updates?</h3><ol><li>Hash 表被用来索引 log 中的 record</li><li>The log itself is segmented into a linked-list of pages storing all key-value pairs.</li></ol><p>Memory in the log can be allocated in a lock-free way by atomically incrementing the page head pointer. 一旦一个 record 写入 log，它就是 immutable 的。因为是无锁的，所以冲突的 entry（具有相同的 key）可以被并发 append 到 log 上。一个 record 只有在它的 pointer 被成功添加到 hash table （或者被更新）之后，才被认为是 valid 的。在冲突的情况下，the record in the log will be invalidated before the data becomes immutable. Deletes are written as specially marked updates with no data. </p><p>如果 hash 表的设计是有锁了，就会是一个 contention point。很多无锁 hash table 的实现都是对某种特定访问模式的。比如，支持 resize，就会限制 lookup 和 update 的性能。TellStore 中预先分配了一个固定大小的 hash table，这个 table 被 storage node 中的所有 table 共享。这个实现使用了一个 open-addressing 算法，使用了 linear probing 机制。这样做是为了在 collision 的情况下，利用空间局部性。当然，坏处是在负载比较高的情况下，open addressing 的办法性能比较差。因此，hash bucket 中只保存 table id，record key 以及指向 record 的指针，目的是为了尽可能减少 hash 表的内存占用。</p><h3 id="How-to-Arrange-Records-1"><a href="#How-to-Arrange-Records-1" class="headerlink" title="How to Arrange Records?"></a>How to Arrange Records?</h3><p>LS 的方法总是固有地和行存绑定。为了支持快速 scan，record 必须要 self-contained。我们特别希望避免通过查找 hash table，从而去确认一个 record 是否 valid，也就是它是否被删除了，或者被 overwritten 了。TellStore-Log 为每个 table 分配了一个 log，所以这样只会 scan 到相关的 page，提高了局部性。进一步，a scan over the log is sensible to the amount of invalid records in the log, impacting the locality requirement, as we will see in Section 4.4.</p><h3 id="How-to-Handle-Versions-1"><a href="#How-to-Handle-Versions-1" class="headerlink" title="How to Handle Versions"></a>How to Handle Versions</h3><p>为了找到一个 key 的较老版本，需要维护一个 version-chain。也就是每个 reocrd 都会存一个自己的 previous pointer。另外，the timestamp of the transaction creating the record 会被存放在一个 valid-from 字段中（放在 metadata 里面）。This version chain is always strictly ordered from newest to oldest according to the snapshot timestamp, with the hash table pointing to the newest element. 给定一个 snapshot timestamp，一个 get 操作能够遍历这个 chain，从而找到第一个满足的元素。这个操作有大量的 cache miss，但是这是实现快速写入的代价。</p><p>看起来，这个设计似乎是和 self-contained 这个要求冲突的，如果只能提供 creation timestamp，那么 scan 的时候就不能确定一个 record 是否已经过期了。因此，为了避免查 hash table，就需要添加一个 valid-to timestamp 表示什么时候过期。这是一个 mutable 字段，也存放在每个 record 的 metadata 里面。当成功写入了一个对象 record 的一个新版本之后，前一个版本的 valid-to 就会被设置为新版本的 valid-from。Given a snapshot timestamp, the scan can decide if an element qualifies for inclusion in the snapshot only by comparing the two timestamps.</p><p>The hash table remains the sole point of synchronization and always points to the newest element. There is no race-condition between updating the hash table and setting the valid-to field, as Snapshot Isolation in TellStore does not guarantee visibility for inprogress transactions. </p><h3 id="When-to-do-Garbage-Collection-1"><a href="#When-to-do-Garbage-Collection-1" class="headerlink" title="When to do Garbage Collection?"></a>When to do Garbage Collection?</h3><p>scan 的性能，受到有多少过期了的 element 的影响。</p><p>对于每一个 page，根据 size 计算一个 valid rate。如果这个值低于某个特定的阈值，page 就会被 gc。也就是在下一次扫描的时候，会被重写。重写是拷贝剩余的 active 的 element 到 log 的头部。不需要的 page 会被返回给 free page pool 复用。当拷贝完新的 log head 之后，这个 key 的 version chain 的 pointer 需要被调整。也就是说，需要在 hash table 中查找这个 key，然后找到 version chain 的对应位置。显然，这个操作代价昂贵，因为空间局部性差。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>这里的主要贡献是提供了一个办法去让 log record 能够 self-contained，这样 MVCC 遍历会更快。另外，它提出 hash table 的内存使用要减少，因为即使 concurrent hash table 也是有 drawback 的。</p><h2 id="TELLSTORE-COL"><a href="#TELLSTORE-COL" class="headerlink" title="TELLSTORE-COL"></a>TELLSTORE-COL</h2><p>如下图所示，包含四个结构：</p><ol><li>一些 page 用来储存 main 的数据</li><li>两个 log 用来保存 delta，一个存 inserts 一个存 updates<br>1， 一个 hash table 用来索引数据</li></ol><p><img src="/img/dbpaper/tellstore/f3.png"></p><h3 id="Where-to-Put-Updates-2"><a href="#Where-to-Put-Updates-2" class="headerlink" title="Where to Put Updates?"></a>Where to Put Updates?</h3><p>Except for select metadata fields, main 中的数据是制度的，所有的更新会被写到一个 append-only 的 LS 存储中。不同于 TS-Log，delta 存在两个 log 里面，分别是 update-log 和 insert-log。作这个区分的好处是可以更容易从 delta 构建 main。在 index 中存了一个 flag，表示这个 pointer 指向的是 delta 还是 main。除了这个 flag 之外，index 和 TS-Log 使用了相同的 hash table。</p><p>在写之前，需要查询 index，寻找 record 的 key。如果这个 key 不存在，就插入到 insert-log。这是因为在 LS 的方法中，冲突的 entry 是可以被并发写到 log 中的。对于插入，index 部分是一个 point of synchronization，只有在将一个 pointer 插入到 index 中之后，这个 insert 才是有效的。</p><p>如果 key 是存在的，record 就会被 append 到 update-log 尾部。在 main 和 insert-log 中的 record 中都有一个可变的 newest 的字段，它保存了一个指向同一个 key 的最新被写入的元素。<br>【Q】从图中可以看出，这是在说 main 和 insert-log 中的每个 key，都会有一个指针 newest 去指向 update-log 中的一个位置，表示这个 key 中最新的数据。所以我理解这个指针的更新会有比较昂贵的开销。<br>同样，冲突的 records 可以被并发地写到这个 log中。这个 newest pointer 是 update 的 point of synchronization。</p><h3 id="How-to-Arrange-Records-2"><a href="#How-to-Arrange-Records-2" class="headerlink" title="How to Arrange Records?"></a>How to Arrange Records?</h3><p>对于两种 delta-log，它们都是以行存进行存储的。但是对于 main，则可以讨论具体的存储方式。</p><p>TS-Col 中使用一个列存，称为 ColumnMap 的方式存储 main。这个思想实际上类似 PAX。<br>如果一个 table 中的每个 field 都是 fixed size，那么就足以知道一个 record 的 first attribute 出现的位置。这个位置可以通过 page 中有多少个 record，以及每个 attribute 的 data type size 来计算出来。但是如果 fields 中有可变长度的类型，那么就不能这么简单计算了。</p><p>所以，如下图所示，除开了 Fixed Size Columns 之外，有一个 heap 用来存储所有的可变长度的字段。This heap is indexed by fixed-size metadata storing the 4-byte offset into the heap and its 4-byte prefix. While the metadata fields are stored in column-major format, the contents of the fields are stored in row-major format in the heap.</p><p>这有两个好处。首先，当物化 records 的时候，变长的 fields 已经是以行存格式存在的了，所以可以被简单拷贝到 output buffer 中。其次，在 fixed-size column-major format 中保存一个前缀，可以加快通常的基于前缀的 scan queries。这是因为我们可以根据前缀，去缩小需要选择的 tuple 的反而，减少查询 heap 的次数。</p><p><img src="/img/dbpaper/tellstore/f4.png"></p><h3 id="How-to-Handle-Versions-2"><a href="#How-to-Handle-Versions-2" class="headerlink" title="How to Handle Versions?"></a>How to Handle Versions?</h3><p>TS-Log 同样也保存了 valid-from，作为 records 的 metadata 的一部分。在 update-log 中的 records 会被从新到旧地连接起来，每个版本都会持有一个 previous pointer。在 main 和 insert-log 中会存储的 newest pointer 会指向 update-log 中的最新的元素。为了避免 loops，没有从 update-log 到 main 的 back pointer。</p><p>在一个 main page 中，同一个 key 的不同版本会被连续地从新到旧地存放在一个 column-major format 中。valid-from 时间戳，和 newest pointer 也会被转成 column-major 的格式，并且在 metadata scetion 中以 normal attributes 的形式进行存储。index 总是指向 the metadata field of the newest element in the ColumnMap or the insert log. 给定一个 snapshot timestamp，会从新到旧开始扫描 valid-from 字段，直到 a timestamp is found that is contained in the snapshot.</p><p>和之前原理相同，为了保证 record 是 self-contained 的，需要将 newest pointer 和 record 一同存储，而不是存在 hash table 中。否则，为了知道一个 new record 有没有被写入过，就必须查找 hash table 了。Records in both delta-logs only store the timestamp of the transaction that created them and as such are not self-contained. This is a trade-off between scan and garbage collection performance, as discussed in Section 5.4.</p><h3 id="When-to-do-Garbage-Collection-2"><a href="#When-to-do-Garbage-Collection-2" class="headerlink" title="When to do Garbage Collection?"></a>When to do Garbage Collection?</h3><p>GC 主要负责定期将两个 delta-logs 中的更新 merge 到 main 中。这能保障有效率的 scan 需要的局部性。所有的 main page 都是不可变的，并且通过 COW 机制去 rewrite。This is necessary in order to not interfere with concurrent access from get/put and scans, as update-in-place would require a latch on the page.</p><p>相比 TS-Log，从 delta 到 main 去 compact page 是更加昂贵的，因为涉及行转列。所以，GC 会作为一个单独的线程来运行，而不会被 piggy-back 到 scan 过程中。这个专门的线程会定期扫描 main 中每个 page 的 metadata 部分，一旦它发现一个 page 中有某个 record，它要么被 update 了（通过检查 newest 指针），要么不在被任何 active 的 snapshot 持有（通过检查 valid-from 字段），就会重写这个 page。</p><p>通过遍历 version chain，可以从 main 和 update-log 中得到这个 key 的所有的 version。 Elements with timestamp that are not contained in any active snapshot are discarded, while elements gathered from the update-log are converted to column-major format. 所有这些元素，会被从新到旧排序，然后被 append 到一个新的 main page 中。在 relocate 一个 record 之后，newest 字段会被更新，指向 new record。这样并发的 update 能够知道发生了这个 relocation。最后，GC 会扫描所有 insert-log 中的 record，将 update-log 中所有这个 key 的写入取出来，并且以列式写到 main page 中。此后，delta-logs 可以被 truncated 掉，然后这些旧的 page 会被放到 free page 池中。</p><p>通过分离 insert 和 update log，GC 只需要扫描 insert-log 从而获取所有不在 main 中的 key。当然，坏处是，它会降低 scan 的数据局部性，因为 update 会导致 scan 为了遍历 version chain 从而去从 update-log 中随机读取。这里的前提是让 GC 更加有效率，这样它能更频繁地跑，从而减少 update-log 的大小。</p><p>Page 是被 aggressively 进行 compact 的。如果一个 page 中的一个 element 变为 invalid 了，整个 page 就会被 rewrite。如果负载比较中，那么写放大就会比较大。这对 dick-based 系统影响比较大，但是 memory-based 的系统就还好。An extension to this approach would be to compact pages based on dirtiness, similar to TellStore-Log. Delaying the compaction, on the other hand, will keep a higher portion of the data in the delta-log which, in turn, will impact scan performance.</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Versioning can be achieved by clustering records of the same key together and treating their timestamp as a regular field in a column-major format.</p><h2 id="IMPLEMENTATION"><a href="#IMPLEMENTATION" class="headerlink" title="IMPLEMENTATION"></a>IMPLEMENTATION</h2><h3 id="Asynchronous-Communication"><a href="#Asynchronous-Communication" class="headerlink" title="Asynchronous Communication"></a>Asynchronous Communication</h3><p>意思是等待 storage request 被完成的时候，processing instance 不要闲置。所以用了叫 InfinIO 的这个异步通信库。 InfinIO, which was built specifically to run on top of Infiniband, employs user-level threads and callback functions through an API similar to the one provided by Boost.Asio for Ethernet communication. All requests to TellStore immediately <strong>return a future object</strong> on which the calling user-level thread can wait.<br>InfinIO then transparently <strong>batches</strong> all requests at the network layer before actually sending them to TellStore. Likewise, responses from the storage are batched together before sending them back to the processing nodes. This batching greatly improves the overall performance as it cuts down the message rate on the Infiniband link, which would otherwise become the performance bottleneck.</p><h3 id="Thread-Model"><a href="#Thread-Model" class="headerlink" title="Thread Model"></a>Thread Model</h3><p>如下所示，分为了下面几种类型的线程。<br><img src="/img/dbpaper/tellstore/tm.png"></p><p>To guarantee a consistent throughput for scans and get/put operations, TellStore only uses lock-free data structures.</p><p>有一个 scan 线程还扮演 scan coordinator 的角色。它会将队列里面的所有 scan request 组合成一个 single shared scan。 The coordinator partitions the storage engine’s set of pages and distributes them equally among the scan threads. All the scan threads (including the coordinator) then process their partition in parallel independently. 每一部分的结果会通过 RDMA 被直接写到 client 的内存中。</p><h3 id="Data-Indexing"><a href="#Data-Indexing" class="headerlink" title="Data Indexing"></a>Data Indexing</h3><p>在 TS-Log 和 TS-Col 的介绍中，讲解了使用一个 lock-free hash table 去在单个 node 中索引 records。为了在多个 nodes 中索引 keys，TS 实现了一个类似 Chord 的分布式 hash table。如何选择 hash table 是和如何支持快速 scan 正交的一个问题。</p><p>对于 range partitioning，可以使用像 Btree 或者 LSM 去在 page 内索引数据。但这会让 get/put 操作更加昂贵。为了支持 range query，Tell uses a lock-free B-tree that is solely implemented in the processing layer as described in [30].</p><h3 id="Predicate-Pushdown"><a href="#Predicate-Pushdown" class="headerlink" title="Predicate Pushdown"></a>Predicate Pushdown</h3><p><img src="/img/dbpaper/tellstore/f6.png"></p><h1 id="PebblesDB"><a href="#PebblesDB" class="headerlink" title="PebblesDB"></a>PebblesDB</h1><p><a href="https://www.cs.utexas.edu/~vijay/papers/sosp17-pebblesdb.pdf" target="_blank" rel="noopener">https://www.cs.utexas.edu/~vijay/papers/sosp17-pebblesdb.pdf</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文提出了一个 Fragmented LSM 降低 LSM 的写放大和内存开销。FLSM 引入了一个叫 guard 的概念来组织 logs，避免在同一层中 rewrite data。通过修改 HyperLevelDB 的代码，来实现 FLSM 的数据结构。测试显示，PebblesDB 能够减少 2.4-3 倍的写放大，提升写吞吐量为 6.7x。</p><h2 id="INTRODUCTION-1"><a href="#INTRODUCTION-1" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>下图是常见的 kvstore 的写放大。在测试中使用了 500M 个 kv 对，并且它们被随机 insert 或者 update。通常的思考是，减少写放大通常需要牺牲 write 或者 read 的吞吐量。在当前的低延迟、大写入的场景中，用户并不愿意牺牲任何一个。<br><img src="/img/dbpaper/pebblesdb/f1.png"></p><p>LSM 的写放大的问题主要是数据结构本生。因为 LSM 要求 sorted order，从而支持高效率的查询。但是当新的 data 被添加到 LSM 中，就需要 rewrite 既有的数据，从而导致大量的 write IO。</p><p>主要贡献：</p><ol><li>提出了 FLSM 树，将跳表和 LSM 树结合。</li><li>实现了 PebblesDB</li><li>实验结果</li></ol><h2 id="BACKGROUND"><a href="#BACKGROUND" class="headerlink" title="BACKGROUND"></a>BACKGROUND</h2><h3 id="Log-Structured-Merge-Trees"><a href="#Log-Structured-Merge-Trees" class="headerlink" title="Log-Structured Merge Trees"></a>Log-Structured Merge Trees</h3><h4 id="Write-Amplification-Root-Cause"><a href="#Write-Amplification-Root-Cause" class="headerlink" title="Write Amplification: Root Cause"></a>Write Amplification: Root Cause</h4><p>下图展示了 LSM KVStore 中的 compaction。Level 1 中最初有两个 sst。假设 Level 0 被配置为最多只能有一个 sst，当达到 limit 之后，compaction 就会发生。在 t1 时刻，添加了一个新的 sst。在 t2 时刻，触发了一个 compaction。后面的 3-6 也是同理的。在 compact 一个 sst 的时候，所有下一层中 range 和这个 sst 相交的都会被 rewrite。在这个例子中，因为 level 0 中的所有 sst 都和 level 1 中的 sst 相交，所以只要 level 0 被 compact 了，level 1 就需要被重写。在这个最坏的情况的例子中，Level 1 sstables are rewritten three times while compacting a single upper level.</p><h4 id="The-Challenge"><a href="#The-Challenge" class="headerlink" title="The Challenge"></a>The Challenge</h4><p>一个减少写放大的做法就是不去 merge sst，而是直接加 sst。但这样会导致 read 和 range query 的性能显著降低。因为：</p><ol><li>如果不 merge，那么 kvstore 中就会存在大量 sst</li><li>因为现在有多个 sst 中包含相同的 key，并且相同的 level 上有 overlap 的 key range，读操作需要访问较多的 sst</li></ol><p><img src="/img/dbpaper/pebblesdb/f2.png"></p><h2 id="FRAGMENTED-LOG-STRUCTURED-MERGE-TREES"><a href="#FRAGMENTED-LOG-STRUCTURED-MERGE-TREES" class="headerlink" title="FRAGMENTED LOG-STRUCTURED MERGE TREES"></a>FRAGMENTED LOG-STRUCTURED MERGE TREES</h2><p>目的是同时达到：低写放大、高写吞吐、好的读取性能。</p><p>FLSM 可以看做是 LSM + SkipList，以及一个新颖的可以减少写放大和增加写吞吐的压缩算法。lsm 的基础问题是 sst 会被重写多次。m. FLSM counters this by fragmenting sstables into smaller units. 现在相比重写 sst，FSLM 的 compaction 只是会将一个新的 sst fragment 去 append 到下一层中。这就保证了数据在大多数层中只会写最多一次。对于较高的层，会用一个不同的 compaction 算法。</p><p>FLSM 通过 guards 去实现这个 lauour。</p><h3 id="Guards"><a href="#Guards" class="headerlink" title="Guards"></a>Guards</h3><p>在传统的 lsm 中，每一层包含的 sst 对应的 key range 都是不相交的，也就是说每个 key 都只会在一个 sst 中出现。本文的主要观察是为了维护这个 invariant，是导致写放大的根因，因为它强迫同一层中的数据被重写。FLSM 放弃了这个 invariant，也就是每一层中可以包含多个 overlap 的 sst，也就是说一个 key 可能在多个 sst 中。为了方便从每一层中找到 key，FLSM 将 sst 组织乘了 guards。</p><p>每一层中包含多个 guards。Guards 将 key space 分成了不相交的单元。每一个 guard Gi 有一个关联的 key Ki，是从被添加到 FLSM 的 key 中选择的。层数越高，guards 越多，也就是当数据被 push 到越来越低的层的时候，guards 就会显著变多。和 skip list 一样，如果一个 key 是 i 层的 guard，那么它也是所有 level &gt; i 的层的 guard。</p><p>每一个 guard 有一系列关联的 sst。每个 sst 都是 sorted 的。如果 guard Gi 和 Ki 关联，guard Gi+1 和 Ki+1 关联，那么在 [Ki, Ki+1) 中的 sst 就会被 attach 到 Gi。每一层中比第一个 guard 小的 sst 会被一个专门的 sentinel guard 来存储。最后一个 guard Gn 会存储所有 keys 大于等于 Kn 的 sst。一层中的 guard 不会有 overlap 的 key range。</p><p>在 FLSM compaction 的实现中，the sstables of a given guard are (merge) sorted and then fragmented (partitioned), so that each child guard receives a new sstable that fits into the key range of that child guard in the next level.</p><p>下图中是一个例子。</p><ul><li>put() 会导致 key 被添加到 memtable 中。最终 memtable 会变慢，那么会被 dump 为 level 0 层的一个 sst。level 0 没有任何的 guards。</li><li>当层数变高，guards 的数量就会变大，但并不一定是指数级别的变大。</li><li>每一层都有个 sentinel guard。</li><li>在 FLSM 中的数据是被部分排序的</li></ul><p><img src="/img/dbpaper/pebblesdb/f3.png"></p><h3 id="Selecting-Guards"><a href="#Selecting-Guards" class="headerlink" title="Selecting Guards"></a>Selecting Guards</h3><h4 id="Guard-Probability"><a href="#Guard-Probability" class="headerlink" title="Guard Probability"></a>Guard Probability</h4><p>用 guard probablity 定义一个 key 是否是 guard。即 <code>gp(key, i)</code> 表示 <code>key</code> 是第 i 层的 guard 的概率。level 1 的 guard 是最少的，所以 gp 就很低。随着 level 的增高而增高。</p><p>如果 K 是第 i 层的 guard，那么它也是第 i + 1、i + 2 等的 guard。</p><h4 id="Other-schemes-for-selecting-guards"><a href="#Other-schemes-for-selecting-guards" class="headerlink" title="Other schemes for selecting guards"></a>Other schemes for selecting guards</h4><p>FLSM could potentially select new guards for each level at compaction time such that sstable partitions are minimized; however, this could introduce skew. We leave exploring alternative selection schemes for future work.</p><h3 id="Inserting-and-Deleting-Guards"><a href="#Inserting-and-Deleting-Guards" class="headerlink" title="Inserting and Deleting Guards"></a>Inserting and Deleting Guards</h3><p>guards 不是同步地被插入 FLSM 中的。因为插入 FLSM 中需要切分或者移动 sstable。如果一个 guard 被插入到了多个 level 中，那么就需要要对所有层进行处理。因此，作者将它设计为并行的。<br>当 guards 被选中，他们会被插入到一个内存中的 set 中，称为 uncommitted guards。sstable 并不会基于这些 uncommitted guards 而进行划分。<br>在下一次的 compaction cycle 中，sstable 会被旧的 guard 以及 uncommitted guard 重新划分。任何需要被 uncommitted guard 切分的 sstable 会被 compact 到下一层中。在 compaction 的最后，uncommitted guards 会被持久化到存储中，并被加到 guards 的集合中。后续的读取都会基于这个全集来做了。</p><p>在大部分的 workload 中，删除 guard 都是不必要的。一个 guard 可能因为 key 被删除了，所以变为空的。但这并不影响性能，因为 get() 会跳过这些空的 guards。当然，有两个场景删除是有用的：</p><ol><li>guard 是空的</li><li>这一层中的数据在 guard 中分布是不均匀的。此时，重新计算 guard 能够提升性能。</li></ol><p>删除 guard 这个行为也是异步做的。也有一个内存中的 set 来维护 uncommitted 的删除。删除 G 这个 guard 会导致所有属于 G 的 sst 被重新添加到 level i 的相邻分区，或者 level i+1 中。注意，从 level i 到 i + 1 的 compaction 是正常的，因为 G 依然是 level + 1 的一个 guard。</p><h3 id="FLSM-Operations"><a href="#FLSM-Operations" class="headerlink" title="FLSM Operations"></a>FLSM Operations</h3><h4 id="get"><a href="#get" class="headerlink" title="get"></a>get</h4><p>首先找 memtable，如果找不到，从 level 0 开始找。<br>这里最坏的情况是每一层都需要读一个 guard，然后这个 guard 里面的每个 sst 都需要被读取。</p><h4 id="range-query"><a href="#range-query" class="headerlink" title="range query"></a>range query</h4><p>首先需要确定每一层涉及到的 guard。对每个 sst 执行一次二分查找，找到最小的 key，后面的 key 就通过类似于 merge 的方式来处理了。</p><h4 id="put"><a href="#put" class="headerlink" title="put"></a>put</h4><p>略</p><h4 id="key-updates-and-deletions"><a href="#key-updates-and-deletions" class="headerlink" title="key updates and deletions"></a>key updates and deletions</h4><p>也是通过 sequence number 来维护版本的。</p><h4 id="compaction"><a href="#compaction" class="headerlink" title="compaction"></a>compaction</h4><p>当一个 guard 中的 <strong>sst 数量到达阈值</strong>之后，就会 compact 到下一个 level。【Q】所以看起来 compaction 的粒度是 guard 了。<br>The sstables in the guard are first (merge) sorted and then partitioned into new sstables based on the guards of the next level; the new sstables are then attached to the correct guards. For example, assume a guard at Level 1 contains keys {1, 20, 45, 101, 245}. If the next level has guards 1, 40, and 200, the sstable will be partitioned into three sstables containing {1, 20}, {45, 101}, and {245} and attached to guards 1, 40, and 200 respectively.</p><p>大多数情况，compaction 都不需要 <strong>rewrite</strong> sst。这是 FLSM 如何减少写放大的 main insight。【Q】但这里 split 一个 sst 应该也是需要重写的？新的 sst 会被简单地直接加入到下一层中的对应 guard 中。但是有两个例外：</p><ol><li>对于最高层，也就是 level 5，sst 需要在 compaction 的时候重写。显然没有更高的层可以给它继续放了。</li><li>对于次高层，也就是 level 4，FLSM will rewrite an sstable into the same level if the alternative is to merge into a large sstable in the highest level (since we cannot attach new sstables in the last level if the guard is full)<br> The exact heuristic is rewrite in second highest-level if merge causes 25× more IO.</li></ol><p>FLSM 的 compaction 是可以并行的。因为 compact 一个 guard 只涉及到下一层中的对应的 guard 们。FLSM 中选择 guards 的方法保证了 compact 一个 guard 的同时不会影响到同一层中的其他 guard。</p><h3 id="Tuning-FLSM"><a href="#Tuning-FLSM" class="headerlink" title="Tuning FLSM"></a>Tuning FLSM</h3><p>Tuning max_sstables_per_guard allows the user to tradeoff more write IO (due to more compaction) for lower read and range query latencies. Interestingly, if this parameter is set to one, FLSM behaves like LSM and obtains similar read and write performance. Thus, FLSM can be viewed as a generalization of the LSM data structure.</p><h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>get 以及范围查询，因为要检查 guard 中的所有的 sst，所以读取的延迟增加了。</p><h1 id="Snowflake"><a href="#Snowflake" class="headerlink" title="Snowflake"></a>Snowflake</h1><p><a href="https://dl.acm.org/doi/pdf/10.1145/2882903.2903741" target="_blank" rel="noopener">https://dl.acm.org/doi/pdf/10.1145/2882903.2903741</a></p><h2 id="ABSTRACT-1"><a href="#ABSTRACT-1" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>这里强调就是性价比高，性价比高的原因是弹性做得更好，比如使用了 serverless 的架构。另外，snowflake 也更云原生。</p><h2 id="INTRODUCTION-2"><a href="#INTRODUCTION-2" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>现在平台变了，上云了。上云主要就是 scalability 和 availablility 和 pay-as-you-go 的 cost model。</p><p>不仅平台变了，数据也变了。现在数据更加 schema-less 或者 semi-structured。</p><p>Hadoop 或者 Spark 这样的大数据平台缺少 much of the efficientcy and feature set of established data warehousing technology。</p><ol><li>Pure Software-as-a-Service (SaaS) Experience</li><li>Relational</li><li>Semi-structured 提供一些内置的函数和 SQL 扩展，方便对 semi-structured 的数据进行遍历、flattening、nesting。支持 JSON 和 Avro。列存以及 automatic schema discovery 的技术让这样的数据也能和关系数据一样处理起来很快。</li><li>Elastic</li><li>Highly Available</li><li>Durable</li><li>Cost-efficient</li><li>Secure</li></ol><p>SNowflake 在 AWS 上运行，但是也能够被 port 到其他的平台上。</p><h2 id="STORAGE-VERSUS-COMPUTE"><a href="#STORAGE-VERSUS-COMPUTE" class="headerlink" title="STORAGE VERSUS COMPUTE"></a>STORAGE VERSUS COMPUTE</h2><p>Share-nothing 系统能够成为主流的数仓，主要是因为 scalability 以及 commodity hardware。在这种架构下，每一个 query processor 都有自己的本地磁盘。表被水平 partition。这样的架构对 star-schema 的查询是比较好的，因为 very little bandwidth is required to join a small (broadcast) dimension table with a large (partitioned) fact table. 因为共享数据结构或者硬件之间的竞争很少，所以不需要很昂贵的硬件。</p><p>Snowflake 认为纯粹的 shared-nothing 架构将存储和计算绑定在一起，从而导致问题，场景有：</p><ol><li>Heterogeneous Workload<br> bulk loading 是高 IO 带宽，低 CPU 开销；相比复杂查询是 CPU 需求高的。这样的异构负载，但是我们的节点又是同构的。</li><li>Membership Changes<br> 这里主要负担是要 shuffle 一堆数据。<br> 可以通过 replication 来缓解这个问题。</li><li>Online Upgrade</li></ol><p>然后，云上环境这三点都是很正常的。</p><p>出于上述考虑，Snowflake 进行了存算分离。Compute 是专有硬件的 shared-nothing 架构的引擎。Storage 是在 S3 上提供的，虽然实际上任何 blob 存储都是满足要求的。为了减少网络传输，Compute node 会在本地磁盘上存储一些表的数据。</p><p>Snowflake 将这种架构称为 multi-cluster、shared-data 架构。</p><h2 id="ARCHITECTURE"><a href="#ARCHITECTURE" class="headerlink" title="ARCHITECTURE"></a>ARCHITECTURE</h2><p>Snowflake 的三层架构：</p><ol><li>Data Storage</li><li>Virtual Warehouses</li><li>Clous Services</li></ol><p><img src="/img/dbpaper/snowflake/f1.png"></p><h3 id="Data-Storage"><a href="#Data-Storage" class="headerlink" title="Data Storage"></a>Data Storage</h3><p>选择 AWS 的原因：</p><ol><li>AWS 最成熟</li><li>AWS 上的潜在用户最多</li></ol><p>第二个选择是直接使用 S3 还是用一个自己基于 HDFS 研发的自有存储服务。Snowflake 的经验是，S3 的性能会变动，但是可用性、以及 durability 是很强的。所以选择 S3，然后主要精力用来研究 VW layer 中的 local caching 和 skew resilience 技术。</p><p>S3 相比本地磁盘，延迟是高很多的，并且每一个 IO 请求的 CPU 开销也大很多，特别是使用 HTTPS 请求。但最关键的是，S3 上文件只能够被 write/overwrite in full。我们甚至无法在一个文件末尾去 append 数据。实际上我们需要在 PUT 的时候，就声明文件的大小。BTW，S3 支持读文件的一部分。</p><p>一张表被分成很多个不可变的大文件。每个文件使用 PAX 格式存储。每个表文件中包含一个 header，记录了文件中每个 column 的 offset。所以只需要下载 metadata，以及感兴趣的 columns。</p><p>Snowflake 也是用 S3 存储被 query operator 生成的临时文件，比如和 join 相关的临时结果。当然，一般这发生在本地磁盘被耗尽的情况。这样，就能处理 OOM 或者 out of disk 的情况。</p><p>Metadata，这里值 catalog 对象、事务日志、锁等，被存放在一个 KVStore 里面。这个 KVStore 属于最上层的 Cloud Service。</p><h3 id="Virtual-Warehouses"><a href="#Virtual-Warehouses" class="headerlink" title="Virtual Warehouses"></a>Virtual Warehouses</h3><p>这一层中是 EC2 集群。它们会以一个 virtual warehouse 即 VW 的抽象的方式暴露给单个用户。VW 中的单个 EC2 节点成为 worker node。用户并不会直接和 worker node 交互，也不关心 VW 具体实现的细节。实际上，会像 AWS 一样提供不同型号的 VW 的抽象供用户选择。这部分的设计实际上很 cloud native。</p><h4 id="Elasticity-and-Isolation"><a href="#Elasticity-and-Isolation" class="headerlink" title="Elasticity and Isolation"></a>Elasticity and Isolation</h4><p>在没有查询的时候，用户可以关闭所有的 VW。单个查询运行在单个 VW 上面，worker node 也不会跨 VW 共享。从好的方面来讲，这导致每个查询的 performance isolation 很好。从坏的方面来讲，利用率可能就不高了。</p><p>所以当一个新的查询被提交的时候，VW 中的全部，或者部分（如果查询比较小的话）work nodes 会各自创建一个全新的 worker process。每个 worker process 的生命周期是整个 query。</p><p>每个用户可能同时有多个 VW 在运行，每个 VW 也可能运行多个并发的查询。每个 VW 都访问同一份 shared tables。</p><blockquote><p>Shared, infinite storage means users can share and integrate all their data, one of the core principles of data warehousing.</p></blockquote><blockquote><p>Another important observation related to elasticity is that it is often possible to achieve much better performance for roughly the same price. For example, a data load which takes 15 hours on a system with 4 nodes might take only 2 hours with 32 nodes</p></blockquote><h4 id="Local-Caching-and-File-Stealing"><a href="#Local-Caching-and-File-Stealing" class="headerlink" title="Local Caching and File Stealing"></a>Local Caching and File Stealing</h4><p>每个 worker node 会在本地磁盘上存储 S3 的一些表文件的元数据，以及一些需要用到的列。这个 cache 的生命周期和 worker node 一致，并且被上面的多个 concurrent 或者 subsequent 的 worker process 共享。有一个 LRU 策略用来 evict 这些 cache。</p><p>进一步，每个查询会对需要读的表的 table id 做一致性哈希，这样访问相同表的查询都会集中到相同 worker node 上，从而减少冗余的 cache。</p><p>一致性哈希是 lazy 进行的，也就是说，当 worker nodes 配置变更时，data 不会立即被 shuffle。相反地，Snowflake 借助于 LRU cache 去最终替换 cache 的内容。这摊还掉了 the cost of replacing cache contents over multiple queries. </p><p>【Q】这里 TiFlash 是通过 Region 信息找到存有副本的实例，从而去读取对应实例的 S3 来解决问题的。</p><p>此外，还需要解决 skew 的问题，也就是一些节点会运行地显著比其他节点慢。所以有一个 file stealing 策略，当一个节点完成自己的任务后，它会尝试向它的 peer 去请求额外的文件。它会直接从 S3 下载文件，以避免给那个 peer 带来额外的进一步的负担。</p><h4 id="Execution-Engine"><a href="#Execution-Engine" class="headerlink" title="Execution Engine"></a>Execution Engine</h4><p>首先，如果能用 10 个 node 跑完的任务，就不需要用 1000 个 node 来跑了。所以尽管 scalability 很重要，但是每个节点本身的效率也是很重要的。</p><p>Snowflake 的执行引擎是 Columnar、Vectorized、Push-based 的。Vectorized 这里指的也是 late materialzation。</p><p>一些传统事务中存在的问题，在 Snowflake 中不需要处理。</p><ul><li>首先，执行的时候不需要处理事务管理，因为查询只会读取一些列不可变的文件。</li><li>然后，没有 buffer pool。因为大部分查询会扫描大量的数据。在内存中 cache 这些结果是一个很不好的实践。<br>  【Q】但是 Cache 所需要的列，特别是解压后的结果，以避免重复解压的开销是很重要的。</li></ul><h3 id="Cloud-Services"><a href="#Cloud-Services" class="headerlink" title="Cloud Services"></a>Cloud Services</h3><p>VW 是 ephemeral 的，用户特定的资源。但是 Cloud Service 层是 multi tenant 的。这一层中有 access control、query optimizer、transaction manager 以及其他的服务，它们都是常驻的，并且被所有用户共同分享。多租户能够有效地提升利用率。</p><h4 id="Query-Management-and-Optimization"><a href="#Query-Management-and-Optimization" class="headerlink" title="Query Management and Optimization"></a>Query Management and Optimization</h4><h4 id="Concurrency-Control"><a href="#Concurrency-Control" class="headerlink" title="Concurrency Control"></a>Concurrency Control</h4><p>也是基于 SI 的 ACID 事务模型。在 SI 下，所有的读看到的是事务开始的时候的一致性视图。SI 基于 MVCC 实现。MVCC 也是因为基于 S3 后，文件都得是 immutable 的。</p><h4 id="Pruning"><a href="#Pruning" class="headerlink" title="Pruning"></a>Pruning</h4><p>这里将如何做到只扫描需要的一部分数据。传统数据库中，通常使用索引做到这一点。Snowflake 不是很适合的原因是：</p><ol><li>索引很依赖随机访问，对于压缩的格式，以及 S3，都不是很友好。</li><li>维护一个索引，会增加数据的大小，以及数据被加载的时间。</li><li>用户需要显式创建索引，这个和 Snowflake 的设计精神不是很契合。</li></ol><p>一个替代的做法是 min-max 索引，也被称为 small materialized aggregates、zone maps 或者 data skipping。这个方案是对于每个 chunk，都记录了它上面的最大值和最小值。</p><p>Snowflake keeps pruning-related metadata for every individual table file. The metadata not only covers plain relational columns, but also a selection of auto-detected columns inside of semi-structured data, see Section 4.3.2.</p><p>The optimizer performs pruning not only for simple base-value predicates, but also for more complex expressions such as WEEKDAY(orderdate) IN (6, 7).</p><p>Besides this static pruning, Snowflake also performs dynamic pruning during execution. For example, as part of hash join processing, Snowflake collects statistics on the distribution of join keys in the build-side records. This information is then pushed to the probe side and used to filter and possibly skip entire files on the probe side. This is in addition to other well-known techniques such as bloom joins.</p><h2 id="FEATURE-HIGHLIGHTS"><a href="#FEATURE-HIGHLIGHTS" class="headerlink" title="FEATURE HIGHLIGHTS"></a>FEATURE HIGHLIGHTS</h2><h3 id="Pure-Software-as-a-Service-Experience"><a href="#Pure-Software-as-a-Service-Experience" class="headerlink" title="Pure Software-as-a-Service Experience"></a>Pure Software-as-a-Service Experience</h3><h3 id="Continuous-Availability"><a href="#Continuous-Availability" class="headerlink" title="Continuous Availability"></a>Continuous Availability</h3><h4 id="Fault-Resilience"><a href="#Fault-Resilience" class="headerlink" title="Fault Resilience"></a>Fault Resilience</h4><h4 id="Online-Upgrade"><a href="#Online-Upgrade" class="headerlink" title="Online Upgrade"></a>Online Upgrade</h4><h3 id="Semi-Structured-and-Schema-Less-Data"><a href="#Semi-Structured-and-Schema-Less-Data" class="headerlink" title="Semi-Structured and Schema-Less Data"></a>Semi-Structured and Schema-Less Data</h3><p>支持 VARIANT 类型。从而实现 “schema later” 模式：相比于 ETL，它把这个叫做 ELT。也就是在加载输入的时候，并不需要指定 schema，无论是从 JSON、Avro 还是 XML 格式去加载。</p><p>ELT 的好处是，如果后续数据需要被转换，就可以利用这个数据库本身来执行。Snowflake 支持基于 js 去定义 UDF。</p><h4 id="Post-relational-Operations"><a href="#Post-relational-Operations" class="headerlink" title="Post-relational Operations"></a>Post-relational Operations</h4><h4 id="Columnar-Storage-and-Processing"><a href="#Columnar-Storage-and-Processing" class="headerlink" title="Columnar Storage and Processing"></a>Columnar Storage and Processing</h4><p>As mentioned in Section 3.1, Snowflake stores data in a hybrid columnar format. When storing semi-structured data, the system automatically performs statistical analysis of the collection of documents within a single table file, to perform automatic type inference and to determine which (typed) paths are frequently common. <strong>The corresponding columns are then removed from the documents and stored separately, using the same compressed columnar format as native relational data.</strong> For these columns, Snowflake even computes materialized aggregates for use by pruning (cf. Section 3.3.3), as with plain relational data.</p><h4 id="Optimistic-Conversion"><a href="#Optimistic-Conversion" class="headerlink" title="Optimistic Conversion"></a>Optimistic Conversion</h4><p>有一些 native 的 SQL 类型，例如时间日期会在外部格式，比如 JSON 或者 XML 中以字符串的形式保存。这些值会在 write 或者 read 的时候，被重新转换成实际的类型。</p><p>如果在 read 的时候进行转换，通常会花费很多 CPU。此外，这会导致之前说的 pruning 无法执行，这特别是对日期类型。</p><p>但是在 write 的时候进行转换，会丢失信息。例如，<code>00000000010</code> 不一定表示 10，他也可能就是一个有很多前导 0 的字符串。或者，一个像日期的数实际上是电话号码。</p><p>Snowflake 会使用乐观转换的办法。也就是同时保留转换后的列，以及转换前的列。因为在读取的时候，要么读转换后的，要么读转换前的，所以不会有读两次的开销。</p><h4 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h4><h3 id="Time-Travel-and-Cloning"><a href="#Time-Travel-and-Cloning" class="headerlink" title="Time Travel and Cloning"></a>Time Travel and Cloning</h3><p>CLONE 操作就是类似于 COW 一样。</p><h3 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h3>]]></content>
    
    
    <summary type="html">&lt;p&gt;这篇文章中，包含 Fast scans on key-value stores、PebblesDB、Snowflake。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
  <entry>
    <title>羽毛球训练纪实</title>
    <link href="http://www.calvinneo.com/2024/11/22/badminton/"/>
    <id>http://www.calvinneo.com/2024/11/22/badminton/</id>
    <published>2024-11-22T15:07:22.000Z</published>
    <updated>2025-02-09T15:20:06.532Z</updated>
    
    <content type="html"><![CDATA[<p>记录一下一些要点</p><a id="more"></a><h1 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h1><p>主要是两点：</p><ol><li>转腰</li><li>架拍</li></ol><p>击球时先转腰，后架拍，手腕不能进一步引拍了，否则击球会不稳定。我的坏习惯是手腕进一步引拍，以增加击球力量。</p><h1 id="Day-2"><a href="#Day-2" class="headerlink" title="Day 2"></a>Day 2</h1><p>教练认为，在击球转腰的过程中，手臂不一定要完全转过来，从而贴近耳朵。这么训练的目的是增加转腰的意识。</p><p>教练认为，在跑动的时候，也要注意架拍的三点一线。否则这会导致击球的不稳定。</p><p>我觉得这里高远球最重要的还是练习转腰挥拍的连贯性。过早过晚会导致击球动作变形。也会导致击球点偏下。转腰的时候，一定要将身体完全转过来。</p><h1 id="Day-3"><a href="#Day-3" class="headerlink" title="Day 3"></a>Day 3</h1><p>几点：</p><ol><li>在击球的时候，左脚往后扭，可能是因为侧身不到位。</li><li>挥拍的时候小臂不要僵硬，而是要发力。</li><li>击球完之后，要有回收的动作。</li><li>握住球拍的时候，不能松。在击球的瞬间，需要发力。</li><li>如果是高远球，击球的位置不能太过往下压。</li><li>侧身时，从水平线上来看，左脚相比右脚要靠后，不然就转不正。</li></ol><h1 id="Day-4"><a href="#Day-4" class="headerlink" title="Day 4"></a>Day 4</h1><p>继续纠正发力时候大臂僵硬的问题。主要是：</p><ol><li>小臂在接触球的时候，需要发力。这个发力的时机比较重要，如果击球时机准确，会有很清脆的声音。</li><li>在挥拍的时候，大臂不要僵硬。比如抡大臂，将大臂甩出去，肩膀也跟着往前冲，然后头往前栽的那种感觉。</li></ol><p>介绍了一个保护膝盖的方式，也就是并腿半蹲屁股贴着墙站。</p><h1 id="Day-5"><a href="#Day-5" class="headerlink" title="Day 5"></a>Day 5</h1><p>介绍了一个跨步的击球方式：</p><ul><li>重心需要在右脚单脚上（实际上可以直接单脚站立）。</li><li>通过转髋来实现跳跃。</li><li>左脚先落地，右脚再落地，脚尖要朝前。</li></ul><p>注意，不能是扫堂腿，而应该有个跨步的动作，先左脚落地，后右脚落地。整个击球过程是在空中和转髋同步完成的。</p><p>通过跨步，可以实现一个新的步伐。在跳步后，右脚是朝前的，中心也在右脚而不是左脚。此时可以朝前垫一步走：</p><ul><li>后退时，是右脚在前左脚在后的。不同于之前的立即转身，这次是先整体向后跳一步，然后再转身，转身后后撤步一到两步调整位置。</li><li>击球时，暂时不使用跨步的技术，但是击球完，右脚顺势向前，形成右脚前左脚后的站姿。然后向前跳一步，然后分别迈左脚和右脚上步。此时挥动球拍可以碰到球网。</li></ul><h1 id="Day-6"><a href="#Day-6" class="headerlink" title="Day 6"></a>Day 6</h1><p>首先纠正了跨步的技术。可以左脚前，右脚后分立在羽毛球场的两条边线上。然后右脚蹬地，在空中完成旋转。此时，右脚应该朝前跨出，感觉在做高抬腿。左脚自然会先落地。击球的动作随着转腰就一并完成了。注意，右脚是脚后跟落地，落地要轻一点。在落地后，左右脚实际上交换了位置，依然踩在两根边线上。整个动作，必须左脚先落地，右脚再落地。击球要在空中。</p><p>然后，我问了下平飞球的处理方法，教练说也要架拍。推荐直接网前干死。</p><p>然后，我问了下所谓内旋的问题，教练说没必要刻意。</p><p>然后是高远球的练习，结合上次学的步伐。我提前热身了半小时，所以这次比较熟练。感觉对于击球点，和转腰侧身的感觉更好了。发力也更集中。</p><p>然后就是扑球的教学。这个类似于杀球。抢高点，小臂手腕用力向下。这里不能是点下去，而是得发力，杀球的终末，球拍可以处于网下的，哪怕球杀下网。</p><p>然后是挑球的教学。不需要引拍，不需要做捞的动作。手腕要往外撅，仅通过手臂和手腕将球往前上方打。这里，纠正了握拍：不能拳式，食指得伸出来。高远球也得这么握拍，我后面发现发力也更容易了，感觉有根筋会拉住。在挑球的时候，不能冲过了。也就是右脚在前，左脚在后，右脚踩到白线就差不多了。</p><p>问了下后撤步膝盖左右移动疼的问题，教练说得外八，脚跟着地。</p><h1 id="Day-7"><a href="#Day-7" class="headerlink" title="Day 7"></a>Day 7</h1><p>感觉今天是螺旋式上升的一天。主要还是练习的后场的高远球。</p><p>因为前几天我和别人对打的时候，发现我的击球的声音不是很清脆响亮，教练的意思是可能是球拍接触球的角度有问题。</p><p>首先，今天握拍改成了半拳式握拍了。教练和我对象讲解了握拍的方式，也就是虎口对着拍框捋下来。</p><p>今天的练习，感觉是几个问题：</p><ul><li>绷着，没有放松<br>  这个应该指的是小臂没有充分发力，而是很僵硬地转腰把球打过来</li><li>球拍有切的动作</li><li>没有打到球拍的甜区，而是在偏上方，这就有种很顶的感觉</li></ul><p>下面几个应该是一个问题：</p><ul><li>收拍的时候，最后是往上勾的，有点类似收剑入鞘的那个动作还要再多绕一点角度</li><li>挥拍的时候，会有从右往左扇耳光的感觉</li></ul><p>这里的原因是我为了避免之前几节课肩膀往前甩的问题。我感觉原因如下：</p><ul><li>我挥拍完，重心太往前了，导致人直接冲出去了。按照教练的意思好像是核心没有收住。</li></ul><p>教练的建议是：</p><ul><li>挥拍，也就是小臂做完内旋之后，其实已经完成了击球，这个时候可以直接把大臂放下来。</li><li>大臂放下来时候，可以让握拍手摸着肚子，确保自己的核心是收住的。</li></ul><p>另外今天进行了左右后场跑动的训练，也就是没有那么右脚在前左脚在后的小跳了，而是直接转侧身后撤步。</p><p>我个人的感觉，我打的比较好的球，基本上都是要迎着球上去的。基本上转身之后，右脚可能还会有个踮脚起来的动作。</p><p>整体来讲，我觉得挥拍接触球的速度，比挥拍的幅度要重要很多。</p><h1 id="Day-8"><a href="#Day-8" class="headerlink" title="Day 8"></a>Day 8</h1><p>先和我对象打了会，我对象打球掉肘严重，击球滞后。这实际上导致了她发力的时候把球是碰过去的，而没有形成合力，并且打框。</p><p>今天是练了后场高远以及前后场的转换。总体来讲，这次高远球好了很多。有个提高点是手腕要随挥的时候发力。</p><p>此外，还学了反手前场挑球。</p><h1 id="Day-9"><a href="#Day-9" class="headerlink" title="Day 9"></a>Day 9</h1><p>今天练习了四方步：</p><ul><li>【中-&gt;左后】首先，我们在场地中央往左后方移动。此时直接转身做后撤步。</li><li>【左后-&gt;右前】击球后，右脚顺势跨出。此时做一个向前跳的启动，走或者跑到右前方。最后，肯定是迈左脚，然后最后右脚迈到前面，同时完成挑球动作。</li><li>【右前-&gt;右后】击球后，直接向后场小跳完成启动。这里不要专门侧身，比如左脚后右脚前这样跳。然后，就继续侧身后撤步，击球。</li><li>【右后-&gt;左前】击球后，同样小跳启动，然后往左前走。最后，是先迈左脚，然后同样是右脚弓箭步上去完成挑球，此时要切换到反手握拍。</li><li>【左前-&gt;中】击球后，小跳启动回中。</li></ul><p>教练强调了很多和拉手相关的问题。击球的时候，左手不要抱在胸前，也不要伸到后面。自然拉到身体左侧就行。</p><h1 id="假期的练习"><a href="#假期的练习" class="headerlink" title="假期的练习"></a>假期的练习</h1><p>感受：</p><ul><li>架拍要高。</li><li>高远球的击球点要高，要迎着球打。</li><li>手腕不要绕，不要二次引拍。因为已经侧身了。我现在觉得二次引拍可能会让击球点偏后，拍子反而加速不到位。</li><li>打完要回中。我习惯打完球看下球在哪里。</li><li>挑球要直着，核心要稳定。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录一下一些要点&lt;/p&gt;</summary>
    
    
    
    
    <category term="运动" scheme="http://www.calvinneo.com/tags/运动/"/>
    
  </entry>
  
  <entry>
    <title>CPU Profiling 经验之谈</title>
    <link href="http://www.calvinneo.com/2024/11/21/cpu-profiling/"/>
    <id>http://www.calvinneo.com/2024/11/21/cpu-profiling/</id>
    <published>2024-11-21T15:07:22.000Z</published>
    <updated>2025-01-03T10:46:23.669Z</updated>
    
    <content type="html"><![CDATA[<p>记录了自己在执行 CPU Profiling 的时候遇到的一些经验。</p><p>相关文章：</p><ol><li><a href="/2024/08/23/monitor-alloc-in-C++/">heap profiling</a></li></ol><a id="more"></a><h1 id="Profiling-基础"><a href="#Profiling-基础" class="headerlink" title="Profiling 基础"></a>Profiling 基础</h1><p>首先，<a href="/2023/12/17/patmc/">Performance analysis and tuning on modern CPUs</a> 这本书是值得阅读的基础。但是里面讲述的很多内容，我目前还没有机会完全实践。</p><h1 id="关于线程池"><a href="#关于线程池" class="headerlink" title="关于线程池"></a>关于线程池</h1><h2 id="记录线程名"><a href="#记录线程名" class="headerlink" title="记录线程名"></a>记录线程名</h2><p>有一些方法设置线程名，包括：</p><ol><li>pthread_setname_np</li><li>prctl</li></ol><p>出于下列原因，建议线程名具有唯一性：</p><ol><li>诸如一些线程池的实际工作内容不一样，最好以数字区分。</li><li>有一些库会扩展 std::mutex，记录上锁的线程名，用来避免重复加锁。当然这个并不好，最好用线程 id。</li></ol><p>在一些很老的 C 库中，没有提供 pthread_setname_np 函数。CK 会写一个 dummy 的函数来替换，这可能导致<a href="https://github.com/pingcap/tiflash/issues/6616" target="_blank" rel="noopener">一些情况下</a>不能设置成功线程名。</p><h2 id="线程名的切换问题"><a href="#线程名的切换问题" class="headerlink" title="线程名的切换问题"></a>线程名的切换问题</h2><p>一些程序会同时记录所有线程的 CPU 用量，以及当前进程的 CPU 总用量。这两个是一致的么？至少在一个使用线程池的程序中，未必一致。</p><p>这里的原因是线程池中往往会将线程按照 <code>${task_name}_${task_id}</code> 这样重新命名，从而区分用途。而处于避免线程启动和销毁的开销，又倾向于维护一个全局常驻线程池，新开辟的线程池会先尝试从这个全局线程池中取，然后用完之后再归还。这就导致如果在这个过程中线程名字发生了从 A 到 B 的变换，则可能会看到 B 对应的指标有一个很高的 delta（比如在 grafana 中能看到一个尖峰）。原因是 <code>/proc/$pid/stat</code> 或者 <code>/proc/tasks/$tid/stat</code> 里面的信息都是从启动开始经历的时钟周期，无论是 stime 还是 utime。所以，如果一开始线程名是 A，后来被某个线程池借走了，名字变成 B，但此时 A 的数据还在。如果此时，线程被归还了，名字改为 A，那么 A 的变化率就是这段时间的 jiffies 增量除以这段时间的长度。</p><h1 id="On-CPU-和-Off-CPU-time"><a href="#On-CPU-和-Off-CPU-time" class="headerlink" title="On CPU 和 Off CPU time"></a>On CPU 和 Off CPU time</h1><p>Off-CPU 例如在等待阻塞 IO、锁、page swap 等的时间。这些时间不会通过普通的火焰图被反映出来，但却是影响读取性能的一个因素。我们常常要回答问题，为什么 CPU 没有被用满，但是查询依然比较慢。</p><h2 id="设计上的-pitfall"><a href="#设计上的-pitfall" class="headerlink" title="设计上的 pitfall"></a>设计上的 pitfall</h2><ul><li>循环中的虚函数调用</li><li>memcpy</li></ul><h2 id="使用-perf-probe-记录函数调用耗时"><a href="#使用-perf-probe-记录函数调用耗时" class="headerlink" title="使用 perf probe 记录函数调用耗时"></a>使用 perf probe 记录函数调用耗时</h2><p>该方案整理自某同事的 idea。</p><p>考虑下面的场景，我们需要查看某动态链接库 <code>/path/to/libtiflash_proxy.so</code> 中 <code>handle_pending_applies</code> 函数每次调用的耗时。此时，可以借助 <code>perf probe</code> 去打点 <code>$tok</code> 和 <code>$tok%return</code>，它们分别对应函数入口和函数出口。这里需要借助于一个 while 循环是因为函数可能有多个重载。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">perf probe --del <span class="string">'probe_libtiflash_proxy:*'</span></span><br><span class="line">BIN=/path/to/libtiflash_proxy.so</span><br><span class="line">TOKEN=handle_pending_applies</span><br><span class="line">ITER=0</span><br><span class="line">objdump <span class="variable">$BIN</span> --syms | grep <span class="variable">$TOKEN</span> | awk <span class="string">'&#123;print $6&#125;'</span> | <span class="keyword">while</span> <span class="built_in">read</span> -r tok ; <span class="keyword">do</span></span><br><span class="line">    ITER=$(expr <span class="variable">$ITER</span> + 1)</span><br><span class="line">    NAME=<span class="variable">$TOKEN</span>\_<span class="variable">$ITER</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$NAME</span>, <span class="variable">$TOKEN</span>, <span class="variable">$ITER</span>, <span class="variable">$TOKEN</span>\_<span class="variable">$ITER</span></span><br><span class="line">    perf probe -x <span class="variable">$BIN</span> --no-demangle <span class="variable">$NAME</span>=<span class="variable">$tok</span></span><br><span class="line">    perf probe -x <span class="variable">$BIN</span> --no-demangle <span class="variable">$NAME</span>=<span class="variable">$tok</span>%<span class="built_in">return</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">perf record -e probe_libtiflash_proxy:\* -aR sleep 10</span><br><span class="line">perf script -s perf-script.py</span><br></pre></td></tr></table></figure><p><a href="/asset/highconcurrency/perf-script.py">附上 perf-script.py</a></p><h1 id="关于-benchmark"><a href="#关于-benchmark" class="headerlink" title="关于 benchmark"></a>关于 benchmark</h1><h2 id="pitfall"><a href="#pitfall" class="headerlink" title="pitfall"></a>pitfall</h2><ul><li>需要多次运行</li><li>需要预热，加载缓存<br>  通常可以使用启发式的方法，等待性能收敛。</li><li>使用高精度时钟</li><li>监控系统负载</li><li>避免编译器优化</li><li>缓存影响</li><li>考虑动态内存分配如 new 或者 delete 对 benchmark 的影响，必要时使用预分配内存池</li></ul><h2 id="google-benchmark"><a href="#google-benchmark" class="headerlink" title="google benchmark"></a>google benchmark</h2><h1 id="关于死锁"><a href="#关于死锁" class="headerlink" title="关于死锁"></a>关于死锁</h1><h2 id="寻找死锁的原因"><a href="#寻找死锁的原因" class="headerlink" title="寻找死锁的原因"></a>寻找死锁的原因</h2><p>通过 gdb 可以找到对应 mutex 结构中的 owner，对应的值表示 LWP 的编号。<br>对于一些程序，可能 debug info 被优化掉了，<a href="https://stackoverflow.com/questions/76489792/how-to-identify-which-thread-holds-the-stdrecursive-mutex-by-gdb" target="_blank" rel="noopener">此时可以选择</a>：</p><ol><li>根据提示的行号，拷贝一份对应的源码到指定位置</li><li>自己编译一个同样 layout 的对象，然后 load 进去解析</li></ol><h1 id="一些工具"><a href="#一些工具" class="headerlink" title="一些工具"></a>一些工具</h1><h2 id="pstack"><a href="#pstack" class="headerlink" title="pstack"></a>pstack</h2><p>可以通过 <a href="https://gist.github.com/JaySon-Huang/e374da1fafa41a3fa30a24e135c60825" target="_blank" rel="noopener">https://gist.github.com/JaySon-Huang/e374da1fafa41a3fa30a24e135c60825</a> 去合并相同的堆栈。</p><p>如果 pstack 没有安装，可以借助于 GDB 的 <code>thread apply all bt</code> 命令。但这个命令会对屏幕输入一堆字符，不是很好看。因此可以</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set logging file mylog.txt</span><br><span class="line">set logging on</span><br></pre></td></tr></table></figure><p>或者使用命令行直接输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gdb -ex <span class="string">"thread apply all bt"</span> -batch -p <span class="variable">$PID</span></span><br></pre></td></tr></table></figure><h2 id="uprobe"><a href="#uprobe" class="headerlink" title="uprobe"></a>uprobe</h2><h2 id="func-latency-工具"><a href="#func-latency-工具" class="headerlink" title="func_latency 工具"></a>func_latency 工具</h2><p>这也是 bcc 套装里面的一个工具。</p><h2 id="PT-PERF-技术"><a href="#PT-PERF-技术" class="headerlink" title="PT_PERF 技术"></a>PT_PERF 技术</h2><p>主要是看 <a href="http://mysql.taobao.org/monthly/2024/04/02/" target="_blank" rel="noopener">mysql 内核月报</a> 和<a href="http://mysql.taobao.org/monthly/2024/04/03/" target="_blank" rel="noopener">续集</a>学的，它还给了一个<a href="http://mysql.taobao.org/monthly/2024/07/04/" target="_blank" rel="noopener">应用场景</a>。<br>这个工具的原理是 Intel CPU 的一个 Processor Trace 技术。主要特点是开销小。它记录程序控制流，特别是 branch 跳转的信息。</p><p>这个工具可以：</p><ol><li>跟踪某个函数在历史时间中执行时间的分布情况。</li><li>跟踪该函数所有子函数的执行情况，包含各自花了多久，占比如何。</li><li>跟踪 Off-CPU，参数 -o。</li><li>通过 –history=1 记录，拷贝数据到另一台机器上通过 –history=2 分析。</li><li>通过 <code>-a do_command#67108864,134217727</code> 指定对应父函数以及耗时范围，从而精准定位子函数存在的问题。</li></ol><p>需要：</p><ol><li>修改 perf_event_mlock_kb 支持更大的 trace buffer，减少 trace 数据丢失。</li><li>修改 kptr_restrict 支持追踪内核函数，如追踪 off-cpu 分析需要的 schedule 内核函数。</li></ol><p>此外对 Linux 版本也有依赖。</p><h2 id="eBPF-技术原理"><a href="#eBPF-技术原理" class="headerlink" title="eBPF 技术原理"></a>eBPF 技术原理</h2><p>包括 kprobe、uprobe、tcpdump 等工具都是<a href="https://cloudnative.to/blog/bpf-intro/" target="_blank" rel="noopener">基于 eBPF 技术实现的</a>：</p><ul><li>kprobes：实现内核中动态跟踪。kprobes 可以跟踪到 Linux 内核中的导出函数入口或返回点，但是不是稳定 ABI 接口，可能会因为内核版本变化导致，导致跟踪失效。</li><li>uprobes：用户级别的动态跟踪。与 kprobes 类似，只是跟踪用户程序中的函数。</li><li>tracepoints：内核中静态跟踪。tracepoints 是内核开发人员维护的跟踪点，能够提供稳定的 ABI 接口，但是由于是研发人员维护，数量和场景可能受限。</li><li>perf_events：定时采样和 PMC。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录了自己在执行 CPU Profiling 的时候遇到的一些经验。&lt;/p&gt;
&lt;p&gt;相关文章：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;/2024/08/23/monitor-alloc-in-C++/&quot;&gt;heap profiling&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    
    <category term="profiling" scheme="http://www.calvinneo.com/tags/profiling/"/>
    
    <category term="CPU" scheme="http://www.calvinneo.com/tags/CPU/"/>
    
    <category term="性能" scheme="http://www.calvinneo.com/tags/性能/"/>
    
    <category term="benchmark" scheme="http://www.calvinneo.com/tags/benchmark/"/>
    
  </entry>
  
  <entry>
    <title>折腾 NAS</title>
    <link href="http://www.calvinneo.com/2024/11/14/on-nas/"/>
    <id>http://www.calvinneo.com/2024/11/14/on-nas/</id>
    <published>2024-11-14T10:07:22.000Z</published>
    <updated>2025-01-18T19:24:30.766Z</updated>
    
    <content type="html"><![CDATA[<p>记录了我折腾 NAS 的相关问题和解决方案。</p><a id="more"></a><h1 id="有线-mesh"><a href="#有线-mesh" class="headerlink" title="有线 mesh"></a>有线 mesh</h1><ol><li>子路由连 lan 口</li><li>关闭 DHCP</li><li>子路由修改 wifi 名字和主路由相同</li></ol><p>在此之后，子路由会重启，然后就无法再次登录子路由的管理界面了。连着子路由，tracert 也不会显示子路由的 ip。</p><p>要做到无缝切换，需要整个过程中 ip 地址是不变的，因此主路由和副路由需要在同一个网段里面。</p><h1 id="外网访问"><a href="#外网访问" class="headerlink" title="外网访问"></a>外网访问</h1><p>为了实现快速的外网访问，有几种思路：</p><ol><li>使用一个服务器转发</li><li>类似 ZeroTier 的 VPN 方案</li><li>直接使用公网 IP</li></ol><p>对于后两种方案，需要：</p><ol><li>首先实现“光猫改桥接”，然后使用路由器拨号。这样，光猫只会负责光信号转电信号，路由器实际上是整个家庭网络的边界了。</li><li>开启路由器的 UPnP 功能。</li></ol><h2 id="ZeroTier"><a href="#ZeroTier" class="headerlink" title="ZeroTier"></a>ZeroTier</h2><h2 id="光猫改桥接"><a href="#光猫改桥接" class="headerlink" title="光猫改桥接"></a>光猫改桥接</h2><p>对于移动来说，路由器拨号的账户是手机号，密码可以打 10086 重置密码。</p><h1 id="全局梯子"><a href="#全局梯子" class="headerlink" title="全局梯子"></a>全局梯子</h1><h2 id="OpenClash"><a href="#OpenClash" class="headerlink" title="OpenClash"></a>OpenClash</h2><p><img src="/img/nas/openclash.r.png"></p><p>下面是第一个配置的截图。总共有 10 张图，修改 url 来查看其他的图。<br><img src="/img/nas/openclash.1.png"></p><p>覆写设置 -&gt; 开发者选项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">. /usr/share/openclash/ruby.sh</span><br><span class="line">. /usr/share/openclash/log.sh</span><br><span class="line">. /lib/functions.sh</span><br><span class="line"></span><br><span class="line"># This script is called by /etc/init.d/openclash</span><br><span class="line"># Add your custom overwrite scripts here, they will be take effict after the OpenClash own srcipts</span><br><span class="line"></span><br><span class="line">LOG_OUT &quot;Tip: Start Running Custom Overwrite Scripts...&quot;</span><br><span class="line">LOGTIME=$(echo $(date &quot;+%Y-%m-%d %H:%M:%S&quot;))</span><br><span class="line">LOG_FILE=&quot;/tmp/openclash.log&quot;</span><br><span class="line">CONFIG_FILE=&quot;$1&quot; #config path</span><br><span class="line"></span><br><span class="line">#Simple Demo:</span><br><span class="line">    #General Demo</span><br><span class="line">    #1--config path</span><br><span class="line">    #2--key name</span><br><span class="line">    #3--value</span><br><span class="line">    #ruby_edit &quot;$CONFIG_FILE&quot; &quot;[&apos;redir-port&apos;]&quot; &quot;7892&quot;</span><br><span class="line">    #ruby_edit &quot;$CONFIG_FILE&quot; &quot;[&apos;secret&apos;]&quot; &quot;123456&quot;</span><br><span class="line">    #ruby_edit &quot;$CONFIG_FILE&quot; &quot;[&apos;dns&apos;][&apos;enable&apos;]&quot; &quot;true&quot;</span><br><span class="line"></span><br><span class="line">    #Hash Demo</span><br><span class="line">    #1--config path</span><br><span class="line">    #2--key name</span><br><span class="line">    #3--hash type value</span><br><span class="line">    ruby_edit &quot;$CONFIG_FILE&quot; &quot;[&apos;experimental&apos;]&quot; &quot;&#123;&apos;sniff-tls-sni&apos;=&gt;true&#125;&quot;</span><br><span class="line">    #ruby_edit &quot;$CONFIG_FILE&quot; &quot;[&apos;sniffer&apos;]&quot; &quot;&#123;&apos;sniffing&apos;=&gt;[&apos;tls&apos;,&apos;http&apos;]&#125;&quot;</span><br><span class="line"></span><br><span class="line">    #Array Demo:</span><br><span class="line">    #1--config path</span><br><span class="line">    #2--key name</span><br><span class="line">    #3--position(start from 0, end with -1)</span><br><span class="line">    #4--value</span><br><span class="line">    #ruby_arr_insert &quot;$CONFIG_FILE&quot; &quot;[&apos;dns&apos;][&apos;nameserver&apos;]&quot; &quot;0&quot; &quot;114.114.114.114&quot;</span><br><span class="line"></span><br><span class="line">    #Array Add From Yaml File Demo:</span><br><span class="line">    #1--config path</span><br><span class="line">    #2--key name</span><br><span class="line">    #3--position(start from 0, end with -1)</span><br><span class="line">    #4--value file path</span><br><span class="line">    #5--value key name in #4 file</span><br><span class="line">    #ruby_arr_add_file &quot;$CONFIG_FILE&quot; &quot;[&apos;dns&apos;][&apos;fallback-filter&apos;][&apos;ipcidr&apos;]&quot; &quot;0&quot; &quot;/etc/openclash/custom/openclash_custom_fallback_filter.yaml&quot; &quot;[&apos;fallback-filter&apos;][&apos;ipcidr&apos;]&quot;</span><br><span class="line"></span><br><span class="line">#Ruby Script Demo:</span><br><span class="line">    #ruby -ryaml -rYAML -I &quot;/usr/share/openclash&quot; -E UTF-8 -e &quot;</span><br><span class="line">    #   begin</span><br><span class="line">    #      Value = YAML.load_file(&apos;$CONFIG_FILE&apos;);</span><br><span class="line">    #   rescue Exception =&gt; e</span><br><span class="line">    #      puts &apos;$&#123;LOGTIME&#125; Error: Load File Failed,【&apos; + e.message + &apos;】&apos;;</span><br><span class="line">    #   end;</span><br><span class="line"></span><br><span class="line">        #General</span><br><span class="line">    #   begin</span><br><span class="line">    #   Thread.new&#123;</span><br><span class="line">    #      Value[&apos;redir-port&apos;]=7892;</span><br><span class="line">    #      Value[&apos;tproxy-port&apos;]=7895;</span><br><span class="line">    #      Value[&apos;port&apos;]=7890;</span><br><span class="line">    #      Value[&apos;socks-port&apos;]=7891;</span><br><span class="line">    #      Value[&apos;mixed-port&apos;]=7893;</span><br><span class="line">    #   &#125;.join;</span><br><span class="line"></span><br><span class="line">    #   rescue Exception =&gt; e</span><br><span class="line">    #      puts &apos;$&#123;LOGTIME&#125; Error: Set General Failed,【&apos; + e.message + &apos;】&apos;;</span><br><span class="line">    #   ensure</span><br><span class="line">    #      File.open(&apos;$CONFIG_FILE&apos;,&apos;w&apos;) &#123;|f| YAML.dump(Value, f)&#125;;</span><br><span class="line">    #   end&quot; 2&gt;/dev/null &gt;&gt; $LOG_FILE</span><br><span class="line"></span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p>注意，和 PS5 相关的要走 DIRECT</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- DOMAIN-SUFFIX,playstation.com,DIRECT</span><br><span class="line">- DOMAIN-SUFFIX,playstation.com.hk,DIRECT</span><br><span class="line">- DOMAIN-SUFFIX,playstation.net,DIRECT</span><br><span class="line">- DOMAIN-SUFFIX,playstationnetwork.com,DIRECT</span><br></pre></td></tr></table></figure><h1 id="Meta-Quest-相关"><a href="#Meta-Quest-相关" class="headerlink" title="Meta Quest 相关"></a>Meta Quest 相关</h1>]]></content>
    
    
    <summary type="html">&lt;p&gt;记录了我折腾 NAS 的相关问题和解决方案。&lt;/p&gt;</summary>
    
    
    
    
    <category term="硬件" scheme="http://www.calvinneo.com/tags/硬件/"/>
    
  </entry>
  
  <entry>
    <title>Database paper part 4</title>
    <link href="http://www.calvinneo.com/2024/11/13/database-paper-4/"/>
    <id>http://www.calvinneo.com/2024/11/13/database-paper-4/</id>
    <published>2024-11-13T13:33:22.000Z</published>
    <updated>2024-11-20T17:12:16.352Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章中，包含 Column Stores vs Row Stores、To BLOB or Not To BLOB: Large Object Storage in a Database or a Filesystem?、Cloud Programming Simplified: A Berkeley View on Serverless Computing。</p><a id="more"></a><h1 id="Column-Stores-vs-Row-Stores-How-Different-Are-They-Really"><a href="#Column-Stores-vs-Row-Stores-How-Different-Are-They-Really" class="headerlink" title="Column-Stores vs. Row-Stores: How Different Are They Really?"></a>Column-Stores vs. Row-Stores: How Different Are They Really?</h1><p>主要是说，列存和行存在 query execution level 和 storage level 上的不一样导致了难以用行存模拟列存。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>尝试回答下面这个问题：<br>Are these performance gains due to something fundamental about the way column-oriented DBMSs are internally architected, or would such gains also be possible in a conventional system that used a more column-oriented physical design?</p><p>下面这些技术尝试用在行存上，看能不能让它 as “column-oriented” as possible.</p><ol><li>Vertically partitioning。将表切分成一系列 two-column table，这个 table 由 (table key, attribute) 对们构成。所以只有需要的 column 会被 query 所读取。</li><li>index-only plan。创建一系列的 index，足以覆盖查询中所有被用到的 column。这样就根本不用查下层的行存表了。</li><li>用一系列物化视图，使得每个查询所需要的列，都能够有一个对应的视图，虽然这个方案要用很多的空间，但是对 row store 来说是一个 best case。</li></ol><p>论文应用了这些优化，然后以 CStore 作为基线来对比，使用 SSBM 负载。结果显示，尽管上面的这些方案都在行存中模拟了列存，但是 query processing performance 依然是很差。</p><p>下一个问题是：<br>Which of the many column-database specific optimizations proposed in the literature are most responsible for the significant performance advantage of column-stores over row-stores on warehouse workloads?<br>这里，作者列出了这些 column-database specific optimizations：</p><ol><li>延迟物化。这里还需要和下面的 block iteraton 结合起来。</li><li>Block iteration。这个技术也被称为 vectorized query processing。这里指从一个列中读到的多个 value，以一个 block 的方式从一个 operator 传到另一个。和这个相对应的是类似于 Volcano 一样的 per-tuple iterator。如果 value 是 fixed width 的，它们会被像一个 array 一样被遍历。</li><li>Column-specific 的压缩方式。例如 RLE，with direct operation on compressed data when using late-materialization plans.</li><li>作者自己还提出了一个 invisible join 的优化，能够提升延迟物化中的 join 性能。</li></ol><p>论文通过在 CStore 中移除不同的优化手段，来度量它们的作用。如果压缩可行的话，则压缩能够提供数量级的提升。延迟物化能提升三倍性能。block iteration 以及 invisible join 提升 1.5 倍性能。<br>TiFlash 的延迟物化在 chbenchmark 上除了 q10（特大查询，过滤率较低）之外提升 10% 左右。在 tpc-h 上性能提升不大，因为没有过滤率很高的条件。在 tpc-ds 这种偏向于小表上的复杂 ap 查询上的场景有限。</p><h2 id="STAR-SCHEMA-BENCHMARK"><a href="#STAR-SCHEMA-BENCHMARK" class="headerlink" title="STAR SCHEMA BENCHMARK"></a>STAR SCHEMA BENCHMARK</h2><p>这个 benchmark 是从tpch 上派生出来的。不同于 tpch，它使用了纯粹的教科书级别的星形模型。它的查询比 tpch 要少。选择它主要是因为它比 tpch 更容易实现，所以就不需要修改 CStore 就能跑。<br>Schema：这个 benchmark 只包含一张事实表，也就是 lineorder 表，它合并了 tpch 中的 lineitem 和 orders 表。</p><p><img src="/img/dbpaper/rvsc/1.png"></p><p>Queries：包含了 13 个 query，可以被分为 4 类，或者四个 flight：</p><ol><li>Flight 1 包含 3 个 queries。这些 query 的约束条件是 1 dimension attribute，以及 discount 和 quantity 列。目的是在不同折扣下计算 gain in revenue(EXTENDEDPRICE * DISCOUNT)。</li><li>Flight 2 包含 3 个 query。约束条件是 2 dimension attributes。计算在特定 region 特定 produce class 的 revenue，并且按照 product class 和 year 去 group。</li><li>Flight 3 包含 4 个 query。约束条件是 3 dimention attributes。计算特定区域的特定时间内的 revenue，按照 customernation、supplier nation 和 year 做 group。</li><li>Flight 4 包含 3 个 query。Queries restrict on three dimension columns, and compute profit (REVENUE - SUPPLYCOST) grouped by year, nation, and category for query 1; and for queries 2 and 3, region and category. The LINEORDER selectivities for the three queries are 1.6×10−2 , 4.5×10−3 , and 9.1 × 10−5 , respectively</li></ol><h2 id="ROW-ORIENTED-EXECUTION"><a href="#ROW-ORIENTED-EXECUTION" class="headerlink" title="ROW-ORIENTED EXECUTION"></a>ROW-ORIENTED EXECUTION</h2><h3 id="Vertical-Partitioning"><a href="#Vertical-Partitioning" class="headerlink" title="Vertical Partitioning"></a>Vertical Partitioning</h3><p>在实现时，需要一个措施让属于相同的 row 的 field 能够彼此连接起来。在列存中这是隐式实现的，因为所有的列中的 field 都是按照相同的顺序来存储的。在行存中，一个简单的办法是对每个表中添加一个 position 列。这样每个 column都对应一个 physical 表，第 i 个表有两个 column，第一个是逻辑表中 column i 的值，第二个是 position 列中对应的值。Queries are then rewritten to perform joins on the position attribute when fetching multiple columns from the same relation. In our implementation, by default, System X chose to use hash joins for this purpose, which proved to be expensive. For that reason, we experimented with adding clustered indices on the position column of every table, and forced System X to use index joins, but this did not improve performance – 因为索引引起的额外的 io 导致了它比 hash join 还要慢。</p><h3 id="Index-only-plans"><a href="#Index-only-plans" class="headerlink" title="Index-only plans"></a>Index-only plans</h3><p>Vertical Partitioning 有两个问题。第一个是每个 column 都需要存一个 position 列，浪费空间和磁盘带宽。第二个是大多数行存会为每个 tuple 存一个相对比较大的 header，从而进一步浪费空间。而列存几乎总是将 header 存在各自的 column 中，从而避免类似的开销。【Q】这个 header 是指的为 MVCC 服务的隐藏列么？<br>因此，现在这个设计中，base relation 会被存在一个标准的行存中，但是一个额外的、unclustered 的 B+ 树索引会被加载每个 table 的每个 column 上。<br>Index-only plan 需要数据库的额外的支持。首先对每个表，建立满足 predicate (record-id, value) 对的 list，然后如果在同一个表上有多个 predicate，则需要在内存中 merge 这些 rids-list。当这些 fields 没有 predicate，那么就可以返回这一列中所有的 (record-id, value) 对。可以看到，这样的 plan 并不需要访问磁盘上的真实 tuple。虽然这些 index 能够显式存放 rid，但是它们不会存储一份重复的 value 了。所以，它有 a lower per-tuple overhead than the vertical-partitioning approach，因为 tuple header 并没被存在 index 中。<br>容易发现，这个问题是如果一个 column 上没有 predicate，就需要扫描一遍 index 从而去提取出需要的 value。相比于 vertical partition 的扫 heap file 会更慢一点。【Q】我理解就是这时候要回表，就比较慢。<br>一个优化是建立 composite keys 的索引。例如 <code>SELECT AVG(salary) FROM emp WHERE age &gt; 40</code> 这个 query，如果建立了一个 (age, salary) 上的 composite index，就可以从这个索引中快速回答这个 query。如果我们为 age 和 salary 分别建立了索引，那么 index-only-plan 就需要首先根据 age 的索引找到所有的 record-ids，然后再去和整个 (record-id, salary) 列表去 merge，而这个就需要加载整个 salary 索引，所以就很慢了。<br>We use this optimization in our implementation by storing the primary key of each dimension table as a secondary sort attribute on the indices over the attributes of that dimension table. 这样，就可以有效访问 the primary key values of the dimension that need to be joined with the fact table. </p><h3 id="Materialized-Views"><a href="#Materialized-Views" class="headerlink" title="Materialized Views"></a>Materialized Views</h3><p>对于每个 query flight，狗仔一个 optimal set of materialized view，其中只包含所有需要的 column。我们没有 pre-join columns needed to answer queries in these views。Our objective with this strategy is to allow System X to access just the data it needs from disk, avoiding the overheads of explicitly storing record-id or positions, and storing tuple headers just once per tuple. 因此，我们期望它比其他两个方式表现更好，尽管它要求 query 的 workload 需要被提前知道。</p><h2 id="COLUMN-ORIENTED-EXECUTION"><a href="#COLUMN-ORIENTED-EXECUTION" class="headerlink" title="COLUMN-ORIENTED EXECUTION"></a>COLUMN-ORIENTED EXECUTION</h2><h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><p>压缩实际上减少了磁盘使用，但是磁盘是越来越便宜的。但是，它还能提高性能。原因是如果数据变小了，那么通过 IO 从磁盘上读取这些数据的时间也就变少了。因此，在更高的压缩率和更快的解压速度之间是一个权衡。</p><p>特别地，如果能够在压缩的数据上直接执行计算，就可以避免解压。比如，RLE 这种将重复的 value 替换为 count 和 value 的做法。</p><p>Prior work [4] concludes that the biggest difference between compression in a row-store and compression in a column-store are the cases where a column is sorted (or secondarily sorted) and there are consecutive repeats of the same value in a column. In a columnstore, it is extremely easy to summarize these value repeats and operate directly on this summary. In a row-store, the surrounding data from other attributes significantly complicates this process. Thus, in general, compression will have a larger impact on query performance if a high percentage of the columns accessed by that query have some level of order.</p><h3 id="延迟物化"><a href="#延迟物化" class="headerlink" title="延迟物化"></a>延迟物化</h3><p>优势：</p><ol><li>select 和 aggregation operator 可以不去构造某些元组。如果 executor 能在构造一个 tuple 时等待足够长的时间，就可以完全避免去构造。</li><li>如果数据被压缩，就需要在和其他 column 组合之前被解压。这样就失去了直接操作压缩数据的优势。</li><li>Cache 利用率提高了。显然，我们可以不用加载一堆东西，从而污染 Cache。</li><li>后面的 Block iteration 优化对于定长的 attribute 的优化性能更强。row store 中，只要有一个 attribute 是变长的，那么整个 tuple 就是变长的，但是在 column store 中，列是单独存放的。</li></ol><h3 id="Block-Iteration"><a href="#Block-Iteration" class="headerlink" title="Block Iteration"></a>Block Iteration</h3><p>为了处理一系列的 tuple，行存首先要遍历每个 tuple，然后提取需要的 attribute。这个提取通常需要几次函数调用。</p><p>在列存中，同一个 column 的 block 会被发送给一个 operator，所以就是一次函数调用。另外，也不需要提取 attribute 了。如果 column 是定长的，就可以以 array 的形式去遍历它。array 的形式还能实现并行处理，比如 loop-pipelining 技术。</p><h3 id="Invisible-Join"><a href="#Invisible-Join" class="headerlink" title="Invisible Join"></a>Invisible Join</h3><p>星型 schema 的 query 通常有如下的结构：通过一个或者多个 dimension table 上的 selection predicate 作为 fact table 上的约束条件。然后基于这个受约束的事实表上做一些聚合，通常是和其他的 dimention table 上的一些 attribute 去 group by。<br>因此，对于每个 selection predicate 以及每个 aggregate group 都需要执行一次 fact table 和 dimension table 的 join。<br>下面的 query 就是一个典型。传统的 plan 是 pipeline joins in order of predicate selectively。例如，如果 <code>c.region = &#39;ASIA&#39;</code> 是最 selective 的 predicate，那么根据 custkey 去 join lineorder 和 customer 两个表就会被首先执行，这样就会过滤 lineorder 表，从而只有在 ASIA 的客户留下来。在这个 join 完成后，customer 的 nation 就会被加入到这个 join 后的 customer-order 中间表中。These results are pipelined into a join with the supplier table where the <code>s.region = &#39;ASIA&#39;</code> predicate is applied and <code>s.nation</code> extracted, followed by a join with the data table and the year predicate applied. The results of these joins are then grouped and aggregated and the results sorted according to the ORDER BY clause</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> c.nation, s.nation, d.year,</span><br><span class="line">    <span class="keyword">sum</span>(lo.revenue) <span class="keyword">as</span> revenue</span><br><span class="line"><span class="keyword">FROM</span> customer <span class="keyword">AS</span> c, lineorder <span class="keyword">AS</span> lo,</span><br><span class="line">    supplier <span class="keyword">AS</span> s, dwdate <span class="keyword">AS</span> d</span><br><span class="line"><span class="keyword">WHERE</span> lo.custkey = c.custkey</span><br><span class="line">    <span class="keyword">AND</span> lo.suppkey = s.suppkey</span><br><span class="line">    <span class="keyword">AND</span> lo.orderdate = d.datekey</span><br><span class="line">    <span class="keyword">AND</span> c.region = <span class="string">'ASIA'</span></span><br><span class="line">    <span class="keyword">AND</span> s.region = <span class="string">'ASIA'</span></span><br><span class="line">    <span class="keyword">AND</span> d.year &gt;= <span class="number">1992</span> <span class="keyword">and</span> d.year &lt;= <span class="number">1997</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> c.nation, s.nation, d.year</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> d.year <span class="keyword">asc</span>, revenue <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><p>另一种做法是延迟物化的方法。In this case, a predicate is applied on the <code>c.region</code> column <code>(c.region = &#39;ASIA&#39;),</code> and the customer key of the customer table is extracted at the positions that matched this predicate. These keys are then joined with the customer key column from the fact table. join 的结果是两个 position 的集合，一个是给 fact table 的，一个是给 dimension table 的。它们表示了这两个表中各有那些 tuple 会被传给 join predicate，然后被 join。<br>一般来说，这两个 posision 集合中，最多只有一个是 sorted order，一般会是 outer table，也就是 fact table。Values from the <code>c.nation</code> column at this (out-of-order) set of positions are then extracted, along with values (using the ordered set of positions) from the other fact table columns (supplier key, order date, and revenue). Similar joins are then performed with the supplier and date tables.</p><p>上面两种方案都有缺点。第一种情况，每次 join 都需要构造一堆 tuple。第二种情况，从 dimension table group-by column 中的值是乱序被提取出来的。</p><h1 id="To-BLOB-or-Not-To-BLOB-Large-Object-Storage-in-a-Database-or-a-Filesystem"><a href="#To-BLOB-or-Not-To-BLOB-Large-Object-Storage-in-a-Database-or-a-Filesystem" class="headerlink" title="To BLOB or Not To BLOB: Large Object Storage in a Database or a Filesystem?"></a>To BLOB or Not To BLOB: Large Object Storage in a Database or a Filesystem?</h1><p>这个论文我比较感兴趣，因为不少朋友在选型的时候面临这个问题：BLOB 应该被存在 fs 里面还是 db 里面呢？<br>需要注意到，这是一篇比较早的论文，正如<a href="https://news.ycombinator.com/item?id=14550982" target="_blank" rel="noopener">文章</a>指出的，随着 SSD 的普及，WAL 和 buffer pool 带来的优势减少了，因为 random write 的性能提高了。</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>小于 256KB 的 blob，db 处理起来比较有效率，fs 对 1MB 以上的 blob 有效率。文章认为，最重要的影响因素是 storage age，也就是 deleted objects 对 live objects 的比值。当 storage age 增加时，fragmentation 就会增加。fs 研究能更好处理 fragmentation。研究中还说，只要平均大小是固定的，其分布如何并不显著影响性能。We also found that, in addition to low percentage free space, a low ratio of free space to average object size leads to fragmentation and performance degradation。</p><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="fragmentation"><a href="#fragmentation" class="headerlink" title="fragmentation"></a>fragmentation</h3><p>NTFS文件系统使用基于“band”的分配策略来管理元数据，但对于文件内容则不是。【Q】这里的 band 是不是别的里面的 stripe？<br>NTFS 通过基于运行的查找缓存来为文件流数据分配空间。这些连续的空闲簇会根据大小和卷偏移量以降序排列。NTFS 尝试从外带开始满足新的空间分配请求。如果失败，它会使用空闲空间缓存中的大范围空间。如果这些尝试都失败了，文件就会被分割。此外，当文件被删除时，分配的空间不能立即被重用；必须先提交NTFS事务日志条目，之后释放的空间才能被重新分配。总体行为是文件流数据倾向于在文件内连续分配。</p><p>对于修改一个 existing object，fs 和 db 的处理方式不同。fs 会优化 append、truncate 这个文件。inplace file update 是有效率的，但是如果要在中间插入或者删除，那么就需要重写整个文件。但是对于某些 db 而言，在一个 object 里面增删性能会比较高，如果它们和 database page 是 align 的。如果 db 使用 B 树，那么就允许插入或者删除任意大小的数据，并且它们可以在任意位置。</p><p>应用也可以自己做 fragmentation，比如视频流是 chunked 的。</p><h3 id="Safe-writes"><a href="#Safe-writes" class="headerlink" title="Safe writes"></a>Safe writes</h3><p>大部分文件系统都能够保护内部的元数据结构，比如目录或者文件名。比如当出现系统宕机或者电源故障的时候，文件系统的数据不至于破坏。但是对于文件的内容就没有类似的保证。特别地，文件系统和下层的操作系统会将写入乱序，从而提升性能。只有一些请求能够在一个 dirty shutdown 之后被完成。<br>不少桌面应用程序会选择使用一个叫 safe write 的技术，去保证当从一个 dirty shutdown 重启后，文件的内容要么是旧的，要么是新的，不会在某个中间不一致的状态。这种做法需要完全拷贝一份文件到磁盘中，哪怕大部分的内容没有发生变更。<br>safe write 的实现方法具体来说就是会创建一个临时的文件，然后写入新数据，然后 flush to disk，最后将文件重命名为原来的文件名，这样就可以同时删除掉原文件。这是因为 UNIX 系统中的 rename 是能保证原子性的。</p><p>相比之下，数据库提供了事务机制。应用可以安全的以任何方便的方式去更新数据。根据数据库的实现，相比像文件系统一样重新写入整个文件，只重写一部分更有效率。</p><p>下面是对 WAL 这个策略的介绍，不翻译了。</p><blockquote><p>The database guarantees transactional semantics by logging both metadata and data changes throughout a transaction. Once the appropriate log records have been flushed to disk, the associated changes to the database are guaranteed to complete. The log is written sequentially, and subsequent database updates can be reordered to minimize seeks. Log entries for each change must be written; but the actual database writes can be coalesced – only the last write to each page need actually occur.</p></blockquote><p>这样的坏处是要写两次数据。顺序写 WAL 类似于顺序写文件。在日志中写入的大的对象，可能导致日志需要被更频繁地截断，或者构建 checkpoint，这样 reorder 和 combine 这些 page 修改的机会少了很多。</p><h3 id="Data-centric-web-services"><a href="#Data-centric-web-services" class="headerlink" title="Data centric web services"></a>Data centric web services</h3><p>为了在 fs 和 db 之间能够“公平”对比，所以使用了 SQL Server 的 bulk-logging 模式。这个模式下，提供了事务的持久性。但是类似于 fs，它并不保证 large object 对象在一次 dirty shutdown 之后还是 consistent 的。<br>这里的 db 和 fs 实际上对 metadata 都是提供事务性的更新。会写一次 large object，并且只会写一次。不保证 large object data 是 consistent 的。</p><p>通过复制的方式去修复 corrupt 的数据。</p><h2 id="Prior-Work"><a href="#Prior-Work" class="headerlink" title="Prior Work"></a>Prior Work</h2><h3 id="Data-layout-mechanisms"><a href="#Data-layout-mechanisms" class="headerlink" title="Data layout mechanisms"></a>Data layout mechanisms</h3><p>介绍了一些不同的解决 fragmentation 的方案。</p><p>FFS：fragmentation aboiding allocation 算法对于磁盘占用在 90% 以内的是可以的。UNIX 需要保留一定的空间去做 disaster recovery，以及防止 excess fragmentation。</p><p>NTFS：当磁盘占用超过 75%，就会有一个 defragmentation 机制在跑了。后面会介绍他的一些缺点。</p><p>LFS：一个 log based fs。针对写入性能进行优化，将数据按照写入请求的 chronological order 组织写入到磁盘上。这使得写入时是顺序的，但是会产生严重的 fragmentation，如果文件被随机地进行更新。</p><p>WAFL：可以在传统以及写入优化之间进行切换。WAFL also leverages NVRAM caching for efficiency and provides access to snapshots of older versions of the filesystem contents. Rather than a direct copy-on-write of the data, WAFL metadata remaps the file blocks. A defragmentation utility is supported, but is said not to be needed until disk occupancy exceeds 90+%.</p><p>GFS（应该不是 Google FS）：使用称为 chunck 的 64MB 的块，从而部分解决了 layout 的问题。提供了一个安全的 record append 操作，它允许多个 client 同时往一个文件 append 数据。这减少了产生 fragmentation 的可能。<br>下面是说，GFS 的 record 不会跨越 chunk。如果一个 record 在当前 chunk 放不下了，剩余空间就会被填上 0，然后这个 record 会在一个新的 chunk 的头部开始写入。这会产生很多的 internal fragmentation。</p><blockquote><p>GFS records may not span chunks, which can result in internal fragmentation. If the application attempts to append a record that will not fit into the end of the current chunk, that chunk is zero padded, and the new record is allocated at the beginning of a new chunk. Records are constrained to be less than ¼ the chunk size to prevent excessive internal fragmentation. However, GFS does not explicitly attempt to address fragmentation introduced by the underlying file system, or to reduce internal fragmentation after records are allocated.</p></blockquote><h2 id="Comparing-Files-and-BLOBs"><a href="#Comparing-Files-and-BLOBs" class="headerlink" title="Comparing Files and BLOBs"></a>Comparing Files and BLOBs</h2><h3 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h3><p>7200 转的机械硬盘，SATA 口。比较老旧了。<br><img src="/img/dbpaper/blob-not-blob/1.png"></p><h3 id="File-based-storage"><a href="#File-based-storage" class="headerlink" title="File based storage"></a>File based storage</h3><p>For the filesystem based storage tests, we stored metadata such as object names and replica locations in SQL server tables. Each application object was stored in its own file. The files were placed in a single directory on an otherwise empty NTFS volume. SQL was given a dedicated log and data drive, and the NTFS volume was accessed via an SMB share.</p><p>这里还是用数据库的原因是避免实现复杂的 recovery 机制。</p><h3 id="Database-Storage"><a href="#Database-Storage" class="headerlink" title="Database Storage"></a>Database Storage</h3><p>We also used out-of-row storage for the application data so that the blobs did not decluster the metadata. Although the blob data and table information are stored in the same file group, out-of-row storage places blob data on pages that are distinct from the pages that store the other table fields. This allows the table data to be kept in cache even if the blob data does not fit in main memory.</p><h3 id="Storage-age"><a href="#Storage-age" class="headerlink" title="Storage age"></a>Storage age</h3><p>提出这个 storage age 指标，也就是曾经写入的 bytes 比上现在还在用的 bytes。这个定义的假设是 free space 是相对来说固定的。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="out-of-the-box-场景下的吞吐量"><a href="#out-of-the-box-场景下的吞吐量" class="headerlink" title="out-of-the-box 场景下的吞吐量"></a>out-of-the-box 场景下的吞吐量</h3><p>也就是一开始 bulk load 之后的 read throughput。</p><p><img src="/img/dbpaper/blob-not-blob/2.png"></p><p>写入的 throughput，SQL Server 是优于 NTFS 的。对于 512 KB 的对象，数据库是 17.8 MB/s，NTFS 是 10.1 MB/s。</p><h3 id="跑了一段时间的情况"><a href="#跑了一段时间的情况" class="headerlink" title="跑了一段时间的情况"></a>跑了一段时间的情况</h3><p>这个时候要注意 fragmentation 对性能的影响。</p><p>首先，它说 SQL Server 没有发现和缓解 fragmentation 的方案。文章上说，隔段时间，把数据从老表复制出来到新表，然后再把老表 drop 掉可以实现 fragmentation。</p><p>To measure fragmentation, we tagged each of our objects with a unique identifier and a sequence number at 1KB intervals. We also implemented a utility that looks for the locations of these markers on a raw device in a way that was robust to page headers, and other artifacts of the storage system.</p><p>下图中的 overwrites 也就是 storage age。bulk load 对应的 storage age 就是 0。<br><img src="/img/dbpaper/blob-not-blob/3.png"></p><p>下图展示了，对于非常大的，比如 10MB 的对象，SQL Server 的性能很差，它的 fragments/object 基本上是线性的。NTFS 要好很多。The best-effort attempt to allocate contiguous space actually defragments such volumes. That experiment also suggests that NTFS is indeed approaching an asymptote in Figure 3.<br><img src="/img/dbpaper/blob-not-blob/4.png"></p><p>The degradation in write performance is shown in Figure 4. In both systems, the write throughput during bulk load is much better than read throughput immediately afterward. This is not surprising, as the storage systems can simply append each new file to the end of allocated storage, avoiding seeks during bulk load. On the other hand, the read requests are randomized, and must incur the overhead of at least one seek. 在 bulk load 之后，SQL Server 的写入性能急剧下降，NTFS 的写入性能要比读取性能稍微好点。<br><img src="/img/dbpaper/blob-not-blob/5.png"></p><p>注意，不能直接比较 Figure 1 和 2 里面的写性能和读性能。因为读性能是在 fragmentation 之后度量的，写性能则是在 fragmention 这个过程中度量的平均值。</p><p>下面这个应该写错了。</p><blockquote><p>To be clear, the “storage age four”(应该是 two 吧) write performance is the average write throughput between the read measurements labeled “bulk load” and “storage age two.” Similarly, the reported write performance for storage age four reflects average write performance between storage ages two and four.</p></blockquote><h3 id="Fragmentation-effects-of-object-size-volume-capacity-and-write-request-size"><a href="#Fragmentation-effects-of-object-size-volume-capacity-and-write-request-size" class="headerlink" title="Fragmentation effects of object size, volume capacity, and write request size"></a>Fragmentation effects of object size, volume capacity, and write request size</h3><h1 id="Cloud-Programming-Simplified-A-Berkeley-View-on-Serverless-Computing"><a href="#Cloud-Programming-Simplified-A-Berkeley-View-on-Serverless-Computing" class="headerlink" title="Cloud Programming Simplified: A Berkeley View on Serverless Computing"></a>Cloud Programming Simplified: A Berkeley View on Serverless Computing</h1><p><a href="https://arxiv.org/pdf/1902.03383" target="_blank" rel="noopener">https://arxiv.org/pdf/1902.03383</a></p><h2 id="Emergence-of-Serverless-Computing"><a href="#Emergence-of-Serverless-Computing" class="headerlink" title="Emergence of Serverless Computing"></a>Emergence of Serverless Computing</h2><p><img src="/img/dbpaper/serverless/t2.png"></p><p>相比 serverful，serverless 的改变是</p><ol><li>存算分离。存储和计算被分开提供和计费。存储一般是单独的服务，计算一般是无状态的。</li><li>代码执行不需要手动管理资源分配。用户提供代码，cloud 自动提供资源。</li><li>按使用量计费，而不是按照使用资源的规格计费。</li></ol><h3 id="Contextualizing-Serverless-Computing"><a href="#Contextualizing-Serverless-Computing" class="headerlink" title="Contextualizing Serverless Computing"></a>Contextualizing Serverless Computing</h3><p>例如 CGI 这样的机制，已经有了 stateless programming model，在此之上支持了 multi-tenancy、elastic response to variable demand 和 standardized function invocation API。CGI 甚至允许直接部署源码比如 PHP 来运行。<br>作者认为，现在的 serverless 相比 CGI 这样的古早方案，有三个特点：更好的自动扩缩容、强隔离、platform flexibility、service ecosystem support。</p><p>扩缩容：AWS Lambda 能够缩容到零实例实现零费用。它的计费是 100ms 级别的，而不是之前的小时级别。<br>隔离：VM 是实现高性能安全隔离的方式。AWS Lambda 解决了 VM 启动速度比较慢，支持不了快速弹性扩缩容的问题。它维护了两个 pool，warm pool 中包含的 VM 实例只是被分配给了某个 tenant，而 active pool 中的实例已经实际运行过了，并且一直保持着，以便维护后续的服务请求。还有除了 VM 之外的隔离方案，比如容器、unikernel、library OS 和语言虚拟机。比如一些使用了浏览器的 JavaScript 沙箱技术。</p><p>认为 k8s 并不是 serverless，而是简化了 serverful computing 的技术。k8s 能提供一个短生命周期的计算环境，类似于 serverless computing，但是限制更少，例如在硬件资源、执行时间和网络通信。只需要少量改动，就可以通过 k8s 让专门为 op 涉及的程序运行在云上。相比之下，Serverless 将运维的责任完全推给了服务提供商，然后要实现 fine-grained multi-tenant multiplexing。GKE 和 EKS 应该是介于这两个中间的一个东西，它帮用户运维 k8s，但是容器还是用户来自定义的。K8s 服务和 serverless 服务的区别之一是 billing model。前者为 reserved resource 计费，后者为 per function execution duration 计费。</p><p>K8s 还会是一个 hybrid application 的好选择。也就是一个程序一部分是 op 部署的也就是在本地硬件上，另一部分是 cloud 部署的。</p><h3 id="Attractiveness-of-Serverless-Computing"><a href="#Attractiveness-of-Serverless-Computing" class="headerlink" title="Attractiveness of Serverless Computing"></a>Attractiveness of Serverless Computing</h3><p><img src="/img/dbpaper/serverless/t4.png"></p><h2 id="Limitations-of-Today’s-Serverless-Computing-Platforms"><a href="#Limitations-of-Today’s-Serverless-Computing-Platforms" class="headerlink" title="Limitations of Today’s Serverless Computing Platforms"></a>Limitations of Today’s Serverless Computing Platforms</h2><p>本节选择了五个传统的 serverful 的云计算应用，然后尝试只使用 cloud functions 来实现它们的 serverless 版本。</p><ol><li>ExCamera 实时视频编码。把编码过程中比较慢的并行化，比较快的继续串行化。</li><li>MapReduce 目前一些 Map-only 的任务被移动到 serverless 上。</li><li>Numpywren 线代。一般这样的任务是部署在超算或者高性能计算集群上的。这样的集群需要高速低延迟的网络。serverless 从历史上来讲，不太合适。但是一方面，数据科学家维护大集群很麻烦，另一方面，线代的并发又是波动很厉害的。所以这是 serverless 的机会。</li><li>Cirrus：机器学习训练。传统上使用 VM 集群处理 ML 工作流上面的不同任务，比如预处理、模型训练、参数调节。不同的这些任务所需要的资源是完全不同的。serverless 可以给每个阶段提供合适的容量。</li><li>Serverless SQLite：数据库。首先，serverless 计算没有内置的持久化存储，需要访问远程存储，带来网络开销。其次，client 需要通过网络地址连接数据库，而 serverless 的 cloud function 并没有暴露出网络。最后，很多高性能的数据库是 share-everything 的，比如共享磁盘，共享网络等，但 serverless 基本肯定是不能共享内存的。即使是 share-nothing 数据库，它们也是需要通过网络来互相访问的。</li></ol><p><img src="/img/dbpaper/serverless/22.png"></p><h3 id="Inadequete-storage-for-fine-grained-operations"><a href="#Inadequete-storage-for-fine-grained-operations" class="headerlink" title="Inadequete storage for fine-grained operations"></a>Inadequete storage for fine-grained operations</h3><p>这一章节中列出了目前云服务商提供的一些外部存储服务。</p><p>诸如 AWS S3、Azure Blob Storage 和 Google Cloud Store 这样的 long-term OSS 的访问开销以及延迟会比较大。测试中，读写小对象有 10ms 左右的延迟。</p><p>诸如 DynamoDB、Azure Cosmos 这样的 KV 数据库提供了很高的 IOPS，但是很昂贵，并且 scale up 很耗时间。</p><p>有一些 in-memory 数据库，但是它们没有容灾，也不能 autoscale。</p><p><img src="/img/dbpaper/serverless/t6.png"></p><h3 id="Lack-of-fine-grained-coordination"><a href="#Lack-of-fine-grained-coordination" class="headerlink" title="Lack of fine-grained coordination"></a>Lack of fine-grained coordination</h3><p>为了支持有状态服务，serverless 需要支持两个 task 之间的通信协调。特别是一些需要通信来保证一致性的服务。</p><p>云服务商会有一些比如 SNS 或者 SQS 的 notification 服务，但是它们的延迟很高，并且代价很大。现在的选择是要么使用一个 VM-based system 来提供通知，要不就是自己实现一套通知机制。</p><h3 id="Poor-performance-for-standard-communication-patterns"><a href="#Poor-performance-for-standard-communication-patterns" class="headerlink" title="Poor performance for standard communication patterns"></a>Poor performance for standard communication patterns</h3><p>Broadcast、aggregation 和 shuffle 是分布式系统中的通用原语。下图中比较了三种原语在 VM 以及 cloud function 两个场景下的实现。可以发现，VM-based 场景下的 remote 消息是显著少的。因为很多消息可以是本地的，或者通过其他方式进行共享。</p><p>另外，即使发消息，也可以将消息进行打包，这样两个 VM node 之间实际上只要传递一个消息。</p><p><img src="/img/dbpaper/serverless/yy.png"></p><h3 id="Predictable-Performance"><a href="#Predictable-Performance" class="headerlink" title="Predictable Performance"></a>Predictable Performance</h3><p>尽管 cloud function 的启动时间比 VM 短，但是启动新实例的代价，对于某些 app 来说会更高。三个影响 cold start 延迟的因素：</p><ol><li>启动 cloud function 的时间</li><li>启动 function 的软件环境的时间，比如 python 库的加载</li><li>用户代码中的初始化。</li></ol><p>后两者会拖累第一个。比如可能启动一个 cloud function 就不到一秒，但是加载所有的库要花十秒。</p><p>另外，使用的底层硬件对用户来说是透明的，有的时候，用户可能会被分配到更老的处理器上。这是云服务商在做调度的时候的权衡。</p><h2 id="What-Serverless-Computing-Should-Become"><a href="#What-Serverless-Computing-Should-Become" class="headerlink" title="What Serverless Computing Should Become"></a>What Serverless Computing Should Become</h2><h3 id="Abstraction-challenges"><a href="#Abstraction-challenges" class="headerlink" title="Abstraction challenges"></a>Abstraction challenges</h3><h4 id="Resource-requirements"><a href="#Resource-requirements" class="headerlink" title="Resource requirements"></a>Resource requirements</h4><p>目前可以定制的只是内存大小以及执行时间，但是对于 CPU、GPU 这些资源则不能。允许开发者进一步去指定，增加云服务提供商进行调度的难度。也需要开发者去进一步关注这些事情，这是违背 serverless 的精神的。</p><p>更好的做法是提高抽象程度，让云服务提供商去推断。云服务商可以从静态代码分析，profile 过去的 run，动态编译面向特定平台的代码这些方面去做。</p><p>要精确预计需要多少内存也是很有挑战性的工作。一些想法是整合语言运行时到 serverless 平台上，这样可以去访问这些语言的 GC 模块。</p><h4 id="Data-dependencies"><a href="#Data-dependencies" class="headerlink" title="Data dependencies"></a>Data dependencies</h4><p>很难知道各个 cloud function 在数据上的依赖关系。比如谁是谁的前序，谁依赖谁的结果这样。特别还有很多 cloud function 是 exchange 数据的，这让情况更复杂。</p><p>一种做法是供应商提供一个 API，让用户去提供一个计算图，这样就可以有更好的 placement decision，使得通信变少。</p><h3 id="System-challenges"><a href="#System-challenges" class="headerlink" title="System challenges"></a>System challenges</h3><h4 id="High-performance-affordable-transparently-provisioned-storage"><a href="#High-performance-affordable-transparently-provisioned-storage" class="headerlink" title="High-performance, affordable, transparently provisioned storage"></a>High-performance, affordable, transparently provisioned storage</h4><p>Serverless Ephemeral Storage 和 Serverless Durable Storage。</p><p>Serverless Ephemeral Storage 可以被部署在 in-memory 的分布式服务中，同时需要一个优化的网络。这样就是 microsecond 级别的延迟。还需要能够快速扩缩容。它能够透明地分配，以及释放内存。也就是当 app 挂掉或者正常退出时，它能够自动回收它使用的存储空间（当然是 in-memory）的。</p><p>诸如 RAMCloud 和 FaRM 的缺陷是，需要显式地估算要使用的 storage。他们也不提供租户之间的强资源隔离。Pocket 缺少自动扩缩容，需要预先分配空间。</p><p>可以通过 statistical multiplexing 来节省内存，也就是如果有人用不到这么多内存，就可以先挪过去给别人用了，就是超卖。即使对于同一个 app 也还是有好处的，比如说不同的服务，原来可能是部署在不同的 vm 上的，现在可能就是能运行在一个 vm 上了。当然，serverless 也还是存在 internal fragmentation 的。</p><p>Serverless Durable Storage 主要是通过一个 SSD 的分布式 store，以及一个 in-memory 的 cache 实现的。这个设计的难点是如何在有较高的 tail access distribution 的情况下达到比较低的 tail latency，考虑到内存 cache 的容量比 SSD 的容量实际上要小很多。<br>类似于 Ephemeral Storage 它也需要能够被透明而不是显式地预测内存，并且能够提供跨租户和 app 之间的隔离。不同于 Ephemeral Storage，Durable Storage 只允许显式回收存储，也就是 app 被 terminate 的时候，不应该自动回收 storage。</p><h4 id="Coordination-signaling-service"><a href="#Coordination-signaling-service" class="headerlink" title="Coordination/signaling service"></a>Coordination/signaling service</h4><p>一般使用生产者-消费者模型来实现在函数之间分享状态。这就需要当数据被生产出来时，消费者能够尽早知道。同样对生产者也是如此。这样的信号系统，需要满足 microsecond 级别的延迟、可靠的投递、支持广播或者组播。当然，因为 cloud function 并不是有独立的地址的，所以我们难以实现教科书级别的共识，或者选举机制。</p><h4 id="Minimize-startup-time"><a href="#Minimize-startup-time" class="headerlink" title="Minimize startup time"></a>Minimize startup time</h4><p>启动时间包含：</p><ol><li>调度资源</li><li>下载环境，比如 OS、库</li><li>执行每个 app 自己的启动和初始化逻辑</li></ol><p>第一部分在创建隔离环境，以及用户的 VPC 和 IAM 阶段可能有显著的延迟。哦，之前不是说这个很快的么？哦，所以最近有一些办法，比如使用 unikernel。它 preconfigure 系统到硬件上，相当于把监测硬件、分配 os 数据结构等变成静态的了。另一方面，它只包含 app 需要的驱动和系统库。</p><p>另一个解决第二部分的方式，是动态或者增量地加载 app 需要的库。</p><p>云提供商可以提供一个 signal 机制，让一个应用在自己能处理的时候，调用这个信号进行通知，然后接受负载。此外，云提供商还可以基于预测，提前启动。这种方案非常适合去处理那些和具体用户行为不相关的任务，比如启动 OS 或者加载库，这样就得到了一个可以被所有 tenant 共享的 warm pool 了。</p><h3 id="Networking-challenges"><a href="#Networking-challenges" class="headerlink" title="Networking challenges"></a>Networking challenges</h3><p>如前文介绍的，serverless 的 broadcast、agg、shuffle 操作的通信成本都比较大。解法：</p><ol><li>增加 cloud function 的核数，这样就能够合并多个 task 的通信</li><li>允许开发者显式将一些 cloud function 部署到同一个 VM 上。</li><li>让 app 开发者提供一个计算图，让 cloud provider 可以去 colocate 这些 cloud function。这个计算图，可以参考 Abstraction Challenges 的论述。</li></ol><p>前两者有点违背 serverless 精神，并且可能无法有效利用资源。</p><h3 id="Security-challenges"><a href="#Security-challenges" class="headerlink" title="Security challenges"></a>Security challenges</h3><p>暂不关注安全，略</p><h3 id="Computer-architecture-challenges"><a href="#Computer-architecture-challenges" class="headerlink" title="Computer architecture challenges"></a>Computer architecture challenges</h3><h4 id="Hardware-Heterogeneity-Pricing-and-Ease-of-Management"><a href="#Hardware-Heterogeneity-Pricing-and-Ease-of-Management" class="headerlink" title="Hardware Heterogeneity, Pricing, and Ease of Management"></a>Hardware Heterogeneity, Pricing, and Ease of Management</h4><p>现在硬件都要接近瓶颈了：</p><blockquote><p>Alas, the x86 microprocessors that dominate the cloud are barely improving in performance. In 2017, single program performance improvement only 3% [69]. Assuming the trends continue, performance won’t double for 20 years. Similarly, DRAM capacity per chip is approaching its limits; 16 Gbit DRAMs are for sale today, but it appears infeasible to build a 32 Gbit DRAM chip. A silver lining of this slow rate of change is letting providers replace older computers as they wear out with little disruption to the current serverless marketplace.</p></blockquote><p>几个方案：</p><ol><li>像 JS 或者 Python 这样的语言写的 cloud function，hardware-software co-design could lead to language-specific custom processors that run one to three orders of magnitude faster. 我不知道具体指的是啥。</li><li>DSA(Domain Specific Architectures)。比如 GPU 适用于图形，TPU 适用于机器学习。</li></ol><p>因此，serverless 需要支持一些 hardware heterogeneity：</p><ol><li>支持多种实例类型，硬件不一样，价格就不一样</li><li>可以自动选择 language-based 加速器，和 DSA。这可以通过选择不同的库，或者语言来隐式实现。例如对 CUDA 代码使用 GPU，对 Tensorflow 代码使用 TPU。</li></ol><p>对于 x86 的 SIMD 来说，Serverless 计算也面临一些 heterogeneity。但是现在 serverless 用户在 AWS Lambda 上似乎还不能够声明自己想要什么样的 CPU，并且他们的价格也是相同的。</p><h2 id="Fallacies-and-Pitfalls"><a href="#Fallacies-and-Pitfalls" class="headerlink" title="Fallacies and Pitfalls"></a>Fallacies and Pitfalls</h2><p>Fallacies 指的是谬误。一个谬误是觉得 Serverless 更贵。原因是相同内存规格的 AWS cloud function 比 AWS t3.nano 要贵 7.5 倍。</p><p>错误点：</p><ol><li>价格中包含了冗余，监控，日志等一个 t3.nano 节点享受不了的东西。</li><li>扩缩容灵活，如果不调用就不收费。</li></ol><p>Pitfall 指的是陷阱。这里说的是 Serverless 计算可能有未预期的成本。<br>这个是比较合理的担忧。解法是基于桶的定价，或者能够根据历史预测成本。</p><p>另一个 Fallacies 是采用诸如 Python 的高级语言，就很容易在不同的 Serverless 供应商之间移植 app。<br>错误点是不同的 Serverless 供应商之间的 API 不同。没有像 POSIX 一样的标准。</p><p>Pitfall： Serverless 计算的供应商锁定可能比 Serverful 计算更强。</p><p>另一个 Fallacies 是云函数无法处理需要可预测性能的 low-lentency 应用程序。<br>Serverful 能，是因为它一直是在线的。所以 Serverless 也可以做 pre-warm。</p><p>Pitfall：少有所谓的 elastic 服务能满足 serverless 计算的灵活性。</p><p>一大段话，懒得翻译了，大概就是说现在叫 elastic 的实际上还不如 serverless 呢。</p><blockquote><p>The word “elastic” is a popular term today, but it is being applied to services that do not scale nearly as well as the best serverless computing services. We are interested in services which can change their capacity rapidly, with minimal user intervention, and can potentially “scale to zero” when not in use. For example, despite its name, AWS ElastiCache only allows you to instantiate an integral number of Redis instances. Other “elastic” services require explicit capacity provisioning, with some taking many minutes to respond to changes in demand, or scaling over only a limited range. Users lose many of the benefits of serverless computing when they build applications that combine highly-elastic cloud functions with databases, search indexes, or serverful application tiers that have only limited elasticity. Without a quantitative and broadly accepted technical definition or metric—something that could aid in comparing or composing systems—“elastic” will remain an ambiguous descriptor</p></blockquote><h2 id="Summary-and-Predictions"><a href="#Summary-and-Predictions" class="headerlink" title="Summary and Predictions"></a>Summary and Predictions</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;这篇文章中，包含 Column Stores vs Row Stores、To BLOB or Not To BLOB: Large Object Storage in a Database or a Filesystem?、Cloud Programming Simplified: A Berkeley View on Serverless Computing。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://www.calvinneo.com/tags/数据库/"/>
    
    <category term="论文阅读" scheme="http://www.calvinneo.com/tags/论文阅读/"/>
    
  </entry>
  
</feed>
