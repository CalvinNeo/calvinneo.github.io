<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="C++,Linux,网络,并行计算,多线程,atomic,CPU,多进程," />





  <link rel="alternate" href="/atom.xml" title="Calvin's Marbles" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="在本篇中比较了各种并发、并行技术。并发(concurrency) 强调的是逻辑上的同时发生，是语义上的模型(semantic model)，在实际上并发程序可能是由一个处理器同时(simultaneously)处理多个任务，因此并发过程中常出现一个线程等待其他资源的情况。此时常伴随着线程的阻塞和调度。并发过程通常可划分为多个级别：Blocking、Obstruction-Free、Lock-Fre">
<meta name="keywords" content="C++,Linux,网络,并行计算,多线程,atomic,CPU,多进程">
<meta property="og:type" content="article">
<meta property="og:title" content="并发编程重要概念及比较">
<meta property="og:url" content="http://www.calvinneo.com/2017/12/28/Concurrency-Programming-Compare/index.html">
<meta property="og:site_name" content="Calvin&#39;s Marbles">
<meta property="og:description" content="在本篇中比较了各种并发、并行技术。并发(concurrency) 强调的是逻辑上的同时发生，是语义上的模型(semantic model)，在实际上并发程序可能是由一个处理器同时(simultaneously)处理多个任务，因此并发过程中常出现一个线程等待其他资源的情况。此时常伴随着线程的阻塞和调度。并发过程通常可划分为多个级别：Blocking、Obstruction-Free、Lock-Fre">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/lsx_ttl_ys.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/bubble.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/forward.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/forward2.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/forward3.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/cur_cpu_rob.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/mem_mout.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/mem_mout_sli_stride.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/mem_mout_sli_size.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/mat_mul_ana.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/mat_mul_perm.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/6.25.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/hchang.jpg">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/6.34.jpg">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/mesi.jpg">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/speed_cmp.jpg">
<meta property="og:image" content="http://www.calvinneo.com/img/bfbc/no-sync-with.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/acquire_atomic.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/acquire_fence.png">
<meta property="og:image" content="http://www.calvinneo.com/img/bfbc/dclpjj.png">
<meta property="og:image" content="http://www.calvinneo.com/img.concur/chenshuo2.png">
<meta property="og:updated_time" content="2023-06-28T17:23:05.672Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="并发编程重要概念及比较">
<meta name="twitter:description" content="在本篇中比较了各种并发、并行技术。并发(concurrency) 强调的是逻辑上的同时发生，是语义上的模型(semantic model)，在实际上并发程序可能是由一个处理器同时(simultaneously)处理多个任务，因此并发过程中常出现一个线程等待其他资源的情况。此时常伴随着线程的阻塞和调度。并发过程通常可划分为多个级别：Blocking、Obstruction-Free、Lock-Fre">
<meta name="twitter:image" content="http://www.calvinneo.com/img/concur/lsx_ttl_ys.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.calvinneo.com/2017/12/28/Concurrency-Programming-Compare/"/>





  <title>并发编程重要概念及比较 | Calvin's Marbles</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Calvin's Marbles</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.calvinneo.com/2017/12/28/Concurrency-Programming-Compare/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Calvin Neo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Calvin's Marbles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                并发编程重要概念及比较
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-28T20:34:20+08:00">
                2017-12-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>在本篇中比较了各种并发、并行技术。<br><strong>并发(concurrency)</strong> 强调的是逻辑上的同时发生，是语义上的模型(semantic model)，在实际上并发程序可能是由一个处理器同时(simultaneously)处理多个任务，因此并发过程中常出现一个线程等待其他资源的情况。此时常伴随着线程的阻塞和调度。并发过程通常可划分为<a href="http://ifeve.com/lock-free-and-wait-free/" target="_blank" rel="noopener">多个级别</a>：Blocking、Obstruction-Free、Lock-Free、Wait-Free，其中后三种统称为Non-blocking的。<br><strong>并行(parallelism)</strong> 属于并发，是运行期的行为(runtime behavior)，并行强调这两个并发事件实际上也是同时发生的，例如在多个处理器上运行的多个任务。但我们不能讲这两个概念绝对化，例如在处理器层面，流水线绝对是并发的，但在操作系统之上提供的机制来说，却体现出顺序的特性。<br>【未完待续】</p>
<a id="more"></a>

<h1 id="处理器层面的并发"><a href="#处理器层面的并发" class="headerlink" title="处理器层面的并发"></a>处理器层面的并发</h1><p>处理器在硬件架构上可以被分为对称多处理器(Symmetric Multiprocessing, SMP)、非均匀访问存储模型(Non-Uniform Memory Access, NUMA)、Massive Parallel Processing(MPP)等。其中SMP被广泛用于PC中，架构简单，但扩展性较差。<br>这里简单地论述处理器层面的并发相关，例如流水线、分支预测、多级缓存等技术。</p>
<h2 id="流水线-pipeline"><a href="#流水线-pipeline" class="headerlink" title="流水线(pipeline)"></a>流水线(pipeline)</h2><h3 id="流水线和吞吐量"><a href="#流水线和吞吐量" class="headerlink" title="流水线和吞吐量"></a>流水线和吞吐量</h3><p>我们通常使用GOPS（每秒千兆次操作）来定义吞吐量，表示每秒内执行操作的次数。CPU流水线的目的是为了提高吞吐量(throughput)，但会增加每条指令的延迟(latency)，这是因为执行一条指令需要经过更多的流水线寄存器。CSAPP使用一个称为SEQ的架构来描述流水线的通用模型，一条指令在CPU中被执行会经过取指(fetch)、译码(decode)、执行(execute)、访存(memory)、写回(write back)、更新PC（在SEQ+中和取指进行了合并）等阶段。<br><strong>取指</strong>从PC处取得指令。指令包含icode和ifun。还包含译码阶段需要读取的寄存器rA和rB（可选的），一个常数valC。<br><strong>译码</strong>指的是从寄存器读取。读到的数令为valA和valB。<br><strong>访存</strong>指的是<strong>读写内存</strong>。如果读内存，读到的值令为valM。<br><strong>写回</strong>指的是写回到<strong>寄存器</strong>。<br>特别注意，处理器可以读写寄存器和内存，读写寄存器和读写内存是不同的阶段。<br>容易想到在某一时钟周期内，每一个阶段都可以独立运行。例如当指令PC在执行阶段时，我们可以对指令PC+1进行译码，这样译码器就不会闲置，这就是流水线化的一个简单思路。这种流水线设计很常见，以486为例，其拥有两条5级流水线<code>取指F-&gt;译码D1-&gt;转址D2-&gt;执行EX-&gt;写回WB</code>。<br>出于两点的考虑，流水线技术会制约了吞吐量能提高的上限：</p>
<ol>
<li>流水线不同阶段的延迟是不同<br> 如下图所示，流水线的吞吐量会受到其中最长操作的局限。<br> <img src="/img/concur/lsx_ttl_ys.png"></li>
<li>一个较深的流水线可能带来很大的流水线寄存器延迟<br> 这是来自于增加的流水线寄存器所带来的额外开销。</li>
</ol>
<h3 id="流水线和冒险"><a href="#流水线和冒险" class="headerlink" title="流水线和冒险"></a>流水线和冒险</h3><p>控制相关和顺序（数据）相关是使用流水线并发执行一些指令需要面临的问题。其中顺序相关指后一条指令的执行依赖于前一条指令的值，控制相关指的是指令流的路径依赖于前一条指令（通常是条件测试）的结果。为了解决这样的问题，CSAPP首先升级了原先的SEQ到SEQ+，现在我们将更新PC移到最前面，并且和取指进行了合并，这样做的目的是使得我们在程序开始时通过上面一条指令结束时的状态来确定地址。CSAPP基于SEQ+引入了PIPE-这个流水线，并希望PIPE-能够实现每个时钟周期发射(issue)一条指令，因此我们需要在取出一条指令后马上确定下一条指令的位置。这对于ret和条件转移来说是较为麻烦的，因为我们要进行<strong>分支预测</strong>。</p>
<p>分支预测有一些策略，包括总是选择(分支)，从不选择(NT)。一种正向不选择(BTFNT)策略只接受跳往地址更低的分支（也就是往前跳，后向分支），因为它可能标志着一个循环的右大括号。现在的分支预测器通常分为静态规则和动态规则的，动态规则会基于一些运行期的历史进行类似“强化学习”，例如如果一段分支历史上不进行跳转的成功率大，那么就这一次预测的时候就不进行跳转，<a href="https://zhuanlan.zhihu.com/p/36795318" target="_blank" rel="noopener">知乎专栏</a>上给出了一个详细的例子来验证这个特性，这个实验中验证了对一个有序数组遍历时其耗时约为无序数组的1/3。</p>
<p>分支预测失败，也就是所谓的<strong>控制冒险(control hazard)<strong>，它的代价是就会导致流水线刷新(flush)。此外当一条指令</strong>写</strong>后面指令会<strong>读</strong>到的那些程序状态时就会带来<strong>数据冒险(data hazard)<strong>，特别地我们可以发现控制冒险可以看做是</strong>对程序计数器PC而言的数据冒险</strong>。考虑整个流水线中可能出现的部件，其中通用寄存器和PC已经被证明是存在冒险的，以通用寄存器为例，其写和读发生在流水线上<strong>不同的阶段</strong>（写回和解码）。剩下来的是EFLAGS以及存储器则是不存在冒险的，以存储器为例，其读写<strong>都</strong>发生在流水线的<strong>访存阶段</strong>，那么前一条指令对存储器的<strong>写</strong>对后一条指令对存储器的<strong>读</strong>总是可见的。<br>CPU流水线中通过暂停(stalling)和转发(forward)/旁路(bypassing)的机制<strong>解决数据冒险</strong>的问题。此外在汇编层面，我们可以使用条件传送而不是条件控制转移来避免分支预测出错的问题。</p>
<h4 id="冒险导致错误的展示"><a href="#冒险导致错误的展示" class="headerlink" title="冒险导致错误的展示"></a>冒险导致错误的展示</h4><h4 id="暂停"><a href="#暂停" class="headerlink" title="暂停"></a>暂停</h4><p>暂停的思路很简单，就是阻塞流水线中的一些指令直到冒险条件不满足。对通用寄存器而言，在解码阶段时流水线会检查前方执行、访存和写回阶段中是否有指令会更新该通用寄存器。如果存在那么就会阻塞处于解码阶段的指令(包括后面即将执行的下一条指令的取指阶段，也就是保持PC的值)。在阻塞时，流水线的一部分会进入空转状态，此时我们成为插入一个气泡(bubble)。如下图所示，在时刻5，原本应该执行的<code>0x00d</code>处的D被阻塞了，因为<code>0x006</code>处的W尚未完成。因此在等待其完成的时间中插入了三个气泡（分别对应EMW阶段）。<br><img src="/img/concur/bubble.png"></p>
<h4 id="转发"><a href="#转发" class="headerlink" title="转发"></a>转发</h4><p>上面的暂停机制非常直白和简单，但考虑到前后连续两条指令对同一个寄存器先写后读是很通常的情况，此时三个气泡是很划不来的。此时可以借助转发来避免暂停。转发机制指将结果从流水线的较晚阶段发送到流水线的较早阶段的过程，通常是从写回阶段W转发到译码D阶段作为操作数之一。<br>【写回–译码】我们查看下面的图，在第6周期上，<code>0x00e</code>的解码逻辑发现<code>0x006</code>上所在的写回阶段有对<code>%eax</code>的写，而自己恰恰要访问这个寄存器，所以与其这样不如直接拿过来用了。这样相当于只插入了两个气泡。<br><img src="/img/concur/forward.png"><br>【访存–译码】更厉害的是我们甚至可以在访存阶段就转发到解码阶段。查看下面的图，在第5周期上位于解码阶段的<code>0x00d</code>发现<code>0x006</code>和<code>0x000</code>分别处于访存和写回阶段，这里写回阶段如上所示，而访存阶段我们发现我们正在读入数据到<code>%eax</code>。因此我们可以直接将这个对<code>%eax</code>的写也转发过去。现在我们相当于只插入了一个气泡。<br><img src="/img/concur/forward2.png"><br>【执行–译码】能不能一个都不插入呢？也是可以的，我们从执行阶段就转发到解码阶段。我们查看下面的图，在第4周期上位于解码阶段的<code>0x00c</code>发现<code>0x006</code>和<code>0x000</code>分别处于执行和访存阶段，这里访存阶段如上所示，而在执行阶段我们发现我们正在计算一个立即数，这个立即数将在稍后写入<code>%eax</code>。<br><img src="/img/concur/forward3.png"><br>问题来了，有没有【访存–译码】呢？我们往下看。</p>
<h3 id="加载互锁"><a href="#加载互锁" class="headerlink" title="加载互锁"></a>加载互锁</h3><p>转发能够解决相当多的数据冒险，但有一类加载/使用冒险(load/use hazard)难以被解决，这是因为加载(从存储器读)存在于访存阶段，而如果下一条指令就要使用的话，那么就会“赶不上趟”。如下所示，mrmovl 试图从内存中读出 %eax，而 0x01e 就要将 %eax 的值作为源操作数了。因为 mrmovl 需要在访存阶段才能读完，而 addl 需要在译码阶段就要读出寄存器的值了，显然来不及。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0x018: mrmovl 0(%edx),%eax</span><br><span class="line">0x01e: addl %ebx,%eax</span><br></pre></td></tr></table></figure>

<p>对于这种情况，我们可以在两个命令之间插入一个气泡。</p>
<h2 id="现代处理器"><a href="#现代处理器" class="headerlink" title="现代处理器"></a>现代处理器</h2><p>在现代的处理器中，流水线被拆分地更加细，出现了所谓的12级、31级乃至更深的流水线。但是这么深的流水线阻塞的代价是非常巨大的。为此Intel使用了乱序执行组件(Out-of-Order core)。<br><img src="/img/concur/cur_cpu_rob.png"></p>
<h3 id="流水线机制对程序优化的启示"><a href="#流水线机制对程序优化的启示" class="headerlink" title="流水线机制对程序优化的启示"></a>流水线机制对程序优化的启示</h3><p>流水线机制对我们程序性能优化的启示主要有下面几点：</p>
<ol>
<li>减少连续指令的相关性<br> 这一点是针对数据冒险而言的。</li>
<li>进行循环展开<br> 这一点是针对控制冒险而言的。循环处必然出现分支，这就带来了可能的分支预测失败的成本。通过展开循环能够减少这样的跳转次数。</li>
<li>减少过程调用</li>
<li>取出不必要的存储器引用</li>
</ol>
<h3 id="combine-函数的初步优化"><a href="#combine-函数的初步优化" class="headerlink" title="combine 函数的初步优化"></a>combine 函数的初步优化</h3><ol>
<li>combine2<br> 在循环结束条件中去掉 strlen 函数</li>
<li>combine3<br> 去掉每次的边界检查。但收益一般，原因是分支预测机制。</li>
<li>combine4<br> 引入一个临时变量acc来记录</li>
</ol>
<h3 id="依赖于目标机器微体系结构的优化"><a href="#依赖于目标机器微体系结构的优化" class="headerlink" title="依赖于目标机器微体系结构的优化"></a>依赖于目标机器微体系结构的优化</h3><p>下面是依赖于目标机器微体系结构的优化。相比于我们刚提到的 in-order 流水线，诸如 Core i7 架构下支持在一个时钟周期内乱序执行多个操作，即所谓的超标量(superscalar)。i7的体系结构分为两个单元，指令控制单元ICU和执行单元EU。</p>
<p>ICU负责取指，这个取指操作往往很超前，这样ICU才有足够时间进行译码，并发送给EU执行。</p>
<h2 id="CPU的缓存和缓存一致性"><a href="#CPU的缓存和缓存一致性" class="headerlink" title="CPU的缓存和缓存一致性"></a>CPU的缓存和缓存一致性</h2><p>现代CPU中寄存器与内存之间没有直接的渠道，而必须通过多级的高速缓存才能到内存。高速缓存的作用依然是为了弥补CPU和内存在速度上的差异，高速缓存提高效率的原理是基于**时间局部性(Temporal Locality)和空间局部性(Spatial Locality)**，将在稍后讨论。高速缓存基于静态RAM(SRAM)技术，区别于主存的动态RAM(DRAM)技术。</p>
<p>虽然高速缓存对用户来说是透明的，汇编要不直接操作寄存器，要不直接操作内存，但它并不是不存在。从实现角度来看内存和对应CPU缓存的同步是个问题，但这问题在一定程度上对用户是透明的，比如我们不要担心“一个核心写另一个核心脏读”之类的情况，缓存一致性协议能够解决内存和多核CPU缓存之间以及缓存与缓存之间的同步的正确性问题。</p>
<p>我们仍然要关注缓存这个概念，以写出高质量的程序。</p>
<h3 id="x86的缓存架构简介"><a href="#x86的缓存架构简介" class="headerlink" title="x86的缓存架构简介"></a>x86的缓存架构简介</h3><h3 id="局部性原理"><a href="#局部性原理" class="headerlink" title="局部性原理"></a>局部性原理</h3><ol>
<li>时间局部性<br> 如果被访问过的存储器地址在较短时间内被再次访问，则程序具有良好的时间局部性。在一定的时间内，重复访问同一个地址的次数越多，时间局部性越好。换句话说，对同一个地址的两次访问间隔时间越短，时间局部性越好。</li>
<li>空间局部性<br> 如果程序访问某个存储器地址后，又在较短时间内访问临近的存储器地址，则程序具有良好的空间局部性。两次访问的地址越接近，空间局部性越好。</li>
</ol>
<p>以控制时间局部性的变量为x轴，控制空间局部性的变量为y轴，存储器访问速率为z轴，就能得到一个三维图形，它看起来像一座有着山峰，山脊和山坡的小山，即存储器山。我们可以构造下面这个循环来生成存储器山图：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Kernel_loop(elems, stride):</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; elems; i += stride)</span><br><span class="line">    result = data[i];</span><br></pre></td></tr></table></figure>

<p>参数stride表示访问时的步长，即相邻两次访问的元素的地址间隔，是<strong>空间局部性</strong>的控制。<br>参数elems表示data数组的尺寸，是<strong>时间局部性</strong>的控制。解释一下，这是因为当stride固定时，elems越小，也就是我们的数组长度越小，遍历一次的时间就更快，从而对相同地址的两次访问间隔(预热和真正访问)就越短。</p>
<p><strong>一般来说stride越小，空间局部性越好；size越小，时间局部性越好</strong>。<br>空间局部性在对二维数组的访问上会更加明显，例如对于行存储的模型，如果以列为单位遍历，那么就会破坏空间局部性。</p>
<h4 id="展示存储器山"><a href="#展示存储器山" class="headerlink" title="展示存储器山"></a>展示存储器山</h4><p>这里我们将 elems 也称为图里的 size。<br>下图展示了 i7 的存储器山。它具有32kb 的 L1 缓存，256KB 的 L2 缓存和 8MB 的 L3 缓存。<br>从 size 看出：</p>
<ol>
<li>由于 CPU 通常有多级缓存，所以一般存储器山会沿着 size 分为若干个台阶，分别对应使用内存、L3、L2、L1 缓存的情况。</li>
</ol>
<p>从 stride 看出：</p>
<ol>
<li>主存山脊的最高点是最低点的7倍还多。这意味着即使在时间局部性很差的情况下，当 stride 变大，性能会急速变差。这说明空间局部性是非常重要的。</li>
</ol>
<p>联合看出：</p>
<ol>
<li>当 size 小于 32k 之后，在 stride 很大时，山脊会明显往下折。这是因为循环只需要执行一次就结束，所以大部分时间都被用在处理迭代之间的事务了。</li>
<li>当步长为1和2时，山脊线平行于 size 轴。也就是说，无论 size 有多大，吞吐量始终是4.5GB。这是因为 i7 的 prefetching 机制。也就是说它能够在块被访问前，就将对应的数据从内存取到高速缓存中。所以即使 size 太大放不下，通过这个机制仍然可以“提前把高速缓存换好”。</li>
</ol>
<p><img src="/img/concur/mem_mout.png"></p>
<p>stride 为 16 时的切面。<br><img src="/img/concur/mem_mout_sli_stride.png"></p>
<p>size 为 4 时的切面。右边完全水平是因为每次读取都不会命中L2，需要从L3重新读取。<br><img src="/img/concur/mem_mout_sli_size.png"></p>
<h4 id="计算存储器山"><a href="#计算存储器山" class="headerlink" title="计算存储器山"></a>计算存储器山</h4><p><a href="https://github.com/fabiensanglard/CpuCacheMountainViewer" target="_blank" rel="noopener">在GitHub</a>上可以找到类似的程序。</p>
<h4 id="Demo：向量求和"><a href="#Demo：向量求和" class="headerlink" title="Demo：向量求和"></a>Demo：向量求和</h4><p>时间局部性：被引用过一次的存储器位置很可能在不远的将来再次被引用<br>空间局部性：存储器中的某一个地址被引用过，那么它附近的地址很可能也会被使用</p>
<p>考虑对一个向量求和</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> s = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">    s += v[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> s;</span><br></pre></td></tr></table></figure>

<ol>
<li>对于标量<code>s</code><br> 它并没有空间局部性一说，但是它在每次循环中都被访问，因此具有较好的时间局部性。</li>
<li>对于向量<code>v</code>是被<strong>逐一</strong>访问的，即具有步长为1的引用模式，因此空间局部性很好，不过用一次就不用了，所以时间局部性不好。<br> 这个在我CFortranTranslator工程的设计上曾有所考虑。</li>
</ol>
<h3 id="Demo：矩阵相乘"><a href="#Demo：矩阵相乘" class="headerlink" title="Demo：矩阵相乘"></a>Demo：矩阵相乘</h3><p>考虑矩阵C=AB，其计算方法为$C_{ij}=A{ik}*B{kj}$。但有6种方法来组织这三层的循环(说到这个<a href="/2020/01/15/linear-alg/">推荐一下MIT18.06的线代课</a>)。因为考虑局部性是看最内层循环的操作，所以我们<strong>根据最内层操作的元素</strong>分为三类：</p>
<ol>
<li>ijk/jik(AB类)<br> 直接算出Cij的最终结果。</li>
<li>jki/kji(AC类)<br> 相当于左边矩阵的每一列Ai，乘上右边矩阵对应的行r，得到n个矩阵再加起来。<br> 这里看最内层循环扫过的坐标就能分辨出来是哪种。</li>
<li>kij/ikj(BC类)<br> 相当于右边矩阵的每一行Bj，乘上左边矩阵的每一列r，得到n个矩阵再加起来。</li>
</ol>
<p>假设程序在下面的环境上运行：</p>
<ol>
<li>每个元素sizeof(double) = 8个字节</li>
<li>只有一个块大小(B)为32字节的缓存，能存4个double</li>
<li>n很大，无法装到L1</li>
<li>局部变量放寄存器</li>
<li>数组以C-style存储</li>
</ol>
<p>可以得到下面的分析。对于AB，内循环对A的扫描的步长是1，因为高速缓存一次只能存4个double，所以内循环每迭代4次就要加载一次，我们计算 miss 次数是0.25。同理，内循环对 B 的扫描步长是n，因为n很大，所以可以认为每次都不命中。特别地，对于BC和AC类，因为有<code>C[i][j] += </code>这样的操作，所以内循环中除了两次加载之外，还需要一次存储。<br><img src="/img/concur/mat_mul_ana.png"></p>
<p>下图是实验结果，y轴表示每次内循环迭代需要的 cpu 周期，曲线越往下说明越快，即BC类最快。可以看出：</p>
<ol>
<li>当 n 很大时，运行速度和外循环的关系并不大。运行速度慢的版本具有更高的 miss 率。</li>
<li>类BC比类AB在内循环中会多引用一次内存，但因为它的 miss 率更低，所以性能更好。</li>
<li>当 n 主键增大时，类BC的性能并没有受到什么影响。这说明我们的存储硬件能对步长为1的访问模式进行很有效的优化。</li>
</ol>
<p><img src="/img/concur/mat_mul_perm.png"></p>
<p>【Q】三个类最右边的平台有什么特别的意义么？</p>
<h4 id="缓存抖动-thrash"><a href="#缓存抖动-thrash" class="headerlink" title="缓存抖动(thrash)"></a>缓存抖动(thrash)</h4><p>下面的代码局部空间性看上去很好，但如果x和y都被映射到一个高速缓存组中，就会造成**缓存抖动(thrash)**。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">8</span>; i++)&#123;</span><br><span class="line">    s += x[i] * y[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在后面的“伪共享”章节会详细探讨这种情况。</p>
<h3 id="缓存不命中-cache-miss"><a href="#缓存不命中-cache-miss" class="headerlink" title="缓存不命中(cache miss)"></a>缓存不命中(cache miss)</h3><p>往下深究局部性原理，自然想到缓存不命中的问题。我们肯定是希望能在当前缓存找到需要的对象，这样最快。但缓存的容量总是有限的：当缓存不能命中时，我们就需要从下一级缓存中找。</p>
<p>缓存不命中的几个case</p>
<ol>
<li>冷不命中/强制不命中<br> 当系统开始运行时缓存是空的，如果缓存是空的，那命中个啥</li>
<li><strong>冲突不命中(conflict miss)</strong><br> 例如我们<code>mod 4</code>一下到四个桶里面。那么假如从<code>k+1</code>层交替访问0号和8号块，缓存会一直不命中，即使其他的块还是空的。</li>
<li><strong>容量不命中(capacity miss)</strong><br> 有的时候缓存就是太小了。</li>
</ol>
<h3 id="高速缓存的架构"><a href="#高速缓存的架构" class="headerlink" title="高速缓存的架构"></a>高速缓存的架构</h3><p>下面考虑如何从缓存中找呢？总不能说也有个现成的哈希表甚至红黑树来维护吧？实际上，我们是快速根据地址来定位和映射Cache。</p>
<p>高速缓存一般分为cache set/cache line/block的三层结构。假如地址长度为 <code>m</code>，即总共有 <code>M=2^m</code> 个地址。将地址 <code>m</code> 分为三段，即组索引位 <code>s</code>、行标记位 <code>t</code> 和偏移位 <code>b</code>，分别用于在cache set/cache line/block的三层结构上进行索引。</p>
<p>这会产生几个问题：</p>
<ol>
<li>s、b、t大小如何指定？<br> 高速缓存具有 $S=2^s$ 个 cache set，E 个 cache line，每个 cache line 包含 $B=2^b$ 字节的数据。因此一个高速缓存可以用 <code>(S,E,B,m)</code> 来描述。整个高速缓存的大小是 <code>S*E*B</code> 个字节。<br> 这里的 cache line 是最特殊的，**需要注意 E 不等于$ 2^t $**，不然这缓存直接当主存用了。<br> s 和 b 的大小取决于要有多少个 S 和 B，然后 <code>t</code> 是由 <code>s</code> 和 <code>b</code> 决定的。假设地址长度为 <code>m</code>，块偏移位数为 <code>b</code>，剩下的 <code>t = m - s - b</code>个 bit 就是标记位。</li>
<li>s、b、t位置如何指定？<br> 一般在地址的<strong>中间</strong>部分抽出 <code>s</code> 个位<strong>作为组索引位</strong>。这是为了利用空间局部性，如果使用高位做索引，那么<strong>连续的块因为空间局部性好</strong>，就会被<strong>映射到一个cache set里面</strong>，会导致<strong>缓存频繁刷新</strong>。<br> 那么 t 就被安排在了高位，b 则在低位。这样相邻的块会被映射到不同的 cache set 上。</li>
<li>为什么要分成三个层？<br> 由于一般高速缓存的容量要小，所以缓存在设计的时候会分成几个桶，每个桶对应一个 cache set。</li>
</ol>
<p>每个 cache line 的构成是：</p>
<ol>
<li>有效位<br> 表示这个 cache line 是不是有效的</li>
<li>标记位<br> 长度为 t，用来和地址里面的那 t 位进行比较</li>
<li>数据块<br> 包含 B 个字节</li>
</ol>
<p><img src="/img/concur/6.25.png"></p>
<p>根据指定的E不同，高速缓存分为了直接映射高速缓存、组相联高速缓存和全相联高速缓存。在后面会详细介绍。</p>
<h4 id="通用架构"><a href="#通用架构" class="headerlink" title="通用架构"></a>通用架构</h4><p>如下图所示，在高速缓存中查找时，在 m 中提出s、t、b，并哈希的方式逐层查找：</p>
<ol>
<li>第一步用 s 做<strong>组选择</strong>，找到对应的 cache set</li>
<li>第二步用 t 做行匹配，找到对应的<strong>有效位被设置了的</strong> cache line。<br> 这是因为缓存可能会失效，这个对于只有一行的直接映射缓存来说的 trivial 的。<br> 一旦找到匹配的 <code>t</code>，就可以认为这个地址在缓存行中。<br> 由于 <code>s</code> 占了中间位，所以 <code>t</code> 实际上就占了高位。</li>
<li>第三步用 b 来做字选择，也就是在 cache line 中根据偏移位 <code>b</code> 找到具体的字。</li>
</ol>
<h4 id="直接映射高速缓存"><a href="#直接映射高速缓存" class="headerlink" title="直接映射高速缓存"></a>直接映射高速缓存</h4><p>直接映射(direct-mapped)高速缓存的 E 为 1。如下图所示，每个组中只有一行。</p>
<p>缓存根据是否命中会选择直接返回或者向下层请求对应块。</p>
<p><img src="/img/concur/hchang.jpg"></p>
<h4 id="组相联高速缓存"><a href="#组相联高速缓存" class="headerlink" title="组相联高速缓存"></a>组相联高速缓存</h4><p>直接映射高速缓存中每个组只有一行，也就是 E = 1。这是其冲突不命中造成问题的原因。组相联高速缓存放松了限制，允许一个组中有多个缓存行。</p>
<p><img src="/img/concur/6.34.jpg"></p>
<h4 id="全相联高速缓存"><a href="#全相联高速缓存" class="headerlink" title="全相联高速缓存"></a>全相联高速缓存</h4><p>这种模式下，只有一个组，也就是 <code>E=C/B</code>。</p>
<h3 id="缓存污染"><a href="#缓存污染" class="headerlink" title="缓存污染"></a>缓存污染</h3><p>对于异常控制流，例如中断和上下文切换，缓存工作会受影响。此时主程序的缓存和中断处理的程序缓存会相互影响导致互相变cold。这种情况下当中断返回或者上下文切换回来时缓存需要较长时间来warm up，这种情况称为缓存污染(cache pollution)。</p>
<h3 id="常见的缓存替换算法"><a href="#常见的缓存替换算法" class="headerlink" title="常见的缓存替换算法"></a>常见的缓存替换算法</h3><p>在组相联高速缓存中，每个组中存在多个缓存行。如果当前的缓存满了的话，就需要去确定一个最合适的牺牲块(victim block)进行替换，常见的有LRU和LFU算法。LFU替换过去引用次数最少的行，LRU替换最后一次访问时间最久远的一行。</p>
<p>LFU：</p>
<ol>
<li>需要额外的一些计算</li>
<li>当数据访问模式改变后LFU需要较长的时间重新进行适应（统计频率）</li>
</ol>
<p>LRU：</p>
<ol>
<li>LRU的问题是当出现<strong>偶发性的批量操作时容易将Hot块（访问频率高的块）移出缓存</strong>，造成缓存污染</li>
</ol>
<p>因此引入LRU-K算法，这个算法比较距当前第K次的访问时间和当前时间的距离来移出缓存。</p>
<p>一般来讲，LFU可以通过优先队列或者双层链表来实现。</p>
<h3 id="缓存一致性协议"><a href="#缓存一致性协议" class="headerlink" title="缓存一致性协议"></a>缓存一致性协议</h3><p>一致性协议，肯定是用来协调多个对象的，缓存一致性协议协调的对象是CPU的多个核心。MESI是实现缓存一致性的一个基础协议，MESI分别表示缓存行可能处于的四个状态Modified、Exclusive、Shared、Invalid，除此之外，Intel使用了扩展的MESIF，增加了状态Forward，而AMD使用了MOESI，增加了状态Owned。CPU的各个核心通过ringbus连接起来，每个核心维护自己的一致性。</p>
<p>MESI协议需要正确处理local read(LR)、local write(LW)、remote read(RR)、remote write(RW)四个场景，其中local表示本core对本地缓存读写，而remote则表示非本地core对非本地缓存的读写。</p>
<ol>
<li>一个缓存行Cache0初始状态为I，因为它并不缓存任何数据</li>
<li>当本地core向该缓存行请求时，CPU会向其他缓存行询问：<ol>
<li>如果存在缓存行Cache1拥有该缓存，则将对应缓存行设为S状态，表示目前有多个缓存行缓存有该数据，并且缓存行中数据和内存中一样。</li>
<li>否则从内存中加载到Cache0，并设为E状态，表示目前只有一个缓存行缓存有该数据。</li>
</ol>
</li>
<li>当本地处理器写入时，缓存行状态变为M，此时缓存与主存之间的数据不一致，CPU通知所有对应的其他的缓存行失效。这时候相当于该core独有这个缓存行，而其他core缓存行的状态变为I。</li>
</ol>
<p>这个模型有点像读写锁的模式，读是Shared，写会作废所有的缓存行。下图描述了四种读写下的状态变化。容易理解的是所有的RW都会导致I，所有的RR都会导致S，所有的LW都会导致M，下面考虑LR。对于状态E，由于是独占的，所以怎么读都是E，因此是自环。同理状态M也是独占的。对于S状态，虽然不是独占，但缓存行中数据和主存一致，因而是有效的，所以也是自环。下面对于I状态，缓存行失效意味着有其他core的写导致了缓存行的刷新，所以进行LR之后实际上就和这些core进行了数据的同步，也就是回到了S状态。<br><img src="/img/concur/mesi.jpg"></p>
<h4 id="当多个核心同时读写一个内存地址时，如何保证其正确性？"><a href="#当多个核心同时读写一个内存地址时，如何保证其正确性？" class="headerlink" title="当多个核心同时读写一个内存地址时，如何保证其正确性？"></a>当多个核心同时读写一个内存地址时，如何保证其正确性？</h4><p>通过缓存一致性协议可以保证。简单来说，就是大家都可以读写，但违反缓存一致性的结果会被扔掉。</p>
<h3 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h3><p>伪共享(False Sharing)是在MESI模型下多个线程对同一缓存行竞争写所导致的性能降低。考虑<a href="https://blog.csdn.net/qq_27680317/article/details/78486220" target="_blank" rel="noopener">这篇博文中的一个场景</a>一个数组<code>int32_t arr[]</code>被同时加载到CPU0和CPU1的L1缓存Cache0和Cache1上。现在两个线程A和B试图分别修改<code>arr[0]</code>和<code>arr[1]</code>。这种情况下是不存在race condition的，但是可能导致伪共享。我们考虑初始情况下Cache0和Cache1都处于S状态，现在CPU0收到线程A的请求，写<code>arr[0]</code>，Cache0状态变为M，而Cache1收到通知后也作废了自己的缓存行。接下来CPU1发起了写操作，根据MESI模型，CPU0会先将<code>arr[0]</code>写回内存，此时Cache0变为I，之后CPU1才能从内存重新读取，Cache1变成E，然后CPU1才能修改<code>arr[1]</code>。<br>为了解决伪共享存在的问题，我们通常的做法是尽量避免将需要访问的数据放到同一个缓存行中，而这就是在一些指令中需要内存对齐的原因，当然还有的原因是原子操作上的考虑。</p>
<h3 id="测试缓存大小"><a href="#测试缓存大小" class="headerlink" title="测试缓存大小"></a>测试缓存大小</h3><p>根据<a href="https://www.zhihu.com/question/30563694" target="_blank" rel="noopener">知乎</a>，方案是创建一个连续的内存块，进行连贯、大量、随机且有意义（防止被优化掉）的访问。在这种情况下，当内存块能够被整块放入Cache时，平均访问速度会显著的快。观察随着内存大小提高，平均访问时间的跃升点，即可估计Cache大小。</p>
<p>特别地，这样的测试构成了一个<a href="https://zh.wikipedia.org/wiki/%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%B1" target="_blank" rel="noopener">存储器山</a>。</p>
<h3 id="缓存一致性和volatile"><a href="#缓存一致性和volatile" class="headerlink" title="缓存一致性和volatile"></a>缓存一致性和volatile</h3><p>我们知道C++中的volatile的作用之一是强制每次从内存中读值。但既然缓存一致性协议保证CPU总是能读到内存里面最新的值，那为啥还需要volatile呢？原因有二</p>
<ol>
<li>CPU不一定会读缓存，可能直接读寄存器<br> 缓存一致性解决的是<strong>Lx缓存和内存之间的问题，而不是寄存器和内存之间的问题</strong>。<br> 这时候要注意区分CPU缓存一致性和volatile之间的关系。例如出于优化的角度，编译器可能把一个在内存的值放到到寄存器里面，以避免访问内存，既然不访问内存那和缓存一致也没啥关系了。但这样就会出现问题，如果某个线程修改了这个值对应的内存，那么寄存器是不知道的，所以这时候volatile强制说不要在寄存器里面读啦，直接从内存里面读，这时候缓存就能发挥应该有的作用了。</li>
<li>有的缓存一致性也不保证是任意时刻的<br> 经过<a href="http://www.infoq.com/cn/articles/cache-coherency-primer/" target="_blank" rel="noopener">简单的了解</a>，CPU缓存行的写操作也分为直写(write though)和回写(write back)两种策略。<br> 直写和会写的定义和Linux、Innodb中类似。<br> 直写就是同时写缓存和内存，因此对于直写来说，确实可以做到任意时刻各缓存中的内容等于内存中内容。<br> 但回写就不一定是任意时刻了，它并不是立即更新缓存，而是只修改本级缓存，然后将对应缓存标记为脏段，只有当所有脏段被回写后才能达到一致性。具体还可以参看<a href="http://ifeve.com/cpu-cache-flushing-fallacy-cn/" target="_blank" rel="noopener">缓存一致性</a>。</li>
</ol>
<h2 id="CPU提供的并发处理机制"><a href="#CPU提供的并发处理机制" class="headerlink" title="CPU提供的并发处理机制"></a>CPU提供的并发处理机制</h2><h3 id="Store-Buffer"><a href="#Store-Buffer" class="headerlink" title="Store Buffer"></a>Store Buffer</h3><h3 id="Fence"><a href="#Fence" class="headerlink" title="Fence"></a>Fence</h3><p>以x86为例，提供了<code>lfence</code>、<code>sfence</code>和<code>mfence</code>。</p>
<p><code>lfence</code>+<code>sfence</code>弱于<code>mfence</code>，因为<a href="https://stackoverflow.com/questions/19047327/why-gcc-does-not-use-loadwithout-fence-and-storesfence-for-sequential-consist" target="_blank" rel="noopener">它不能禁止Store-Load的乱序</a>。</p>
<p>下面给出三个fence的<a href="https://stackoverflow.com/questions/27627969/why-is-or-isnt-sfence-lfence-equivalent-to-mfence" target="_blank" rel="noopener">精确定义</a>。</p>
<ol>
<li>MFENCE prevents any later loads or stores from becoming globally observable before any earlier loads or stores. It drains the store buffer before later loads can execute.<br> 包含两层意思：<ol>
<li>禁止一切形式的Store/Load重排</li>
<li>在下一个指令开始前，清空Store Buffer</li>
</ol>
</li>
<li>LFENCE blocks instruction dispatch (Intel’s terminology) until all earlier instructions retire. This is currently implemented by draining the ROB (ReOrder Buffer) before later instructions can issue into the back-end.</li>
<li>SFENCE only orders stores against other stores, i.e. prevents NT stores from committing from the store buffer ahead of SFENCE itself. But otherwise SFENCE is just like a plain store that moves through the store buffer. Think of it like putting a divider on a grocery-store checkout conveyor belt that stops NT stores from getting grabbed early. It does not necessarily force the store buffer to be drained before it retires from the ROB, so putting LFENCE after it doesn’t add up to MFENCE.<br> 包含几层意思：<ol>
<li>只禁止Store-Store重排</li>
<li>可以看做在超市售货员的传送带上放置的分隔条，从而防止NT store被过早取走。这里的NT store指non temporal store。</li>
<li>不强制排空Store Buffer</li>
</ol>
</li>
</ol>
<p>在Linux中，可以通过<code>smp_mb</code>这个宏代替<code>mfence</code>，它实际上<a href="https://zhuanlan.zhihu.com/p/41872203" target="_blank" rel="noopener">是<code>lock add</code>指令</a>，<a href="https://stackoverflow.com/questions/49107683/why-does-a-stdatomic-store-with-sequential-consistency-use-xchg" target="_blank" rel="noopener">它的性能更好</a>，当然<code>mfence</code>可能更强一点，<a href="https://stackoverflow.com/questions/40409297/does-lock-xchg-have-the-same-behavior-as-mfence" target="_blank" rel="noopener">例如它可以fence a subsequent non-temporal load from a WC-type memory region</a><br>在Linux中，<a href="https://zhuanlan.zhihu.com/p/41872203" target="_blank" rel="noopener"><code>smp_store_mb</code>实际上就是”xchg”指令</a>。</p>
<h3 id="总线锁"><a href="#总线锁" class="headerlink" title="总线锁"></a>总线锁</h3><p><a href="https://www.zhihu.com/question/65372648" target="_blank" rel="noopener">在较为古老的CPU上LOCK指令通常是锁总线的，后面有使用Ringbus+MESI协议的</a>，这个协议我们后面会讲到。</p>
<h1 id="内核层面的同步与并发"><a href="#内核层面的同步与并发" class="headerlink" title="内核层面的同步与并发"></a>内核层面的同步与并发</h1><h2 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h2><h3 id="x86上的中断"><a href="#x86上的中断" class="headerlink" title="x86上的中断"></a>x86上的中断</h3><p>在一些经典的x86系统中使用的是Intel 8259 PIC处理中断，在这种形式下CPU通过两个8259处理16个IRQ，这两个8259以Master/Slave形式存在。在现在的多核CPU特别是SMP架构背景下，中断的机制和单核有所区别，此时主要借助于高级可编程中断控制器(APIC)。APIC由本地APIC和IO APIC组成，其中本地APIC与每个处理器核心对应，IO APIC负责采集和转发来自IO设备的中断信号。<br>根据Intel的规定，广义上的中断可分为<a href="https://www.ibm.com/developerworks/cn/linux/l-cn-linuxkernelint/index.html" target="_blank" rel="noopener">同步中断和异步中断</a>。</p>
<ol>
<li>同步中断又称<strong>异常</strong>，实际上是由CPU产生的，因此显然<strong>不能被屏蔽</strong>。异常分为故障(fault)、陷阱(trap)和终止(abort)，对应到中断号的0-15。</li>
<li>异步中断又称中断，分为**外部非屏蔽中断(NMI)<strong>和</strong>外部可屏蔽中断(INTR)**，分别对应中断号IRQ的16-31和32-47。Intel将非屏蔽中断也归入异常，所以异常一般为来自外设或CPU中的非法或故障状态，例如常见的除零错误、缺页（故障）、单步调试（陷阱）等情况。</li>
</ol>
<p>在中断的语境中，我们主要讨论异步中断中的可屏蔽中断，它通常是来自外部设备的中断。这是因为除了一些硬件故障，来自外部IO设备的中断常是可以等待的，所以属于可屏蔽中断，当IF标志为1时，CPU可以不响应可屏蔽中断，而是将它<strong>缓存</strong>起来，在开中断后会传给CPU。当CPU在响应一个异常时，所有的可屏蔽中断都将被屏蔽，而如果此时再出现一个异常，即产生了double fault故障，一般来说系统就会宕机。</p>
<h3 id="Linux的中断"><a href="#Linux的中断" class="headerlink" title="Linux的中断"></a>Linux的中断</h3><p>Linux上每一个CPU都拥有一个中断栈，这个始于Linux2.6的版本，在此之前，中断共享其所在的内核栈，后来Linux认为对每个进程提供两页<strong>不可换出</strong>的内核栈太奢侈的，所以就将其缩小为1页，并且将中断栈独立了出来。<br>中断处理的原则是快，否则很容易被覆盖。因此，中断上下文又被称为原子上下文（《Linux内核设计与实现》），该上下文中的代码不允许阻塞，这是因为中断上下文完全不具备进程的结构，因此在睡眠之后无法被重新调度。<br>在操作系统如Linux中，中断还可以被分为<strong>软件中断（内部中断）</strong>和硬中断，硬中断是来自硬件的中断，它可以是可屏蔽的，也可以是不可屏蔽的。软件中断一般是由<code>int</code>指令产生的，由操作系统提供，在Linux中软中断对应于中断号48-255。软件中断是不可屏蔽的（不然干嘛调用<code>int</code>呢），但在操作系统中软件中断也可能是由一个硬中断产生的，例如一个来自打印机的硬中断可能产生一个软件中断给内核中的相关处理程序。我们需要区分<strong>软件中断</strong>和<strong>软中断</strong>，前者指的是<code>INT</code>指令，后者特指Linux的一种<strong>中断推后处理机制</strong>（在Windows和Linux的分别被称为中断延时处理和中断下半部）。</p>
<h3 id="x86中断向量-中断描述符"><a href="#x86中断向量-中断描述符" class="headerlink" title="x86中断向量/中断描述符"></a>x86中断向量/中断描述符</h3><p>在实模式中使用中断向量表，在保护模式中使用中断描述符表IDT。从上文中我们得到不可屏蔽中断占用了IDT的0-31，其中前半是异常，后半是外部中断。<br>Intel使用了三种中断描述符：中断门、任务门、陷阱门。而Linux中则分为五种，即中断门、系统门、系统中断门、陷阱门、任务门。</p>
<h3 id="中断程序的注册和处理"><a href="#中断程序的注册和处理" class="headerlink" title="中断程序的注册和处理"></a>中断程序的注册和处理</h3><p>需要使用中断的驱动程序会调用<code>request_irq()</code>向内核注册一个中断号<code>irq</code>和中断处理函数<code>irq_handler_t handler</code>，并激活对应的中断线。<code>request_irq()</code>会接受一个flag，flag中的一个选项<code>IRQF_DISABLED</code>表示禁用所有中断，如果不设置这个值，那么该中断处理程序可以被<strong>非同种中断</strong>打断，这也就是说Linux中硬中断是<strong>可以嵌套</strong>的。不过Linux禁止来自同种类中断的打断，它会挂起后来的中断，这主要是为了<strong>防止重入现象</strong>的发生，从而简化系统实现。Linux通过<a href="http://blog.csdn.net/yusiguyuan/article/details/23701519" target="_blank" rel="noopener">巧妙的机制</a>来防止同种类中断重入。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 当中断来临时，IRQ_PENDING被设置，表示正在排队</span></span><br><span class="line"><span class="comment">// action为当前的中断处理函数指针</span></span><br><span class="line">action = <span class="literal">NULL</span>;</span><br><span class="line"><span class="comment">// 如果IRQ_INPROGRESS不为0，说明有正在处理的同种中断，所以拜拜</span></span><br><span class="line"><span class="keyword">if</span> (likely(!(status &amp; (IRQ_DISABLED | IRQ_INPROGRESS)))) &#123;</span><br><span class="line">	action = desc-&gt;action;</span><br><span class="line">    <span class="comment">// 如果当前没有中断等待处理，我们清除IRQ_PENDING，设置IRQ_INPROGRESS</span></span><br><span class="line">	status &amp;= ~IRQ_PENDING; <span class="comment">/* we commit to handling */</span></span><br><span class="line">	status |= IRQ_INPROGRESS; <span class="comment">/* we are handling it */</span></span><br><span class="line">&#125;</span><br><span class="line">desc-&gt;status = status;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * If there is no IRQ handler or it was disabled, exit early.</span></span><br><span class="line"><span class="comment"> * Since we set PENDING, if another processor is handling</span></span><br><span class="line"><span class="comment"> * a different instance of this same irq, the other processor</span></span><br><span class="line"><span class="comment"> * will take care of it.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (unlikely(!action))</span><br><span class="line">	<span class="keyword">goto</span> out;</span><br></pre></td></tr></table></figure>

<p>需要特别注意的是“只要非同种中断发生就可以抢占内核”这句话也是不准确的，因为开中断发生在中断处理函数<code>handle_IRQ_event</code>中，此时如果没有设置<code>IRQF_DISABLED</code>，Linux就会立马开中断。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">irqreturn_t</span> handle_IRQ_event(<span class="keyword">unsigned</span> <span class="keyword">int</span> irq, struct irqaction *action)</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">	<span class="keyword">if</span> (!(action-&gt;flags &amp; IRQF_DISABLED))</span><br><span class="line">	    local_irq_enable_in_hardirq();</span><br></pre></td></tr></table></figure>

<p>但是在这个函数前的一条调用链中都是<strong>关中断</strong>的，这是CPU的一个特性，即中断发生时触发中断门会自动关中断，也就是置IF为0，可参考<a href="http://abcdxyzk.github.io/blog/2015/05/07/kernel-irq-irq/" target="_blank" rel="noopener">这篇文章</a>。关中断的好处在于可以防止中断嵌套，防止<strong>内核抢占</strong>，但不能禁止<strong>来自SMP架构下其他处理器的并发访问</strong>，为了解决这种并发访问，通常的做法是借助于例如自旋锁的机制。此外在关中断时要注意关中断会导致异步IO、调度等一系列依赖中断的功能失效，所以屏蔽中断后一定要尽快执行完临界区内代码。<br>此外，flag中还有一些其他的选项，例如<code>IRQF_SAMPLE_RANDOM</code>，这个被Linux用来实现随机数，会将每次的中断间隔填入内存熵池。与之对应的是<code>IRQF_TIMER</code>，这个表示系统时钟中断，显然系统时钟具有固定间隔，是不适合用来实现随机数的。</p>
<h3 id="中断的开启与关闭"><a href="#中断的开启与关闭" class="headerlink" title="中断的开启与关闭"></a>中断的开启与关闭</h3><p>我们使用<code>local_irq_disable</code>和<code>local_irq_enable</code>来控制<strong>当前</strong>处理器的中断，他们对应到x86架构上就是常见的<code>cli</code>和<code>sti</code>命令。不过Linux更推荐使用<code>local_irq_save</code>来禁止中断、<code>local_irq_restore</code>来恢复到原来的状态（因为可能一直就是禁止中断的）。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">native_irq_disable</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">"cli"</span>: : :<span class="string">"memory"</span>)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">native_irq_enable</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">"sti"</span>: : :<span class="string">"memory"</span>)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>《Linux内核设计与实现》指出在2.5版本前存在一个禁止所有处理器中断的内核函数<code>cli()</code>，这个函数非常暴力，乃至它实际上提供了对其他所有中断处理程序的互斥访问机制，在这一把全局大锁下我们实际上就可以保证共享数据的互斥了，也就不要像后面版本中那样关闭本地中断后还需要用自旋锁来维护。取消这个全局大锁的好处是使用细粒度的锁能提高性能。<br>相对于<code>local_</code>系更轻量级的方案是只禁用一种中断，也就是<code>disable_irq</code>、<code>disable_irq_nosync</code>系列，他们禁止中断控制器上的指定中断线<code>irq</code>，其中<code>_nosync</code>系列立即返回，而前面的需要等待已有的中断处理完毕，其实就是在调用<code>_nosync</code>之后调用<code>synchronize_irq</code>去等待，借助于<code>raw_spin_lock_irqsave</code>。《Linux内核设计与实现》指出<code>disable_irq</code>和<code>enable_irq</code>不是幂等的，因此要成对调用才能确保正确回到原始状态。此外还指出这个是保证不会sleep的，但是我在4.17的内核中看到现在的实现是<code>wait_event</code>一个事件，里面涉及一个<code>might_sleep</code>宏的调用。</p>
<h3 id="共享中断"><a href="#共享中断" class="headerlink" title="共享中断"></a>共享中断</h3><p>Linux的中断是可以共享的，也就是说同一个中断可以有多个处理程序响应。一个共享中断，例如定时器中断，必须通过<code>request_irq</code>设置<code>IRQF_SHARED</code>标志。</p>
<h3 id="中断下半部"><a href="#中断下半部" class="headerlink" title="中断下半部"></a>中断下半部</h3><p>Linux中，中断下半部可以被硬中断打断，所以可以认为硬中断具有更高的“优先级”（不过Linux中并没有中断优先级的概念，虽然也有个中断线程化的东西）。这道理是显然的，因为我们又要快速地响应设备，又不能在中断上下文停留过久，所以才发明了中断下半部这个东西。<br>Linux中的中断下半部的实现有三种机制：Orignial Bottom Half机制、Task Queue机制、软中断Softirq机制、tasklet和工作队列，其中前两种已被替代。</p>
<h4 id="Orignial-Bottom-Half-BH"><a href="#Orignial-Bottom-Half-BH" class="headerlink" title="Orignial Bottom Half(BH)"></a>Orignial Bottom Half(BH)</h4><p>使用32个链表串联，全局中只有一个BH能够运行。</p>
<h4 id="Task-Queue"><a href="#Task-Queue" class="headerlink" title="Task Queue"></a>Task Queue</h4><h4 id="软中断"><a href="#软中断" class="headerlink" title="软中断"></a>软中断</h4><p>从2.3开始，软中断和tasklet被引入，其中tasklet是基于软中断实现的。软中断和软中断之间是不会抢占的，事实上它们被抢占也就是如之前提到的<strong>只能被硬中断抢占</strong>，但包括相同类型的软中断都可以在SMP的不同CPU上并行执行。注意<a href="http://unicornx.github.io/2016/02/11/20160211-lk-drv-softirq/" target="_blank" rel="noopener">软中断处理函数属于中断上下文</a>，从而在处理软中断时也不允许休眠，所以其实软中断的优先级还是很高的。<br>Linux中使用<code>softirq_action</code>结构表示软中断，Linux中设置了一个长度为32的<code>softirq_action</code>数组来存放这些中断。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">softirq_action</span> &#123;</span>  </span><br><span class="line">    <span class="keyword">void</span> (*action) (struct softirq_action *); <span class="comment">/* 软中断的处理函数 */</span>  </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>可以看出，软中断实际上很像一个回调函数。那么软中断和回调函数之间有什么区别呢：</p>
<ol>
<li>软中断能够实现不同优先级代码的跳转</li>
<li>软中断的重入性和回调函数不同</li>
</ol>
<p>软中断的检查与执行一般出现在以下几种情况：</p>
<ol>
<li>从硬中断返回时。这是一个很常见的情况，因为从硬中断返回之后往往会立即开启软中断，但是在软中断时可以自由地抢占了。</li>
<li>ksoftirqd内核线程。<br> 这个内核线程是为了处理可能存在的大量的软中断。对于如网络子系统之类的使用软中断的系统，他们可能会频繁的触发软中断，并且在软中断处理函数中可能还会重复触发软中断。这样就会存在大量的软中断抢占其他任务执行时间的问题。对于这个问题，单纯地选择执行完所有当前的软中断或者所有重复触发的软中断都放到下一跳执行都是不合适的。</li>
<li>来自网络子系统等显式要求检查软中断的部分。</li>
</ol>
<p>软中断的执行非常有意思，通过移位操作来实现按顺序check并执行32个软中断的行为，具体可以查看《Linux内核与实现》</p>
<p>虽然不如硬中断处理函数那么严苛，但由上可见软中断的使用还是有很大限制的，目前使用软中断的主要有网络IO、SCSI、内核定时器、tasklet等、RCU等。<br>但注意工作队列由内核线程eventX执行，允许被调度甚至睡眠。<br>Linux的外部中断处理过程可以参考<a href="http://home.ustc.edu.cn/~boj/courses/linux_kernel/2_int.html" target="_blank" rel="noopener">文章</a>。</p>
<h4 id="tasklet"><a href="#tasklet" class="headerlink" title="tasklet"></a>tasklet</h4><p>相对于softirq，相同类型的tasklet在一个时刻只有一个在执行。tasklet通过<code>TASKLET_SOFTIRQ</code>和<code>HI_SOFTIRQ</code>两个软中断触发，实际上也是出于中断上下文之中的，所以不能睡眠。</p>
<h2 id="进程与线程设施"><a href="#进程与线程设施" class="headerlink" title="进程与线程设施"></a>进程与线程设施</h2><h3 id="进程模型"><a href="#进程模型" class="headerlink" title="进程模型"></a>进程模型</h3><p>五状态进程模型包括新建、就绪（等待CPU）、阻塞（等待事件）、运行和退出。在五状态模型之外，还有挂起操作。挂起操作指的是将进程交换到外存，这常常是由于内存紧张或者该进程被阻塞的缘故。挂起不同于阻塞或者就绪，被挂起的进程犹如进入一个平行世界，当等待的事件到达时，它能够从挂起阻塞直接切换成挂起就绪。一个挂起的进程必须脱去挂起这层壳之后才能重新进入五状态模型，如一个挂起就绪态进程必须换回到内存切换成就绪态才能被调度。<br>在Linux中，进程的状态主要有<code>TASK_RUNNING</code>、<code>TASK_INTERRUPTIBLE</code>、<code>TASK_UNINTERRUPTIBLE</code>、<code>_TASK_TRACED</code>、<code>_TASK_STOPPED</code>。其中<code>TASK_RUNNING</code>表示进程处于执行或者排队等待执行的状态，此时进程可能位于用户态，也可能位于内核态。<code>TASK_INTERRUPTIBLE</code>表示进程正在被阻塞，等待条件达成或者信号。<code>TASK_UNINTERRUPTIBLE</code>是不可中断的睡眠状态，这是指这个进程不响应<code>SIGKILL</code>等外部信号，因此必须是十分短暂的，在<code>ps -aux</code>命令中显示为D。顺带一提另一令不能响应外部信号的僵尸进程Z（区别于失去父进程的孤儿进程），僵尸进程的资源已经被全部释放，只留下包括<code>task_struct</code>在内的一点信息用来给父进程提供返回码等信息，如果此时父进程被阻塞而不能回收子进程，那么子进程就会进入僵尸状态。<br><code>fork</code>出的子进程默认会拷贝父进程的一系列资源，包括内存（包括堆栈）、文件描述符（特别地<code>exec</code>也会保留文件描述符，可以参考我有关subprocess的文章）、信号设定、Nice优先级值、工作目录等。</p>
<h3 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h3><p>Linux根据调度者在内核内还是内核外将线程分为用户线程和核心线程，前者一般更利于并发使用多核处理器资源，后者则需要较多地考虑上下文切换的开销。为此在设计时往往会引入一对多或者一对一多对多等线程模型，例如使用一个核心线程去调度多个用户线程。<br>pthread(POSIX threads)是POSIX下的一套线程模型，而Linux对这套模型或者接口的实现跟随时间先后有LinuxThreads和NPTL等几种方式。</p>
<ol>
<li>LinuxThreads<br> 容易想到的简单办法就是直接复用进程，也就是LinuxThread轻量级线程。无论是<code>fork()</code>还是<code>pthread_create()</code>，最后都是调用<code>do_fork()</code>，普通进程和轻量级进程（线程）的区别在于调用参数不同。线程的创建一般会使用<code>CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND</code>等<code>clone_flags</code>参数选项，表示共享地址空间、文件系统、描述符和信号处理，而<code>fork</code>只有<code>CLONE_CHLD</code>。<br> 在Linux内核2.6出现之前进程是(最小)可调度的对象，当时的Linux不真正支持线程。LinuxThreads计划使用系统调用<code>clone()</code>来提供一个内核级的线程支持。但是这个解决方法与真正的POSIX标准有一些不兼容的地方，尤其是在信号处理、进程调度和进程间同步原语方面。</li>
<li>NPTL<br> <a href="https://zh.wikipedia.org/wiki/Native_POSIX_Thread_Library" target="_blank" rel="noopener">Native POSIX Thread Library(NPTL)是Linux内核中实践POSIX Threads标准的库</a>，是POSIX线程模型的新实现。我们可以在glibc库源码的<em>nptl</em>目录下可以看到它被用来实现了pthread系列函数接口。这里的<a href="https://zh.wikipedia.org/wiki/POSIX%E7%BA%BF%E7%A8%8B" target="_blank" rel="noopener">POSIX Threads标准</a>也就是一系列<code>pthread_</code>开头的函数。</li>
</ol>
<h3 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h3><p>Linux中信号是一个实现异步的机制。信号分为同步信号(synchronous signal)和异步信号(asynchronous signal)。同步信号类似于SIGFPE、SIGSEGV，通常标记着一个无法恢复的错误，来自当前执行上下文中，通常<a href="https://www.linuxjournal.com/article/3985" target="_blank" rel="noopener">由一个trap陷入内核，并由一个trap handler触发</a>。异步信号则来自当前的执行上下文之外</p>
<h3 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h3><p>在稍后的论述中，我们将看到进程在用户态和内核态之间切换时常伴随有很多奇妙的工作，不过首先来先行讨论一下系统调用。进程从用户态进入内核态可以通过系统调用、异常（如缺页异常）和来自外部设备的硬中断，而系统调用是最常见的一种，也是应用程序唯一主动进入内核的机制。<br>Linux的系统调用以<code>asmlinkage long sys_</code>打头，据说<code>asmlinkage</code>保证从栈中提取函数的参数，其实就是<code>CPP_ASMLINKAGE __attribure__((syscall_linkage))</code>，其中<code>CPP_ASMLINKAGE</code>就是在C++上用<code>extern &quot;C&quot;</code>导出符号。<code>system_call</code>系统调用负责系统调用并陷入内核，从前它是一个<code>int 0x80</code>指令，现在它是<code>sysenter</code>指令，它精简了<code>int</code>的流程。这是因为保护模式中CPU首先从中断描述符表(IDT)中取出对应的门描述符，比较中断描述符级别DPL和<code>int</code>调用者级别CPL，我们禁止<code>CPL&gt;DPL</code>的调用，但是对于系统调用来说比较描述符的这一步是能省掉的，因为我们可以确定这个CPL和DPL。<code>system_call</code>从<code>eax</code>中获得系统调用号，并定位到对应的<code>NR_</code>调用位置。<br>我们需要特别注意的是由于内核抢占和SMP的关系，我的系统调用一定要是可重入的。因此<strong>系统调用时完全可以被信号打断的</strong>，当然我们也可以在调用前通过<code>SIG_IGN</code>、<code>sigprocmask()</code>、<code>pthread_sigmask()</code>的方法去屏蔽掉信号以防止系统调用被打断。</p>
<h2 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h2><p>多任务系统常使用非抢占式(cooperative)或者抢占式(preemptive)的调度策略，Linux支持抢占式的任务调度。和处理器的流水线设计类似，一个好的调度策略需要balance延迟和吞吐量，也就是说它应该能在一定程度上<strong>识别</strong>和<strong>预测</strong>出IO型和计算型的程序，并且分别给予它们更短的响应时间或者吞吐量。此外，调度的时间间隔，或者说每个进程所拥有的时间片的大小也对应着处理器流水线深度的情况，太频繁的调度会导致系统在调度器上浪费太多的资源，所以我们也要控制调度的切换代价。Linux的调度算法从简单粗暴，变为了O(1)，并在最后使用了RSDL也就是目前的CFS算法。</p>
<h3 id="CFS调度算法"><a href="#CFS调度算法" class="headerlink" title="CFS调度算法"></a>CFS调度算法</h3><p>CFS根据NICE给每个进程分配一个处理器使用比，一个实际消耗使用比小于当前进程的进程将抢占当前进程。注意到这种策略相对于传统的，按照NICE值给高优先级进程分配更长时间片要更为贴近现实，因为NICE值较高（也就是优先级较低）的进程通常是计算密集型的，而如果按照NICE值，这些进程将获得较短的时间片，反而是优先级高的获得较多的时间片，旱的旱死，涝的涝死。此外，直接用NICE去标定时间片还会涉及定时器节拍改变导致时间片改变、优化NICE到时间片映射的问题，最终的结论是进程之间的切换频率如果非固定的，效果会更好。<br>CFS理论上希望一个进程能运行多久取决于处理器使用比，因此指定目标延迟（如20ms）的情况下，每个进程实际能得到的运行时间就和它占到的比例以及总的可运行进程数有关了。当然，我们的分配也是要有最小粒度的，例如最小的时间片长度不能小于1ms。Linux使用<code>task_struct</code>中的<code>sched_entity</code>结构来描述。在具体实现的时候我们并不会望文生义地来做，而是在结构<code>sched_entity</code>中使用<code>vruntime</code>表示加权的虚拟运行时间，这里的加权指的是默认进程的权重比上当前进程的权重。在<code>update_urr</code>中，Linux使用<code>now - curr-&gt;exec_start</code>计算出<code>delta_exec</code>时间并使用<code>__update_curr</code>，将未加权的加入到<code>sum_exec_runtime</code>，加权的加入到<code>vruntime</code>中。根据CFS的原则，我们现在应当从CFS队列<code>cfs_rq</code>（这里rq表示run queue的意思，在Linux源码中有很多这样的简写）中调用<code>__pick_next_entity()</code>选取<code>vruntime</code>最小的进程，Linux在这里使用了红黑树来实现。</p>
<h3 id="Linux的调度器"><a href="#Linux的调度器" class="headerlink" title="Linux的调度器"></a>Linux的调度器</h3><p><code>schedule()</code>函数负责选中最高优先级的调度类中最高优先级的进程，整个过程最后会到idle<strong>类</strong>，对应到Linux中的0号(idle)进程。有多个调度类的原因是由于Linux中不但存在普通进程（对应于CFS），还存在实时进程。在选中之后，<code>schedule()</code>会调用<code>context_switch()</code>来进行上下文切换。<br>一般来说，<code>schedule()</code>函数是由进程调用的，当进程死亡（调用<code>do_exit</code>）、阻塞等需要放弃当前时间片时就会调用<code>schedule()</code>。我们现在考虑最主要的等待某个条件而陷入阻塞的情况，这时候线程会将自己放入等待队列，等待一个condition。这个过程涉及到多个函数，其中<code>DEFINE_WAIT</code>宏用来创建一个<code>wait_queue_entry</code>结构，<code>add_wait_queue</code>负责将一个进程增加到等待队列，<code>prepare_to_wait</code>负责<strong>等待队列</strong>上的一个进程置入睡眠，<code>finish_wait</code>负责将一个进程移出等待队列。这些函数中都使用了内部结构<code>spin_lock</code>来维护等待队列。《Linux内核设计与实现》书中举了下面的典型的用例，我们看到整个过程用<code>while</code>所维护，期间会发生若干次<code>schedule()</code>。此外我们发现进程可能会被信号所唤醒，也就是所谓的虚假唤醒/伪唤醒，这时候我们同样退出循环，而不是继续循环等待，这也就是为什么我们在后面看到使用条件变量要while-wait的原因。唤醒操作由<code>wake_up()</code>函数负责，它会负责调用<code>try_to_wake_up</code>，该函数会唤醒等待队列上的所有进程，注意<a href="https://unix.stackexchange.com/questions/268027/how-does-linux-kernel-find-out-which-process-to-wake-up-during-interrupt-handlin" target="_blank" rel="noopener">系统中有<strong>很多</strong>个这样的等待队列</a>，每个等待队列上的所有进程等待同一个事件。一般来说，<code>wake_up</code>的调用者就是使得条件达成的那一方，这个和条件变量的逻辑是相同的。<br>刚才说到有虚假唤醒，其实还有无效唤醒，也就是进程带着condition进入睡眠。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 3.11.10</span></span><br><span class="line"><span class="comment">// inotify_read</span></span><br><span class="line">DEFINE_WAIT(wait);</span><br><span class="line">start = buf;</span><br><span class="line">group = file-&gt;private_data;</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    prepare_to_wait(&amp;group-&gt;notification_waitq, &amp;wait, TASK_INTERRUPTIBLE);</span><br><span class="line">    mutex_lock(&amp;group-&gt;notification_mutex);</span><br><span class="line">    kevent = get_one_event(group, count);</span><br><span class="line">    mutex_unlock(&amp;group-&gt;notification_mutex);</span><br><span class="line">    <span class="keyword">if</span> (kevent) &#123;</span><br><span class="line">        ...</span><br><span class="line">        ret = copy_event_to_user(group, kevent, buf);</span><br><span class="line">        fsnotify_put_event(kevent);</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> (signal_pending(current))</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    ...</span><br><span class="line">    schedule();</span><br><span class="line">&#125;</span><br><span class="line">finish_wait(&amp;group-&gt;notification_waitq, &amp;wait);</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h2 id="Linux的抢占"><a href="#Linux的抢占" class="headerlink" title="Linux的抢占"></a>Linux的抢占</h2><p>被动式的调度指的是使用一个<strong>调度器</strong>决定哪一个任务会在下一刻运行，而不是由进程主动放弃处理器。由调度器决定暂时停止一个任务并让另一个任务开始执行的行为就是抢占式(preempt)调度。抢占式调度分为<a href="http://blog.csdn.net/gatieme/article/details/51872618" target="_blank" rel="noopener">用户抢占和内核抢占</a>两种。<br>先前提到，进程可以通过主动调用<code>schedule()</code>来放弃剩余时间片，但对于时间片耗尽的情况，内核中的<code>scheduler_tick()</code>函数（此时关中断，需要在2.6版本左右查看）会通过<code>set_tsk_need_resched(p)</code>函数设置一个<code>need_resched</code>标志，这个标志从逻辑上讲应该是全局性的，但为了方便从高速缓存中读取，它自2.2版本后被放到了每一个进程的<code>task_struct</code>中，自2.6内核后放到<code>thread_info</code>中。此外在刚才的<code>try_to_wake_up()</code>唤醒过程中，如果被唤醒的进程的优先级更高，这个标志也会被设置。从系统调用/中断处理程序中返回的情况也包括在内，这也对应着用户抢占。</p>
<h3 id="用户抢占"><a href="#用户抢占" class="headerlink" title="用户抢占"></a>用户抢占</h3><p>Linux的用户抢占并不是在用户态下，而是发生在进程即将从内核态返回用户态时，这对应两种情况，从系统调用返回和从中断处理程序返回。如果不开启内核抢占，抢占式调度会给每一个进程的运行分配一个固定或者动态计算的时间片(timeslice)，进程在内核态的运行会直至结束（主动放弃(yield)/时间片耗尽/阻塞）。这样的假设方便了内核的编写，特别是在单处理器(UP)下，因为我们考虑到在内核态中不存在对进程上下文的切换，所以内核并不需要考虑对临界资源的竞争访问问题，因此用户程序也可以假设在一次系统调用过程中不需要保护内核临界资源。但需要注意的是中断仍然存在，所以在进入临界区前还需要关中断。</p>
<h3 id="内核抢占"><a href="#内核抢占" class="headerlink" title="内核抢占"></a>内核抢占</h3><p>通过内核抢占，系统允许高优先级的进程抢占低优先级的进程的<strong>内核态</strong>，这将能提高系统的实时性能。内核抢占可能发生在中断处理程序返回到内核空间前、内核代码具有抢占性、内核代码显式调用调度器schedule、内核中的任务被阻塞时。此外，内核抢占是可以被关闭的，即所谓的关抢占的几种情况：</p>
<ol>
<li><p>当内核调度器scheduler正在运行时<br> 这个是显然的，我们可以直接在<code>schedule()</code>函数中看到相应实现</p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 2.6.11</span></span><br><span class="line"><span class="comment">// /include/linux/preempt.</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> preempt_disable() \</span></span><br><span class="line"><span class="keyword">do</span> &#123; \</span><br><span class="line">    inc_preempt_count(); \</span><br><span class="line">    barrier(); \</span><br><span class="line">&#125; <span class="keyword">while</span> (<span class="number">0</span>)</span><br><span class="line"><span class="comment">// /kernel/sched.c</span></span><br><span class="line">need_resched:</span><br><span class="line">    preempt_disable();</span><br><span class="line">    prev = current;</span><br><span class="line">    release_kernel_lock(prev);</span><br><span class="line">need_resched_nonpreemptible:</span><br><span class="line">    rq = this_rq();</span><br></pre></td></tr></table></figure>

<p> 另及，Linux通过内核抢占锁<code>preempt_count</code>来跟踪一个进程的可抢占性，当内核代码具有抢占性时（此时<code>preempt_count</code>为0，且<code>need_resched</code>被设置），则调用<code>preempt_schedule_irq -&gt; schedule</code>进行内核抢占，这过程的发生场景之一就是<a href="https://unix.stackexchange.com/questions/84107/are-time-interrupts-always-followed-by-a-scheduler-call" target="_blank" rel="noopener">从时间中断返回</a>。我们看到这里关中断实际上是自增了<code>preempt_count</code>使它不等于0。这里的<code>do{}while(0)</code>是出于宏的考虑，防止和其他语法结构（如没有括号的if）混用导致错误。</p>
</li>
<li><p>中断的bottom half<br> 通常有上文所述的三种方式，当内核执行软中断和tasklet禁止内核抢占，但注意此时可以被硬中断打断。</p>
</li>
<li><p>当进程持有自旋锁读写锁<br> 这实际上是为了保护临界资源，在有关自旋锁的讨论中会详细说明。事实上当进程持有锁时<code>preempt_count</code>会自增，释放锁时<code>preempt_count</code>会自减，这也就是使用<code>preempt_count</code>的缘由，进程持有锁的数量直接影响到它的可抢占性。</p>
</li>
<li><p>内核正在处理中断<br> 这时候也就是所谓的中断上半部，中断在操作系统中拥有最高的优先级，我们也在前文中论述了中断上下文中不能睡眠的原因，这里不能抢占的原因也是类似的。</p>
</li>
<li><p>内核操作Per-CPU data structures<br> 在SMP架构中，不同的CPU仍然会维护一些私有数据，此时抢占可能造成一个进程被调度到另一个CPU上去，此时Per-CPU变量就会发生改变。我们可以查看相关代码</p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 2.6.39.4</span></span><br><span class="line"><span class="comment">// /include/linux/smp.h</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> get_cpu()		(&#123; preempt_disable(); smp_processor_id(); &#125;)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> put_cpu()		preempt_enable()</span></span><br></pre></td></tr></table></figure>

<p> 而<code>get_cpu</code>就是获得当前的CPU，我们看到首先这一步骤就关了抢占，其中<code>smp_processor_id</code>会调用<code>raw_smp_processor_id</code>这个宏，然后根据不同的CPU来讨论。例如对x86来说，这个宏是<code>#define raw_smp_processor_id() (percpu_read(cpu_number))</code>，然后是<code>#define percpu_read(var)    percpu_from_op(&quot;mov&quot;, var, &quot;m&quot; (var))</code>。然后我们就可以根据获得的CPU号操作<code>unsigned long my_percpu[NR_CPUS]</code>这样的每个CPU独有的数据了。注意所有这样的操作是不需要加锁的，因为这是当前CPU独有的数据，而内核抢占又被关闭了，所以不存在并发访问问题。<br> 《Linux内核设计与实现》中指出了对每个CPU维护私有数据的好处：</p>
<ol>
<li>减少了竞态条件和锁的使用，这个在上面已经提到</li>
<li>减少了缓存失效的可能<br> 根据MESI，同一数据可能存在于多个CPU的缓存中，这样一个CPU造成的修改会导致缓存失效。而一些性能不佳的代码会造成缓存抖动，也就是缓存的不停刷新，这样极大地降低了效率。Linux2.6内核提供了<code>per_cpu</code>接口能够缓存对齐(cache-align)所有数据，这样可以保证不会讲其他处理器的数据带到同一缓存上。</li>
</ol>
</li>
<li><p>关中断<br> 这是一种特殊情况，关中断后抢占机制自然无法实现了，Linux关中断通常借助于<code>local_irq_disable</code>或者<code>local_irq_save</code>。</p>
</li>
</ol>
<h2 id="可重入、异步信号安全、线程安全与中断安全"><a href="#可重入、异步信号安全、线程安全与中断安全" class="headerlink" title="可重入、异步信号安全、线程安全与中断安全"></a>可重入、异步信号安全、线程安全与中断安全</h2><h3 id="可重入函数"><a href="#可重入函数" class="headerlink" title="可重入函数"></a>可重入函数</h3><p>考虑单线程模型，一般来说执行流程是不会被外部打断的，但考虑可重入(reentrant)性仍然是有必要的。一个典型的场景是signal机制（借助于软中断实现）。例如，我们在函数<code>func</code>涉及读写全局变量<code>errno</code>，在这个过程中被signal中断，而中断处理程序也会访问这个<code>errno</code>，那么当继续进行<code>func</code>时就可能读到无效的<code>errno</code>。很多的系统调用是可重入的，一般来说不可重入函数具有以下几个特征：</p>
<ol>
<li>在未保护的情况下访问全局或者局部静态变量<br> 我们希望可重入函数只访问自己栈上的变量。<br> 这里注意，严格意义上<code>errno</code>这个全局变量是怎么都避免不了的，但幸好这个变量有着明确的修改时间，所以我们推荐**在信号处理函数一开始保存<code>errno</code>**，退出时恢复<code>errno</code>的做法，从而保护了调用前后的现场。</li>
<li>调用<code>malloc</code>/<code>free</code>函数<br> 因此我们在信号处理函数里面应当避免使用<code>malloc</code>，这是因为如果我们在主逻辑里面<code>malloc</code>时被signal了，这时候信号处理对<code>malloc</code>的调用就有可能破坏内核数据结构。</li>
<li>调用标准IO等对硬件有副作用的函数</li>
<li>调用<code>longjmp</code>之类的函数</li>
</ol>
<p>POSIX中还描述了异步信号安全(async-signal-safe)的概念，并<a href="http://man7.org/linux/man-pages/man7/signal-safety.7.html" target="_blank" rel="noopener">列举了一系列信号安全的系统调用</a>。从本质上讲一个异步信号安全的函数要不是可重入的，要不对信号处理函数来说是原子的，即不能被打断。</p>
<h3 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h3><p>异步可重入和线程安全是两个不同的概念，线程安全指一个函数能够同时被多个线程安全地调用。<br>一般来说线程安全的函数不一定是可重入的，如<code>malloc</code>，而反之则一般是成立的。所以我们可以体会到Linux提供的signal机制虽然能够实现异步，但是却添加了许多需要考虑的成分。</p>
<h3 id="中断安全"><a href="#中断安全" class="headerlink" title="中断安全"></a>中断安全</h3><h1 id="内核和运行时向外提供的并发与同步设施"><a href="#内核和运行时向外提供的并发与同步设施" class="headerlink" title="内核和运行时向外提供的并发与同步设施"></a>内核和运行时向外提供的并发与同步设施</h1><h2 id="多进程与多线程"><a href="#多进程与多线程" class="headerlink" title="多进程与多线程"></a>多进程与多线程</h2><p>进程是UNIX设计模型中的一个重要部分，UNIX推崇以多进程+IPC的方式组成应用系统，充分贯彻了KISS的方针。在UNIX产生的年代，这种方式无疑是很健壮的。<br>从定义上看，进程是资源分配的最小单位，那么线程是程序执行的最小单位。线程通常和同一程序下的其他线程共享一套地址空间，其中包含应用程序拥有的程序代码与资源，每个线程自己维护一套运行上下文。</p>
<h3 id="同步与异步"><a href="#同步与异步" class="headerlink" title="同步与异步"></a>同步与异步</h3><p>在进程IPC中同步和异步是两种编程模型，描述了IPC中<strong>被调用者</strong>的行为。在同步模型中一个调用只有在等到结果（也就是被调用者完成计算）时才返回，被调用者并不会进行通知。而异步模型中调用会立即返回，而由<strong>被调用者</strong>选择在结果达到后通过回调函数或者信号等机制进行通知。UNP书中还强调异步过程中用户不需要手动将数据从内核复制到用户（即不需要在被通知后调用<code>read</code>等函数），但我觉得这是异步过程所必须具备的特性，而不是其根本的区分点。<br>需要和同步异步进行区分的是阻塞和非阻塞的概念，这两个描述了调用结果未到达时<strong>调用者</strong>的状态。阻塞调用会直接睡眠线程，而非阻塞调用不会阻塞线程。在<strong>非阻塞同步</strong>调用中，当调用者还没有收到来自调用者的返回时，调用者可以原地进行轮询等待，此时虽然逻辑无法持续，但线程并没有进入睡眠。此外，非阻塞模型还可以是异步的，此时线程可以继续执行下面无关返回值的逻辑，消息到达时线程收到一个异步信号或者回调，或者采用类似协程的方法。<br>IO多路复用是一种特殊的同步模型，并且它们在消息到来前必须在一个循环中轮询，而不是立即返回并跳出循环。不过IO多路复用并不属于同步阻塞模型，因为当一个fd在等待结果时，线程可能在处理来自其它fd的IO，因此并不一定会进入睡眠。IO多路复用也不属于同步非阻塞模型，因为当没有任何一个fd产生IO事件时，线程还是会被阻塞的。此外UNP还特别指出<code>poll</code>函数中仍然需要手动将数据从内核复制回来，并把它作为多路复用和异步之间的一个区别。<br>以UNIX套接口为例，<code>SS_NBIO</code>和<code>SS_ASYNC</code>标志分别表示非阻塞和异步的选项，其中非阻塞套接口在请求资源不满足时会返回<code>EWOULDBLOCK</code>，而异步套接口则会通过<code>SIGIO</code>信号来通知进程。</p>
<h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><p>协程(Coroutine)是具有多个入口点的函数，协程内部可通过<code>yield</code>进行中断，此时处理器可能被调度到执行其他的函数。虽然线程也可以睡眠，但睡眠本身涉及用户态与内核态的上下文切换，开销较大。对于套接字等IO密集型的应用，协程在提高CPU使用率上比线程轻很多。<br>协程根据其底层实现可以分为stackful和stackless两种。stackless实现不保存调用栈和寄存器等上下文，因此效率比较高。stackless的协程实现例如C++中的setjmp、Python中的生成器等。stackful即栈式构造，这时候协程拥有自己的堆栈等上下文。stackful的协程类似于C++中的ucontext、libco等。<br>协程根据控制传递方式可以分为对称(symmetric)协程和非对称协程(asymmetric)。我们知道协程实际上是一种对CPU控制权的转移，对称协程在转移时可以转移到其指定的任一对称协程，而非对称协程只能转移到其“调用者”。理论上已经证明了这两种协程是<a href="https://www.jianshu.com/p/9330e6d61f34" target="_blank" rel="noopener">等价</a>的，但显然非对称协程在使用上更友好。</p>
<h2 id="C-下协程的实现方式"><a href="#C-下协程的实现方式" class="headerlink" title="C++下协程的实现方式"></a>C++下协程的实现方式</h2><h3 id="基于ucontext"><a href="#基于ucontext" class="headerlink" title="基于ucontext"></a>基于ucontext</h3><p>ucontext是POSIX上的一套用于保存上下文的库，这里上下文包括寄存器（通用和浮点）、信号等。</p>
<h3 id="黑科技1"><a href="#黑科技1" class="headerlink" title="黑科技1"></a>黑科技1</h3><p>Protothreads基于C的是围绕switch展开的一系列黑科技实现的协程。我们首先看它定义的一些原语，原来这就是一个简易的，关于行号的状态机。我在<a href="https://paste.ubuntu.com/p/MDjGpX3999/" target="_blank" rel="noopener">这里模仿Protothreads实现了一个简易版的协程</a></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> PT_BEGIN() bool ptYielded = true; (void) ptYielded; switch (_ptLine) &#123; case 0:</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> PT_YIELD() \</span></span><br><span class="line">    <span class="keyword">do</span> &#123; ptYielded = <span class="literal">false</span>; _ptLine = __LINE__; <span class="keyword">case</span> __LINE__: \</span><br><span class="line">    <span class="keyword">if</span> (!ptYielded) <span class="keyword">return</span> <span class="literal">true</span>; &#125; <span class="keyword">while</span> (<span class="number">0</span>)</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> PT_END() default: ; &#125; Stop(); return false;</span></span><br></pre></td></tr></table></figure>

<p>为了理解这段代码，我们回想C++实现协程需要实现的一个核心问题，并不是调度，而是实现从多个入口点进入。这就意味着我们需要在退出协程函数时记录下已经到了哪里，然后在下一次进入函数时回到这个地方。对于第一个需求，我们可以借助于<code>__LINE__</code>这个宏表示执行到的行号，每次将这个行号赋值给一个int。对于第二个需求，我们可以借助于<code>switch</code>实现跳转。这里用<code>switch</code>而不用<code>goto</code>的原因是<code>switch</code>能够根据int变量来实现<code>goto</code>的功能，而<code>goto</code>需要依赖静态的label。这种巧妙的机制不禁让我想起了称为<a href="https://en.wikipedia.org/wiki/Duff%27s_device" target="_blank" rel="noopener">Duff’s device</a>的优化方案。<br>不过这种机制有一个语法缺陷就是在里面嵌套的switch语句会产生干扰。</p>
<h3 id="基于setjmp和longjmp"><a href="#基于setjmp和longjmp" class="headerlink" title="基于setjmp和longjmp"></a>基于setjmp和longjmp</h3><p>setjmp和longjmp类似跨栈帧的带上下文的goto。<br><code>int setjmp(jmp_buf env)</code>负责将函数当前的上下文保存在<code>jmp_buf</code>中。</p>
<h1 id="约束线程间并发行为-有锁"><a href="#约束线程间并发行为-有锁" class="headerlink" title="约束线程间并发行为(有锁)"></a>约束线程间并发行为(有锁)</h1><p>线程间实现互斥与同步的任务常具有下面两种形式：</p>
<ol>
<li>多个线程同时访问一个共享资源，需要维护该共享资源的完整性。这就是Race condition问题，将在本节讨论。</li>
<li>一个线程向另一个线程通告自己的结果/等待另一个线程的结果，这将在章节数据共享中讨论。</li>
</ol>
<p>总的来说，为了实现同步，等待资源的一方可以处于用户态（忙等）或者内核态（睡眠），而获得资源的一方可以选择锁进行同步，或者使用原子操作保证自己访问不被打断。这分别下面的基于锁和原子操作的工具。Linux、Windows和C++11的标准库中都对这些工具提供了不同程度的支持，具体可参考<a href="https://www.ibm.com/developerworks/cn/linux/l-cn-mthreadps/index.html" target="_blank" rel="noopener">文档</a>。</p>
<h2 id="Race-condition"><a href="#Race-condition" class="headerlink" title="Race condition"></a>Race condition</h2><p>竞态条件常出现在逻辑电路这样的硬件环境中，对于软件环境而言，当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件(race condition)，导致竞态条件发生的代码区称作临界区。</p>
<p>另一种定义是<a href="https://stackoverflow.com/questions/34510/what-is-a-race-condition" target="_blank" rel="noopener">A race condition occurs when two or more threads can access shared data and they try to change it at the same time</a>。</p>
<p>为了解决竞态条件，有下面的思路：</p>
<ol>
<li>确保只有当前进行修改的线程才能看到不变量被修改的中间状态。<br> 需要临界资源保护起来，前面看到的互斥量等属于这种机制。</li>
<li>借助于锁无关编程技术，将对数据结构的修改分解为若干个不破坏不变量的原子操作。</li>
<li>借助于事务的STM技术，将所需要的操作存储于日志中，再合并提交。</li>
</ol>
<h3 id="不变量"><a href="#不变量" class="headerlink" title="不变量"></a>不变量</h3><p>不变量(invariant)是某个特定数据结构始终保持的特性。例如通过链表的前向指针始终能到达前驱结点。</p>
<p>不变量对应的特性常常在更新过程中被破坏，特别是当更新涉及到修改多个值，或者需要多个过程时。这就类似于在最终一致性系统的窗口内强一致性被破坏。当不变量遭到破坏时，才会产生竞态条件（C++ Concurrency in Action: Ch3）。</p>
<h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><p>在有关CPU缓存一致性的章节中，讨论的volatile、寄存器、主存和CPU缓存之间的关系。这里我们讨论语言（C/C++）层面的<code>volatile</code>的有关特性。<br>C++中的<code>volatile</code>并不以任何形式保证线程安全，它仅用来告知编译器期修饰的变量是易变的，要避免对其进行优化，比如<strong>将变量缓存到寄存器中而不是每次都从内存读取</strong>。<code>volatile</code>并不蕴含禁止编译器或者处理器进行重排或乱序，我们需要通过编译器屏障(Compiler Barrier)或者内存屏障(Fence)来实现这一点。</p>
<p><code>volatile</code>关键字有时是有用的，例如可以<strong>在自旋锁中防止多次循环中始终读取寄存器中的值</strong>。但滥用<code>volatile</code>不仅不会提高程序的安全性，而且会导致程序变慢。对于以为可以加“volatile”就可以解决的问题，一般可以使用<code>std::atomic</code>来避免使用内核锁的开销。</p>
<h2 id="内核锁"><a href="#内核锁" class="headerlink" title="内核锁"></a>内核锁</h2><p>内核锁一般基于内核对象互斥量/信号量，它们通常是阻塞锁，会导致线程进入睡眠。锁的存在通常限制了并发范围，变并行访问为串行访问。在使用锁维护临界资源时应当争取让序列化访问最小化，真实并发最大化。</p>
<h3 id="互斥量"><a href="#互斥量" class="headerlink" title="互斥量"></a>互斥量</h3><p>在C++中一般不直接使用 <code>std::mutex</code>，而使用 <code>lock_guard</code>、<code>scoped_lock</code> 和 <code>unique_lock</code>。它们利用了RAII来自动管理加锁解锁操作，从而可以应用到<strong>包括互斥量的所有</strong> Lockable 的对象上。</p>
<p><code>unique_lock</code>相比于<code>lock_guard</code>更灵活这体现在：</p>
<ol>
<li><p>用户能够手动地加/解锁，例如在条件变量中就需要<code>unique_lock</code>以便解锁，而在取得对临界资源后进行处理时也可以暂时解锁。</p>
</li>
<li><p>可移动<br> 以下面的代码为例，这里1处是一个直接返回 <code>lk</code>，编译器可能进行 NRVO。当然即使不这么做，2作为一个直接初始化操作，也可以接受 <code>get_lock</code> 返回的将亡值，从而完成移动构造 <code>std::unique_lock&lt;std::mutex&gt;</code>。因此这里锁的控制权从 <code>get_lock</code> 转移到了 <code>process_data</code>。</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; get_lock()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">extern</span> <span class="built_in">std</span>::mutex some_mutex;</span><br><span class="line">    <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lk(some_mutex);</span><br><span class="line">    prepare_data();</span><br><span class="line">    <span class="keyword">return</span> lk;  <span class="comment">// 1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process_data</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lk(get_lock());  <span class="comment">// 2</span></span><br><span class="line">    do_something();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 有些时候，我们可能需要将某些 lock_guard 保存在一个容器中，此时有<a href="https://stackoverflow.com/questions/76340294/how-can-i-add-non-copyable-objects-into-a-map" target="_blank" rel="noopener">两种做法</a>：</p>
<ol>
<li>利用 emplace 系列函数进行本地构造<br> 但这使得我们无法用 get_lock() 函数返回了。<br> 我觉得后续也许可以引入一个 emplace_by 函数。或者这里也可以利用 operator T 进行一些优化。</li>
<li>用 unique_lock 替换 lock_guard</li>
</ol>
</li>
</ol>
<p>根据 C++ Concurrency in Action，一般会将 mutex 和临界资源一起放到一个类中进行管理，此时宜保证该临界资源是非 public 的，并且不会以引用或者指针的形式传出。这些场景例如：</p>
<ol>
<li>成员函数直接返回指针或者引用</li>
<li>友元函数</li>
<li>一个接受函数指针 P 作为参数的函数，且 P 接受了临界成员的指针或引用，并将其泄露到类外<br> 因此要避免在持有锁时调用用户传入的函数。</li>
</ol>
<h3 id="std-recursive-mutex-互斥量"><a href="#std-recursive-mutex-互斥量" class="headerlink" title="std::recursive_mutex 互斥量"></a>std::recursive_mutex 互斥量</h3><p>在大多数时候，我们是否一定需要 <code>std::recursive_mutex</code> 呢，还是往往这是一个架构问题？在一个线程中，会遇到这样的情况：</p>
<ol>
<li>模块 A 加锁</li>
<li>模块 A 调用模块 B</li>
<li>模块 B 处发生事件，需要调用模块 A 中的另一个方法</li>
<li>模块 A 再次加锁</li>
</ol>
<p>这个问题的核心在于，1-2 阶段加锁顺序和调用顺序是正的，而 3-4 阶段是反的，从而产生死锁。当然可以采用一些办法解决：</p>
<ol>
<li>将锁透传，但一个模块 A 的锁为什么要给到模块 B 呢？这个我认为破坏了封装性。</li>
<li>在调用模块 B 之前解锁，但这个未必可行，可能在解锁的时候产生了 race。当然，我们可以为这个过程引入一个锁来保护过程逻辑。</li>
</ol>
<p>问题核心在于，这个架构是否可以避免 3-4 这样的回调？如果让模块 B 返回一个 flag 告知模块 A 后续需要调用另一个方法，其实是更好的设计。</p>
<h3 id="场景讨论"><a href="#场景讨论" class="headerlink" title="场景讨论"></a>场景讨论</h3><p>我们的愿景是最大化真实并发，因此要追求较小粒度的锁(small granularity)，一个较小的粒度表现在锁所保护的临界数据较少，并且持有锁的时间较短，但粒度不可能无限小。</p>
<h4 id="删除链表节点"><a href="#删除链表节点" class="headerlink" title="删除链表节点"></a>删除链表节点</h4><p>考虑删除双向链表中的一个节点，需要修改三个节点的数据。但如果对这三个修改以此单独加锁，其实等于没有加锁。一个直截了当的解决方案是在删除过程中锁住整个链表，但粒度有点大了。</p>
<p>如果是仍然希望为每个节点维护一把锁，那么对于删除操作必须获得被删除节点和其相邻的共三把锁，当重新连接节点时，必须在获得当前节点锁的前提下尝试获取下一节点的锁（但一旦持有了下一节点的锁就可以释放当前节点的锁了），以防后继节点产生变化，这有点类似于数据库上的蟹行协议，称为lock coupling。与此同时，在遍历时同样需要按照和删除相同的上锁步骤。我有个朋友当时就对这一点很疑惑，他说我添加删除都上锁了，那为啥访问还需要加锁？锁这玩意，防君子不防小人，那我访问的时候完全可以不去获取锁的嘛，那你那边的线程加不加锁管我什么事，除非加锁、解锁和改指针的操作是原子的。那么在遍历的时候是只锁一个节点就行了，还是要蟹行呢？我们可以举一个很夸张的例子，例如我们从头遍历链表<code>[a,b,c]</code>并试图删除<code>b</code>，其过程是获取<code>a</code>的锁，然后获取<code>b=a.next</code>，然后锁住<code>b</code>，然后移除从<code>a</code>到<code>b</code>的指针。那么我们同时有一个遍历线程，它是龟兔赛跑里面属兔子的，乌龟还没出发，他就遍历到<code>a</code>了，这时候<code>a</code>没有被锁住，然后这位兔子线程释放了<code>a</code>的锁（蛮良心的，睡觉前懂得释放锁），然后拿着<code>a</code>的后继也就是<code>b</code>去睡觉去了。这时候乌龟线程才开始锁住<code>a</code>和<code>b</code>，并删除掉了<code>b</code>。乌龟线程释放完锁继续往后面遍历了，这时候<code>a</code>的后继已经是<code>c</code>了，兔子线程醒来了， 此时他还以为<code>b</code>是真的后继呢！</p>
<h4 id="线程安全的栈"><a href="#线程安全的栈" class="headerlink" title="线程安全的栈"></a>线程安全的栈</h4><p>下面我们再考虑一个线程安全的栈，其中实现了<code>empty()</code>、<code>top()</code>、<code>size()</code>、<code>push()</code>、<code>pop()</code>等常见方法。在多线程下，下面的代码中<code>pop()</code>可能使得<code>top()</code>的结果无效，这是因为在1和2两个方法<strong>间</strong>可能有另一个线程执行了<code>pop()</code>。容易看出无论这些方法内部怎么加锁都无法避免这种情况，因为这里的竞态发生在这些方法<strong>之间</strong>，C++ Concurrency in Action特别指出这属于接口设计的问题。在后面内存模型的部分，我们能看到<strong>类似的问题</strong>，原子操作虽然避免了竞态，但原子操作之间可能存在的乱序必须要被考虑。书中还指出了另一个更严重的2和3之间竞争的错误，假设有两个线程并行执行该段代码，我们期望的顺序是<code>top[1] -&gt; pop[1] -&gt; top[2] -&gt; pop[2]</code>，中括号表示执行该方法的线程。然而实际执行顺序可能是<code>top[1] -&gt; top[2] -&gt; pop[1] -&gt; pop[2]</code>。这就导致了从栈顶开始的两个元素有一个被处理了两次，另一个完全没有被处理。一个简单的解决方案是将这两个调用<strong>合并成一个带返回值的pop</strong>，使用一个mutex来管理，但Tom Cargill指出这处理方式是有问题的。这涉及到为什么标准库在设计时选择将<code>top()</code>和<code>pop()</code>两个方法，原因是可能发生在成功将元素pop后而拷贝函数失败，这个元素就被丢失，所以先取<code>top()</code>再<code>pop()</code>保证了<code>top()</code>失败情况下可以选择不执行<code>pop()</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; s;</span><br><span class="line"><span class="keyword">if</span> (! s.empty())&#123;    <span class="comment">// 1</span></span><br><span class="line">  <span class="keyword">int</span> <span class="keyword">const</span> value = s.top();    <span class="comment">// 2</span></span><br><span class="line">  s.pop();    <span class="comment">// 3</span></span><br><span class="line">  do_something(value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>使用互斥量的另一个问题是死锁，这时候锁机制避免了竞态，却可能产生线程对锁的竞争(contention)，即线程间互相等待对方的锁。死锁的产生满足四个条件：互斥、占有且请求、不可抢占和循环等待。其中等待且请求条件很关键，当完成一个操作需要获得两个及以上的锁时，死锁往往就会发生。为了解决死锁就要想办法破坏它的四个条件之一。</p>
<ol>
<li><p>破坏占有且请求<br> 可以借助于Dijkstra的银行家算法。在C++11中，可以使用标准库函数 <code>std::lock</code> 来同时上锁，不过现实情境下往往难以在申请锁时就确定自己需要哪些锁。因此在诸如数据库的系统中，会引入两段加锁协议。</p>
</li>
<li><p>破坏循环等待<br> 可以永远按照一个顺序来获得锁。以哲学家就餐问题为例，可以将筷子进行编号，并约定哲学家们总是先尝试获得编号较低的筷子，用完后总是先释放编号较高的筷子，这样就能避免死锁问题。<br> 推广来说，在加锁阶段只加锁不解锁，在解锁阶段只解锁不加锁。<br> 注意到约定哲学家们总是先拿起左手边的筷子，再拿起右手边的筷子恰恰会导致死锁问题，因为并不是<strong>对每一个哲学家</strong>的操作指定一个<strong>相对的规则</strong>，而是为<strong>所有的资源</strong>也就是锁的获取直接指定一个<strong>绝对的顺序</strong>。于是可以发现有时候去确定一个顺序并不是很容易。对 <code>swap</code> 函数，可以按照参数的顺序来加锁。例如先获得第一个参数的锁，再获得第二个参数的锁。可惜这个是相对的，例如考虑如下面代码所示的两个规则，容易发现这两个线程并行执行时死锁就会发生了。</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// thread 1</span></span><br><span class="line">swap(a, b);</span><br><span class="line"><span class="comment">// thread 2</span></span><br><span class="line">swap(b, a);</span><br></pre></td></tr></table></figure>

<p> 为了解决这个问题，一个方法是对每个对象求 Hash，从而进行排序。或者还是借助于 <code>std::lock</code> 函数。</p>
</li>
</ol>
<p>另一种解决死锁的办法从锁的角度，为锁提供层级。一个已持有低层级锁的线程是不能试图获得高层级的锁的，试图违反这一约定的行为将导致抛出异常或终止程序。注意到不能同时持有相同层级上的锁，所以这些互斥量往往形成一条链。一个层次互斥量 <code>hierarchical_mutex</code> 的实现可以对每个线程使用一个 <code>thread_local</code> 全局变量进行维护当前线程所持有的锁的层级，默认取 <code>UINT_MAX</code> ，这样线程可以获得任何层级的互斥量。</p>
<p>锁的粒度是它保护数据规模与持有时间。所以即使可以避免死锁也要注意锁的粒度对性能的影响。总的原则：</p>
<ol>
<li>一个锁应当被持有尽可能少的时间，并且在持有过程中只应该去完成必要的工作。</li>
<li>持有一个锁的同时等待另一个锁，即使不造成死锁，也要考虑其性能问题。</li>
</ol>
<p>以判定两个int是否相等为例，刚才介绍了个 <code>swap</code> 函数的实现方案，同时对两个互斥量进行加锁。但这里考虑到实际上 int 非常小，所以比较好的是分别对两个 int 加锁，复制并比较两个副本，从而避免同时持有两个锁。注意和前面 <code>top()</code> 和 <code>pop()</code> 所遇到的问题一样，在对 intA 和 intB 的读操作(LOAD)间可能发生另一个线程对 intA 的写操作，导致先前读取到的是旧值。</p>
<p>值得注意的是引起死锁的并不一定是锁，而可以扩展到造成互相等待的其他情况。例如一组线程互相 join 等待对方，相互阻塞，这导致整个程序无法往下运行。或者线程在持有锁时同时等待其他线程。此外即使在一个线程中，也会出现如同死锁的现象。例如下面的代码希望 <code>subroutine1</code> 和 <code>routine</code> 都在 <code>mut</code> 的保护下，但它在。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">subroutine1</span><span class="params">()</span></span>&#123;</span><br><span class="line">    mut.lock();</span><br><span class="line">    mut.unlock();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">routine</span><span class="params">()</span></span>&#123;</span><br><span class="line">    mut.lock();</span><br><span class="line">    subroutine1();</span><br><span class="line">    ...</span><br><span class="line">    subroutine2();</span><br><span class="line">    mut.unlock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="std-lock-的实现"><a href="#std-lock-的实现" class="headerlink" title="std::lock 的实现"></a>std::lock 的实现</h3><p><code>std::lock</code> 的作用是将多个互斥量同时上锁。如果失败时则抛出异常并释放已经获得的锁。下面代码展示了一个线程安全的<code>swap</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">some_big_object</span>;</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(some_big_object&amp; lhs,some_big_object&amp; rhs)</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">X</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    some_big_object some_detail;</span><br><span class="line">    <span class="built_in">std</span>::mutex m;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    X(some_big_object <span class="keyword">const</span>&amp; sd):some_detail(sd)&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">friend</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(X&amp; lhs, X&amp; rhs)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(&amp;lhs==&amp;rhs)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      <span class="built_in">std</span>::lock(lhs.m, rhs.m); <span class="comment">// 1</span></span><br><span class="line">      <span class="comment">// std::adopt_lock 告知这个 lock_guard 已获得锁</span></span><br><span class="line">      <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock_a(lhs.m, <span class="built_in">std</span>::adopt_lock); <span class="comment">// 2</span></span><br><span class="line">      <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock_b(rhs.m, <span class="built_in">std</span>::adopt_lock); <span class="comment">// 3</span></span><br><span class="line">      swap(lhs.some_detail, rhs.some_detail);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 注意1/2/3也可以换为以下代码</span></span><br><span class="line"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lock_a(lhs.m, <span class="built_in">std</span>::defer_lock);</span><br><span class="line"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lock_b(rhs.m, <span class="built_in">std</span>::defer_lock); <span class="comment">// unique_lock 不对互斥量上锁</span></span><br><span class="line"><span class="built_in">std</span>::lock(lock_a, lock_b); <span class="comment">// 互斥量在这里上锁</span></span><br></pre></td></tr></table></figure>

<p><code>std::lock</code>的实现借助了 <code>try_lock</code> 即 <code>_Try_lock</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> _<span class="title">Lock0</span>, <span class="title">class</span> _<span class="title">Lock1</span>, <span class="title">class</span>... _<span class="title">LockN</span>&gt; <span class="title">inline</span></span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">lock</span>(_<span class="title">Lock0</span>&amp; _<span class="title">Lk0</span>, _<span class="title">Lock1</span>&amp; _<span class="title">Lk1</span>, _<span class="title">LockN</span>&amp;... _<span class="title">LkN</span>)</span></span><br><span class="line"><span class="class">&#123;</span>   <span class="comment">// lock N mutexes</span></span><br><span class="line">    <span class="keyword">int</span> _Res = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (_Res != <span class="number">-1</span>)</span><br><span class="line">        _Res = _Try_lock(_Lk0, _Lk1, _LkN...);</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> _<span class="title">Lock0</span>&gt; <span class="title">inline</span></span></span><br><span class="line"><span class="class"><span class="title">int</span> _<span class="title">Try_lock</span>(_<span class="title">Lock0</span>&amp; _<span class="title">Lk0</span>)</span></span><br><span class="line"><span class="class">&#123;</span>   <span class="comment">// try to lock one mutex</span></span><br><span class="line">    <span class="keyword">if</span> (!_Lk0.try_lock())</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> (<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> _<span class="title">Lock0</span>, <span class="title">class</span> _<span class="title">Lock1</span>, <span class="title">class</span>... _<span class="title">LockN</span>&gt; <span class="title">inline</span></span></span><br><span class="line"><span class="class"><span class="title">int</span> _<span class="title">Try_lock</span>(_<span class="title">Lock0</span>&amp; _<span class="title">Lk0</span>, _<span class="title">Lock1</span>&amp; _<span class="title">Lk1</span>, _<span class="title">LockN</span>&amp;... _<span class="title">LkN</span>)</span></span><br><span class="line"><span class="class">&#123;</span> <span class="comment">// try to lock n-1 mutexes</span></span><br><span class="line">    <span class="keyword">int</span> _Res;</span><br><span class="line">    <span class="comment">// 如果第一个锁_Lk0直接失败，则返回失败0</span></span><br><span class="line">    <span class="keyword">if</span> (!_Lk0.try_lock())</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        <span class="comment">// 否则递归地尝试获取第二个锁_Lk1，如果失败则解开第一个锁并修改_Res为失败0</span></span><br><span class="line">        <span class="keyword">if</span> ((_Res = <span class="built_in">std</span>:: try_lock(_Lk1, _LkN...)) != <span class="number">-1</span>)</span><br><span class="line">            &#123;   <span class="comment">// tail lock failed</span></span><br><span class="line">            _Lk0.unlock();</span><br><span class="line">            ++_Res;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;<span class="keyword">catch</span>(...)&#123;</span><br><span class="line">        <span class="comment">// 如果出现异常同样解开第一个锁并返回失败0</span></span><br><span class="line">        _Lk0.unlock();</span><br><span class="line">        <span class="keyword">throw</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (_Res);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h2><p>自旋锁是一种忙等锁(busy waiting)，它适用于短时间锁定某个资源，从而避免内核锁所需要的线程睡眠产生，比如两次线程上下文切换等一系列的开销。诸如 epoll 的函数为了<strong>防止在睡眠时丢失事件</strong>，在等待 rdllist 的时候也会使用自旋锁。<br>但持有过长的自旋锁会导致浪费大量 CPU 资源。特别是在单核 CPU 上，自旋锁的使用需要审慎考虑。因为在单核CPU上同一时间只能运行一个线程，这时候如果等待锁的线程先运行，那么它势必进入空等直到时间片用完，因为获得锁的线程势必不能运行以释放锁。因此在单核 CPU 上使用内核锁进入睡眠，而不是用自旋锁忙等是一个好的选择。自旋锁常被用在对称多处理器(SMP)系统中，在多CPU的情况下保护临界区。</p>
<h3 id="自旋锁与中断处理"><a href="#自旋锁与中断处理" class="headerlink" title="自旋锁与中断处理"></a>自旋锁与中断处理</h3><p>处理中断时不能使用互斥量、信号量等让线程进入睡眠的锁，因此自旋锁常用于内核中有关中断处理的部分。内核锁必须在进程上下文（对应于中断上下文）中才能使用，这里的关闭中断的目的是为了关闭调度，因为关闭了时钟中断（时钟中断是可以被关闭的），调度器就无法运转了。这样就产生了睡死的现象。</p>
<h3 id="持有自旋锁时不能进入睡眠"><a href="#持有自旋锁时不能进入睡眠" class="headerlink" title="持有自旋锁时不能进入睡眠"></a>持有自旋锁时不能进入睡眠</h3><p>自旋锁适用于不能睡眠的场景，但双向地来说，持有自旋锁时也不能进入睡眠，否则会引起死锁。</p>
<p>如果进程 A 获得了自旋锁并且阻塞在内核态，此时内核就可能调度起了进程 B。B 也试图获得自旋锁，但因为 A 持有这自旋锁并在睡眠无法释放，那么 B 将永远自旋，A 将永远睡眠，直到 B 的时间片用尽。此外<a href="http://blog.csdn.net/samantha_sun/article/details/6365770" target="_blank" rel="noopener">另一种解释</a>认为对于不关中断的自旋锁在睡眠后可能会被重新调度，从而造成自死锁的现象。</p>
<p>Linux 内核中的自旋锁常伴随<strong>关中断</strong>和<strong>关抢占</strong>。在 Linux 中提供了 <code>spin_lock</code> 系列的关闭了抢占而不关中断，而 <code>spin_lock_irqsave</code>、<code>spin_lock_irq</code>、<code>spin_lock_bh</code> 会一道把中断也关了。</p>
<p><a href="http://blog.csdn.net/liduxun/article/details/47833143" target="_blank" rel="noopener">关抢占的原因是</a>如果一个低优先级的线程 A 获得自旋锁而紧接着被一个高优先级的进程 B 抢占，那么会造成这两个线程死锁，直到时间片用尽。这就是所谓的优先级反转，或者称为优先级倒置现象。这会严重影响性能。</p>
<p>关中断的原因是类似的，只是现在抢占的“线程”是中断。考虑一个进程 A 获得自旋锁然后被一个中断打断。此时中断处理器也试图获得同一个自旋锁，因为自旋锁不能嵌套上锁，所以中断内部就会死锁，这就是自死锁现象。并且中断处理无法被抢占（但可以被其他中断打断）。可以参考<a href="http://blog.guorongfei.com/2014/09/06/linux-interrupt-preemptive-lock/" target="_blank" rel="noopener">文章</a>和<a href="https://www.zhihu.com/question/28821201" target="_blank" rel="noopener">知乎</a>。</p>
<p>这种思想同样值得用在处理异常、信号等会破坏程序执行顺序的地方。</p>
<h3 id="自旋锁的实现"><a href="#自旋锁的实现" class="headerlink" title="自旋锁的实现"></a>自旋锁的实现</h3><p>查看原子操作部分。</p>
<h2 id="临界区"><a href="#临界区" class="headerlink" title="临界区"></a>临界区</h2><p>相对于互锁访问函数这种“有限的”原子操作，临界区允许对<strong>一段代码</strong>进行“原子操作”。临界区相对于互斥量比较轻便，这是由于互斥量能够跨进程，并且支持等待多个内核对象。同时线程在进入一个被占用的临界区时会首先尝试自旋锁，在自旋锁循环一定次数失败后再让线程进入睡眠。</p>
<h2 id="临界资源的初始化"><a href="#临界资源的初始化" class="headerlink" title="临界资源的初始化"></a>临界资源的初始化</h2><p>临界资源的初始化问题的一个重要的情景就是实现单例模式。在 C++11 后，可以有 Meyers Singleton，它满足满足初始化和定义完全在一个线程中发生，并且发生在所有其他线程访问之前。【Q】似乎这个是Lazy的。<br>如果希望带参数初始化，还可以使用 <code>std::call_once</code>，或者在 C++11 前使用 <code>pthread_once</code>。</p>
<h3 id="C-11前的朴素方案"><a href="#C-11前的朴素方案" class="headerlink" title="C++11前的朴素方案"></a>C++11前的朴素方案</h3><p>在C++11前，可以用下面的代码实现单例。这里用一把大锁保证了不会有两个线程竞争创建/访问 <code>p_singleton</code>的实例。这无疑是正确的，但却开销巨大。因为当实例被唯一地创建好后，这个函数就是纯只读的，不需要锁来保护了。事与愿违的是每次调用这个函数都需要获得锁，因此需要一种<strong>仅保护临界资源初始化过程的机制</strong>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Singleton * p_singleton = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="function">Singleton * <span class="title">get_singleton</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(mtx);</span><br><span class="line">    <span class="keyword">if</span> (p_singleton == <span class="literal">nullptr</span>) &#123; </span><br><span class="line">        p_singleton = <span class="keyword">new</span> Singleton();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> p_singleton;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="双重检查锁定模式"><a href="#双重检查锁定模式" class="headerlink" title="双重检查锁定模式"></a>双重检查锁定模式</h3><p>双重检查锁定模式(Double-checked locking pattern, DCLP)指的是在加锁前先进行一次验证是否可以加锁，目的是减少加锁的开销，具体的做法是先检查一遍 <code>p_singleton</code> 是否为 <code>nullptr</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Singleton * p_singleton = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="function">Singleton * <span class="title">get_singleton</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (p_singleton == <span class="literal">nullptr</span>) &#123; <span class="comment">// a</span></span><br><span class="line">        <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(mtx);</span><br><span class="line">        <span class="keyword">if</span> (p_singleton == <span class="literal">nullptr</span>) &#123; <span class="comment">// b</span></span><br><span class="line">            p_singleton = <span class="keyword">new</span> Singleton();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> p_singleton;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这种加锁方式也是有<a href="http://blog.jobbole.com/86392/" target="_blank" rel="noopener">理论上的风险</a>的，例如 <code>p_singleton</code> 不是原子的，甚至都不是 volatile 的。基于我们与编译器的约定，编译器完全可以认为 <code>p_singleton</code> 的值不会发生变化，因此直接将两层 <code>if</code> 削掉一层。</p>
<p>但即使将 <code>p_singleton</code> 套上 <code>std::atomic</code>、加上 <code>volatile</code>，这个代码<strong>仍然是错误的</strong>。原因在于 <code>p_singleton = new Singleton()</code> 这条语句不是原子的。因为该语句的执行分为三步</p>
<ol>
<li>分配内存</li>
<li>构造对象</li>
<li>指针指向对象</li>
</ol>
<p>尽管实践中编译器没有理由去进行这样的重排，但<strong>编译器</strong>在理论上可以在2构造对象前执行1内存分配和3指针指向操作。假设线程在1/3步骤完毕之后被挂起而来不及执行2步骤，而另一个线程开始访问 a 处的代码，注意到此时<code>p_singleton</code>已经不是<code>nullptr</code>了，于是函数会返回一段未初始化的内存。</p>
<p>继续思考发现，第一个线程此时已经在初始化 <code>p_singleton</code>，这第二个线程就<strong>不应该有机会执行到a处的代码</strong>。试想即使第二个线程知道另一个线程在初始化了，那它又能做什么呢？因为这个函数的声明是要么初始化并返回指针，要么直接返回指针。选择前者会破坏第一个线程的初始化过程，选择后一个会造成上面说的结果。不然总不能 throw 吧。因此在 a 处对 <code>p_singleton</code> 进行保护是非常有必要的。</p>
<p>在后面对类型模型的讨论中，将讲解如何<strong>通过添加 fence 或者借助 acquire/release 语义来写出一个正确的 DCLP 代码</strong>。</p>
<h3 id="call-once方案"><a href="#call-once方案" class="headerlink" title="call_once方案"></a>call_once方案</h3><p>在下面的代码中，只会输出一行 <code>Called once</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::once_flag flag;  </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_once</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="built_in">std</span>::call_once(flag, []()&#123; <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Called once"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; &#125;);  </span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="built_in">std</span>::<span class="function">thread <span class="title">t1</span><span class="params">(do_once)</span></span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="function">thread <span class="title">t2</span><span class="params">(do_once)</span></span>;</span><br><span class="line">    </span><br><span class="line">    t1.join();</span><br><span class="line">    t2.join();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里的 <code>std::once_flag</code> 不能被拷贝和移动，其实相当于一个锁，<code>call_once</code> 是借助于 runtime 函数 <code>__crtInitOnceExecuteOnce</code> 实现的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> _<span class="title">Fn</span>,</span></span><br><span class="line"><span class="class">    <span class="title">class</span>... _<span class="title">Args</span>&gt; <span class="title">inline</span></span></span><br><span class="line"><span class="class">    <span class="title">void</span> (<span class="title">call_once</span>)(<span class="title">once_flag</span>&amp; _<span class="title">Flag</span>, _<span class="title">Fn</span>&amp;&amp; _<span class="title">Fx</span>, _<span class="title">Args</span>&amp;&amp;... _<span class="title">Ax</span>)</span></span><br><span class="line"><span class="class">    &#123;</span>   <span class="comment">// call _Fx(_Ax...) once</span></span><br><span class="line">    <span class="comment">// 定义一个_Tuple类型</span></span><br><span class="line">    <span class="keyword">typedef</span> tuple&lt;_Fn&amp;&amp;, _Args&amp;&amp;..., _XSTD exception_ptr&amp;&gt; _Tuple;</span><br><span class="line">    <span class="comment">// _Seq的值索引上面的_Tuple</span></span><br><span class="line">    <span class="keyword">typedef</span> make_integer_sequence&lt;<span class="keyword">size_t</span>, <span class="number">1</span> + <span class="keyword">sizeof</span>...(_Args)&gt; _Seq;</span><br><span class="line"></span><br><span class="line">    _XSTD exception_ptr _Exc;</span><br><span class="line">    <span class="comment">// 将回调函数参数打包到 _Tuple 类型里面，最后一个是 exception_ptr</span></span><br><span class="line">    _Tuple _Tup(_STD forward&lt;_Fn&gt;(_Fx), _STD forward&lt;_Args&gt;(_Ax)..., _Exc);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 使用 _Tup 里面的上下文特化 _Callback_once 函数模板</span></span><br><span class="line">    _Lambda_fp_t _Fp = &amp;_Callback_once&lt;_Tuple, _Seq, <span class="number">1</span> + <span class="keyword">sizeof</span>...(_Args)&gt;;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 在 xonce.cpp 中实际调用了 __crtInitOnceExecuteOnce的 WINAPI</span></span><br><span class="line">    <span class="keyword">if</span> (_Execute_once(_Flag, _Fp, _STD addressof(_Tup)) != <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_Exc)</span><br><span class="line">        _<span class="function">XSTD <span class="title">rethrow_exception</span><span class="params">(_Exc)</span></span>;</span><br><span class="line"></span><br><span class="line">    _XGetLastError();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">// xonce.cpp</span></span><br><span class="line">_STD_BEGIN</span><br><span class="line">_CRTIMP2_PURE <span class="keyword">int</span> __CLRCALL_PURE_OR_CDECL _Execute_once(</span><br><span class="line">    once_flag&amp; _Flag, _Lambda_fp_t _Lambda_fp, <span class="keyword">void</span> *_Pv) _NOEXCEPT</span><br><span class="line">    &#123;   <span class="comment">// wrap Win32 InitOnceExecuteOnce()</span></span><br><span class="line">    <span class="keyword">static_assert</span>(<span class="keyword">sizeof</span>(_Flag._Opaque) == <span class="keyword">sizeof</span>(INIT_ONCE), <span class="string">"invalid size"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (__crtInitOnceExecuteOnce(</span><br><span class="line">        <span class="keyword">reinterpret_cast</span>&lt;PINIT_ONCE&gt;(&amp;_Flag._Opaque),</span><br><span class="line">        <span class="keyword">reinterpret_cast</span>&lt;PINIT_ONCE_FN&gt;(_Lambda_fp),</span><br><span class="line">        _Pv, <span class="number">0</span>));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>虽然可以通过 Meyer’s Singleton 来做线程安全的单例，但如果想带参数地初始化是困难的。可以借鉴<a href="https://liam.page/2020/10/27/implement-a-singleton-class-template-in-cxx/" target="_blank" rel="noopener">下面的代码</a></p>
<ol>
<li>使用 Meyer’s Singleton 声明一个全局单例的 once_flag</li>
<li>借助这个 once_flag 就可以 call_once 地初始化单例了</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> F&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Singleton</span> &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> T* <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">static</span> T* p&#123;<span class="literal">nullptr</span>&#125;;</span><br><span class="line">        <span class="built_in">std</span>::call_once(flag, F());</span><br><span class="line">        <span class="keyword">return</span> p;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">     <span class="keyword">static</span> <span class="built_in">std</span>::once_flag flag;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="built_in">std</span>::once_flag Singleton&lt;T&gt;::flag;</span><br></pre></td></tr></table></figure>

<h2 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h2><p>相对于临界区，读写锁能提供更精细的控制，它适用于写操作远少于读操作的数据结构。读写锁允许一个写线程独占访问，而多个读线程并行访问。当写线程需要独占访问时，它需要获得一个排它锁。如果此时有另外的线程持有排它锁或者共享锁，那么写线程就会被阻塞。当读线程需要共享访问时，只要没有线程持有排它锁，那么他就可以立即获得共享锁。读写锁的过程可以参照来自<a href="http://ytliu.info/blog/2013/04/14/tong-bu-yuan-yu-xue-xi-bi-ji-lock,rcuhe-transaction/" target="_blank" rel="noopener">博文</a>的论述</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Read object begin</span><br><span class="line">  P(object.lock)</span><br><span class="line">  AtomicAdd(object.activeReader, 1)</span><br><span class="line">  V(object.lock)</span><br><span class="line">  Do Actual Read</span><br><span class="line">  AtomicAdd(object.activeReaders, −1)</span><br><span class="line">end</span><br><span class="line">Write object begin</span><br><span class="line">  P(object.lock)</span><br><span class="line">  while object.activeReaders != 0 do delay</span><br><span class="line">  Do Actual Write</span><br><span class="line">  V(object.lock)</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<p>对读写锁 Windows API 提供了所谓的 SRW 系列函数，Linux 提供了 rwlock 系列函数。在C++14中终于提供了<code>std::shared_timed_mutex</code>来实现读写锁，C++17中提供了<code>std::shared_mutex</code>来实现一个<strong>没有定时的读写锁</strong>。</p>
<p>这从设计上看来这是有点本末倒置的，为什么要在C++17实现一个功能更少的类呢？<a href="https://stackoverflow.com/questions/40207171/why-shared-timed-mutex-is-defined-in-c14-but-shared-mutex-in-c17" target="_blank" rel="noopener">SoF指出这是出于性能原因</a>。在C++14制定时，原本的<code>std::shared_mutex</code>拥有定时功能，但稍后发现去掉定时功能能够提高效率，例如借助Windows上的<code>SRWLOCK</code>机制可以高效简便实现没有定时的读写锁，所以后来C++14版本的 <code>std::shared_mutex</code> 被重命名到 <code>std::shared_timed_mutex</code>，而一个没有定时的 <code>std::shared_mutex</code> 在 C++17 提供。</p>
<p>在C++17中读锁可以声明为 <code>std::shared_lock&lt;std::shared_mutex&gt;</code>(<code>shared_lock</code>来自C++14)，写锁可以声明为<code>std::unique_lock&lt;std::shared_mutex&gt;</code>，如此跨越三个版本的标准才最终完成的实现，你只有在C++中才能看到。</p>
<p>从实现上来看，无论是关键段、互斥量、信号量，甚至是条件变量都可以实现读写锁。</p>
<ol>
<li><p>关键段的实现方式<br> 这里摘录了<a href="http://blog.csdn.net/StanfordZhang/article/details/40784975" target="_blank" rel="noopener">CSDN上的一个实现</a>。其思想<a href="https://paste.ubuntu.com/p/9vy7wgbBVS/" target="_blank" rel="noopener">如下</a></p>
</li>
<li><p>互斥量的实现方式<br> 注意读操作时要获取写锁以免脏读。<br> 作为优化，为了避免多个读线程竞争写锁的情况，还需要一个读锁。只有竞争到读锁的线程才能去锁定写锁。其过程如下</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 写</span></span><br><span class="line">lock(mutex_write);</span><br><span class="line">write();</span><br><span class="line">unlock(mutex_write);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读</span></span><br><span class="line">lock(mutex_read);</span><br><span class="line"><span class="keyword">if</span>(readers == <span class="number">0</span>)</span><br><span class="line">    lock(mutex_write);</span><br><span class="line">readers++;</span><br><span class="line">unlock(mutex_read);</span><br><span class="line">read();</span><br><span class="line">lock(mutex_read);</span><br><span class="line">readers--;</span><br><span class="line"><span class="keyword">if</span>(readers == <span class="number">0</span>)</span><br><span class="line">    unlock(mutex_write);</span><br><span class="line">unlock(mutex_read);</span><br></pre></td></tr></table></figure></li>
<li><p>信号量的实现方式<br> 这里的 <code>Swait(sem, t, d)</code> 表示信号量 <code>sem</code> 的 P 操作需要 <code>t</code> 个资源，并且会消耗 <code>d</code> 个资源。<code>Ssignal(sem, d)</code> 表示信号量 <code>sem</code> 的 V 操作产生 <code>d</code> 个资源。这里 <code>Swait</code> 类似 <code>std::lock</code>，可以同时对若干个信号量上锁，从而避免死锁。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">// 初始化</span><br><span class="line">max_reader = n; // 最多允许n个读者读</span><br><span class="line">Sinit(sem_read, max_reader);</span><br><span class="line">Sinit(sem_write, 1);</span><br><span class="line"></span><br><span class="line">// 写</span><br><span class="line">Swait(sem_write, 1, 1; sem_read, max_reader, 0);</span><br><span class="line">write();</span><br><span class="line">Ssignal(sem_write, 1);</span><br><span class="line"></span><br><span class="line">// 读</span><br><span class="line">Swait(sem_write, 1, 0; sem_read, 1, 1);</span><br><span class="line">write();</span><br><span class="line">Ssignal(sem_read, 1);</span><br></pre></td></tr></table></figure></li>
<li><p>条件变量的实现方式</p>
</li>
</ol>
<h1 id="约束线程间并发行为-无锁"><a href="#约束线程间并发行为-无锁" class="headerlink" title="约束线程间并发行为(无锁)"></a>约束线程间并发行为(无锁)</h1><p>无锁情况下，主要存在下面几个问题：</p>
<ol>
<li>并发访问</li>
<li>GC</li>
<li>编译器和处理器的重排和乱序</li>
</ol>
<h2 id="锁无关和原子操作"><a href="#锁无关和原子操作" class="headerlink" title="锁无关和原子操作"></a>锁无关和原子操作</h2><h3 id="锁无关简介"><a href="#锁无关简介" class="headerlink" title="锁无关简介"></a>锁无关简介</h3><p>锁无关(Lock-Free)是一种比无干扰(Obstruction-Free)高层次的并发模型，它是一个容易混淆的概念。如果我们的算法中不使用锁，称为 Lockless。但锁无关并不是不用锁，而是确保各个线程在访问共享资源时之间<strong>不会互相阻塞</strong>，从而使得整个程序整体上能够始终向后执行。也就是说，如果线程 T1 被阻塞在某个操作上，那么一定有另一个线程 T2 在某个操作上成功了，通常我们也会这样证明一个算法是锁无关的。相对应地，如果使用内核锁，如果一个获得内核锁的线程被挂起或者挂掉，这容易导致其他拥有锁的线程陷入永久等待。但即使借助于原子操作，也会产生死锁、竞态的问题，例如自旋锁的死锁问题和使用CAS时可能出现的<a href="http://www.isnowfy.com/understand-to-lock-free/" target="_blank" rel="noopener">ABA问题</a>。</p>
<p>加锁操作通常存在着<a href="http://blog.csdn.net/liuxuejiang158blog/article/details/17559901" target="_blank" rel="noopener">一些问题</a>，锁无关的编程虽然复杂，但相对于使用锁，锁无关的可伸缩性和性能方面可能会强于锁相关的算法，并且如果我们能够有序地组织各个线程“各行其道”，就能减少锁的使用。通常来说一个基于锁的算法在高竞争的系统中有较好的效率，因为当发生竞态时线程进行睡眠而不是立即重试，但在一般的情境中，不使用锁往往能避免上下文切换的开销。</p>
<p>相应的还有一个无阻塞(Non-blocking)的概念，无阻塞的限制条件要弱于锁无关。属于无阻塞算法而不属于无锁算法的常见例子是自旋锁。在自旋锁中：</p>
<ol>
<li>所有的线程都不会进入睡眠，因此是非阻塞算法</li>
<li>考虑当获得锁的线程因为一些原因被暂停时，所有的其他线程仍然需要在原地自旋<strong>忙等</strong>，因而自旋锁不是无锁算法。</li>
</ol>
<p>由此可见，锁无关编程中定义了如原子操作、CAS之类的范式，它们本身都是不涉及到锁的。但为了确保读写成功，往往需要尝试若干次，但这个多次尝试造成的<strong>等待</strong>本身不属于锁无关的范畴。并且这个等待的过程中，总有人能持续推进。</p>
<p>其实锁机制本身也是<strong>和等待没有关系的</strong>，因为有些操作中的等待是客观的，不能看到锁，就想到阻塞和等待。即使不停 <code>while</code> 去轮询，没有锁，但还是存在忙等。</p>
<h3 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h3><p>原子操作是常见的实现锁无关编程的方式。</p>
<p>An operation acting on shared memory is atomic if it completes in a single step relative to other threads。</p>
<p><a href="https://preshing.com/20130618/atomic-vs-non-atomic-operations/" target="_blank" rel="noopener">原子操作具有以下的特点</a></p>
<ol>
<li>When an atomic store is performed on a shared variable, no other thread can observe the modification half-complete. </li>
<li>When an atomic load is performed on a shared variable, it reads the entire value as it appeared at a single moment in time. Non-atomic loads and stores do not make those guarantees.</li>
</ol>
<p>原子操作指的是<strong>不可被中断的一系列操作</strong>。原子操作保证当前操作中不发生线程切换，因此保证了其他的线程不可能访问这个资源。</p>
<h4 id="对C-中原子操作的特别说明"><a href="#对C-中原子操作的特别说明" class="headerlink" title="对C++中原子操作的特别说明"></a>对C++中原子操作的特别说明</h4><p>下面对C++中的原子操作做一个特别说明，展示声明一个<code>std::atomic</code>变量是必要的。<strong>除非放弃遵守C++标准，那么不要尝试仅通过non-atomic变量，和一些volatile、atomic_thread_fence等怪异手段来约束不同线程间不同变量的操作行为</strong>。</p>
<h5 id="atomic对象是线程间order的桥梁"><a href="#atomic对象是线程间order的桥梁" class="headerlink" title="atomic对象是线程间order的桥梁"></a>atomic对象是线程间order的桥梁</h5><p>因为C++11前根本没有考虑对多线程或者内存模型提供语言级别的支持(这点Java就做得比较好)。事实上，C++标准规定data race，即并发地去修改一个对象是UB的，所以编译器优化可以不考虑多线程的情况，<a href="https://www.zhihu.com/question/27026846" target="_blank" rel="noopener">可能导致错误</a>。在线程A中对x的修改，以及在线程B中对y的修改，可能都是不可见的。为了约束跨线程间store/load的顺序，只有求助与语言外的工具，例如CPU指令或者操作系统正面的支持。</p>
<p>下面展示了<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/" target="_blank" rel="noopener">早期GCC编译器的问题</a>，可以发现，<strong>一个线程是没办法感知某个变量是可能在线程外被修改的</strong>。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">int</span> v;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">int</span> set_v)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (set_v)</span><br><span class="line">    v = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// GCC 3.3.4--4.3.0 O1</span></span><br><span class="line">f:</span><br><span class="line">        pushl   %ebp</span><br><span class="line">        movl    %esp, %ebp</span><br><span class="line">        cmpl    $<span class="number">0</span>, <span class="number">8</span>(%ebp)</span><br><span class="line">        movl    $<span class="number">1</span>, %eax</span><br><span class="line">        cmove   v, %eax        ; load (maybe)</span><br><span class="line">        movl    %eax, v        ; store (always)</span><br><span class="line">        popl    %ebp</span><br><span class="line">        ret</span><br></pre></td></tr></table></figure>

<p>在这个问题中考虑调用<code>f(0)</code>，单线程情况下肯定不会执行<code>v=1</code>。在gcc生成的代码中，也确实看到if被优化掉了，始终执行<code>movl %eax, v</code>，显然编译器认为<code>f</code>并不会被修改。但在多线程下，<code>set_v</code>完全有可能在线程外被修改。</p>
<p>在C++11之后，增加了<a href="https://en.cppreference.com/w/cpp/atomic/memory_order#Inter-thread_happens-before" target="_blank" rel="noopener">原子操作的定义</a>，其中也定义了各种order，例如Happens-before啥的。通过原子变量和原子操作，就可以指定order。一般的思路是这样的：</p>
<ol>
<li>按照原来单线程的Sequenced-before，单线程中的各个操作是有序的<br> 当然，Compiler和CPU可以reorder。</li>
<li>atomic对象和atomic对象之间可能构成synchronizes-with关系<br> 那么通过<strong>两个atomic对象之间构成的桥梁</strong>，就可以联系两个线程之间的其他的<strong>哪怕是non-atomic</strong>的对象了。<br> 所以atomic对象是不可或缺的。</li>
</ol>
<h5 id="store-load的原子性"><a href="#store-load的原子性" class="headerlink" title="store/load的原子性"></a>store/load的原子性</h5><p><a href="https://www.zhihu.com/question/27026846" target="_blank" rel="noopener">知道x86汇编要求</a>对任意位置的1字节，以及对<strong>2/4/8对齐</strong>的2/4/8长度的整型读取都<strong>是原子的</strong>，但是 C++11 前却不能假设甚至是对一个 <code>int</code> 赋值的操作是原子的，而在 C++11 后就可以使用 <code>std::atomic</code> 来显式声明一个原子变量。<br>这是因为考虑一些违反 strict aliasing 的胡乱 cast 破坏了对齐，C++ 无法保证从内存 load 一个 plain 的值是原子的。</p>
<h4 id="原子操作的分类"><a href="#原子操作的分类" class="headerlink" title="原子操作的分类"></a>原子操作的分类</h4><p>原子操作<a href="https://preshing.com/20150402/you-can-do-any-kind-of-atomic-read-modify-write-operation/" target="_blank" rel="noopener">可以分为</a>简单的原子 Store Load，以及更为复杂的 RMW 操作，比如 CAS、FAA、TAS、TTAS 等。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;&gt;::fetch_add()</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;&gt;::fetch_sub()</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;&gt;::fetch_and()</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;&gt;::fetch_or()</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;&gt;::fetch_xor()</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;&gt;::exchange()</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;&gt;::compare_exchange_strong()</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;&gt;::compare_exchange_weak()</span><br></pre></td></tr></table></figure>

<p>一般来说可以借助<strong>原子的CAS</strong>，即 C++ 中的 <code>compare_exchange_weak</code>，实现其他的原子操作。</p>
<p>通过解答下面两个问题，可以看到原子操作的一般使用场景：</p>
<ol>
<li><p>能通过原子操作实现复杂的逻辑么？<br> 答案是可以的，下面的代码乐观地前置了大部分操作，但是对其他线程可见的只有最后一步到位的 <code>compare_exchange_weak</code> 修改。</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">uint32_t</span> atomicDecrementOrHalveWithLimit(<span class="built_in">std</span>::atomic&lt;<span class="keyword">uint32_t</span>&gt;&amp; shared)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">uint32_t</span> oldValue = shared.load();</span><br><span class="line">    <span class="keyword">uint32_t</span> newValue;</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (oldValue % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line">            newValue = oldValue - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            newValue = oldValue / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (newValue &lt; <span class="number">10</span>)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (!shared.compare_exchange_weak(oldValue, newValue));</span><br><span class="line">    <span class="keyword">return</span> oldValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>能通过原子操作操作多个变量么？<br> 答案是可以的，可以将多个变量封装到一个 struct 里面，然后操作这个 struct。</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Terms</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> x;</span><br><span class="line">    <span class="keyword">uint32_t</span> y;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">std</span>::atomic&lt;Terms&gt; terms;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">atomicFibonacciStep</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Terms oldTerms = terms.load();</span><br><span class="line">    Terms newTerms;</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">    &#123;</span><br><span class="line">        newTerms.x = oldTerms.y;</span><br><span class="line">        newTerms.y = oldTerms.x + oldTerms.y;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (!terms.compare_exchange_weak(oldTerms, newTerms));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="如何判断是不是原子操作"><a href="#如何判断是不是原子操作" class="headerlink" title="如何判断是不是原子操作"></a>如何判断是不是原子操作</h4><p>举个例子，<code>i++</code> 是原子操作么？答案并不是。可 <code>i++</code> 不就是一条 INC 指令么，为什么不是原子？别忘了执行只是流水线的一部分，还有访存、解码、写回啥的呢。所以需要考虑三个维度：</p>
<ol>
<li>内存</li>
<li>CPU 缓存</li>
<li>寄存器和指令</li>
</ol>
<p>在这些维度中，还需要考虑是否对齐。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/syscall.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> gettid() syscall(SYS_gettid)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> acc = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">start_routine</span><span class="params">(<span class="keyword">void</span>* arg)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++)&#123;</span><br><span class="line">        acc++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    acc = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pthread_t</span> tid1;</span><br><span class="line">    pthread_create(&amp;tid1, <span class="literal">NULL</span>, start_routine, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pthread_t</span> tid2;</span><br><span class="line">    pthread_create(&amp;tid2, <span class="literal">NULL</span>, start_routine, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pthread_t</span> tid3;</span><br><span class="line">    pthread_create(&amp;tid3, <span class="literal">NULL</span>, start_routine, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pthread_t</span> tid4;</span><br><span class="line">    pthread_create(&amp;tid4, <span class="literal">NULL</span>, start_routine, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> a1, a2;</span><br><span class="line">    pthread_join(tid1, <span class="number">0</span>);</span><br><span class="line">    pthread_join(tid2, <span class="number">0</span>);</span><br><span class="line">    pthread_join(tid3, <span class="number">0</span>);</span><br><span class="line">    pthread_join(tid4, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"res %d\n"</span>, acc);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="互锁访问函数和CAS操作"><a href="#互锁访问函数和CAS操作" class="headerlink" title="互锁访问函数和CAS操作"></a>互锁访问函数和CAS操作</h3><p>操作系统提供的原子 API 常借助于某些 CPU，比如 Intel 处理器提供的指令。这些指令能够对<strong>某些类型</strong>实现<strong>某些原子操作</strong>。对 SMP 架构而言，会出现多个核心并发写的情况，这个涉及到后面的内存模型，并且这里可以暂时忽略这个问题。<br>Windows API 提供了一系列 Interlocked 开头的互锁访问函数，这些函数在处理器层面被保证独占访问。其中一个很关键的便是 <code>InterlockedCompareExchange(PLONG dest, LONG value, LONG old)</code> 函数，这个函数提供了对 <code>LONG</code> 类型的原子的 CAS 操作。显然，通过内核锁能够方便地实现原子语义，但内核锁会导致线程睡眠，而这可以通过 CAS 避免。</p>
<p>例如下面的 <code>InterlockedExchange</code> 函数，设置新值并返回老值，这就利用了 CAS。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">LONG <span class="title">InterlockedExchange</span><span class="params">(LONG <span class="keyword">volatile</span> * target, LONG value)</span></span>&#123;</span><br><span class="line">  LONG old;</span><br><span class="line">  <span class="keyword">do</span>&#123;</span><br><span class="line">    old = *target;</span><br><span class="line">  &#125;<span class="keyword">while</span>(! InterlockedCompareExchange(target, value, old));</span><br><span class="line">  <span class="keyword">return</span> old;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里的 <code>do-while</code> 循环保证了在 <code>InterlockedCompareExchange</code> 失败之后再来一遍能够再来一遍直到成功。但是<strong>不能将这个循环和自旋锁中的忙等混淆</strong>，从而认为CAS不是锁无关的。这是因为</p>
<ol>
<li>CAS实际上并没有“持有”临界资源，它只需要一个指令就能结束战斗。<br> 因此，某个线程被 block 住了，或者被睡眠了，也不会导致其他线程忙等或者死锁。反而因为竞争减少了，可能导致 CAS 成功率变高。</li>
<li>如果这里的 CAS 失败了，说明另外一个线程的 CAS 成功了。</li>
</ol>
<p>因此可以看出CAS在这里对竞争访问实际上是“消极防御”的态度，也就是所谓的**乐观锁(Optimistic Locking)**。乐观锁是一种非独占锁，它并不是向内核锁一样直接让竞争者们睡眠，而是返回一个失败的状态。相对应的，之前的内核锁和自旋锁等机制属于悲观锁、独占锁。相比乐观锁，悲观锁有以下的弱点</p>
<ol>
<li>上下文切换造成的性能开销</li>
<li>可能造成的死锁问题</li>
<li>优先级倒置<br> 也就是持有锁的线程被其他线程抢占了。</li>
</ol>
<h3 id="原子操作底层实现"><a href="#原子操作底层实现" class="headerlink" title="原子操作底层实现"></a>原子操作底层实现</h3><p>原子操作一般有两种实现方式：</p>
<ol>
<li>使用锁或者 CPU 的指令等机制来维持原子性</li>
<li>当出现并发写等破坏原子性的情况时<strong>让操作失败</strong><br> 如果最终要执行，则需要在一个循环不断尝试。</li>
</ol>
<p>需要注意的是，原子操作并不一定就能够提高效率，也就是所谓的scalability，这是由于涉及对共享对象操作的原子指令都可能造成cache invalidation，也就是需要重新刷新缓存行。另外原子操作本身也是不意味着就快，如<a href="https://www.ibm.com/developerworks/cn/linux/l-rcu/" target="_blank" rel="noopener">下图</a>所示<br><img src="/img/concur/speed_cmp.jpg"></p>
<p>在 std::atomic 这一章中讨论了 CAS 操作：</p>
<ol>
<li>对于通常情况，可能会使用自旋锁甚至内核锁</li>
<li>对于一些特殊类型，比如 int 等，会借助于 CPU 的原子操作，而 CPU 原子操作的实现可能借助于总线锁、缓存锁等机制<br> 细究上面WINAPI的 <code>InterlockedCompareExchange</code>，容易猜到它的实现方式来自于 CPU 的硬件支持，因为它只能为特定数据类型提供服务。事实上，这里<a href="http://blog.csdn.net/zhangliang1223/article/details/7614027" target="_blank" rel="noopener">用了x86中的<strong>cmpxchg</strong>命令</a>。</li>
</ol>
<p>下面介绍一下 LOCK 指令对<a href="https://albk.tech/%E8%81%8A%E8%81%8ACPU%E7%9A%84LOCK%E6%8C%87%E4%BB%A4.html" target="_blank" rel="noopener">总线锁和缓存锁的选用</a>：</p>
<ol>
<li>总线锁<br> <code>LOCK#</code>信号就是总线锁，处理器使用 <code>LOCK#</code> 信号达到锁定总线，来解决原子性问题。当一个处理器往总线上输出 <code>LOCK#</code> 信号时，<strong>其它处理器的请求将被阻塞</strong>，此时该处理器此时独占共享内存。<br> 总线锁这种做法锁定的范围太大了，导致CPU利用率急剧下降，因为<strong>LOCK#把CPU和内存之间的通信锁住了</strong>，这使得锁定时期间，其它处理器不能访问内存，所以总线锁的开销比较大。</li>
<li>缓存锁<br> 如果访问的内存区域已经缓存在处理器的缓存行中，P6 系统和之后系列的处理器则不会声明 <code>LOCK#</code>信号，它会对 CPU 的缓存中的缓存行进行锁定.在锁定期间，其它CPU不能同时缓存此数据，在修改之后，通过<strong>缓存一致性协议</strong>来保证修改的原子性，这个操作被称为“缓存锁”。</li>
</ol>
<p>需要注意，虽然总线锁和缓存锁可能有较大的性能开销，但这只是处理器级别针对于单个指令而言的，最多会导致某些指令执行变慢。而内核锁则涉及操作系统，特别是线程间的上下文切换了。</p>
<p>特别地，当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行时，也会使用总线锁。<br>诸如BTS、BTR、BTC、XADD、XCHG、ADD、OR等指令自带总线锁。注意CMPXCHG应该不默认是原子的，对于单核，可以不加LOCK；但是对于多核，需要加LOCK。</p>
<h4 id="CAS操作的实现"><a href="#CAS操作的实现" class="headerlink" title="CAS操作的实现"></a>CAS操作的实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;atomic&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; ai;</span><br><span class="line">    <span class="keyword">int</span> z = <span class="number">10</span>;</span><br><span class="line">    ai.compare_exchange_weak(z, <span class="number">11</span>, <span class="built_in">std</span>::memory_order_seq_cst);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d"</span>, ai.load());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看一下反汇编 <code>g++ --std=c++11 cas.cpp -o cas -S</code>，可以发现是通过 lock cmpxchgl 实现的<br><code>_ZStanSt12memory_orderSt23__memory_order_modifier</code> 是 <code>std::operator&amp;(std::memory_order, std::__memory_order_modifier)</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">.cfi_startproc</span><br><span class="line">pushq   %rbp</span><br><span class="line">.cfi_def_cfa_offset 16</span><br><span class="line">.cfi_offset 6, -16</span><br><span class="line">movq    %rsp, %rbp</span><br><span class="line">.cfi_def_cfa_register 6</span><br><span class="line">subq    $48, %rsp</span><br><span class="line">movq    %rdi, -24(%rbp)</span><br><span class="line">movq    %rsi, -32(%rbp)</span><br><span class="line">movl    %edx, -36(%rbp)</span><br><span class="line">movl    %ecx, -40(%rbp)</span><br><span class="line">movl    %r8d, -44(%rbp)</span><br><span class="line">movl    -44(%rbp), %eax</span><br><span class="line">movl    $65535, %esi</span><br><span class="line">movl    %eax, %edi</span><br><span class="line">call    _ZStanSt12memory_orderSt23__memory_order_modifier</span><br><span class="line">movl    %eax, -4(%rbp)</span><br><span class="line">movl    -40(%rbp), %eax</span><br><span class="line">movl    $65535, %esi</span><br><span class="line">movl    %eax, %edi</span><br><span class="line">call    _ZStanSt12memory_orderSt23__memory_order_modifier</span><br><span class="line">movl    %eax, -8(%rbp)</span><br><span class="line">movl    -36(%rbp), %ecx</span><br><span class="line">movq    -24(%rbp), %rdx</span><br><span class="line">movq    -32(%rbp), %rax</span><br><span class="line">movl    (%rax), %eax</span><br><span class="line">lock cmpxchgl   %ecx, (%rdx)</span><br><span class="line">movl    %eax, %ecx</span><br><span class="line">sete    %al</span><br><span class="line">testb   %al, %al</span><br><span class="line">jne .L21</span><br><span class="line">movq    -32(%rbp), %rdx</span><br><span class="line">movl    %ecx, (%rdx)</span><br></pre></td></tr></table></figure>

<p>下面看复杂类型</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Comp</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> x = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">double</span> y = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> z = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">int</span> w = <span class="number">4</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">test</span><span class="params">(<span class="built_in">std</span>::atomic&lt;Comp&gt;&amp; ai, Comp &amp;z, Comp &amp;y)</span> </span>&#123;</span><br><span class="line">    ai.compare_exchange_weak(z, y, <span class="built_in">std</span>::memory_order_seq_cst);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::atomic&lt;Comp&gt; ai;</span><br><span class="line">    Comp z;</span><br><span class="line">    Comp y;</span><br><span class="line">    test(ai, z, y);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d"</span>, ai.load().x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="使用CAS操作实现的无锁链表"><a href="#使用CAS操作实现的无锁链表" class="headerlink" title="使用CAS操作实现的无锁链表"></a>使用CAS操作实现的无锁链表</h3><p>因为文章太长，所以被拆出来一篇<a href="/2017/12/28/lockfree-queue/">新文章</a>。</p>
<h3 id="CAS-和-LL-SC"><a href="#CAS-和-LL-SC" class="headerlink" title="CAS 和 LL/SC"></a>CAS 和 LL/SC</h3><h3 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h3><p>伴随着CAS的是可能存在的ABA问题。原则上，这不是CAS造成的，毕竟CAS只是比较相等而已，但问题是<strong>相等并不代表没有发生变化</strong>。<br><del>ABA问题的根源是从内存中取出值和CAS这两个操作不是原子的，因此可能在这两个过程中发生切换。</del><br>ABA问题的根源是我们使用CAS操作时，希望是和某个时刻的状态来Compare的。但是在实现上，我们却只比较两个状态的值是否相等，而忽略了时刻。<br>初看ABA问题，会觉得这也是个问题？相等就行了啊，清朝的石头和秦朝的石头不都是石头么？我最终一致就行了，管它中途发生什么呢。但实际上ABA描述的是一个“浅层的”的比较，<strong>当涉及多个对象时</strong>，不能因为一个对象不变，就判断所有对象组成的系统就不变。<br>例如以<a href="https://www.zhihu.com/question/23281499" target="_blank" rel="noopener">栈<code>A -&gt; B -&gt; C</code></a>为例，很可能一个线程在试图pop栈顶A的时候被调度走，新的线程先弹出A再弹出B再压入A。这时候老线程被调度回来，发现栈顶还是A，就会认为栈没有发生变化，还是<code>A -&gt; B -&gt; C</code>，但实际上栈已经变成了<code>A -&gt; C</code>了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">()</span>:</span></span><br><span class="line">    cur = top</span><br><span class="line">    next = cur.next</span><br><span class="line">    old = cur</span><br><span class="line">    <span class="comment"># 此时第一个线程被调度了</span></span><br><span class="line">    <span class="keyword">while</span> (old != CAS(top, cur, next)):</span><br><span class="line">        old = cur</span><br><span class="line">        next = cur.next</span><br><span class="line">    <span class="keyword">return</span> cur</span><br></pre></td></tr></table></figure>

<p>刚才的例子是对一个栈来说的，A/B/C是不同的数据对象，有的人可以说，我们比较栈里面的全部元素不就行了？在下面的一个例子中可以看到，即使对于相同的对象，也是会产生问题的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X is $100.</span><br><span class="line"></span><br><span class="line">Thread 1. If X is $100, A will sub $50 from X</span><br><span class="line">Thread 2. If X is $100, B will sub $50 from X</span><br><span class="line">Thread 3. If X is $50, C add $50 to X</span><br></pre></td></tr></table></figure>

<p>考虑下面的执行顺序，Thread 2会Fail掉，最后X还是100。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 - 2 - 3</span><br><span class="line">2 will fail, and X will end up with $100</span><br></pre></td></tr></table></figure>

<p>但是对于下面的执行顺序，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 - 3 - 2</span><br><span class="line">X will end up with $50</span><br></pre></td></tr></table></figure>

<p>可以看出，这其实还是一个逻辑上的问题：对于前者来说，Thread 1和Thread 2可以理解为发送了重复的请求；对于后者来说，可以理解为Thread 2是一个新的请求，只是恰巧和Thread 1的判断条件相等。一般来说，我们认为三个线程的任务是在同一个时间戳下面开始执行的，并且我们认为是原子的。</p>
<p>ABA问题的解决有如下的一些思路。</p>
<h4 id="Tagged-state-reference"><a href="#Tagged-state-reference" class="headerlink" title="Tagged state reference"></a>Tagged state reference</h4><p>一个通常的做法，是添加一个额外的 tag。例如在 CAS 时，可以添加一个 counter，表示对象被修改的次数。这样 ABA 就会变成 ABA’。</p>
<h4 id="Deferred-reclamation"><a href="#Deferred-reclamation" class="headerlink" title="Deferred reclamation"></a>Deferred reclamation</h4><p>此类方案包括 HazardPointer 和 RCU 等。核心思路是延迟 GC。<br>【Q】为什么延迟 GC <a href="https://en.wikipedia.org/wiki/ABA_problem" target="_blank" rel="noopener">可以解决 ABA 问题</a>呢？我们需要考虑 ABA 出现的常见场景。如果我们删除了一个对象，然后又创建了一个同类型的新对象，那么这个新的对象很可能和老对象有着相同的内存地址，从而产生 ABA 问题。</p>
<h4 id="指令集"><a href="#指令集" class="headerlink" title="指令集"></a>指令集</h4><p>诸如 ARM 等架构会提供一个 <a href="https://en.wikipedia.org/wiki/Load-Link/Store-Conditional" target="_blank" rel="noopener">LL/SC</a>，即 load linked, store conditional 命令。This effectively separates the notion of “storage contains value” from “storage has been changed”. Since these instructions provide atomicity using the address rather than the value, routines using these instructions are immune to the ABA problem.</p>
<h3 id="原子操作与锁的关系"><a href="#原子操作与锁的关系" class="headerlink" title="原子操作与锁的关系"></a>原子操作与锁的关系</h3><p>在上面的讨论中，我们能够直观地发现原子操作和锁的关系。原子操作看起来是“独善其身”的只能管住自己，原子操作之间、原子操作和非原子操作之间可能发生乱序或重排；而锁像大哥，能护住一段代码。由此思考如何通过原子操作来组织其他的那些非原子操作呢？这就要引入下面讨论的内存模型的问题。</p>
<h2 id="原子操作-以C-为例"><a href="#原子操作-以C-为例" class="headerlink" title="原子操作(以C++为例)"></a>原子操作(以C++为例)</h2><p>上面章节概览了锁无关编程和原子操作的概念。从现在开始，我们将讨论<strong>C++11标准库</strong>提供的原子操作机器具体实现。<br>因为本段过长，所以被移动到<a href="/2017/12/28/C++-atomic/">新文章中</a>。</p>
<h2 id="其他的同步原语"><a href="#其他的同步原语" class="headerlink" title="其他的同步原语"></a>其他的同步原语</h2><p>在上面的几个章节中，论述了基于锁和基于原子操作的同步原语。还有一些其他的同步原语，例如RCU、MCS Lock等。</p>
<h3 id="Hazard-Pointer"><a href="#Hazard-Pointer" class="headerlink" title="Hazard Pointer"></a>Hazard Pointer</h3><p>被迁移至<a href="/2023/05/16/hazptr/">Hazard Pointer</a>。</p>
<h3 id="RCU"><a href="#RCU" class="headerlink" title="RCU"></a>RCU</h3><p><a href="http://www.rdrop.com/~paulmck/RCU/whatisRCU.html" target="_blank" rel="noopener">RCU(Read Copy Update)</a>是Linux2.6引入的一种替代读写锁的方法，在Linux内核中被广泛使用。其思想是在多个读者能和一个写者并行，写者在访问值时首先拷贝一个副本，对副本进行修改，再在适当的时候将新的数据一次性写回，这个时机就是所有读者完成读取之后。<a href="http://www.ibm.com/developerworks/cn/linux/l-rcu/index.html" target="_blank" rel="noopener">由此</a>看出这种方法能够很好地适应读多写少的情况，因为现在读者端不需要任何锁来保证同步，也不会被写者阻塞。但是写者端的任务加重了，一方面它仍然要处理和其他写者的竞争问题，另一方面它具有复制开销，还需要监听所有读者的信号以确定数据的修改时间。下面描述了写操作的流程：</p>
<ol>
<li>对旧数据建立一块副本，对副本进行修改</li>
<li>等待前面所有的读者完成读取<br> 这时候RCU实际上向专门的垃圾回收器注册一个callback并等待器通知，这段时间称为grace period。</li>
<li>写者将原来的数据替换为新的数据</li>
<li>写者删除旧的数据</li>
</ol>
<h3 id="MCS-Lock"><a href="#MCS-Lock" class="headerlink" title="MCS Lock"></a>MCS Lock</h3><p><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-mcsspinlock/index.html" target="_blank" rel="noopener">MCS Lock</a>是一种高性能的自旋锁，通过保存执行线程申请锁的顺序信息解决了传统自旋锁的“不公平”问题。MCS Lock具有Owner和Next两个域，初始值都为0。当内核线程申请锁时，会<code>return Next++</code>值作为自己的Ticket Number。如果返回的Ticket Number等于申请时的Owner，则直接获得锁，否则该线程就进行忙等。</p>
<p>普通的MCS Lock要求线程自旋在同一个共享变量上，因此涉及对该共享变量的频繁修改，这给诸如NUMA架构的系统会导致缓存失效的问题。因此有了MCS Spinlock这个基于链表的数据结构。MCS Spinlock维护多个被组织为链表的自旋变量waiting，其初始值为1。每个节点的申请者都自旋在waiting上等待其prev释放锁，当waiting变为0时结束自旋。</p>
<h2 id="通过内存模型约束线程对变量的读写顺序"><a href="#通过内存模型约束线程对变量的读写顺序" class="headerlink" title="通过内存模型约束线程对变量的读写顺序"></a>通过内存模型约束线程对变量的读写顺序</h2><p>这一篇主要还是围绕 C++ 的内存模型来讲解的，通过讲述语言的实现，来介绍 OS 和 CPU 微架构层面的相关知识。</p>
<p>锁无关编程的难点之一就是需要从编译器与 CPU 两个层面考虑行为对线程间的同步造成的的影响，也就是考虑<strong>编译器重排和CPU缓存与乱序</strong>对读写逻辑可能造成的影响。当我们试图使用原子操作去解决非原子操作间的竞态问题时，需要谨慎选择使用恰当的内存模型，这样才能保证安全性。</p>
<h3 id="as-if-rule"><a href="#as-if-rule" class="headerlink" title="as-if rule"></a>as-if rule</h3><p><a href="https://en.cppreference.com/w/cpp/language/as_if" target="_blank" rel="noopener">as-if rule</a>指出，C++ allows any and all code transformations that do not change the observable behavior of the program.</p>
<h3 id="原子操作的线程间顺序"><a href="#原子操作的线程间顺序" class="headerlink" title="原子操作的线程间顺序"></a>原子操作的线程间顺序</h3><p>从C++语言到运行程序得到结果之间需要经历编译器优化和处理器优化两道坎：编译器优化可能进行重排，处理器优化包括高速缓存和指令乱序。编译器和处理器达成的协议是不能改变单线程程序的行为。</p>
<p>以编译器优化为例，下面代码使用g++7编译。在O0下，按照1-2顺序；开启O1后，g++7就会进行Store-Store重排，将2提到1前面，先对b赋值，再对a赋值；并且还去除了一部分没用的代码。</p>
<p>对单线程来说，这样的优化并没有任何问题。但对于多线程来说则可能出现问题：</p>
<ol>
<li>一方面，由于去除部分代码的原因，汇编O1事实上不能在a处观察到<code>a == 1 &amp;&amp; b == 1</code>的情况，而假设O0汇编在进行到b处被抢占，那么其他的线程有机会看到以上的情况。</li>
<li>另一方面，在O1中先对b赋值再对a赋值，仍然会出现问题。假如说在3和4间线程被强占，那么另外一个线程观察<code>a</code>和<code>b</code>，得到<code>b</code>为123，而<code>a</code>为不确定值（或者1，如果前面赋初值语句没有被删去的话），而如果编译器不进行重排，我们理想中的原始结果是<code>a</code>为43，<code>b</code>为不确定值。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">1</span>, b = <span class="number">1</span>; <span class="comment">// 0</span></span><br><span class="line">    <span class="comment">// a</span></span><br><span class="line">    a = b + <span class="number">42</span>; <span class="comment">// 1</span></span><br><span class="line">    <span class="comment">// c</span></span><br><span class="line">    b = <span class="number">123</span>; <span class="comment">// 2</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d %d"</span>, a, b);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// compile with -O0</span></span><br><span class="line">    movl    $<span class="number">1</span>, <span class="number">-8</span>(%rbp)</span><br><span class="line">    movl    $<span class="number">1</span>, <span class="number">-4</span>(%rbp)</span><br><span class="line">    <span class="comment">// b</span></span><br><span class="line">    movl    <span class="number">-4</span>(%rbp), %eax</span><br><span class="line">    addl    $<span class="number">42</span>, %eax</span><br><span class="line">    movl    %eax, <span class="number">-8</span>(%rbp)</span><br><span class="line">    movl    $<span class="number">123</span>, <span class="number">-4</span>(%rbp)</span><br><span class="line">    movl    <span class="number">-4</span>(%rbp), %edx</span><br><span class="line">    movl    <span class="number">-8</span>(%rbp), %eax</span><br><span class="line"><span class="comment">// compile with -O1</span></span><br><span class="line">    movl    $<span class="number">123</span>, %ecx <span class="comment">// 3</span></span><br><span class="line">    movl    $<span class="number">43</span>, %edx <span class="comment">// 4</span></span><br></pre></td></tr></table></figure>

<p>出于性能方面的考虑，对<strong>多线程</strong>的程序而言并不存在和单线程一样的硬性要求。在使用原子操作等锁无关技术时，不能假设所有环境下程序最后行为一如我们希望代码所“暗示”一样。事实上编译器或处理器可以在<strong>不同线程间</strong>对<strong>不同变量间</strong>进行读写乱序，而这在多线程中会造成问题。例如在单线程中将对B的写提到对A的读前面是没有问题的，但是对多线程来说，这往往就会出现问题。虽然大部分时候我们不需要操心这个问题，这是因为一方面在使用mutex等内核锁时，内核帮我们做了相关工作，另一方面部分处理器（如x86）也提供了TSO模型，蕴含了acquire/release的保障，并也可以通过一些指令命令编译器在某些地方减少优化，但这依然是一个客观存在的问题。</p>
<h3 id="可见性和有序性"><a href="#可见性和有序性" class="headerlink" title="可见性和有序性"></a>可见性和有序性</h3><p>可见性指一个线程对变量的写操作对其它线程后续的读操作可见，这里见的是结果。可见性要求CPU在对缓存行写操作后能够保证至少在某个时间点前必须写回内存，从而保证其他线程能读到<strong>最新的值</strong>。有序性指的是数据不相关变量在并发的情况下，实际执行的结果和单线程的执行结果和单线程的执行结果是一样的，不会因为重排/乱序的问题导致结果不可预知。</p>
<p>在<a href="https://en.cppreference.com/w/cpp/atomic/memory_order" target="_blank" rel="noopener">CppReference</a>中，有下面的定义</p>
<h4 id="Sequence-Points"><a href="#Sequence-Points" class="headerlink" title="Sequence Points"></a>Sequence Points</h4><p>在 C++98/03 的标准中定义了 sequence point 来描述求值顺序，在C++11中已经用Sequence before来代替了。<br>At certain specified points in the execution sequence called sequence points, all side effects of previous evaluations shall be complete and no side effects of subsequent evaluations shall have taken place.</p>
<h4 id="Sequenced-before"><a href="#Sequenced-before" class="headerlink" title="Sequenced-before"></a>Sequenced-before</h4><p>在单线程中，如果A Sequenced-before B，那么A在B之前执行。这个先后根据<a href="https://en.cppreference.com/w/cpp/language/eval_order" target="_blank" rel="noopener">eval order</a>来判断。</p>
<p><a href="https://stackoverflow.com/questions/4176328/undefined-behavior-and-sequence-points/4183735#4183735" target="_blank" rel="noopener">如果A不Sequenced-before B，且B不Sequenced-before A</a>，那么这两个操作是：</p>
<ol>
<li>unsequenced的：既可以以任意顺序发生，也可以overlap地发生(也就是在<strong>单线程</strong>中，组成A的指令和组成B的指令<strong>interleave地执行</strong>)</li>
<li>indeterminately sequenced的：只可以以任意顺序发生，不能overlap地发生</li>
</ol>
<p>总结一下规则，<a href="https://blog.csdn.net/shuangguo121/article/details/51419663" target="_blank" rel="noopener">这里有个简单的翻译</a>。先介绍一下 full expression，它指的是 an expression that is not a subexpression of another expression。例如:</p>
<ol>
<li>an unevaluated operand<br> 例如 typeid, sizeof, noexcept, decltype。</li>
<li>a constant expression</li>
<li>an immediate invocation(Since C++20)<br> 指的是 consteval 修饰的</li>
<li>an entire initializer, including any comma-separated constituent expressions the destructor call generated at the end of the lifetime of a non-temporary object<br> 注意，<code>int a = 1</code> 这样的初始化语句也是 full expression 了。</li>
<li>an expression that is not part of another full-expression<br> 比如整个entire expression statement，for/while循环，if/switch循环，return中的表达式等。<br> 还包括对expression的隐式转换，临时变量的析构，default member initializers (when initializing aggregates)，以及其他涉及到函数调用的language construct。</li>
</ol>
<ol>
<li>(Each value computation and side effect) of a full expression is sequenced before (each value computation and side effect) of the next full expression.</li>
<li>The value computations (but not the side effects) of the operands to any operator are sequenced before the value computation of the result of the operator (but not its side effects).<br>后面还有一堆我就不翻译了。但最重要的就是分号以前的一堆东西是 full expression。</li>
</ol>
<h4 id="Sequenced-before和as-if-rule是否冲突？"><a href="#Sequenced-before和as-if-rule是否冲突？" class="headerlink" title="Sequenced-before和as-if rule是否冲突？"></a>Sequenced-before和as-if rule是否冲突？</h4><p>考虑下面代码，根据Sequenced-before规则，3是Sequenced-before 4的，因此3要在4之前执行。但这<a href="https://stackoverflow.com/questions/70623925/how-to-understand-sequenced-before-and-reorder" target="_blank" rel="noopener">不符合事实</a>，因为编译器可以重排3和4。<br>原因是as-if rule，它要求只要外部观测起来的行为是不变的，那么编译器就可以做任何优化。因为，先计算a和b都不影响printf阶段的结果，所以reorder是可以发生的，即使看起来违背了Sequenced-before原则。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">1</span>; <span class="comment">// 1</span></span><br><span class="line">    <span class="keyword">int</span> b = <span class="number">2</span>; <span class="comment">// 2</span></span><br><span class="line">    a = random_int(); <span class="comment">// 3 </span></span><br><span class="line">    b = random_int(); <span class="comment">// 4</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d %d"</span>, a, b); <span class="comment">// 5</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="Carries-dependency"><a href="#Carries-dependency" class="headerlink" title="Carries dependency"></a>Carries dependency</h4><p>在单线程中，如果A Sequenced-before B，那么对于下列情况，<strong>可能</strong>A Carries dependency into B，也就是说B依赖A：</p>
<ol>
<li>A的值被作为B的操作数，但不包括下列情况：<ol>
<li>B是std::kill_dependency调用。</li>
<li>A是<code>&amp;&amp;</code>、<code>||</code>,、<code>?:</code>、<code>,</code>的左操作数。这些情况要不就是短路原则，要不就是作为条件。</li>
</ol>
</li>
<li>A写到scalar object M，B从M读。</li>
<li>A carries dependency into another evaluation X, and X carries dependency into B</li>
</ol>
<h4 id="Modification-order"><a href="#Modification-order" class="headerlink" title="Modification order"></a>Modification order</h4><p>Modification order 是对原子操作而言的：<strong>所有对某个atomic变量操作都是total order的</strong>，可以概括成下面四种情况：</p>
<ol>
<li>Write-write coherence: If evaluation A that modifies some atomic M (a write) happens-before evaluation B that modifies M, then A appears earlier than B in the modification order of M</li>
<li>Read-read coherence: if a value computation A of some atomic M (a read) happens-before a value computation B on M, and if the value of A comes from a write X on M, then the value of B is either the value stored by X, or the value stored by a side effect Y on M that appears later than X in the modification order of M.</li>
<li>Read-write coherence: if a value computation A of some atomic M (a read) happens-before an operation B on M (a write), then the value of A comes from a side-effect (a write) X that appears earlier than B in the modification order of M</li>
<li>Write-read coherence: if a side effect (a write) X on an atomic object M happens-before a value computation (a read) B of M, then the evaluation B shall take its value from X or from a side effect Y that follows X in the modification order of M</li>
</ol>
<h4 id="Dependency-ordered-before"><a href="#Dependency-ordered-before" class="headerlink" title="Dependency-ordered before"></a>Dependency-ordered before</h4><p>在线程间，对于下面两种情况，操作A dependency-ordered before 操作B</p>
<ol>
<li>线程1中A对M执行了release；线程2中，B对M执行了comsume，并且B读取的是A写的值(by any part of the release sequence headed (until C++20))。</li>
<li>A dependency-ordered before X，并且X carries a dependency into B。</li>
</ol>
<h4 id="Inter-thread-happens-before"><a href="#Inter-thread-happens-before" class="headerlink" title="Inter-thread happens-before"></a>Inter-thread happens-before</h4><p>在线程间，A Inter-thread happens-before B，当满足下面几种情况<strong>之一</strong>：</p>
<ol>
<li>A synchronizes-with B</li>
<li>A dependency-ordered before B</li>
<li>A synchronizes-with some evaluation X, and X is sequenced-before B</li>
<li>A is sequenced-before some evaluation X, and X inter-thread happens-before B</li>
<li>A inter-thread happens-before some evaluation X, and X inter-thread happens-before B</li>
</ol>
<h4 id="Happens-before"><a href="#Happens-before" class="headerlink" title="Happens before"></a>Happens before</h4><p>不考虑线程，A happens-before B，当满足下列两种情况<strong>之一</strong>：</p>
<ol>
<li>A sequenced-before B</li>
<li>A inter-thread happens before B</li>
</ol>
<h4 id="Visible-side-effects"><a href="#Visible-side-effects" class="headerlink" title="Visible side-effects"></a>Visible side-effects</h4><p>对于标量 M 的写入操作 A，对于对同一个标量 M 的读操作 B 是 side-effect visible 的，如果</p>
<ol>
<li>A happens-before B。</li>
<li>在 A 和 B 之间没有其他对 M 的副作用 X 了。</li>
</ol>
<p>If side-effect A is visible with respect to the value computation B, then the longest contiguous subset of the side-effects to M, in modification order, where B does not happen-before it is known as the visible sequence of side-effects. (the value of M, determined by B, will be the value stored by one of these side effects)</p>
<p>Note: inter-thread synchronization boils down to preventing data races (by establishing happens-before relationships) and defining which side effects become visible under what conditions</p>
<h4 id="Synchronizes-with"><a href="#Synchronizes-with" class="headerlink" title="Synchronizes-with"></a>Synchronizes-with</h4><p><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3337.pdf" target="_blank" rel="noopener">An atomic operation A that performs a release operation on an atomic object M synchronizes with an atomic operation B that performs an acquire operation on M and takes its value from any side effect in the release sequence headed by A.</a></p>
<p>简单来说，可以理解为Inter-thread的Happens Before，使得一个时间点前内存的变化能够被其他线程看到。<br>一个常见的例子是<code>atomic_thread_fence(memory_order_acquire)</code>是synchronizes-with <code>atomic_thread_fence(memory_order_release)</code>的。</p>
<p>但请注意，<strong>这个顺序并不是代码层面，而是执行层面的</strong>。<a href="https://preshing.com/20130823/the-synchronizes-with-relation/" target="_blank" rel="noopener">preshing</a>的这篇文章中描述了具体的条件，也就是说load(acq)需要<strong>正好去读store(rel)写进去的那个value</strong>。</p>
<blockquote>
<p>let’s just say it’s sufficient for the read-acquire to read the value written by the write-release. If that happens, the synchronized-with relationship is complete</p>
</blockquote>
<p>如下图所示，<strong>如果load早于store被执行，那么两者之间就没有synchronizes-with关系</strong>，因为它是读的别的store写入的value。这也是C++标准所谓“atomic operation B must “take its value” from atomic operation A”的意思。<br><img src="/img/bfbc/no-sync-with.png"></p>
<p>结合上文容易看出，Synchronizes-with是一种取得Happens before关系的方式。但需要注意，初学者经常犯的错误之一，就是常常希望<strong>通过直接比较某原子量</strong>来在多线程中<strong>同步非原子量</strong>，但这在Relax这种弱Memory Order约束的内存模型下是不可靠的。</p>
<p>例如，在下面的代码中，语句4并不一定成立。这是因为2和3之间并没有任何Synchronizes-with关系，并且1、2，以及3、4之间都可以进行重排。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> data;</span><br><span class="line"><span class="built_in">std</span>::<span class="keyword">atomic_bool</span> flag &#123; <span class="literal">false</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// thread A</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">producer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    data = <span class="number">42</span>;  <span class="comment">// (1)</span></span><br><span class="line">    flag.store(<span class="literal">true</span>, memory_order_relaxed);  <span class="comment">// (2)</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// thread B</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">consume</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (!flag.load(memory_order_relaxed));  <span class="comment">// (3)</span></span><br><span class="line">    assert(data == <span class="number">42</span>);  <span class="comment">// (4)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="coherence-ordered-before"><a href="#coherence-ordered-before" class="headerlink" title="coherence-ordered-before"></a>coherence-ordered-before</h4><p>对于同一个原子变量M，原子操作A是coherence-ordered-before原子操作B，当满足下列之一：</p>
<ol>
<li>A is a modification, and B reads the value stored by A</li>
<li>A precedes B in the modification order of M</li>
<li>A reads the value stored by an atomic modification X, X precedes B in the modification order, and A and B are not the same atomic read-modify-write operation</li>
<li>A is coherence-ordered-before X, and X is coherence-ordered-before B</li>
</ol>
<h4 id="Release-sequence"><a href="#Release-sequence" class="headerlink" title="Release sequence"></a>Release sequence</h4><p>After a release operation A is performed on an atomic object M, the longest continuous subsequence of the modification order of M that consists of</p>
<ol>
<li>【until C++20】Writes performed by the same thread that performed A </li>
<li>Atomic read-modify-write operations made to M by any thread</li>
</ol>
<p>is known as release sequence headed by A</p>
<h3 id="内存一致性模型综述"><a href="#内存一致性模型综述" class="headerlink" title="内存一致性模型综述"></a>内存一致性模型综述</h3><p>广义上的<a href="https://en.wikipedia.org/wiki/Consistency_model" target="_blank" rel="noopener">一致性模型</a>包括Strict Consistency、Sequential Consistency、Causal Consistency、Processor Consistency、FIFO consistency、Cache Consistency、Slow Consistency、Release consistency、Entry Consistency、General Consistency、Local Consistency等。在C++中提供了六种内存模型(memory order)来描述不同线程之间相同/不同数据的读写的顺序。</p>
<p>为什么会有内存模型呢？主要是因为计算机的并发执行过程和我们程序员以为的并发执行过程是不一样的。例如下面的程序1和2，程序员的视野里的执行顺序可能是ACBD/ACBD等等，但肯定不会是CABD这样的顺序的，这就是所谓的sequential consistency(SC)内存模型。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1           2</span><br><span class="line">A           B</span><br><span class="line">C           D</span><br></pre></td></tr></table></figure>

<p>但是因为计算机允许重排和乱序，所以CABD这样的顺序是实际可能发生的！这不就乱套了么？所以内存模型用来限制重排和乱序。也就是说，如果我们很在乎重排和乱序，就可以通过内存模型去限制，甚至完全禁用。当然，可能会导致性能上的影响。但如果我们不在乎，计算机则可以充分自由地进行重排。</p>
<p>在研究内存一致性模型时，需要考虑下面几点：</p>
<ol>
<li>区分读和写</li>
<li>区分对同一变量的操作和不同变量的操作</li>
<li>区分线程内和跨线程</li>
<li>区分跨内存模型之间的交互关系<br> 比如acquire对plain store的影响。</li>
<li>微架构方面<br> 例如多核CPU之间的Cache。</li>
</ol>
<h3 id="内存模型：Relaxed"><a href="#内存模型：Relaxed" class="headerlink" title="内存模型：Relaxed"></a>内存模型：Relaxed</h3><p>自由模型(Relaxed ordering)是最弱的模型，它对<strong>线程间</strong>的执行顺序不做任何synchronizes-with的假设，但同线程的变量仍然遵循happens-before假设，即它只禁止重排<strong>单线程</strong>上对<strong>单个变量</strong>的访问顺序(关于是否是单个变量，后面还有讨论)。注意，这实际上是允许编译器对不同变量进行重排的。根据CppReference，Relaxed Ordering的目的是<a href="https://en.cppreference.com/w/cpp/atomic/memory_order" target="_blank" rel="noopener">保证了当前变量的原子性</a>。</p>
<h4 id="Litmus-test：Message-Passing"><a href="#Litmus-test：Message-Passing" class="headerlink" title="Litmus test：Message Passing"></a>Litmus test：Message Passing</h4><p>考虑下面的代码，对于Relaxed Ordering，仍然保证了1先于2、3先于4，且3读到<code>true</code>，但<code>z</code><strong>可能为0</strong>。这是由于<code>x</code>和<code>y</code>是两个不同变量，Relaxed不关注它们之间的关系。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">bool</span>&gt; x = <span class="literal">false</span>, y = <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; z = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// thread 1</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">write_x_then_y</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  x.store(<span class="literal">true</span>, <span class="built_in">std</span>::memory_order_relaxed);  <span class="comment">// 1</span></span><br><span class="line">  y.store(<span class="literal">true</span>, <span class="built_in">std</span>::memory_order_relaxed);  <span class="comment">// 2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// thread 2</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">read_y_then_x</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(!y.load(<span class="built_in">std</span>::memory_order_relaxed));  <span class="comment">// 3</span></span><br><span class="line">  <span class="keyword">if</span>(x.load(<span class="built_in">std</span>::memory_order_relaxed))  <span class="comment">// 4</span></span><br><span class="line">    ++z;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但实际在x86下的MSVC2015上测试下，发现<code>z</code>始终不为0，这是为什么呢？我在StackOverflow上<a href="https://stackoverflow.com/questions/48139399/memory-order-relaxed-not-work-as-expected-in-code-from-c-concurrency-in-action?noredirect=1#comment83256917_48139399" target="_blank" rel="noopener">提了个问题</a>，它的解答我觉得比较全面：</p>
<ol>
<li><p><code>std::memory_order_relaxed</code>会禁止<strong>编译器</strong>重排<code>x</code>和<code>y</code>的Store-Store，可以理解成下面的代码</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">atomic&lt;<span class="keyword">bool</span>&gt; x, y;</span><br><span class="line">x.store(<span class="literal">true</span>, <span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">y.store(<span class="literal">true</span>, <span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line"></span><br><span class="line"><span class="comment">// is similar to...</span></span><br><span class="line"><span class="keyword">volatile</span> <span class="keyword">bool</span> x, y;</span><br><span class="line">x = <span class="literal">true</span>;</span><br><span class="line"><span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">""</span> ::: <span class="string">"memory"</span>)</span></span>;  <span class="comment">// Tells compiler to stop optimizing here,</span></span><br><span class="line">                                <span class="comment">// but issues no instructions</span></span><br><span class="line">y = <span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>但是CPU可能重排<code>x</code>和<code>y</code>的Store-Store；并且因为Store buffer的存在，<code>x</code>可能被延迟写入内存</p>
</li>
<li><p>因为x86的TSO提供了acquire/release语义，保证了当3是true时，在2前的对3后的可见</p>
</li>
</ol>
<p>所以结论是由于特定平台的一致性模型要强于Relaxed Ordering，所以<code>std::memory_order_relaxed</code>只是保证强于等于自由模型，在自己的x86电脑上编译该测试可能得到不同的结果。</p>
<h4 id="Litmus-test"><a href="#Litmus-test" class="headerlink" title="Litmus test"></a>Litmus test</h4><p><a href="https://en.cppreference.com/w/cpp/atomic/memory_order#Relaxed_ordering" target="_blank" rel="noopener">例子来自cppreference</a>。<br>Thread 1中A sequenced-before B，thread 2中C sequenced before D。nothing prevents D from appearing before A in the modification order of y, and B from appearing before C in the modification order of x。这个似乎和上面说的relaxed不会限制不同变量的访问顺序有冲突了。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 1:</span></span><br><span class="line">r1 = y.load(<span class="built_in">std</span>::memory_order_relaxed); <span class="comment">// A</span></span><br><span class="line">x.store(r1, <span class="built_in">std</span>::memory_order_relaxed); <span class="comment">// B</span></span><br><span class="line"><span class="comment">// Thread 2:</span></span><br><span class="line">r2 = x.load(<span class="built_in">std</span>::memory_order_relaxed); <span class="comment">// C </span></span><br><span class="line">y.store(<span class="number">42</span>, <span class="built_in">std</span>::memory_order_relaxed); <span class="comment">// D</span></span><br></pre></td></tr></table></figure>

<p>对此，在<a href="https://stackoverflow.com/questions/35648936/reordering-and-memory-order-relaxed" target="_blank" rel="noopener">SoF</a>上也有相关提问。解释是sequenced before只适用于单线程中，但编译器和CPU都可能进行重排。另一个<a href="https://stackoverflow.com/questions/25287484/does-sequenced-before-relation-in-c11-prevent-compiler-cpu-reordering" target="_blank" rel="noopener">问题</a>进一步做了阐释。</p>
<h4 id="Out-of-thin-air问题"><a href="#Out-of-thin-air问题" class="headerlink" title="Out of thin air问题"></a>Out of thin air问题</h4><p>考虑下面的代码，它是交换x和y的值的一个错误范例，比如可能读到x=y=10/20。</p>
<p>但至少，我们期望两个线程中的load，要不看到初始值，要不看到另一个线程store之后的值。<br>Out of thin air问题指，x和y的load可能都会读到42，或者其他任意不知道从哪里来的值。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">10</span></span><br><span class="line">y = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">Thread <span class="number">1</span>:</span><br><span class="line">  r1 = x.load(memory_order_relaxed);</span><br><span class="line">  y.store(r1, memory_order_relaxed);</span><br><span class="line"></span><br><span class="line">Thread <span class="number">2</span>:</span><br><span class="line">  r2 = y.load(memory_order_relaxed);</span><br><span class="line">  x.store(r2, memory_order_relaxed);</span><br></pre></td></tr></table></figure>

<p>这个问题的核心是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = 0, y = 0</span><br><span class="line">r1 = x   | r2 = y</span><br><span class="line">y = r1   | x = r2</span><br></pre></td></tr></table></figure>

<p>上述代码可以被编译器优化为下面的形式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = 0, y = 0</span><br><span class="line">r1 = x   | r2 = 42</span><br><span class="line">y = r1   | x = r2</span><br><span class="line">         | if(y != 42)</span><br><span class="line">         |    x = r2 = y</span><br></pre></td></tr></table></figure>

<h3 id="内存模型：acquire-release以及release-consume"><a href="#内存模型：acquire-release以及release-consume" class="headerlink" title="内存模型：acquire/release以及release/consume"></a>内存模型：acquire/release以及release/consume</h3><p>acquire/release模型相对灵活一点，也是x86实现的语义。<strong>acquire只对应读(Load)操作使用，release只对应写(Store)操作使用</strong>。<a href="https://stackoverflow.com/questions/20398094/atomict-load-with-stdmemory-order-release" target="_blank" rel="noopener">如果对W使用acquire fence，或者对R使用release fence会怎么样呢</a>？很简单，C++中不允许：</p>
<ol>
<li>对读，不允许<code>memory_order_release</code>和<code>memory_order_acq_rel</code></li>
<li>对写，不允许<code>memory_order_consume</code>和<code>memory_order_acquire</code>和<code>memory_order_acq_rel</code>。</li>
</ol>
<p>稍弱一点的<code>memory_order_release</code>和<code>memory_order_consume</code>只用来保证<strong>当前操作涉及到的对象</strong>的可见性。<br>consume语义可以被替换为acquire语义，因为aquire语义是更强的。</p>
<p>对STORE/LOAD操作，下面直接翻译<a href="https://en.cppreference.com/w/cpp/atomic/memory_order" target="_blank" rel="noopener">CppReference</a>，在阅读时需要注意“当前线程”和“其他线程”的区别。</p>
<p>同时<a href="https://stackoverflow.com/questions/70846124/how-to-deduce-order-of-two-variables-store-load-with-acq-rel-order" target="_blank" rel="noopener">需要注意</a>，这里<strong>不能理解为</strong>对atomic变量的读会等待对atomic的写完成，更准确的说法是**a release store synchronizes with an acquire load that takes its value from the store.**。可以参考“Synchronizes-with”的介绍。</p>
<h4 id="acquire-release-配对："><a href="#acquire-release-配对：" class="headerlink" title="acquire-release 配对："></a>acquire-release 配对：</h4><ol>
<li><code>memory_order_acquire</code>的Load<br> 在<strong>当前线程</strong>上，任何后面的RW都不能重排到自己这个Load之前。<strong>也就是禁止load-store和load-load重排</strong>。<br> 在其他线程中的所有W(必须是release相同atomic变量的W)，都对当前线程可见。<br> 直觉上来看，acquire是获得锁。那么不能把被锁保护的东西(读和写)提到获得锁前面。另外，必须要先释放锁再获得锁。</li>
<li><code>memory_order_release</code>的Store<br> 在<strong>当前线程</strong>上，任何前面的RW都不能重排到自己这个Store操作之后。<strong>也就是禁止load-store和store-store重排</strong>。<br> 在当前线程中的所有W，对其他线程中所有acquire相同的atomic变量的操作，都是可见的。<br> 直觉上来看，release是释放锁。那么不能把被锁保护的东西(读和写)放到释放锁后面。另外，必须要先释放锁再获得锁。</li>
</ol>
<p>下面是 CppReference 上的介绍，部分我们之前已经讨论过了。<br>如果线程 A 上的 release atomic store 和线程 B 上的 acquire atomic load 读写同一个变量，并且线程 B 恰恰是读的线程 A 的写入。那么线程 A 上的 store synchronizes-with 线程 B 上的 load。</p>
<p>从线程 A 来看，所有的 non-atomic 和 relaxed atomic 写，如果它们 happen-before release atomic store，则它们在线程 B 中有 visible side-effects。也就是说，一旦线程 B 中的 atomic load 完成了，线程 B 保证能见到线程 A 写入的任何数据。当然，这个也只在 B 真的返回了 A 存储的变量，或者返回 a value from later in the release sequence 时成立。</p>
<p>这样的 acquire-release 同步需要这些不同的线程读写同一个变量才成立。其他的线程可能见到和这些同步线程不一样的 order。</p>
<p>互斥锁，例如 std::mutex，或者 atomic spinlock，是 release-acquire 同步的例子。当这个锁被线程 A release，并被随后线程 B acquire，那么线程 A 的关键段(也就是 release 前)中所有发生的一切，都在线程 B acquire 之后可见。当然，线程 B 也是在执行同一个关键段。</p>
<h4 id="acquire-consume-配对："><a href="#acquire-consume-配对：" class="headerlink" title="acquire-consume 配对："></a>acquire-consume 配对：</h4><ol>
<li><code>memory_order_consume</code>的Load</li>
<li><code>memory_order_release</code>的Store<br> 在当前线程中的所有W，在其他线程中consume相同atomic变量的操作，如果W carry a dependency into the atomic variable，那么是对这些线程是可见的。这里涉及到consume order，可能翻译不准确。</li>
</ol>
<p>注意，从 C++17 开始，acquire-consume 配对被 revise，所以暂时不建议使用这个。</p>
<h4 id="总结注意点"><a href="#总结注意点" class="headerlink" title="总结注意点"></a>总结注意点</h4><ol>
<li>简单来说，acquire load 不能把后面的操作往前提，release store 不能把前面的操作往后提。</li>
<li>在当前线程上，不能避免<code>c.store(release)</code>被排到<code>c.load(acquire)</code>后面，也就是所谓的Store-Load重排。</li>
</ol>
<h4 id="memory-order-acq-rel"><a href="#memory-order-acq-rel" class="headerlink" title="memory_order_acq_rel"></a>memory_order_acq_rel</h4><p>另一个问题是，<code>memory_order_acq_rel</code>表示即是acquire的，又是release的，类似于acquire和release的合并。<a href="https://stackoverflow.com/questions/12340773/how-do-memory-order-seq-cst-and-memory-order-acq-rel-differ" target="_blank" rel="noopener">那么和<code>memory_order_seq_cst</code>有啥区别呢</a>？其中一个比较是acquire/release需要互相配合才有效，但是<code>memory_order_seq_cst</code>对于普通的load都是有效的。在实际使用中，涉及RMW操作，例如exchange时，需要指定<code>memory_order_acq_rel</code>。这是因为exchange本身同时有load和store。</p>
<h4 id="Demo-acquire-release"><a href="#Demo-acquire-release" class="headerlink" title="Demo acquire/release"></a>Demo acquire/release</h4><p>可以参考<a href="https://zhuanlan.zhihu.com/p/45566448" target="_blank" rel="noopener">下面的Demo</a>。其中a/b/c都是 atomic variable。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">c = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// thread 1</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">t1</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  a = <span class="number">1</span>; <span class="comment">// 1</span></span><br><span class="line">  b.store(<span class="number">2</span>, memory_order_relaxed); <span class="comment">// 2</span></span><br><span class="line">  c.store(<span class="number">3</span>, memory_order_release); <span class="comment">// 3</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// thread 2</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">t2</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (c.load(memory_order_acquire) != <span class="number">3</span>) <span class="comment">// 4</span></span><br><span class="line">    ;</span><br><span class="line">  <span class="comment">// 以下 assert 永远不会失败</span></span><br><span class="line">  assert(a == <span class="number">1</span> &amp;&amp; b == <span class="number">2</span>); <span class="comment">// 5</span></span><br><span class="line">  assert(b.load(memory_order_relaxed) == <span class="number">2</span>); <span class="comment">// 6</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>进行下面三点分析：</p>
<ol>
<li>在 Thread 1 中 release store c。因为<strong>当前线程</strong>所有的 RW 都不能重排到 <code>c.store</code> 之后，所以1/2都不能排到3后面。</li>
<li>在 Thread 2 中 acquire load c。因为<strong>当前线程</strong>所有的 RW 都不能重排到 <code>c.load</code> 之前，所以5/6都不能排到4前面。</li>
<li>考虑 c：<br> 其实下面两句话是一个意思：<br> Thread 1中的 release store c 要求对Thread 2中所有的 acquire load c 是可见的。<br> Thread 2中的 acquire load c 要求Thread 1中的所有的 release store c 对其可见，所以它能看到这个<code>c=3</code>这个值。</li>
</ol>
<p>上面的讨论保证了当c的值为3之后，一定会读到a和b的值是2。无论a和b是以什么方式访存的，都不会影响最终结果。</p>
<p>特别地，可以<a href="https://stackoverflow.com/questions/31993500/difference-between-memory-order-consume-and-memory-order-acquire" target="_blank" rel="noopener">用专业术语描述一下对应的行为</a>：</p>
<ol>
<li>1 Sequenced-before 2</li>
<li>2 Sequenced-before 3</li>
<li>3 Dependency-ordered before 4</li>
<li>4 Sequenced-before 5</li>
<li>5 Sequenced-before 6</li>
</ol>
<h4 id="Demo-release-consume"><a href="#Demo-release-consume" class="headerlink" title="Demo release/consume"></a>Demo release/consume</h4><p>如下所示，对a的赋值和对c的赋值涉及两个内存地址，所以a和c的赋值可能会进行乱序。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">0</span>;</span><br><span class="line">c = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">thread <span class="number">1</span>:</span><br><span class="line">&#123;</span><br><span class="line">  a = <span class="number">1</span>;</span><br><span class="line">  c.store(<span class="number">3</span>, memory_order_release);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">thread <span class="number">2</span>:</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">while</span> (c.load(memory_order_consume) != <span class="number">3</span>);</span><br><span class="line">  assert(a == <span class="number">1</span>); <span class="comment">// assert 可能失败也可能不失败</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="内存模型：Sequential"><a href="#内存模型：Sequential" class="headerlink" title="内存模型：Sequential"></a>内存模型：Sequential</h3><p>顺序一致性(sequential consistency, SC)要求程序中的行为从任意角度来看，序列顺序都是一致的(have single total order)。这是在说这段多线程程序的行为和一段单线程程序的行为是一致的，类似于不是并行的并发。这个模型禁止了任何四种类型的读写重排，因此可以认为SC下每次读到的都是最新值。</p>
<h4 id="不能太乐观"><a href="#不能太乐观" class="headerlink" title="不能太乐观"></a>不能太乐观</h4><p>虽然SC是C++下最强的一致性模型，但不能有“无脑SC”就行了的看法。</p>
<h5 id="出于正确性原因"><a href="#出于正确性原因" class="headerlink" title="出于正确性原因"></a>出于正确性原因</h5><p>可以把SC简单理解成</p>
<ol>
<li>给Load加Acquire</li>
<li>给Store加Release</li>
<li>给所有SC的操作，赋予global total order</li>
</ol>
<p>而这第三个是tricky的，<a href="(https://stackoverflow.com/questions/39053600/does-standard-c11-guarantee-that-memory-order-seq-cst-prevents-storeload-reord)">它实际暗示了SC操作和非SC操作之间并没有global total order，这包含两个层面</a>：</p>
<ol>
<li>SC操作和非SC的atomic操作之间没有</li>
<li>SC操作和plain操作之间更没有</li>
</ol>
<p>换种说法，<a href="https://stackoverflow.com/questions/39053600/does-standard-c11-guarantee-that-memory-order-seq-cst-prevents-storeload-reord?rq=1" target="_blank" rel="noopener">SoF上</a>指出虽然<code>atomic(seq_cst)</code>和<code>atomic(seq_cst)</code>始终不会重排，但是在<code>atomic(seq_cst)</code>附近的<code>non-atomic</code>甚至是<code>atomic(non-seq_cst)</code>形式的<code>STORE-LOAD</code>都会被重排。例如在下面的代码中1和3的<code>STORE-LOAD</code>肯定不会被重排，但2和3的<code>STORE-LOAD</code>就可能被重排，所以一定要注意。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; a, b, c;</span><br><span class="line">a.store(<span class="number">2</span>, <span class="built_in">std</span>::memory_order_seq_cst);          <span class="comment">// 1: movl 2,[a]; mfence;</span></span><br><span class="line">c.store(<span class="number">4</span>, <span class="built_in">std</span>::memory_order_release);          <span class="comment">// 2: movl 4,[c];</span></span><br><span class="line"><span class="keyword">int</span> tmp = b.load(<span class="built_in">std</span>::memory_order_seq_cst);    <span class="comment">// 3: movl [b],[tmp];</span></span><br></pre></td></tr></table></figure>

<p>比如考虑下面的Litmus test：Store buffer，C++11是可以同时见到r1和r2为0的。此时操作1/2之间并没有global total order，3/4也是这样。此时我们可以将两个<code>memory_order_seq_cst</code>直接替换成<code>memory_order_acquire</code>，</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// https://godbolt.org/g/2NLy12</span></span><br><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; x(<span class="number">0</span>), y(<span class="number">0</span>);</span><br><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line">x.store(<span class="number">1</span>, <span class="built_in">std</span>::memory_order_release); <span class="comment">// 1</span></span><br><span class="line"><span class="keyword">int</span> r1 = y.load(<span class="built_in">std</span>::memory_order_seq_cst); <span class="comment">// 2</span></span><br><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line">y.store(<span class="number">1</span>, <span class="built_in">std</span>::memory_order_release); <span class="comment">// 3</span></span><br><span class="line"><span class="keyword">int</span> r2 = x.load(<span class="built_in">std</span>::memory_order_seq_cst); <span class="comment">// 4</span></span><br></pre></td></tr></table></figure>

<p>稍微进行修改，下面的代码根据C++11，也是可以同时见到r1和r2为0的。但在X86上实际是见不到的，这是因为<code>x.store(memory_order_seq_cst)</code>会产生一个Full Barrier，即mfence。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// https://godbolt.org/g/mVZJs0</span></span><br><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; x(<span class="number">0</span>), y(<span class="number">0</span>);</span><br><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line">x.store(<span class="number">1</span>, <span class="built_in">std</span>::memory_order_seq_cst);</span><br><span class="line"><span class="keyword">int</span> r1 = y.load(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line">y.store(<span class="number">1</span>, <span class="built_in">std</span>::memory_order_seq_cst);</span><br><span class="line"><span class="keyword">int</span> r2 = x.load(<span class="built_in">std</span>::memory_order_acquire);</span><br></pre></td></tr></table></figure>

<h5 id="出于性能原因"><a href="#出于性能原因" class="headerlink" title="出于性能原因"></a>出于性能原因</h5><h4 id="Litmus-test：Store-buffer"><a href="#Litmus-test：Store-buffer" class="headerlink" title="Litmus test：Store buffer"></a>Litmus test：Store buffer</h4><h4 id="Litmus-test：读写不同变量"><a href="#Litmus-test：读写不同变量" class="headerlink" title="Litmus test：读写不同变量"></a>Litmus test：读写不同变量</h4><p>在C++ Concurrency in Action中举了一个例子，使用四个线程运行下面四个函数：</p>
<ol>
<li>其中两个写线程分别将x和y设置为true</li>
<li>两个读线程分别尝试按照<code>x -&gt; y</code>和<code>y -&gt; x</code>的顺序读取<br> 以<code>read_x_then_y</code>为例，它循环等到读到x为true，然后读取y，如果y也是true，则设置z为1。</li>
</ol>
<p>在SC下，可以断言无论如何<code>z</code>永远不可能为0，也就是两个读线程至少有一个能看到<code>x</code>和<code>y</code>同时被设为<code>true</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">bool</span>&gt; x = <span class="literal">false</span>, y = <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; z = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// thread 1</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">write_x</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x.store(<span class="literal">true</span>, <span class="built_in">std</span>::memory_order_seq_cst);  <span class="comment">// 1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// thread 2</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">write_y</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    y.store(<span class="literal">true</span>, <span class="built_in">std</span>::memory_order_seq_cst);  <span class="comment">// 2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// thread 3</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">read_x_then_y</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(!x.load(<span class="built_in">std</span>::memory_order_seq_cst)); <span class="comment">// a</span></span><br><span class="line">    <span class="comment">// Now x is true, check if y is true</span></span><br><span class="line">    <span class="keyword">if</span>(y.load(<span class="built_in">std</span>::memory_order_seq_cst))  <span class="comment">// 3</span></span><br><span class="line">        ++z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// thread 4</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">read_y_then_x</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(!y.load(<span class="built_in">std</span>::memory_order_seq_cst)); <span class="comment">// b</span></span><br><span class="line">    <span class="comment">// Now y is true, check if x is true</span></span><br><span class="line">    <span class="keyword">if</span>(x.load(<span class="built_in">std</span>::memory_order_seq_cst))  <span class="comment">// 4</span></span><br><span class="line">        ++z;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>容易看出将1/2/3/4任意排序，那么上面的断言是显然的(注意到即使<code>read_x_then_y</code>在<code>write_x</code>前被调用也有while循环兜底)。但如果<code>(1 -&gt; 3)</code>和<code>(2 -&gt; 4)</code>这两个步骤并行发生的话，上面断言就不成立了。我们可以构造出下面的执行序列</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">    Thread 0                  Thread 1</span><br><span class="line">(3)find y = 0</span><br><span class="line">                            (2)y = 1</span><br><span class="line">                            (b)read until y = 1</span><br><span class="line">                            (4)find x = 0</span><br><span class="line">(1)x = 1</span><br><span class="line">(a)read until x = 1</span><br></pre></td></tr></table></figure>

<h3 id="如何选择内存模型？"><a href="#如何选择内存模型？" class="headerlink" title="如何选择内存模型？"></a>如何选择内存模型？</h3><ol>
<li>如果只是想实现<strong>单变量的原子操作</strong>，使用Relaxed就行了</li>
</ol>
<h2 id="通过fence-barrier约束线程对变量的读写顺序"><a href="#通过fence-barrier约束线程对变量的读写顺序" class="headerlink" title="通过fence/barrier约束线程对变量的读写顺序"></a>通过fence/barrier约束线程对变量的读写顺序</h2><h3 id="C-层面的fence及其实现"><a href="#C-层面的fence及其实现" class="headerlink" title="C++层面的fence及其实现"></a>C++层面的fence及其实现</h3><p>常见的fence包括thread fence(memory/CPU barrier)和signal fence(compiler barrier)。</p>
<h4 id="signal-fence"><a href="#signal-fence" class="headerlink" title="signal fence"></a>signal fence</h4><p>signal fence类似下面的东西，参考<a href="https://en.wikipedia.org/wiki/Memory_ordering" target="_blank" rel="noopener">Wikipedia</a>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// gcc</span></span><br><span class="line"><span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">""</span> ::: <span class="string">"memory"</span>)</span></span>;</span><br><span class="line"><span class="comment">// msvc</span></span><br><span class="line">__MACHINE(<span class="keyword">void</span> _ReadWriteBarrier(<span class="keyword">void</span>))</span><br><span class="line"><span class="comment">// c++11</span></span><br><span class="line"><span class="built_in">std</span>::atomic_signal_fence(memory_order_acq_rel)</span><br></pre></td></tr></table></figure>

<ol>
<li><p>gcc版本<br> 关于这条命令可以参考<a href="https://stackoverflow.com/questions/14950614/working-of-asm-volatile-memory" target="_blank" rel="noopener">SoF上的回答</a>，以及<a href="/2020/12/11/pthread_rwlock-impl/">扩展形式的GCC汇编介绍</a>。<br> 这里简单解释一下，实际上是用asm声明了一个空指令，但是后面的<code>memory</code>clobber会告诉编译器这个空指令可能访问任意内存，因此编译器会防止这条指令前后的访存操作跨过自己进行重排。并且这条指令还会<a href="https://zhuanlan.zhihu.com/p/41872203" target="_blank" rel="noopener">将寄存器中的值flush回内存，并重新读取</a>。<br> 直接指明指令可能会访问哪些内存。比如下面语句表示可能会读<code>x</code>写<code>y</code>，并且涉及内存操作。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WRITE(x)</span><br><span class="line">asm volatile(&quot;&quot;: &quot;=m&quot;(y) : &quot;m&quot;(x):) // memory fence</span><br><span class="line">READ(y)</span><br></pre></td></tr></table></figure></li>
<li><p>MSVC版本，根据<a href="https://msdn.microsoft.com/en-us/library/f20w0x5e.aspx" target="_blank" rel="noopener">MSDN</a>，<code>_ReadWriteBarrier</code>限制了编译器可能的重排</p>
</li>
<li><p>C++11标准库版本<br> <code>std::atomic_signal_fence</code>在MSVC上也是利用Compiler Barrier实现的。<br> 一个signal fence的<a href="https://stackoverflow.com/questions/18449291/when-is-a-compiler-only-memory-barrier-such-as-stdatomic-signal-fence-useful" target="_blank" rel="noopener">作用是</a></p>
<ol>
<li>强制单线程和该线程上的异步中断之间的顺序性</li>
<li>强制单核上运行的多线程之间的顺序性<br> 注意到在SMP架构下这一点难以保证，所以对于多线程程序往往需要更强的thread fence。</li>
</ol>
</li>
</ol>
<h3 id="thread-fence"><a href="#thread-fence" class="headerlink" title="thread fence"></a>thread fence</h3><p>thread fence也就是所谓的内存屏障。根据 <a href="https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence" target="_blank" rel="noopener">cppreference</a>，它的作用是同步non-atomic和relaxed atomic之间的order。</p>
<h4 id="一个简单的例子"><a href="#一个简单的例子" class="headerlink" title="一个简单的例子"></a>一个简单的例子</h4><p>【Q】 thread fence是否只对atomic变量起作用呢？比如对于plain(non-atomic)变量呢？<br>答案是：可以起作用，但必须借助于atomic变量。</p>
<p>不妨用下面<a href="https://stackoverflow.com/questions/54110588/atomic-thread-fence-why-is-there-a-data-race-on-this-non-atomic-variable-and-d" target="_blank" rel="noopener">SoF上的错误的例子进行解释</a>。这个代码中存在 data race。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> isDataReady = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">int</span> data = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Producer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  data = <span class="number">42</span>;</span><br><span class="line">  <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_release);</span><br><span class="line">  isDataReady = <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Consumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(!isDataReady);</span><br><span class="line">  <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">  assert(data == <span class="number">42</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个程序存在下面的问题：</p>
<ol>
<li><code>while(!isDataReady)</code>会被干成死循环，或者直接干掉<br> 这是因为编译器不知道isDataReady可能会被其他线程改。<br> 【Q】不过我印象里C++编译器会倾向于假设<code>while(x)</code>不是死循环？</li>
<li>理论上，因为读<code>isDataReady</code>这个bool不是原子的，所以可能脏读</li>
<li>对isDataReady的修改可能其他线程不可见<br> 看评论，因为<code>isDataReady</code>不是原子的，所以可能这个修改可能不会立即体现到内存上。<br> 而如果需要使用fence/fence同步的机制，则<strong>需要一个原子变量</strong>。这里没有，所以行为未知。</li>
</ol>
<h4 id="full-general-thread-fence"><a href="#full-general-thread-fence" class="headerlink" title="full/general thread fence"></a>full/general thread fence</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// x86</span></span><br><span class="line"><span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">"mfence"</span>:::<span class="string">"memory"</span>)</span></span></span><br><span class="line"><span class="function"><span class="comment">// gcc</span></span></span><br><span class="line"><span class="function">__sync_synchronize</span></span><br><span class="line"><span class="function"><span class="comment">// msvc</span></span></span><br><span class="line"><span class="function"><span class="title">MemoryBarrier</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="comment">// c++11</span></span></span><br><span class="line">std::atomic_thread_fence(memory_order_seq_cst)</span><br><span class="line"><span class="comment">// other methods</span></span><br><span class="line">_mm_mfence</span><br></pre></td></tr></table></figure>

<p>我们需要注意的是内存屏障是相当耗时的操作，甚至还要超过原子操作，内存屏障还会干扰CPU的流水线，导致性能的降低。</p>
<h5 id="MSVC的atomic-thread-fence实现"><a href="#MSVC的atomic-thread-fence实现" class="headerlink" title="MSVC的atomic_thread_fence实现"></a>MSVC的atomic_thread_fence实现</h5><p>介绍标准库<code>atomic_thread_fence</code>函数的实现</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MSVC</span></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span> _Atomic_thread_fence(memory_order _Order)</span><br><span class="line">    &#123;   <span class="comment">/* force memory visibility and inhibit compiler reordering */</span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">if</span> defined(_M_ARM) || defined(_M_ARM64)</span></span><br><span class="line">    <span class="keyword">if</span> (_Order != memory_order_relaxed)</span><br><span class="line">        &#123;</span><br><span class="line">        _Memory_barrier();</span><br><span class="line">        &#125;</span><br><span class="line"> <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    _Compiler_barrier();</span><br><span class="line">    <span class="keyword">if</span> (_Order == memory_order_seq_cst)</span><br><span class="line">        &#123;   <span class="comment">/* force visibility */</span></span><br><span class="line">        <span class="keyword">static</span> _Uint4_t _Guard;</span><br><span class="line">        _Atomic_exchange_4(&amp;_Guard, <span class="number">0</span>, memory_order_seq_cst);</span><br><span class="line">        _Compiler_barrier();</span><br><span class="line">        &#125;</span><br><span class="line"> <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// GCC</span></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span></span><br><span class="line">atomic_thread_fence(memory_order __m) <span class="keyword">noexcept</span></span><br><span class="line">&#123; __atomic_thread_fence(__m); &#125;</span><br></pre></td></tr></table></figure>

<p>可以发现ARM架构下就直接上<code>_Memory_barrier()</code>了。</p>
<p>而由于x86自带的acquire/release语义，除非是最强的<code>memory_order_seq_cst</code>，否则<code>atomic_thread_fence</code>等价于<code>atomic_signal_fence</code>。</p>
<p>而x86实现<code>memory_order_seq_cst</code>下的thread fence则比较奇特，为啥不直接插入一个<code>MemoryBarrier()</code>，<a href="https://stackoverflow.com/questions/48316830/why-does-this-stdatomic-thread-fence-work" target="_blank" rel="noopener">而是利用了一个原子操作呢</a>？结论是<code>_Atomic_exchange_4</code>这个函数会自动生成一个<code>LOCK XCHG</code>，这个指令是一个full memory barrier，类似于mfence。</p>
<p>当然，SoF上老哥还提到了这个实现很傻逼，不如直接用mfence。有人说这是因为<a href="https://www.cnblogs.com/icanth/archive/2012/06/10/2544300.html" target="_blank" rel="noopener">32位的CPU上不支持mfence</a>，但是老哥自己在godbolt验证了在64架构下的GCC9已经能编译出mfence了。</p>
<p>进一步的，在<a href="https://stackoverflow.com/questions/27595595/when-are-x86-lfence-sfence-and-mfence-instructions-required" target="_blank" rel="noopener">这篇文章中</a>，答主列出了四种实现Seq的方法，并且指出GCC用了第一种，MSVC用了第二种，虽然有bug(2012版本)，所以MSVC在这块的实现确实是不需要借鉴的。</p>
<ol>
<li>LOAD (without fence) and STORE + MFENCE</li>
<li>LOAD (without fence) and LOCK XCHG</li>
<li>MFENCE + LOAD and STORE (without fence)</li>
<li>LOCK XADD ( 0 ) and STORE (without fence)</li>
</ol>
<h4 id="acquire-release-thread-fence"><a href="#acquire-release-thread-fence" class="headerlink" title="acquire/release thread fence"></a>acquire/release thread fence</h4><p>下面说明<a href="https://preshing.com/20130922/acquire-and-release-fences/" target="_blank" rel="noopener">acquire/release fence</a>。需要注意，这两个模型即使组合起来也不能禁止其前面的W和后面的R重排，可以看Store-Load章节。</p>
<p>注意，这里的重排到前和后，并不是针对的fence，而是针对的fence周围的read和write。</p>
<p>【Q】这个是对当前线程，还是所有线程而言的？<br>【Q】fence中涉及fence，fence前面的rw，fence后面的rw三个。这里不仅是前面的不能排到后面去，也包括了后面的不能排到前面来？看起来是的，以<a href="https://stackoverflow.com/questions/70616742/can-atomic-thread-fenceacquire-prevent-previous-loads-being-reordered-after-it/70618465?noredirect=1#comment124840255_70618465" target="_blank" rel="noopener">LoadStore乱序为例</a>，</p>
<h5 id="acquire-fence"><a href="#acquire-fence" class="headerlink" title="acquire fence"></a>acquire fence</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_acquire);</span><br></pre></td></tr></table></figure>

<p>fence后面的RW不能与fence前面的R重排。也就是后面的RW不能重排到原本在fence前面的所有R前。<br>即不能重排load-store，load-load。<br>例如下面的是不行的，其中<code>==</code>表示acquire fence。</p>
<ol>
<li><p>load-store<br> 总共3!中顺序，除了原始的哪一种，其它所有的顺序都不允许。<br> 直觉来看，如果允许 load-store 会有问题。例如如果 load 排到 store 后面，那么读到的就可能是一个后面写入的值。可以结合之前的atomic load 和 store 来理解。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">R1       W2</span><br><span class="line">==  -x-&gt; R1</span><br><span class="line">W2       ==</span><br><span class="line"></span><br><span class="line">R1       W2</span><br><span class="line">==  -x-&gt; ==</span><br><span class="line">W2       R1</span><br><span class="line"></span><br><span class="line">R1       ==</span><br><span class="line">==  -x-&gt; W2</span><br><span class="line">W2       R1</span><br><span class="line"></span><br><span class="line">R1       R1</span><br><span class="line">==  -x-&gt; W2</span><br><span class="line">W2       ==</span><br><span class="line"></span><br><span class="line">R1       ==</span><br><span class="line">==  -x-&gt; R1</span><br><span class="line">W2       W2</span><br></pre></td></tr></table></figure></li>
<li><p>load-load</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">R1       R2</span><br><span class="line">==  -x-&gt; ==</span><br><span class="line">R2       R1</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="release-fence"><a href="#release-fence" class="headerlink" title="release fence"></a>release fence</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_release);</span><br></pre></td></tr></table></figure>

<p>fence前面的RW不能和fence后面的W重排。也就是前面的RW不能重排到原本在fence后面的所有W后。<br>即不能重排load-store，store-store。类似于 acquire fence，它同样禁止 load-store。</p>
<h3 id="fence-atomic同步、fence-fence同步"><a href="#fence-atomic同步、fence-fence同步" class="headerlink" title="fence/atomic同步、fence/fence同步"></a>fence/atomic同步、fence/fence同步</h3><p>进一步看一下<a href="https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence#:~:text=Atomic-fence%20synchronization%20An%20atomic%20release%20operation%20X%20in,an%20atomic%20read%20Y%20%28with%20any%20memory%20order%29" target="_blank" rel="noopener">cppreference</a></p>
<h4 id="Fence-atomic-synchronization"><a href="#Fence-atomic-synchronization" class="headerlink" title="Fence-atomic synchronization"></a>Fence-atomic synchronization</h4><p>在下列条件下，线程 A 中的一个 release fence F synchronizes-with 线程 B 中的 atomic acquire 操作 Y，如果：</p>
<ol>
<li>存在一个任意 memory order 的 atomic store X<br> 比如下面的 X store</li>
<li>Y 读取 X 写的值，或者如果 X 是一个 release 操作且这个值被 release sequence headed by X 写入</li>
<li>在 thread A 中，F sequenced-before X<br> 在线程 A 中，F sequenced-before X。</li>
</ol>
<p>这个情况下：</p>
<ol>
<li>考虑线程 A 中所有的非原子及 relax atomic store 操作<br> 比如 α。</li>
<li>如果它们 sequenced-before F<br> 在线程 A 中，α sequenced-before F。</li>
<li>那么将 happen-before<br> 如下所示，所有的 α happen-before β。</li>
<li>线程 B 中 Y 之后的所有对同一位置的非原子及 relax atomic load 操作<br> 比如 β。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">thread A                            thread B</span><br><span class="line">non-atomic/atomic relax store (α)</span><br><span class="line">F</span><br><span class="line">X store(arbitrary order)</span><br><span class="line">                                    Y load(acquire order) value written by X</span><br><span class="line">                                    non-atomic/atomic relax load (β)</span><br></pre></td></tr></table></figure>

<h4 id="Atomic-fence-synchronization"><a href="#Atomic-fence-synchronization" class="headerlink" title="Atomic-fence synchronization"></a>Atomic-fence synchronization</h4><p>An atomic release operation X in thread A synchronizes-with an acquire fence F in thread B, if</p>
<ol>
<li>there exists an atomic read Y (with any memory order)</li>
<li>Y reads the value written by X (or by the release sequence headed by X)</li>
<li>Y is sequenced-before F in thread B</li>
</ol>
<p>In this case, all non-atomic and relaxed atomic stores that are sequenced-before X in thread A will happen-before all non-atomic and relaxed atomic loads from the same locations made in thread B after F.</p>
<h4 id="Fence-fence-synchronization"><a href="#Fence-fence-synchronization" class="headerlink" title="Fence-fence synchronization"></a>Fence-fence synchronization</h4><p>A release fence FA in thread A synchronizes-with an acquire fence FB in thread B, if</p>
<ol>
<li>There exists an atomic object M,</li>
<li>There exists an atomic write X (with any memory order) that modifies M in thread A<br> 在thread A中有个对<strong>atomic</strong>对象M的<strong>atomic</strong>写(但是order不论)。</li>
<li>FA is sequenced-before X in thread A<br> 在这个写之<strong>前</strong>放个FA(acquire fence)。</li>
<li>There exists an atomic read Y (with any memory order) in thread B<br> 在thread B中有个对<strong>atomic</strong>对象M的<strong>atomic</strong>读(但是order不论)。</li>
<li>Y reads the value written by X (or the value would be written by release sequence headed by X if X were a release operation)</li>
<li>Y is sequenced-before FB in thread B<br> 在这个读之<strong>后</strong>放个F(release fence)</li>
</ol>
<p>In this case, all non-atomic and relaxed atomic stores that are sequenced-before FA in thread A will happen-before all non-atomic and relaxed atomic loads from the same locations made in thread B after FB.</p>
<p>那么thread A中所有FA之前的non-atomic/relaxed操作，一定happen-before thread B中所有FB之后的non-atomic/relaxed操作。也就是 α happend-before β。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">thread A                            thread B</span><br><span class="line">non-atomic/atomic relax store(α)</span><br><span class="line">FA</span><br><span class="line">M store(arbitrary order) (X)</span><br><span class="line">                                    M load(arbitrary order) value written by X (Y)</span><br><span class="line">                                    FB</span><br><span class="line">                                    non-atomic/atomic relax load (β)</span><br></pre></td></tr></table></figure>

<h4 id="thread-fence-和-barrier-指令间的关系"><a href="#thread-fence-和-barrier-指令间的关系" class="headerlink" title="thread fence 和 barrier 指令间的关系"></a>thread fence 和 barrier 指令间的关系</h4><p>有一种理解对内存屏障进行如下的区分：</p>
<ol>
<li>Store Barrier强制所有屏障<strong>前</strong>的store指令，都在屏障指令执行之前被执行，并drain store buffer的数据。</li>
<li>Load Barrier强制所有屏障<strong>后</strong>的load指令，都在屏障指令执行之后被执行，并且一直等到load缓冲区被该CPU读完才能执行之后的load指令。</li>
<li>Full Barrier同时具有Store和Load Barrier的全部作用。</li>
</ol>
<p>但根据前面对sfence/lfence/mfence的介绍，其实sfence和lfence都不能对应Store/Load Barrier。</p>
<h3 id="Store-Load乱序问题"><a href="#Store-Load乱序问题" class="headerlink" title="Store-Load乱序问题"></a>Store-Load乱序问题</h3><p>在前面的讨论中提到了x86的Store-Load乱序问题，对于x86，Loads May Be Reordered with Earlier Stores to Different Locations，但<a href="https://software.intel.com/en-us/forums/intel-moderncode-for-parallel-architectures/topic/277126" target="_blank" rel="noopener">对于相同地址则不会乱序</a>。</p>
<p>在<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/" target="_blank" rel="noopener">这篇博文</a>中记录了一个有关Store-Load乱序的实验。在实验中，X的写操作可能被延迟到Y的读操作之后，尽管我们插入了compiler barrier。</p>
<p>这时候需要一个full/general memory barrier，也就是实现让它前面所有的Load/Store操作对它后面的Load/Store操作都是可见的，包括了禁止Store-Load类型的乱序。在同一篇博文中指出可以使用插入一个<code>mfence</code>，以实现full/general memory barrier。</p>
<p>在C++中，可以插入一个<code>atomic_thread_fence(memory_order_seq_cst)</code>，<a href="https://stackoverflow.com/questions/25478029/does-atomic-thread-fencememory-order-seq-cst-have-the-semantics-of-a-full-memo" target="_blank" rel="noopener">它可以始终产生一个full memory barrier</a>。</p>
<p>因此在x86上至少要对<code>LOAD</code>/<code>STORE</code>其中的一个加上<code>MFENCE</code>，或者用一个<code>LOCK</code>指令，而这也实现了类似<code>memory_order_seq_cst</code>的效果。在章节内存模型的实现中还有更多说明。<br>下面的代码不一定是等价的</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">atomic&lt;<span class="keyword">int</span>&gt; x, y</span><br><span class="line"></span><br><span class="line">y.store(<span class="number">1</span>, memory_order_relaxed);            <span class="comment">//(1)</span></span><br><span class="line">atomic_thread_fence(memory_order_seq_cst);   <span class="comment">//(2)</span></span><br><span class="line">x.load(memory_order_relaxed);                <span class="comment">//(3)</span></span><br><span class="line"></span><br><span class="line">atomic&lt;<span class="keyword">int</span>&gt; x, y;</span><br><span class="line">y.store(<span class="number">1</span>, memory_order_seq_cst);            <span class="comment">//(1)</span></span><br><span class="line"><span class="comment">// Nothing</span></span><br><span class="line">x.load(memory_order_seq_cst);                <span class="comment">//(3)</span></span><br></pre></td></tr></table></figure>

<h3 id="通过fence和barrier实现同步"><a href="#通过fence和barrier实现同步" class="headerlink" title="通过fence和barrier实现同步"></a>通过fence和barrier实现同步</h3><p>一般来说，如果需要实现同步，则直接使用原子变量(atomic variable)会安全很多。但其实通过加入 Compiler Barrier 和 Memory Barrier 是可以实现六种内存模型的 atomic store 和 atomic load 的。</p>
<h4 id="atomic-variable-VS-atomic-fence"><a href="#atomic-variable-VS-atomic-fence" class="headerlink" title="atomic variable VS atomic fence"></a>atomic variable VS atomic fence</h4><p>我们可以用fence替换atomic store/load。</p>
<p>可以结合下面两张图对比</p>
<p>|atomic variable|atomic fence|<br>|:-:|:-:|:-:|<br>|<img src="/img/concur/acquire_atomic.png">|<img src="/img/concur/acquire_fence.png">|</p>
<h3 id="Acq-Rel"><a href="#Acq-Rel" class="headerlink" title="Acq/Rel"></a>Acq/Rel</h3><p>在<a href="https://stackoverflow.com/questions/7461484/memory-model-ordering-and-visibility" target="_blank" rel="noopener">SoF中指出</a>acquire/release 一个 atomic variable 可以通过在 relax 后面加一道对应 memory order 的 thread fence 来替换。</p>
<p>这里注意，fence 加在 load 后面，store 前面。可以从 fence 禁止重排的类型来理解。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对于 load</span></span><br><span class="line">a.load(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line"><span class="comment">// can be replaced by, but not equivalent</span></span><br><span class="line">a.load(<span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line"><span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对于 store</span></span><br><span class="line">a.store(<span class="number">1</span>, <span class="built_in">std</span>::memory_order_release);</span><br><span class="line"><span class="comment">// can be replaced by, but not equivalent</span></span><br><span class="line"><span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_release);</span><br><span class="line">a.store(<span class="number">1</span>, <span class="built_in">std</span>::memory_order_relaxed);</span><br></pre></td></tr></table></figure>

<p>但其实<a href="https://www.modernescpp.com/index.php/acquire-release-fences" target="_blank" rel="noopener">这里的替换未必是等价的</a>：</p>
<ol>
<li>A memory barrier with acquire semantic establishes stronger ordering constraints. Although the acquire operation on an atomic and on a memory barrier requires, that no read or write operation can be moved before the acquire operation, there is an additional guarantee with the acquire memory barrier. No read operation can be moved after the acquire memory barrier.<br> 尽管 atomic acquire 操作，或者 acquire 的 memory barrier 要求没有 RW 操作可以被移动到这个 acquire 之前。但 aquire memory barrier 还有一个额外的保证，也就是没有读操作可以被移动到这个 aquire 之后。</li>
<li>The relaxed semantic is sufficient for the reading of the atomic variable var. The std::atomic_thread_fence(std::memory_order_acquire) ensures that this operation can not be moved after the acquire fence.<br> 这个感觉和上面一个意思</li>
</ol>
<p>此外，如果不显式加入 fence 的话，编译器可以视情况生成等价的更好的代码。</p>
<p>而在x86等强内存模型架构cpu上，也不一定生成fence，例如单独的<code>atomic_thread_fence(memory_order_acquire)</code>就可以简化为nop。</p>
<h4 id="SeqCst"><a href="#SeqCst" class="headerlink" title="SeqCst"></a>SeqCst</h4><p>而<code>memory_order_seq_cst</code>则需要额外的<code>MFENCE</code>或者<code>LOCK</code>，这个之前已经说过。<br><a href="https://stackoverflow.com/questions/42450342/whats-the-difference-between-atomic-store-and-atomic-thread-fence" target="_blank" rel="noopener">下面的代码</a>是等价的</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (var.load(<span class="built_in">std</span>::memory_order_acquire) == <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">    assert(a==<span class="number">123</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (var.load(<span class="built_in">std</span>::memory_order_relaxed) == <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">    assert(a==<span class="number">123</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="无等待"><a href="#无等待" class="headerlink" title="无等待"></a>无等待</h2><p>无等待(Wait-Free)是比锁无关更高层面的并发。无等待指的是程序中的每个线程都可以一直运行下去而不阻塞。</p>
<h2 id="无锁编程实战"><a href="#无锁编程实战" class="headerlink" title="无锁编程实战"></a>无锁编程实战</h2><h3 id="读写共享对象"><a href="#读写共享对象" class="headerlink" title="读写共享对象"></a>读写共享对象</h3><p>来自yubai大佬的<a href="http://oceanbase.org.cn/?p=82" target="_blank" rel="noopener">共享对象的并发读写</a>。<br>多个线程对下面这个对象进行读写。显然，这个超过了128bit，没法一次原子操作来搞定。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">GConf</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="keyword">int64_t</span> a;</span><br><span class="line">  <span class="keyword">int64_t</span> b;</span><br><span class="line">  <span class="keyword">int64_t</span> c;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<ol>
<li>读写锁<br> 容易读者和锁者互相阻塞。</li>
<li>COW 第一版<br> 这个也介绍过，在更新的时候原子地swap指针。<br> 一个要点是，旧的Version不能立刻被析构，而应该维护一个引用计数。<br> 但我们很快想到，类似于实现单例的过程，取对象指针，以及根据指针读取该对象的引用计数并判断要不要swap这两个操作并不是原子的。</li>
<li>COW 第二版<br> 一个简单的办法是将上面两个阶段用锁保护起来。这个锁是全局的。</li>
<li>COW 第三版<br> 现在需要设计一个无锁的办法。</li>
<li>HazardPointer</li>
</ol>
<h3 id="使用内存模型解决双重检查锁定模式-DCLP-存在的问题"><a href="#使用内存模型解决双重检查锁定模式-DCLP-存在的问题" class="headerlink" title="使用内存模型解决双重检查锁定模式(DCLP)存在的问题"></a>使用内存模型解决双重检查锁定模式(DCLP)存在的问题</h3><p>在之前的章节中，我们曾经提到过双重检查锁定模式中存在的问题，对此文章<a href="http://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/" target="_blank" rel="noopener">Double-Checked Locking is Fixed In C++11</a>指出我们可以通过适当的fence或者atomic store/load语义来解决。</p>
<h4 id="使用atomic-store-load语义"><a href="#使用atomic-store-load语义" class="headerlink" title="使用atomic store/load语义"></a>使用atomic store/load语义</h4><p>对于下面的代码，解答几个问题：</p>
<ol>
<li><p>为什么第一个load至少是acquire的？<br> 因为<code>m_instance.load(acquire)</code>一定能看到<code>m_instance.store(release)</code>，所以也一定能看到<code>tmp = new Singleton</code>。<br> 如果都是relaxed，那么锁是约束线程间行为的最后一道屏障了。那么<code>m_instance.store</code>可能会被reorder到锁的作用域退出之后，就会出现下面的情况。</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">T2: <span class="keyword">if</span> (tmp == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">T2: &#125;</span><br><span class="line">T2: &#125; <span class="comment">// 锁被释放了</span></span><br><span class="line"></span><br><span class="line">T1: Singleton* tmp = m_instance.load(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">...</span><br><span class="line">T1: <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(m_mutex);</span><br><span class="line">...</span><br><span class="line">T1: tmp = <span class="keyword">new</span> Singleton;</span><br><span class="line">T2: tmp = <span class="keyword">new</span> Singleton;</span><br><span class="line"></span><br><span class="line">T2: m_instance.store(tmp, <span class="built_in">std</span>::memory_order_release);</span><br></pre></td></tr></table></figure></li>
<li><p>为什么这里只需要acquire和release就够了？</p>
</li>
<li><p>为什么第二个load是relaxed的？<br> 首先这里有个锁保护着，只有一个线程能执行第二个load。<br> 然后第二个load是Sequenced-before后面的store的。</p>
</li>
<li><p>为什么还要锁？<br> 这个之前讲过，<code>tmp = new Singleton</code>不是原子的。</p>
</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;Singleton*&gt; Singleton::m_instance;</span><br><span class="line"><span class="built_in">std</span>::mutex Singleton::m_mutex;</span><br><span class="line"></span><br><span class="line">Singleton* Singleton::getInstance() &#123;</span><br><span class="line">    Singleton* tmp = m_instance.load(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">    <span class="keyword">if</span> (tmp == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(m_mutex);</span><br><span class="line">        tmp = m_instance.load(<span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">        <span class="keyword">if</span> (tmp == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            tmp = <span class="keyword">new</span> Singleton;</span><br><span class="line">            m_instance.store(tmp, <span class="built_in">std</span>::memory_order_release);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> tmp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="使用fence"><a href="#使用fence" class="headerlink" title="使用fence"></a>使用fence</h4><p>主要是几点：</p>
<ol>
<li>为什么对m_instance的读写仍然要是原子的？</li>
<li>在load后和store前插入fence</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;Singleton*&gt; Singleton::m_instance;</span><br><span class="line"><span class="built_in">std</span>::mutex Singleton::m_mutex;</span><br><span class="line"></span><br><span class="line">Singleton* Singleton::getInstance() &#123;</span><br><span class="line">    Singleton* tmp = m_instance.load(<span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">    <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">    <span class="keyword">if</span> (tmp == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(m_mutex);</span><br><span class="line">        tmp = m_instance.load(<span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">        <span class="keyword">if</span> (tmp == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            tmp = <span class="keyword">new</span> Singleton;</span><br><span class="line">            <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_release);</span><br><span class="line">            m_instance.store(tmp, <span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> tmp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面的代码可以对应到下面的图上<br><img src="/img/bfbc/dclpjj.png"></p>
<h3 id="基于CAS实现自旋锁"><a href="#基于CAS实现自旋锁" class="headerlink" title="基于CAS实现自旋锁"></a>基于CAS实现自旋锁</h3><p>摘录自<a href="https://www.cnblogs.com/FateTHarlaown/p/9170474.html" target="_blank" rel="noopener">博客</a>。<br>可以通过<code>i++</code>的方式来检验对错。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpinLock</span> &#123;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    SpinLock() : flag_(<span class="literal">false</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">bool</span> expect = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">while</span> (!flag_.compare_exchange_weak(expect, <span class="literal">true</span>))</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 这里一定要将expect复原，执行失败时expect结果是未定的</span></span><br><span class="line">            expect = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        flag_.store(<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">std</span>::atomic&lt;<span class="keyword">bool</span>&gt; flag_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>上面的实现比较基础，但是有个问题，其他线程可以直接调用<code>unlock</code>来解锁。事实上，我们可以加一下线程唯一性的东西，保证只有持有锁的线程才能解锁。</p>
<p>此外，在下面介绍如何通过<code>std::atomic_flag</code>实现自旋锁。</p>
<h3 id="无锁队列"><a href="#无锁队列" class="headerlink" title="无锁队列"></a>无锁队列</h3><p>被移动到<a href="/2017/12/28/lockfree-queue/">Lockfree Queue</a>。</p>
<h1 id="多线程并发模型"><a href="#多线程并发模型" class="headerlink" title="多线程并发模型"></a>多线程并发模型</h1><p>在本章节中将讨论多线程编程中变量共享与消息传递机制。</p>
<h2 id="共享-vs-通信"><a href="#共享-vs-通信" class="headerlink" title="共享 vs 通信"></a>共享 vs 通信</h2><p>通过共享来通信，和通过通信来共享，是并发编程中的两种不同模式。</p>
<h2 id="虚假唤醒-spurious-wakeup"><a href="#虚假唤醒-spurious-wakeup" class="headerlink" title="虚假唤醒(spurious wakeup)"></a>虚假唤醒(spurious wakeup)</h2><p>条件变量的通信模型可能导致<a href="https://en.m.wikipedia.org/wiki/Spurious_wakeup" target="_blank" rel="noopener">虚假唤醒/伪唤醒(spurious wakeup)的问题</a>。</p>
<p>虚假唤醒指的是在条件变量上等待的线程被唤醒之后，却发现条件不满足。这样看下来，似乎线程毫无缘由地就被唤醒了。</p>
<p>为什么会发生这种现象呢？考虑：</p>
<ol>
<li>条件 <code>condition</code> 被满足</li>
<li>线程 A 被唤醒</li>
<li>线程 B 被唤醒</li>
<li>线程 B 获得锁，从 wait 返回，并重置了 <code>condition</code><br> 注意，即使是虚假唤醒的情况，<code>cv.wait</code>也是<strong>在获得锁之后再返回</strong></li>
<li>线程 A 尝试获得锁并从 wait 返回，发现 condition 已经不满足了</li>
</ol>
<p>可以想到，如果条件满足了，并且只能被一个线程消费，我们整个 <code>notify_all()</code> 把大家都叫起来，肯定会虚假唤醒，其实也就是所谓的惊群效应。</p>
<p>但是如果我们每次都 <code>notify_one()</code>，是不是就不会发生这样的事情呢？其实并不是这样，在很多 <code>notify_one()</code> 的实现中，会唤醒不止一个线程。譬如：</p>
<ol>
<li>在多处理器系统和<strong>接收Linux信号</strong>时，出于性能因素允许了虚假唤醒存在</li>
<li>APUE指出<code>pthread_cond_signal</code>函数可能唤起多个线程。</li>
<li><a href="https://stackoverflow.com/questions/1050592/do-spurious-wakeups-actually-happen" target="_blank" rel="noopener">当等待队列中的Linux线程收到一个系统信号时，会得到虚假唤醒</a></li>
<li><a href="https://stackoverflow.com/questions/1461913/does-c-sharp-monitor-wait-suffer-from-spurious-wakeups/1461956#1461956" target="_blank" rel="noopener">Jon Skeet大神指出其深层次原因是没有任何的保障是一个被唤醒(awakened)的线程一定会被调度(scheduled)</a></li>
</ol>
<h3 id="复现虚假唤醒"><a href="#复现虚假唤醒" class="headerlink" title="复现虚假唤醒"></a>复现虚假唤醒</h3><p>在<a href="https://segmentfault.com/q/1010000010421523" target="_blank" rel="noopener">SF</a>上记录了一番实验，强行产生虚假唤醒。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">con_var.notify_one();</span><br><span class="line"><span class="comment">// trigger the spurious wakeup</span></span><br><span class="line">lock.unlock();</span><br><span class="line"><span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">2</span>));</span><br><span class="line">condition = <span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p>可以发现在 notify 和 unlock 两个过程之后的两秒内消费者线程已经被唤醒了，但在拿到锁和条件变量后它发现其实<code>condition</code>值并不为<code>true</code>，这就产生了一次虚假唤醒。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>可以将wait包裹在一个while循环里面，如<code>wait_for_event</code>所示。</p>
<h2 id="惊群效应"><a href="#惊群效应" class="headerlink" title="惊群效应"></a>惊群效应</h2><p>惊群效应是指多进程在 wait 的时候，如果希望唤起特定的几个，或者不清楚需要唤醒几个，就得使用<code>notify_all()</code>唤醒全部线程。但是最终大部分的唤醒都是无效的，甚至只有一个线程能够真的获得锁。</p>
<ol>
<li>notify_one 的常见场景<br> accept 调用中，当多个线程的套接口 listen 同一个 fd 时，内核只 notify 等待队列最顶部的套接口。</li>
<li>notify_all 的常见场景<br> <code>epoll</code>，内核不知道究竟有多少个线程需要被唤醒。</li>
</ol>
<p>惊群效应的影响是造成性能浪费，例如线程调度造成的上下文切换开销。<br>一些<a href="https://www.zhihu.com/question/22756773" target="_blank" rel="noopener">解决惊群的方案</a>包括：</p>
<ol>
<li><p>epoll</p>
</li>
<li><p>Linux网络内核对accept的优化<br> 我们知道，单线程listen/accept往往不能很好处理高并发的连接。因此通常会选择用多个线程去accept同一个套接字。<br> 如下所示，每一个子进程在fork之后，都会去accept，并且send一些数据，然后关闭连接。但是在Linux早期版本中，当新的连接到来时，所有睡在accept上的进程都会被唤醒，但是因为只有一个进程最终能accpet成功，这也是惊群现象。<br> 后续版本中，引入了<code>WQ_FLAG_EXCLUSIVE</code>解决该问题。</p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/socket.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;netinet/in.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;  </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> PROCESS_NUM 10  </span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="keyword">int</span> fd = socket(PF_INET, SOCK_STREAM, <span class="number">0</span>);  </span><br><span class="line">    <span class="keyword">int</span> connfd;  </span><br><span class="line">    <span class="keyword">int</span> pid;  </span><br><span class="line">    <span class="keyword">char</span> sendbuff[<span class="number">1024</span>];  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">serveraddr</span>;</span>  </span><br><span class="line">    serveraddr.sin_family = AF_INET;  </span><br><span class="line">    serveraddr.sin_addr.s_addr = htonl(INADDR_ANY);  </span><br><span class="line">    serveraddr.sin_port = htons(<span class="number">1234</span>);  </span><br><span class="line">    bind(fd, (struct sockaddr*)&amp;serveraddr, <span class="keyword">sizeof</span>(serveraddr));  </span><br><span class="line">    listen(fd, <span class="number">1024</span>);  </span><br><span class="line">    <span class="keyword">int</span> i;  </span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; PROCESS_NUM; i++)  </span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="keyword">int</span> pid = fork();  </span><br><span class="line">        <span class="keyword">if</span>(pid == <span class="number">0</span>)  </span><br><span class="line">        &#123;  </span><br><span class="line">            <span class="keyword">while</span>(<span class="number">1</span>)  </span><br><span class="line">            &#123;  </span><br><span class="line">                connfd = accept(fd, (struct sockaddr*)<span class="literal">NULL</span>, <span class="literal">NULL</span>);  </span><br><span class="line">                <span class="built_in">snprintf</span>(sendbuff, <span class="keyword">sizeof</span>(sendbuff), <span class="string">"accept PID is %d\n"</span>, getpid());  </span><br><span class="line">                </span><br><span class="line">                send(connfd, sendbuff, <span class="built_in">strlen</span>(sendbuff) + <span class="number">1</span>, <span class="number">0</span>);  </span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">"process %d accept success!\n"</span>, getpid());  </span><br><span class="line">                close(connfd);  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">int</span> status;  </span><br><span class="line">    wait(&amp;status);  </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><code>SO_REUSEPORT</code>/<code>SO_REUSEADDR</code><br> 这个Linux3.9版本带来的新特性，类似于一个负载均衡。<br> 在使用<code>SO_REUSEPORT</code>后，多个进程可以同时bing和listen同一个<code>ip:port</code>，<strong>产生多个套接字</strong>，然后由内核决定将新连接发送给谁。当然，监听这些端口的套接口只能在同一个用户(effective user id)下面，这是为了保证安全性。<br> 这里特别说明一下，因为套接口连接是五元组，所以对于同一个四元组，可以建立tcp连接和udp连接。但是如果不开启<code>SO_REUSEPORT</code>选项，是不能多个套接口绑定到一个port上的，我们可以简单想一想，此时一个tcp包来了，我们如何选择对应的套接字呢？没有<code>SO_REUSEPORT</code>的情况下，默认报错；有<code>SO_REUSEPORT</code>的情况下，我们随机选一个。<br> 但是在<a href="https://zhuanlan.zhihu.com/p/230888784" target="_blank" rel="noopener">文章中指出</a>，并不一定能够实现负载均衡。</p>
</li>
</ol>
<h2 id="条件变量-Condition-Variable"><a href="#条件变量-Condition-Variable" class="headerlink" title="条件变量 Condition Variable"></a>条件变量 Condition Variable</h2><h3 id="C-中的-condition-variable"><a href="#C-中的-condition-variable" class="headerlink" title="C++ 中的 condition_variable"></a>C++ 中的 condition_variable</h3><p>锁 <code>lock_guard</code> 和 <code>unique_lock</code> 能够保证线程之间的互斥访问临界资源，但是不能控制这些访问的先后顺序。自然而然地可以想到可以用锁维护一个共享变量记录状态，以实现线程间同步的措施，例如在生产者/消费者模型中用它来描述产品数量。一个比较 naive 的方式是轮询(poll)，注意在实现时仍然是需要锁的，否则可能两个互相竞争的线程同时获得flag。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> flag;</span><br><span class="line"><span class="built_in">std</span>::mutex m;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">wait_for_flag</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lk(m);</span><br><span class="line">  <span class="keyword">while</span>(!flag)</span><br><span class="line">  &#123;</span><br><span class="line">    lk.unlock();  <span class="comment">// 1 解锁互斥量</span></span><br><span class="line">    <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::milliseconds(<span class="number">100</span>));  <span class="comment">// 2 休眠100ms</span></span><br><span class="line">    lk.lock();   <span class="comment">// 3 再锁互斥量</span></span><br><span class="line">  &#125;</span><br><span class="line">  flag = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>另一种更好的方法是利用条件变量。条件变量(condition variable)利用共享的 mutex 进行线程之间同步，可以理解为实际上是帮用户以一种更好的方法做了轮询。即维护一个等待列表，线程不是用轮询去 pull，而是等待条件变量的 push：</p>
<ol>
<li>当某一个线程所需要的条件不满足时，用户调用 <code>wait</code> 阻塞在 CV 上，此时用户必须持有互斥量<br> wait 的作用是：<ul>
<li>解锁互斥量<br>  这很显然，不然生产者怎么干活呢？</li>
<li>block 当前线程</li>
<li>将当前线程放入等待队列上。该线程后续将会被 <code>notify_one</code>/<code>notify_all</code> 唤醒。<br>注意，wait 方法在返回后，<strong>会获得锁</strong>。这也是符合语义的，因为调用 wait 时本来就需要持有互斥量，不然是 UB。</li>
</ul>
</li>
<li>拥有锁的线程在退出临界区时使用 <code>notify_one</code>/<code>notify_all</code> 发出信号通知条件变量，条件变量会唤醒一个/所有正在等待的线程。</li>
</ol>
<p>不同于其他语言，C++ 中的 <code>wait</code> 还支持传入一个 predicate 参数 stop_waiting。在 wait 结束后，会用 stop_waiting 去检查一下条件是否真的满足。如果不满足说明是虚假唤醒(spurious awakening)，会继续 wait。实际上等价于下面的代码。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt; <span class="class"><span class="keyword">class</span> <span class="title">Predicate</span> &gt;</span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">wait</span>( <span class="title">std</span>:</span>:unique_lock&lt;<span class="built_in">std</span>::mutex&gt;&amp; lock, Predicate stop_waiting );</span><br><span class="line"><span class="comment">// Equals to</span></span><br><span class="line"><span class="keyword">while</span> (!stop_waiting()) &#123;</span><br><span class="line">    wait(lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="条件变量的用法"><a href="#条件变量的用法" class="headerlink" title="条件变量的用法"></a>条件变量的用法</h3><p>使用条件变量等待事件通常是类似下面的形式，容易发现期间需要解锁，所以这里只能用 <code>unique_lock</code> 而不能用 <code>lock_guard</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">wait_for_event</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; uni_lock(mtx);</span><br><span class="line">    <span class="keyword">while</span> (!condition)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 调用wait后发生的操作:</span></span><br><span class="line">        <span class="comment">// 1. 将线程挂到等待队列上</span></span><br><span class="line">        <span class="comment">// 2. 释放锁(前面说过带着锁睡觉会死锁)</span></span><br><span class="line">        <span class="comment">// 3. 进入睡眠阻塞线程</span></span><br><span class="line">        cv.wait(uni_lock, []()&#123;<span class="keyword">return</span> condition;&#125;); <span class="comment">// wait until condition</span></span><br><span class="line">        <span class="comment">// wait返回时会重新获得锁</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">signal_event</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; uni_lock(mtx);</span><br><span class="line">    condition = <span class="literal">true</span>;</span><br><span class="line">    cv.notify_one();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">broadcast_event</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; uni_lock(mtx);</span><br><span class="line">    <span class="comment">// 在notify前需要在锁保护下修改condition</span></span><br><span class="line">    condition = <span class="literal">true</span>;</span><br><span class="line">    cv.notify_all();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意先修改 <code>condition</code>，再 <code>cv.notify_one</code> 和 <code>cv.notify_all</code>。这也是为了保证睡眠线程在收到信号后能够及时观察到条件满足了。</p>
<h4 id="notify-时是否要加锁"><a href="#notify-时是否要加锁" class="headerlink" title="notify 时是否要加锁"></a>notify 时是否要加锁</h4><p>理论上 notify 的时候不一定要拥有锁，例如下面 <a href="https://en.cppreference.com/w/cpp/thread/condition_variable/wait" target="_blank" rel="noopener">cppreference</a> 中的 demo 就没用锁保护</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">signals</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">    <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">1</span>));</span><br><span class="line"> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lk(cv_m);</span><br><span class="line">        i = <span class="number">1</span>;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; <span class="string">"Notifying again...\n"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cv.notify_all();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但需要注意几点问题：</p>
<ol>
<li>修改 condition 必须要加锁<br> 也就是这里 i = 1 必须要用锁保护起来</li>
<li>尽管 notify 可以不上锁，但这可能导致 <a href="https://stackoverflow.com/questions/4544234/calling-pthread-cond-signal-without-locking-mutex" target="_blank" rel="noopener">less optimal scheduling of threads</a>，并且你反正已经上过一次锁了。</li>
</ol>
<p><a href="https://stackoverflow.com/questions/4544234/calling-pthread-cond-signal-without-locking-mutex" target="_blank" rel="noopener">如下代码展示了不保护 condition 如何导致错误</a>，可能在 wait 部分在检测到 condition 不满足准备 <code>pthread_cond_wait</code> 前，另一个线程修改 <code>condition</code> 并 <code>pthread_cond_signal</code>，这样进入 <code>pthread_cond_wait</code> 的 wait 部分代码就会丢失这次的 signal。<br>所以在 signal 部分加锁，让两个 Process 不是 interleave 地执行。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Process A                             Process B</span><br><span class="line"></span><br><span class="line">pthread_mutex_lock(&amp;mutex);</span><br><span class="line">while (condition == FALSE)</span><br><span class="line"></span><br><span class="line">                                      condition = TRUE;</span><br><span class="line">                                      pthread_cond_signal(&amp;cond);</span><br><span class="line"></span><br><span class="line">pthread_cond_wait(&amp;cond, &amp;mutex);</span><br></pre></td></tr></table></figure>

<h4 id="为什么需要维护一个-condition-变量"><a href="#为什么需要维护一个-condition-变量" class="headerlink" title="为什么需要维护一个 condition 变量"></a>为什么需要维护一个 condition 变量</h4><p>不过即使为 signal 部分上锁还可能丢失信号。原因是生产者和消费者竞争同一把锁虽然能够保证 wait 和 signal 是串行的顺序，但可能整个 signal 过程都在 wait 过程前面。陈硕的博客中得到 Case 2 就是这种情况<br><img src="/img.concur/chenshuo2.png"></p>
<p>这一现象广泛出现在使用边缘触发(Edge triggered)机制的程序中，例如 Linux 的信号，<code>pthread_cond_</code> 系列。相对于水平触发，边缘触发只会唤醒<strong>已经等待在 wait 上的线程</strong>(可以参考<a href="/2018/08/01/python-join-no-signal/">Python的Condition条件变量</a>的实现)，因此可能出现丢失信号的问题。例如当 notify 操作早于 wait 操作时，这个 notify 就会丢失了。其实这个也可以认为是虚假唤醒的一种情况。</p>
<p>解决方案就是用一个 condition 来记录。当一个 signal 先于 wait 时，它会设置 condition 为 true。在 wait_for_event 时，有两处地方判断 condition：</p>
<ol>
<li>while 的条件<br> 用来防止虚假唤醒，同时也用来检查是否已经有一个前面的 signal 触发过了，还没来得及被消费。</li>
<li>cv.wait 的 predicate 参数<br> 用来防止虚假唤醒</li>
</ol>
<h4 id="condition-variable-的错误用法"><a href="#condition-variable-的错误用法" class="headerlink" title="condition variable 的错误用法"></a>condition variable 的错误用法</h4><p><del>程序在条件不满足时，<strong>释放锁并阻塞在 CV 上进入睡眠</strong>，这个过程<strong>必须是原子的</strong>。考虑在释放锁之后另一个线程获得锁并发送了 signal，但此时本线程上还没有来得及阻塞在 CV 上，这个信号就不能被本线程收到了。</del></p>
<h3 id="几个有关-CV-和-mutex-之间联系的问题"><a href="#几个有关-CV-和-mutex-之间联系的问题" class="headerlink" title="几个有关 CV 和 mutex 之间联系的问题"></a>几个有关 CV 和 mutex 之间联系的问题</h3><ol>
<li><p>只用 mutex 行不行<br> 我认为这是因为从逻辑上来讲，CV提供了一种新的同步原语。如果使用mutex来进行同步，其实也是可以的。如下面代码所示，两个线程竞争一个<code>mut</code>，以类似轮询的方式来获得同步，不仅很耗资源，而且从逻辑上不够整齐。而CV把<code>consumer</code>的轮询变成了阻塞wait，以<code>provider</code>的通知notify来唤醒，节省了资源，从逻辑上也有了一个完整过程的抽象。</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">provider</span><span class="params">(mut)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        lock(mut)</span><br><span class="line">        count++</span><br><span class="line">        unlock(mut)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">consumer</span><span class="params">(mut)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        lock(mut)</span><br><span class="line">        <span class="keyword">if</span> count:</span><br><span class="line">            count--</span><br><span class="line">        unlock(mut)</span><br></pre></td></tr></table></figure></li>
<li><p>只用 condition variable 行不行<br> 一方面，<code>condition</code>是一个临界变量，必须要用锁来保护。所以之前在 <code>signal_event</code> 中修改 condition 是带锁的。<br> 另一个方面，<code>cv.wait</code>对应的一系列步骤必须<a href="http://blog.csdn.net/ysu108/article/details/49508205" target="_blank" rel="noopener">要是原子的</a>，否则会造成丢失signal的问题。所以也需要用锁保护，在wait中再解锁。<br> 在下一章节中会提到各种 condition variable 的错误用法，我们会详细讨论这两个问题。关于使用CV时使用锁的错误用法<a href="http://www.cppblog.com/Solstice/archive/2015/10/30/203094.html" target="_blank" rel="noopener">在陈硕大牛的博客中</a>还指出了更多的例子，其优化点很多也是为了解决可能的<strong>丢失信号的问题</strong>。</p>
</li>
<li><p>condition variable 是全局一份，还是是生产者和消费者各自创建，通过 mutex 关联<br> wait 和 notify 需要作用在条件变量，而不是 mutex 上。并且这个条件变量需要在内部维护所有的waiter。我们可以看<a href="/2018/08/01/python-join-no-signal/">Python的Condition条件变量</a>的实现来了解这一点。<br> 做到这一点，既可以是全局一份，也可以是各自创建。</p>
</li>
</ol>
<h3 id="信号量的实现"><a href="#信号量的实现" class="headerlink" title="信号量的实现"></a>信号量的实现</h3><p>在 POSIX 和 Linux 中分别提供了两种信号量的实现方式。<br>也可以通过 mutex+cv+counter 来实现信号量。</p>
<h2 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h2><p>Windows内核编程中出现了事件，可以用来替代条件变量的使用。<br>相比使用条件变量显式等待，事件机制将这个<strong>wait</strong>前置，将处理函数直接<strong>register</strong>给一个代理，当需要<strong>notify</strong>时，代理会直接调用这个处理函数。实际上事件机制更类似于对回调的一种封装，能够更好地实现模块化和组件化。事件机制减少了阻塞，因此能更好地服务于异步编程。<br>事件和回调有什么区别？<a href="https://stackoverflow.com/questions/36213948/what-is-the-difference-between-asynchronous-calls-and-callbacks" target="_blank" rel="noopener">回调不一定是异步的</a>。</p>
<h2 id="基于线程的异步调用"><a href="#基于线程的异步调用" class="headerlink" title="基于线程的异步调用"></a>基于线程的异步调用</h2><h3 id="std-thread"><a href="#std-thread" class="headerlink" title="std::thread"></a>std::thread</h3><p><code>std::thread</code>是实现并行最简单的方式了。</p>
<h4 id="区分std-thread和线程实体的生命周期"><a href="#区分std-thread和线程实体的生命周期" class="headerlink" title="区分std::thread和线程实体的生命周期"></a>区分std::thread和线程实体的生命周期</h4><p>线程实体是由操作系统管理的，它不等同于<code>std::thread</code>对象。特别地，<code>std::thread</code>的生命周期是不同于线程实体的。当主线程退出时所有的子线程释放，或者当子线程执行完毕时子线程释放。而<code>std::thread</code>对象遵循所有C++对象的生命周期。</p>
<p><code>std::thread</code>是由程序员管理生命周期的，程序员应当在<code>join()</code>或者<code>detach()</code>后释放<code>std::thread</code>。如果强行析构一个joinable的<code>std::thread</code>会导致异常terminate。</p>
<p>程序员可以通过<code>std::thread</code>控制线程实体，直到调用<code>detach()</code>之后。而一旦detach之后，原有的线程就和<code>std::thread</code>无关了，<code>*this</code>不再<a href="https://en.cppreference.com/w/cpp/thread/thread/detach" target="_blank" rel="noopener">管理任何线程</a>。此时<code>std::thread</code>对象即使析构也无碍于线程实体。</p>
<h4 id="让子线程主动退出"><a href="#让子线程主动退出" class="headerlink" title="让子线程主动退出"></a>让子线程主动退出</h4><p>试图从主线程fire掉子线程<a href="https://stackoverflow.com/questions/23454793/whats-the-c-11-way-to-fire-off-an-asynchronous-task-and-forget-about-it" target="_blank" rel="noopener">一个坏主意</a>。如果希望某个线程的生命周期等同于某个对象，则可以在该线程的loop里面去跟踪一个flag，这个flag可以是全局变量，也可以作为参数传入或者直接捕获。当对象需要析构时，设置这个flag使得线程内部的loop检测并最终<strong>主动</strong>退出，此时只要在主线程中join这个线程即可。</p>
<h4 id="注意线程带来的开销"><a href="#注意线程带来的开销" class="headerlink" title="注意线程带来的开销"></a>注意线程带来的开销</h4><p>从<a href="https://stackoverflow.com/questions/14351352/does-asynclaunchasync-in-c11-make-thread-pools-obsolete-for-avoiding-expen" target="_blank" rel="noopener">这个问题</a>可以看出，Linux 创建线程的开销并不是那么小，创建一个线程去处理，相比直接处理该逻辑，可能慢10000倍。所以如果有一堆小的处理逻辑，使用线程池是一个好主意。</p>
<h4 id="其他注意事项"><a href="#其他注意事项" class="headerlink" title="其他注意事项"></a>其他注意事项</h4><ol>
<li>注意<code>std::thread</code>不能复制，只能移动。</li>
<li>注意<code>std::thread</code>大概率<a href="https://stackoverflow.com/questions/12993451/c11-stdthread-pooled" target="_blank" rel="noopener">不会被pooling</a>。</li>
</ol>
<h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><p>线程池的产生是为了解决维护线程生命周期所带来的开销的问题，同时节约操作系统资源。一个线程池维护多个线程，当任务到来时在池中取出一个线程来执行这个任务。线程池可以动态地进行扩展。<br>一般对于IO型的任务，维护线程池在<code>2x</code>或者<code>2x+2</code>的规模，而对于计算型的任务，盲目加线程是不正确的。甚至对于一些HT超线程的架构线程还要少一点会更好。具体是多少，需要profile来看。</p>
<h3 id="工作队列-任务队列"><a href="#工作队列-任务队列" class="headerlink" title="工作队列/任务队列"></a>工作队列/任务队列</h3><p>注意这里并不是特指Linux中的特定数据结构，而是指一种通用的编程概念。<br>工作队列(work queue)/任务队列(task queue)维护一组工作线程，调用者将异步任务注册到工作队列中，工作线程竞争运行这些异步任务。由此看到工作队列的实现依赖一个线程安全的队列，我们可以通过使用CV做一个简单的生产者消费者的模式来实现。<br>使用工作队列需要<a href="https://www.ibm.com/developerworks/cn/java/j-jtp0730/index.html" target="_blank" rel="noopener">注意的方面</a>：</p>
<ol>
<li>死锁/优先级反转<br> 例如所有正在执行的任务都阻塞等待锁A，但持有锁A的任务却因为没有空余的线程而在队列中空等。</li>
<li>线程泄露<br> 例如在异步任务中触发了异常，那么控制流就可能跳出loop循环，导致该线程无法参与到后面的计算任务中。</li>
<li>过载</li>
</ol>
<h4 id="工作队列模型和其他异步模型的比较"><a href="#工作队列模型和其他异步模型的比较" class="headerlink" title="工作队列模型和其他异步模型的比较"></a>工作队列模型和其他异步模型的比较</h4><ol>
<li>与线程池相比<br> 线程池存在一些显著缺点，例如当主线程希望取得一个空闲进程执行异步任务，线程池中可用线程为空的时候，此时无论是扩展线程池加入新线程或者等待某一个线程执行完任务重新变为空闲，都会导致主线程的阻塞。而工作队列能够避免这样的问题。</li>
<li>与future相比<br> 和线程池一样，工作队列解决<strong>一系列</strong>的异步计算问题。相比future，工作队列需要额外考虑任务的调度、负载均衡等问题。我觉得它更类似于是future的executor的一种实现：execute一个future我们可以单独起一个线程，也可以使用线程池或者工作队列。</li>
</ol>
<h2 id="future模型"><a href="#future模型" class="headerlink" title="future模型"></a>future模型</h2><p>条件变量Condition Variable的一个重要的应用就是生产者/消费者模型，但对于一些平凡的情况，消费者只等待<strong>一次(one-off)<strong>来自生产者的结果。一个最简单的做法是启动一个计算线程，或者从线程池中取出一个线程去执行，然后</strong>异步获取</strong>它的结果，不过<code>std::thread</code>不能直接提供获取返回值的方法。当然，可以使用全局变量、传入指针、回调函数这些做法，这些方案是完全异步的。</p>
<p>另一个做法是使用<code>future</code>来获取异步任务中的结果。future是异步编程中一个非常通用的概念，它表示一个可能还没有被计算完成的值。在C++中被实现为<code>std::future</code>，在Python3中被实现为<code>concurrent.future</code>，在Rust中被实现为trait Future。</p>
<p><code>std::future</code>通常是下面提到的<code>async</code>、<code>promise</code>等异步机制<strong>返回给主线程</strong>的一个句柄。在启动这个异步任务后，当我们需要用到结果时，可以通过<code>future::get()</code>来获取。此时如果异步任务已经完成，则该函数立即返回，否则主线程会阻塞在<code>future::get()</code>上。这可以理解为主线程在等待异步线程的join。特别地，<code>std::future</code>也可以调用<code>wait()</code>、<code>wait_for(const chrono::duration&lt;Rep,Period&gt;&amp; rel_time)</code>等函数进行主动等待，这些函数会返回三种状态，<code>future_status::ready</code>表就绪，<code>future_status::timeout</code>表超时，<code>future_status::deferred</code>表示这个future对应一个deferred function，此时我们还没有执行这个异步任务，我们将在下节进行详细说明。<br>需要注意的是，当多个线程访问<code>std::future</code>时，要锁来保护线程安全。不过我们应当尽量避免这种用法，因为C++中还提供了<code>std::shared_future</code>，相比<code>std::future</code>，它是可以复制的。这也意味着它的结果可以被多次get，而多个线程可以通过一个<code>std::shared_future</code>来跟踪异步任务的结果。需要注意的是，为了保证线程安全，我们需要对每个线程维护一份<code>std::shared_future</code>，而每个线程仅仅可以操作自己的一份。</p>
<h3 id="async"><a href="#async" class="headerlink" title="async"></a>async</h3><p><code>std::async</code>被用来实现一次异步调用。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::future&lt;<span class="keyword">int</span>&gt; the_answer = <span class="built_in">std</span>::async(get_integer);</span><br><span class="line">    do_other_stuff();</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span>&lt;&lt; the_answer.get() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>std::async</code>有两种形式，第二种相比第一种接受一个<code>std::launch</code>类型的参数：</p>
<ol>
<li><code>std::launch::defered</code>表示异步调用是个deferred function，它将延迟到<code>.wait()</code>或<code>.get()</code>再执行。</li>
<li><code>std::launch::async</code>表示在一个独立线程中运行。</li>
</ol>
<p>第一种默认是<code>std::launch::defered | std::launch::async</code>，表示这两个二选一，由具体实现来决定。不指定任何 policy 是未定义行为。</p>
<p><code>std::async</code>能够接受函数指针和函数对象的左值、右值、引用和<code>std::ref</code>，也能够通过类似<code>std::bind</code>一样的机制以引用、<code>std::ref</code>等方式传入对象的上下文。</p>
<h4 id="优先使用async等机制替代std-thread"><a href="#优先使用async等机制替代std-thread" class="headerlink" title="优先使用async等机制替代std::thread"></a>优先使用async等机制替代std::thread</h4><p>相比裸线程，async<strong>隐藏了底层的细节</strong>，这样可以更关注<strong>异步逻辑</strong>本身。特别地，它有可能会**使用线程池进行优化(pooling)**，从而避免每次都创建新线程。<br>此外，裸线程还存在<a href="http://callbackhell.com/" target="_blank" rel="noopener">回调地狱(callback hell)</a>的缺点，使用async或者后面提到的future.then甚至co_wait等机制能够让代码更加平展。</p>
<h4 id="future析构的阻塞问题"><a href="#future析构的阻塞问题" class="headerlink" title="future析构的阻塞问题"></a>future析构的阻塞问题</h4><p>如果我们不关注<code>std::async</code>的返回值，可能写出下面的代码。即我们不将<code>std::async</code>返回的结果绑定到某个变量或者进行移动。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// https://zh.cppreference.com/w/cpp/thread/async</span></span><br><span class="line"><span class="built_in">std</span>::async(<span class="built_in">std</span>::launch::async, []&#123; f(); &#125;); <span class="comment">// 1 临时量的析构函数等待 f()</span></span><br><span class="line"><span class="built_in">std</span>::async(<span class="built_in">std</span>::launch::async, []&#123; g(); &#125;); <span class="comment">// 2 f() 完成前不开始</span></span><br></pre></td></tr></table></figure>

<p>那么这个返回<code>std::future</code>会在整个表达式1执行完之后被析构，而这个析构会<a href="https://zh.cppreference.com/w/cpp/thread/async" target="_blank" rel="noopener"><strong>阻塞</strong>到异步操作f()结束</a>。所以<code>std::async</code>不能被简单地当做<code>std::thread</code>来使用。</p>
<p>SoF中也提到这是一个<a href="https://stackoverflow.com/questions/23455104/why-is-the-destructor-of-a-future-returned-from-stdasync-blocking" target="_blank" rel="noopener">争议问题</a>，<a href="https://stackoverflow.com/questions/18143661/what-is-the-difference-between-packaged-task-and-async" target="_blank" rel="noopener">但至少在C++11中，future的析构函数可能会阻塞线程</a>。</p>
<p>此外，我们也不能将返回值通过回调传出去，当然后续可以通过future.then实现。</p>
<h4 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h4><p><code>std::async</code>会cache住所有的异常。</p>
<h4 id="wait-for"><a href="#wait-for" class="headerlink" title="wait_for"></a>wait_for</h4><p>在Rust中，trait Future 中的 <code>poll</code> 方法可以返回当前任务的结果，或者 <code>Pending</code> 表示目前还在计算中。在 C++ 中 get 会直接阻塞地获取结果，而不会返回 Pending 这样的状态。因此可以通过下面的方法来检查 future 是否已经 ready，然后只有在 future ready 的时候我们再取结果，否则就可以干别的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (fut.wait_for(<span class="number">0</span>) == <span class="built_in">std</span>::future_status::ready)&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>此外，wait_for 还可以被来检查某个 future 是不是被 defer 的</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> fut = <span class="built_in">std</span>::async(func);</span><br><span class="line"><span class="keyword">if</span> (fut.wait_for(<span class="number">0</span>) == <span class="built_in">std</span>::future_status::deferred)&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="packaged-task"><a href="#packaged-task" class="headerlink" title="packaged_task"></a>packaged_task</h3><p><code>std::packaged_task</code>可以封装所有Callable的对象。它有点类似<code>std::function</code>函数对象，但它不能被复制。</p>
<p>不同于<code>std::async</code>，我们需要手动<code>std::packaged_task</code>来执行它持有的Callable。因此这也允许我们使用不同的Executor，例如我们可以自己实现一个线程池来执行，而不是像<code>std::async</code>一样是一个盲盒。我们也可以将它移动到某个<code>std::thread</code>中，起一个单独的线程来执行。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">f</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">std</span>::<span class="built_in">pow</span>(x,y); &#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">std</span>::packaged_task&lt;<span class="keyword">int</span>()&gt; task(<span class="built_in">std</span>::bind(f, <span class="number">2</span>, <span class="number">11</span>));</span><br><span class="line"><span class="built_in">std</span>::future&lt;<span class="keyword">int</span>&gt; result = task.get_future();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在主线程中运行</span></span><br><span class="line">task();</span><br><span class="line"><span class="comment">// 启动另一个线程运行，注意只能移动packaged_task</span></span><br><span class="line">std::thread myThread(std::move(task));</span><br><span class="line"><span class="comment">// </span></span><br><span class="line">f.get();</span><br></pre></td></tr></table></figure>

<p><code>std::packaged_task</code>的另一个用法是将某个任务打包，然后派发给另一个线程执行。</p>
<p><code>std::packaged_task</code> 有两种执行方式：</p>
<ol>
<li><p>operator()</p>
</li>
<li><p>make_ready_at_thread_exit<br> 表示只有在当前线程退出，并且 thread local storage 都析构之后，再将返回的 future 的 ready 设置为 ready。<br> 例如下面 cppreference 提供的这个 demo。如果使用 <code>operator()</code>，则在 my_task 执行完之后，result 立刻变为 ready。如果使用 make_ready_at_thread_exit，则需要在 worker 线程退出之后，result 才会变为 ready。因此可以看到此时在 worker 线程中打印 result 都是 timeout 而非 ready。</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">worker</span><span class="params">(<span class="built_in">std</span>::future&lt;<span class="keyword">void</span>&gt;&amp; output)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::packaged_task&lt;<span class="keyword">void</span>(<span class="keyword">bool</span>&amp;)&gt; my_task&#123; [](<span class="keyword">bool</span>&amp; done) &#123; done=<span class="literal">true</span>; &#125; &#125;;</span><br><span class="line">    <span class="keyword">auto</span> result = my_task.get_future();</span><br><span class="line">    <span class="keyword">bool</span> done = <span class="literal">false</span>;</span><br><span class="line">    my_task.make_ready_at_thread_exit(done); <span class="comment">// execute task right away</span></span><br><span class="line">    <span class="comment">// my_task(done)</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"worker: done = "</span> &lt;&lt; <span class="built_in">std</span>::boolalpha &lt;&lt; done &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">auto</span> status = result.wait_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">0</span>));</span><br><span class="line">    <span class="keyword">if</span> (status == <span class="built_in">std</span>::future_status::timeout)</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"worker: result is not ready yet"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    output = <span class="built_in">std</span>::move(result);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::future&lt;<span class="keyword">void</span>&gt; result;</span><br><span class="line">    <span class="built_in">std</span>::thread&#123;worker, <span class="built_in">std</span>::ref(result)&#125;.join();</span><br><span class="line">    <span class="keyword">auto</span> status = result.wait_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">0</span>));</span><br><span class="line">    <span class="keyword">if</span> (status == <span class="built_in">std</span>::future_status::ready)</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"main: result is ready"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 使用make_ready_at_thread_exit</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">worker: done = true</span><br><span class="line">worker: result is not ready yet</span><br><span class="line">main: result is ready</span><br></pre></td></tr></table></figure>

<p> 使用operator()</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">worker: done = true</span><br><span class="line">main: result is ready</span><br></pre></td></tr></table></figure></li>
</ol>
<p><code>std::packaged_task</code>还提供了<code>reset</code>这个方法，方便复用。</p>
<h3 id="promise"><a href="#promise" class="headerlink" title="promise"></a>promise</h3><p>在上面的两种派发任务-等待获取结果的模型中，主线程是作为等待任务结果的一方，而将执行任务的异步线程则是产生结果的一方。<code>std::future</code>对象由<strong>调用者</strong>(这里是主线程)持有，调用者会使用<code>std::async</code>或者<code>std::packaged_task</code>等启动一个任务，并且在需要结果时调用返回的 future 对象的<code>get</code>方法。对于异步线程来说，调用者对自己是<strong>透明</strong>的，只能通过<strong>执行完任务正常返回</strong>完成向调用者同步。</p>
<p>但在使用<code>std::promise</code>时，异步线程需要显式向调用者设置值<code>std::promise::set_value()</code>或传递异常<code>std::promise::set_exception()</code>。</p>
<p>因此promise实际上为被调用者提供一个显式向调用者同步的方法。被调用者显得更加主动，而且它现在可以返回一个异常。</p>
<h2 id="基于future组织链式调用"><a href="#基于future组织链式调用" class="headerlink" title="基于future组织链式调用"></a>基于future组织链式调用</h2><h3 id="future-then"><a href="#future-then" class="headerlink" title="future.then"></a>future.then</h3><p>future模型有一个美中不足就是最后get时候归根到底是一个同步的过程，并可能会阻塞。相比之下，如果我们自己创建线程或者线程池，然后通过回调来返回值，则更为灵活，是完全的异步，当然也可能带来回调地狱的问题。</p>
<p><a href="https://stackoverflow.com/questions/22175100/how-to-add-a-callback-in-boostfuture-in-c" target="_blank" rel="noopener">能不能两相结合呢？</a>。实际上有一个提案称为future.then就是用来解决这个问题的。其风格类似于CPS，利用了回调链的机制避免了调用<code>future::get()</code>形成阻塞。</p>
<p>future.then目前还没有进入C++标准，因此C++中目前还需要借助于线程池、事件或者IOCP的方式来实现异步。</p>
<h3 id="await"><a href="#await" class="headerlink" title="await"></a>await</h3><p>future.then机制降低了流程操控的复杂度，不过写起来仍然很繁琐，而且存在回调地狱的问题。相比之下，await 能够拍平这些回调函数，让整个异步程序看起来和同步一样。</p>
<p>在链式调用的过程中，整个流程难以在中间直接abort，为此Rust先后提出了<code>try!</code>和<code>?</code>这样的机制。</p>
<p>C++也引入了co_await、co_yield、co_return三个函数，但截至目前它们尚未进入C++标准，但这种由C Sharp流行开来的异步编程范式其实十分优雅，我们将在一个单独的专题进行讨论。</p>
<h1 id="多进程并发模型"><a href="#多进程并发模型" class="headerlink" title="多进程并发模型"></a>多进程并发模型</h1><h2 id="通信和共享内存"><a href="#通信和共享内存" class="headerlink" title="通信和共享内存"></a>通信和共享内存</h2><p>常见的并发模型有两种思路，通过通信共享内存，或者通过共享内存来通信。</p>
<p>通过共享内存来通信的模型中，多个线程通过锁或者原子操作对变量进行有序访问。在先前我们讨论了future等基于线程的共享内存的模型，它们在<strong>多线程</strong>环境中非常实用。可以发现在future等模式中信息的交互是一次性的，即调用者在启动异步任务后很难再去操作异步任务，而异步任务更是看不到调用者。</p>
<p>另一种思路是通过<strong>通信来共享内存</strong>，Communicating Sequential Process(CSP)和Actor模型选择后者，因此在<strong>多进程</strong>情况下会更得心应手。CSP模型可以参照Go语言中的Channel，Actor模型可以参照Mapreduce模型，他们都是通过消息来进行同步的。</p>
<h2 id="Actor模型"><a href="#Actor模型" class="headerlink" title="Actor模型"></a>Actor模型</h2><p>Actor模型围绕<strong>具名</strong>节点（称为Actor）展开，消息从一个Actor<strong>直接发送</strong>到另一个Actor，而并不需要通过诸如Channel的桥梁。特别地，Actor是与线程无关的，一个线程上可以存在多个Actor。更进一步地，<a href="https://tonybai.com/2014/09/29/a-channel-compendium-for-golang/" target="_blank" rel="noopener">Actor的消息传递也是异步的</a>，消息的发送和接受可以在任意时间发生。<br>Actor之间进行严格地隔离，实现所谓“Share nothing”的机制，每一个Actor只能同时处理一个消息，多余的消息会存放在Mailbox里面。这样实际上消息的处理过程是独占的。</p>
<h2 id="CSP模型"><a href="#CSP模型" class="headerlink" title="CSP模型"></a>CSP模型</h2><p>相比Actor，CSP模型围绕一个中间桥梁（在这里使用Go语言中的具象也就是Channel来表示），不同的节点向对应的Channel获取或者发送消息，因此在耦合性上要比Actor模型松一点。相比Actor模型，CSP模型要求发送方在接收方准备好接受消息时才能发送消息，所以同步性要更强一点。<br>以Go为例，Channel一般具有4个基本操作：</p>
<ol>
<li>创建<br> <code>c = make(chan int, buffer_size)</code></li>
<li>发送<br> <code>c &lt;-</code></li>
<li>接受<br> <code>&lt;- c</code></li>
<li>关闭<br> <code>close(c)</code></li>
</ol>
<h3 id="Channel的C-实现"><a href="#Channel的C-实现" class="headerlink" title="Channel的C++实现"></a>Channel的C++实现</h3><p><a href="https://st.xorian.net/blog/2012/08/go-style-channel-in-c/" target="_blank" rel="noopener">这篇文章中讲述了使用C++模拟Go中的Channel的一个方案</a>。首先Channel一个最基础的功能就是收发消息，这个可以通过一个队列来实现。</p>
<h1 id="并发编程中的基础架构"><a href="#并发编程中的基础架构" class="headerlink" title="并发编程中的基础架构"></a>并发编程中的基础架构</h1><p>在设计高性能的并发代码时，我们需要注意以下几点：</p>
<ol>
<li>充分利用局部性假设，是同一线程中的数据紧密联系</li>
<li>减少线程上所需的数据量</li>
<li>让不同线程访问不同位置，避免伪共享，这里也是将<strong>内存分配对齐到缓存行大小</strong>的一个重要原因。</li>
</ol>
<h2 id="响应式-reactive-架构"><a href="#响应式-reactive-架构" class="headerlink" title="响应式(reactive)架构"></a>响应式(reactive)架构</h2><h1 id="网络编程相关"><a href="#网络编程相关" class="headerlink" title="网络编程相关"></a>网络编程相关</h1><h2 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h2><h3 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h3><ol>
<li><p>是不是所有fd都可以被epoll<br> 并不是的，需要实现poll函数的fd。</p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">file_operations</span> &#123;</span></span><br><span class="line">    <span class="keyword">__poll_t</span> (*poll) (struct file *, struct poll_table_struct *);</span><br></pre></td></tr></table></figure></li>
<li><p>为什么要有等待队列<br> 所有等待这个epoll的进程都会在等待队列上面，这个有点类似于Python的Condition里面的waiters数组。</p>
</li>
<li><p>水平和边沿触发</p>
</li>
<li><p>为什么epoll快</p>
<ol>
<li>只有调用<code>epoll_ctl</code>的时候才进行拷贝fd，而不是在<code>epoll_wait</code>的时候拷贝</li>
<li><code>epoll_wait</code>不会遍历所有的fd，而是只判断就绪队列是否为空</li>
<li><code>epoll_ctl</code>的复杂度是<code>O(log(n))</code>的，这是因为引入了红黑树</li>
<li>回调机制</li>
</ol>
</li>
<li><p>为什么epoll使用红黑树<br> socket的句柄是key，socket对象是红黑树的节点。方便快速找到对应的socket对象，从而快速修改监听socket的读写事件。</p>
</li>
</ol>
<p>一个epoll的<a href="https://man7.org/linux/man-pages/man7/epoll.7.html" target="_blank" rel="noopener">demo</a></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAX_EVENTS 10</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> <span class="title">ev</span>, <span class="title">events</span>[<span class="title">MAX_EVENTS</span>];</span></span><br><span class="line"><span class="keyword">int</span> listen_sock, conn_sock, nfds, epollfd;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Code to set up listening socket, 'listen_sock',</span></span><br><span class="line"><span class="comment">  (socket(), bind(), listen()) omitted. */</span></span><br><span class="line"></span><br><span class="line">epollfd = epoll_create1(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">if</span> (epollfd == <span class="number">-1</span>) &#123;</span><br><span class="line">   perror(<span class="string">"epoll_create1"</span>);</span><br><span class="line">   <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ev.events = EPOLLIN;</span><br><span class="line">ev.data.fd = listen_sock;</span><br><span class="line"><span class="keyword">if</span> (epoll_ctl(epollfd, EPOLL_CTL_ADD, listen_sock, &amp;ev) == <span class="number">-1</span>) &#123;</span><br><span class="line">   perror(<span class="string">"epoll_ctl: listen_sock"</span>);</span><br><span class="line">   <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (;;) &#123;</span><br><span class="line">   nfds = epoll_wait(epollfd, events, MAX_EVENTS, <span class="number">-1</span>);</span><br><span class="line">   <span class="keyword">if</span> (nfds == <span class="number">-1</span>) &#123;</span><br><span class="line">       perror(<span class="string">"epoll_wait"</span>);</span><br><span class="line">       <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; nfds; ++n) &#123;</span><br><span class="line">       <span class="keyword">if</span> (events[n].data.fd == listen_sock) &#123;</span><br><span class="line">           conn_sock = accept(listen_sock,</span><br><span class="line">                              (struct sockaddr *) &amp;addr, &amp;addrlen);</span><br><span class="line">           <span class="keyword">if</span> (conn_sock == <span class="number">-1</span>) &#123;</span><br><span class="line">               perror(<span class="string">"accept"</span>);</span><br><span class="line">               <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">           &#125;</span><br><span class="line">           setnonblocking(conn_sock);</span><br><span class="line">           ev.events = EPOLLIN | EPOLLET;</span><br><span class="line">           ev.data.fd = conn_sock;</span><br><span class="line">           <span class="keyword">if</span> (epoll_ctl(epollfd, EPOLL_CTL_ADD, conn_sock,</span><br><span class="line">                       &amp;ev) == <span class="number">-1</span>) &#123;</span><br><span class="line">               perror(<span class="string">"epoll_ctl: conn_sock"</span>);</span><br><span class="line">               <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           do_use_fd(events[n].data.fd);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li><a href="https://coolshell.cn/articles/8239.html" target="_blank" rel="noopener">https://coolshell.cn/articles/8239.html</a></li>
<li><a href="https://www.zhihu.com/question/24301047" target="_blank" rel="noopener">https://www.zhihu.com/question/24301047</a><br> 大家对于memory order的理解，我在修订文章时，采用了一些更为简洁的说法</li>
<li><a href="https://preshing.com/20130922/acquire-and-release-fences/" target="_blank" rel="noopener">https://preshing.com/20130922/acquire-and-release-fences/</a><br> 2013年的老文章</li>
<li><a href="https://acg.cis.upenn.edu/papers/dac11_litmus.pdf" target="_blank" rel="noopener">https://acg.cis.upenn.edu/papers/dac11_litmus.pdf</a><br> 有关litmus test</li>
<li><a href="https://preshing.com/20140709/the-purpose-of-memory_order_consume-in-cpp11/" target="_blank" rel="noopener">https://preshing.com/20140709/the-purpose-of-memory_order_consume-in-cpp11/</a><br> preshing对memory_order_consume的讲解</li>
<li><a href="https://sites.utexas.edu/jdm4372/2018/01/01/notes-on-non-temporal-aka-streaming-stores/" target="_blank" rel="noopener">https://sites.utexas.edu/jdm4372/2018/01/01/notes-on-non-temporal-aka-streaming-stores/</a><br> 对Non temporal store的讲解</li>
<li><a href="https://www.modernescpp.com/index.php/acquire-release-fences" target="_blank" rel="noopener">https://www.modernescpp.com/index.php/acquire-release-fences</a><br> 对atomic thread fence的讲解，acquire和release</li>
<li><a href="https://www.zhihu.com/question/24301047" target="_blank" rel="noopener">https://www.zhihu.com/question/24301047</a><br> 如何理解memory order。以及TSO的论述</li>
<li><a href="https://ljalphabeta.gitbooks.io/a-primer-on-memory-consistency-and-cache-coherenc/content/%E7%AC%AC%E5%9B%9B%E7%AB%A0-total-store-order%E5%92%8Cx.html" target="_blank" rel="noopener">https://ljalphabeta.gitbooks.io/a-primer-on-memory-consistency-and-cache-coherenc/content/%E7%AC%AC%E5%9B%9B%E7%AB%A0-total-store-order%E5%92%8Cx.html</a><br> 讲解TSO模型</li>
<li><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3710.html" target="_blank" rel="noopener">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3710.html</a></li>
<li><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1217r0" target="_blank" rel="noopener">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1217r0</a><br> 以上两篇，讲解out of thin air</li>
<li><a href="https://www.cl.cam.ac.uk/~pes20/cpp/notes42.html" target="_blank" rel="noopener">https://www.cl.cam.ac.uk/~pes20/cpp/notes42.html</a><br> 这个讲解out of thin air更易懂</li>
<li><a href="https://zhuanlan.zhihu.com/p/31386431" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31386431</a><br> 知乎对happens before和sync-with的讲解，我觉得讲得不好</li>
</ol>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div></div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/img/fkm/wxfk.jpg" alt="Calvin Neo WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/img/fkm/zfbfk.jpg" alt="Calvin Neo Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/C/" rel="tag"># C++</a>
          
            <a href="/tags/Linux/" rel="tag"># Linux</a>
          
            <a href="/tags/网络/" rel="tag"># 网络</a>
          
            <a href="/tags/并行计算/" rel="tag"># 并行计算</a>
          
            <a href="/tags/多线程/" rel="tag"># 多线程</a>
          
            <a href="/tags/atomic/" rel="tag"># atomic</a>
          
            <a href="/tags/CPU/" rel="tag"># CPU</a>
          
            <a href="/tags/多进程/" rel="tag"># 多进程</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/12/05/libutp源码简析/" rel="next" title="libutp源码简析">
                <i class="fa fa-chevron-left"></i> libutp源码简析
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/12/28/lockfree-queue/" rel="prev" title="Lockfree Queue">
                Lockfree Queue <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/favicon.jpg"
               alt="Calvin Neo" />
          <p class="site-author-name" itemprop="name">Calvin Neo</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">199</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">143</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/CalvinNeo" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/CalvinNeo0" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/1568200035" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://xqq.im/" title="xqq" target="_blank">xqq</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.lovelywen.com/" title="wenwen" target="_blank">wenwen</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://smlight.github.io/blog/" title="zyyyyy" target="_blank">zyyyyy</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#处理器层面的并发"><span class="nav-number">1.</span> <span class="nav-text">处理器层面的并发</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#流水线-pipeline"><span class="nav-number">1.1.</span> <span class="nav-text">流水线(pipeline)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#流水线和吞吐量"><span class="nav-number">1.1.1.</span> <span class="nav-text">流水线和吞吐量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流水线和冒险"><span class="nav-number">1.1.2.</span> <span class="nav-text">流水线和冒险</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#冒险导致错误的展示"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">冒险导致错误的展示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#暂停"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">暂停</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#转发"><span class="nav-number">1.1.2.3.</span> <span class="nav-text">转发</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#加载互锁"><span class="nav-number">1.1.3.</span> <span class="nav-text">加载互锁</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#现代处理器"><span class="nav-number">1.2.</span> <span class="nav-text">现代处理器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#流水线机制对程序优化的启示"><span class="nav-number">1.2.1.</span> <span class="nav-text">流水线机制对程序优化的启示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#combine-函数的初步优化"><span class="nav-number">1.2.2.</span> <span class="nav-text">combine 函数的初步优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#依赖于目标机器微体系结构的优化"><span class="nav-number">1.2.3.</span> <span class="nav-text">依赖于目标机器微体系结构的优化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CPU的缓存和缓存一致性"><span class="nav-number">1.3.</span> <span class="nav-text">CPU的缓存和缓存一致性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#x86的缓存架构简介"><span class="nav-number">1.3.1.</span> <span class="nav-text">x86的缓存架构简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#局部性原理"><span class="nav-number">1.3.2.</span> <span class="nav-text">局部性原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#展示存储器山"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">展示存储器山</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#计算存储器山"><span class="nav-number">1.3.2.2.</span> <span class="nav-text">计算存储器山</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Demo：向量求和"><span class="nav-number">1.3.2.3.</span> <span class="nav-text">Demo：向量求和</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Demo：矩阵相乘"><span class="nav-number">1.3.3.</span> <span class="nav-text">Demo：矩阵相乘</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存抖动-thrash"><span class="nav-number">1.3.3.1.</span> <span class="nav-text">缓存抖动(thrash)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存不命中-cache-miss"><span class="nav-number">1.3.4.</span> <span class="nav-text">缓存不命中(cache miss)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#高速缓存的架构"><span class="nav-number">1.3.5.</span> <span class="nav-text">高速缓存的架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#通用架构"><span class="nav-number">1.3.5.1.</span> <span class="nav-text">通用架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#直接映射高速缓存"><span class="nav-number">1.3.5.2.</span> <span class="nav-text">直接映射高速缓存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#组相联高速缓存"><span class="nav-number">1.3.5.3.</span> <span class="nav-text">组相联高速缓存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#全相联高速缓存"><span class="nav-number">1.3.5.4.</span> <span class="nav-text">全相联高速缓存</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存污染"><span class="nav-number">1.3.6.</span> <span class="nav-text">缓存污染</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#常见的缓存替换算法"><span class="nav-number">1.3.7.</span> <span class="nav-text">常见的缓存替换算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存一致性协议"><span class="nav-number">1.3.8.</span> <span class="nav-text">缓存一致性协议</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#当多个核心同时读写一个内存地址时，如何保证其正确性？"><span class="nav-number">1.3.8.1.</span> <span class="nav-text">当多个核心同时读写一个内存地址时，如何保证其正确性？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#伪共享"><span class="nav-number">1.3.9.</span> <span class="nav-text">伪共享</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试缓存大小"><span class="nav-number">1.3.10.</span> <span class="nav-text">测试缓存大小</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存一致性和volatile"><span class="nav-number">1.3.11.</span> <span class="nav-text">缓存一致性和volatile</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CPU提供的并发处理机制"><span class="nav-number">1.4.</span> <span class="nav-text">CPU提供的并发处理机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Store-Buffer"><span class="nav-number">1.4.1.</span> <span class="nav-text">Store Buffer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fence"><span class="nav-number">1.4.2.</span> <span class="nav-text">Fence</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#总线锁"><span class="nav-number">1.4.3.</span> <span class="nav-text">总线锁</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#内核层面的同步与并发"><span class="nav-number">2.</span> <span class="nav-text">内核层面的同步与并发</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#中断"><span class="nav-number">2.1.</span> <span class="nav-text">中断</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#x86上的中断"><span class="nav-number">2.1.1.</span> <span class="nav-text">x86上的中断</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linux的中断"><span class="nav-number">2.1.2.</span> <span class="nav-text">Linux的中断</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#x86中断向量-中断描述符"><span class="nav-number">2.1.3.</span> <span class="nav-text">x86中断向量/中断描述符</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#中断程序的注册和处理"><span class="nav-number">2.1.4.</span> <span class="nav-text">中断程序的注册和处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#中断的开启与关闭"><span class="nav-number">2.1.5.</span> <span class="nav-text">中断的开启与关闭</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#共享中断"><span class="nav-number">2.1.6.</span> <span class="nav-text">共享中断</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#中断下半部"><span class="nav-number">2.1.7.</span> <span class="nav-text">中断下半部</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Orignial-Bottom-Half-BH"><span class="nav-number">2.1.7.1.</span> <span class="nav-text">Orignial Bottom Half(BH)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Task-Queue"><span class="nav-number">2.1.7.2.</span> <span class="nav-text">Task Queue</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#软中断"><span class="nav-number">2.1.7.3.</span> <span class="nav-text">软中断</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tasklet"><span class="nav-number">2.1.7.4.</span> <span class="nav-text">tasklet</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#进程与线程设施"><span class="nav-number">2.2.</span> <span class="nav-text">进程与线程设施</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#进程模型"><span class="nav-number">2.2.1.</span> <span class="nav-text">进程模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线程模型"><span class="nav-number">2.2.2.</span> <span class="nav-text">线程模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#信号"><span class="nav-number">2.2.3.</span> <span class="nav-text">信号</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#系统调用"><span class="nav-number">2.2.4.</span> <span class="nav-text">系统调用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#调度"><span class="nav-number">2.3.</span> <span class="nav-text">调度</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CFS调度算法"><span class="nav-number">2.3.1.</span> <span class="nav-text">CFS调度算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linux的调度器"><span class="nav-number">2.3.2.</span> <span class="nav-text">Linux的调度器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linux的抢占"><span class="nav-number">2.4.</span> <span class="nav-text">Linux的抢占</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#用户抢占"><span class="nav-number">2.4.1.</span> <span class="nav-text">用户抢占</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内核抢占"><span class="nav-number">2.4.2.</span> <span class="nav-text">内核抢占</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#可重入、异步信号安全、线程安全与中断安全"><span class="nav-number">2.5.</span> <span class="nav-text">可重入、异步信号安全、线程安全与中断安全</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#可重入函数"><span class="nav-number">2.5.1.</span> <span class="nav-text">可重入函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线程安全"><span class="nav-number">2.5.2.</span> <span class="nav-text">线程安全</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#中断安全"><span class="nav-number">2.5.3.</span> <span class="nav-text">中断安全</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#内核和运行时向外提供的并发与同步设施"><span class="nav-number">3.</span> <span class="nav-text">内核和运行时向外提供的并发与同步设施</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#多进程与多线程"><span class="nav-number">3.1.</span> <span class="nav-text">多进程与多线程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#同步与异步"><span class="nav-number">3.1.1.</span> <span class="nav-text">同步与异步</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#协程"><span class="nav-number">3.2.</span> <span class="nav-text">协程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#C-下协程的实现方式"><span class="nav-number">3.3.</span> <span class="nav-text">C++下协程的实现方式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基于ucontext"><span class="nav-number">3.3.1.</span> <span class="nav-text">基于ucontext</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#黑科技1"><span class="nav-number">3.3.2.</span> <span class="nav-text">黑科技1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于setjmp和longjmp"><span class="nav-number">3.3.3.</span> <span class="nav-text">基于setjmp和longjmp</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#约束线程间并发行为-有锁"><span class="nav-number">4.</span> <span class="nav-text">约束线程间并发行为(有锁)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Race-condition"><span class="nav-number">4.1.</span> <span class="nav-text">Race condition</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#不变量"><span class="nav-number">4.1.1.</span> <span class="nav-text">不变量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#volatile"><span class="nav-number">4.2.</span> <span class="nav-text">volatile</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#内核锁"><span class="nav-number">4.3.</span> <span class="nav-text">内核锁</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#互斥量"><span class="nav-number">4.3.1.</span> <span class="nav-text">互斥量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#std-recursive-mutex-互斥量"><span class="nav-number">4.3.2.</span> <span class="nav-text">std::recursive_mutex 互斥量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#场景讨论"><span class="nav-number">4.3.3.</span> <span class="nav-text">场景讨论</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#删除链表节点"><span class="nav-number">4.3.3.1.</span> <span class="nav-text">删除链表节点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#线程安全的栈"><span class="nav-number">4.3.3.2.</span> <span class="nav-text">线程安全的栈</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#死锁"><span class="nav-number">4.3.4.</span> <span class="nav-text">死锁</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#std-lock-的实现"><span class="nav-number">4.3.5.</span> <span class="nav-text">std::lock 的实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自旋锁"><span class="nav-number">4.4.</span> <span class="nav-text">自旋锁</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#自旋锁与中断处理"><span class="nav-number">4.4.1.</span> <span class="nav-text">自旋锁与中断处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#持有自旋锁时不能进入睡眠"><span class="nav-number">4.4.2.</span> <span class="nav-text">持有自旋锁时不能进入睡眠</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自旋锁的实现"><span class="nav-number">4.4.3.</span> <span class="nav-text">自旋锁的实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#临界区"><span class="nav-number">4.5.</span> <span class="nav-text">临界区</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#临界资源的初始化"><span class="nav-number">4.6.</span> <span class="nav-text">临界资源的初始化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#C-11前的朴素方案"><span class="nav-number">4.6.1.</span> <span class="nav-text">C++11前的朴素方案</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#双重检查锁定模式"><span class="nav-number">4.6.2.</span> <span class="nav-text">双重检查锁定模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#call-once方案"><span class="nav-number">4.6.3.</span> <span class="nav-text">call_once方案</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#读写锁"><span class="nav-number">4.7.</span> <span class="nav-text">读写锁</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#约束线程间并发行为-无锁"><span class="nav-number">5.</span> <span class="nav-text">约束线程间并发行为(无锁)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#锁无关和原子操作"><span class="nav-number">5.1.</span> <span class="nav-text">锁无关和原子操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#锁无关简介"><span class="nav-number">5.1.1.</span> <span class="nav-text">锁无关简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#原子操作"><span class="nav-number">5.1.2.</span> <span class="nav-text">原子操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#对C-中原子操作的特别说明"><span class="nav-number">5.1.2.1.</span> <span class="nav-text">对C++中原子操作的特别说明</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#atomic对象是线程间order的桥梁"><span class="nav-number">5.1.2.1.1.</span> <span class="nav-text">atomic对象是线程间order的桥梁</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#store-load的原子性"><span class="nav-number">5.1.2.1.2.</span> <span class="nav-text">store/load的原子性</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#原子操作的分类"><span class="nav-number">5.1.2.2.</span> <span class="nav-text">原子操作的分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#如何判断是不是原子操作"><span class="nav-number">5.1.2.3.</span> <span class="nav-text">如何判断是不是原子操作</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#互锁访问函数和CAS操作"><span class="nav-number">5.1.3.</span> <span class="nav-text">互锁访问函数和CAS操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#原子操作底层实现"><span class="nav-number">5.1.4.</span> <span class="nav-text">原子操作底层实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CAS操作的实现"><span class="nav-number">5.1.4.1.</span> <span class="nav-text">CAS操作的实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用CAS操作实现的无锁链表"><span class="nav-number">5.1.5.</span> <span class="nav-text">使用CAS操作实现的无锁链表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CAS-和-LL-SC"><span class="nav-number">5.1.6.</span> <span class="nav-text">CAS 和 LL/SC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ABA问题"><span class="nav-number">5.1.7.</span> <span class="nav-text">ABA问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Tagged-state-reference"><span class="nav-number">5.1.7.1.</span> <span class="nav-text">Tagged state reference</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Deferred-reclamation"><span class="nav-number">5.1.7.2.</span> <span class="nav-text">Deferred reclamation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#指令集"><span class="nav-number">5.1.7.3.</span> <span class="nav-text">指令集</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#原子操作与锁的关系"><span class="nav-number">5.1.8.</span> <span class="nav-text">原子操作与锁的关系</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#原子操作-以C-为例"><span class="nav-number">5.2.</span> <span class="nav-text">原子操作(以C++为例)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他的同步原语"><span class="nav-number">5.3.</span> <span class="nav-text">其他的同步原语</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hazard-Pointer"><span class="nav-number">5.3.1.</span> <span class="nav-text">Hazard Pointer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RCU"><span class="nav-number">5.3.2.</span> <span class="nav-text">RCU</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MCS-Lock"><span class="nav-number">5.3.3.</span> <span class="nav-text">MCS Lock</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#通过内存模型约束线程对变量的读写顺序"><span class="nav-number">5.4.</span> <span class="nav-text">通过内存模型约束线程对变量的读写顺序</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#as-if-rule"><span class="nav-number">5.4.1.</span> <span class="nav-text">as-if rule</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#原子操作的线程间顺序"><span class="nav-number">5.4.2.</span> <span class="nav-text">原子操作的线程间顺序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#可见性和有序性"><span class="nav-number">5.4.3.</span> <span class="nav-text">可见性和有序性</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Sequence-Points"><span class="nav-number">5.4.3.1.</span> <span class="nav-text">Sequence Points</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sequenced-before"><span class="nav-number">5.4.3.2.</span> <span class="nav-text">Sequenced-before</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sequenced-before和as-if-rule是否冲突？"><span class="nav-number">5.4.3.3.</span> <span class="nav-text">Sequenced-before和as-if rule是否冲突？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Carries-dependency"><span class="nav-number">5.4.3.4.</span> <span class="nav-text">Carries dependency</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Modification-order"><span class="nav-number">5.4.3.5.</span> <span class="nav-text">Modification order</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dependency-ordered-before"><span class="nav-number">5.4.3.6.</span> <span class="nav-text">Dependency-ordered before</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Inter-thread-happens-before"><span class="nav-number">5.4.3.7.</span> <span class="nav-text">Inter-thread happens-before</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Happens-before"><span class="nav-number">5.4.3.8.</span> <span class="nav-text">Happens before</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Visible-side-effects"><span class="nav-number">5.4.3.9.</span> <span class="nav-text">Visible side-effects</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Synchronizes-with"><span class="nav-number">5.4.3.10.</span> <span class="nav-text">Synchronizes-with</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#coherence-ordered-before"><span class="nav-number">5.4.3.11.</span> <span class="nav-text">coherence-ordered-before</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Release-sequence"><span class="nav-number">5.4.3.12.</span> <span class="nav-text">Release sequence</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内存一致性模型综述"><span class="nav-number">5.4.4.</span> <span class="nav-text">内存一致性模型综述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内存模型：Relaxed"><span class="nav-number">5.4.5.</span> <span class="nav-text">内存模型：Relaxed</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Litmus-test：Message-Passing"><span class="nav-number">5.4.5.1.</span> <span class="nav-text">Litmus test：Message Passing</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Litmus-test"><span class="nav-number">5.4.5.2.</span> <span class="nav-text">Litmus test</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Out-of-thin-air问题"><span class="nav-number">5.4.5.3.</span> <span class="nav-text">Out of thin air问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内存模型：acquire-release以及release-consume"><span class="nav-number">5.4.6.</span> <span class="nav-text">内存模型：acquire/release以及release/consume</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#acquire-release-配对："><span class="nav-number">5.4.6.1.</span> <span class="nav-text">acquire-release 配对：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#acquire-consume-配对："><span class="nav-number">5.4.6.2.</span> <span class="nav-text">acquire-consume 配对：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#总结注意点"><span class="nav-number">5.4.6.3.</span> <span class="nav-text">总结注意点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#memory-order-acq-rel"><span class="nav-number">5.4.6.4.</span> <span class="nav-text">memory_order_acq_rel</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Demo-acquire-release"><span class="nav-number">5.4.6.5.</span> <span class="nav-text">Demo acquire/release</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Demo-release-consume"><span class="nav-number">5.4.6.6.</span> <span class="nav-text">Demo release/consume</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内存模型：Sequential"><span class="nav-number">5.4.7.</span> <span class="nav-text">内存模型：Sequential</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#不能太乐观"><span class="nav-number">5.4.7.1.</span> <span class="nav-text">不能太乐观</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#出于正确性原因"><span class="nav-number">5.4.7.1.1.</span> <span class="nav-text">出于正确性原因</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#出于性能原因"><span class="nav-number">5.4.7.1.2.</span> <span class="nav-text">出于性能原因</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Litmus-test：Store-buffer"><span class="nav-number">5.4.7.2.</span> <span class="nav-text">Litmus test：Store buffer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Litmus-test：读写不同变量"><span class="nav-number">5.4.7.3.</span> <span class="nav-text">Litmus test：读写不同变量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#如何选择内存模型？"><span class="nav-number">5.4.8.</span> <span class="nav-text">如何选择内存模型？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#通过fence-barrier约束线程对变量的读写顺序"><span class="nav-number">5.5.</span> <span class="nav-text">通过fence/barrier约束线程对变量的读写顺序</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#C-层面的fence及其实现"><span class="nav-number">5.5.1.</span> <span class="nav-text">C++层面的fence及其实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#signal-fence"><span class="nav-number">5.5.1.1.</span> <span class="nav-text">signal fence</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#thread-fence"><span class="nav-number">5.5.2.</span> <span class="nav-text">thread fence</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#一个简单的例子"><span class="nav-number">5.5.2.1.</span> <span class="nav-text">一个简单的例子</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#full-general-thread-fence"><span class="nav-number">5.5.2.2.</span> <span class="nav-text">full/general thread fence</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#MSVC的atomic-thread-fence实现"><span class="nav-number">5.5.2.2.1.</span> <span class="nav-text">MSVC的atomic_thread_fence实现</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#acquire-release-thread-fence"><span class="nav-number">5.5.2.3.</span> <span class="nav-text">acquire/release thread fence</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#acquire-fence"><span class="nav-number">5.5.2.3.1.</span> <span class="nav-text">acquire fence</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#release-fence"><span class="nav-number">5.5.2.3.2.</span> <span class="nav-text">release fence</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fence-atomic同步、fence-fence同步"><span class="nav-number">5.5.3.</span> <span class="nav-text">fence/atomic同步、fence/fence同步</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Fence-atomic-synchronization"><span class="nav-number">5.5.3.1.</span> <span class="nav-text">Fence-atomic synchronization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Atomic-fence-synchronization"><span class="nav-number">5.5.3.2.</span> <span class="nav-text">Atomic-fence synchronization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Fence-fence-synchronization"><span class="nav-number">5.5.3.3.</span> <span class="nav-text">Fence-fence synchronization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#thread-fence-和-barrier-指令间的关系"><span class="nav-number">5.5.3.4.</span> <span class="nav-text">thread fence 和 barrier 指令间的关系</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Store-Load乱序问题"><span class="nav-number">5.5.4.</span> <span class="nav-text">Store-Load乱序问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#通过fence和barrier实现同步"><span class="nav-number">5.5.5.</span> <span class="nav-text">通过fence和barrier实现同步</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#atomic-variable-VS-atomic-fence"><span class="nav-number">5.5.5.1.</span> <span class="nav-text">atomic variable VS atomic fence</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Acq-Rel"><span class="nav-number">5.5.6.</span> <span class="nav-text">Acq/Rel</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SeqCst"><span class="nav-number">5.5.6.1.</span> <span class="nav-text">SeqCst</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#无等待"><span class="nav-number">5.6.</span> <span class="nav-text">无等待</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#无锁编程实战"><span class="nav-number">5.7.</span> <span class="nav-text">无锁编程实战</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#读写共享对象"><span class="nav-number">5.7.1.</span> <span class="nav-text">读写共享对象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用内存模型解决双重检查锁定模式-DCLP-存在的问题"><span class="nav-number">5.7.2.</span> <span class="nav-text">使用内存模型解决双重检查锁定模式(DCLP)存在的问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用atomic-store-load语义"><span class="nav-number">5.7.2.1.</span> <span class="nav-text">使用atomic store/load语义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用fence"><span class="nav-number">5.7.2.2.</span> <span class="nav-text">使用fence</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于CAS实现自旋锁"><span class="nav-number">5.7.3.</span> <span class="nav-text">基于CAS实现自旋锁</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#无锁队列"><span class="nav-number">5.7.4.</span> <span class="nav-text">无锁队列</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#多线程并发模型"><span class="nav-number">6.</span> <span class="nav-text">多线程并发模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#共享-vs-通信"><span class="nav-number">6.1.</span> <span class="nav-text">共享 vs 通信</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#虚假唤醒-spurious-wakeup"><span class="nav-number">6.2.</span> <span class="nav-text">虚假唤醒(spurious wakeup)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#复现虚假唤醒"><span class="nav-number">6.2.1.</span> <span class="nav-text">复现虚假唤醒</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#解决方案"><span class="nav-number">6.2.2.</span> <span class="nav-text">解决方案</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#惊群效应"><span class="nav-number">6.3.</span> <span class="nav-text">惊群效应</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#条件变量-Condition-Variable"><span class="nav-number">6.4.</span> <span class="nav-text">条件变量 Condition Variable</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#C-中的-condition-variable"><span class="nav-number">6.4.1.</span> <span class="nav-text">C++ 中的 condition_variable</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#条件变量的用法"><span class="nav-number">6.4.2.</span> <span class="nav-text">条件变量的用法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#notify-时是否要加锁"><span class="nav-number">6.4.2.1.</span> <span class="nav-text">notify 时是否要加锁</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么需要维护一个-condition-变量"><span class="nav-number">6.4.2.2.</span> <span class="nav-text">为什么需要维护一个 condition 变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#condition-variable-的错误用法"><span class="nav-number">6.4.2.3.</span> <span class="nav-text">condition variable 的错误用法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#几个有关-CV-和-mutex-之间联系的问题"><span class="nav-number">6.4.3.</span> <span class="nav-text">几个有关 CV 和 mutex 之间联系的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#信号量的实现"><span class="nav-number">6.4.4.</span> <span class="nav-text">信号量的实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#事件"><span class="nav-number">6.5.</span> <span class="nav-text">事件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于线程的异步调用"><span class="nav-number">6.6.</span> <span class="nav-text">基于线程的异步调用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#std-thread"><span class="nav-number">6.6.1.</span> <span class="nav-text">std::thread</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#区分std-thread和线程实体的生命周期"><span class="nav-number">6.6.1.1.</span> <span class="nav-text">区分std::thread和线程实体的生命周期</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#让子线程主动退出"><span class="nav-number">6.6.1.2.</span> <span class="nav-text">让子线程主动退出</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#注意线程带来的开销"><span class="nav-number">6.6.1.3.</span> <span class="nav-text">注意线程带来的开销</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#其他注意事项"><span class="nav-number">6.6.1.4.</span> <span class="nav-text">其他注意事项</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线程池"><span class="nav-number">6.6.2.</span> <span class="nav-text">线程池</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#工作队列-任务队列"><span class="nav-number">6.6.3.</span> <span class="nav-text">工作队列/任务队列</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#工作队列模型和其他异步模型的比较"><span class="nav-number">6.6.3.1.</span> <span class="nav-text">工作队列模型和其他异步模型的比较</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#future模型"><span class="nav-number">6.7.</span> <span class="nav-text">future模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#async"><span class="nav-number">6.7.1.</span> <span class="nav-text">async</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#优先使用async等机制替代std-thread"><span class="nav-number">6.7.1.1.</span> <span class="nav-text">优先使用async等机制替代std::thread</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#future析构的阻塞问题"><span class="nav-number">6.7.1.2.</span> <span class="nav-text">future析构的阻塞问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#异常"><span class="nav-number">6.7.1.3.</span> <span class="nav-text">异常</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#wait-for"><span class="nav-number">6.7.1.4.</span> <span class="nav-text">wait_for</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#packaged-task"><span class="nav-number">6.7.2.</span> <span class="nav-text">packaged_task</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#promise"><span class="nav-number">6.7.3.</span> <span class="nav-text">promise</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于future组织链式调用"><span class="nav-number">6.8.</span> <span class="nav-text">基于future组织链式调用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#future-then"><span class="nav-number">6.8.1.</span> <span class="nav-text">future.then</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#await"><span class="nav-number">6.8.2.</span> <span class="nav-text">await</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#多进程并发模型"><span class="nav-number">7.</span> <span class="nav-text">多进程并发模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#通信和共享内存"><span class="nav-number">7.1.</span> <span class="nav-text">通信和共享内存</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Actor模型"><span class="nav-number">7.2.</span> <span class="nav-text">Actor模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CSP模型"><span class="nav-number">7.3.</span> <span class="nav-text">CSP模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Channel的C-实现"><span class="nav-number">7.3.1.</span> <span class="nav-text">Channel的C++实现</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#并发编程中的基础架构"><span class="nav-number">8.</span> <span class="nav-text">并发编程中的基础架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#响应式-reactive-架构"><span class="nav-number">8.1.</span> <span class="nav-text">响应式(reactive)架构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#网络编程相关"><span class="nav-number">9.</span> <span class="nav-text">网络编程相关</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#epoll"><span class="nav-number">9.1.</span> <span class="nav-text">epoll</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#QA"><span class="nav-number">9.1.1.</span> <span class="nav-text">QA</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">10.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Calvin Neo</span>
  <span> &nbsp; Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a></span>
</div>
<div>
  <span><a href="/about/yytl/">版权声明</a></span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse 
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://www.calvinneo.com/2017/12/28/Concurrency-Programming-Compare/';
          this.page.identifier = '2017/12/28/Concurrency-Programming-Compare/';
          this.page.title = '并发编程重要概念及比较';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://calvinneo.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  








  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      $('#local-search-input').focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
