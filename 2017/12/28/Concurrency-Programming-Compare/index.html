<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="C++,并行计算,多线程,Linux," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="在本篇中比较了各种并发、并行技术。并发(concurrency)强调的是逻辑上的同时发生，是语义上的模型(semantic model)，在实际上并发程序可能是由一个处理器同时(simultaneously)处理多个任务，因此并发过程中常出现一个线程等待其他资源的情况。此时常伴随着线程的阻塞和调度。并发过程通常可划分为多个级别：Blocking、Obstruction-Free、Lock-Free">
<meta name="keywords" content="C++,并行计算,多线程,Linux">
<meta property="og:type" content="article">
<meta property="og:title" content="并发编程重要概念及比较">
<meta property="og:url" content="http://www.calvinneo.com/2017/12/28/Concurrency-Programming-Compare/index.html">
<meta property="og:site_name" content="Calvin&#39;s Marbles">
<meta property="og:description" content="在本篇中比较了各种并发、并行技术。并发(concurrency)强调的是逻辑上的同时发生，是语义上的模型(semantic model)，在实际上并发程序可能是由一个处理器同时(simultaneously)处理多个任务，因此并发过程中常出现一个线程等待其他资源的情况。此时常伴随着线程的阻塞和调度。并发过程通常可划分为多个级别：Blocking、Obstruction-Free、Lock-Free">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/lsx_ttl_ys.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/bubble.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/cur_cpu_rob.png">
<meta property="og:image" content="http://www.calvinneo.com/img/concur/speed_cmp.jpg">
<meta property="og:image" content="http://www.calvinneo.com/img/bfbc/dclpjj.png">
<meta property="og:updated_time" content="2018-07-26T03:08:52.212Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="并发编程重要概念及比较">
<meta name="twitter:description" content="在本篇中比较了各种并发、并行技术。并发(concurrency)强调的是逻辑上的同时发生，是语义上的模型(semantic model)，在实际上并发程序可能是由一个处理器同时(simultaneously)处理多个任务，因此并发过程中常出现一个线程等待其他资源的情况。此时常伴随着线程的阻塞和调度。并发过程通常可划分为多个级别：Blocking、Obstruction-Free、Lock-Free">
<meta name="twitter:image" content="http://www.calvinneo.com/img/concur/lsx_ttl_ys.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.calvinneo.com/2017/12/28/Concurrency-Programming-Compare/"/>





  <title>并发编程重要概念及比较 | Calvin's Marbles</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Calvin's Marbles</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.calvinneo.com/2017/12/28/Concurrency-Programming-Compare/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Calvin Neo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Calvin's Marbles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                并发编程重要概念及比较
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-28T20:34:20+08:00">
                2017-12-28
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/12/28/Concurrency-Programming-Compare/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/12/28/Concurrency-Programming-Compare/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>在本篇中比较了各种并发、并行技术。<br><strong>并发(concurrency)</strong>强调的是逻辑上的同时发生，是语义上的模型(semantic model)，在实际上并发程序可能是由一个处理器同时(simultaneously)处理多个任务，因此并发过程中常出现一个线程等待其他资源的情况。此时常伴随着线程的阻塞和调度。并发过程通常可划分为<a href="http://ifeve.com/lock-free-and-wait-free/" target="_blank" rel="noopener">多个级别</a>：Blocking、Obstruction-Free、Lock-Free、Wait-Free，其中后三种统称为Non-blocking的。<br><strong>并行(parallelism)</strong>属于并发，是运行期的行为(runtime behavior)，并行强调这两个并发事件实际上也是同时发生的，例如在多个处理器上运行的多个任务。但我们不能讲这两个概念绝对化，例如在处理器层面，流水线绝对是并发的，但在操作系统之上提供的机制来说，却体现出顺序的特性<br>【未完待续】</p>
<a id="more"></a>
<h1 id="处理器层面的并发"><a href="#处理器层面的并发" class="headerlink" title="处理器层面的并发"></a>处理器层面的并发</h1><p>这里简单地论述处理器层面的并发相关，例如SMP架构、流水线、分支预测、多级缓存等技术。</p>
<h2 id="流水线-pipeline"><a href="#流水线-pipeline" class="headerlink" title="流水线(pipeline)"></a>流水线(pipeline)</h2><h3 id="流水线和吞吐量"><a href="#流水线和吞吐量" class="headerlink" title="流水线和吞吐量"></a>流水线和吞吐量</h3><p>我们通常使用GOPS（每秒千兆次操作）来定义吞吐量，表示每秒内执行操作的次数。CPU流水线的目的是为了提高吞吐量(throughput)，但会增加每条指令的延迟(latency)，这是因为执行一条指令需要经过更多的流水线寄存器。CSAPP使用一个称为SEQ的架构来描述流水线的通用模型，一条指令在CPU中被执行会经过取指(fetch)、译码(decode)、执行(execute)、访存(memory)、写回(write back)、更新PC（在SEQ+中和取指进行了合并）等阶段。容易想到在某一时钟周期内，每一个阶段都可以独立运行。例如当指令PC在执行阶段时，我们可以对指令PC+1进行译码，这样译码器就不会闲置，这就是流水线化的一个简单思路。这种流水线设计很常见，以486为例，其拥有两条5级流水线<code>取指F-&gt;译码D1-&gt;转址D2-&gt;执行EX-&gt;写回WB</code>。<br>出于两点的考虑，流水线技术会制约了吞吐量能提高的上限：</p>
<ol>
<li>流水线不同阶段的延迟是不同<br> 如下图所示，流水线的吞吐量会受到其中最长操作的局限。<br> <img src="/img/concur/lsx_ttl_ys.png" alt=""></li>
<li>一个较深的流水线可能带来很大的流水线寄存器延迟<br> 这是来自于增加的流水线寄存器所带来的额外开销。</li>
</ol>
<h3 id="流水线和冒险"><a href="#流水线和冒险" class="headerlink" title="流水线和冒险"></a>流水线和冒险</h3><p>控制相关和顺序（数据）相关是使用流水线并发执行一些指令需要面临的问题。其中顺序相关指后一条指令的执行依赖于前一条指令的值，控制相关指的是指令流的路径依赖于前一条指令（通常是条件测试）的结果。为了解决这样的问题，CSAPP首先升级了原先的SEQ到SEQ+，现在我们将更新PC移到最前面，并且和取指进行了合并，这样做的目的是使得我们在程序开始时通过上面一条指令结束时的状态来确定地址。CSAPP基于SEQ+引入了PIPE-这个流水线，并希望PIPE-能够实现每个时钟周期发射(issue)一条指令，因此我们需要在取出一条指令后马上确定下一条指令的位置。这对于ret和条件转移来说是较为麻烦的，因为我们要进行<strong>分支预测</strong>。分支预测有一些策略，包括总是选择（分支），从不选择(NT)。一种正向不选择(BTFNT)策略只接受跳往地址更低的分支（也就是往前跳，后向分支），因为它可能标志着一个循环的右大括号。现在的分支预测器通常分为静态规则和动态规则的，动态规则会基于一些运行期的历史进行类似“强化学习”，例如如果一段分支历史上不进行跳转的成功率大，那么就这一次预测的时候就不进行跳转，<a href="https://zhuanlan.zhihu.com/p/36795318" target="_blank" rel="noopener">知乎专栏</a>上给出了一个详细的例子来验证这个特性，这个实验中验证了对一个有序数组遍历时其耗时约为无序数组的1/3。分支预测失败，也就是所谓的控制冒险(hazard)，它的代价是就会导致流水线刷新(flush)。此外当一条指令<strong>写</strong>后面指令会<strong>读</strong>到的那些程序状态时就会带来数据冒险，特别地我们可以发现控制冒险可以看做是对程序计数器PC而言的数据冒险。我们考虑整个流水线中可能出现的部件，其中通用寄存器和PC已经被证明是存在冒险的，以通用寄存器为例，其写和读发生在流水线上<strong>不同的阶段</strong>（写回和解码）。剩下来的是EFLAGS以及存储器则是不存在冒险的，以存储器为例，其读写<strong>都</strong>发生在流水线的<strong>访存阶段</strong>，那么前一条指令对存储器的<strong>写</strong>对后一条指令对存储器的<strong>读</strong>总是可见的。<br>CPU流水线中通过暂停(stalling)和转发(forward)/旁路(bypassing)的机制解决数据冒险的问题。此外在汇编层面，我们可以使用条件传送而不是条件控制转移来避免分支预测出错的问题。</p>
<h4 id="暂停"><a href="#暂停" class="headerlink" title="暂停"></a>暂停</h4><p>暂停的思路很简单，就是阻塞流水线中的一些指令直到冒险条件不满足。对通用寄存器而言，在解码阶段时流水线会检查前方执行、访存和写回阶段中是否有指令会更新该通用寄存器。如果存在那么就会阻塞处于解码阶段的指令（包括后面即将执行的下一条指令的取指阶段，也就是保持PC的值）。在阻塞时，流水线的一部分会进入空转状态，此时我们成为插入一个气泡(bubble)。如下图所示，在时刻5，原本应该执行的<code>0x00d</code>处的D被阻塞了，因为<code>0x006</code>处的W尚未完成。因此在等待其完成的时间中插入了三个气泡（分别对应EMW阶段）。<br><img src="/img/concur/bubble.png" alt=""></p>
<h4 id="转发"><a href="#转发" class="headerlink" title="转发"></a>转发</h4><p>上面的暂停机制非常直白和简单，但考虑到前后连续两条指令对同一个寄存器先写后读是很通常的情况，此时三个气泡是很划不来的。此时可以借助转发来避免暂停。</p>
<h3 id="现代处理器"><a href="#现代处理器" class="headerlink" title="现代处理器"></a>现代处理器</h3><p>在现代的处理器中，流水线被拆分地更加细，出现了所谓的12级、31级乃至更深的流水线。但是这么深的流水线阻塞的代价是非常巨大的。为此Intel使用了乱序执行组件(Out-of-Order core)。<br><img src="/img/concur/cur_cpu_rob.png" alt=""></p>
<h2 id="CPU的缓存和缓存一致性"><a href="#CPU的缓存和缓存一致性" class="headerlink" title="CPU的缓存和缓存一致性"></a>CPU的缓存和缓存一致性</h2><p>x86往往都有高速缓存Cache，而且有多级。高速缓存基于静态RAM(SRAM)技术，区别于主存的动态RAM(DRAM)技术。现代CPU中寄存器与内存之间没有直接的渠道，而必须通过多级的高速缓存才能到内存。高速缓存的作用依然是为了弥补CPU和内存在速度上的差异，高速缓存提高效率的原理是基于时间局部性和空间局部性，也就是说被引用过一次的存储器位置很可能在不远的将来再次被引用，而存储器中的某一个地址被引用过，那么它附近的地址很可能也会被使用。在CSAPP中专门对高速缓存有将近一章的讨论。<br>虽然高速缓存对用户来说是透明的，我们的代码要不直接操作寄存器，要不直接操作内存，但它并不是不存在，如果深究下去会发现如何保障内存和对应CPU缓存的同步是个问题。但是我们不要担心诸如此类的“一个核心写另一个核心脏读”的情况，x86会在一个CPU修改高速缓存行后自动作废其他CPU的高速缓存行，而缓存一致性协议能够解决内存和多核CPU缓存之间的同步性问题。</p>
<h3 id="局部性原理"><a href="#局部性原理" class="headerlink" title="局部性原理"></a>局部性原理</h3><h3 id="缓存一致性和volatile"><a href="#缓存一致性和volatile" class="headerlink" title="缓存一致性和volatile"></a>缓存一致性和volatile</h3><p>既然我们CPU总是能读到内存里面最新的值，那为啥还需要volatile呢？原因有二</p>
<ol>
<li>CPU不一定会读缓存<br> 这时候要注意区分CPU缓存一致性和volatile之间的关系。例如出于优化的角度，编译器可能把一个在内存的值放到到寄存器里面，以避免访问内存，既然不访问内存那和缓存一致也没啥关系了。但这样就会出现问题，如果某个线程修改了这个值对应的内存，那么寄存器是不知道的，所以这时候volatile强制说不要在寄存器里面读啦，直接从内存里面读，这时候缓存就能发挥应该有的作用了。所以<strong>CPU缓存一致性解决的是CPU的Lx缓存和内存之间之间的问题，而不是CPU寄存器和内存之间的问题</strong>。</li>
<li>有的缓存一致性也不保证是任意时刻的<br> 经过<a href="http://www.infoq.com/cn/articles/cache-coherency-primer/" target="_blank" rel="noopener">简单的了解</a>，CPU缓存行的写操作也分为直写(write though)和回写(write back)两种策略。对于直写来说，确实可以做到任意时刻各缓存中的内容等于内存中内容；但回写就不一定是任意时刻了，因为它并不是立即更新缓存，而是值修改本级缓存，而将对应缓存标记为脏段，只有当所有脏段被会邂逅我们才能达到一致性。具体还可以参看<a href="http://ifeve.com/cpu-cache-flushing-fallacy-cn/" target="_blank" rel="noopener">缓存一致性</a>。</li>
</ol>
<h3 id="缓存一致性协议"><a href="#缓存一致性协议" class="headerlink" title="缓存一致性协议"></a>缓存一致性协议</h3><p>MESI是实现缓存一致性的一个基础协议，MESI分别表示缓存行可能处于的四个状态Modified、Exclusive、Shared、Invalid。其中Intel使用了扩展的MESIF，增加了状态Forward，而AMD使用了MOESI，增加了状态Owned。MESI协议需要正确处理local read(LR)、local write(LW)、remote read(RR)、remote write(RW)四个场景，其中local表示处理器对本地缓存读写，而remote则表示处理器需要对主存读写。一个缓存行Cache0初始状态为I，因为它并不缓存任何数据。当本地处理器向该缓存行请求时，CPU会向其他缓存行询问，如果存在缓存行Cache1拥有该缓存，则将对应缓存行设为S状态，表示目前有多个缓存行缓存有该数据；否则从内存中加载到Cache0，并设为E状态，表示目前只有一个缓存行缓存有该数据。当本地处理器写入时，缓存行状态变为M，此时缓存与主存之间的数据不一致，CPU通知所有对应的其他的缓存行失效，状态变为I。</p>
<h3 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h3><p>伪共享(False Sharing)是在MESI模型下多个线程对同一缓存行竞争写所导致的性能降低。我们考虑<a href="https://blog.csdn.net/qq_27680317/article/details/78486220" target="_blank" rel="noopener">这篇博文中的一个场景</a>一个数组<code>int32_t arr[]</code>被同时加载到CPU0和CPU1的L1缓存Cache0和Cache1上。现在两个线程A和B试图分别修改<code>arr[0]</code>和<code>arr[1]</code>。这种情况下是不存在race condition的，但是可能导致伪共享。我们考虑初始情况下Cache0和Cache1都处于S状态，现在CPU0收到线程A的请求，写<code>arr[0]</code>，Cache0状态变为M，而Cache1收到通知后也作废了自己的缓存行。接下来CPU1发起了写操作，根据MESI模型，CPU0会先将<code>arr[0]</code>写回内存，此时Cache0变为I，之后CPU1才能从内存重新读取，Cache1变成E，然后CPU1才能修改<code>arr[1]</code>。</p>
<h3 id="测试缓存大小"><a href="#测试缓存大小" class="headerlink" title="测试缓存大小"></a>测试缓存大小</h3><h1 id="内核层面的并发"><a href="#内核层面的并发" class="headerlink" title="内核层面的并发"></a>内核层面的并发</h1><h2 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h2><p>在现在的多核CPU（特别是SMP架构）背景下，中断的机制和单核有所区别。在x86中使用的是高级可编程中断控制器(APIC)，APIC由本地APIC和IO APIC组成，其中本地APIC与每个处理器核心对应，IO APIC负责采集和转发来自IO设备的中断信号。<br>根据Intel的规定，广义上的中断可分为<a href="https://www.ibm.com/developerworks/cn/linux/l-cn-linuxkernelint/index.html" target="_blank" rel="noopener">同步中断和异步中断</a>。同步中断又称异常，实际上是由CPU产生的，因此显然不能被屏蔽，异常分为故障(fault)、陷阱(trap)和终止(abort)，异常对应到中断号的0-15。异步中断又称中断，分为外部非屏蔽中断(NMI)和外部可屏蔽中断(INTR)，分别对应中断号的16-31和32-47。中断处理的原则是快，否则很容易被覆盖。在Intel中将非屏蔽中断也归入异常，所以异常一般为来自外设或CPU中的非法或故障状态。除了一些硬件故障，来自外部IO设备的中断常是可以等待的，所以属于可屏蔽中断，当IF标志为1时，CPU可以不响应可屏蔽中断，而是将它缓存起来，在开中断后会传给CPU。当CPU在响应一个异常时，所有的可屏蔽中断都将被屏蔽，而如果此时再出现一个异常，即产生了double fault故障，一般来说系统就会宕机。</p>
<h3 id="软中断和硬中断"><a href="#软中断和硬中断" class="headerlink" title="软中断和硬中断"></a>软中断和硬中断</h3><p>在操作系统如Linux中，中断还可以被分为软中断（内部中断）和硬中断，硬中断是来自硬件的中断，它可以是可屏蔽的，也可以是不可屏蔽的，软中断一般是由<code>int</code>指令产生的，由操作系统提供，在Linux中软中断对应于中断号48-255。软中断是不可屏蔽的（不然干嘛调用<code>int</code>呢），但在操作系统中软中断也可能是由一个硬中断产生的，例如一个来自打印机的硬中断可能产生一个软中断给内核中的相关处理程序，这就是所谓的中断推后处理机制。<br>Linux中硬中断是可嵌套的，也就是说它可以被<strong>非同种中断</strong>打断，Linux禁止来自同种类中断的打断，而是挂起后来的中断，这主要是为了防止重入现象的发生。Linux通过<a href="http://blog.csdn.net/yusiguyuan/article/details/23701519" target="_blank" rel="noopener">巧妙的办法</a>来防止同种类中断重入。<br>如果不希望中断的嵌套的发生，可以进行关中断操作，因为它屏蔽的可屏蔽硬件中断具有抢占性。在关中断时要注意关中断会导致异步IO、调度等一系列依赖中断的功能失效，所以屏蔽中断后一定要尽快执行完临界区内代码。<br>在Linux内核中是允许在硬中断中出现中断嵌套的。这是指在中断处理函数<code>handle_IRQ_event</code>中开启了中断，但是在这个函数前的一条调用链中都是<strong>关中断</strong>的，可参考<a href="http://abcdxyzk.github.io/blog/2015/05/07/kernel-irq-irq/" target="_blank" rel="noopener">这篇文章</a>。所以说只要非同种中断发生就可以抢占内核是不准确的。<br>研究Linux中的进程状态时，我们可以看到一个<code>TASK_UNINTERRUPTIBLE</code>，即不可中断的睡眠状态，这是指这个进程不响应<code>SIGKILL</code>等外部信号，因此必须是十分短暂的，在<code>ps -aux</code>命令中显示为D。顺带一提另一中不能响应外部信号的僵尸进程Z，僵尸进程的资源已经被全部释放，只留下包括<code>task_struct</code>在内的一点信息用来给父进程提供返回码等信息，如果此时父进程被阻塞而不能回收子进程，那么子进程就会进入僵尸状态。<br>Linux中，软中断是不能嵌套的，但可以被硬中断打断，所以可以认为硬中断具有更高的“优先级”，但Linux中并没有中断优先级的概念（不过也有个中断线程化的东西）。软中断可以在SMP的不同CPU上并行执行，Linux上每一个CPU都拥有一个中断栈。<br>Linux中使用一个<code>softirq_action</code>结构维护软中断<br><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">softirq_action</span></span> &#123;  </span><br><span class="line">    void (*action) (<span class="class"><span class="keyword">struct</span> <span class="title">softirq_action</span></span> *); <span class="comment">/* 软中断的处理函数 */</span>  </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>可以看出，软中断实际上很像一个回调函数。那么软中断和回调函数之间有什么区别呢：</p>
<ol>
<li>中断能够实现不同优先级代码的跳转</li>
<li>中断的重入性和回调函数不同</li>
</ol>
<h3 id="中断下半部和软中断"><a href="#中断下半部和软中断" class="headerlink" title="中断下半部和软中断"></a>中断下半部和软中断</h3><p>Linux的外部中断处理过程可以参考<a href="http://home.ustc.edu.cn/~boj/courses/linux_kernel/2_int.html" target="_blank" rel="noopener">文章</a>。<br>中断延时处理和中断下半部分别是来自Windows和Linux的中断推后处理机制。<br>Linux中完整的中断处理包含上半部和下半部，其中上半部是真正的中断处理程序，它短小精悍，运行时需要关中断。<br>Linux中的中断下半部的实现有三种机制：Orignial Bottom Half机制、Task Queue机制、软中断Softirq机制、tasklet和工作队列，其中前两种已被替代。注意到很多博客提到众多下半部不属于中断上下文，但又有说<a href="http://unicornx.github.io/2016/02/11/20160211-lk-drv-softirq/" target="_blank" rel="noopener">软中断处理函数属于中断上下文</a>，从而不允许休眠。但注意工作队列由内核线程eventX执行，允许被调度甚至睡眠</p>
<h2 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h2><h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><h3 id="内核态和用户态"><a href="#内核态和用户态" class="headerlink" title="内核态和用户态"></a>内核态和用户态</h3><p>为了深入了解调度，需要了解一下Linux用户态和内核态的实现机制。从用户态进入内核态可以通过系统调用、异常（如缺页异常）和来自外部设备的硬中断</p>
<h3 id="抢占式调度"><a href="#抢占式调度" class="headerlink" title="抢占式调度"></a>抢占式调度</h3><p>被动式的调度指的是使用一个<strong>调度器</strong>决定哪一个任务会在下一刻运行，而不是由进程主动放弃处理器。调度器暂时停止一个任务并让另一个任务开始执行的行为就是抢占式(preempt)调度。抢占式调度分为<a href="http://blog.csdn.net/gatieme/article/details/51872618" target="_blank" rel="noopener">用户抢占和内核抢占</a>两种。<br>以Linux为例，调度器工作在内核态，所以用户抢占并不是在用户态下，而是发生在进程即将从内核态返回用户态时，这对应两种情况，从系统调用返回和从中断处理程序返回。<br>如果不开启内核抢占，那么进程在内核态的运行会直至结束（主动放弃/时间片耗尽/阻塞），这样的假设方便了内核的编写，特别是在单处理器(UP)下。考虑到在内核态中不存在进程上下文的切换，内核并不需要考虑对临界资源的竞争访问问题，而用户程序也可以假设在一次系统调用过程中不需要保护内核临界资源。但需要注意的是中断仍然存在，所以在进入临界区前还需要关中断。<br>通过内核抢占，系统允许高优先级的进程抢占低优先级的进程的<strong>内核态</strong>，这将能提高系统的实时性能。内核抢占是可以被关闭的，即所谓的关抢占的几种情况：</p>
<ol>
<li>内核正在处理中断<br> 这时候也就是所谓的中断上半部，中断在操作系统中拥有最高的优先级</li>
<li>中断的bottom half<br> 通常有上文所述的三种方式，当内核执行软中断和tasklet是禁止内核抢占（注意此时可以被硬中断打断）</li>
<li>当进程持有自旋锁读写锁<br> 这实际上是为了保护临界资源，在有关自旋锁的讨论中会详细说明</li>
<li>当内核调度器scheduler正在运行时</li>
<li>内核操作Per-CPU data structures<br> 在SMP架构中，不同的CPU仍然会维护一些私有数据，此时抢占可能造成一个进程被调度到另一个CPU上去，此时Per-CPU变量就会发生改变</li>
<li>关中断<br> 这是一种特殊情况，关中断后抢占机制自然无法实现了</li>
</ol>
<p>Linux通过内核抢占锁<code>preempt_count</code>来跟踪一个进程的可抢占性，当内核代码具有抢占性时，则调用<code>preempt_schedule_irq</code>进行内核抢占。<br>因此可以总结到内核抢占可能发生在中断处理程序返回到内核空间前、内核代码具有抢占性、内核代码显式调用调度器schedule、内核中的任务被阻塞。</p>
<h2 id="可重入函数"><a href="#可重入函数" class="headerlink" title="可重入函数"></a>可重入函数</h2><p>考虑单线程模型下的并发，一个典型的模型是signal机制（借助于软中断实现）。一些条件会影响函数的可重入性，例如全局变量的使用，假如说在函数<code>func</code>涉及读写全局变量<code>errno</code>，在运行过程中被signal中断，而中断处理程序也会访问这个<code>errno</code>，那么当继续进行<code>func</code>时就可能读到无效的<code>errno</code>。容易联想到一些和硬件有副作用的函数也是不可重入的，如<code>fprintf</code>、<code>malloc</code>等。<br>异步可重入和线程安全是两个不同的概念，一般来说线程安全的函数不一定是可重入的，如malloc，而反之则可以使用锁机制来避免。所以我们可以体会到Linux提供的signal机制虽然能够实现异步，但是却十分不体面。</p>
<h1 id="内核向外提供的并发设施"><a href="#内核向外提供的并发设施" class="headerlink" title="内核向外提供的并发设施"></a>内核向外提供的并发设施</h1><h2 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h2><p>进程是UNIX设计模型中的一个重要部分，UNIX推崇以多进程+IPC的方式组成应用系统，充分贯彻了KISS的方针。在UNIX产生的年代，这种方式无疑是很健壮的。</p>
<h3 id="进程模型"><a href="#进程模型" class="headerlink" title="进程模型"></a>进程模型</h3><p>五状态进程模型包括新建、就绪（等待CPU）、阻塞（等待事件）、运行和退出。在五状态模型之外，还有挂起操作。挂起操作指的是将进程交换到外存，这常常是由于内存紧张或者该进程被阻塞的缘故。挂起不同于阻塞或者就绪，被挂起的进程犹如进入一个平行世界，当等待的事件到达时，它能够从挂起阻塞直接切换成挂起就绪。一个挂起的进程必须脱去挂起这层壳之后才能重新进入五状态模型，如一个挂起就绪态进程必须换回到内存切换成就绪态才能被调度。</p>
<h3 id="同步与异步"><a href="#同步与异步" class="headerlink" title="同步与异步"></a>同步与异步</h3><p>在进程IPC中同步和异步是两种编程模型，描述了IPC中<strong>被调用者</strong>的行为。在同步模型中一个调用只有在等到结果时才返回，被调用者并不会进行通知。而异步模型中调用会立即返回，而由<strong>被调用者</strong>选择在结果达到后通过回调函数或者信号等机制进行通知。UNP书中还强调异步过程中用户不需要手动将数据从内核复制到用户（即不需要在被通知后调用<code>read</code>等函数）。<br>需要和同步异步进行区分的是阻塞和非阻塞的概念，这两个描述了调用结果未到达时<strong>调用者</strong>的状态。阻塞调用会直接睡眠线程。而非阻塞调用不会阻塞线程，这时候线程可以继续执行下面的逻辑，消息到达时线程收到一个异步信号或者回调，或者采用类似协程的方法，这时候适用异步非阻塞模型。当然线程也可以选择在原地自旋进行轮询，这就是同步非阻塞模型。<br>IO多路复用是一种特殊的同步模型，这是因为在<code>poll</code>函数中仍然需要手动将数据从内核复制回来，并且它们在消息到来前必须在一个循环中轮询，而不是立即返回，跳出循环。不过IO多路复用并不属于同步阻塞模型，因为当一个fd在等待结果时，线程可能在处理来自其它fd的返回结果。IO多路复用也不属于同步非阻塞模型，因为事实上线程还是会被阻塞的。<br>以UNIX套接口为例，<code>SS_NBIO</code>和<code>SS_ASYNC</code>标志分别表示非阻塞和异步的选项，其中非阻塞套接口在请求资源不满足时会返回<code>EWOULDBLOCK</code>，而异步套接口则会通过<code>SIGIO</code>信号来通知进程。</p>
<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>从定义上看，进程是资源分配的最小单位，而线程是程序执行的最小单位。线程通常和同一程序下的其他线程共享一套地址空间，其中包含应用程序拥有的程序代码与资源，每个线程自己维护一套运行上下文。</p>
<h2 id="Linux的进程-线程模型"><a href="#Linux的进程-线程模型" class="headerlink" title="Linux的进程/线程模型"></a>Linux的进程/线程模型</h2><p>对Linux内核来说，线程和进程是不区分的，无论是<code>fork()</code>还是<code>pthread_create()</code>，最后都是调用<code>do_fork()</code>，不过是普通进程和轻量级进程的区别。pthread(POSIX threads)是POSIX下的一套线程模型，它运行在内核外。在Linux平台上，在glibc库源码的<em>nptl</em>目录下可以看到pthread的具体实现。NPTL(Native POSIX Thread Library)是POSIX线程模型的新实现，它的性能和稳定性方面都优于从前用进程模拟线程的的LinuxThreads。<br><code>fork</code>出的子进程默认会拷贝父进程的一系列资源，包括内存（包括堆栈）、文件描述符（特别地<code>exec</code>也会保留文件描述符，可以参考我有关subprocess的文章）、信号设定、Nice优先级值、工作目录等。</p>
<h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><p>协程(Coroutine)是具有多个入口点的函数，协程内部可通过<code>yield</code>进行中断，此时处理器可能被调度到执行其他的函数。虽然线程也可以被睡眠，睡眠本身涉及用户态与内核态的上下文切换，开销较大。对于套接字等IO密集型的应用，协程在提高CPU使用率上比线程轻很多。<br>协程通常分为stackful和stackless两种。stackless实现不保存调用栈和寄存器等上下文，因此效率比较高。stackless的协程实现例如C++中的setjmp、Python中的生成器等。stackful即栈式构造，这时候协程拥有自己的堆栈等上下文。stackful的协程类似于C++中的ucontext、libco等。</p>
<h2 id="C-下协程的实现方式"><a href="#C-下协程的实现方式" class="headerlink" title="C++下协程的实现方式"></a>C++下协程的实现方式</h2><h3 id="基于ucontext"><a href="#基于ucontext" class="headerlink" title="基于ucontext"></a>基于ucontext</h3><p>ucontext是POSIX上的一套用于保存上下文的库，这里上下文包括寄存器（通用和浮点）、信号等。</p>
<h3 id="黑科技1"><a href="#黑科技1" class="headerlink" title="黑科技1"></a>黑科技1</h3><p>Protothreads基于C的是围绕switch展开的一系列黑科技实现的协程。我们首先看它定义的一些原语，原来这就是一个简易的，关于行号的状态机。我在<a href="https://paste.ubuntu.com/p/MDjGpX3999/" target="_blank" rel="noopener">这里模仿Protothreads实现了一个简易版的协程</a><br><figure class="highlight d"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#define PT_BEGIN() <span class="built_in">bool</span> ptYielded = <span class="literal">true</span>; (<span class="keyword">void</span>) ptYielded; <span class="keyword">switch</span> (_ptLine) &#123; <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">#define PT_YIELD() \</span><br><span class="line">    <span class="keyword">do</span> &#123; ptYielded = <span class="literal">false</span>; _ptLine = <span class="keyword">__LINE__</span>; <span class="keyword">case</span> <span class="keyword">__LINE__</span>: \</span><br><span class="line">    <span class="keyword">if</span> (!ptYielded) <span class="keyword">return</span> <span class="literal">true</span>; &#125; <span class="keyword">while</span> (<span class="number">0</span>)</span><br><span class="line">#define PT_END() <span class="keyword">default</span>: ; &#125; Stop(); <span class="keyword">return</span> <span class="literal">false</span>;</span><br></pre></td></tr></table></figure></p>
<p>为了理解这段代码，我们回想C++实现协程需要实现的一个核心问题，并不是调度，而是实现从多个入口点进入。这就意味着我们需要在退出协程函数时记录下已经到了哪里，然后在下一次进入函数时回到这个地方。对于第一个需求，我们可以借助于<code>__LINE__</code>这个宏表示执行到的行号，每次将这个行号赋值给一个int。对于第二个需求，我们可以借助于<code>switch</code>实现跳转。这里用<code>switch</code>而不用<code>goto</code>的原因是<code>switch</code>能够根据int变量来实现<code>goto</code>的功能，而<code>goto</code>需要依赖静态的label。这种巧妙的机制不禁让我想起了称为<a href="https://en.wikipedia.org/wiki/Duff%27s_device" target="_blank" rel="noopener">Duff’s device</a>的优化方案。<br>不过这种机制有一个语法缺陷就是在里面嵌套的switch语句会产生干扰。</p>
<h3 id="基于setjmp和longjmp"><a href="#基于setjmp和longjmp" class="headerlink" title="基于setjmp和longjmp"></a>基于setjmp和longjmp</h3><h1 id="约束线程间并发行为"><a href="#约束线程间并发行为" class="headerlink" title="约束线程间并发行为"></a>约束线程间并发行为</h1><p>线程间实现互斥与同步的任务常具有下面两种形式：</p>
<ol>
<li>多个线程同时访问一个共享资源，需要维护该共享资源的完整性。这就是Race condition问题，将在本节讨论。</li>
<li>一个线程向另一个线程通告自己的结果/等待另一个线程的结果，这将在章节数据共享中讨论。</li>
</ol>
<p>总的来说，为了实现同步，等待资源的一方可以处于用户态（忙等）或者内核态（睡眠），而获得资源的一方可以选择锁进行同步，或者使用原子操作保证自己访问不被打断。这分别下面的基于锁和原子操作的工具。Linux、Windows和C++11的标准库中都对这些工具提供了不同程度的支持，具体可参考<a href="https://www.ibm.com/developerworks/cn/linux/l-cn-mthreadps/index.html" target="_blank" rel="noopener">文档</a>。</p>
<h2 id="Race-condition"><a href="#Race-condition" class="headerlink" title="Race condition"></a>Race condition</h2><p>竞态条件常出现在逻辑电路这样的硬件环境中，对于软件环境而言，当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件(race condition)，导致竞态条件发生的代码区称作临界区。</p>
<h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><p>在有关CPU缓存一致性的章节中，我们讨论的volatile、寄存器、主存和CPU缓存之间的关系。这里我们讨论语言（C/C++）层面的<code>volatile</code>的有关特性。<br>C++中的<code>volatile</code>并不以任何形式保证线程安全，它仅用来告知编译器期修饰的变量是易变的，要避免对其进行优化，这里所谓的优化常常是将变量缓存到寄存器中而不是每次都从内存读取。<code>volatile</code>并不蕴含禁止编译器或者处理器进行重排或乱序，我们需要通过编译器屏障或者内存屏障来实现这一点。<br><code>volatile</code>关键字有时是有用的，例如可以在自旋锁中防止多次循环中始终读取寄存器中的值。但滥用<code>volatile</code>不仅不会提高程序的安全性，而且会导致程序变慢。对于以为可以加“volatile”就可以解决的问题，一般可以使用<code>std::atomic</code>来避免使用内核锁的开销。</p>
<h2 id="内核锁"><a href="#内核锁" class="headerlink" title="内核锁"></a>内核锁</h2><p>内核锁一般基于内核对象互斥量/信号量，它们通常是阻塞锁，会导致线程进入睡眠。锁的存在通常限制了并发范围，变并行访问为串行访问。在使用锁维护临界资源时应当争取让序列化访问最小化，真实并发最大化。</p>
<h3 id="互斥量"><a href="#互斥量" class="headerlink" title="互斥量"></a>互斥量</h3><p>在C++中一般不直接使用<code>std::mutex</code>，而使用<code>lock_guard</code>和<code>unique_lock</code>。<code>lock_guard</code>和<code>unique_lock</code>利用了RAII来自动管理加锁解锁操作，它们能够应用到包括互斥量的所有Lockable的对象上。<code>unique_lock</code>相比于<code>lock_guard</code>更灵活，用户能够手动地加/解锁，例如在条件变量中就需要<code>unique_lock</code>以便解锁，而在取得对临界资源后进行处理时也可以暂时解锁。<code>unique_lock</code>还是可移动的，以下面的代码为例，这里1处是一个直接返回<code>lk</code>，编译器可能进行NRVO，当然即使不这么做，2作为一个直接初始化操作，也可以接受<code>get_lock</code>返回的将亡值，从而完成移动构造<code>std::unique_lock&lt;std::mutex&gt;</code>。因此这里锁的控制权从<code>get_lock</code>转移到了<code>process_data</code>。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; get_lock()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">extern</span> <span class="built_in">std</span>::mutex some_mutex;</span><br><span class="line">  <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lk(some_mutex);</span><br><span class="line">  prepare_data();</span><br><span class="line">  <span class="keyword">return</span> lk;  <span class="comment">// 1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process_data</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lk(get_lock());  <span class="comment">// 2</span></span><br><span class="line">  do_something();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>一般会将mutex和临界资源一起放到一个类中进行管理，此时宜保证该临界资源是非public的，并且不会以引用或者指针的形式传出。这些场景例如成员函数直接返回指针或者引用，友元函数，或者一个接受函数指针P作为参数的函数，且P接受了临界成员的指针或引用，并将其泄露到类外（C++ Concurrency in Action），因此我们还要避免在持有锁时调用用户提供的代码。<br>虽然我们的愿景是希望最大化真实并发，因此要追求较小粒度的锁(small granularity)，一个较小的粒度表现在锁所保护的临界数据较少，并且持有锁的时间较短，但粒度不可能无限小。例如考虑删除双向链表中的一个节点，需要修改三个节点的数据，如果对这三个修改单独加锁，其实等于没有加锁。因此一个直截了当的解决方案是在删除过程中锁住整个链表。如果是仍然希望为每个节点维护一把锁，那么对于删除操作必须获得被删除节点和其相邻的共三把锁，当重新连接节点时，必须在获得当前节点锁的前提下尝试获取下一节点的锁（但一旦持有了下一节点的锁就可以释放当前节点的锁了），以防后继节点产生变化。与此同时，我们还要考虑在遍历的时候需要对要访问的节点上锁，因此遍历时同样需要按照和删除相同的上锁步骤。<br>下面我们考虑一个线程安全的栈，其中实现了<code>empty()</code>、<code>top()</code>、<code>size()</code>、<code>push()</code>、<code>pop()</code>等常见方法。在多线程下，下面的代码中<code>pop()</code>可能使得<code>top()</code>的结果无效，这是因为在1和2两个方法<strong>间</strong>可能有另一个线程执行了<code>pop()</code>。容易看出无论这些方法内部怎么加锁都无法避免这种情况，因为这里的竞态发生在这些方法<strong>之间</strong>，C++ Concurrency in Action特别指出这属于接口设计的问题。在后面内存模型的部分，我们能看到<strong>类似的问题</strong>，原子操作虽然避免了竞态，但原子操作之间可能存在的乱序必须要被考虑。书中还指出了另一个更严重的2和3之间竞争的错误，假设有两个线程并行执行该段代码，我们期望的顺序是<code>top[1] -&gt; pop[1] -&gt; top[2] -&gt; pop[2]</code>，中括号表示执行该方法的线程。然而实际执行顺序可能是<code>top[1] -&gt; top[2] -&gt; pop[1] -&gt; pop[2]</code>。这就导致了从栈顶开始的两个元素有一个被处理了两次，另一个完全没有被处理。一个简单的解决方案是将这两个调用<strong>合并成一个带返回值的pop</strong>，使用一个mutex来管理，但Tom Cargill指出这处理方式是有问题的。这涉及到为什么标准库在设计时选择将<code>top()</code>和<code>pop()</code>两个方法，原因是可能发生在成功将元素pop后而拷贝函数失败，这个元素就被丢失，所以先取<code>top()</code>再<code>pop()</code>保证了<code>top()</code>失败情况下可以选择不执行<code>pop()</code>。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; s;</span><br><span class="line"><span class="keyword">if</span> (! s.empty())&#123;    <span class="comment">// 1</span></span><br><span class="line">  <span class="keyword">int</span> <span class="keyword">const</span> value = s.top();    <span class="comment">// 2</span></span><br><span class="line">  s.pop();    <span class="comment">// 3</span></span><br><span class="line">  do_something(value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>使用互斥量的另一个问题是死锁，这时候锁机制避免了竞态，却可能产生线程对锁的竞争，即线程间互相等待对方的锁。死锁的产生满足四个条件：互斥、占有且请求、不可抢占和循环等待。其中等待且请求条件很关键，当完成一个操作需要获得两个及以上的锁时，死锁往往就会发生。为了解决死锁就要想办法破坏它的四个条件之一。从占有且求的角度来解决，我们可以借助于Dijkstra的银行家算法。在C++11中，我们可以使用标准库函数<code>std::lock</code>来同时上锁，不过现实情境下我们往往难以在申请锁时就确定自己需要哪些锁。从破坏循环等待条件的解读来设计的一个解决方案是永远按照一个顺序来获得锁，以哲学家就餐问题为例，我们将筷子进行编号，并约定哲学家们总是先尝试获得编号较低的筷子，用完后总是先释放编号较高的筷子，这样就能避免死锁问题。注意到约定哲学家们总是先拿起左手边的筷子，再拿起右手边的筷子恰恰会导致死锁问题，因为在这里我们并不是<strong>对每一个哲学家</strong>的操作指定一个<strong>相对的规则</strong>，而是为<strong>所有的资源（锁）</strong>的获取直接指定一个<strong>绝对的顺序</strong>。于是我们发现有时候去确定一个顺序并不是很容易。对于<code>swap</code>函数来说，我们可以按照参数的顺序来加锁，例如先获得第一个参数的锁，再获得第二个参数的锁。可惜这个是相对的，例如考虑如下面代码所示的两个规则，容易发现这两个线程并行执行时死锁就会发生了。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// thread 1</span></span><br><span class="line">swap(a, b);</span><br><span class="line"><span class="comment">// thread 2</span></span><br><span class="line">swap(b, a);</span><br></pre></td></tr></table></figure></p>
<p>为了解决这个问题，一个方法是对每个对象求Hash，从而进行排序，另一种是借助于<code>std::lock</code>函数。这个函数的作用是将多个互斥量同时上锁（失败时则抛出异常并释放已经获得的锁），下面代码展示了一个线程安全的<code>swap</code>。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">some_big_object</span>;</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(some_big_object&amp; lhs,some_big_object&amp; rhs)</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">X</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  some_big_object some_detail;</span><br><span class="line">  <span class="built_in">std</span>::mutex m;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  X(some_big_object <span class="keyword">const</span>&amp; sd):some_detail(sd)&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">friend</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(X&amp; lhs, X&amp; rhs)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(&amp;lhs==&amp;rhs)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">std</span>::lock(lhs.m, rhs.m); <span class="comment">// 1</span></span><br><span class="line">    <span class="comment">// std::adopt_lock告知这个lock_guard已获得锁</span></span><br><span class="line">    <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock_a(lhs.m, <span class="built_in">std</span>::adopt_lock); <span class="comment">// 2</span></span><br><span class="line">    <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock_b(rhs.m, <span class="built_in">std</span>::adopt_lock); <span class="comment">// 3</span></span><br><span class="line">    swap(lhs.some_detail, rhs.some_detail);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 注意1/2/3也可以换为以下代码</span></span><br><span class="line">    <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lock_a(lhs.m, <span class="built_in">std</span>::defer_lock);</span><br><span class="line">    <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lock_b(rhs.m, <span class="built_in">std</span>::defer_lock); <span class="comment">// unique_lock 不对互斥量上锁</span></span><br><span class="line">    <span class="built_in">std</span>::lock(lock_a, lock_b); <span class="comment">// 互斥量在这里上锁</span></span><br></pre></td></tr></table></figure></p>
<p><code>std::lock</code>的实现借助了<code>try_lock</code>即<code>_Try_lock</code>。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> _<span class="title">Lock0</span>, <span class="title">class</span> _<span class="title">Lock1</span>, <span class="title">class</span>... _<span class="title">LockN</span>&gt; <span class="title">inline</span></span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">lock</span>(_<span class="title">Lock0</span>&amp; _<span class="title">Lk0</span>, _<span class="title">Lock1</span>&amp; _<span class="title">Lk1</span>, _<span class="title">LockN</span>&amp;... _<span class="title">LkN</span>)</span></span><br><span class="line"><span class="class">&#123;</span>   <span class="comment">// lock N mutexes</span></span><br><span class="line">    <span class="keyword">int</span> _Res = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (_Res != <span class="number">-1</span>)</span><br><span class="line">        _Res = _Try_lock(_Lk0, _Lk1, _LkN...);</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> _<span class="title">Lock0</span>&gt; <span class="title">inline</span></span></span><br><span class="line"><span class="class"><span class="title">int</span> _<span class="title">Try_lock</span>(_<span class="title">Lock0</span>&amp; _<span class="title">Lk0</span>)</span></span><br><span class="line"><span class="class">&#123;</span>   <span class="comment">// try to lock one mutex</span></span><br><span class="line">    <span class="keyword">if</span> (!_Lk0.try_lock())</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> (<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> _<span class="title">Lock0</span>, <span class="title">class</span> _<span class="title">Lock1</span>, <span class="title">class</span>... _<span class="title">LockN</span>&gt; <span class="title">inline</span></span></span><br><span class="line"><span class="class"><span class="title">int</span> _<span class="title">Try_lock</span>(_<span class="title">Lock0</span>&amp; _<span class="title">Lk0</span>, _<span class="title">Lock1</span>&amp; _<span class="title">Lk1</span>, _<span class="title">LockN</span>&amp;... _<span class="title">LkN</span>)</span></span><br><span class="line"><span class="class">&#123;</span> <span class="comment">// try to lock n-1 mutexes</span></span><br><span class="line">    <span class="keyword">int</span> _Res;</span><br><span class="line">    <span class="comment">// 如果第一个锁_Lk0直接失败，则返回失败0</span></span><br><span class="line">    <span class="keyword">if</span> (!_Lk0.try_lock())</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        <span class="comment">// 否则递归地尝试获取第二个锁_Lk1，如果失败则解开第一个锁并修改_Res为失败0</span></span><br><span class="line">        <span class="keyword">if</span> ((_Res = <span class="built_in">std</span>:: try_lock(_Lk1, _LkN...)) != <span class="number">-1</span>)</span><br><span class="line">            &#123;   <span class="comment">// tail lock failed</span></span><br><span class="line">            _Lk0.unlock();</span><br><span class="line">            ++_Res;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;<span class="keyword">catch</span>(...)&#123;</span><br><span class="line">        <span class="comment">// 如果出现异常同样解开第一个锁并返回失败0</span></span><br><span class="line">        _Lk0.unlock();</span><br><span class="line">        <span class="keyword">throw</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (_Res);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>值得注意的是引起死锁的并不一定是锁，而可以扩展到造成互相等待的其他情况，例如一组线程互相join等待对方，相互阻塞，这导致整个程序无法往下运行，或者线程在持有锁时同时等待其他线程。<br>另一种解决死锁的办法从锁的角度，为锁提供层级。一个已持有低层级锁的线程是不能试图获得高层级的锁的，试图违反这一约定的行为将导致抛出异常或终止程序。注意到不能同时持有相同层级上的锁，所以这些互斥量往往形成一条链。一个层次互斥量<code>hierarchical_mutex</code>的实现可以对每个线程使用一个<code>thread_local</code>全局变量进行维护当前线程所持有的锁的层级，默认取<code>UINT_MAX</code>，这样线程可以获得任何层级的互斥量。<br>但即使可以避免死锁也要注意锁的粒度（保护数据规模与持有时间）对性能的影响，一个总的原则是一个锁应当被持有尽可能少的时间，并且在持有过程中只应该去完成必要的工作。特别地，持有一个锁的同时等待另一个锁，即使不造成死锁，也要考虑其性能问题。以判定两个int是否相等为例，在先前我们看到了一个<code>swap</code>函数的实现方案，同时对两个互斥量进行加锁。但这里考虑到实际上int非常小，所以比较好的是分别对两个int加锁，复制副本，并比较两个副本，从而避免同时持有两个锁。注意和前面<code>top()</code>和<code>pop()</code>所遇到的问题一样，在对intA和intB的读操作(LOAD)间可能发生另一个线程对intA的写操作，导致先前读取到的是旧值。</p>
<h2 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h2><p>自旋锁是一种忙等锁(busy waiting)，它适用于短时间锁定某个资源，这样可以避免内核锁所需要的线程睡眠（两次线程上下文切换）等一系列的开销，但持有过长的自旋锁会导致浪费大量CPU资源。特别是在单核CPU上，自旋锁的使用需要审慎考虑，因为在单核CPU上同一时间只能运行一个线程，这时候如果等待锁的线程先运行，那么它势必进入空等直到时间片用完，因为获得锁的线程势必不能运行以释放锁。因此在单核CPU上使用内核锁进入睡眠是一个好的选择。自旋锁常被用在对称多处理器(SMP)系统中，在多CPU的情况下保护临界区。</p>
<h3 id="自旋锁与中断处理"><a href="#自旋锁与中断处理" class="headerlink" title="自旋锁与中断处理"></a>自旋锁与中断处理</h3><p>处理中断时不能使用互斥量、信号量等让线程进入睡眠的锁，因此自旋锁常用于内核中有关中断处理的部分。内核锁必须在进程上下文中才能使用，这里的关闭中断的目的是为了关闭调度，因为关闭了时钟中断（时钟中断是可以被关闭的），调度器就无法运转了。这样就产生了睡死的现象。</p>
<h3 id="持有自旋锁时不能进入睡眠"><a href="#持有自旋锁时不能进入睡眠" class="headerlink" title="持有自旋锁时不能进入睡眠"></a>持有自旋锁时不能进入睡眠</h3><p>自旋锁适用于不能睡眠的场景，但双向地来说，持有自旋锁时也不能进入睡眠，否则会引起死锁。<br>为了理解原因，首先要了解为什么自旋锁常伴随<strong>关中断</strong>和<strong>关抢占</strong>。Linux中提供了各个品种的自旋锁操作函数。其中<code>spin_lock</code>系列的关闭了抢占而不关中断，而<code>spin_lock_irqsave</code>、<code>spin_lock_irq</code>、<code>spin_lock_bh</code>会一道把中断也关了。<br><a href="http://blog.csdn.net/liduxun/article/details/47833143" target="_blank" rel="noopener">关抢占的原因是</a>如果一个低优先级的线程A获得自旋锁而紧接着被一个高优先级的进程B抢占，那么会造成这两个线程死锁，直到时间片用尽，也就是所谓的优先级反转（优先级倒置）现象，会严重影响性能。<br>关中断的原因是如果一个进程A获得自旋锁然后被一个中断打断，如果这个中断处理器也试图获得同一个自旋锁，那么就会造成在中断内部的死锁（自旋锁不能嵌套上锁，否则会造成自死锁现象），并且中断处理无法被抢占（但可以被其他中断打断）。可以参考<a href="http://blog.guorongfei.com/2014/09/06/linux-interrupt-preemptive-lock/" target="_blank" rel="noopener">文章</a>和<a href="https://www.zhihu.com/question/28821201" target="_blank" rel="noopener">知乎</a>。<br>既然使用自旋锁应当关闭中断或者调度，那么原因就很明显了，如果进程A获得了自旋锁并且阻塞在内核态，此时内核调度了进程B（阻塞可导致调度），而B也试图获得自旋锁，那么B将永远自旋，A将永远睡眠，这类似于开中断时在中断内的死锁情况，不过在这种情况下仍有可能B时间片用完从而再次重新调度。此外<a href="http://blog.csdn.net/samantha_sun/article/details/6365770" target="_blank" rel="noopener">另一种解释</a>认为对于不关中断的自旋锁在睡眠后可能会被重新调度，从而造成自死锁的现象。<br>这种思想同样值得用在处理异常、信号等会破坏程序执行顺序的地方。</p>
<h2 id="临界区"><a href="#临界区" class="headerlink" title="临界区"></a>临界区</h2><p>相对于互锁访问函数这种“有限的”原子操作，临界区允许对<strong>一段代码</strong>进行“原子操作”，临界区相对于互斥量比较轻便，这是由于互斥量能够跨进程，并且支持等待多个内核对象。同时线程在进入一个被占用的临界区时会首先尝试自旋锁，在自旋锁循环一定次数失败后再让线程进入睡眠。</p>
<h3 id="临界资源的初始化"><a href="#临界资源的初始化" class="headerlink" title="临界资源的初始化"></a>临界资源的初始化</h3><p>我们考虑临界资源的初始化问题，一个重要的情景就是实现单例模式。在C++11后，可以方便地使用局部静态变量（Meyers Singleton满足初始化和定义完全在一个线程中发生，并且发生在所有其他线程访问之前）或者<code>std::call_once</code>（在C++11前我们只能使用Linux系统中的替代品<code>pthread_once</code>）实现线程安全的单例模式。<br>不过首先先看看一个使用锁的朴素的，也是开销巨大的方案。查看下面的代码，我们可以发现这里用一把大锁保证了不会有两个线程竞争创建/访问<code>p_singleton</code>的实例。但同时需要意识到当实例被唯一地创建好后，这个函数就不需要要锁来保护了，因为在这种情况下它简单到可以作为原子操作，然而事与愿违的是每次调用这个函数都需要获得锁。因此我们需要一种<strong>仅保护临界资源初始化过程的机制</strong>。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Singleton * p_singleton = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="function">Singleton * <span class="title">get_singleton</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(mtx);</span><br><span class="line">    <span class="keyword">if</span> (p_singleton == <span class="literal">nullptr</span>) &#123; </span><br><span class="line">        p_singleton = <span class="keyword">new</span> Singleton();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> p_singleton;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>双重检查锁定模式(Double-checked locking pattern, DCLP)指的是在加锁前先进行一次验证是否可以加锁。下面使用双重检查锁定模式来减少加锁的开销，具体的做法是先检查一遍<code>p_singleton</code>是否为<code>nullptr</code>。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Singleton * p_singleton = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="function">Singleton * <span class="title">get_singleton</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (p_singleton == <span class="literal">nullptr</span>) &#123; <span class="comment">// a</span></span><br><span class="line">        <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(mtx);</span><br><span class="line">        <span class="keyword">if</span> (p_singleton == <span class="literal">nullptr</span>) &#123; <span class="comment">// b</span></span><br><span class="line">            p_singleton = <span class="keyword">new</span> Singleton();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> p_singleton;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>但其实这种加锁方式也是有<a href="http://blog.jobbole.com/86392/" target="_blank" rel="noopener">理论上的风险</a>的，例如我们的<code>p_singleton</code>不是原子的，甚至都不是volatile的，基于我们与编译器的约定，编译器完全可以认为<code>p_singleton</code>的值不会发生变化，因此直接将两层<code>if</code>削掉一层。<br>但是即使我们将<code>p_singleton</code>套上<code>std::atomic</code>、加上<code>volatile</code>，这个代码仍然是错误的。原因在于<code>p_singleton = new Singleton()</code>这条语句不是原子的。我们可以把该语句分为三步</p>
<ol>
<li>分配内存</li>
<li>构造对象</li>
<li>指针指向对象</li>
</ol>
<p><strong>编译器</strong>在理论上（但实践中编译器没有理由去进行这样的重排）会在2构造对象前执行1内存分配和3指针指向操作。假设线程在1/3步骤完毕之后被挂起而来不及执行2步骤，而另一个线程开始访问a处的代码，注意到此时<code>p_singleton</code>已经不是<code>nullptr</code>了，于是函数会返回一个未初始化的内存。继续思考我们发现，这里的问题是由于第一个线程此时已经在初始化<code>p_singleton</code>，这第二个线程就<strong>不应该有机会执行到a处的代码</strong>，试想即使第二个线程知道初始化再被另一个线程执行，那它也做不了任何事情，因为代码中写了要么初始化并返回指针，要么直接返回指针。选择前者会破坏第一个线程的初始化过程，选择后一个会造成上面说的结果。因此在a处对<code>p_singleton</code>进行保护是非常有必要的。在稍后的章节中，我们将对双重检查锁定模式进行进一步的讨论。</p>
<p>因此实际上使用上面提到的<code>std::call_once</code>是一个更好的解决方案。在下面的代码中，只会输出一行<code>Called once</code>。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::once_flag flag;  </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_once</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="built_in">std</span>::call_once(flag, []()&#123; <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Called once"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; &#125;);  </span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="built_in">std</span>::<span class="function">thread <span class="title">t1</span><span class="params">(do_once)</span></span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="function">thread <span class="title">t2</span><span class="params">(do_once)</span></span>;</span><br><span class="line">    </span><br><span class="line">    t1.join();</span><br><span class="line">    t2.join();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里的<code>std::once_flag</code>不能被拷贝和移动，其实相当于一个锁，<code>call_once</code>实现如下<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> _<span class="title">Fn</span>,</span></span><br><span class="line"><span class="class">    <span class="title">class</span>... _<span class="title">Args</span>&gt; <span class="title">inline</span></span></span><br><span class="line"><span class="class">    <span class="title">void</span> (<span class="title">call_once</span>)(<span class="title">once_flag</span>&amp; _<span class="title">Flag</span>, _<span class="title">Fn</span>&amp;&amp; _<span class="title">Fx</span>, _<span class="title">Args</span>&amp;&amp;... _<span class="title">Ax</span>)</span></span><br><span class="line"><span class="class">    &#123;</span>   <span class="comment">// call _Fx(_Ax...) once</span></span><br><span class="line">    <span class="comment">// 定义一个_Tuple类型</span></span><br><span class="line">    <span class="keyword">typedef</span> tuple&lt;_Fn&amp;&amp;, _Args&amp;&amp;..., _XSTD exception_ptr&amp;&gt; _Tuple;</span><br><span class="line">    <span class="comment">// _Seq的值索引上面的_Tuple</span></span><br><span class="line">    <span class="keyword">typedef</span> make_integer_sequence&lt;<span class="keyword">size_t</span>, <span class="number">1</span> + <span class="keyword">sizeof</span>...(_Args)&gt; _Seq;</span><br><span class="line"></span><br><span class="line">    _XSTD exception_ptr _Exc;</span><br><span class="line">    <span class="comment">// 将回调函数参数打包到_Tuple类型里面，最后一个是exception_ptr</span></span><br><span class="line">    _Tuple _Tup(_STD forward&lt;_Fn&gt;(_Fx), _STD forward&lt;_Args&gt;(_Ax)..., _Exc);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 使用_Tup里面的上下文特化_Callback_once函数模板</span></span><br><span class="line">    _Lambda_fp_t _Fp = &amp;_Callback_once&lt;_Tuple, _Seq, <span class="number">1</span> + <span class="keyword">sizeof</span>...(_Args)&gt;;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 在xonce.cpp中实际调用了__crtInitOnceExecuteOnce的WINAPI</span></span><br><span class="line">    <span class="keyword">if</span> (_Execute_once(_Flag, _Fp, _STD addressof(_Tup)) != <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_Exc)</span><br><span class="line">        _<span class="function">XSTD <span class="title">rethrow_exception</span><span class="params">(_Exc)</span></span>;</span><br><span class="line"></span><br><span class="line">    _XGetLastError();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">// xonce.cpp</span></span><br><span class="line">_STD_BEGIN</span><br><span class="line">_CRTIMP2_PURE <span class="keyword">int</span> __CLRCALL_PURE_OR_CDECL _Execute_once(</span><br><span class="line">    once_flag&amp; _Flag, _Lambda_fp_t _Lambda_fp, <span class="keyword">void</span> *_Pv) _NOEXCEPT</span><br><span class="line">    &#123;   <span class="comment">// wrap Win32 InitOnceExecuteOnce()</span></span><br><span class="line">    <span class="keyword">static_assert</span>(<span class="keyword">sizeof</span>(_Flag._Opaque) == <span class="keyword">sizeof</span>(INIT_ONCE), <span class="string">"invalid size"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (__crtInitOnceExecuteOnce(</span><br><span class="line">        <span class="keyword">reinterpret_cast</span>&lt;PINIT_ONCE&gt;(&amp;_Flag._Opaque),</span><br><span class="line">        <span class="keyword">reinterpret_cast</span>&lt;PINIT_ONCE_FN&gt;(_Lambda_fp),</span><br><span class="line">        _Pv, <span class="number">0</span>));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h2><p>相对于临界区，读写锁能提供更精细的控制，它适用于写操作远少于读操作的数据结构。读写锁允许一个写线程独占访问，而多个读线程并行访问。当写线程需要独占访问时，它需要获得一个排它锁，如果此时有另外的线程持有排它锁或者共享锁，那么本线程就会被阻塞。当读线程需要共享访问时，只要没有线程持有排它锁，那么他就可以立即获得共享锁。读写锁的过程可以参照来自<a href="http://ytliu.info/blog/2013/04/14/tong-bu-yuan-yu-xue-xi-bi-ji-lock,rcuhe-transaction/" target="_blank" rel="noopener">博文</a>的论述<br><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Read</span> <span class="keyword">object</span> <span class="keyword">begin</span></span><br><span class="line">  P(<span class="keyword">object</span>.lock)</span><br><span class="line">  AtomicAdd(<span class="keyword">object</span>.activeReader, <span class="number">1</span>)</span><br><span class="line">  V(<span class="keyword">object</span>.lock)</span><br><span class="line">  <span class="keyword">Do</span> Actual <span class="keyword">Read</span></span><br><span class="line">  AtomicAdd(<span class="keyword">object</span>.activeReaders, −<span class="number">1</span>)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">Write</span> <span class="keyword">object</span> <span class="keyword">begin</span></span><br><span class="line">  P(<span class="keyword">object</span>.lock)</span><br><span class="line">  <span class="keyword">while</span> <span class="keyword">object</span>.activeReaders != <span class="number">0</span> <span class="keyword">do</span> delay</span><br><span class="line">  <span class="keyword">Do</span> Actual <span class="keyword">Write</span></span><br><span class="line">  V(<span class="keyword">object</span>.lock)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<p>对读写锁Windows API提供了所谓的SRW系列函数，Linux提供了rwlock系列函数。在C++14中终于提供了<code>std::shared_timed_mutex</code>来实现读写锁，C++17中提供了<code>std::shared_mutex</code>来实现一个没有定时的读写锁，从设计上看来这是有点本末倒置的，为什么要在C++17实现一个功能更少的类呢？<a href="https://stackoverflow.com/questions/40207171/why-shared-timed-mutex-is-defined-in-c14-but-shared-mutex-in-c17" target="_blank" rel="noopener">SoF指出这是出于性能原因</a>，在C++14制定时，原本的<code>std::shared_mutex</code>拥有定时功能，但稍后一些人指出去掉定时功能能够提高效率，例如在Windows上的<code>SRWLOCK</code>机制提供了高效简便地实现一个没有定时的读写锁的方案，因此后来C++14版本的<code>std::shared_mutex</code>被重命名到<code>std::shared_timed_mutex</code>，而一个没有定时的<code>std::shared_mutex</code>在C++17提供。在C++17中我们的读锁可以声明为<code>std::shared_lock&lt;std::shared_mutex&gt;</code>(<code>shared_lock</code>来自C++14)，写锁可以声明为<code>std::unique_lock&lt;std::shared_mutex&gt;</code>(<code>unique_lock</code>来自C++11)，如此跨越三个版本的标准才最终完成的实现，你只有在C++中才能看到。<br>从实现上来看，无论是关键段、互斥量、信号量，甚至是条件变量都可以实现读写锁。</p>
<ol>
<li>关键段的实现方式<br> 这里摘录了<a href="http://blog.csdn.net/StanfordZhang/article/details/40784975" target="_blank" rel="noopener">CSDN上的一个实现</a>。其思想<a href="https://paste.ubuntu.com/p/9vy7wgbBVS/" target="_blank" rel="noopener">如下</a></li>
<li><p>互斥量的实现方式<br> 使用互斥量时我们需要注意在进行读操作时我们要获取写锁以免脏读，但可能出现多个读线程竞争写锁的情况，所以我们需要一个读锁。只有竞争到读锁的线程才能去锁定写锁。其过程如下</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 写</span></span><br><span class="line">lock(mutex_write);</span><br><span class="line">write();</span><br><span class="line">unlock(mutex_write);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读</span></span><br><span class="line">lock(mutex_read);</span><br><span class="line"><span class="keyword">if</span>(readers == <span class="number">0</span>)</span><br><span class="line">    lock(mutex_write);</span><br><span class="line">readers++;</span><br><span class="line">unlock(mutex_read);</span><br><span class="line">read();</span><br><span class="line">lock(mutex_read);</span><br><span class="line">readers--;</span><br><span class="line"><span class="keyword">if</span>(readers == <span class="number">0</span>)</span><br><span class="line">    unlock(mutex_write);</span><br><span class="line">unlock(mutex_read);</span><br></pre></td></tr></table></figure>
</li>
<li><p>信号量的实现方式<br> 这里的<code>Swait(sem, t, d)</code>表示信号量<code>sem</code>的P操作需要<code>t</code>个资源，并且会消耗<code>d</code>个资源，<code>Ssignal(sem, d)</code>表示信号量<code>sem</code>的V操作产生<code>d</code>个资源。这里<code>Swait</code>类似<code>std::lock</code>，可以同时对若干个信号量上锁，从而避免死锁。</p>
 <figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始化</span></span><br><span class="line">max_reader = n; <span class="comment">// 最多允许n个读者读</span></span><br><span class="line">Sinit(sem_read, max_reader);</span><br><span class="line">Sinit(sem_write, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写</span></span><br><span class="line">Swait(sem_write, <span class="number">1</span>, <span class="number">1</span>; sem_read, max_reader, <span class="number">0</span>);</span><br><span class="line">write();</span><br><span class="line">Ssignal(sem_write, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读</span></span><br><span class="line">Swait(sem_write, <span class="number">1</span>, <span class="number">0</span>; sem_read, <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">write();</span><br><span class="line">Ssignal(sem_read, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p>条件变量的实现方式</p>
</li>
</ol>
<h2 id="不变量与恶性条件竞争"><a href="#不变量与恶性条件竞争" class="headerlink" title="不变量与恶性条件竞争"></a>不变量与恶性条件竞争</h2><p>不变量(invariant)是某个特定数据结构始终保持的特性。例如通过链表的前向指针始终能到达前驱结点。不变量对应的特性常常在更新过程中被破坏，特别是当更新涉及到修改多个值，或者需要多个过程时。这就类似于在最终一致性系统的窗口内强一致性被破坏。当不变量遭到破坏时，才会产生竞态条件（C++ Concurrency in Action: Ch3）。<br>为了解决竞态条件，一种方法是确保只有当前进行修改的线程才能看到不变量被修改的中间状态，也就是将临界资源保护起来，前面看到的互斥量等属于这种机制。另一种方法是借助于锁无关编程技术，这种技术将对数据结构的修改分解为若干个不破坏不变量的原子操作。还有一种办法是借助于事务的STM技术，将所需要的操作存储于日志中，再合并提交。</p>
<h2 id="锁无关"><a href="#锁无关" class="headerlink" title="锁无关"></a>锁无关</h2><p>锁无关(Lock-Free)是一种比无干扰(Obstruction-Free)高层次的并发模型，它是一个容易混淆的概念。锁无关与其他模型的本质区别并不是不用锁(Lockless)，而是确保各个线程在访问共享资源时之间不会互相阻塞，从而使得整个程序整体上能够始终向后执行。相对应地，如果使用内核锁，如果一个获得内核锁的线程被挂起或者挂掉，这容易导致其他拥有锁的线程陷入永久等待。但即使借助于原子操作，也会产生死锁、竞态的问题，例如自旋锁的死锁问题和使用CAS时可能出现的<a href="http://www.isnowfy.com/understand-to-lock-free/" target="_blank" rel="noopener">ABA问题</a>。<br>加锁操作通常存在着<a href="http://blog.csdn.net/liuxuejiang158blog/article/details/17559901" target="_blank" rel="noopener">一些问题</a>，锁无关的编程虽然复杂，但相对于使用锁，锁无关的可伸缩性和性能方面会强于锁相关的算法，并且如果我们能够有序地组织各个线程“各行其道”，就能减少锁的使用。通常来说一个基于锁的算法在高竞争的系统中有较好的效率，因为当发生竞态时线程进行睡眠而不是立即重试，但在一般的情境中，不使用锁往往能避免上下文切换的开销。<br>相应的还有一个无阻塞(Non-blocking)的概念，无阻塞的限制条件要弱于锁无关。属于无阻塞算法而不属于无锁算法的常见例子包括自旋锁。在自旋锁中，所有的线程都不会进入睡眠，因此是非阻塞算法；而考虑当获得锁的线程因为一些原因被暂停时，所有的其他线程仍然需要在原地自旋<strong>忙等</strong>，因而自旋锁不是无锁算法。由此可见，锁无关编程中定义了如原子操作、CAS之类的范式，它们本身都是不涉及到锁的，但为了确保我们的读写成功，往往需要尝试若干次，但这个多次尝试造成的等待本身不属于锁无关的范畴。</p>
<h3 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h3><p>原子操作是常见的实现锁无关编程的方式，常见的原子操作有CAS、FAA、TAS、TTAS等。原子操作指的是<strong>不可被中断的一系列操作</strong>，在原子操作保证当前操作中不发生线程切换，因此保证了其他的线程不可能访问这个资源。原子操作一般有两种实现方式，第一个是使用锁或者CPU的特殊指令等机制来维持原子性，第二个是当出现并发写等破坏原子性的情况时<strong>让操作失败</strong>，因此对于第二种情况需要使用一个循环不断尝试。这里需要注意的是，原子操作并不一定就能够提高效率，也就是所谓的scalability，这是由于涉及对共享对象操作的原子指令都可能造成cache invalidation，也就是需要重新刷新缓存行。另外，原子操作本身也是很慢的，如<a href="https://www.ibm.com/developerworks/cn/linux/l-rcu/" target="_blank" rel="noopener">下图</a>所示<br><img src="/img/concur/speed_cmp.jpg" alt=""><br><a href="https://www.zhihu.com/question/27026846" target="_blank" rel="noopener">我们知道x86汇编要求</a>对任意位置的1字节，以及对<strong>2/4/8对齐</strong>的2/4/8长度的整型读取都<strong>是原子的</strong>，但是C++11前我们却不能假设甚至是对一个<code>int</code>赋值的操作是原子的，而在C++11后我们需要使用<code>std::atomic</code>来显式声明一个原子的变量。这一方面是由于C++无法保证通过一条指令从内存的存取（考虑一些违反strict aliasing的胡乱cast破坏了对齐）。另一方面也是C++11前根本没有考虑对多线程提供语言级别的支持（这点Java就做得比较好），C++标准规定data race，即并发地去修改一个对象是UB的，所以编译器可以不考虑多线程的情况而进行优化，<a href="https://www.zhihu.com/question/27026846" target="_blank" rel="noopener">产生错误</a>。因此通常的方式是直接使用操作系统提供的API，一般来说如果能够有一个<strong>原子的CAS</strong>，那么就能够借助它实现其他的原子操作。<br>为了展示问题的复杂性，下面展示了一个<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/" target="_blank" rel="noopener">早期GCC编译器的问题</a><br><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">extern <span class="keyword">int</span> v;</span><br><span class="line"></span><br><span class="line">void f(<span class="keyword">int</span> set_v)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> (set_v)</span><br><span class="line">    v = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// GCC 3.3.4--4.3.0 O1</span></span><br><span class="line">f:</span><br><span class="line">        pushl   %ebp</span><br><span class="line">        movl    %esp, %ebp</span><br><span class="line">        cmpl    $0, <span class="number">8</span>(%ebp)</span><br><span class="line">        movl    $1, %eax</span><br><span class="line">        cmove   v, %eax        ; load (maybe)</span><br><span class="line">        movl    %eax, v        ; store (always)</span><br><span class="line">        popl    %ebp</span><br><span class="line">        ret</span><br></pre></td></tr></table></figure></p>
<p>在这个问题中考虑调用<code>f(0)</code>，理想情况下<code>v</code>的值无论如何都不会变动的，但是在gcc生成的代码中，我们看到一个始终执行的存储<code>movl %eax, v</code>。显然编译器认为<code>f</code>并不会被修改，而且这对仅面向单线程优化的编译器是完全有理由说得通的。但如果在load和store之间发生了切换，并导致竞态。<br>除了上面的例子，一些常见的优化，例如循环展开都会造成严重后果。</p>
<h3 id="互锁访问函数和CAS操作"><a href="#互锁访问函数和CAS操作" class="headerlink" title="互锁访问函数和CAS操作"></a>互锁访问函数和CAS操作</h3><p>操作系统提供的原子API常借助于某些CPU（比如Intel处理器）提供的指令，能够对<strong>某些类型</strong>实现<strong>某些原子操作</strong>。注意到对SMP架构而言，会出现多个核心并发写的情况，这个涉及到后面的内存模型，并且在这里我们可以暂时忽略这个问题。<br>Windows API提供了一系列Interlocked开头的互锁访问函数，这些函数在处理器层面被保证独占访问。其中一个很关键的便是<code>InterlockedCompareExchange(PLONG dest, LONG value, LONG old)</code>函数，这个函数提供了对<code>LONG</code>类型的原子的CAS操作。<code>InterlockedCompareExchange</code>将<code>*dest</code>和<code>old</code>进行比较，如果相等就将<code>*dest</code>设为<code>value</code>。显然，通过内核锁能够方便地实现原子语义，但原子操作通常会借助于这样的CAS操作，因为这样能避免线程进入睡眠。借助于CAS可以实现其他的原子操作，例如下面的对<code>LONG</code>进行原子赋值的<code>InterlockedExchange</code>函数。在C++11的<code>std::atomic</code>类型中，我们会看到更多的CAS的应用。<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LONG</span> InterlockedExchange(<span class="keyword">LONG</span> <span class="keyword">volatile</span> * target, <span class="keyword">LONG</span> value)&#123;</span><br><span class="line">  <span class="keyword">LONG</span> old;</span><br><span class="line">  <span class="keyword">do</span>&#123;</span><br><span class="line">    old = *target;</span><br><span class="line">  &#125;<span class="keyword">while</span>(! InterlockedCompareExchange(target, value, old));</span><br><span class="line">  <span class="keyword">return</span> old;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里的<code>do-while</code>循环保证了在<code>InterlockedCompareExchange</code>失败之后再来一遍能够再来一遍直到成功，但是<strong>不能将这个循环和自旋锁中的忙等混淆</strong>，从而认为CAS不是锁无关的。这是因为CAS实际上并没有“持有”临界资源，它只需要一个指令就能结束战斗。因此任意一个线程的暂停并不会使得其他线程进入忙等，甚至能够使得CAS的成功率更高。因此可以看出CAS在这里对竞争访问实际上是“消极防御”的态度，也就是所谓的<strong>乐观锁(Optimistic Locking)</strong>，乐观锁是一种非独占锁，它并不是向内核锁一样直接让竞争者们睡眠，而是返回一个失败的状态。相对应的，之前的内核锁和自旋锁等机制属于悲观锁、独占锁。相比乐观锁，悲观锁有以下的弱点（也可以理解为基于锁算法的弱点）</p>
<ol>
<li>上下文切换造成的性能开销</li>
<li>可能造成的死锁问题</li>
<li>优先级倒置</li>
</ol>
<h3 id="使用CAS操作实现的并发缓冲队列"><a href="#使用CAS操作实现的并发缓冲队列" class="headerlink" title="使用CAS操作实现的并发缓冲队列"></a>使用CAS操作实现的并发缓冲队列</h3><p>常见的用CAS实现的Lockfree算法例如缓冲队列。首先对于一读一写的模型我们可以仅通过<a href="http://blog.csdn.net/linyt/article/details/5764312" target="_blank" rel="noopener">约束读指针和写指针</a>的行为即可实现，并不需要接触并发模型。下面我们考虑多对多的模型，以论文<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.8674&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Implementing Lock-Free Queues</a>中的论述为例。<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Enqueue(x) &#123;</span><br><span class="line">    q = <span class="keyword">new</span> record();</span><br><span class="line">    q-&gt;value = x;</span><br><span class="line">    q-&gt;next = <span class="keyword">NULL</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        p = tail; <span class="comment">// 使用tail维护链表尾指针的位置</span></span><br><span class="line">    &#125; <span class="keyword">while</span>( CAS(p-&gt;next, <span class="keyword">NULL</span>, q) != <span class="keyword">true</span>); <span class="comment">// 1</span></span><br><span class="line"> </span><br><span class="line">    CAS(tail, p, q); <span class="comment">// 2</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DeQueue() &#123;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">        p = head;</span><br><span class="line">        <span class="keyword">if</span> (p-&gt;next == <span class="keyword">NULL</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> ERR_EMPTY_QUEUE;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span>( CAS(head, p, p-&gt;next) != <span class="keyword">TRUE</span> );</span><br><span class="line">    <span class="keyword">return</span> p-&gt;next-&gt;value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里有一个疑问，就是为什么2这句不使用循环保护起来，这是因为这个语句是始终能够成功的。我们考虑成功进行了1处CAS的线程T1，它使得<code>tail-&gt;next</code>不为<code>NULL</code>了，假如此时另一个线程T2执行到1，那么它的CAS一定是失败的。这个过程一直到语句2之后<code>tail</code>被成功更新成<code>q</code>，因此实际上可以把<code>tail-&gt;next</code>看成一个锁一样的东西。既然如此，我们容易发现一个违背锁无关性质的可能性，也就是当线程T1在执行语句2时挂掉了，那就会阻塞所有其他在循环中的线程。因此我们提出下面的改良版<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">EnQueue(x)</span><br><span class="line">&#123;</span><br><span class="line">    q = <span class="keyword">new</span> record();</span><br><span class="line">    q-&gt;value = x;</span><br><span class="line">    q-&gt;next = <span class="keyword">NULL</span>;</span><br><span class="line"> </span><br><span class="line">    p = tail;</span><br><span class="line">    oldp = tail;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (p-&gt;next != <span class="keyword">NULL</span>)</span><br><span class="line">            p = p-&gt;next;</span><br><span class="line">    &#125; <span class="keyword">while</span>( CAS(p-&gt;next, <span class="keyword">NULL</span>, q) != <span class="keyword">TRUE</span>); <span class="comment">// 1</span></span><br><span class="line"> </span><br><span class="line">    CAS(tail, oldp, q); <span class="comment">// 2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>考虑到可能来自其他线程的未提交（指未执行语句2）的添加，我们发现语句<code>p = tail</code>中的<code>tail</code>并不一定是结尾，这也导致了为了维护离开循环时<code>p</code>必须指向结尾这个特性，线程需要在循环内自旋，从而导致上述的死锁现象的产生。为了解决问题，在这一版本中我们索性放宽假设，认为<code>tail</code>只是“接近”结尾，因此现在我们需要使用一个内层的<code>while</code>循环来从<code>tail</code>开始尝试更新结尾。这样即使T1线程挂在语句2，没能更新完<code>tail</code>指针，线程T2也可以自动跟踪到T1在1处的修改。此时我们也不要担心语句2的失败问题，因为有的时候它应该失败。考虑下面的执行顺序：原先链表中只有一个元素1，此时线程T1添加了一个元素2，并且成功执行语句1，将<code>p</code>指向了元素2的位置。此时发生了调度，线程T2获得处理器，它需要在队列中加一个元素3，T2在刚进入循环时它发现自己的<code>tail</code>是指向1的，但它在内层的<code>while</code>循环中根据<code>p</code>的<code>next</code>指针走到了刚被T1添加进去的元素2处。因此T2在元素2的末尾增加了元素3，并且更新自己的<code>p</code>指向元素3。T2继续执行语句2，此时<code>tail == oldp</code>指向元素1，所以CAS成功，<code>tail</code>指向了元素3。接着T1重新获得了处理器，此时<code>tail</code>已经被T2修改到指向元素3了，于是不能匹配<code>oldp</code>，这个CAS就会失败。容易看到这个失败不会影响<code>tail</code>指向精确的队列结尾。但是如果我们稍稍修改下上面的运行顺序，按照<code>T1添加元素2 =&gt; T2添加元素3 =&gt; T1修改tail =&gt; T2修改tail(失败)</code>来执行，那么我们就会发现<code>tail</code>被更新到指向元素2而不是元素3。所以我们看到先前我们放宽的假设是非常有必要的，在论文中作者指出这种情况下<code>tail</code>指针距离列表的准确结束位置最多相差<code>2 * p - 1</code>个节点。其实这个“最多”还是有点多的，所以在实践中我们常常结合两种方案来使用。</p>
<h3 id="CPU提供的原子操作"><a href="#CPU提供的原子操作" class="headerlink" title="CPU提供的原子操作"></a>CPU提供的原子操作</h3><p>如果细究上面WINAPI的<code>InterlockedCompareExchange</code>，容易猜到它的实现方式来自于CPU的硬件支持，因为它只能为特定数据类型提供服务。事实上，这里<a href="http://blog.csdn.net/zhangliang1223/article/details/7614027" target="_blank" rel="noopener">用了x86中的<strong>cmpxchg</strong>命令</a>。<br>CPU原子操作的实现借助于总线锁、缓存锁等机制。</p>
<h2 id="C-的原子操作库"><a href="#C-的原子操作库" class="headerlink" title="C++的原子操作库"></a>C++的原子操作库</h2><p>在上面的章节中，我们概览了锁无关编程的一些思想。从现在开始，我们将讨论<strong>C++11标准库</strong>提供的原子操作支持。</p>
<h3 id="std-atomic-flag"><a href="#std-atomic-flag" class="headerlink" title="std::atomic_flag"></a>std::atomic_flag</h3><p><code>std::atomic_flag</code>是C++11原子库的一个基础设施，它被广泛地运用到下面的<code>std::atomic</code>类模板的实现中。<code>std::atomic_flag</code>基于TAS(test-and-set)操作维护了一个布尔量flag，提供了<code>test_and_set</code>和<code>clear</code>两个方法，可以保证对flag的写不会冲突，读不会脏读。<code>test_and_set</code>尝试将flag从false设为true，如果发现flag已被设置，否则原子地设置flag为true，该函数返回的是flag先前的值。由于<code>std::atomic_flag</code>原子地维护了一个flag，它常被用来实现自旋锁。下面的代码来自MSVC的atomic库，它在<code>std::atomic</code>的<code>_Atomic_copy</code>方法中被调用。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span> _Lock_spin_lock(</span><br><span class="line">    <span class="keyword">volatile</span> _Atomic_flag_t *_Flag)</span><br><span class="line">    &#123;</span><br><span class="line">    <span class="keyword">while</span> (_ATOMIC_FLAG_TEST_AND_SET(_Flag, memory_order_acquire))</span><br><span class="line">        _YIELD_PROCESSOR;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span> _Unlock_spin_lock(</span><br><span class="line">    <span class="keyword">volatile</span> _Atomic_flag_t *_Flag)</span><br><span class="line">    &#123;</span><br><span class="line">    _ATOMIC_FLAG_CLEAR(_Flag, memory_order_release);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>此外，容易发现TAS操作也可以通过CAS实现，其代码很简单<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> InterlockedCompareExchange(&amp;flag, <span class="literal">true</span>, <span class="literal">false</span>);</span><br></pre></td></tr></table></figure></p>
<p>在MSVC的标准库实现中<code>test_and_set</code>借助了Interlock互锁访问函数，保证了访问的原子性<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"> <span class="meta">#<span class="meta-keyword">if</span> defined(_M_ARM) || defined(_M_ARM64)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _INTRIN_RELAXED(x)    _CONCAT(x, _nf)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _INTRIN_ACQUIRE(x)    _CONCAT(x, _acq)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _INTRIN_RELEASE(x)    _CONCAT(x, _rel)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _INTRIN_SEQ_CST(x)    x</span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">else</span> <span class="comment">/* defined(_M_ARM) || defined(_M_ARM64) */</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _INTRIN_RELAXED(x)    x</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _INTRIN_ACQUIRE(x)    x</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _INTRIN_RELEASE(x)    x</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _INTRIN_SEQ_CST(x)    x</span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* defined(_M_ARM) || defined(_M_ARM64) */</span></span></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">int</span> _Atomic_flag_test_and_set(<span class="keyword">volatile</span> _Atomic_flag_t *_Flag,</span><br><span class="line">    memory_order _Order)</span><br><span class="line">    &#123;   <span class="comment">/* atomically test flag and set to true */</span></span><br><span class="line">    <span class="keyword">switch</span> (_Order)</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="keyword">case</span> memory_order_relaxed:</span><br><span class="line">            <span class="keyword">return</span> (_INTRIN_RELAXED(_interlockedbittestandset)(_Flag, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> memory_order_consume:</span><br><span class="line">        <span class="keyword">case</span> memory_order_acquire:</span><br><span class="line">            <span class="keyword">return</span> (_INTRIN_ACQUIRE(_interlockedbittestandset)(_Flag, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> memory_order_release:</span><br><span class="line">            <span class="keyword">return</span> (_INTRIN_RELEASE(_interlockedbittestandset)(_Flag, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> memory_order_acq_rel:</span><br><span class="line">        <span class="keyword">case</span> memory_order_seq_cst:</span><br><span class="line">            <span class="keyword">return</span> (_INTRIN_SEQ_CST(_interlockedbittestandset)(_Flag, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            _INVALID_MEMORY_ORDER;</span><br><span class="line">            <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span> _Atomic_flag_clear(<span class="keyword">volatile</span> _Atomic_flag_t *_Flag,</span><br><span class="line">    memory_order _Order)</span><br><span class="line">    &#123;   <span class="comment">/* atomically clear flag */</span></span><br><span class="line">    <span class="keyword">static_assert</span>(<span class="keyword">sizeof</span>(_Atomic_flag_t) == <span class="keyword">sizeof</span>(_Uint4_t),</span><br><span class="line">        <span class="string">"Unexpected _Atomic_flag_t size"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">switch</span> (_Order)</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="keyword">case</span> memory_order_relaxed:</span><br><span class="line">        <span class="keyword">case</span> memory_order_release:</span><br><span class="line">        <span class="keyword">case</span> memory_order_seq_cst:</span><br><span class="line">            _Atomic_store_4((<span class="keyword">volatile</span> _Uint4_t *)_Flag, <span class="number">0</span>, _Order);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            _INVALID_MEMORY_ORDER;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="std-atomic"><a href="#std-atomic" class="headerlink" title="std::atomic"></a>std::atomic</h3><p>在前面的讨论中我们已经明白C++中的基本类型并不保证是原子的，所以<code>std::atomic&lt;T&gt;</code>定义了一系列具有<strong>原子行为</strong>的<strong>类型</strong>。<code>std::atomic</code>禁用了复制构造函数和复制赋值运算符（同时也不允许移动）。这是由于这两个操作发生在两个对象间，势必要破坏原子性，而一个<code>std::atomic</code>的所有操作都是原子的。<br>对于用户自定义类型(UDT)<code>typename T</code>，<code>std::atomic</code>的<strong>主模板</strong>要求<code>T</code>满足<a href="http://zh.cppreference.com/w/cpp/atomic/atomic" target="_blank" rel="noopener">standard layout、trivial default constructor和trivial destructor</a>，即编译器可以使用<code>memcpy</code>等进行bitwise的复制并使用<code>memcmp</code>进行bitwise的比较。在CAS操作的实现中调用了<code>memcpy</code>和<code>memcmp</code>。这看起来限制很大，我们希望有用户自定义的复制构造函数，这样我们就可以进行member-wise的操作了，对此想法，<em>C++ Concurrency in Action</em>一书中指出，如果有自定义的复制构造函数，那么就势必要将锁定区域（下文中会交待其实<code>std::atomic</code>的主模板实现中可能会有自旋锁）内的数据交给这些用户代码，如果在用户代码中再使用了锁，就可能产生死锁的现象。容易发现我们常用的智能指针<code>std::shared_ptr</code>并不能被放到<code>std::atomic</code>里面，但是我们又确实有这个需要，因此标准库通过重载<code>std::atomic_</code>系列函数为<code>std::shared_ptr</code>提供了原子操作的支持。而对于<code>std::atomic</code>类型，我们既可以通过<code>std::atomic_</code>系列函数，也可以通过<code>std::atomic</code>模板中提供了<code>compare_exchange_weak</code>、<code>compare_exchange_strong</code>、<code>load</code>、<code>store</code>等操作。<br>一般标准库会对一些大小满足能够直接使用某些处理器的原子指令的类型进行特化，例如指针类型、integral类型和一些用户定义类型。对于指针类型，<code>std::atomic</code>会进行偏特化。原子的指针运算可以通过<code>fetch_</code>开头的函数和相应的<code>operator</code>运算符来实现。对integeral类型<code>std::atomic</code>类模板也会进行特化，其实现类似指针类型，并且添加了对位运算的支持。对于“复杂”的整型计算如乘法，虽然atomic未提供，但可以通过<code>compare_exchange_weak</code>等函数间接实现。从C++20开始，<code>std::atomic</code>类模板提供对浮点类型的特化。注意在这之前，<code>compare_exchange_strong</code>等CAS方法对浮点数可能出现问题，原因显而易见是<code>memcmp</code>的锅，C++浮点数之间比较时甚至都不能使用<code>==</code>，遑论<code>memcmp</code>。<br>在上文中提到，除了<code>std::atomic_flag</code>，<code>std::atomic&lt;typename T&gt;</code>类模板都是<strong>不保证不使用锁</strong>的（情况特定于处理器和标准库实现），用户可通过<code>bool is_lock_free()</code>函数判断是否Lockfree的。以PJ Plauger的实现为例，主模板的<code>load()</code>内部就使用了上文提到的用<code>std::atomic_flag</code>实现的自旋锁。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span> _Atomic_copy(<span class="keyword">volatile</span> _Atomic_flag_t *_Flag, <span class="keyword">size_t</span> _Size,</span><br><span class="line">    <span class="keyword">volatile</span> <span class="keyword">void</span> *_Tgt, <span class="keyword">volatile</span> <span class="keyword">const</span> <span class="keyword">void</span> *_Src, memory_order _Order)</span><br><span class="line">&#123;</span><br><span class="line">    _Lock_spin_lock(_Flag);</span><br><span class="line">    _CSTD memcpy((void *)_Tgt, (void *)_Src, _Size);</span><br><span class="line">    _Unlock_spin_lock(_Flag);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里要提一句，主模板的<code>template&lt;class _Ty&gt; struct atomic</code>的实现继承了<code>_Atomic_base&lt;_Ty, sizeof (_Ty)&gt;</code>。这个<code>_Atomic_base&lt;_Ty, sizeof (_Ty)&gt;</code>模板又继承了<code>_Atomic_impl&lt;_Bytes&gt;</code>模板，其作用相当于把<code>_Atomic_impl&lt;_Bytes&gt;</code>中全<code>void *</code>的东西封装回了<code>_Ty</code>。我们查看最核心的<code>_Atomic_impl&lt;_Bytes&gt;</code>模板，它是和数据字节数相关的，分别对1/2/4/8字节的进行了偏特化。模板里面定义了最重要的<code>_Is_lock_free</code>、<code>_Store</code>、<code>_Load</code>、<code>_Exchange</code>、<code>_Compare_exchange_weak</code>、<code>_Compare_exchange_strong</code>等操作，全部是<code>void*</code>的。我们刚才看到的<code>_Atomic_copy</code>来自于主模板。我们下面看看<code>_Atomic_impl&lt;_Bytes&gt;</code>的偏特化版本，如对于一个<code>uint2_t</code>是如何实现的<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _Compiler_barrier()   _ReadWriteBarrier()</span></span><br><span class="line"></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">if</span> defined(_M_ARM)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _Memory_barrier()     __dmb(_ARM_BARRIER_ISH)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* defined(_M_ARM) */</span></span></span><br><span class="line"></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">if</span> defined(_M_ARM64)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> _Memory_barrier()     __dmb(_ARM64_BARRIER_ISH)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* defined(_M_ARM64) *</span></span></span><br><span class="line"><span class="meta"><span class="comment">  </span></span></span><br><span class="line"><span class="meta"><span class="comment">    /* _Atomic_load_2 */</span></span></span><br><span class="line"><span class="keyword">inline</span> _Uint2_t _Load_seq_cst_2(<span class="keyword">volatile</span> _Uint2_t *_Tgt)</span><br><span class="line">    &#123;</span><br><span class="line">    _Uint2_t _Value;</span><br><span class="line"></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">if</span> defined(_M_ARM) || defined(_M_ARM64)</span></span><br><span class="line">    _Value = __iso_volatile_load16((<span class="keyword">volatile</span> <span class="keyword">short</span> *)_Tgt);</span><br><span class="line">    _Memory_barrier();</span><br><span class="line"></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    _Value = *_Tgt;</span><br><span class="line">    _Compiler_barrier();</span><br><span class="line"> <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (_Value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> _Uint2_t _Load_relaxed_2(<span class="keyword">volatile</span> _Uint2_t *_Tgt)</span><br><span class="line">    &#123;</span><br><span class="line">    _Uint2_t _Value;</span><br><span class="line"></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">if</span> defined(_M_ARM) || defined(_M_ARM64)</span></span><br><span class="line">    _Value = __iso_volatile_load16((<span class="keyword">volatile</span> <span class="keyword">short</span> *)_Tgt);</span><br><span class="line"></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    _Value = *_Tgt;</span><br><span class="line"> <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">return</span> (_Value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> _Uint2_t _Load_acquire_2(<span class="keyword">volatile</span> _Uint2_t *_Tgt)</span><br><span class="line">    &#123;   </span><br><span class="line">    <span class="keyword">return</span> (_Load_seq_cst_2(_Tgt));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>可以发现在这个偏特化版本的实现中直接借助了处理器提供的设施，而避免了自旋锁的使用。</p>
<h3 id="weak和strong版本的CAS"><a href="#weak和strong版本的CAS" class="headerlink" title="weak和strong版本的CAS"></a>weak和strong版本的CAS</h3><p>类似与Windows API的互锁访问函数，atomic库通过<code>bool atomic::compare_exchange_weak(old, value)</code>和<code>bool atomic::compare_exchange_strong(old, value)</code>提供了对CAS操作的支持。这两个函数监测该<code>std::atomic</code>中维护的<code>std::atomic_flag _My_flag</code>（在<code>_Atomic_impl</code>模板中定义）的值，如果等于<code>old</code>就改为<code>value</code>，函数返回一个表示修改是否成功的bool量。因此容易发现这两个函数不总是成功的，因为CPU可能仅对某些类型提供了相应的CAS原子指令，对于其他的类型则必须通过使用自旋锁甚至内核锁来实现。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">int</span> _Atomic_compare_exchange_weak(<span class="keyword">volatile</span> _Atomic_flag_t *_Flag, <span class="keyword">size_t</span> _Size, <span class="keyword">volatile</span> <span class="keyword">void</span> *_Tgt, <span class="keyword">volatile</span> <span class="keyword">void</span> *_Exp, <span class="keyword">const</span> <span class="keyword">volatile</span> <span class="keyword">void</span> *_Src, memory_order _Order1, memory_order _Order2)</span><br><span class="line">&#123;   <span class="comment">/* atomically compare and exchange with memory ordering */</span></span><br><span class="line">    <span class="keyword">int</span> _Result;</span><br><span class="line"></span><br><span class="line">    _Lock_spin_lock(_Flag);</span><br><span class="line">    _Result = _CSTD <span class="built_in">memcmp</span>((<span class="keyword">const</span> <span class="keyword">void</span> *)_Tgt, (<span class="keyword">const</span> <span class="keyword">void</span> *)_Exp, _Size) == <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (_Result != <span class="number">0</span>)</span><br><span class="line">        _CSTD memcpy((void *)_Tgt, (void *)_Src, _Size);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        _CSTD <span class="built_in">memcpy</span>((<span class="keyword">void</span> *)_Exp, (<span class="keyword">void</span> *)_Tgt, _Size);</span><br><span class="line">    _Unlock_spin_lock(_Flag);</span><br><span class="line">    <span class="keyword">return</span> (_Result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这两个函数有一些细致的区别，<code>compare_exchange_weak</code>在可能会False Negative，这是由于weak允许spurious failure。在某些平台（不错ARM、PowerPC又被点名了）上的CAS是通过LL/SC实现的，而不像x86上那样只通过一条指令，所以可能存在问题。因此使用<code>compare_exchange_weak</code>的时候需要一个循环。注意到这个<code>!expected</code>不是必要的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> expected=<span class="literal">false</span>;</span><br><span class="line"><span class="keyword">extern</span> atomic&lt;<span class="keyword">bool</span>&gt; b; <span class="comment">// set somewhere else</span></span><br><span class="line"><span class="keyword">while</span>(!b.compare_exchange_weak(expected,<span class="literal">true</span>) &amp;&amp; !expected);</span><br></pre></td></tr></table></figure></p>
<p>在<a href="https://chaomai.github.io/2015/06/09/2015-2015-06-09-translation-understand-std-atomic-compare-exchange-weak-in-cpp11/" target="_blank" rel="noopener">Stackoverflow上相关问题的整理</a>中提到了这两者之间的性能比较，由于weak会忽视检查，所以一般weak比strong快。但是如果使用strong能避免weak+loop，那么选择strong是适合的。注意到即使使用strong，loop也不是就一定可以避免的，因为原子操作本来就存在使用乐观锁的情况。</p>
<h3 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h3><p>伴随着CAS的是可能存在的ABA问题。ABA问题的根源是从内存中取出值和CAS这两个操作不是原子的，因此可能在这两个过程中发生切换。</p>
<h3 id="原子操作与锁的关系"><a href="#原子操作与锁的关系" class="headerlink" title="原子操作与锁的关系"></a>原子操作与锁的关系</h3><p>在上面的讨论中，我们能够直观地发现原子操作和锁的关系。原子操作看起来是“独善其身”的只能管住自己，原子操作之间、原子操作和非原子操作之间可能发生乱序或重排；而锁像大哥，能护住一段代码。由此我们思考如何通过原子操作来组织其他的那些非原子操作呢？这就要引入下面讨论的内存模型的问题。</p>
<h2 id="其他的同步原语"><a href="#其他的同步原语" class="headerlink" title="其他的同步原语"></a>其他的同步原语</h2><p>在上面的几个章节中，我们论述了基于锁和基于原子操作的同步原语。还有一些其他的同步原语，例如RCU、MCS Lock等。在Linux中使用了</p>
<h3 id="Hazard-Pointer"><a href="#Hazard-Pointer" class="headerlink" title="Hazard Pointer"></a>Hazard Pointer</h3><p><a href="http://www.cs.otago.ac.nz/cosc440/readings/hazard-pointers.pdf" target="_blank" rel="noopener">Hazard Pointer</a>类似于面向多线程的智能指针，它能够无等待地进行线程安全的垃圾回收。</p>
<h3 id="RCU"><a href="#RCU" class="headerlink" title="RCU"></a>RCU</h3><p><a href="http://www.rdrop.com/~paulmck/RCU/whatisRCU.html" target="_blank" rel="noopener">RCU(Read Copy Update)</a>是一种替代读写锁的方法，在Linux内核中被广泛使用。其思想是</p>
<ol>
<li>对于写操作<ol>
<li>从数据结构中移除对应的指针，因此后面的读者将不能成功读取</li>
<li>等待前面的读者完成读取</li>
<li></li>
</ol>
</li>
</ol>
<h2 id="通过内存模型约束线程对变量的读写顺序"><a href="#通过内存模型约束线程对变量的读写顺序" class="headerlink" title="通过内存模型约束线程对变量的读写顺序"></a>通过内存模型约束线程对变量的读写顺序</h2><p>锁无关编程的难点之一就是需要从编译器与CPU两个层面考虑行为对线程间的同步造成的的影响，也就是考虑<strong>编译器重排和CPU缓存</strong>与乱序对读写逻辑可能造成的影响。当我们试图使用原子操作去解决非原子操作间的竞态问题时，那么我们需要谨慎选择使用恰当的内存模型，这样能够在提升效率的同时保证安全性。</p>
<h3 id="原子操作的线程间顺序"><a href="#原子操作的线程间顺序" class="headerlink" title="原子操作的线程间顺序"></a>原子操作的线程间顺序</h3><p>我们知道从C++语言到运行程序得到结果之间需要经历编译器优化和处理器优化两道坎，处理器优化包括高速缓存和指令乱序，编译器优化可能进行重排。编译器和处理器达成的协议是不能改变单线程程序的行为。以编译器优化为例，下面展示的代码在O0下，g++7按照1-2的原始顺序来编译，但开启O1后，g++7就会进行Store-Store重排，将2提到1前面，先对b赋值，再对a赋值；并且还去除了一部分没用的代码。对单线程来说，这样的优化并没有任何问题。但对于多线程来说则可能出现问题。一方面，由于去除部分代码的原因，汇编O1事实上不能在a处观察到<code>a == 1 &amp;&amp; b == 1</code>的情况，而假设O0汇编在进行到b处被抢占，那么其他的线程有机会看到以上的情况。另一方面，在O1中先对b赋值再对a赋值，仍然会出现问题。假如说在3和4间线程被强占，那么另外一个线程观察<code>a</code>和<code>b</code>，得到<code>b</code>为123，而<code>a</code>为不确定值（或者1，如果前面赋初值语句没有被删去的话），而如果编译器不进行重排，我们理想中的原始结果是<code>a</code>为43，<code>b</code>为不确定值。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">1</span>, b = <span class="number">1</span>; <span class="comment">// 0</span></span><br><span class="line">    <span class="comment">// a</span></span><br><span class="line">    a = b + <span class="number">42</span>; <span class="comment">// 1</span></span><br><span class="line">    <span class="comment">// c</span></span><br><span class="line">    b = <span class="number">123</span>; <span class="comment">// 2</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d %d"</span>, a, b);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// compile with -O0</span></span><br><span class="line">    movl    $<span class="number">1</span>, <span class="number">-8</span>(%rbp)</span><br><span class="line">    movl    $<span class="number">1</span>, <span class="number">-4</span>(%rbp)</span><br><span class="line">    <span class="comment">// b</span></span><br><span class="line">    movl    <span class="number">-4</span>(%rbp), %eax</span><br><span class="line">    addl    $<span class="number">42</span>, %eax</span><br><span class="line">    movl    %eax, <span class="number">-8</span>(%rbp)</span><br><span class="line">    movl    $<span class="number">123</span>, <span class="number">-4</span>(%rbp)</span><br><span class="line">    movl    <span class="number">-4</span>(%rbp), %edx</span><br><span class="line">    movl    <span class="number">-8</span>(%rbp), %eax</span><br><span class="line"><span class="comment">// compile with -O1</span></span><br><span class="line">    movl    $<span class="number">123</span>, %ecx <span class="comment">// 3</span></span><br><span class="line">    movl    $<span class="number">43</span>, %edx <span class="comment">// 4</span></span><br></pre></td></tr></table></figure></p>
<p>出于性能方面的考虑，对<strong>多线程</strong>的程序而言并不存在和单线程一样的硬性要求。在使用原子操作等锁无关技术时，不能假设所有环境下程序最后行为一如我们希望代码所“暗示”一样。事实上编译器或处理器可以在<strong>不同线程间</strong>对<strong>不同变量间</strong>进行读写乱序，而这在多线程中会造成问题。例如在单线程中将对B的写提到对A的读前面是没有问题的，但是对多线程来说，这往往就会出现问题。虽然大部分时候我们不需要操心这个问题，这是因为一方面在使用mutex等内核锁时，内核帮我们做了相关工作，另一方面部分处理器（如x86）也提供了（<a href="https://www.zhihu.com/question/24301047" target="_blank" rel="noopener">近似</a>，实际上是<a href="https://ljalphabeta.gitbooks.io/a-primer-on-memory-consistency-and-cache-coherenc/content/%E7%AC%AC%E5%9B%9B%E7%AB%A0-total-store-order%E5%92%8Cx.html" target="_blank" rel="noopener">TSO</a>）acquire/release的保障，并也可以通过一些指令命令编译器在某些地方减少优化，但这依然是一个客观存在的问题。</p>
<h3 id="可见性和有序性"><a href="#可见性和有序性" class="headerlink" title="可见性和有序性"></a>可见性和有序性</h3><p>可见性指一个线程对变量的写操作对其它线程后续的读操作可见，这里见的是结果。可见性要求CPU在对缓存行写操作后能够保证至少在某个时间点前必须写回内存，从而保证其他线程能读到<strong>最新的值</strong>。有序性指的是数据不相关变量在并发的情况下，实际执行的结果和单线程的执行结果和单线程的执行结果是一样的，不会因为重排/乱序的问题导致结果不可预知。</p>
<p>根据以上的定义，我们引入下面的两个概念：<br>如果操作A先行发生(happen-before)于操作B，那么A造成的修改能够被B观察到。我们以<a href="https://zhuanlan.zhihu.com/p/31386431" target="_blank" rel="noopener">知乎</a>上举出的一个例子来理解，根据上面有关原子操作的线程间顺序的讨论，我们知道下面的代码在单线程条件下断言是始终成立的，即使语句1和2之间发生了重排。容易看出happen-before强调的是一个现象，C++保证在单线程中happen-before现象是始终成立的，不管后面编译器和CPU如何进行重排。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a, b;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    a = <span class="number">42</span>; <span class="comment">// 1</span></span><br><span class="line">    b = a; <span class="comment">// 2</span></span><br><span class="line">    assert(b == <span class="number">42</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如果A同步发生(synchronizes-with)于B，那么某个线程中A的修改能够被另一个线程中的B观察到。它实际上是建立一种方法，使得一个时间点前内存的变化能够被其他线程看到。我们引用同样的来源的一个例子，由于重排的问题，在下面的代码中语句4的断言不一定成立（我们不考虑x86 CPU的TSO模型）。这就说明<strong>在Relax等无约束或者少约束的内存模型下，在多线程中试图通过某原子量来同步非原子量并不是可靠的</strong>。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> data;</span><br><span class="line"><span class="built_in">std</span>::<span class="keyword">atomic_bool</span> flag &#123; <span class="literal">false</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Execute in thread A</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">producer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    data = <span class="number">42</span>;  <span class="comment">// (1)</span></span><br><span class="line">    flag.store(<span class="literal">true</span>, memory_order_relaxed);  <span class="comment">// (2)</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Execute in thread B</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">consume</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (!flag.load(memory_order_relaxed));  <span class="comment">// (3)</span></span><br><span class="line">    assert(data == <span class="number">42</span>);  <span class="comment">// (4)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="内存一致性模型"><a href="#内存一致性模型" class="headerlink" title="内存一致性模型"></a>内存一致性模型</h3><p>广义上的<a href="https://en.wikipedia.org/wiki/Consistency_model" target="_blank" rel="noopener">一致性模型</a>包括Strict Consistency、Sequential Consistency、Causal Consistency、Processor Consistency、FIFO consistency、Cache Consistency、Slow Consistency、Release consistency、Entry Consistency、General Consistency、Local Consistency等。在<code>std::atomic</code>中提供了六种内存模型(memory order)来描述不同线程之间相同/不同数据的读写的顺序。<br>顺序一致性(sequential consistency, SC)是最强的模型，要求程序中的行为从任意角度来看，序列顺序都是一致的(have single total order)；这是在说这段多线程程序的行为和一段单线程程序的行为是一致的，类似于不是并行的并发。这个模型禁止了任何四种类型的读写重排，因此我们可以认为SC下每次读到的都是最新值。在C++ Concurrency in Action中举了一个例子，使用四个线程运行下面四个函数，断言无论如何<code>z</code>永远不可能为0。这说明了在<code>read_x_then_y</code>和<code>read_y_then_x</code>两个函数至少有一个能看到<code>x</code>和<code>y</code>同时被设为<code>true</code>。容易看出将1/2/3/4任意排序，那么上面的断言是显然的（注意到即使<code>read_x_then_y</code>在<code>write_x</code>前被调用也有while循环兜底）。但是如果<code>(1 -&gt; 3)</code>和<code>(2 -&gt; 4)</code>这两个步骤并行发生的话，上面断言就不成立了。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">bool</span>&gt; x = <span class="literal">false</span>, y = <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; z = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">write_x</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  x.store(<span class="literal">true</span>,<span class="built_in">std</span>::memory_order_seq_cst);  <span class="comment">// 1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">write_y</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  y.store(<span class="literal">true</span>,<span class="built_in">std</span>::memory_order_seq_cst);  <span class="comment">// 2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">read_x_then_y</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(!x.load(<span class="built_in">std</span>::memory_order_seq_cst)); <span class="comment">// a</span></span><br><span class="line">  <span class="keyword">if</span>(y.load(<span class="built_in">std</span>::memory_order_seq_cst))  <span class="comment">// 3</span></span><br><span class="line">    ++z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">read_y_then_x</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(!y.load(<span class="built_in">std</span>::memory_order_seq_cst)); <span class="comment">// b</span></span><br><span class="line">  <span class="keyword">if</span>(x.load(<span class="built_in">std</span>::memory_order_seq_cst))  <span class="comment">// 4</span></span><br><span class="line">    ++z;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>自由模型(Relaxed ordering)是最弱的模型，它对<strong>线程间</strong>的执行顺序不做任何synchronizes-with的假设，但同线程的变量仍然遵循happens-before假设，即它除了禁止重排<strong>单线程</strong>上对<strong>单个变量</strong>的访问顺序，并不作任何额外的事情。下面展示的一个C++11对应的自由模型<code>std::memory_order_relaxed</code>的例子，注意在后面的详述中可以看到，由于特定平台的一致性模型要强于自由模型，所以<code>std::memory_order_relaxed</code>只是保证强于等于自由模型。注意到这时候仍然保证了1先于2、3先于4，且3读到<code>true</code>，但是<code>z</code>就可能为0了。这是由于<code>x</code>和<code>y</code>是两个不同变量，自由模型不关注它们之间的关系。关注一下图5.4，我们发现这张图非常反直觉，例如4步骤还会返回false，这是出于什么机理呢？但是在这之前，先在x86下的MSVC2015上测试一下，发现<code>z</code>始终不为0，这是为什么呢？我在StackOverflow上<a href="https://stackoverflow.com/questions/48139399/memory-order-relaxed-not-work-as-expected-in-code-from-c-concurrency-in-action?noredirect=1#comment83256917_48139399" target="_blank" rel="noopener">提了个问题</a>。回答首先指出<code>std::memory_order_relaxed</code>的副作用实际上是禁止<strong>编译器</strong>（注意区分编译器的重排行为和处理器的乱序行为）重排<code>x</code>和<code>y</code>的Store-Store，但是断言失败还可能由于CPU决定颠倒写<code>x</code>和写<code>y</code>的顺序（虽然一般不会进行这种乱序），或者CPU的缓存导致了<code>x</code>延迟写入内存。回答接着解释了为什么x86上不会assertion fail，这是因为x84提供了acquire/release语义，保证了当3是true时，在2前的对3后的可见。注意到这个并不违反x86对Store-Load可能的乱序，它实际上利用了Store-Store不会乱序的特性。回顾之前的最严格的顺序一致模型，它要求对于每个共享变量，Load-Load、Load-Store、Store-Load、Store-Store都不乱序。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">bool</span>&gt; x = <span class="literal">false</span>, y = <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; z = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">write_x_then_y</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  x.store(<span class="literal">true</span>,<span class="built_in">std</span>::memory_order_relaxed);  <span class="comment">// 1</span></span><br><span class="line">  y.store(<span class="literal">true</span>,<span class="built_in">std</span>::memory_order_relaxed);  <span class="comment">// 2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">read_y_then_x</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(!y.load(<span class="built_in">std</span>::memory_order_relaxed));  <span class="comment">// 3</span></span><br><span class="line">  <span class="keyword">if</span>(x.load(<span class="built_in">std</span>::memory_order_relaxed))  <span class="comment">// 4</span></span><br><span class="line">    ++z;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>acquire/release模型相对灵活一点，也是x86实现的语义。release可以理解为写操作，acquire可以理解为读操作。acquire fence要求其后面的RW不能与其前面的R重排，也就是RW不能重排到（原本在自己前面的）R前，例如<code>R1 W2</code>不能变成<code>W2 R1</code>，否则<code>R1</code>读到的就是脏值的。release fence要求其前面的RW不能和其后面的W重排，也就是RW不能重排到（原本在自己后面的）W后，例如<code>R1 W2</code>不能重排为<code>W2 R1</code>，否则<code>R1</code>又脏读。但是这两个模型即使组合起来也不能禁止其前面的W和后面的R重排。<br>C++11使用剩下四个内存模型常数来实现这一机制，<code>memory_order_release</code>和<code>memory_order_acquire</code>表示B线程在使用<code>memory_order_acquire</code>读时，线程A在<code>memory_order_release</code>前的所有写操作都是可见的。而稍弱一点的<code>memory_order_release</code>和<code>memory_order_consume</code>只用来保证当前操作涉及到的对象的可见性。</p>
<h3 id="Store-Load乱序问题"><a href="#Store-Load乱序问题" class="headerlink" title="Store-Load乱序问题"></a>Store-Load乱序问题</h3><p>在前面的讨论中提到了x86的Store-Load乱序问题，对于x86，Loads May Be Reordered with Earlier Stores to Different Locations，但<a href="https://software.intel.com/en-us/forums/intel-moderncode-for-parallel-architectures/topic/277126" target="_blank" rel="noopener">对于相同地址则不会乱序</a>。<br>在<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/" target="_blank" rel="noopener">这篇博文</a>中记录了一个有关Store-Load乱序的实验。在实验中，X的写操作可能被延迟到Y的读操作之后，尽管我们插入了compiler barrier。这时候我们需要一个full/general memory barrier，也就是实现让它前面所有的Load/Store操作对它后面的Load/Store操作都是可见的，包括了止Store-Load类型的乱序。在同一篇博文中指出可以使用插入一个<code>mfence</code>，以实现full/general memory barrier。<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// gcc</span></span><br><span class="line"><span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">"mfence"</span> ::: <span class="string">"memory"</span>)</span></span></span><br><span class="line"><span class="function"><span class="comment">// c++11</span></span></span><br><span class="line"><span class="function"><span class="comment">// https://stackoverflow.com/questions/25478029/does-atomic-thread-fencememory-order-seq-cst-have-the-semantics-of-a-full-memo</span></span></span><br><span class="line">std::atomic_thread_fence(std::memory_order_seq_cst)</span><br></pre></td></tr></table></figure></p>
<p><a href="https://stackoverflow.com/questions/39053600/does-standard-c11-guarantee-that-memory-order-seq-cst-prevents-storeload-reord?rq=1" target="_blank" rel="noopener">SoF上</a>指出虽然<code>atomic(seq_cst)</code>和<code>atomic(seq_cst)</code>始终不会重排，但是在<code>atomic(seq_cst)</code>附近的<code>non-atomic</code>甚至是<code>atomic(non-seq_cst)</code>形式的<code>STORE-LOAD</code>都会被重排。例如在下面的代码中1和3的<code>STORE-LOAD</code>肯定不会被重排，但2和3的<code>STORE-LOAD</code>就可能被重排，所以一定要注意。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; a, b, c;</span><br><span class="line">a.store(<span class="number">2</span>, <span class="built_in">std</span>::memory_order_seq_cst);          <span class="comment">// 1: movl 2,[a]; mfence;</span></span><br><span class="line">c.store(<span class="number">4</span>, <span class="built_in">std</span>::memory_order_release);          <span class="comment">// 2: movl 4,[c];</span></span><br><span class="line"><span class="keyword">int</span> tmp = b.load(<span class="built_in">std</span>::memory_order_seq_cst);    <span class="comment">// 3: movl [b],[tmp];</span></span><br></pre></td></tr></table></figure></p>
<p>因此在x86上至少要对<code>LOAD</code>/<code>STORE</code>其中的一个加上<code>MFENCE</code>，或者用一个<code>LOCK</code>指令，而这也实现了类似<code>memory_order_seq_cst</code>的效果。在章节内存模型的实现中还有更多说明。<br>下面的代码不一定是等价的<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">atomic&lt;<span class="keyword">int</span>&gt; x, y</span><br><span class="line"></span><br><span class="line">y.store(<span class="number">1</span>, memory_order_relaxed);            <span class="comment">//(1)</span></span><br><span class="line">atomic_thread_fence(memory_order_seq_cst);   <span class="comment">//(2)</span></span><br><span class="line">x.load(memory_order_relaxed);                <span class="comment">//(3)</span></span><br><span class="line"></span><br><span class="line">atomic&lt;<span class="keyword">int</span>&gt; x, y;</span><br><span class="line">y.store(<span class="number">1</span>, memory_order_seq_cst);            <span class="comment">//(1)</span></span><br><span class="line"><span class="comment">// Nothing</span></span><br><span class="line">x.load(memory_order_seq_cst);                <span class="comment">//(3)</span></span><br></pre></td></tr></table></figure></p>
<h3 id="fence"><a href="#fence" class="headerlink" title="fence"></a>fence</h3><p>常见的fence包括thread fence(memory/CPU barrier)和signal fence(compiler barrier)。</p>
<h4 id="signal-fence"><a href="#signal-fence" class="headerlink" title="signal fence"></a>signal fence</h4><p>signal fence类似下面的东西，参考<a href="https://en.wikipedia.org/wiki/Memory_ordering" target="_blank" rel="noopener">Wikipedia</a><br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// gcc</span></span><br><span class="line"><span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">""</span> ::: <span class="string">"memory"</span>)</span></span>;</span><br><span class="line"><span class="comment">// msvc</span></span><br><span class="line">__MACHINE(<span class="keyword">void</span> _ReadWriteBarrier(<span class="keyword">void</span>))</span><br><span class="line"><span class="comment">// c++11</span></span><br><span class="line"><span class="built_in">std</span>::atomic_signal_fence(memory_order_acq_rel)</span><br></pre></td></tr></table></figure></p>
<p>对于gcc版本，<code>asm</code>、<code>volatile</code>、<code>memory</code>三个关键字的作用可以参考<a href="https://stackoverflow.com/questions/14950614/working-of-asm-volatile-memory" target="_blank" rel="noopener">SoF上的回答</a><br>对于MSVC版本，根据<a href="https://msdn.microsoft.com/en-us/library/f20w0x5e.aspx" target="_blank" rel="noopener">MSDN</a>，<code>_ReadWriteBarrier</code>限制了编译器可能的重排。C++11标准库中的<code>std::atomic_signal_fence</code>在MSVC上也是利用Compiler Barrier实现的。<br>一个signal fence的<a href="https://stackoverflow.com/questions/18449291/when-is-a-compiler-only-memory-barrier-such-as-stdatomic-signal-fence-useful" target="_blank" rel="noopener">作用是</a></p>
<ol>
<li>强制单线程和该线程上的异步中断之间的顺序性</li>
<li>强制单核上运行的多线程之间的顺序性<br> 注意到在SMP架构下这一点难以保证，所以对于多线程程序往往需要更强的thread fence。</li>
</ol>
<h4 id="thread-fence"><a href="#thread-fence" class="headerlink" title="thread fence"></a>thread fence</h4><p>thread fence也就是所谓的内存屏障，我们可以使用下面的语句进行声明，此外，我们还可以声明一个单独的Store/Load Barrier。这里补充一下Store Barrier强制所有屏障<strong>前</strong>的store指令，都在屏障指令执行之前被执行，并把store缓冲区的数据都刷到主存。Load Barrier强制所有屏障<strong>后</strong>的load指令，都在屏障指令执行之后被执行，并且一直等到load缓冲区被该CPU读完才能执行之后的load指令。而一个full barrier兼而有之。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// x86</span></span><br><span class="line"><span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">"mfence"</span>:::<span class="string">"memory"</span>)</span></span></span><br><span class="line"><span class="function"><span class="comment">// gcc</span></span></span><br><span class="line"><span class="function">__sync_synchronize</span></span><br><span class="line"><span class="function"><span class="comment">// msvc</span></span></span><br><span class="line"><span class="function"><span class="title">MemoryBarrier</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="comment">// c++11</span></span></span><br><span class="line">std::atomic_thread_fence(memory_order_seq_cst)</span><br><span class="line"><span class="comment">// other methods</span></span><br><span class="line">_mm_mfence</span><br></pre></td></tr></table></figure></p>
<p>我们需要注意的是内存屏障是相当耗时的操作，甚至还要超过原子操作，内存屏障还会干扰CPU的流水线，导致性能的降低。下面我们查看一下标准库<code>atomic_thread_fence</code>函数的实现<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MSVC</span></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span> _Atomic_thread_fence(memory_order _Order)</span><br><span class="line">    &#123;   <span class="comment">/* force memory visibility and inhibit compiler reordering */</span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">if</span> defined(_M_ARM) || defined(_M_ARM64)</span></span><br><span class="line">    <span class="keyword">if</span> (_Order != memory_order_relaxed)</span><br><span class="line">        &#123;</span><br><span class="line">        _Memory_barrier();</span><br><span class="line">        &#125;</span><br><span class="line"> <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    _Compiler_barrier();</span><br><span class="line">    <span class="keyword">if</span> (_Order == memory_order_seq_cst)</span><br><span class="line">        &#123;   <span class="comment">/* force visibility */</span></span><br><span class="line">        <span class="keyword">static</span> _Uint4_t _Guard;</span><br><span class="line">        _Atomic_exchange_4(&amp;_Guard, <span class="number">0</span>, memory_order_seq_cst);</span><br><span class="line">        _Compiler_barrier();</span><br><span class="line">        &#125;</span><br><span class="line"> <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// GCC</span></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span></span><br><span class="line">atomic_thread_fence(memory_order __m) <span class="keyword">noexcept</span></span><br><span class="line">&#123; __atomic_thread_fence(__m); &#125;</span><br></pre></td></tr></table></figure></p>
<p>可以发现由于x86自带的acquire/release语义，除非是最强的<code>memory_order_seq_cst</code>，否则<code>atomic_thread_fence</code>等价于<code>atomic_signal_fence</code>。而<code>memory_order_seq_cst</code>下的thread fence的full barrier实现则比较奇特，仔细查看这个full barrier的实现这里为啥不直接插入一个<code>MemoryBarrier()</code>，而是利用了一个原子操作呢？</p>
<h3 id="内存模型的实现"><a href="#内存模型的实现" class="headerlink" title="内存模型的实现"></a>内存模型的实现</h3><p>六种内存模型通过加入Compiler Barrier和Memory Barrier来实现。<br>在<a href="https://stackoverflow.com/questions/7461484/memory-model-ordering-and-visibility" target="_blank" rel="noopener">SoF中指出</a>acquire/release相当于在relax后面加一道栅栏，即下面的代码是等价的。但如果不显示加入fence的话，编译器可以视情况生成等价的更好的代码。而在x86等强内存模型架构cpu上，也不一定生成fence，例如单独的<code>atomic_thread_fence(memory_order_acquire)</code>就可以简化为nop。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1</span></span><br><span class="line">a.load(memory_order_acquire)</span><br><span class="line"><span class="comment">// 2</span></span><br><span class="line">a.load(memory_order_relaxed)</span><br><span class="line">atomic_thread_fence(memory_order_acquire)</span><br></pre></td></tr></table></figure></p>
<p>而<code>memory_order_seq_cst</code>则需要额外的<code>MFENCE</code>或者<code>LOCK</code>，可参考上节所述。<br><a href="https://stackoverflow.com/questions/42450342/whats-the-difference-between-atomic-store-and-atomic-thread-fence" target="_blank" rel="noopener">下面的代码</a>是等价的<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (var.load(<span class="built_in">std</span>::memory_order_acquire) == <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">    assert(a==<span class="number">123</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (var.load(<span class="built_in">std</span>::memory_order_relaxed) == <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">    assert(a==<span class="number">123</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="使用内存模型解决双重检查锁定模式-DCLP-存在的问题"><a href="#使用内存模型解决双重检查锁定模式-DCLP-存在的问题" class="headerlink" title="使用内存模型解决双重检查锁定模式(DCLP)存在的问题"></a>使用内存模型解决双重检查锁定模式(DCLP)存在的问题</h3><p>在之前的章节中，我们曾经提到过双重检查锁定模式中存在的问题，对此文章<a href="http://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/" target="_blank" rel="noopener">Double-Checked Locking is Fixed In C++11</a>指出我们可以通过适当的内存屏障或者atomic store/load语义来解决。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;Singleton*&gt; Singleton::m_instance;</span><br><span class="line"><span class="built_in">std</span>::mutex Singleton::m_mutex;</span><br><span class="line"></span><br><span class="line">Singleton* Singleton::getInstance() &#123;</span><br><span class="line">    Singleton* tmp = m_instance.load(<span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">    <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">    <span class="keyword">if</span> (tmp == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(m_mutex);</span><br><span class="line">        tmp = m_instance.load(<span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">        <span class="keyword">if</span> (tmp == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            tmp = <span class="keyword">new</span> Singleton;</span><br><span class="line">            <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_release);</span><br><span class="line">            m_instance.store(tmp, <span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> tmp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><img src="/img/bfbc/dclpjj.png" alt=""></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;Singleton*&gt; Singleton::m_instance;</span><br><span class="line"><span class="built_in">std</span>::mutex Singleton::m_mutex;</span><br><span class="line"></span><br><span class="line">Singleton* Singleton::getInstance() &#123;</span><br><span class="line">    Singleton* tmp = m_instance.load();</span><br><span class="line">    <span class="keyword">if</span> (tmp == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(m_mutex);</span><br><span class="line">        tmp = m_instance.load();</span><br><span class="line">        <span class="keyword">if</span> (tmp == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            tmp = <span class="keyword">new</span> Singleton;</span><br><span class="line">            m_instance.store(tmp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> tmp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="无等待"><a href="#无等待" class="headerlink" title="无等待"></a>无等待</h2><p>无等待(Wait-Free)是比锁无关更高层面的并发。无等待指的是程序中的每个线程都可以一直运行下去而不阻塞。</p>
<h1 id="并发编程中数据共享措施"><a href="#并发编程中数据共享措施" class="headerlink" title="并发编程中数据共享措施"></a>并发编程中数据共享措施</h1><p>常见的并发模型有共享变量、Communicating Sequential Process(CSP)、Actor等模型。共享变量最为常见，多个线程通过锁或者原子操作对变量进行有序访问。CSP模型可以参照Go语言中的channel。Actor模型可以参照Mapreduce模型。</p>
<h2 id="condition-variable"><a href="#condition-variable" class="headerlink" title="condition variable"></a>condition variable</h2><p>锁<code>lock_guard</code>和<code>unique_lock</code>能够保证线程之间的互斥访问临界资源，但是不能控制这些访问的先后顺序。自然而然地可以想到可以用锁维护一个共享变量记录状态，以实现线程间同步的措施，例如在生产者/消费者模型中用它来描述产品数量。一个比较naive的方式是轮询(poll)<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> flag;</span><br><span class="line"><span class="built_in">std</span>::mutex m;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">wait_for_flag</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lk(m);</span><br><span class="line">  <span class="keyword">while</span>(!flag)</span><br><span class="line">  &#123;</span><br><span class="line">    lk.unlock();  <span class="comment">// 1 解锁互斥量</span></span><br><span class="line">    <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::milliseconds(<span class="number">100</span>));  <span class="comment">// 2 休眠100ms</span></span><br><span class="line">    lk.lock();   <span class="comment">// 3 再锁互斥量</span></span><br><span class="line">  &#125;</span><br><span class="line">  flag = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>注意这里这里仍然是需要锁的，否则可能两个互相竞争的线程同时获得flag。<br>另一种更好的方法是利用条件变量，条件变量(condition variable)是利用共享的变量进行线程之间同步的一种机制。条件变量维护一个等待列表，相对于前面的轮询，条件变量应用了推的机制，当某一个线程所需要的条件不满足时，它会被阻塞。拥有锁的线程在退出临界区时使用<code>notify_one</code>/<code>notify_all</code>发出信号通知（注意并不是拥有锁才能notify）条件变量，条件变量会唤醒一个/所有正在等待的线程。<br>使用条件变量等待事件通常是类似下面的形式<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">wait_for_event</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; uni_lock(mtx);</span><br><span class="line">    <span class="keyword">while</span> (!condition)</span><br><span class="line">    &#123;</span><br><span class="line">        cv.wait(uni_lock, []()&#123;<span class="keyword">return</span> condition;&#125;); <span class="comment">// wait until condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">signal_event</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; uni_lock(mtx);</span><br><span class="line">    condition = <span class="literal">true</span>;</span><br><span class="line">    cv.notify_one();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">broadcast_event</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; uni_lock(mtx);</span><br><span class="line">    condition = <span class="literal">true</span>;</span><br><span class="line">    cv.notify_all();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>其中<code>cv.wait</code>会将线程挂到等待队列上，然后释放锁，并使用进入睡眠阻塞线程，否则带着锁睡觉会死锁。当<code>cv.wait</code>返回时，它会重新获得锁。特别地，上面wait对应的一系列步骤必须<a href="http://blog.csdn.net/ysu108/article/details/49508205" target="_blank" rel="noopener">要是原子的</a>，否则会造成丢失signal的问题。例如当条件满足<code>!condition</code>时，程序进入<code>cv.wait</code>等待，<code>cv.wait</code>会释放锁并准备进入睡眠，此时一个signal产生了，但是线程却并不能收到这个信号。这一现象广泛出现在使用边缘触发(Edge triggered)机制的程序中，常见的边缘触发还有Linux的信号。相对于水平触发（select/poll等），边缘触发只会唤醒已经等待在wait上的线程，因此可能出现丢失信号的问题，例如当notify操作早于wait操作时，这个notify就会丢失了。注意到上面的实现中，<code>cv.notify_one</code>和<code>cv.notify_all</code>函数始终是出现在修改<code>condition</code><strong>之后</strong>的，这也是为了保证当睡眠线程在收到信号后能够及时观察到条件满足了。<br><a href="http://www.cppblog.com/Solstice/archive/2015/10/30/203094.html" target="_blank" rel="noopener">在陈硕大牛的博客中</a>还指出了更多的例子。例如<a href="https://stackoverflow.com/questions/4544234/calling-pthread-cond-signal-without-locking-mutex" target="_blank" rel="noopener">不为signal部分上锁是错误的</a>，因为可能在wait部分的<code>while</code>循环和<code>pthread_cond_wait</code>函数之间发生修改<code>condition</code>和<code>pthread_cond_signal</code>，这样进入<code>pthread_cond_wait</code>的wait部分代码就会丢失这次的signal。不过即使为signal部分上锁还可能丢失信号。原因是生产者和消费者竞争同一把锁虽然能够保证wait和signal是串行的顺序，但可能整个signal过程都在wait过程前面。<br>使用条件变量时可能发生虚假唤醒(spurious wakeup)的问题，虚假唤醒指的是被wait中阻塞的线程在没有notify的情况下被唤醒，或者一次<code>signal_one</code>唤醒多个线程。虚假唤醒可能发生在多处理器系统和接收Linux信号时，条件变量设计者出于性能因素容忍了虚假唤醒的存在。APUE指出<code>pthread_cond_signal</code>函数可能唤起多个线程。<a href="https://stackoverflow.com/questions/1050592/do-spurious-wakeups-actually-happen" target="_blank" rel="noopener">SoF</a>中指出，当等待队列中的Linux线程收到一个系统信号时，会得到虚假唤醒。在<a href="https://stackoverflow.com/questions/1461913/does-c-sharp-monitor-wait-suffer-from-spurious-wakeups/1461956#1461956" target="_blank" rel="noopener">另一个回答</a>中，Jon Skeet大神指出其深层次原因是没有任何的保障是一个被唤醒(awakened)的线程一定会被调度(scheduled)，很可能当一个等待队列中的线程被唤醒后准备获得锁时，另一个线程已经捷足先登了获得了锁，并且重置了条件<code>condition</code>的值。但注意，即使是虚假唤醒的情况，<code>cv.wait</code>也是<strong>在获得锁之后再返回</strong>，但这时候条件<code>condition</code>可能已经不满足了，这时候就出现了虚假唤醒。解决虚假唤醒的方案很简单，如上文<code>wait_for_event</code>所示，可以将wait包裹在一个while循环里面。在<a href="https://segmentfault.com/q/1010000010421523" target="_blank" rel="noopener">SF</a>上记录了一番实验，强行产生虚假唤醒。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">con_var.notify_one();</span><br><span class="line"><span class="comment">// trigger the spurious wakeup</span></span><br><span class="line">lock.unlock();</span><br><span class="line"><span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">2</span>));</span><br><span class="line">condition = <span class="literal">true</span>;</span><br></pre></td></tr></table></figure></p>
<p>可以发现在notify和unlock两个过程之后的两秒内消费者线程已经被唤醒了，但在拿到锁和条件变量后它发现其实<code>condition</code>值并不为<code>true</code>，这就产生了一次虚假唤醒。<br>在使用<code>notify_all()</code>唤醒时需要注意惊群问题。</p>
<h3 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h3><p>Windows中通过事件的机制类似于条件变量的机制。</p>
<h3 id="信号量的实现"><a href="#信号量的实现" class="headerlink" title="信号量的实现"></a>信号量的实现</h3><h2 id="future"><a href="#future" class="headerlink" title="future"></a>future</h2><p>条件变量的一个重要的应用就是生产者/消费者模型，但对于一些平凡的情况，消费者只等待<strong>一次(one-off)</strong>来自生产者的结果。一个普遍的场景是启动一个计算线程并<strong>异步获取</strong>它的结果，不过<code>std::thread</code>不能直接提供获取返回值的方法，此时可以考虑使用全局变量或者传入指针和回调函数。<br>另一个较为方便的做法是使用<code>std::future</code>来获取异步任务中的结果。从一定意义上讲，future类似于一个callback。C++中提供了<code>std::future</code>和<code>std::shared_future</code>，可以触发一个或多个事件。当多个线程访问<code>std::future</code>时，需要锁来保护线程安全。</p>
<h3 id="async"><a href="#async" class="headerlink" title="async"></a>async</h3><p>如下面代码所示，future常和<code>std::async</code>一并使用，容易看到，它类似于Python中的<code>subprocess.call</code>，是个高层面的封装。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::future&lt;<span class="keyword">int</span>&gt; the_answer = <span class="built_in">std</span>::async(get_integer());</span><br><span class="line">    do_other_stuff();</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span>&lt;&lt; the_answer.get() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里面的<code>std::async</code>用来实现一次异步调用。<code>std::async</code>是一个模板<strong>函数</strong>，它可以接受一个<code>std::launch</code>类型的参数，其中使用<code>std::launch::defered</code>表示异步调用延迟到<code>.wait()</code>或<code>.get()</code>再执行。而<code>std::launch::async</code>表示在一个独立线程中运行。默认是<code>std::launch::defered | std::launch::async</code>表示这两个二选一。<code>std::async</code>能够接受函数指针、函数对象（的左值、右值。引用和<code>std::ref</code>），也能够通过类似<code>std::bind</code>一样的机制以引用、<code>std::ref</code>等方式传入对象的上下文。<br>注意在仅C++11中，future的析构函数可能会<a href="https://stackoverflow.com/questions/18143661/what-is-the-difference-between-packaged-task-and-async" target="_blank" rel="noopener">阻塞线程</a>。</p>
<h3 id="packaged-task"><a href="#packaged-task" class="headerlink" title="packaged_task"></a>packaged_task</h3><p>不同于<code>std::async</code>，<code>std::packaged_task</code>是个函数对象，这个函数对象有点类似<code>std::function</code>（但<code>std::function</code>还能够复制构造），因此<code>std::packaged_task</code>需要手动调用以运行。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::packaged_task&lt;<span class="keyword">int</span>()&gt; task(sleep);</span><br><span class="line"><span class="keyword">auto</span> f = task.get_future();</span><br><span class="line"><span class="comment">// 在主线程中运行</span></span><br><span class="line">task();</span><br><span class="line"><span class="comment">// 启动另一个线程运行，注意只能移动packaged_task</span></span><br><span class="line">std::thread myThread(std::move(task));</span><br><span class="line">f.get();</span><br></pre></td></tr></table></figure></p>
<p>由于<code>std::packaged_task</code>能移动到某个<code>std::thread</code>中，因此适合用来实现线程池，负责打包待计算的任务。<code>std::packaged_task</code>还可以被用来向另一个线程派发任务。</p>
<h3 id="promise"><a href="#promise" class="headerlink" title="promise"></a>promise</h3><p>在上面的两种派发任务-等待获取结果的模型中，我们的主线程是作为等待任务结果的一方，而将执行任务的异步线程则是产生结果的一方。<code>std::future</code>对象<strong>由主线程持有</strong>，主线程会调用<code>std::async</code>或者<code>packaged_task</code>启动一个任务，并且在需要结果时调用<code>f.get()</code>获得异步线程的结果。对于异步线程来说，<strong>自己并不需要额外工作</strong>，正常返回。但是这在promise中就不一样了，在使用promise时，异步线程需要显式向主线程设置值<code>p.set_value()</code>或传递异常<code>p.set_exception()</code>。</p>
<h3 id="future-then"><a href="#future-then" class="headerlink" title="future.then"></a>future.then</h3><p>future.then目前还没有进入C++标准，其风格类似于CPS和Haskell中的Monad，相比先前介绍的三种机制，future.then利用了回调链的机制避免了手动的同步。</p>
<h2 id="co-await、co-yield、co-return"><a href="#co-await、co-yield、co-return" class="headerlink" title="co_await、co_yield、co_return"></a>co_await、co_yield、co_return</h2><p>future.then机制降低了流程操控的复杂度，不过写起来仍然很繁琐，而且存在回调地狱的问题。在链式调用的过程中，整个流程难以在中间直接abort，为此Rust先后提出了<code>try!</code>和<code>?.</code>这样的机制。截至目前这三个函数尚未进入C++标准，但这种由CS流行开来的异步编程范式其实十分优雅，我们将在一个单独的专题进行讨论。</p>
<h1 id="并发编程中的基础架构"><a href="#并发编程中的基础架构" class="headerlink" title="并发编程中的基础架构"></a>并发编程中的基础架构</h1><p>在设计高性能的并发代码时，我们需要注意以下几点：</p>
<ol>
<li>充分利用局部性假设，是同一线程中的数据紧密联系</li>
<li>减少线程上所需的数据量</li>
<li>让不同线程访问不同位置，避免伪共享</li>
</ol>
<h2 id="线程安全的队列"><a href="#线程安全的队列" class="headerlink" title="线程安全的队列"></a>线程安全的队列</h2><h2 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h2><p>一个简单的线程池的实现需要借助一个线程安全队列。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div></div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/img/fkm/wxfk.jpg" alt="Calvin Neo WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/img/fkm/zfbfk.jpg" alt="Calvin Neo Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/C/" rel="tag"># C++</a>
          
            <a href="/tags/并行计算/" rel="tag"># 并行计算</a>
          
            <a href="/tags/多线程/" rel="tag"># 多线程</a>
          
            <a href="/tags/Linux/" rel="tag"># Linux</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/12/05/libutp源码简析/" rel="next" title="libutp源码简析">
                <i class="fa fa-chevron-left"></i> libutp源码简析
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/17/B-tree/" rel="prev" title="B树">
                B树 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/favicon.jpg"
               alt="Calvin Neo" />
          <p class="site-author-name" itemprop="name">Calvin Neo</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">106</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">121</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/CalvinNeo" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/CalvinNeo0" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/1568200035" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://xqq.im/" title="xqq" target="_blank">xqq</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.lovelywen.com/" title="wenwen" target="_blank">wenwen</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://smlight.github.io/blog/" title="zyyyyy" target="_blank">zyyyyy</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#处理器层面的并发"><span class="nav-number">1.</span> <span class="nav-text">处理器层面的并发</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#流水线-pipeline"><span class="nav-number">1.1.</span> <span class="nav-text">流水线(pipeline)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#流水线和吞吐量"><span class="nav-number">1.1.1.</span> <span class="nav-text">流水线和吞吐量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流水线和冒险"><span class="nav-number">1.1.2.</span> <span class="nav-text">流水线和冒险</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#暂停"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">暂停</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#转发"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">转发</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#现代处理器"><span class="nav-number">1.1.3.</span> <span class="nav-text">现代处理器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CPU的缓存和缓存一致性"><span class="nav-number">1.2.</span> <span class="nav-text">CPU的缓存和缓存一致性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#局部性原理"><span class="nav-number">1.2.1.</span> <span class="nav-text">局部性原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存一致性和volatile"><span class="nav-number">1.2.2.</span> <span class="nav-text">缓存一致性和volatile</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存一致性协议"><span class="nav-number">1.2.3.</span> <span class="nav-text">缓存一致性协议</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#伪共享"><span class="nav-number">1.2.4.</span> <span class="nav-text">伪共享</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试缓存大小"><span class="nav-number">1.2.5.</span> <span class="nav-text">测试缓存大小</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#内核层面的并发"><span class="nav-number">2.</span> <span class="nav-text">内核层面的并发</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#中断"><span class="nav-number">2.1.</span> <span class="nav-text">中断</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#软中断和硬中断"><span class="nav-number">2.1.1.</span> <span class="nav-text">软中断和硬中断</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#中断下半部和软中断"><span class="nav-number">2.1.2.</span> <span class="nav-text">中断下半部和软中断</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#调度"><span class="nav-number">2.2.</span> <span class="nav-text">调度</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#任务"><span class="nav-number">2.2.1.</span> <span class="nav-text">任务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内核态和用户态"><span class="nav-number">2.2.2.</span> <span class="nav-text">内核态和用户态</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#抢占式调度"><span class="nav-number">2.2.3.</span> <span class="nav-text">抢占式调度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#可重入函数"><span class="nav-number">2.3.</span> <span class="nav-text">可重入函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#内核向外提供的并发设施"><span class="nav-number">3.</span> <span class="nav-text">内核向外提供的并发设施</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#多进程"><span class="nav-number">3.1.</span> <span class="nav-text">多进程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#进程模型"><span class="nav-number">3.1.1.</span> <span class="nav-text">进程模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#同步与异步"><span class="nav-number">3.1.2.</span> <span class="nav-text">同步与异步</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多线程"><span class="nav-number">3.2.</span> <span class="nav-text">多线程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linux的进程-线程模型"><span class="nav-number">3.3.</span> <span class="nav-text">Linux的进程/线程模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#协程"><span class="nav-number">3.4.</span> <span class="nav-text">协程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#C-下协程的实现方式"><span class="nav-number">3.5.</span> <span class="nav-text">C++下协程的实现方式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基于ucontext"><span class="nav-number">3.5.1.</span> <span class="nav-text">基于ucontext</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#黑科技1"><span class="nav-number">3.5.2.</span> <span class="nav-text">黑科技1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于setjmp和longjmp"><span class="nav-number">3.5.3.</span> <span class="nav-text">基于setjmp和longjmp</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#约束线程间并发行为"><span class="nav-number">4.</span> <span class="nav-text">约束线程间并发行为</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Race-condition"><span class="nav-number">4.1.</span> <span class="nav-text">Race condition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#volatile"><span class="nav-number">4.2.</span> <span class="nav-text">volatile</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#内核锁"><span class="nav-number">4.3.</span> <span class="nav-text">内核锁</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#互斥量"><span class="nav-number">4.3.1.</span> <span class="nav-text">互斥量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#死锁"><span class="nav-number">4.3.2.</span> <span class="nav-text">死锁</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自旋锁"><span class="nav-number">4.4.</span> <span class="nav-text">自旋锁</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#自旋锁与中断处理"><span class="nav-number">4.4.1.</span> <span class="nav-text">自旋锁与中断处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#持有自旋锁时不能进入睡眠"><span class="nav-number">4.4.2.</span> <span class="nav-text">持有自旋锁时不能进入睡眠</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#临界区"><span class="nav-number">4.5.</span> <span class="nav-text">临界区</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#临界资源的初始化"><span class="nav-number">4.5.1.</span> <span class="nav-text">临界资源的初始化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#读写锁"><span class="nav-number">4.6.</span> <span class="nav-text">读写锁</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#不变量与恶性条件竞争"><span class="nav-number">4.7.</span> <span class="nav-text">不变量与恶性条件竞争</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#锁无关"><span class="nav-number">4.8.</span> <span class="nav-text">锁无关</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原子操作"><span class="nav-number">4.8.1.</span> <span class="nav-text">原子操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#互锁访问函数和CAS操作"><span class="nav-number">4.8.2.</span> <span class="nav-text">互锁访问函数和CAS操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用CAS操作实现的并发缓冲队列"><span class="nav-number">4.8.3.</span> <span class="nav-text">使用CAS操作实现的并发缓冲队列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU提供的原子操作"><span class="nav-number">4.8.4.</span> <span class="nav-text">CPU提供的原子操作</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#C-的原子操作库"><span class="nav-number">4.9.</span> <span class="nav-text">C++的原子操作库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#std-atomic-flag"><span class="nav-number">4.9.1.</span> <span class="nav-text">std::atomic_flag</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#std-atomic"><span class="nav-number">4.9.2.</span> <span class="nav-text">std::atomic</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#weak和strong版本的CAS"><span class="nav-number">4.9.3.</span> <span class="nav-text">weak和strong版本的CAS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ABA问题"><span class="nav-number">4.9.4.</span> <span class="nav-text">ABA问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#原子操作与锁的关系"><span class="nav-number">4.9.5.</span> <span class="nav-text">原子操作与锁的关系</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他的同步原语"><span class="nav-number">4.10.</span> <span class="nav-text">其他的同步原语</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hazard-Pointer"><span class="nav-number">4.10.1.</span> <span class="nav-text">Hazard Pointer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RCU"><span class="nav-number">4.10.2.</span> <span class="nav-text">RCU</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#通过内存模型约束线程对变量的读写顺序"><span class="nav-number">4.11.</span> <span class="nav-text">通过内存模型约束线程对变量的读写顺序</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原子操作的线程间顺序"><span class="nav-number">4.11.1.</span> <span class="nav-text">原子操作的线程间顺序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#可见性和有序性"><span class="nav-number">4.11.2.</span> <span class="nav-text">可见性和有序性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内存一致性模型"><span class="nav-number">4.11.3.</span> <span class="nav-text">内存一致性模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Store-Load乱序问题"><span class="nav-number">4.11.4.</span> <span class="nav-text">Store-Load乱序问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fence"><span class="nav-number">4.11.5.</span> <span class="nav-text">fence</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#signal-fence"><span class="nav-number">4.11.5.1.</span> <span class="nav-text">signal fence</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#thread-fence"><span class="nav-number">4.11.5.2.</span> <span class="nav-text">thread fence</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内存模型的实现"><span class="nav-number">4.11.6.</span> <span class="nav-text">内存模型的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用内存模型解决双重检查锁定模式-DCLP-存在的问题"><span class="nav-number">4.11.7.</span> <span class="nav-text">使用内存模型解决双重检查锁定模式(DCLP)存在的问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#无等待"><span class="nav-number">4.12.</span> <span class="nav-text">无等待</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#并发编程中数据共享措施"><span class="nav-number">5.</span> <span class="nav-text">并发编程中数据共享措施</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#condition-variable"><span class="nav-number">5.1.</span> <span class="nav-text">condition variable</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#事件"><span class="nav-number">5.1.1.</span> <span class="nav-text">事件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#信号量的实现"><span class="nav-number">5.1.2.</span> <span class="nav-text">信号量的实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#future"><span class="nav-number">5.2.</span> <span class="nav-text">future</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#async"><span class="nav-number">5.2.1.</span> <span class="nav-text">async</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#packaged-task"><span class="nav-number">5.2.2.</span> <span class="nav-text">packaged_task</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#promise"><span class="nav-number">5.2.3.</span> <span class="nav-text">promise</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#future-then"><span class="nav-number">5.2.4.</span> <span class="nav-text">future.then</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#co-await、co-yield、co-return"><span class="nav-number">5.3.</span> <span class="nav-text">co_await、co_yield、co_return</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#并发编程中的基础架构"><span class="nav-number">6.</span> <span class="nav-text">并发编程中的基础架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#线程安全的队列"><span class="nav-number">6.1.</span> <span class="nav-text">线程安全的队列</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线程池"><span class="nav-number">6.2.</span> <span class="nav-text">线程池</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Calvin Neo</span>
  <span> &nbsp; Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a></span>
</div>
<div>
  <span><a href="/about/yytl/">版权声明</a></span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse 
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://calvinneo.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://www.calvinneo.com/2017/12/28/Concurrency-Programming-Compare/';
          this.page.identifier = '2017/12/28/Concurrency-Programming-Compare/';
          this.page.title = '并发编程重要概念及比较';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://calvinneo.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  








  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      $('#local-search-input').focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

</body>
</html>
