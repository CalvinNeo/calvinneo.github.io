<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="分布式,paxos,raft,一致性," />





  <link rel="alternate" href="/atom.xml" title="Calvin's Marbles" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="分布式系统中常出现以下的一些应用场景：分布式锁、负载均衡、发布订阅模型、选举、分布式队列。为了提高在这些场景下的高可用或者容错特性，常常采用维护多个冗余副本的办法来实现，因此需要维护这些副本之间的一致性。 相比单机，分布式集群搭建在网络上，而网络通信是复杂的，数据包的丢失、重复、乱序需要被妥善处理，此外节点宕机或者网络分区的情况也需要被考虑。事实上，CAP理论认为一致性C、可用性A和分区容错P不可">
<meta name="keywords" content="分布式,paxos,raft,一致性">
<meta property="og:type" content="article">
<meta property="og:title" content="分布式一致性和分布式共识协议">
<meta property="og:url" content="http://www.calvinneo.com/2017/09/20/distributed-system-consistency-and-consensus/index.html">
<meta property="og:site_name" content="Calvin&#39;s Marbles">
<meta property="og:description" content="分布式系统中常出现以下的一些应用场景：分布式锁、负载均衡、发布订阅模型、选举、分布式队列。为了提高在这些场景下的高可用或者容错特性，常常采用维护多个冗余副本的办法来实现，因此需要维护这些副本之间的一致性。 相比单机，分布式集群搭建在网络上，而网络通信是复杂的，数据包的丢失、重复、乱序需要被妥善处理，此外节点宕机或者网络分区的情况也需要被考虑。事实上，CAP理论认为一致性C、可用性A和分区容错P不可">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://i.imgur.com/bbWksIz.jpg">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210223153842194.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/db-midware.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/replicate_sync_async.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/57.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/yzxdj.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/lin.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/read-after-write.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/mono-read.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/lamport_clock_counter.jpg">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/lamportclock.jpg">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/lamport_clock_prove.jpg">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/lamport_clock_drawback.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/vectorclock_prove.jpg">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/vectorclock_prove2.jpg">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/fifob.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/causalb.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/totorderb.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/fifob_a.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/causalb_a.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/flpf2.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/flpf3.png">
<meta property="og:image" content="http://www.calvinneo.com/img/fbs/fzztj.jpg">
<meta property="og:updated_time" content="2021-11-04T15:09:24.359Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="分布式一致性和分布式共识协议">
<meta name="twitter:description" content="分布式系统中常出现以下的一些应用场景：分布式锁、负载均衡、发布订阅模型、选举、分布式队列。为了提高在这些场景下的高可用或者容错特性，常常采用维护多个冗余副本的办法来实现，因此需要维护这些副本之间的一致性。 相比单机，分布式集群搭建在网络上，而网络通信是复杂的，数据包的丢失、重复、乱序需要被妥善处理，此外节点宕机或者网络分区的情况也需要被考虑。事实上，CAP理论认为一致性C、可用性A和分区容错P不可">
<meta name="twitter:image" content="https://i.imgur.com/bbWksIz.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.calvinneo.com/2017/09/20/distributed-system-consistency-and-consensus/"/>





  <title>分布式一致性和分布式共识协议 | Calvin's Marbles</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Calvin's Marbles</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.calvinneo.com/2017/09/20/distributed-system-consistency-and-consensus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Calvin Neo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Calvin's Marbles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                分布式一致性和分布式共识协议
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-09-20T12:33:22+08:00">
                2017-09-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>分布式系统中常出现以下的一些应用场景：分布式锁、负载均衡、发布订阅模型、选举、分布式队列。为了提高在这些场景下的高可用或者容错特性，常常采用维护多个冗余副本的办法来实现，因此需要维护这些副本之间的一致性。</p>
<p>相比单机，分布式集群搭建在网络上，而网络通信是复杂的，数据包的丢失、重复、乱序需要被妥善处理，此外节点宕机或者网络分区的情况也需要被考虑。事实上，CAP理论认为一致性C、可用性A和分区容错P不可能同时做到。因此如何在分布式系统下实现事务是一个有趣的课题。</p>
<p>本篇文章以DDIA以及作者的讲解视频为骨架，辅以业界的相关实现，来综述性探讨上述的一些问题。</p>
<a id="more"></a>

<h1 id="分布式系统的相关性能要求"><a href="#分布式系统的相关性能要求" class="headerlink" title="分布式系统的相关性能要求"></a>分布式系统的相关性能要求</h1><h2 id="可用性和可靠性"><a href="#可用性和可靠性" class="headerlink" title="可用性和可靠性"></a>可用性和可靠性</h2><p>可用性(availability)需要系统在任何给定的时刻都能够正确工作。可靠性(reliability)需要系统可以无故障地持续运行。这两者的区别是可靠性强调的是较少的崩溃次数，而可用性指的是较长的服务时长。<a href="http://wrran.com/blog/2017/12/28/review/distributed-system/8-fault-tolerance/" target="_blank" rel="noopener">例如</a>，系统A可以运行一年，但每隔一个月会崩溃一次，并花费1s恢复；系统B无崩溃工作一年，但需要每年停机维护2小时。那么系统A的可用性会强一点，但系统B的可靠性会强一点。</p>
<p>而根据《InnoDB存储引擎卷1》 P274页的论述，可靠性强调系统本身的能力，而不考虑在遇到不确定的环境因素，例如地震海啸破坏硬盘等情况导致的问题。</p>
<h3 id="高可用性HA与容错FT"><a href="#高可用性HA与容错FT" class="headerlink" title="高可用性HA与容错FT"></a>高可用性HA与容错FT</h3><p>根据DDIA，首先应当区分fault和failure，故障Fault通常定义为系统的一部分状态偏离其标准，而失效Failure则是系统作为一个整体停止向用户提供服务。能预料并应对故障的系统特性可称为容错(fault-tolerant)或韧性(resilient)。<br>单点(Single  point of failure, SPOF)表示因为某个fault(比如网络或者节点的)导致的failure。而FT即Fault Tolerant，表示在一定fault规模下，系统还能够持续运行，而不failure。</p>
<p>从定义上来看，<a href="https://www.ibm.com/support/knowledgecenter/en/SSPHQG_7.2/concept/ha_concepts_fault.htm" target="_blank" rel="noopener">Fault tolerant的系统不允许服务中断(service interruption)，但其开销较高；High availability的系统追求最小的服务中断</a>。</p>
<p>衡量容错能力通常可以通过MTBF、MTTR、MTTF等指标，分别表示开始工作到第一个故障的时间的平均值，平均修复时间和平均失效时间。</p>
<h3 id="Failure-detector"><a href="#Failure-detector" class="headerlink" title="Failure detector"></a>Failure detector</h3><p>Failure detector检查节点是否失效。<br>Perfect Failure detector会在当且仅当一个节点失效的时候标记它是失效的。</p>
<ol>
<li>通常实现<br> 发消息等待超时。对crash stop和crash recovery是有效的。<br> 无法区分无响应、丢包和延迟消息。</li>
<li>Eventuall perfect failure detector</li>
</ol>
<h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><p>安全性强调的是在故障的情况下系统能够正确操作而不造成灾难。</p>
<h2 id="可维护性"><a href="#可维护性" class="headerlink" title="可维护性"></a>可维护性</h2><p>可维护性描述发生发生故障的系统被恢复的难易程度。</p>
<h1 id="分布式系统模型"><a href="#分布式系统模型" class="headerlink" title="分布式系统模型"></a>分布式系统模型</h1><h2 id="网络行为假设"><a href="#网络行为假设" class="headerlink" title="网络行为假设"></a>网络行为假设</h2><ol>
<li>Reliable<br> 如果消息被发送，那么就会被收到。<br> 但是，信息可能是被乱序收到的。<br> 我们将在后面对广播和全序广播的讨论中继续看到Reliable的链接。</li>
<li>Fair loss<br> 消息可能丢失、重复、乱序。但如果不断重试，消息最终会被送达。</li>
<li>Arbitrary(active adversary)<br> 消息可能会被损坏</li>
</ol>
<h2 id="节点行为假设"><a href="#节点行为假设" class="headerlink" title="节点行为假设"></a>节点行为假设</h2><ol>
<li>Crash(Fail) stop<br> 当节点crash后，就会永远停止运行</li>
<li>Crash(Fail) recovery<br> 当节点crash后，可能在某个时刻恢复</li>
<li>Byzantine</li>
</ol>
<h2 id="同步假设"><a href="#同步假设" class="headerlink" title="同步假设"></a>同步假设</h2><ol>
<li>同步<br> 消息延迟不会高于某个上限。</li>
<li>部分同步<br> 在某些有限时间段中，系统是异步的。</li>
<li>异步<br> 所有信息可以被任意地延迟，各个节点可以任意地停止工作。</li>
</ol>
<h1 id="分布式系统上的数据存储"><a href="#分布式系统上的数据存储" class="headerlink" title="分布式系统上的数据存储"></a>分布式系统上的数据存储</h1><p>分布式存储架构的演变主要源于三点需求：扩大数据在地理上的分布范围从而<strong>减少延迟(latency)<strong>，为系统提供容错/高可用性从而</strong>提高可用性</strong>，通过将请求负载均衡到各个机器上以提高**伸缩性(Scalability)**（例如读写分离）。</p>
<p>在高并发的场景下，我们对服务器和数据库性能的扩展方案可以分为两种思路水平扩展(horizontal scaling, scale out)和垂直扩展(vertical scaling, scale up)。在这两种思路的领导下有三种方案，即共享内存(shared-memory)、共享磁盘(shared-disk)和无共享(share-nothing)。</p>
<h2 id="复制-replicate"><a href="#复制-replicate" class="headerlink" title="复制(replicate)"></a>复制(replicate)</h2><p>复制(replicate)，指通过网络连接的多台机器上保留相同数据的副本(replica)。复制可以是single leader的、multi leader的或者leaderless。</p>
<h3 id="一个最原始的系统"><a href="#一个最原始的系统" class="headerlink" title="一个最原始的系统"></a>一个最原始的系统</h3><p>为了理解复制的作用，我们首先引入一个最原始的系统。它通常是单服务器单库的架构。但它显然不能应付高并发的场景，因此需要<a href="https://www.cnblogs.com/chanshuyi/p/mycat_enlighten.html" target="_blank" rel="noopener">逐步进行升级</a>。<br>首先我们可以对服务器进行集群化和负载均衡。这个并不难，因为用户的请求从接入层打过来，通常已经经过了一系列路由、鉴权、限流、降级、LB等过程。在业务层通常就是去处理每一个请求，其中涉及到与各种中间件和数据库交互，比如ES、Redis、MySQL、Kafka、ZK、ETCD等等。对于这些场景，因此对业务层动态扩容并不是很麻烦。<br>但是业务虽然扩容了，所有的请求还是打到同一个数据库上，数据库成为瓶颈。当然我们可以在业务侧做些聚合啥的，但这不是一个通用的方案。我们在服务器和数据库之间加上一层缓存。鲁迅说过，计算机科学领域的任何问题都可以通过增加一个间接的中间层解决。缓存的加入是为了减少数据库的压力，但显而易见的，和CPU一样，如果我们双写缓存和数据库，那么就一定需要解决一致性问题。比如我们先写库，再删缓存(Cache Aside Pattern)，那么在这一段时间中缓存就是脏的；又比如我们先删缓存再写库，那么只要这个操作不是原子的（绝大多数情况下就不是原子的），那么就可能中间有个读线程在读库的时候再重新写一遍旧数据到缓存中。我们有一些方案能够尽可能处理缓存和数据库一致的问题——再不济我们按照分布式事务提交的方式（例如在MySQL里面就用2PC来处理binlog和redolog的一致性），或者借助于<a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md" target="_blank" rel="noopener">一个队列维护</a>。<br>随着数据库压力的进一步增大，我们使用主从架构。对于更大并发的要求，我们还可以采用分区的方案。这些是和数据库实现直接相关的，也是我们主要论述的部分。</p>
<h3 id="主动复制和被动复制"><a href="#主动复制和被动复制" class="headerlink" title="主动复制和被动复制"></a>主动复制和被动复制</h3><p>primary-backup system的代表是zab协议。state machine replication的代表是paxos协议。<br><img src="https://i.imgur.com/bbWksIz.jpg"></p>
<p>这里引用<a href="http://baotiao.github.io/2017/11/08/state-machine-vs-primary-backup/" target="_blank" rel="noopener">Vive La Différence: Paxos vs. Viewstamped Replication vs. Zab</a>的观点。state machine replication 也称作active replication，而primary-backup system(主从复制)也称作passive replication。SMR上每个节点维护一个确定状态机，彼此一致性协议来返回给client。primary-backup system中，<a href="https://blog.csdn.net/weixin_43705457/article/details/113994669" target="_blank" rel="noopener">只有primary维护确定性状态机</a>，然后通过一致性协议备份到backup。</p>
<p><img src="https://img-blog.csdnimg.cn/20210223153842194.png"></p>
<p>SMR和primary-backup的区别还体现在，SMR更讲究“过程”：</p>
<ol>
<li>例如<code>x=1</code>和<code>x=2</code>这两个操作，primary-backup只需要复制一个最终的<code>x=2</code>即可，但是SMR需要两条日志表示过程；</li>
<li>因为SMR要在所有的机器上apply过程，所以不支持诸如随机、时间相关的操作。</li>
</ol>
<h3 id="Single-Leader架构（主从复制）"><a href="#Single-Leader架构（主从复制）" class="headerlink" title="Single Leader架构（主从复制）"></a>Single Leader架构（主从复制）</h3><p>最常用的是leader-based replication，又称为active/passive或者主从(master/slave)架构，由一个Leader(Master/Primary)负责协调多个Follower(Read replica, Slave, Sencondary)。主从架构是一个HA解决方案，能实现<strong>读写分离</strong>，从而提高读写效率。主从方案可以通过MySQL Proxy等机制实现，阿里巴巴有一个Canal的数据库中间件，能够实现数据库的增量订阅和消费业务。</p>
<p>主从数据库可以互为热(hot)/温(warm)备份(standby)：</p>
<ol>
<li>冷备<br> 这个备份节点平时不启用</li>
<li>温备<br> 只Follow来自Leader的更新，但是不Serve客户端的请求</li>
<li>热备<br> 可以Serve客户端的读（也许还有写）请求</li>
</ol>
<p>需要分清楚主备和主从的概念。主备的备，并不会去服务。主从的从，会提供读服务。</p>
<p>主从架构下，通常会涉及到下面几种中间件</p>
<p><img src="/img/fbs/db-midware.png"></p>
<p>增加新Follower：</p>
<ol>
<li>获取主库的一致性快照</li>
<li>将快照复制到从库</li>
<li>从库连接主库，并拉取快照之后发生的所有数据库变更</li>
<li>从库现在已经caught up主库，可以进行正常的主从复制了</li>
</ol>
<p>主库宕机后的FailOver：</p>
<ol>
<li>确认主库宕机<br> 一般可以基于timeout来判断。</li>
<li>选择一个新的从库<br> 通常是一个共识问题。</li>
<li>重新配置系统<br> 例如重新路由客户端的请求，确保老领导在分区或者重启后Step down。</li>
</ol>
<p>FailOver可能出现的问题：</p>
<ol>
<li>在异步复制情况下，新主可能没有老主宕机前最后的写入数据。特别地，当老主重新加入集群后，新主可能会收到冲突的写入，如果此时丢弃老主未复制的写入，就可能破坏持久性</li>
<li>如果数据库需要和其他外部存储协调，丢弃写入内容会很危险</li>
<li>脑裂，即有两个节点都认为自己是主</li>
<li>如何确定一个合理的超时时间<br> 考虑到临时负载的峰值可能导致节点响应超时，或者网络拥塞可能导致数据报延迟，但这些都不是主节点宕机的情况。如果此时发生FailOver，可能会加剧系统的压力。</li>
</ol>
<h4 id="Push和Pull"><a href="#Push和Pull" class="headerlink" title="Push和Pull"></a>Push和Pull</h4><p>Pull模式，一般发生在Slave长时间不和Master同步的场景下。例如Slave重启了，那么此时只有Slave知道什么时候能够重新同步，所以通过Slave来拉取增量是最合适的。</p>
<p>Push模式，一般发生在Master产生数据时。此时只能通过主动propagate的方式通知Slave。</p>
<h4 id="处理集群成员变更"><a href="#处理集群成员变更" class="headerlink" title="处理集群成员变更"></a>处理集群成员变更</h4><h4 id="处理宕机"><a href="#处理宕机" class="headerlink" title="处理宕机"></a>处理宕机</h4><p>在主从架构下的从节点宕机的处理采取简单的catch up recovery。</p>
<p>我们讨论主节点的故障的处理方式，即故障切换(failover)。Failover主要涉及确认Leader失败、选举新Leader和重新配置系统三个主要步骤。对于确认Leader失败步骤，我们应当审慎地选取一个Timeout时间，因为Leader的超时可能是由于网络负载导致的，此时如果我们认为Leader宕机而开始选举会导致网络负载进一步恶化。对于选举步骤，我们需要在剩余的节点中决议出一个拥有旧Leader中最新数据副本的Follower以期最小化数据损失，一般通过共识协议解决。</p>
<p>对于集群成员变更，我们需要处理新Leader选出后老Leader重新连接的情况。一方面这可能导致脑裂(split brain)，即新老Leader同时接受来自客户端的写请求，从而导致冲突。错误地解决脑裂问题可能导致新老Leader都被关闭，从而导致集群无主的现象。另一方面，在异步复制的环境下，新Leader可能没收到老Leader宕机前的写入操作，此时这部分的写入可能被丢弃掉，从而影响到持久性。</p>
<h4 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h4><p>Leader节点负责将日复制到Follower节点上。日志复制有如下的几种形式：</p>
<ol>
<li>基于语句<br> 这种模式下，主库直接记录下每个写入请求如INSERT等，并转发给从库。这种方式存在一些弊端，例如SQL语句中可能存在随机函数或者时间函数导致每个库上的执行结果不一致，或者数据库中使用了AUTO INCR等语句时，对每个副本上语句的执行顺序也有要求。</li>
<li>基于WAL<br> 无论是为存储日志结构的LSM树还是覆写单个磁盘块的B树，其修改都涉及预写式日志WAL。在这些情况下日志是包含所有写入的仅追加序列，因此通过相同的日志可以在另一个节点上构建相同的副本。<br> 缺点是WAL的信息和数据库的底层存储紧密耦合，这使得更改底层存储格式变得困难。例如通常不可能在Leader和Follower上运行不同版本的数据库。</li>
<li>逻辑日志复制/基于行的日志复制</li>
<li>基于触发器的复制</li>
</ol>
<h4 id="同步复制和异步复制"><a href="#同步复制和异步复制" class="headerlink" title="同步复制和异步复制"></a>同步复制和异步复制</h4><p>日志复制需要确认么？<br>在强一致场景下，是需要确认的。事实上，有三种方式：</p>
<ol>
<li>异步复制<br> MySQL的默认复制方式。Master在执行完事务之后立即返回。容易发现，如果此时Master宕掉了，已提交的事务并不会传到Slave上，此时如果promote这个Slave，则会丢失修改。</li>
<li>半同步复制<br> 对MySQL而言，要求至少一个Slave收到，并且Flush binlog到Relay log。开销至少是一个额外的rtt。</li>
<li>全同步复制<br> 对MySQL而言，要求所有的Slave都提交完事务才返回。</li>
</ol>
<p>异步复制在性能上是美好的，<a href="http://www.voidcn.com/article/p-sfcgwsjt-zg.html" target="_blank" rel="noopener">具有高吞吐量和低延迟</a>，但是在一致性和持久性上会打折扣，每个节点上的数据可能是不一样的，并且主库已经向客户端确认的写入可能会丢失。异步复制的一个典型是Redis的哨兵机制。同步复制的情况下一旦一个从库失去响应，就会阻塞所有写入操作。在下图中，Follower1是同步的，Follower2是异步的。通常情况下的同步复制指的是半同步(semi-synchronous)，即设置一个Follower为同步的，其余的为异步的。</p>
<p><img src="/img/fbs/replicate_sync_async.png"></p>
<h4 id="一致性问题"><a href="#一致性问题" class="headerlink" title="一致性问题"></a>一致性问题</h4><p>日志复制的不同实现方式可能产生一致性问题。例如在读写分离的架构下，同步复制对可用性的损害是很大的，但如果采用异步复制的方式，在从库落后的情况下，同时对主库和从库的查询可能产生不同的结果，从而产生一致性问题。主从复制的架构是最终一致的(eventually consistency)，也就是在副本之间实现同步间存在不一致窗口，称为复制延迟(replication lag)。复制延迟的持续时间是不确定的。</p>
<p>从CAP的观点来看，主从复制实际上是在最大可用(Max Availability)和最大保护(Max Protect)之间的一个trade-off，其核心原因是网络分区和宕机是不可避免的。如果我们允许主从节点在某个Slave宕机到恢复的时间段内继续服务，那么我们就必然要为不一致窗口付出代价。如果我们不容许一致性受到损害，那么就必然要等到这个Slave恢复或者超时并切换到备用机之后。<strong>哪怕只有一个机器宕机</strong>，这段时间内的可用性也无法保证。</p>
<p>但这个是不符合常识的，比如说我想知道我们班新的班长是谁，我首先找室友问，发现室友出去和女朋友High了，或者室友给了我一个错误的答案，难道我就不能真正知道班长是谁了么？事实上我只要问足够多的人就行。例如如果每个人都是言行一致的话，那么过半数人认为的班长就是班长了。这个原理，就对应到Lamport提出的基于复制自动机的分布式集群，它使用共识算法来维护一致性，能够承受不多于半数的节点失效。</p>
<h3 id="Multi-Leader架构"><a href="#Multi-Leader架构" class="headerlink" title="Multi Leader架构"></a>Multi Leader架构</h3><p>多主复制：<br>单主复制，或者说传统的主从架构，基于单个领导的复制存在缺点。也就是说所有的写入只能通过一个主库，所以可用性会很差。</p>
<p>多主复制的一个问题是当两个主库同时对同一个记录进行更新时如何处理写入冲突。一个典型的冲突如DDIA的5-7所示，原值为A，但两个用户1和2分别想把它改成B或者C。</p>
<p><img src="/img/fbs/57.png"></p>
<p>如果我们试图将冲突检测提前到记录更新时，会导致各个主节点之间的同步开销，多主复制的优势不复存在。有下面的解决方案：</p>
<ol>
<li><p>避免冲突<br> 由应用程序保证特定记录的所有写入都通过同一个Leader，那么冲突就不会发生。<br> 需要处理某个特定主库故障，从而要迁移这个主库对应的写请求到其他主库的情况。</p>
</li>
<li><p>冲突合并<br> 对于单主数据库而言，可以采用LWW策略，即如果同一个字段有多个更新，则最后一个写操作将确定该字段的最终值。<br> 但对多主配置中，写入顺序没有定义，所以最终值应该是什么并不清楚。在DDIA的图5-7中，在主库1中标题首先更新为B而后更新为C；在主库2中，首先更新为C，然后更新为B。两个顺序都不是“更正确”的。<br> 如果每个副本只是按照它看到写入的顺序写入，那么数据库最终将处于不一致的状态：最终值将是在主库1的C和主库2的B。这是不可接受的，每个复制方案都必须确保数据在所有副本中最终都是相同的。因此，数据库必须以一种收敛(convergent)的方式解决冲突，这意味着所有副本必须在所有变更复制完成时收敛至一个相同的最终值。</p>
<p> 实现冲突合并解决有多种途径：</p>
<ol>
<li>给每个写入一个唯一的ID<br> 这个ID可以是时间戳、长的随机数、UUID、键和值的哈希。<br> 挑选最高ID的写入作为胜利者，并丢弃其他写入。<br> 如果使用时间戳，这种技术被称为最后写入胜利(LWW, last write wins)。<br> 很容易造成数据丢失。</li>
<li>为每个副本分配一个唯一的ID<br> ID编号更高的写入具有更高的优先级。这种方法也意味着数据丢失。</li>
<li>以某种方式将这些值合并在一起<br> 例如，按字母顺序排序，然后连接它们（DDIA的图5-7中，合并的标题可能类似于“B/C”）。</li>
<li>在保留所有信息的显式数据结构中记录冲突<br> 并编写解决冲突的应用程序代码（也许通过提示用户的方式）。<br> 我理解就是由应用层解决这个冲突。</li>
</ol>
</li>
</ol>
<h3 id="Leaderless架构"><a href="#Leaderless架构" class="headerlink" title="Leaderless架构"></a>Leaderless架构</h3><h3 id="链式复制"><a href="#链式复制" class="headerlink" title="链式复制"></a>链式复制</h3><p>链式复制的概念主要来自于<a href="https://www.cs.cornell.edu/home/rvr/papers/OSDI04.pdf" target="_blank" rel="noopener">Chain Replication for Supporting High Throughput and Availability</a>这一篇论文。</p>
<p>链式复制总是从头写，从尾读。当尾节点写成功了，头节点才会返回Committed。</p>
<p>但实际上，可以从任何节点开始读。此时，我们就可以引入MVCC这个解决读写冲突的神器了。当读取某个节点，发现存在多个版本的数据时，需要先去尾节点查询当前数据的最新版本。<br>每个节点收到下一个结点的ACK时，就可以删除旧版本的数据了。</p>
<p>相对于主从：</p>
<ol>
<li>减少了Master的replication的负担<br> 因为Master只要往后面一个节点复制了</li>
<li>可能不需要借助于分布式共识了</li>
<li>相对于主从要慢，应为replication不能是并行的<br> 对此可以采用pipeline或者<a href="https://datatracker.ietf.org/doc/html/rfc1546" target="_blank" rel="noopener">Multicast</a>之类的配置。</li>
</ol>
<h3 id="级联复制"><a href="#级联复制" class="headerlink" title="级联复制"></a>级联复制</h3><p>级联复制模式下，部分Slave的数据同步不连接Master，而是连接Slave。</p>
<h2 id="partition"><a href="#partition" class="headerlink" title="partition"></a>partition</h2><h3 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h3><h4 id="雪崩问题"><a href="#雪崩问题" class="headerlink" title="雪崩问题"></a>雪崩问题</h4><p>令环<code>A -&gt; B -&gt; C -&gt; D</code>，如果A崩溃了，会导致数据从A往B迁移，这几乎导致B必然崩溃。<br>为了解决以上的雪崩问题，可以引入<strong>虚拟节点</strong>的方案。</p>
<h2 id="分布式集群"><a href="#分布式集群" class="headerlink" title="分布式集群"></a>分布式集群</h2><p>分布式集群相比主从架构提供了更好的冗余方式，集群可以管理超过两个节点，并且所有节点都是对等的，称为replica，这些replica可以（并且应当）在空间位置上广泛分布，并且具有负载均衡的能力。而主从数据库一般将一主n从整体<a href="http://duqingfeng.net/2018/06/12/%E5%93%88%E5%B8%8C%E5%88%86%E5%8C%BA%E6%8A%80%E6%9C%AF%E4%B9%8B%E9%97%B4%E7%9A%84%E5%AF%B9%E6%AF%94%EF%BC%88%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E3%80%81Redis%20cluster%E8%99%9A%E6%8B%9F%E6%A7%BD%EF%BC%89/" target="_blank" rel="noopener">视为一个节点</a>，并不适用分库分表。</p>
<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>我们基于上一章来扩展讨论一下缓存相关的问题，主要以Redis为主。</p>
<h3 id="缓存双写"><a href="#缓存双写" class="headerlink" title="缓存双写"></a>缓存双写</h3><p>最经典的缓存数据库双写模式是Cache Aside Pattern，也就是先更新库，再<strong>删除</strong>缓存，与之配合的是先读缓存，如果缓存没有的话就读库，顺便更新缓存。为什么选择删除缓存，而不是更新缓存的<a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md" target="_blank" rel="noopener">原因</a>是更新缓存的代价比较大，例如缓存中有数据库里面<code>a</code>和<code>b</code>两个字段的缓存，还有一个缓存<code>c</code>是由一个复杂的函数<code>func(a, 6b)</code>计算得到的，那么单独更新<code>a</code>之后，还需要重新计算一下<code>c</code>，而事实上这个<code>c</code>并不一定是被频繁使用到的。<br>在先前，我们提到了Cache Aside Pattern模式的可能存在的不一致问题，它常常在高并发场景下出现，对于这种问题，可以采用<a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md" target="_blank" rel="noopener">队列进行优化</a>。假设A写B读，我们需要防止B脏读，那么我们把A删缓存、A写库、B读都入队，并使用若干工作线程加速处理这个队列。如果我们在A删缓存后写库前从队列中取到了B读的请求，那么我们将这个请求重新放回队列。对于对同一值的多个更新缓存请求，可以进行归并。这个方案的一个注意点是读请求可能被长时间阻塞，例如当数据更新很频繁时，这时候需要做好压测。此外，需要注意对同一个数据的读写请求必须要在一个节点上完成，此时，一些热点数据的存在会导致某个节点的压力过大。</p>
<h3 id="缓存雪崩、穿透和击穿"><a href="#缓存雪崩、穿透和击穿" class="headerlink" title="缓存雪崩、穿透和击穿"></a>缓存雪崩、穿透和击穿</h3><p>缓存雪崩、穿透和击穿是使用缓存时出现的致命性问题。<br>缓存雪崩主要出现在<strong>缓存宕掉</strong>后，所有的流量会<strong>打到数据库</strong>上，从而<strong>数据库也挂</strong>了，导致整个服务崩溃，“雪崩”二字，形象生动。对于这种情况的处理方案分为：</p>
<ol>
<li>事前：redis高可用，主从+哨兵，redis cluster，避免全盘崩溃。</li>
<li>事中：限流降级（例如本地ehcache缓存+hystrix），避免MySQL被打死。</li>
<li>事后：redis持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li>
</ol>
<p>缓存穿透是一种恶意攻击的手段，它会构造大量的请求去查询一些<strong>缓存中肯定没有的数据</strong>，迫使所有的请求<strong>都打到数据库</strong>上面，从而导致<strong>数据库宕机</strong>。解决方案就是对所有查不到的值，<strong>在缓存中创建一个空值</strong>。</p>
<p>缓存击穿指的是一个热点Key<strong>在失效的瞬间</strong>，大量对它的请求会击穿缓存，<strong>打到数据库</strong>上面。和雪崩相比，它更接近于在缓存上凿了一个洞。解决方案包含：</p>
<ol>
<li>如果更新频率低，可以设置为永不过期</li>
<li>如果更新频率较低，可以通过分布式锁来保证只有少数的请求能请求数据库并更新缓存，其余的线程在所释放后再请求缓存</li>
<li>如果更新频率高，可以用定时线程在过期前主动构建缓存，或者延迟缓存过期时间</li>
</ol>
<h3 id="并发竞争写"><a href="#并发竞争写" class="headerlink" title="并发竞争写"></a>并发竞争写</h3><p>这个问题出现在多客户端并发写一个key时，其中A读和B读可能乱序，A写和B写也可能乱序。对于这个问题，可以采用分布式锁来解决。并且维护一个时间戳，往数据库更新时，必须要满足缓存的时间戳要比数据库的时间戳大。</p>
<h3 id="缓存Demo：Redis"><a href="#缓存Demo：Redis" class="headerlink" title="缓存Demo：Redis"></a>缓存Demo：Redis</h3><h4 id="Redis内存淘汰机制"><a href="#Redis内存淘汰机制" class="headerlink" title="Redis内存淘汰机制"></a>Redis内存淘汰机制</h4><p>详见<a href="/2018/07/23/redis_learn_object/">我的专题文章</a></p>
<h4 id="Redis主从模式"><a href="#Redis主从模式" class="headerlink" title="Redis主从模式"></a>Redis主从模式</h4><p><a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-master-slave.md" target="_blank" rel="noopener">Redis主从模式</a></p>
<h4 id="Redis集群模式"><a href="#Redis集群模式" class="headerlink" title="Redis集群模式"></a>Redis集群模式</h4><p>在之前版本的Redis中，多节点部署需要依靠诸如<code>codis</code>、<code>twemproxy</code>等中间件实现，我们对中间件读写，由中间件管理Redis实例。<br>现在版本的Redis原生支持了Redis Cluster方式。相比于sentinel的高可用和一写多读，Redis Cluster能够真正在多个Redis节点之间共享数据。</p>
<h4 id="生产环境下的Redis部署"><a href="#生产环境下的Redis部署" class="headerlink" title="生产环境下的Redis部署"></a>生产环境下的Redis部署</h4><p><a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-production-environment.md" target="_blank" rel="noopener">生产环境下的Redis部署</a></p>
<h4 id="Redis持久化方式"><a href="#Redis持久化方式" class="headerlink" title="Redis持久化方式"></a>Redis持久化方式</h4><p>详见<a href="/2021/03/13/redis-persist/">我的专题文章</a></p>
<h1 id="分布式系统上的一致性和Order"><a href="#分布式系统上的一致性和Order" class="headerlink" title="分布式系统上的一致性和Order"></a>分布式系统上的一致性和Order</h1><p>在这个章节中，主要介绍和一致性相关的一些概念，包括：</p>
<ol>
<li>Consistency</li>
<li>Order</li>
<li>Clock</li>
<li>Broadcast</li>
</ol>
<p>从概念上分布式中的一致性(CAP中的C)和事务一致性(ACID中的C)是完全不一样的，CAP中的一致性要求多副本的系统的行为表现得像单系统一样，并且对这个系统的修改是原子的。而事务一致性强调事务前后不变量不能改变。</p>
<p><img src="/img/fbs/yzxdj.png" alt="一致性的等级"></p>
<h2 id="强一致性"><a href="#强一致性" class="headerlink" title="强一致性"></a>强一致性</h2><p>分布式系统，特别是CAP理论中对一致性(consistency)的定义是<em>all nodes see the same data at the same time</em>，这个要求是比较高的，<a href="https://blog.csdn.net/chao2016/article/details/81149674#%E5%8E%9F%E5%AD%90%E4%B8%80%E8%87%B4%E6%80%A7atomic-consistency" target="_blank" rel="noopener">一些人会将它等价位</a>强一致性(Strong consistency)、线性一致性(Linearizability)、外部一致性(External consistency)、原子一致性(atomic consistency)。</p>
<p>强一致性强调each operation appears to execute instantaneously, exactly once, at some point between its invocation and its response。</p>
<p>考虑一个简单的主从架构的例子(来自<em>Designing Data-Intensive Applications</em>)，在下图中比赛结果由Referee写入Leader主库，并向两个Follower同步复制，线性一致性需要这个过程是透明的。在本场景中即当我们任何一个读取返回新值后，所有后续读取都必须返回新值（可以参考<a href="/2017/12/28/Concurrency-Programming-Compare/">C++内存模型</a>中的可见性一块）。但简单的读写分离主从复制会出现当Leader只同步了Follower1而没有同步到Follower2时，对两个副本的读取结果分别返回新值和旧值的现象。</p>
<p><img src="/img/fbs/lin.png"></p>
<p>通过线性一致性<a href="https://www.jianshu.com/p/64b7b286ef7c" target="_blank" rel="noopener">可以实现</a>分布式锁、选举、和唯一性约束等功能。我们使用共识算法实现的是<strong>线性一致性</strong>，而主从复制则不是。由此可见，分布式一致性(Consistency)和共识(Consensus)是完全不同的两个概念，后者是实现前者的一个工具。</p>
<h3 id="辨析Linearizability、Serializability"><a href="#辨析Linearizability、Serializability" class="headerlink" title="辨析Linearizability、Serializability"></a>辨析Linearizability、Serializability</h3><p>我们还需要区分<a href="http://www.bailis.org/blog/linearizability-versus-serializability/" target="_blank" rel="noopener">Linearizability和Serializability</a>。</p>
<p>线性一致性(Linearizability)来源于分布式系统和并发编程，其语境是single-operation, single-object, real-time order，线性一致性保证了<strong>写操作对后续的读操作是可见的</strong>，也就是经典的写后读问题。线性一致性往往对应于CAP中的C，线性一致性是composable，即local的。即如果每一个对象上的操作是线性的，那么系统上的所有操作都是线性的。</p>
<p>顺序一致性(Serializability)来源于数据库，其语境是multi-operation, multi-object, arbitrary total order，它是一个有关事务的保证，涉及一组操作。它保证了在多个对象上执行的多个事务等同于<strong>某个</strong>序列化的执行过程。Serializability相当于ACID中的I，如果用户的每一个事务都能保证correctness即ACID中的C，那么顺序执行的事务也能保证correctness。不同于Linearizability，Serializability本身不给事务的执行顺序加上任何的real-time约束，也就是<a href="https://www.jianshu.com/p/76ff7718d381" target="_blank" rel="noopener">不需要操作是按照真实时间严格排序的</a>。Serializability 也不是composable的，它也不表示任何的确定性的顺序，它只是要求存在一些等价的执行序列。</p>
<p>另外一位<a href="http://gaocegege.com/Blog/%E9%9A%8F%E7%AC%94/consistency" target="_blank" rel="noopener">博主给出了如下的论述</a>，即“线性化的一致性要求操作生效的顺序等于实际的实时操作排序。顺序一致性允许操作被重新排序，只要在每个节点上观察到的顺序保持一致。作为用户, 能区分两者的唯一方法是，观察系统的所有输入和时间. 从客户端与节点交互的角度来看，两者是等价的”。</p>
<p>Serializability + Linearizability = Strict Serializability。</p>
<h3 id="实现External-Consistency"><a href="#实现External-Consistency" class="headerlink" title="实现External Consistency"></a>实现External Consistency</h3><p>外部一致性<a href="https://cloud.google.com/spanner/docs/true-time-external-consistency" target="_blank" rel="noopener">由Spanner引入</a>。</p>
<p>在实现外部一致性时，需要考虑写后读一致性(read-after-write consistency)和单调读一致性。也就是不能写完还读不到，或者读到旧的。由于分布式系统是多副本的，所以实现起来需要进行设计。</p>
<p>考虑<a href="https://disksing.com/external-consistency/" target="_blank" rel="noopener">一个例子</a>：事务1在节点1写入数据A，事务1完成后，事务B在另一个节点2写入数据B。在这个场景下，A和B并不是并发的。在上面这个过程中，有一个并发事务读取A和B，那么它读取A和B的相对顺序是什么呢？例如如果他读到了B而没有读到A，可以认为外部一致性被破坏了。</p>
<p>为了解决外部一致性要求的顺序问题，一个简单粗暴的办法是所有事务的序列号都通过一个统一的中心节点分配。例如Spanner就使用了原子钟进行授时。为了解决原子钟的误差问题，我们可以在事务提交时，等待误差这么久的余量。</p>
<p>CockroachDB通过逻辑时钟解决物理时钟太过接近，导致难以排序的问题。逻辑时钟的概念，可以参考Lamport时钟。</p>
<h2 id="弱一致性"><a href="#弱一致性" class="headerlink" title="弱一致性"></a>弱一致性</h2><p>有的时候系统保证在更新操作后的一段时间后，系统能够达到一致性状态，这称为弱一致性。弱一致性和强一致性的区别是弱一致性存在“不一致窗口”，在不一致窗口中系统不一定保证用户总能看到最新的值。弱一致性可以分为最终一致性、因果一致性、单调读一致性、单调写一致性、有界旧一致性、前缀一致性等。<br><a href="https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels" target="_blank" rel="noopener">在Azure Cosmos中将一致性的强弱程度建立以下的关系</a>。Strong–Bounded staleness–Session–Consistent prefix–Eventual。从前向后的延迟。可用性和扩展性越好，但一致性会差一点。</p>
<h3 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h3><p>最终一致性也被称为乐观复制(optimistic replication)，是一种<a href="https://en.wikipedia.org/wiki/Eventual_consistency" target="_blank" rel="noopener">获得HA的常见方式</a>，要求当没有新的对X的提交发生时，最终所有对X的访问都返回最后一次更新的值。最终一致性通常用来提供BASE语义。<br>我们常见的异步复制的主从架构实现的是<strong>最终一致性</strong>。它的一个典型常见是用户读取异步从库时，可能读取到较旧的信息，因为该从库尚未完全与主库同步。注意，同步复制的主从架构会出现<strong>任一节点</strong>宕机导致的单点问题。</p>
<h3 id="读己所写一致性"><a href="#读己所写一致性" class="headerlink" title="读己所写一致性"></a>读己所写一致性</h3><p>读己所写一致性(read-your-writes consistency)又称为read-after-write consistency，<br>这里的己，指的是客户端。如下图所示，读己所写一致性要求客户端总能读到<strong>自己最新提交的</strong>写入。特别地，读己之写一致性不对其他用户的更新做出承诺。<br><img src="/img/fbs/read-after-write.png"></p>
<p>读己所写一致性可以通过以下的一些方式实现：</p>
<ol>
<li>当读取可能被修改过的内容时，强制从主库读。</li>
<li>对于大部分内容都可能被修改的系统来说，以上的方法并不适用，此时可以跟踪上次被更新的时间，并强制在上次更新后的某段时间内强制从主库读取。</li>
<li>客户端维护最近一次写入的时间戳，系统只从至少拥有该时间戳的修改的从库中进行查询。</li>
<li>当数据副本分布在多个数据中心时，可能带来额外的复杂性，这里略过，详见DDIA。</li>
</ol>
<h3 id="会话一致性"><a href="#会话一致性" class="headerlink" title="会话一致性"></a>会话一致性</h3><p>会话一致性<a href="https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels" target="_blank" rel="noopener">能够保证在该会话内</a>一致前缀读、单调读、单调写、读己所写、write-follows-reads一致性。</p>
<h3 id="单调读一致性"><a href="#单调读一致性" class="headerlink" title="单调读一致性"></a>单调读一致性</h3><p>单调读一致性要求客户端在已经读到某个数据的某个版本之后，不可能在稍后的读中读到该数据先前的某个版本。如下图所示，User2345首先从Follower1读到了55555这个评论，但是在稍后的对Follower2的读中却没有读到，这是因为Follower2此时还没有收到Leader异步复制过来的日志。令User2345读Follower1的时刻为X，则User2345在晚于X的一个时刻读取到了数据早于X时刻的版本，这违背了单调读一致性，即发生了时光倒流的“现象”。<br>这种时光倒流的原因通常是用户先查询了一个<strong>延迟很小</strong>的从库，然后又去查询一个<strong>延迟很大</strong>的从库。</p>
<p>实现单调读一致性的一种方案是确保每个用户从同一个副本进行读取，例如可以Hash用户的ID到不同的节点上。</p>
<p>DDIA指出单调读一致性介于强一致性和最终一致性之间，保证了先前读取到较新的数据的情况下后续不会读到更旧的数据。<br><img src="/img/fbs/mono-read.png"></p>
<h3 id="一致前缀读"><a href="#一致前缀读" class="headerlink" title="一致前缀读"></a>一致前缀读</h3><p><a href="https://docs.microsoft.com/zh-cn/azure/cosmos-db/consistency-levels" target="_blank" rel="noopener">在一致前缀选项中，返回的更新包含所有更新的一些前缀，不带间隔。一致前缀一致性级别保证读取操作永远不会看到无序写入</a>。</p>
<p>相比于单调读，一直前缀读要求如果一系列写入按照某个顺序发生，那么<strong>任何人</strong>在读取时，也会读到同样的顺序。<br>【Q】是不是能对应到Causal广播？应该是的<br>一致前缀读的要求，往往会用在partitioned/shared数据库中。在这样的数据库中，不同分区是独立运行的，所以不存在<strong>全局写入顺序</strong>。为了解决这个问题，可以强制所有带有因果的写入都在相同的分区上。当然，也可以采用一些显式跟踪因果关系的算法。</p>
<h3 id="有界旧一致性"><a href="#有界旧一致性" class="headerlink" title="有界旧一致性"></a>有界旧一致性</h3><p>有界旧一致性(Bounded staleness)保证了读到的数据和最新版本最多差K个版本。</p>
<h3 id="可调一致性"><a href="#可调一致性" class="headerlink" title="可调一致性"></a>可调一致性</h3><p>诸如Cassandra的系统在最终一致性的基础上提供了可调一致性。对于任何读写操作，系统允许用户配置成功写操作的最小节点数W、成功读操作的最小节点数R和副本节点的数量N。我们可以根据读写请求的数量来动态调整可用性C和一致性A之间的trade-off。</p>
<h3 id="因果-Causal-一致性"><a href="#因果-Causal-一致性" class="headerlink" title="因果(Causal)一致性"></a>因果(Causal)一致性</h3><p>因果一致性(causal consistency)是在ZAB协议中常常见到的一种一致性。因果一致性要求如果A在因果上先于B（在实际场景中可以表现为B依赖A的结果、A先于B发生等），那么A一定先于B被提交。因此，因果一致性实际上是偏序的，如果A和B之间没有先后关系，那么A和B就是可以以任意顺序被提交的。因此，可以看出，因果一致性是比线性一致性要弱的一个一致性，因为线性一致要求全序关系。</p>
<p><a href="https://scattered-thoughts.net/writing/causal-ordering/" target="_blank" rel="noopener">在单核单线程上</a>的因果一致就是线性一致，这是因为整个程序是顺序执行的。</p>
<h3 id="因果-Causal-一致性和逻辑时钟"><a href="#因果-Causal-一致性和逻辑时钟" class="headerlink" title="因果(Causal)一致性和逻辑时钟"></a>因果(Causal)一致性和逻辑时钟</h3><p>由于在集群中维护以现实为标准的物理时钟的性价比是较低的，而从对因果一致性的讨论中可以看出，节点之间只需要在需要共同访问的时间的先后顺序上达成一致，所以逻辑时钟是描述因果一致性的好工具。逻辑时钟主要是Lamport clocks，以及后来加强了的Vector clock。<br>Lamport<br> Clock或者Lamport timestamp，定义<a href="https://scattered-thoughts.net/writing/causal-ordering/" target="_blank" rel="noopener">如下</a></p>
<ol>
<li>在同一进程中，如果a先于b发生，那么C(a) &lt; C(b)<br> 注意**反过来是不成立的**。一个平凡情况，就是进程p1上面有一个事件a，LC是1。另一个进程p2上面发生了非常多的事件b1..b100，b100的LC是100。两个进程没有任何交互。那么肯定是没有happen before的关系。<br> 下图中列出了另一个case<br> <img src="/img/fbs/lamport_clock_counter.jpg"><br> 注意，虽然反过来不成立，但是也不会有<code>C(a) &lt; C(b)</code>且<code>b -&gt; a</code>的现象了。</li>
<li>如果消息M从进程P1发送到进程P2，令P1的发送事件为a，P2的接收事件为b，有C(a) &lt; C(b)</li>
<li>如果C(a) &lt; C(b)，C(b) &lt; C(c)，则C(a) &lt; C(c)</li>
</ol>
<p>Lamport Clock实际上描述了<a href="https://en.wikipedia.org/wiki/Happened-before" target="_blank" rel="noopener">happen before</a>关系。</p>
<p>Lamport时钟的算法可以被描述<a href="https://en.wikipedia.org/wiki/Lamport_timestamps" target="_blank" rel="noopener">如下</a>。注意Wikipedia与诸如<a href="https://yq.aliyun.com/articles/689658" target="_blank" rel="noopener">文章1</a>和<a href="https://zhuanlan.zhihu.com/p/56146800" target="_blank" rel="noopener">文章2</a>在表述上有一些冲突，但看下面的图发现说的是一个意思。说法的不同是：</p>
<ol>
<li><p>Wikipedia是把事件产生和事件发送拆开来说的，产生一个事件+1，发送不加，收到+1。例如原始状态是0，产生一个事件是1，发出去还是1，收到之后要+1，变成了2。</p>
</li>
<li><p>另外两篇文章说的是我一个事件产生完就立马发送了，这整个过程中，+了1。</p>
</li>
<li><p>事件在当前节点发生</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">time</span> = <span class="built_in">time</span> + <span class="number">1</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>发送事件</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">send(<span class="name">message</span>, time)<span class="comment">;</span></span><br></pre></td></tr></table></figure></li>
<li><p>接收事件</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">message</span>, time_stamp) = receive()<span class="comment">;</span></span><br><span class="line">time = max(<span class="name">time_stamp</span>, time) + <span class="number">1</span><span class="comment">;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<p><img src="/img/fbs/lamportclock.jpg"><br>Lamport Clock得到了偏序关系，但是我们可以从这个偏序关系整理出若干种全序关系（一个常用的方式是按照进程号进行排序），虽然真实发生的是其中的一种情况。在下图中展示了B4这个事件的“光锥”。蓝色部分的是因，红色部分的是果。</p>
<p>总而言之，可以按照下面的办法生成全序关系：定义<code>a -&gt; b</code>为，其中<code>-&gt;</code>表示Happen before而不是蕴含关系(implication)：</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ci (<span class="name">a</span>) &lt; Cj (<span class="name">b</span>)</span><br><span class="line">Ci (<span class="name">a</span>) = Cj (<span class="name">b</span>) and Pi &lt; Pj</span><br></pre></td></tr></table></figure>

<p>其中C表示逻辑时钟，P表示进程号，i/j表示进程，a/b表示进程上的事件。</p>
<p>下面我们看看，为什么<code>a -&gt; b</code>，则<code>C(a) &lt; C(b)</code>：</p>
<ol>
<li>如果a和b位于同一个进程内，显然是成立的</li>
<li>如果a和b位于不同进程i和j中，那么必然在事件a到事件b之间有一次从i到j的通信<br> 我们不妨把这次通信<code>c-&gt;d</code>画出来，其中c可能为a，d可能为b。<br> <img src="/img/fbs/lamport_clock_prove.jpg"><br> 容易发现a/c，c/d，d/b之间都会伴随着Lamport Clock的自增。</li>
</ol>
<p>通过逻辑时钟，可以解决对共享状态访问的竞态问题了，因为我们可以对所有<code>a -&gt; b</code>这样存在happen before关系的时间赋一个逻辑时间戳了。但诸如节点故障单点问题等问题还需要容错机制来解决。</p>
<h4 id="Lamport时钟的缺点"><a href="#Lamport时钟的缺点" class="headerlink" title="Lamport时钟的缺点"></a>Lamport时钟的缺点</h4><p>首先，如果<code>A -&gt; B</code>(happen before)则<code>C(A) &lt; C(B)</code>，但是对Lamport时钟来讲，反之并不成立。<br>其次，它并不能<strong>识别</strong>a和b不存在happen before关系的情况。如下图所示，A和B上面的事件是平行发生的。所以他们都发送消息给C后，因为B的逻辑时钟更大，所以A的消息被丢掉了。但这个合理吗？站在上帝视角，我们看到其实A事件的发生在物理时间上是比B要更晚的，如果我们走物理时钟，应该把B的消息丢掉！当然，这种平行时空的问题，本来就是婆说婆有理，公说公有理的，所以这是一个<strong>时钟冲突</strong>。这样的冲突不好<strong>解决</strong>，但Lamport Clock并不能<strong>识别出</strong>这种冲突，这是问题所在。我们希望的是Lamport Clock能够在这种情况下告诉我们时钟冲突了，而不是武断认为B更靠后发生。<strong>因此，我们有了Vector Clock</strong>。</p>
<p><img src="/img/fbs/lamport_clock_drawback.png"></p>
<h2 id="计算机中的时钟"><a href="#计算机中的时钟" class="headerlink" title="计算机中的时钟"></a>计算机中的时钟</h2><h3 id="NTP"><a href="#NTP" class="headerlink" title="NTP"></a>NTP</h3><p>在计算机系统中，NTP协议被普遍用来进行授时。<br>授时的核心在于计算两个终端之间的clock drift。计算方式在<a href="/2017/12/05/libutp%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/">libutp源码简析</a>这文章中已经介绍过了。这个方案有个很强的假设，就是认为网络是对称的，即A-&gt;B和B-&gt;A的时间是对等的。</p>
<h3 id="Lamport-Clock"><a href="#Lamport-Clock" class="headerlink" title="Lamport Clock"></a>Lamport Clock</h3><p>刨去这个假设，我们如何在分布式系统中实现更靠谱的授时呢？其实在分布式系统中，只是需要知道事件发生的全序关系而不是具体的时刻，所以我们自然想到了<strong>Lamport时钟</strong>。在Lamport时钟中，我们根据发送和接收消息可以确定某些事件之间的偏序关系。剩余的互相处于“平行时空”的事件咋办呢？这个我们根据所处进程号进行排序。这个在之前讲过了，就不再赘述。</p>
<h3 id="Vector-Clock-VC"><a href="#Vector-Clock-VC" class="headerlink" title="Vector Clock(VC)"></a>Vector Clock(VC)</h3><p>向量时钟针对Lamport Clock做了两点改进：</p>
<ol>
<li>提出了vector clocks ordering，能够识别平行关系</li>
<li>允许<code>VC(A) &lt; VC(B)</code>则<code>A -&gt; B</code>的反向推理</li>
</ol>
<h4 id="vector-clocks-ordering"><a href="#vector-clocks-ordering" class="headerlink" title="vector clocks ordering"></a>vector clocks ordering</h4><p>首先介绍一下vector clocks ordering：</p>
<ol>
<li><code>T=T&#39;</code><br> 等于关系表示两个向量的每个对应元素都相等</li>
<li><code>T&lt;=T&#39;</code><br> ……都小于等于</li>
<li><code>T&lt;T&#39;</code><br> <code>T&lt;=T&#39;</code>且非<code>T=T&#39;</code>，也就是说只要有一个不等于，那就是小于</li>
<li><code>T||T&#39;</code><br> 平行关系，既不<code>T&lt;=T&#39;</code>，也不<code>T&#39;&lt;=T</code></li>
</ol>
<p>向量时钟的一个作用是发现数据冲突，也就是所谓的version clock。</p>
<h4 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h4><p>假设分布式系统中有 N 个进程，每个进程都有一个本地的向量时间戳 Ti，其中Ti[j]表示进程i<strong>知道的</strong>进程j的本地的向量时钟值。特别地，对于进程 i 来说，Ti[i] 是进程 i 本地的向量时钟值。<br>向量时钟算法实现如下：</p>
<ol>
<li><p>当进程 i 当有新的事件发生时，自增向量时间戳<code>Ti[i]</code>，即<code>Ti[i] ++</code></p>
</li>
<li><p>当进程 i 发送消息时同时发送自己的向量时间戳(MT=Ti)</p>
</li>
<li><p>接受消息的进程 j 更新本地的向量时间戳Tj<br> 更新方法很简单，自己的Tj，以及Ti刚传过来的MT，zip一下比较，哪个大取哪个。</p>
 <figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for k = <span class="number">1</span> to N:</span><br><span class="line">    Tj<span class="string">[k]</span> = max(Tj<span class="string">[k]</span>, MT<span class="string">[k]</span>)</span><br></pre></td></tr></table></figure>

<p> 同样，接受消息的时候，也要自增向量时间戳<code>Tj[j]</code>，即<code>Tj[j] ++</code></p>
</li>
</ol>
<h4 id="应用：判断因果关系"><a href="#应用：判断因果关系" class="headerlink" title="应用：判断因果关系"></a>应用：判断因果关系</h4><p>如何使用向量时钟判断两个时间A和B的因果关系呢？不妨先看两个进程比较的情况。在这里，我们把事件的下标放到进程前面，这是为了方便后面推广。<br>进程i和j上发生了事件A和B，向量时钟分别为TA和TB。TA[i]表示进程i上事件A的值。</p>
<ol>
<li>如果<code>TA[j] &lt; TB[j]</code><ol>
<li>如果<code>TA[i] &lt;= TB[i]</code>则A happen before B，记作<code>i -&gt; j</code><br> 也就是说，在两个进程<code>i</code>和<code>j</code>上，事件B的向量时钟都要大于事件A。<br> 这个应该对应了vector clocks ordering里面的小于情况，即<code>A &lt; B</code>。</li>
<li>如果<code>TA[i] &gt; TB[i]</code>则A和B同时发生，记作<code>i &lt;-&gt; j</code></li>
</ol>
</li>
</ol>
<h4 id="推广和证明"><a href="#推广和证明" class="headerlink" title="推广和证明"></a>推广和证明</h4><p>上面只是涉及了两个进程i和j，我们可以推广下，证明如果<code>VC(A) &lt; VC(B)</code>则<code>A -&gt; B</code>。</p>
<p>令<code>VC(A) = [m, n]</code>，<code>VC(B) = [s, t]</code>，由<code>VC(A) &lt; VC(B)</code>可以得出：</p>
<ol>
<li>m &lt;= s</li>
<li>n &lt;= t</li>
<li>两个等号不会同时成立</li>
</ol>
<p>我们不妨画一张图，Pa表示事件A所在的进程，Pb表示事件B所在的进程。如果说<code>m &lt;= s</code>，那么肯定在不早于A和不晚于B时，A往B发了消息，也就对应了下图的[m1, n1]和[s1, t1]。不然的话，这个s是哪里来的？<br><img src="/img/fbs/vectorclock_prove.jpg"></p>
<p>上面一张图只是一种情况，实际上这个大于等于m的s可能来自如下图所示的4种不同的情况。<br><img src="/img/fbs/vectorclock_prove2.jpg"></p>
<h4 id="和Lamport-Clock比较"><a href="#和Lamport-Clock比较" class="headerlink" title="和Lamport Clock比较"></a>和Lamport Clock比较</h4><p>比较一下Vector Clock和Lamport Clock，我们发现在Lamport Clock中，我们比较的是一个Scalar；但是在Vector Clock中，我们比较的是一个Vector。</p>
<h4 id="能不能只用Vector-Clock呢？"><a href="#能不能只用Vector-Clock呢？" class="headerlink" title="能不能只用Vector Clock呢？"></a>能不能只用Vector Clock呢？</h4><p>我觉得是可以的，但这样就是完全依靠通信来同步。通信是不可靠的，如果通信链路上拥塞，或者干脆隔离了，那么系统就不可用了。<br>此外，对一个N节点的集群，每个节点需要维护长度为N的向量，并且每次发送消息也得是这个长度。</p>
<h3 id="TrueTime"><a href="#TrueTime" class="headerlink" title="TrueTime"></a>TrueTime</h3><p>TrueTime结合了原子钟和GPS时钟，使得误差相比NTP的100ms级别的误差减少到个位数毫秒的误差。<br>因此TrueTime返回的当前时间now会包含earliest和latest两个值，表示考虑误差下，当前时间最早和最晚可能是什么。</p>
<h3 id="混合时钟"><a href="#混合时钟" class="headerlink" title="混合时钟"></a>混合时钟</h3><p>例如，我们可以在每一秒，重置逻辑时钟(是一个integer)为0，然后每一次分配TSO都递增逻辑时钟。我们的TSO就是物理时间(秒)+逻辑时钟的值，而对准这1s是容易的。</p>
<h2 id="广播和全序广播"><a href="#广播和全序广播" class="headerlink" title="广播和全序广播"></a>广播和全序广播</h2><p>全序广播(total order boardcast)有关一致性的另一个概念。首先，total order即全序关系，是相对于偏序关系(partial order)的一个概念。全序要求在序列中的任何元素都能有确定的先后关系，而偏序则只要求序列中某些元素具有先后关系。整除关系是一个典型的偏序关系。</p>
<p>广播主要分为几个过程，首先是从发送方发出消息的broadcast过程，消息在网络中传播的过程（可能会丢包乱序重复等），以及最后送达接受方的deliver过程。<br>广播根据broadcast和deliver的顺序可以分为下面几种类型，这些类型是依次增强的，从FIFO开始，对各种乱序的情况进行了规范。</p>
<ol>
<li>best effort广播</li>
<li>reliable广播<br> 引入重传</li>
<li>FIFO广播<br> 如果m1和m2来自同一个node，并且<code>broadcast(m1)-&gt;broadcast(m2)</code>（这里箭头表示happen before关系），那么m1也要在m2前面被deliver。<br> 通俗一点讲，就是从同一个节点broadcast出来的消息的书序和他们被deliver的顺序是一致的，但是对于不同节点出来的，是无所谓顺序的。<br> 对于下面的图，到C节点的deliver顺序可以是213，123，132。<br> <img src="/img/fbs/fifob.png"></li>
<li>Causal广播（Causal表示因果的，不要和casual搞混）<br> 如果<code>broadcast(m1)-&gt;broadcast(m2)</code>，那么m1也要在m2前面被deliver。<br> 看起来，只是比FIFO广播少了“在同一个node上的条件”而已，实际差别是什么呢？其实在后面的文章中定义了happen before，照着happen before的三种情况，就容易理解了。这里多了的就是A发消息，B收消息这种跨node的happen before关系。<br> 对于下面的图，如果<code>broadcast(m1)-&gt;broadcast(m2)</code>且<code>broadcast(m1)-&gt;broadcast(m3)</code>，那么合法的deliver顺序是123和132。<br> <img src="/img/fbs/causalb.png"></li>
<li>Total Order广播<br> 如果在一个node上，m1在m2前面被deliver，那么在所有node上，m1都在m2前面被deliver。<br> 既可以像下面的图一样，所有节点都按照123的顺序deliver。这里需要看到来自node A的请求m3，必须要delay到来自node B的请求m2被deliver之后才能deliver，即使这个请求是自己发给自己的。<br> <img src="/img/fbs/totorderb.png"><br> 当然了，所有节点也可以按照132的顺序来deliver。</li>
<li>FIFO Total Order广播<br> 就是FIFO和 Total Order的结合。</li>
</ol>
<h3 id="各类广播的实现"><a href="#各类广播的实现" class="headerlink" title="各类广播的实现"></a>各类广播的实现</h3><h4 id="reliable"><a href="#reliable" class="headerlink" title="reliable"></a>reliable</h4><p>一个naive的想法是重传，同时处理重复包（例如可以通过编号的方式）。但如果在重传前传播的节点就宕掉了，那么reliable就无法保证。<br>一个简单的修复，就是每个节点在第一次收到消息之后，往其他节点转发一下消息。但这个行为会导致为了广播每一条消息，整个集群中总共发送$O(n^2)$个消息。<br>Gossip协议是对上述的一个优化。每个节点在第一次收到消息之后，会随机发送给fanout个节点（例如随机发给3个节点），有点像流行病毒传播一样。Gossip协议能以很高的概率实现reliable。</p>
<h4 id="FIFO"><a href="#FIFO" class="headerlink" title="FIFO"></a>FIFO</h4><p>对于每一个node，维护下面几个变量：</p>
<ol>
<li>i<br> 表示发送方node的编号</li>
<li>seq<br> 每个节点维护自己broadcast的信息的序号</li>
<li>delivered[j]<br> 是一个数组，表示对于node j，我们总共deliver了几个序号</li>
<li>buffer<br> 用来存放尚未准备好deliver的信息</li>
</ol>
<p>发送方发送信息<code>m</code>，格式是<code>(i,seq,m)</code>。在发送后，需要自增seq。<br>接收方在接收来自<code>i</code>的信息后，先放到<code>buffer</code>中。接着在<code>buffer</code>中寻找seq等于<code>delivered[i]</code>的信息，如果存在，就deliver，并且自增<code>delivered[i]</code>。<br>这个方案实际上就是说接收方给每个发送方维护一个队列，通过这个队列保证自己收到来自<code>i</code>连续递增<code>seq</code>的信息。</p>
<p><img src="/img/fbs/fifob_a.png"></p>
<h4 id="Causal"><a href="#Causal" class="headerlink" title="Causal"></a>Causal</h4><p>对于发送方，需要复制自己的delivered数组为dep数组，设置<code>dep[i]</code>为seq。发送方发送<code>(i,deps,m)</code>。在发送后，需要自增seq。<br>接收方在收到某个消息<code>(i,deps,m)</code>之后，需要满足<code>deps&lt;=delivered</code>条件之后，才能deliver这条信息。不过这个涉及到了比较两个数组，其规则就是之前提到的vector clocks ordering。</p>
<p><img src="/img/fbs/causalb_a.png"></p>
<h4 id="Total-Order"><a href="#Total-Order" class="headerlink" title="Total Order"></a>Total Order</h4><p>通常有两种方式：</p>
<ol>
<li>借助Leader<br> 如果需要广播信息，则发送给Leader。Leader按照FIFO的方式广播信息。<br> 这种方式需要解决Leader可能存在的单点问题。</li>
<li>借助于Lamport timestamp<br> 对每个消息加上Lamport时间戳，并且按照Lamport时间戳deliver消息。<br> 这种方式的问题是如何判断自己已经收到了所有timestamp小于T的所有消息。这需要使用FIFO连接，并且等到所有node上大于等于T的信息。</li>
</ol>
<p><a href="https://www.zhihu.com/question/275845393/answer/386816571" target="_blank" rel="noopener">实现全序广播等价于实现线性一致的存储</a>。</p>
<h2 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h2><p>可用性即<em>reads and writes always succeed</em>。这个要求系统能够始终在<strong>正常时间</strong>内对用户的请求进行响应。当然由于可能出现的一致性问题，这个响应不一定是正确的。</p>
<h2 id="分区容错性"><a href="#分区容错性" class="headerlink" title="分区容错性"></a>分区容错性</h2><p>分区容错性即<em>the system continues to operate despite arbitrary message loss or failure of part of the system</em>。由于分布式集群中常出现网络分区情况，即集群中的一部分机器与另一部分机器中断连接，这可能是由于网络故障，产生网络分区；也可能是由于某些节点宕机。网络分区可能产生的一个后果是脑裂(split brain)，也就是存在多个节点认为自己是领导者。</p>
<p>我们除非设计出一个永远不会出故障的网络，否则我们必须要容忍P。于是C和A便成为了trade-off。由于网络分区的概率比较小，并且是易于探测的，所以C和A大多数情况是能够比较好地满足的，所以说我们要做的不是根除网络分区及其导致的部分失效(partial failure)问题，而是去正确地处理它，这就引入了诸如2PC、RWN、Paxos等协议。</p>
<h1 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h1><p>由于分布式系统中存在多个副本，所以维护这些副本的一致性成为核心问题之一。分布式事务相对于仅涉及单个数据库事务的难点在于其提交或回滚不仅决定于自身，还决定于其他节点上事务执行的状态。从理想考虑，只要有一台节点失效，其他节点就要进行rollback。为了实现这一点，需要一个协调者(Coordinator)来根据所有参与者(Cohorts)的情况判断是否完成提交或终止提交。同时协调者的故障称为单点故障，也就是这个故障能够直接导致集群无法运行，需要特别考虑。</p>
<h2 id="2PC和3PC"><a href="#2PC和3PC" class="headerlink" title="2PC和3PC"></a>2PC和3PC</h2><p>对于分布式事务处理，MySQL引入了XA机制，也就是所谓的2PC、3PC的算法。这种方案是在数据库层面的，也就是通过一个事务管理器去协调各个事务的提交，因此往往不能很好地适配现在<a href="https://zhuanlan.zhihu.com/p/130729144" target="_blank" rel="noopener">微服务的框架</a>，因为微服务下不允许访问其他服务的数据库。<br>出于篇幅限制，见文章<a href="/2019/03/12/2pc-3pc/">2PC和3PC</a>。</p>
<h2 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h2><p>补偿事务(Try-Confirm-Cancel, TCC)的中心思想是：针对每个操作都要注册一个与其对应的确认和撤销操作。相比于2PC等算法，TCC<a href="https://blog.csdn.net/bjweimengshu/article/details/86698036" target="_blank" rel="noopener">是一个应用层面的协议</a>。<br>这个方案对应用架构是强侵入性的，因为要求每个业务的接口都要实现TCC三个接口。所以一般用在金融领域。</p>
<h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>在使用分布式锁前，可以先考虑是否能够通过一（原子）写多读来维护分布式状态。</p>
<h3 id="通过Redis实现分布式锁"><a href="#通过Redis实现分布式锁" class="headerlink" title="通过Redis实现分布式锁"></a>通过Redis实现分布式锁</h3><ol>
<li><code>SETNX</code>命令<br> 这里NX表示会创建也就是说如果不存在就创建一个key，表示这个进程获得了锁。</li>
<li>解决持锁进程崩溃带来的死锁问题<br> 给锁字段加一个超时时间，即使用EXPIRE命令。</li>
<li>现在需要SETNX和EXPIRE两条命令，不是原子的了<br> 有两个选择：<ol>
<li>对于旧版本，可以使用LUA脚本</li>
<li>对于新版本，可以使用新的SET命令</li>
</ol>
</li>
<li>确定锁的所有权<br> 有人问，为什么要确定锁的所有权呢？我加锁的进程自己知道，没加成锁的进程也自己知道。其实不然，假如说进程A加锁之后，锁过期了，被进程B重新获得，那进程A是不知觉的。他可能直接把锁DEL掉了，但实际上他DEL的是进程B的锁。但如果每个进程，用随机数，或者pid来标记，并且在删除的时候判断下，就不会有这个问题了。</li>
</ol>
<h1 id="分布式共识"><a href="#分布式共识" class="headerlink" title="分布式共识"></a>分布式共识</h1><h2 id="分布式共识的特性"><a href="#分布式共识的特性" class="headerlink" title="分布式共识的特性"></a>分布式共识的特性</h2><p>我们需要区分分布式共识和分布式事务。分布式共识协议被用来解决分布式系统上出现的一致性问题。通过共识协议，我们能够让一个集群的行为如同一个单机版的可靠的节点一样，即使其中有一小部分的节点宕机或分区。<br>具体地讲，一个正确的分布式共识算法应当满足以下三个特性。</p>
<ol>
<li>agreement<br> 决议需要得到所有节点的认同，通常是首先批准一个多数票的决议，然后进行同步。</li>
<li>validity<br> 决议的值需要满足合法性要求。</li>
<li>termination(liveness)<br> 决议过程能够在有限步内结束，并产生结果。</li>
</ol>
<p>以上的三个特性可以总结成两点，safety和liveness。safety要求系统不会产生一个错误的值，而liveness要求系统不至于陷入阻塞。对于分布式事务来说，safety要求<a href="http://www0.cs.ucl.ac.uk/staff/B.Karp/gz03/f2010/gz03-lecture6-2PC.pdf" target="_blank" rel="noopener">一个进程提交则全体进程提交，一个进程回滚则全部进程回滚</a>，liveness要求如果没有故障，并且可提交则立即提交；如果有故障则立即回滚。</p>
<h2 id="FLP定理"><a href="#FLP定理" class="headerlink" title="FLP定理"></a>FLP定理</h2><p>论文<a href="https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf" target="_blank" rel="noopener">Impossibility of Distributed Consensus with One Faulty Process</a>证明了在异步系统中，只要有一个进程出错，那么系统就不一定能达成共识（不满足termination要求）；而在同步系统中，即使是拜占庭条件下却能够达成。</p>
<p>首先，FLP定义了一个异步系统，它应该满足如下的特点</p>
<ol>
<li>非拜占庭的Fail-stop模型</li>
<li>最多一个进程失败</li>
<li>可靠通信、原子广播<br> 即通信最终会被送达，且仅被送达一次。但是消息消息可任意延迟、可乱序。例如基于TCP的通信并不满足这个条件，因为TCP承载的消息是不可以乱序的。</li>
<li>异步通信<br> 没有时钟、不能时间同步、不能使用超时。<br> 此外，进程之间还不能探测失败，因为我们无法判定一个异步进程到底是宕机了还是只是算得太慢。</li>
</ol>
<p>系统中包含一系列进程，他们之间通过全局消息队列进行通信。例如进程<code>p1</code>可以用<code>send(p2, m)</code>向进程<code>p2</code>发送消息<code>m</code>，进程<code>p2</code>通过持续不断<code>receive(p2)</code>来获取自己的消息，并<code>event(p2, m)</code>来执行这个消息，这称为一个step，一系列连续的step组成一个run。我们定义一个configuration为当前所有进程和消息队列的状态（也就是整个系统的状态），那么一个step就会使得系统从一个configuration到达另一个configuration。当然，可能<code>p2</code>由于分区等原因接受不到消息，这时候就表示为<code>m</code>为NULL。</p>
<p>假定所有进程以一个输入<code>yp</code>的<code>{0, 1}</code>初始值开始，并试图达成一个<code>{0, 1}</code>的某个值上达成一个决议，并输出到寄存器<code>yp</code>。<code>yp</code>的值为<code>{b, 0,  1}</code>，其中<code>b</code>表示未产生表决结果的初始状态，一旦<code>yp</code>从<code>b</code>变为0或1，这个值就不再可以被修改。如果某个configuration中存在进程的<code>yp</code>是<code>v</code>，那么就可以说这个configuration是<code>v</code>-valent的。如果只有一个这样的<code>v</code>，那么就是univalent，否则就是bivalent。我们期望所有的正常进程最终都能达成正确的决议，但实际上FLP定理的证明中构造了一种情况，即使某些进程能够最终进入univalent的这一点都无法保证。</p>
<p>最后，还有一些定义。如果一个进程<code>p</code>在一个run中能运行无数个step，那么它是非故障的。定义能从初始configuration到达的configuration是accessible的，一个共识算法是部分正确的，当</p>
<ol>
<li>所有accessible的configuration都有相同的决定值</li>
<li>所有accessible的configuration里面不能只有0或者1，不然这样我搞一个系统永远输出0，那不是永远部分正确了么？我们不允许这样的平凡解</li>
</ol>
<p>整个的FLP定理的证明分为三个引理。第一个引理很直观，把进程分为两个不相交集合P1和P2，往P1和P2分别发送R1和R2，那么R1和R2的提交顺序不影响最终结果。这个对Lamport时钟有了解的都能够想明白。第二三引理类似于归纳法。第二引理证明了<strong>在有一个进程失败的系统中</strong>，一定存在一个不确定的初始configuration。证明用到了构建相邻环的思路，用大白话讲一下就是反证法假设系统从某个univalent开始，根据部分正确的条件2，我们要求有两个configuration为C0和C1分别是0/1-valent的。l论文中指出，必然存在decision value为0的系统C0和为1的系统C1只差一个进程<code>p</code>。例如三个进程的状态<code>110</code>和<code>100</code>就只差一个<code>p2</code>，但我们设计一个投票制的共识算法，那么前者决议为1，后者为0。现在我们假设<code>p</code>故障了，然后我们尝试以C0或C1为初始configuration来进行admissible deciding run。那么C0和C1必然会进入同一个值，假如说我们令它为1，那么<code>C0</code>的decision value就是{0, 1}了，它就不是univalent的了，从而推出矛盾。<br>第三个引理中指出在某种情况下，如果<code>C</code>是bivalent的，那么从它可达的<code>Y</code>也是bivalent的。首先，我们定义事件<code>e=(p,m)</code>，可以分出不应用<code>e</code>可达的configuration的集合<code>X</code>和对<code>X</code>中的configuration应用<code>e</code>可达的configuration的集合<code>Y</code>。因为<code>e</code>能应用到<code>C</code>，并且可以被任意延迟，所以它肯定也能应用到<code>E</code>。<br>现在同样使用反证法，假设<code>Y</code>中不含有bivalent的configuration，<code>Ei</code>是从<code>Ci</code>到达的某个i-valent的配置，由于<code>Ci</code>是bivalent的，所以<code>i</code>能够取0或1。如果<code>Ei</code>属于<code>X</code>，那么对它应用<code>e</code>得到<code>Fi</code>，则<code>Fi</code>肯定就属于<code>Y</code>了。如果<code>Ei</code>不属于<code>X</code>，说明<code>Ei</code>已经在之前收到过消息<code>e</code>了，那么它会先到达一个属于<code>Y</code>的配置<code>Fi</code>，然后再到达<code>Ei</code>。总而言之，无论走那条路，我们都会得到一个<code>Fi</code>的configuration，它是落在集合<code>Y</code>中的。那我们开始的集合是bivalent的，最后又都会落到同一个集合中，那么<code>Y</code>中肯定既有0-valent又有1-valent的configuration，到这里为止和假设还是不矛盾的。<br>我们定义两个configuration相邻，当其中一个在一个step里面会产生另一个时，也就是<code>C0</code>和<code>C1</code>都属于<code>X</code>。不妨设<code>C1=e&#39;(C0)</code>，其中<code>e&#39;=(p&#39;, m&#39;)</code>，当然反过来假设也可以。容易得到，对于这两个<code>Ci</code>，<code>D0=e(C0)</code>是0-valent，<code>D1=e(C1)</code>是1-valent的。我们可以得到一个如下图中<strong>实线</strong>所表示的有向图。下面展开讨论<br><img src="/img/fbs/flpf2.png"></p>
<ol>
<li>如果<code>p</code>不等<code>p&#39;</code>，我们可以将它们划分到两个不相交集合中，所以根据引理1，可以得到<code>D1=e&#39;(D0)</code>（上图中的虚线）。那么这也就意味着从一个0-valent的节点到达一个1-valent的节点，而这是不可能的，因为0-valent的后继只能是0-valent的。</li>
<li>那么<code>p</code>等于<code>p&#39;</code>了，也就是说从<code>C0</code>到<code>D0</code>和从<code>C0</code>到<code>C1</code>都源于同一个节点进行的step。那么我们将这个进程独立出来，假定它宕掉了。那么从<code>C0</code>就能通过<code>σ</code>到达一个<code>A</code>状态。看图的左半部分，假设对于这个<code>A</code>状态应用<code>e</code>，可以到达<code>E0</code>，那么根据引理1，对<code>D0</code>应用<code>σ</code>得到<code>E0</code>。同理，可以构造右边的一个<code>E1</code>，从而发现<code>A</code>既可以变到<code>E0</code>又可以变到<code>E1</code>，它是bivalent的，与假设矛盾。<br><img src="/img/fbs/flpf3.png"></li>
</ol>
<h2 id="拜占庭将军问题"><a href="#拜占庭将军问题" class="headerlink" title="拜占庭将军问题"></a>拜占庭将军问题</h2><p>拜占庭将军问题指在一个有<code>N</code>个节点的集群内部，有<code>F</code>个节点可能发生任意错误的情况下，如果<code>N &lt;= 3F</code>，一个正确的共识不可能达成。这里的任意错误包括节点前后的行为不一致，例如在投票时投给两个不同的节点。</p>
<p>诸如Paxos之类的算法只能对节点宕机进行容错，而不能对节点的拜占庭故障进行容错。这类基于复制状态机实现的协议，需要<code>N &gt;= 2F + 1</code>才能<a href="https://en.wikipedia.org/wiki/State_machine_replication" target="_blank" rel="noopener">确保共识的达成</a>。</p>
<p>实用拜占庭容错算法(Pratical Byzantine Fault Tolerance, PBFT)是一种多项式复杂度的状态机复制算法。</p>
<h2 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h2><p>CAP理论认为一致性(consistency)、可用性(availability)和分区容错性(partition tolerance)是不可能同时被满足的。这里的一致性指的是强一致性。<br>如果我们将这里的<a href="http://betathoughts.blogspot.com/2007/06/brief-history-of-consensus-2pc-and.html" target="_blank" rel="noopener">Consistency替换为Consensus</a>（实际上两者说的不是一个东西），那么根据FLP定理，对于一个异步系统，我们无法保证CA。当然，在工程上，CAP理论的情况还是能够被极大程度绕开的。例如我们可以引入同步机制，当一个节点与其他节点分区达到一定时间后，就会去声明自己宕掉了。或者，我们可以使用像Redis Sentinel一样的机制，使用另外一套班子来检测集群的状态。</p>
<h2 id="复制状态机"><a href="#复制状态机" class="headerlink" title="复制状态机"></a>复制状态机</h2><p>复制状态机(Replicated State Machine, RSM)由Lamport提出，源自Paxos算法。复制状态机通过同步日志，使得多个节点从相同的初始状态开始，按顺序执行相同的命令，转移到相同的状态。容易看出，复制状态机的关键点是如何让每个状态机就提交顺序达成一致。因此，分布式共识协议常被用作在复制状态机的上下文中。<br>复制状态机中向所有节点同步的内容是操作本身，我们可以理解为同步的是某个值的增量。与复制状态机相对应的是在ZAB等协议中常出现的primary backup system，它向所有节点同步的是操作的结果，我们可以认为同步的是值本身。<a href="https://zhuanlan.zhihu.com/p/30856272" target="_blank" rel="noopener">容易看出RSM的设计使得我们回滚操作变得简单，仅仅删除掉后面的日志即可，但不好的地方在于RSM往往需要比PBS系统较多的日志条目，因为PBS可以只保存对状态机有修改的操作</a>。<br><img src="/img/fbs/fzztj.jpg"></p>
<p>基于RSM的日志复制形式是State-machine replication，<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/HPSMR.pdf" target="_blank" rel="noopener">能够实现FT</a>。<a href="https://en.wikipedia.org/wiki/State_machine_replication" target="_blank" rel="noopener">通常地</a>，一个支持F个（独立随机的）故障的系统需要<code>2F+1</code>个replica，对于Fail-Stop情况，即故障的系统保证不产生任何输出时，只需要<code>F+1</code>个replica即可。特别地，对于拜占庭故障，即某个节点向不同方向发送不同值的情况下，根据消息是否加密验证需要<code>2F+1</code>和<code>3F+1</code>个replica。</p>
<p>通常的SMR的实现是串行的，即每一个SMR的副本以单线程的形式处理<a href="https://alexstocks.github.io/html/etcd.html" target="_blank" rel="noopener">Propose-Append-Broadcast-Apply</a>的过程，只有当客户A的请求Apply之后，才能继续处理客户B的Propose。事实上，SMR的一个实现细节就是为所有的输入选择一个特定的顺序，注意到现实中的输入是偏序的，但SMR要求一个全序(total order)的输入。<a href="https://en.wikipedia.org/wiki/State_machine_replication" target="_blank" rel="noopener">这样每一个非故障的副本才能在同样的状态通过同样的输入到达同样的结果</a>。</p>
<p>Pipeline是对串行方式SMR的一个优化，即<a href="https://zhuanlan.zhihu.com/p/30043911" target="_blank" rel="noopener">使用一个线程接收请求，一个线程处理请求，一个线程响应客户端</a>。</p>
<p>分布式共识算法被用来解决SMR中存在的问题，例如如何选主，如何处理网络分区等，常见的分布式共识算法包括Paxos和Raft等。这里的共识(Consensus)指的是<a href="https://en.wikipedia.org/wiki/State_machine_replication" target="_blank" rel="noopener">由一系列独立的实体为一个值进行投票</a>。</p>
<h2 id="2PC、RWN、Paxos等算法的区别"><a href="#2PC、RWN、Paxos等算法的区别" class="headerlink" title="2PC、RWN、Paxos等算法的区别"></a>2PC、RWN、Paxos等算法的区别</h2><p>首先从设计上讲2PC和Paxos之流就奔着不同的目标而去。诸如2PC之类的协议是为了实现分布式事务，因此它涉及到的是对多个值修改的ACID性质，而分布式共识协议是为了管理一个值的多个replica。<a href="https://www.zhihu.com/question/266759495/answer/312931690" target="_blank" rel="noopener">例如</a>，我们可以认为2PC针对多个Partition，而共识算法针对于多个Replication。</p>
<p>再从可用性上考虑，分布式共识协议是为了维护复制状态机，即通过Leader保证复制状态机的输入是全序(total order的)，从而可以通过复制状态机保证各个节点上的日志是一致的。进一步地，共识协议提供了Leader宕机情况下的选主策略，从而保证了集群的HA。特别注意到在这里，2PC算法中的Leader，也就是协调者在宕机之后集群会整体阻塞，而利用分布式共识算法实现选主策略之后能够极大程度避免这一点。</p>
<p><a href="http://matt33.com/2018/07/08/distribute-system-consistency-protocol/" target="_blank" rel="noopener">从CAP理论</a>上来讲，2PC是CA的，它要求所有节点保持全体一致。诸如Paxos的Quorum类算法是CP的，它仅要求实现多数一致。RWN是AP的，因此它实现的是可调一致性而不是强一致性。</p>
<h2 id="常见的共识算法介绍"><a href="#常见的共识算法介绍" class="headerlink" title="常见的共识算法介绍"></a>常见的共识算法介绍</h2><h3 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h3><p>出于篇幅限制，有关Raft已经移到新文章<a href="/2019/03/12/raft-algorithm/">Raft共识算法</a>中。</p>
<h3 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h3><p>出于篇幅限制，有关Paxos已经移到新文章<a href="/2021/01/06/paxos/">Paxos算法</a>中。</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>除去在原文中标注引用的内容外，本文还参考了一下内容：</p>
<ol>
<li>DDIA</li>
<li>本文中提到的所有概念的原论文，例如FLP定理等。</li>
<li>Staring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores</li>
<li>High Performance MySQL, 3rd edition</li>
<li>Zookeepers’s atomic broadcast protocol: Theory and practice</li>
<li>ZooKeeper: Wait-free coordination for Internet-scale systems</li>
<li>A simple totally ordered broadcast protocol</li>
<li><a href="http://duanple.com/" target="_blank" rel="noopener">http://duanple.com/</a></li>
<li><a href="https://danielw.cn/FLP-proof" target="_blank" rel="noopener">https://danielw.cn/FLP-proof</a></li>
<li><a href="https://www.cnblogs.com/firstdream/p/6585923.html" target="_blank" rel="noopener">https://www.cnblogs.com/firstdream/p/6585923.html</a></li>
<li><a href="http://loopjump.com/flp_proof_note/" target="_blank" rel="noopener">http://loopjump.com/flp_proof_note/</a></li>
<li><a href="https://www.cnblogs.com/grefr/p/6087942.html" target="_blank" rel="noopener">https://www.cnblogs.com/grefr/p/6087942.html</a></li>
<li><a href="https://www.bilibili.com/video/BV17A411W7Cr?p=12" target="_blank" rel="noopener">https://www.bilibili.com/video/BV17A411W7Cr?p=12</a></li>
<li><a href="https://danielw.cn/history-of-distributed-systems-5" target="_blank" rel="noopener">https://danielw.cn/history-of-distributed-systems-5</a></li>
<li><a href="http://yang.observer/2020/07/11/time-ntp/" target="_blank" rel="noopener">http://yang.observer/2020/07/11/time-ntp/</a><br> 介绍计算机中的时钟</li>
<li>Time, Clocks, and the Ordering of Events in a Distributed System<br> Lamport的有关分布式时钟的论文</li>
<li><a href="https://zhuanlan.zhihu.com/p/56886156" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/56886156</a><br> 对向量时钟的一个讲解</li>
<li><a href="https://writings.sh/post/logical-clocks" target="_blank" rel="noopener">https://writings.sh/post/logical-clocks</a><br> 同样是对逻辑时钟的讲解，我这边摘录了他的几幅图</li>
<li><a href="https://www.raychase.net/5768" target="_blank" rel="noopener">https://www.raychase.net/5768</a><br> 用了其中的图和某个case</li>
</ol>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div></div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/img/fkm/wxfk.jpg" alt="Calvin Neo WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/img/fkm/zfbfk.jpg" alt="Calvin Neo Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/分布式/" rel="tag"># 分布式</a>
          
            <a href="/tags/paxos/" rel="tag"># paxos</a>
          
            <a href="/tags/raft/" rel="tag"># raft</a>
          
            <a href="/tags/一致性/" rel="tag"># 一致性</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/08/20/黄山游记/" rel="next" title="黄山游记">
                <i class="fa fa-chevron-left"></i> 黄山游记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/09/20/transaction/" rel="prev" title="数据库系统中的事务">
                数据库系统中的事务 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/favicon.jpg"
               alt="Calvin Neo" />
          <p class="site-author-name" itemprop="name">Calvin Neo</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">169</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">161</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/CalvinNeo" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/CalvinNeo0" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/1568200035" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://xqq.im/" title="xqq" target="_blank">xqq</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.lovelywen.com/" title="wenwen" target="_blank">wenwen</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://smlight.github.io/blog/" title="zyyyyy" target="_blank">zyyyyy</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#分布式系统的相关性能要求"><span class="nav-number">1.</span> <span class="nav-text">分布式系统的相关性能要求</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#可用性和可靠性"><span class="nav-number">1.1.</span> <span class="nav-text">可用性和可靠性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#高可用性HA与容错FT"><span class="nav-number">1.1.1.</span> <span class="nav-text">高可用性HA与容错FT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Failure-detector"><span class="nav-number">1.1.2.</span> <span class="nav-text">Failure detector</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安全性"><span class="nav-number">1.2.</span> <span class="nav-text">安全性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#可维护性"><span class="nav-number">1.3.</span> <span class="nav-text">可维护性</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分布式系统模型"><span class="nav-number">2.</span> <span class="nav-text">分布式系统模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#网络行为假设"><span class="nav-number">2.1.</span> <span class="nav-text">网络行为假设</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#节点行为假设"><span class="nav-number">2.2.</span> <span class="nav-text">节点行为假设</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#同步假设"><span class="nav-number">2.3.</span> <span class="nav-text">同步假设</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分布式系统上的数据存储"><span class="nav-number">3.</span> <span class="nav-text">分布式系统上的数据存储</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#复制-replicate"><span class="nav-number">3.1.</span> <span class="nav-text">复制(replicate)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#一个最原始的系统"><span class="nav-number">3.1.1.</span> <span class="nav-text">一个最原始的系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#主动复制和被动复制"><span class="nav-number">3.1.2.</span> <span class="nav-text">主动复制和被动复制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Single-Leader架构（主从复制）"><span class="nav-number">3.1.3.</span> <span class="nav-text">Single Leader架构（主从复制）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Push和Pull"><span class="nav-number">3.1.3.1.</span> <span class="nav-text">Push和Pull</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#处理集群成员变更"><span class="nav-number">3.1.3.2.</span> <span class="nav-text">处理集群成员变更</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#处理宕机"><span class="nav-number">3.1.3.3.</span> <span class="nav-text">处理宕机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#日志复制"><span class="nav-number">3.1.3.4.</span> <span class="nav-text">日志复制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#同步复制和异步复制"><span class="nav-number">3.1.3.5.</span> <span class="nav-text">同步复制和异步复制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#一致性问题"><span class="nav-number">3.1.3.6.</span> <span class="nav-text">一致性问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multi-Leader架构"><span class="nav-number">3.1.4.</span> <span class="nav-text">Multi Leader架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Leaderless架构"><span class="nav-number">3.1.5.</span> <span class="nav-text">Leaderless架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#链式复制"><span class="nav-number">3.1.6.</span> <span class="nav-text">链式复制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#级联复制"><span class="nav-number">3.1.7.</span> <span class="nav-text">级联复制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#partition"><span class="nav-number">3.2.</span> <span class="nav-text">partition</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#一致性Hash"><span class="nav-number">3.2.1.</span> <span class="nav-text">一致性Hash</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#雪崩问题"><span class="nav-number">3.2.1.1.</span> <span class="nav-text">雪崩问题</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分布式集群"><span class="nav-number">3.3.</span> <span class="nav-text">分布式集群</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#缓存"><span class="nav-number">3.4.</span> <span class="nav-text">缓存</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存双写"><span class="nav-number">3.4.1.</span> <span class="nav-text">缓存双写</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存雪崩、穿透和击穿"><span class="nav-number">3.4.2.</span> <span class="nav-text">缓存雪崩、穿透和击穿</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#并发竞争写"><span class="nav-number">3.4.3.</span> <span class="nav-text">并发竞争写</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存Demo：Redis"><span class="nav-number">3.4.4.</span> <span class="nav-text">缓存Demo：Redis</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Redis内存淘汰机制"><span class="nav-number">3.4.4.1.</span> <span class="nav-text">Redis内存淘汰机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Redis主从模式"><span class="nav-number">3.4.4.2.</span> <span class="nav-text">Redis主从模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Redis集群模式"><span class="nav-number">3.4.4.3.</span> <span class="nav-text">Redis集群模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#生产环境下的Redis部署"><span class="nav-number">3.4.4.4.</span> <span class="nav-text">生产环境下的Redis部署</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Redis持久化方式"><span class="nav-number">3.4.4.5.</span> <span class="nav-text">Redis持久化方式</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分布式系统上的一致性和Order"><span class="nav-number">4.</span> <span class="nav-text">分布式系统上的一致性和Order</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#强一致性"><span class="nav-number">4.1.</span> <span class="nav-text">强一致性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#辨析Linearizability、Serializability"><span class="nav-number">4.1.1.</span> <span class="nav-text">辨析Linearizability、Serializability</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实现External-Consistency"><span class="nav-number">4.1.2.</span> <span class="nav-text">实现External Consistency</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#弱一致性"><span class="nav-number">4.2.</span> <span class="nav-text">弱一致性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#最终一致性"><span class="nav-number">4.2.1.</span> <span class="nav-text">最终一致性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#读己所写一致性"><span class="nav-number">4.2.2.</span> <span class="nav-text">读己所写一致性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#会话一致性"><span class="nav-number">4.2.3.</span> <span class="nav-text">会话一致性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单调读一致性"><span class="nav-number">4.2.4.</span> <span class="nav-text">单调读一致性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一致前缀读"><span class="nav-number">4.2.5.</span> <span class="nav-text">一致前缀读</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#有界旧一致性"><span class="nav-number">4.2.6.</span> <span class="nav-text">有界旧一致性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#可调一致性"><span class="nav-number">4.2.7.</span> <span class="nav-text">可调一致性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#因果-Causal-一致性"><span class="nav-number">4.2.8.</span> <span class="nav-text">因果(Causal)一致性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#因果-Causal-一致性和逻辑时钟"><span class="nav-number">4.2.9.</span> <span class="nav-text">因果(Causal)一致性和逻辑时钟</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Lamport时钟的缺点"><span class="nav-number">4.2.9.1.</span> <span class="nav-text">Lamport时钟的缺点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#计算机中的时钟"><span class="nav-number">4.3.</span> <span class="nav-text">计算机中的时钟</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#NTP"><span class="nav-number">4.3.1.</span> <span class="nav-text">NTP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lamport-Clock"><span class="nav-number">4.3.2.</span> <span class="nav-text">Lamport Clock</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Vector-Clock-VC"><span class="nav-number">4.3.3.</span> <span class="nav-text">Vector Clock(VC)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#vector-clocks-ordering"><span class="nav-number">4.3.3.1.</span> <span class="nav-text">vector clocks ordering</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#规则"><span class="nav-number">4.3.3.2.</span> <span class="nav-text">规则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#应用：判断因果关系"><span class="nav-number">4.3.3.3.</span> <span class="nav-text">应用：判断因果关系</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#推广和证明"><span class="nav-number">4.3.3.4.</span> <span class="nav-text">推广和证明</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#和Lamport-Clock比较"><span class="nav-number">4.3.3.5.</span> <span class="nav-text">和Lamport Clock比较</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#能不能只用Vector-Clock呢？"><span class="nav-number">4.3.3.6.</span> <span class="nav-text">能不能只用Vector Clock呢？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TrueTime"><span class="nav-number">4.3.4.</span> <span class="nav-text">TrueTime</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#混合时钟"><span class="nav-number">4.3.5.</span> <span class="nav-text">混合时钟</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#广播和全序广播"><span class="nav-number">4.4.</span> <span class="nav-text">广播和全序广播</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#各类广播的实现"><span class="nav-number">4.4.1.</span> <span class="nav-text">各类广播的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#reliable"><span class="nav-number">4.4.1.1.</span> <span class="nav-text">reliable</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FIFO"><span class="nav-number">4.4.1.2.</span> <span class="nav-text">FIFO</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Causal"><span class="nav-number">4.4.1.3.</span> <span class="nav-text">Causal</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Total-Order"><span class="nav-number">4.4.1.4.</span> <span class="nav-text">Total Order</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#可用性"><span class="nav-number">4.5.</span> <span class="nav-text">可用性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分区容错性"><span class="nav-number">4.6.</span> <span class="nav-text">分区容错性</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分布式事务"><span class="nav-number">5.</span> <span class="nav-text">分布式事务</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2PC和3PC"><span class="nav-number">5.1.</span> <span class="nav-text">2PC和3PC</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TCC"><span class="nav-number">5.2.</span> <span class="nav-text">TCC</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分布式锁"><span class="nav-number">5.3.</span> <span class="nav-text">分布式锁</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#通过Redis实现分布式锁"><span class="nav-number">5.3.1.</span> <span class="nav-text">通过Redis实现分布式锁</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分布式共识"><span class="nav-number">6.</span> <span class="nav-text">分布式共识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#分布式共识的特性"><span class="nav-number">6.1.</span> <span class="nav-text">分布式共识的特性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FLP定理"><span class="nav-number">6.2.</span> <span class="nav-text">FLP定理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#拜占庭将军问题"><span class="nav-number">6.3.</span> <span class="nav-text">拜占庭将军问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CAP理论"><span class="nav-number">6.4.</span> <span class="nav-text">CAP理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#复制状态机"><span class="nav-number">6.5.</span> <span class="nav-text">复制状态机</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2PC、RWN、Paxos等算法的区别"><span class="nav-number">6.6.</span> <span class="nav-text">2PC、RWN、Paxos等算法的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#常见的共识算法介绍"><span class="nav-number">6.7.</span> <span class="nav-text">常见的共识算法介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Raft"><span class="nav-number">6.7.1.</span> <span class="nav-text">Raft</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Paxos"><span class="nav-number">6.7.2.</span> <span class="nav-text">Paxos</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">7.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Calvin Neo</span>
  <span> &nbsp; Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a></span>
</div>
<div>
  <span><a href="/about/yytl/">版权声明</a></span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse 
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://www.calvinneo.com/2017/09/20/distributed-system-consistency-and-consensus/';
          this.page.identifier = '2017/09/20/distributed-system-consistency-and-consensus/';
          this.page.title = '分布式一致性和分布式共识协议';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://calvinneo.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  








  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      $('#local-search-input').focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
