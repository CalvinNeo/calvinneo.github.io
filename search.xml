<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[概率论中的几个有趣问题]]></title>
    <url>%2F2021%2F05%2F15%2Fprobability-problems%2F</url>
    <content type="text"><![CDATA[本文介绍概率论中一些有趣的问题，其中很多是反直觉的 三门问题两个男孩基本比率谬误假设同性恋染上某病的概率是异性恋的9倍。已知小明染上某病，求小明同性恋的概率。错误的答案是$\frac{9}{10}$。正确答案是无法计算，因为我们并不知道同性恋和异性恋的比例。 令同性恋是$S$，异性恋是$H$，患某病是$X$。已知 $$P(X|S) = 9 \quad P(X|H)$$ 求$P(S|X)$ 我们计算 $$P(S|X) = \frac{P(S)P(X|S)}{P(X)}$$ 我们考虑另一个问题，我们统计篮球比赛中两个球员的三分球和二分球命中率，假如A的三分球命中率比B高，二分球命中率也比B高，那么A的总命中率比B高么？答案是不确定。我们不如考虑下面这个极端情况： A的二分球命中率是100\%，B的是99\% A的三分球命中率是1\%，B的是0\% 那B说好的，我田忌赛马了，我就直投二分球，你A只投三分球。结果B的总命中率是99\%，而A的是1\%。 婚姻/秘书问题或者博士后问题我们在海滩捡贝壳，必须在捡贝壳的时候决定留不留下，并且只有一次选择留下的机会，问如何最大化选到最佳贝壳的概率。 贝特朗悖论凯利公式Refernce https://blog.csdn.net/itnerd/article/details/107348933 https://zh.wikipedia.org/wiki/%E5%9F%BA%E6%9C%AC%E6%AF%94%E7%8E%87%E8%AC%AC%E8%AA%A4 https://www.zhihu.com/question/330408241]]></content>
      <tags>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis主从复制]]></title>
    <url>%2F2021%2F05%2F15%2Fredis-replication%2F</url>
    <content type="text"><![CDATA[在Redis Sentinel实现原理分析这篇文。Sentinel是为主从复制服务的，所以在这篇文章里面，我们反过来讲一下主从复制的实现。 主从复制涉及到RDB等机制，其中持久化部分在Redis持久化机制实现中介绍。 Redis主从复制流程简介Redis Sentinel是对主从复制流程而言的，所以我们先要理解主从复制的大概流程。这里需要注意，主从复制并不是Redis Cluster。 Slave接受到SLAVEOF命令 Slave连接Master Slave PING Master 鉴权 Slave发送SYNC/PSYNC命令 PSYNC命令用法PSYNC命令如下所示，其中： replicationid表示我们断线重连前Master服务器的id offset表示Slave接受到最后命令的偏移量，以字节计算 1234// 旧PSYNC runid offset// 新PSYNC replicationid offset 这里还有个特殊用法，表示我们要触发一次全量复制。1PSYNC ? -1 在Redis 2.8后，提供了PSYNC，这个命令能够支持全量复制和部分复制。这样在Slave断线重连之后，就可以部分复制，从而节省Master的计算资源和带宽。在Redis 4.0版本后，优化了增量复制，主要包括： 重启后，也可以进行部分复制 之前这种情况，重启后会丢失runid，从而触发PSYNC ? -1 当Slave被promote称为Master后，其他Slave可以从新Master处复制 主要流程主要类以及常数在服务器类中定义了masterhost，表示Master节点的地址。如果是NULL，表示自己就是Master。所以这个字段会被用来判断是MAster还是Slave。1234567// server.hstruct redisServer &#123; char *masteruser; /* AUTH with this user and masterauth with master */ char *masterauth; /* AUTH with this password with master */ char *masterhost; /* Hostname of master */ int masterport; /* Port of master */&#125; 介绍下repl_state的状态： REPL_STATE_NONE 0 表示现在是SLAVEOF NO ONE的 REPL_STATE_CONNECT 1 在replicationCron判断，如果处于这个状态，表示现在要去尝试连接Master了。 REPL_STATE_CONNECTING 2 下面的状态是握手过程中的状态： REPL_STATE_RECEIVE_PONG 3 REPL_STATE_SEND_AUTH 4 REPL_STATE_RECEIVE_AUTH 5 REPL_STATE_SEND_PORT 6 REPL_STATE_RECEIVE_PORT 7 REPL_STATE_SEND_IP 8 REPL_STATE_RECEIVE_IP 9 REPL_STATE_SEND_CAPA 10 REPL_STATE_RECEIVE_CAPA 11 REPL_STATE_SEND_PSYNC 12 REPL_STATE_RECEIVE_PSYNC 13 下面状态是握手完毕的状态： REPL_STATE_TRANSFER 14 REPL_STATE_CONNECTED 15 连接建立流程 connectWithMaster Full Sync流程Partial Sync流程代码解释 Slave部分connectWithMaster: 建立套接口连接connConnect系列函数，以及connection类封装了有关网络连接的库。实际上connConnect通过anetTcpNonBlockBestEffortBindConnect尝试建立一个非阻塞的套接字，此时connect函数可能返回EINPROGRESS表示连接还在建立过程中，但我们其实可以不用等。通过aeCreateFileEvent将这个Socket描述符加入到事件循环里面，等到这个套接字可以写之后，会触发对应的回调。等到连接建立后，回调会通过connSocketEventHandler被唤起。1234567891011121314151617int connectWithMaster(void) &#123; server.repl_transfer_s = server.tls_replication ? connCreateTLS() : connCreateSocket(); if (connConnect(server.repl_transfer_s, server.masterhost, server.masterport, NET_FIRST_BIND_ADDR, syncWithMaster) == C_ERR) &#123; serverLog(LL_WARNING,"Unable to connect to MASTER: %s", connGetLastError(server.repl_transfer_s)); connClose(server.repl_transfer_s); server.repl_transfer_s = NULL; return C_ERR; &#125; server.repl_transfer_lastio = server.unixtime; server.repl_state = REPL_STATE_CONNECTING; serverLog(LL_NOTICE,"MASTER &lt;-&gt; REPLICA sync started"); return C_OK;&#125; syncWithMaster: 握手以及准备传输RDB在连接完毕后，connectWithMaster会回调syncWithMaster，此时状态是REPL_STATE_CONNECTING。1234void syncWithMaster(connection *conn) &#123; char tmpfile[256], *err = NULL; int dfd = -1, maxtries = 5; int psync_result; 检查一下，如果现在又是SLAVEOF NO ONE了，就把这个连接关掉。123456/* If this event fired after the user turned the instance into a master * with SLAVEOF NO ONE we must just return ASAP. */if (server.repl_state == REPL_STATE_NONE) &#123; connClose(conn); return;&#125; 因为是非阻塞的连接，所以我们要检查一下现在连接的状态。如果失败，就goto error，里面内容是重置状态，例如，server.repl_state会被重置为REPL_STATE_CONNECT。1234567/* Check for errors in the socket: after a non blocking connect() we * may find that the socket is in error state. */if (connGetState(conn) != CONN_STATE_CONNECTED) &#123; serverLog(LL_WARNING,"Error condition on socket for SYNC: %s", connGetLastError(conn)); goto error;&#125; 下面是一个状态机的实现。我们在Sentinel中已经见过类似的了，Redis中状态机的实现就是，对于状态X，表示状态X前一个状态已经处理完了，目前正在处理状态X的工作。当状态机处理完一个状态后，在最后将状态设置为下一个要做的事情。也就是我们不用类似X_FINISHED这样的状态，因为X_FINISHED根据完成的情形不同，可能有多种状态转移。【REPL_STATE_CONNECTING】这个状态下，我们尝试发送一个同步命令PING，然后直接修改状态到REPL_STATE_RECEIVE_PONG。如果这个同步命令发送有问题，就直接goto error了，不会走到下面流程。1234567891011121314/* Send a PING to check the master is able to reply without errors. */if (server.repl_state == REPL_STATE_CONNECTING) &#123; serverLog(LL_NOTICE,"Non blocking connect for SYNC fired the event."); /* Delete the writable event so that the readable event remains * registered and we can wait for the PONG reply. */ connSetReadHandler(conn, syncWithMaster); connSetWriteHandler(conn, NULL); server.repl_state = REPL_STATE_RECEIVE_PONG; /* Send the PING, don't check for errors at all, we have the timeout * that will take care about this. */ err = sendSynchronousCommand(SYNC_CMD_WRITE,conn,"PING",NULL); if (err) goto write_error; return;&#125; 【REPL_STATE_RECEIVE_PONG】我们只要收到对PING的回复，就进入了REPL_STATE_RECEIVE_PONG状态，但这个回复未必是PONG，也可能是一个AUTH错误。123456789101112131415161718192021222324/* Receive the PONG command. */if (server.repl_state == REPL_STATE_RECEIVE_PONG) &#123; err = sendSynchronousCommand(SYNC_CMD_READ,conn,NULL); /* We accept only two replies as valid, a positive +PONG reply * (we just check for "+") or an authentication error. * Note that older versions of Redis replied with "operation not * permitted" instead of using a proper error code, so we test * both. */ if (err[0] != '+' &amp;&amp; strncmp(err,"-NOAUTH",7) != 0 &amp;&amp; strncmp(err,"-NOPERM",7) != 0 &amp;&amp; strncmp(err,"-ERR operation not permitted",28) != 0) &#123; serverLog(LL_WARNING,"Error reply to PING from master: '%s'",err); sdsfree(err); goto error; &#125; else &#123; serverLog(LL_NOTICE, "Master replied to PING, replication can continue..."); &#125; sdsfree(err); server.repl_state = REPL_STATE_SEND_AUTH;&#125; 【REPL_STATE_SEND_AUTH】如果需要AUTH认证，我们就发送AUTH，进入REPL_STATE_RECEIVE_AUTH。否则直接进入REPL_STATE_SEND_PORT。1234567891011121314151617/* AUTH with the master if required. */if (server.repl_state == REPL_STATE_SEND_AUTH) &#123; if (server.masteruser &amp;&amp; server.masterauth) &#123; err = sendSynchronousCommand(SYNC_CMD_WRITE,conn,"AUTH", server.masteruser,server.masterauth,NULL); if (err) goto write_error; server.repl_state = REPL_STATE_RECEIVE_AUTH; return; &#125; else if (server.masterauth) &#123; err = sendSynchronousCommand(SYNC_CMD_WRITE,conn,"AUTH",server.masterauth,NULL); if (err) goto write_error; server.repl_state = REPL_STATE_RECEIVE_AUTH; return; &#125; else &#123; server.repl_state = REPL_STATE_SEND_PORT; &#125;&#125; 【REPL_STATE_RECEIVE_AUTH】如果验证通过，就进入REPL_STATE_SEND_PORT。1234567891011/* Receive AUTH reply. */if (server.repl_state == REPL_STATE_RECEIVE_AUTH) &#123; err = sendSynchronousCommand(SYNC_CMD_READ,conn,NULL); if (err[0] == '-') &#123; serverLog(LL_WARNING,"Unable to AUTH to MASTER: %s",err); sdsfree(err); goto error; &#125; sdsfree(err); server.repl_state = REPL_STATE_SEND_PORT;&#125; 【REPL_STATE_SEND_PORT】下面一步，我们需要发送我们当前的端口，进入REPL_STATE_RECEIVE_PORT状态。在发送完之后，我们在主节点执行INFO replication，会在其中显示我们反馈的port。【Q】slave_announce_port和port的区别是什么？12345678910111213141516/* Set the slave port, so that Master's INFO command can list the * slave listening port correctly. */if (server.repl_state == REPL_STATE_SEND_PORT) &#123; int port; if (server.slave_announce_port) port = server.slave_announce_port; else if (server.tls_replication &amp;&amp; server.tls_port) port = server.tls_port; else port = server.port; sds portstr = sdsfromlonglong(port); err = sendSynchronousCommand(SYNC_CMD_WRITE,conn,"REPLCONF", "listening-port",portstr, NULL); sdsfree(portstr); if (err) goto write_error; sdsfree(err); server.repl_state = REPL_STATE_RECEIVE_PORT; return;&#125; 【REPL_STATE_RECEIVE_PORT】接下来，我们用类似的办法发送IP，这里注意，如果没有指定slave_announce_ip就直接跳转到REPL_STATE_SEND_CAPA，否则跳转到REPL_STATE_SEND_IP。12345678910111213141516171819202122232425262728293031323334353637383940414243/* Receive REPLCONF listening-port reply. */if (server.repl_state == REPL_STATE_RECEIVE_PORT) &#123; err = sendSynchronousCommand(SYNC_CMD_READ,conn,NULL); /* Ignore the error if any, not all the Redis versions support * REPLCONF listening-port. */ if (err[0] == '-') &#123; serverLog(LL_NOTICE,"(Non critical) Master does not understand " "REPLCONF listening-port: %s", err); &#125; sdsfree(err); server.repl_state = REPL_STATE_SEND_IP;&#125;/* Skip REPLCONF ip-address if there is no slave-announce-ip option set. */if (server.repl_state == REPL_STATE_SEND_IP &amp;&amp; server.slave_announce_ip == NULL)&#123; server.repl_state = REPL_STATE_SEND_CAPA;&#125;/* Set the slave ip, so that Master's INFO command can list the * slave IP address port correctly in case of port forwarding or NAT. */if (server.repl_state == REPL_STATE_SEND_IP) &#123; err = sendSynchronousCommand(SYNC_CMD_WRITE,conn,"REPLCONF", "ip-address",server.slave_announce_ip, NULL); if (err) goto write_error; sdsfree(err); server.repl_state = REPL_STATE_RECEIVE_IP; return;&#125;/* Receive REPLCONF ip-address reply. */if (server.repl_state == REPL_STATE_RECEIVE_IP) &#123; err = sendSynchronousCommand(SYNC_CMD_READ,conn,NULL); /* Ignore the error if any, not all the Redis versions support * REPLCONF listening-port. */ if (err[0] == '-') &#123; serverLog(LL_NOTICE,"(Non critical) Master does not understand " "REPLCONF ip-address: %s", err); &#125; sdsfree(err); server.repl_state = REPL_STATE_SEND_CAPA;&#125; 【REPL_STATE_SEND_CAPA】发送IP的过程很类似，我们就不说了。下面这一对状态是REPL_STATE_SEND_CAPA，用来发送Slave的容量。这一对状态结束之后，进入REPL_STATE_SEND_PSYNC状态。【Q】这个容量指的是什么？123456789101112131415161718192021222324252627/* Inform the master of our (slave) capabilities. * * EOF: supports EOF-style RDB transfer for diskless replication. * PSYNC2: supports PSYNC v2, so understands +CONTINUE &lt;new repl ID&gt;. * * The master will ignore capabilities it does not understand. */if (server.repl_state == REPL_STATE_SEND_CAPA) &#123; err = sendSynchronousCommand(SYNC_CMD_WRITE,conn,"REPLCONF", "capa","eof","capa","psync2",NULL); if (err) goto write_error; sdsfree(err); server.repl_state = REPL_STATE_RECEIVE_CAPA; return;&#125;/* Receive CAPA reply. */if (server.repl_state == REPL_STATE_RECEIVE_CAPA) &#123; err = sendSynchronousCommand(SYNC_CMD_READ,conn,NULL); /* Ignore the error if any, not all the Redis versions support * REPLCONF capa. */ if (err[0] == '-') &#123; serverLog(LL_NOTICE,"(Non critical) Master does not understand " "REPLCONF capa: %s", err); &#125; sdsfree(err); server.repl_state = REPL_STATE_SEND_PSYNC;&#125; 【REPL_STATE_SEND_PSYNC】下面，我们尝试PSYNC。主要就是调用若干次slaveTryPartialResynchronization：第一次传0进去，让它发PSYNC指令，并且设置状态为REPL_STATE_RECEIVE_PSYNC；后面就不断地传1进去，查询结果。1234567891011121314151617181920212223/* Try a partial resynchonization. If we don't have a cached master * slaveTryPartialResynchronization() will at least try to use PSYNC * to start a full resynchronization so that we get the master run id * and the global offset, to try a partial resync at the next * reconnection attempt. */if (server.repl_state == REPL_STATE_SEND_PSYNC) &#123; if (slaveTryPartialResynchronization(conn,0) == PSYNC_WRITE_ERROR) &#123; err = sdsnew("Write error sending the PSYNC command."); goto write_error; &#125; server.repl_state = REPL_STATE_RECEIVE_PSYNC; return;&#125;/* If reached this point, we should be in REPL_STATE_RECEIVE_PSYNC. */if (server.repl_state != REPL_STATE_RECEIVE_PSYNC) &#123; serverLog(LL_WARNING,"syncWithMaster(): state machine error, " "state should be RECEIVE_PSYNC but is %d", server.repl_state); goto error;&#125;psync_result = slaveTryPartialResynchronization(conn,1); 下面查看返回值1234567891011121314151617181920212223242526if (psync_result == PSYNC_WAIT_REPLY) return; /* Try again later... *//* If the master is in an transient error, we should try to PSYNC * from scratch later, so go to the error path. This happens when * the server is loading the dataset or is not connected with its * master and so forth. */if (psync_result == PSYNC_TRY_LATER) goto error;/* Note: if PSYNC does not return WAIT_REPLY, it will take care of * uninstalling the read handler from the file descriptor. */if (psync_result == PSYNC_CONTINUE) &#123; serverLog(LL_NOTICE, "MASTER &lt;-&gt; REPLICA sync: Master accepted a Partial Resynchronization."); if (server.supervised_mode == SUPERVISED_SYSTEMD) &#123; redisCommunicateSystemd("STATUS=MASTER &lt;-&gt; REPLICA sync: Partial Resynchronization accepted. Ready to accept connections.\n"); redisCommunicateSystemd("READY=1\n"); &#125; return;&#125;/* PSYNC failed or is not supported: we want our slaves to resync with us * as well, if we have any sub-slaves. The master may transfer us an * entirely different data set and we have no way to incrementally feed * our slaves after that. */disconnectSlaves(); /* Force our slaves to resync with us as well. */freeReplicationBacklog(); /* Don't allow our chained slaves to PSYNC. */ 如果PSYNC能支持，我们前面就返回了，下面对于不支持的情况，我们就得用老的SYNC方法。在开始传输后，进入REPL_STATE_TRANSFER状态。1234567891011/* Fall back to SYNC if needed. Otherwise psync_result == PSYNC_FULLRESYNC * and the server.master_replid and master_initial_offset are * already populated. */if (psync_result == PSYNC_NOT_SUPPORTED) &#123; serverLog(LL_NOTICE,"Retrying with SYNC..."); if (connSyncWrite(conn,"SYNC\r\n",6,server.repl_syncio_timeout*1000) == -1) &#123; serverLog(LL_WARNING,"I/O error writing to MASTER: %s", strerror(errno)); goto error; &#125;&#125; 如果不支持无盘加载，那么就要在磁盘上创建一个临时文件。查看函数useDisklessLoad，无盘加载需要满足： repl_diskless_load配置 所有的模块都能处理读错误 12345678910111213141516/* Prepare a suitable temp file for bulk transfer */if (!useDisklessLoad()) &#123; while(maxtries--) &#123; snprintf(tmpfile,256, "temp-%d.%ld.rdb",(int)server.unixtime,(long int)getpid()); dfd = open(tmpfile,O_CREAT|O_WRONLY|O_EXCL,0644); if (dfd != -1) break; sleep(1); &#125; if (dfd == -1) &#123; serverLog(LL_WARNING,"Opening the temp file needed for MASTER &lt;-&gt; REPLICA synchronization: %s",strerror(errno)); goto error; &#125; server.repl_transfer_tmpfile = zstrdup(tmpfile); server.repl_transfer_fd = dfd;&#125; 下面非阻塞地进行SYNC，设置读取SYNC数据的回调readSyncBulkPayload，如果成功就切换状态为REPL_STATE_TRANSFER。这里，我们设置了repl_transfer_size为1，1234567891011121314151617/* Setup the non blocking download of the bulk file. */if (connSetReadHandler(conn, readSyncBulkPayload) == C_ERR)&#123; char conninfo[CONN_INFO_LEN]; serverLog(LL_WARNING, "Can't create readable event for SYNC: %s (%s)", strerror(errno), connGetInfo(conn, conninfo, sizeof(conninfo))); goto error;&#125;server.repl_state = REPL_STATE_TRANSFER;server.repl_transfer_size = -1;server.repl_transfer_read = 0;server.repl_transfer_last_fsync_off = 0;server.repl_transfer_lastio = server.unixtime;return; 下面是错误处理，需要将状态重置为等待连接的REPL_STATE_CONNECT。123456789101112131415161718error: if (dfd != -1) close(dfd); connClose(conn); server.repl_transfer_s = NULL; if (server.repl_transfer_fd != -1) close(server.repl_transfer_fd); if (server.repl_transfer_tmpfile) zfree(server.repl_transfer_tmpfile); server.repl_transfer_tmpfile = NULL; server.repl_transfer_fd = -1; server.repl_state = REPL_STATE_CONNECT; return;write_error: /* Handle sendSynchronousCommand(SYNC_CMD_WRITE) errors. */ serverLog(LL_WARNING,"Sending command to master in replication handshake: %s", err); sdsfree(err); goto error;&#125; slaveTryPartialResynchronization: PSYNC分支123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* Try a partial resynchronization with the master if we are about to reconnect. * If there is no cached master structure, at least try to issue a * "PSYNC ? -1" command in order to trigger a full resync using the PSYNC * command in order to obtain the master run id and the master replication * global offset. * * This function is designed to be called from syncWithMaster(), so the * following assumptions are made: * * 1) We pass the function an already connected socket "fd". * 2) This function does not close the file descriptor "fd". However in case * of successful partial resynchronization, the function will reuse * 'fd' as file descriptor of the server.master client structure. * * The function is split in two halves: if read_reply is 0, the function * writes the PSYNC command on the socket, and a new function call is * needed, with read_reply set to 1, in order to read the reply of the * command. This is useful in order to support non blocking operations, so * that we write, return into the event loop, and read when there are data. * * When read_reply is 0 the function returns PSYNC_WRITE_ERR if there * was a write error, or PSYNC_WAIT_REPLY to signal we need another call * with read_reply set to 1. However even when read_reply is set to 1 * the function may return PSYNC_WAIT_REPLY again to signal there were * insufficient data to read to complete its work. We should re-enter * into the event loop and wait in such a case. * * The function returns: * * PSYNC_CONTINUE: If the PSYNC command succeeded and we can continue. * PSYNC_FULLRESYNC: If PSYNC is supported but a full resync is needed. * In this case the master run_id and global replication * offset is saved. * PSYNC_NOT_SUPPORTED: If the server does not understand PSYNC at all and * the caller should fall back to SYNC. * PSYNC_WRITE_ERROR: There was an error writing the command to the socket. * PSYNC_WAIT_REPLY: Call again the function with read_reply set to 1. * PSYNC_TRY_LATER: Master is currently in a transient error condition. * * Notable side effects: * * 1) As a side effect of the function call the function removes the readable * event handler from "fd", unless the return value is PSYNC_WAIT_REPLY. * 2) server.master_initial_offset is set to the right value according * to the master reply. This will be used to populate the 'server.master' * structure replication offset. */ PSYNC_WRITE_ERROR 0 套接口不可写。 PSYNC_WAIT_REPLY 1 需要read_erply设置为1，并调用函数。 PSYNC_CONTINUE 2 PSYNC_FULLRESYNC 3 表示虽然支持PSYNC，但现在仍然需要一次Full SYNC。在这情况下，我们需要保存Master的runid和offset。 PSYNC_NOT_SUPPORTED 4 不支持PSYNC。 PSYNC_TRY_LATER 5 暂时连不上Master，要重试。 1234int slaveTryPartialResynchronization(connection *conn, int read_reply) &#123; char *psync_replid; char psync_offset[32]; sds reply; 首先，是写部分。这里的写，指的是往连接里面发送PSYNC指令: 如果我们缓存了server.master到server.cached_master 通常是在replicationCacheMaster中设置的 如果是第一次连 发送 1PSYNC ? -1 1234567891011121314151617181920212223242526272829/* Writing half */if (!read_reply) &#123; /* Initially set master_initial_offset to -1 to mark the current * master run_id and offset as not valid. Later if we'll be able to do * a FULL resync using the PSYNC command we'll set the offset at the * right value, so that this information will be propagated to the * client structure representing the master into server.master. */ server.master_initial_offset = -1; if (server.cached_master) &#123; psync_replid = server.cached_master-&gt;replid; snprintf(psync_offset,sizeof(psync_offset),"%lld", server.cached_master-&gt;reploff+1); serverLog(LL_NOTICE,"Trying a partial resynchronization (request %s:%s).", psync_replid, psync_offset); &#125; else &#123; serverLog(LL_NOTICE,"Partial resynchronization not possible (no cached master)"); psync_replid = "?"; memcpy(psync_offset,"-1",3); &#125; /* Issue the PSYNC command */ reply = sendSynchronousCommand(SYNC_CMD_WRITE,conn,"PSYNC",psync_replid,psync_offset,NULL); if (reply != NULL) &#123; serverLog(LL_WARNING,"Unable to send PSYNC to master: %s",reply); sdsfree(reply); connSetReadHandler(conn, NULL); return PSYNC_WRITE_ERROR; &#125; return PSYNC_WAIT_REPLY;&#125; 我们读出Master的回复，如果是空，我们就返回继续等待PSYNC_WAIT_REPLY。12345678910/* Reading half */reply = sendSynchronousCommand(SYNC_CMD_READ,conn,NULL);if (sdslen(reply) == 0) &#123; /* The master may send empty newlines after it receives PSYNC * and before to reply, just to keep the connection alive. */ sdsfree(reply); return PSYNC_WAIT_REPLY;&#125;connSetReadHandler(conn, NULL); 如果回复是+FULLRESYNC，表示需要一次Full SYNC。1234567891011if (!strncmp(reply,"+FULLRESYNC",11)) &#123; char *replid = NULL, *offset = NULL; /* FULL RESYNC, parse the reply in order to extract the run id * and the replication offset. */ replid = strchr(reply,' '); if (replid) &#123; replid++; offset = strchr(replid,' '); if (offset) offset++; &#125; 123456789101112131415161718192021 if (!replid || !offset || (offset-replid-1) != CONFIG_RUN_ID_SIZE) &#123; serverLog(LL_WARNING, "Master replied with wrong +FULLRESYNC syntax."); /* This is an unexpected condition, actually the +FULLRESYNC * reply means that the master supports PSYNC, but the reply * format seems wrong. To stay safe we blank the master * replid to make sure next PSYNCs will fail. */ memset(server.master_replid,0,CONFIG_RUN_ID_SIZE+1); &#125; else &#123; memcpy(server.master_replid, replid, offset-replid-1); server.master_replid[CONFIG_RUN_ID_SIZE] = '\0'; server.master_initial_offset = strtoll(offset,NULL,10); serverLog(LL_NOTICE,"Full resync from master: %s:%lld", server.master_replid, server.master_initial_offset); &#125; /* We are going to full resync, discard the cached master structure. */ replicationDiscardCachedMaster(); sdsfree(reply); return PSYNC_FULLRESYNC;&#125; 否则，我们可以部分同步。12345678910111213if (!strncmp(reply,"+CONTINUE",9)) &#123; /* Partial resync was accepted. */ serverLog(LL_NOTICE, "Successful partial resynchronization with master."); /* Check the new replication ID advertised by the master. If it * changed, we need to set the new ID as primary ID, and set or * secondary ID as the old master ID up to the current offset, so * that our sub-slaves will be able to PSYNC with us after a * disconnection. */ char *start = reply+10; char *end = reply+9; while(end[0] != '\r' &amp;&amp; end[0] != '\n' &amp;&amp; end[0] != '\0') end++; 这里new表示Master端传来的runid。如果和我们当前的server.replid不一样，我们要重新设置一下，并且将老的server.replid复制给server.replid2。【Q】这里涉及到三个replid，他们的区别是什么呢？ server.replid server.replid2 server.cached_master-&gt;replid 123456789101112131415161718if (end-start == CONFIG_RUN_ID_SIZE) &#123; char new[CONFIG_RUN_ID_SIZE+1]; memcpy(new,start,CONFIG_RUN_ID_SIZE); new[CONFIG_RUN_ID_SIZE] = '\0'; if (strcmp(new,server.cached_master-&gt;replid)) &#123; /* Master ID changed. */ serverLog(LL_WARNING,"Master replication ID changed to %s",new); /* Set the old ID as our ID2, up to the current offset+1. */ memcpy(server.replid2,server.cached_master-&gt;replid, sizeof(server.replid2)); server.second_replid_offset = server.master_repl_offset+1; /* Update the cached master ID and our own primary ID to the * new one. */ memcpy(server.replid,new,sizeof(server.replid)); memcpy(server.cached_master-&gt;replid,new,sizeof(server.replid)); 如果当前Slave有Sub Slave，全部断开，让他们重新走PSYNC流程。12345678910111213141516171819202122232425262728293031323334353637383940414243444546 /* Disconnect all the sub-slaves: they need to be notified. */ disconnectSlaves(); &#125; &#125; /* Setup the replication to continue. */ sdsfree(reply); replicationResurrectCachedMaster(conn); /* If this instance was restarted and we read the metadata to * PSYNC from the persistence file, our replication backlog could * be still not initialized. Create it. */ if (server.repl_backlog == NULL) createReplicationBacklog(); return PSYNC_CONTINUE; &#125; /* If we reach this point we received either an error (since the master does * not understand PSYNC or because it is in a special state and cannot * serve our request), or an unexpected reply from the master. * * Return PSYNC_NOT_SUPPORTED on errors we don't understand, otherwise * return PSYNC_TRY_LATER if we believe this is a transient error. */ if (!strncmp(reply,"-NOMASTERLINK",13) || !strncmp(reply,"-LOADING",8)) &#123; serverLog(LL_NOTICE, "Master is currently unable to PSYNC " "but should be in the future: %s", reply); sdsfree(reply); return PSYNC_TRY_LATER; &#125; if (strncmp(reply,"-ERR",4)) &#123; /* If it's not an error, log the unexpected event. */ serverLog(LL_WARNING, "Unexpected reply to PSYNC from master: %s", reply); &#125; else &#123; serverLog(LL_NOTICE, "Master does not support PSYNC or is in " "error state (reply: %s)", reply); &#125; sdsfree(reply); replicationDiscardCachedMaster(); return PSYNC_NOT_SUPPORTED;&#125; readSyncBulkPayload: SYNC分支 接受RDB123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361/* Asynchronously read the SYNC payload we receive from a master */#define REPL_MAX_WRITTEN_BEFORE_FSYNC (1024*1024*8) /* 8 MB */void readSyncBulkPayload(connection *conn) &#123; char buf[PROTO_IOBUF_LEN]; ssize_t nread, readlen, nwritten; int use_diskless_load = useDisklessLoad(); redisDb *diskless_load_backup = NULL; int empty_db_flags = server.repl_slave_lazy_flush ? EMPTYDB_ASYNC : EMPTYDB_NO_FLAGS; off_t left; /* Static vars used to hold the EOF mark, and the last bytes received * form the server: when they match, we reached the end of the transfer. */ static char eofmark[CONFIG_RUN_ID_SIZE]; static char lastbytes[CONFIG_RUN_ID_SIZE]; static int usemark = 0; /* If repl_transfer_size == -1 we still have to read the bulk length * from the master reply. */ if (server.repl_transfer_size == -1) &#123; if (connSyncReadLine(conn,buf,1024,server.repl_syncio_timeout*1000) == -1) &#123; serverLog(LL_WARNING, "I/O error reading bulk count from MASTER: %s", strerror(errno)); goto error; &#125; if (buf[0] == '-') &#123; serverLog(LL_WARNING, "MASTER aborted replication with an error: %s", buf+1); goto error; &#125; else if (buf[0] == '\0') &#123; /* At this stage just a newline works as a PING in order to take * the connection live. So we refresh our last interaction * timestamp. */ server.repl_transfer_lastio = server.unixtime; return; &#125; else if (buf[0] != '$') &#123; serverLog(LL_WARNING,"Bad protocol from MASTER, the first byte is not '$' (we received '%s'), are you sure the host and port are right?", buf); goto error; &#125; /* There are two possible forms for the bulk payload. One is the * usual $&lt;count&gt; bulk format. The other is used for diskless transfers * when the master does not know beforehand the size of the file to * transfer. In the latter case, the following format is used: * * $EOF:&lt;40 bytes delimiter&gt; * * At the end of the file the announced delimiter is transmitted. The * delimiter is long and random enough that the probability of a * collision with the actual file content can be ignored. */ if (strncmp(buf+1,"EOF:",4) == 0 &amp;&amp; strlen(buf+5) &gt;= CONFIG_RUN_ID_SIZE) &#123; usemark = 1; memcpy(eofmark,buf+5,CONFIG_RUN_ID_SIZE); memset(lastbytes,0,CONFIG_RUN_ID_SIZE); /* Set any repl_transfer_size to avoid entering this code path * at the next call. */ server.repl_transfer_size = 0; serverLog(LL_NOTICE, "MASTER &lt;-&gt; REPLICA sync: receiving streamed RDB from master with EOF %s", use_diskless_load? "to parser":"to disk"); &#125; else &#123; usemark = 0; server.repl_transfer_size = strtol(buf+1,NULL,10); serverLog(LL_NOTICE, "MASTER &lt;-&gt; REPLICA sync: receiving %lld bytes from master %s", (long long) server.repl_transfer_size, use_diskless_load? "to parser":"to disk"); &#125; return; &#125; if (!use_diskless_load) &#123; /* Read the data from the socket, store it to a file and search * for the EOF. */ if (usemark) &#123; readlen = sizeof(buf); &#125; else &#123; left = server.repl_transfer_size - server.repl_transfer_read; readlen = (left &lt; (signed)sizeof(buf)) ? left : (signed)sizeof(buf); &#125; nread = connRead(conn,buf,readlen); if (nread &lt;= 0) &#123; if (connGetState(conn) == CONN_STATE_CONNECTED) &#123; /* equivalent to EAGAIN */ return; &#125; serverLog(LL_WARNING,"I/O error trying to sync with MASTER: %s", (nread == -1) ? strerror(errno) : "connection lost"); cancelReplicationHandshake(1); return; &#125; server.stat_net_input_bytes += nread; /* When a mark is used, we want to detect EOF asap in order to avoid * writing the EOF mark into the file... */ int eof_reached = 0; if (usemark) &#123; /* Update the last bytes array, and check if it matches our * delimiter. */ if (nread &gt;= CONFIG_RUN_ID_SIZE) &#123; memcpy(lastbytes,buf+nread-CONFIG_RUN_ID_SIZE, CONFIG_RUN_ID_SIZE); &#125; else &#123; int rem = CONFIG_RUN_ID_SIZE-nread; memmove(lastbytes,lastbytes+nread,rem); memcpy(lastbytes+rem,buf,nread); &#125; if (memcmp(lastbytes,eofmark,CONFIG_RUN_ID_SIZE) == 0) eof_reached = 1; &#125; /* Update the last I/O time for the replication transfer (used in * order to detect timeouts during replication), and write what we * got from the socket to the dump file on disk. */ server.repl_transfer_lastio = server.unixtime; if ((nwritten = write(server.repl_transfer_fd,buf,nread)) != nread) &#123; serverLog(LL_WARNING, "Write error or short write writing to the DB dump file " "needed for MASTER &lt;-&gt; REPLICA synchronization: %s", (nwritten == -1) ? strerror(errno) : "short write"); goto error; &#125; server.repl_transfer_read += nread; /* Delete the last 40 bytes from the file if we reached EOF. */ if (usemark &amp;&amp; eof_reached) &#123; if (ftruncate(server.repl_transfer_fd, server.repl_transfer_read - CONFIG_RUN_ID_SIZE) == -1) &#123; serverLog(LL_WARNING, "Error truncating the RDB file received from the master " "for SYNC: %s", strerror(errno)); goto error; &#125; &#125; /* Sync data on disk from time to time, otherwise at the end of the * transfer we may suffer a big delay as the memory buffers are copied * into the actual disk. */ if (server.repl_transfer_read &gt;= server.repl_transfer_last_fsync_off + REPL_MAX_WRITTEN_BEFORE_FSYNC) &#123; off_t sync_size = server.repl_transfer_read - server.repl_transfer_last_fsync_off; rdb_fsync_range(server.repl_transfer_fd, server.repl_transfer_last_fsync_off, sync_size); server.repl_transfer_last_fsync_off += sync_size; &#125; /* Check if the transfer is now complete */ if (!usemark) &#123; if (server.repl_transfer_read == server.repl_transfer_size) eof_reached = 1; &#125; /* If the transfer is yet not complete, we need to read more, so * return ASAP and wait for the handler to be called again. */ if (!eof_reached) return; &#125; /* We reach this point in one of the following cases: * * 1. The replica is using diskless replication, that is, it reads data * directly from the socket to the Redis memory, without using * a temporary RDB file on disk. In that case we just block and * read everything from the socket. * * 2. Or when we are done reading from the socket to the RDB file, in * such case we want just to read the RDB file in memory. */ serverLog(LL_NOTICE, "MASTER &lt;-&gt; REPLICA sync: Flushing old data"); /* We need to stop any AOF rewriting child before flusing and parsing * the RDB, otherwise we'll create a copy-on-write disaster. */ if (server.aof_state != AOF_OFF) stopAppendOnly(); /* When diskless RDB loading is used by replicas, it may be configured * in order to save the current DB instead of throwing it away, * so that we can restore it in case of failed transfer. */ if (use_diskless_load &amp;&amp; server.repl_diskless_load == REPL_DISKLESS_LOAD_SWAPDB) &#123; /* Create a backup of server.db[] and initialize to empty * dictionaries */ diskless_load_backup = disklessLoadMakeBackups(); &#125; /* We call to emptyDb even in case of REPL_DISKLESS_LOAD_SWAPDB * (Where disklessLoadMakeBackups left server.db empty) because we * want to execute all the auxiliary logic of emptyDb (Namely, * fire module events) */ emptyDb(-1,empty_db_flags,replicationEmptyDbCallback); /* Before loading the DB into memory we need to delete the readable * handler, otherwise it will get called recursively since * rdbLoad() will call the event loop to process events from time to * time for non blocking loading. */ connSetReadHandler(conn, NULL); serverLog(LL_NOTICE, "MASTER &lt;-&gt; REPLICA sync: Loading DB in memory"); rdbSaveInfo rsi = RDB_SAVE_INFO_INIT; if (use_diskless_load) &#123; rio rdb; rioInitWithConn(&amp;rdb,conn,server.repl_transfer_size); /* Put the socket in blocking mode to simplify RDB transfer. * We'll restore it when the RDB is received. */ connBlock(conn); connRecvTimeout(conn, server.repl_timeout*1000); startLoading(server.repl_transfer_size, RDBFLAGS_REPLICATION); if (rdbLoadRio(&amp;rdb,RDBFLAGS_REPLICATION,&amp;rsi) != C_OK) &#123; /* RDB loading failed. */ stopLoading(0); serverLog(LL_WARNING, "Failed trying to load the MASTER synchronization DB " "from socket"); cancelReplicationHandshake(1); rioFreeConn(&amp;rdb, NULL); if (server.repl_diskless_load == REPL_DISKLESS_LOAD_SWAPDB) &#123; /* Restore the backed up databases. */ disklessLoadRestoreBackups(diskless_load_backup,1, empty_db_flags); &#125; else &#123; /* Remove the half-loaded data in case we started with * an empty replica. */ emptyDb(-1,empty_db_flags,replicationEmptyDbCallback); &#125; /* Note that there's no point in restarting the AOF on SYNC * failure, it'll be restarted when sync succeeds or the replica * gets promoted. */ return; &#125; stopLoading(1); /* RDB loading succeeded if we reach this point. */ if (server.repl_diskless_load == REPL_DISKLESS_LOAD_SWAPDB) &#123; /* Delete the backup databases we created before starting to load * the new RDB. Now the RDB was loaded with success so the old * data is useless. */ disklessLoadRestoreBackups(diskless_load_backup,0,empty_db_flags); &#125; /* Verify the end mark is correct. */ if (usemark) &#123; if (!rioRead(&amp;rdb,buf,CONFIG_RUN_ID_SIZE) || memcmp(buf,eofmark,CONFIG_RUN_ID_SIZE) != 0) &#123; serverLog(LL_WARNING,"Replication stream EOF marker is broken"); cancelReplicationHandshake(1); rioFreeConn(&amp;rdb, NULL); return; &#125; &#125; /* Cleanup and restore the socket to the original state to continue * with the normal replication. */ rioFreeConn(&amp;rdb, NULL); connNonBlock(conn); connRecvTimeout(conn,0); &#125; else &#123; /* Ensure background save doesn't overwrite synced data */ if (server.rdb_child_pid != -1) &#123; serverLog(LL_NOTICE, "Replica is about to load the RDB file received from the " "master, but there is a pending RDB child running. " "Killing process %ld and removing its temp file to avoid " "any race", (long) server.rdb_child_pid); killRDBChild(); &#125; /* Rename rdb like renaming rewrite aof asynchronously. */ int old_rdb_fd = open(server.rdb_filename,O_RDONLY|O_NONBLOCK); if (rename(server.repl_transfer_tmpfile,server.rdb_filename) == -1) &#123; serverLog(LL_WARNING, "Failed trying to rename the temp DB into %s in " "MASTER &lt;-&gt; REPLICA synchronization: %s", server.rdb_filename, strerror(errno)); cancelReplicationHandshake(1); if (old_rdb_fd != -1) close(old_rdb_fd); return; &#125; /* Close old rdb asynchronously. */ if (old_rdb_fd != -1) bioCreateBackgroundJob(BIO_CLOSE_FILE,(void*)(long)old_rdb_fd,NULL,NULL); if (rdbLoad(server.rdb_filename,&amp;rsi,RDBFLAGS_REPLICATION) != C_OK) &#123; serverLog(LL_WARNING, "Failed trying to load the MASTER synchronization " "DB from disk"); cancelReplicationHandshake(1); if (server.rdb_del_sync_files &amp;&amp; allPersistenceDisabled()) &#123; serverLog(LL_NOTICE,"Removing the RDB file obtained from " "the master. This replica has persistence " "disabled"); bg_unlink(server.rdb_filename); &#125; /* Note that there's no point in restarting the AOF on sync failure, it'll be restarted when sync succeeds or replica promoted. */ return; &#125; /* Cleanup. */ if (server.rdb_del_sync_files &amp;&amp; allPersistenceDisabled()) &#123; serverLog(LL_NOTICE,"Removing the RDB file obtained from " "the master. This replica has persistence " "disabled"); bg_unlink(server.rdb_filename); &#125; zfree(server.repl_transfer_tmpfile); close(server.repl_transfer_fd); server.repl_transfer_fd = -1; server.repl_transfer_tmpfile = NULL; &#125; /* Final setup of the connected slave &lt;- master link */ replicationCreateMasterClient(server.repl_transfer_s,rsi.repl_stream_db); server.repl_state = REPL_STATE_CONNECTED; server.repl_down_since = 0; /* Fire the master link modules event. */ moduleFireServerEvent(REDISMODULE_EVENT_MASTER_LINK_CHANGE, REDISMODULE_SUBEVENT_MASTER_LINK_UP, NULL); /* After a full resynchroniziation we use the replication ID and * offset of the master. The secondary ID / offset are cleared since * we are starting a new history. */ memcpy(server.replid,server.master-&gt;replid,sizeof(server.replid)); server.master_repl_offset = server.master-&gt;reploff; clearReplicationId2(); /* Let's create the replication backlog if needed. Slaves need to * accumulate the backlog regardless of the fact they have sub-slaves * or not, in order to behave correctly if they are promoted to * masters after a failover. */ if (server.repl_backlog == NULL) createReplicationBacklog(); serverLog(LL_NOTICE, "MASTER &lt;-&gt; REPLICA sync: Finished with success"); if (server.supervised_mode == SUPERVISED_SYSTEMD) &#123; redisCommunicateSystemd("STATUS=MASTER &lt;-&gt; REPLICA sync: Finished with success. Ready to accept connections.\n"); redisCommunicateSystemd("READY=1\n"); &#125; /* Send the initial ACK immediately to put this replica in online state. */ if (usemark) replicationSendAck(); /* Restart the AOF subsystem now that we finished the sync. This * will trigger an AOF rewrite, and when done will start appending * to the new file. */ if (server.aof_enabled) restartAOFAfterSYNC(); return;error: cancelReplicationHandshake(1); return;&#125; 主事件循环replicationCron主要代码位于replication.c中。主函数replicationCron被serverCron触发，每隔一秒钟触发一次。1run_with_period(1000) replicationCron(); 下面查看主函数。123// replication.cvoid replicationCron(void) &#123; static long long replication_cron_loops = 0; 首先，下面是几个超时判断： 建立连接过程中超时 传输过程中超时 心跳/数据超时 12345678910111213141516171819202122232425/* Non blocking connection timeout? */if (server.masterhost &amp;&amp; (server.repl_state == REPL_STATE_CONNECTING || slaveIsInHandshakeState()) &amp;&amp; (time(NULL)-server.repl_transfer_lastio) &gt; server.repl_timeout)&#123; serverLog(LL_WARNING,"Timeout connecting to the MASTER..."); cancelReplicationHandshake(1);&#125;/* Bulk transfer I/O timeout? */if (server.masterhost &amp;&amp; server.repl_state == REPL_STATE_TRANSFER &amp;&amp; (time(NULL)-server.repl_transfer_lastio) &gt; server.repl_timeout)&#123; serverLog(LL_WARNING,"Timeout receiving bulk data from MASTER... If the problem persists try to set the 'repl-timeout' parameter in redis.conf to a larger value."); cancelReplicationHandshake(1);&#125;/* Timed out master when we are an already connected slave? */if (server.masterhost &amp;&amp; server.repl_state == REPL_STATE_CONNECTED &amp;&amp; (time(NULL)-server.master-&gt;lastinteraction) &gt; server.repl_timeout)&#123; serverLog(LL_WARNING,"MASTER timeout: no data nor PING received..."); freeClient(server.master);&#125; 判断是否需要连接Master。connectWithMaster这个函数会将状态设置为REPL_STATE_CONNECTING，并设置回调syncWithMaster。1234567/* Check if we should connect to a MASTER */if (server.repl_state == REPL_STATE_CONNECT) &#123; serverLog(LL_NOTICE,"Connecting to MASTER %s:%d", server.masterhost, server.masterport); connectWithMaster();&#125; 如果Master支持PSYNC，就定期发送ACK。这个ACK的作用是发送一个REPLCONF ACK命令给Master，从而通知自己当前的复制偏移。123456/* Send ACK to master from time to time. * Note that we do not send periodic acks to masters that don't * support PSYNC and replication offsets. */if (server.masterhost &amp;&amp; server.master &amp;&amp; !(server.master-&gt;flags &amp; CLIENT_PRE_PSYNC)) replicationSendAck(); 下面，我们对所有Slave发送PING。根据注释，如果我们连接了Slave（是不是说明当前节点是Master？），就按时PING它们。这样Slave们能够维护到Master的显式的超时时间，从而在TCP连接并没有真正丢失的时候，检查一个断线的情况。12345678910111213141516171819202122232425262728/* If we have attached slaves, PING them from time to time. * So slaves can implement an explicit timeout to masters, and will * be able to detect a link disconnection even if the TCP connection * will not actually go down. */listIter li;listNode *ln;robj *ping_argv[1];/* First, send PING according to ping_slave_period. */if ((replication_cron_loops % server.repl_ping_slave_period) == 0 &amp;&amp; listLength(server.slaves))&#123; /* Note that we don't send the PING if the clients are paused during * a Redis Cluster manual failover: the PING we send will otherwise * alter the replication offsets of master and slave, and will no longer * match the one stored into 'mf_master_offset' state. */ int manual_failover_in_progress = server.cluster_enabled &amp;&amp; server.cluster-&gt;mf_end &amp;&amp; clientsArePaused(); if (!manual_failover_in_progress) &#123; ping_argv[0] = createStringObject("PING",4); replicationFeedSlaves(server.slaves, server.slaveseldb, ping_argv, 1); decrRefCount(ping_argv[0]); &#125;&#125; 123456789101112131415161718192021222324252627/* Second, send a newline to all the slaves in pre-synchronization * stage, that is, slaves waiting for the master to create the RDB file. * * Also send the a newline to all the chained slaves we have, if we lost * connection from our master, to keep the slaves aware that their * master is online. This is needed since sub-slaves only receive proxied * data from top-level masters, so there is no explicit pinging in order * to avoid altering the replication offsets. This special out of band * pings (newlines) can be sent, they will have no effect in the offset. * * The newline will be ignored by the slave but will refresh the * last interaction timer preventing a timeout. In this case we ignore the * ping period and refresh the connection once per second since certain * timeouts are set at a few seconds (example: PSYNC response). */listRewind(server.slaves,&amp;li);while((ln = listNext(&amp;li))) &#123; client *slave = ln-&gt;value; int is_presync = (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START || (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_END &amp;&amp; server.rdb_child_type != RDB_CHILD_TYPE_SOCKET)); if (is_presync) &#123; connWrite(slave-&gt;conn, "\n", 1); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677 /* Disconnect timedout slaves. */ if (listLength(server.slaves)) &#123; listIter li; listNode *ln; listRewind(server.slaves,&amp;li); while((ln = listNext(&amp;li))) &#123; client *slave = ln-&gt;value; if (slave-&gt;replstate != SLAVE_STATE_ONLINE) continue; if (slave-&gt;flags &amp; CLIENT_PRE_PSYNC) continue; if ((server.unixtime - slave-&gt;repl_ack_time) &gt; server.repl_timeout) &#123; serverLog(LL_WARNING, "Disconnecting timedout replica: %s", replicationGetSlaveName(slave)); freeClient(slave); &#125; &#125; &#125; /* If this is a master without attached slaves and there is a replication * backlog active, in order to reclaim memory we can free it after some * (configured) time. Note that this cannot be done for slaves: slaves * without sub-slaves attached should still accumulate data into the * backlog, in order to reply to PSYNC queries if they are turned into * masters after a failover. */ if (listLength(server.slaves) == 0 &amp;&amp; server.repl_backlog_time_limit &amp;&amp; server.repl_backlog &amp;&amp; server.masterhost == NULL) &#123; time_t idle = server.unixtime - server.repl_no_slaves_since; if (idle &gt; server.repl_backlog_time_limit) &#123; /* When we free the backlog, we always use a new * replication ID and clear the ID2. This is needed * because when there is no backlog, the master_repl_offset * is not updated, but we would still retain our replication * ID, leading to the following problem: * * 1. We are a master instance. * 2. Our slave is promoted to master. It's repl-id-2 will * be the same as our repl-id. * 3. We, yet as master, receive some updates, that will not * increment the master_repl_offset. * 4. Later we are turned into a slave, connect to the new * master that will accept our PSYNC request by second * replication ID, but there will be data inconsistency * because we received writes. */ changeReplicationId(); clearReplicationId2(); freeReplicationBacklog(); serverLog(LL_NOTICE, "Replication backlog freed after %d seconds " "without connected replicas.", (int) server.repl_backlog_time_limit); &#125; &#125; /* If AOF is disabled and we no longer have attached slaves, we can * free our Replication Script Cache as there is no need to propagate * EVALSHA at all. */ if (listLength(server.slaves) == 0 &amp;&amp; server.aof_state == AOF_OFF &amp;&amp; listLength(server.repl_scriptcache_fifo) != 0) &#123; replicationScriptCacheFlush(); &#125; replicationStartPendingFork(); /* Remove the RDB file used for replication if Redis is not running * with any persistence. */ removeRDBUsedToSyncReplicas(); /* Refresh the number of slaves with lag &lt;= min-slaves-max-lag. */ refreshGoodSlavesCount(); replication_cron_loops++; /* Incremented with frequency 1 HZ. */&#125; 如果SLAVEOF自己会怎么样？Reference http://cbsheng.github.io/posts/redis%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1servercron/ https://www.cnblogs.com/kismetv/p/9236731.html https://youjiali1995.github.io/redis/replication/ https://wenfh2020.com/2020/05/31/redis-replication-next/ 有注释 https://redis.io/commands/psync https://zhuanlan.zhihu.com/p/44105707 https://zhuanlan.zhihu.com/p/86617437 讲解sub slave]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重庆攻略]]></title>
    <url>%2F2021%2F05%2F09%2Fmeet-in-chongqing%2F</url>
    <content type="text"><![CDATA[今年五一的主题是重庆。因为疫情刚解封的缘故，所以大家出门游玩的热情十分高涨，限于钱包有限，我们选择了1号晚上从无锡出发，5号中午从重庆返回无锡的计划，在重庆玩三个整天。 Prelude首先，我们整理了一份重庆景点资料 江北渝中体系： 主要位于居住点附近的渝中区舌头上，这边人很多，很密集 小什字北 洪崖洞 千厮门大桥 小什字南 解放碑（实际上离小什字还有点远，但可以从那边走，因为下坡） 长江索道 湖广会馆 朝天门 朝天门 朝天门码头-弹子石码头 李子坝： 网红轻轨，以及观景台 鹅岭二厂 两路口地区 山城步道 宋庆龄故居 两路口地铁站大扶梯 红土地地铁站 东岸体系(实际位于南岸区)： 弹子石 杜莎夫人 弹子石老街 法国水师兵营旧址 南山 一棵树观景园 壹华里 沙坪坝体系 磁器口 磁器口古镇 白公馆 渣滓洞 九龙坡体系 川美 四川美术学院 涂鸦一条街 总体来讲，重庆的行主要靠打车即可，这边无论是的士还是滴滴都非常便宜。但是需要有两点考量： 打滴滴接单比较慢，并且如果在一些很有重庆特色的地方，你的定位很容易就不准，建议手动输入旁边的路名。 节假日下重庆的堵车比较严重，堵车主要分布在 渝中区朝天宫-小什字-较场口附近，强烈建议坐地铁出渝中区再打车 途径千厮门大桥和东水关大桥，建议由地铁六号线过江 山路，例如壹华里的下山路 前往涂鸦一条街（根本打不到车，有条件的可以选择做三蹦子） 很多地图上看起来近的点，是需要绕的 同理，如果走路的话，也需要做好规划，因为高差的原因，很多地方是要绕的，会走断脚，例如： 长江索道和湖广会馆 解放碑到长江索道（有个大上坡） 【打车】南滨路上东水门大桥 【打车】南滨路去较场口等区域，需要绕行重庆长江大桥 由于我们住在东原1891时光道，所以我们的行程规划是： D1 【午】和记火爆 弹子石老街 法国水师兵营旧址 弹子石码头乘船到朝天门 逛重庆来福士以寻找可以轻松前往地铁站的道路 朝天门地铁到红土地地铁站 红土地地铁站到小什字出 【临时】一只酸奶牛 走到解放碑步行街 【临时】排队买好又来酸辣粉和玫瑰糍粑冰粉，小酥肉 【晚】秦云老太婆摊摊面 南滨路 在小区平台看渝中区夜景 D2 打车前往较场口地铁站，坐到李子坝站下 观赏李子坝轻轨穿楼 根据小红书上列举的short cut，从李子坝地铁站走到二厂文创公园 【午】大王油茶 游览二厂文创公园 坐地铁前往杨家坪站 【临时】重庆特色的某面包房 在钟书阁排队，并参观 坐233路去涂鸦一条街 在涂鸦一条街寻找真正的涂鸦，发现西洋景 【临时】梯坎豆花，并放弃人太多的交通茶馆 从涂鸦一条街打车去九九牛肉馆 【晚】九九牛肉馆（老店） 从九九牛肉馆打车到壹华里公园 在壹华里公园爬山，玩手机，以及观赏落日 回宾馆打牌 D3 【午】洪崖洞猴三火锅店 重庆美术馆假装欣赏艺术 在当当网书店喝一只酸奶牛，并旁听自称可能是重庆最好玩的脱口秀 长江索道体验VIP待遇 步行抵达洪崖洞(11楼) 【晚】体验重庆KFC，并手机斗地主和充电 分别参观洪崖洞的4楼和底楼 挤两部电梯回到11楼，并前往千厮门大桥 桥上步行观光，从大剧院站乘搭地铁，观赏洪崖洞 上新街站打车回家 D0D1在从红土地回来的路上，我们发现明天的长江索道票不知何时已经被定完了，于是我们只能去定人均100的讲解票，票面上说是免排队的，我感觉还是可以的。 D2钟书阁是在这个商场的某个正数楼层，这么说是因为商场太古怪了，地下室有B1到B6，向上是L1和L2，也就是我们进来的地方，在往上又从1开始编号了。反正我们很不瑞雪地从B6上来之后，就发现了一条超级长的队——当然是去钟书阁的了。路上我还搜了钟书阁，在上海甚至无锡都有好几家，但从来没听过，所以这帮人来重庆排这家店干嘛。考虑到Z她们去上厕所了，我想着也没事做，就去排了。前面两个人是腾讯的，穿着那个灰色的文化衫，非常有辨识度。队伍的前进速度是意料之外的快，等到Z上完厕所回来，我都快到门口了。中途还有人发了一下旁边一家奶茶店的优惠券。进去之后，就明白为啥这家店这么网红了，原来在一个跨越两层楼的空间的天花板上装上了玻璃，这个玻璃反射了四面墙壁上的书架和扶梯，显得很壮观。 逛完钟书阁，打算去涂鸦一条街。站在路边打车，拦车，等了好久，都没有响应。是因为打车的人太多了么？旁边倒是挤满了人，但都是往公交站台走的。我看了会两个人下棋，单车对单车单炮，很没意思。最后，我们还是选择了坐公交车，这个体验真的非常酸爽的。公交车相对是比较挤，路又很颠簸。这是一条风情街，附近应该之前是很多工厂，所以路边的人行道上隔三差五放了很多工业零件的雕塑。 过了一座桥之后，路两边的涂鸦渐渐多了起来。 到了公交站，发现路两边的房子都涂满了涂鸦，一栋楼一个风格，于是我们满心欢喜打算去涂鸦一条街，没想到这楼的涂鸦已经是巅峰了。 往前走，路过交通茶馆和蹄花店，人都在排老长的队，所以我们再往前去吃梯坎豆花。这家豆花便宜好吃，才三块钱，另外一定要加上3块钱一碗的调料。调料虽然看起来很红，但实际上并不辣。 很多清洁工在擦地。 我们顺着之前的巷子一直往前走。 越走，标语就越哲学。 走到了一所中学门边，我们准备打车。对面有人在排长队，我正好找厕所，就去看了下，原来是易烊千玺的一个雕塑在那边，大家都去合影。上完厕所回来，发现这家中学竞赛基本都是省二，但居然有3个清华，看起来重庆教育也不是很卷啊。 打车去久久牛肉馆。这趟路是最长的，大约有十几公里，但是总共也就花了五十多。 D3]]></content>
      <tags>
        <tag>游记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LevelDB之流程概览]]></title>
    <url>%2F2021%2F04%2F24%2Fleveldb-proc%2F</url>
    <content type="text"><![CDATA[在了解了LevelDB的相关模块的实现后，本文时序地展示LevelDB的流程概览。至少要先了解： Memtable SSTable Compaction机制 先跑一个Demo。1234567891011leveldb::DB* db;leveldb::Options options;options.create_if_missing = true;leveldb::Status status = leveldb::DB::Open(options,"./testdb",&amp;db);std::string key = "calvinneo";std::string value = "calvinneo@calvinneo.com";status = db-&gt;Put(leveldb::WriteOptions(), key, value);//添加status = db-&gt;Get(leveldb::ReadOptions(), key, &amp;value);//获取 创建创建的逻辑实际上是在打开逻辑DB::Open里面分出来的。但由于这部分逻辑简单独立，并且有益于理解整个数据库的layout所以提出来单独讲。首先设置几个数： SetLogNumber将日志号设置为0 DescriptorFileName生成Manifest文件，序号为1 SetNextFile设置为21234567Status DBImpl::NewDB() &#123; VersionEdit new_db; new_db.SetComparatorName(user_comparator()-&gt;Name()); new_db.SetLogNumber(0); new_db.SetNextFile(2); new_db.SetLastSequence(0); const std::string manifest = DescriptorFileName(dbname_, 1); 下面创建Manifest文件。12345WritableFile* file;Status s = env_-&gt;NewWritableFile(manifest, &amp;file);if (!s.ok()) &#123; return s;&#125; 下面一连串操作，就是把new_db去Encode到log里面，并且刷盘12345678910111213&#123; log::Writer log(file); std::string record; new_db.EncodeTo(&amp;record); s = log.AddRecord(record); if (s.ok()) &#123; s = file-&gt;Sync(); &#125; if (s.ok()) &#123; s = file-&gt;Close(); &#125;&#125;delete file; 设置CURRENT指向最新的Manifest12345678 if (s.ok()) &#123; // Make "CURRENT" file that points to the new manifest file. s = SetCurrentFile(env_, dbname_, 1); &#125; else &#123; env_-&gt;RemoveFile(manifest); &#125; return s;&#125; 打开调用链如下所示 DB::OpenDBImpl的构造函数只是一个初始化成员列表，并不包含其他逻辑了。在得到DBImpl对象后，我们首先加锁，并且调用Recover方法。这个方法内容是加载Manifest文件，并恢复故障。值得注意的是save_manifest这个参数，会被通过调用链传得很深，具体作用是： 在RecoverLogFile中可能出现Memtable被Dump的情况 在Version::Recover中，如果不能ReuseManifest123456789Status DB::Open(const Options&amp; options, const std::string&amp; dbname, DB** dbptr) &#123; *dbptr = nullptr; DBImpl* impl = new DBImpl(options, dbname); impl-&gt;mutex_.Lock(); VersionEdit edit; // Recover handles create_if_missing, error_if_exists bool save_manifest = false; Status s = impl-&gt;Recover(&amp;edit, &amp;save_manifest); 创建一个新的log文件。如果没有Memtable，需要创建一个。123456789101112131415if (s.ok() &amp;&amp; impl-&gt;mem_ == nullptr) &#123; // Create new log and a corresponding memtable. uint64_t new_log_number = impl-&gt;versions_-&gt;NewFileNumber(); WritableFile* lfile; s = options.env-&gt;NewWritableFile(LogFileName(dbname, new_log_number), &amp;lfile); if (s.ok()) &#123; edit.SetLogNumber(new_log_number); impl-&gt;logfile_ = lfile; impl-&gt;logfile_number_ = new_log_number; impl-&gt;log_ = new log::Writer(lfile); impl-&gt;mem_ = new MemTable(impl-&gt;internal_comparator_); impl-&gt;mem_-&gt;Ref(); &#125;&#125; 【Q】有个问题，这里为啥还需要调用LogAndApply？因为在VersionSet::Recover里面已经看到有类似的过程了。123456789101112131415161718 if (s.ok() &amp;&amp; save_manifest) &#123; edit.SetPrevLogNumber(0); // No older logs needed after recovery. edit.SetLogNumber(impl-&gt;logfile_number_); s = impl-&gt;versions_-&gt;LogAndApply(&amp;edit, &amp;impl-&gt;mutex_); &#125; if (s.ok()) &#123; impl-&gt;RemoveObsoleteFiles(); impl-&gt;MaybeScheduleCompaction(); &#125; impl-&gt;mutex_.Unlock(); if (s.ok()) &#123; assert(impl-&gt;mem_ != nullptr); *dbptr = impl; &#125; else &#123; delete impl; &#125; return s;&#125; DBImpl::Recover首先创建数据库目录，并且加文件锁，也就是目录下的LOCK文件，这个函数很有意思，后面专门来讲。123456789101112Status DBImpl::Recover(VersionEdit* edit, bool* save_manifest) &#123; mutex_.AssertHeld(); // Ignore error from CreateDir since the creation of the DB is // committed only when the descriptor is created, and this directory // may already exist from a previous failed creation attempt. env_-&gt;CreateDir(dbname_); assert(db_lock_ == nullptr); Status s = env_-&gt;LockFile(LockFileName(dbname_), &amp;db_lock_); if (!s.ok()) &#123; return s; &#125; 下面我们检查db目录下有没有CURRENT文件。如果没有，我们认为数据库就不存在，如果此时设置了options_.create_if_missing，就创建，否则返回错误。123456789101112131415161718if (!env_-&gt;FileExists(CurrentFileName(dbname_))) &#123; if (options_.create_if_missing) &#123; Log(options_.info_log, "Creating DB %s since it was missing.", dbname_.c_str()); s = NewDB(); if (!s.ok()) &#123; return s; &#125; &#125; else &#123; return Status::InvalidArgument( dbname_, "does not exist (create_if_missing is false)"); &#125;&#125; else &#123; if (options_.error_if_exists) &#123; return Status::InvalidArgument(dbname_, "exists (error_if_exists is true)"); &#125;&#125; 下面调用VersionSet里面的Recover函数。这个函数负责读取Manifest文件，恢复版本信息。1234s = versions_-&gt;Recover(save_manifest);if (!s.ok()) &#123; return s;&#125; 下面，我们要分析Log文件，如果有Log文件大于Manifest中记录的值，就说明这些日志是上次关闭时丢失的数据，我们需要恢复这些日志。注意PrevLogNumber不再使用了，但是出于兼容性，我们依旧关注这个字段。1234567891011121314151617SequenceNumber max_sequence(0);// Recover from all newer log files than the ones named in the// descriptor (new log files may have been added by the previous// incarnation without registering them in the descriptor).//const uint64_t min_log = versions_-&gt;LogNumber();const uint64_t prev_log = versions_-&gt;PrevLogNumber();std::vector&lt;std::string&gt; filenames;s = env_-&gt;GetChildren(dbname_, &amp;filenames);if (!s.ok()) &#123; return s;&#125;std::set&lt;uint64_t&gt; expected;versions_-&gt;AddLiveFiles(&amp;expected);uint64_t number;FileType type;std::vector&lt;uint64_t&gt; logs; filenames表示数据库目录下面的所有文件，我们依次遍历这些文件，并用ParseFileName解析出他们的number。这里的number就是诸如MANIFEST-000002里面的2，应该也是对应到FileMetaData里面的number字段。12345678910111213for (size_t i = 0; i &lt; filenames.size(); i++) &#123; if (ParseFileName(filenames[i], &amp;number, &amp;type)) &#123; expected.erase(number); if (type == kLogFile &amp;&amp; ((number &gt;= min_log) || (number == prev_log))) logs.push_back(number); &#125;&#125;if (!expected.empty()) &#123; char buf[50]; std::snprintf(buf, sizeof(buf), "%d missing files; e.g.", static_cast&lt;int&gt;(expected.size())); return Status::Corruption(buf, TableFileName(dbname_, *(expected.begin())));&#125; RecoverLogFile的作用是回放日志，既然这样，就需要对日志进行排序。回放日志会修改VersionEdit，并且可能会导致Compaction。12345678// Recover in the order in which the logs were generatedstd::sort(logs.begin(), logs.end());for (size_t i = 0; i &lt; logs.size(); i++) &#123; s = RecoverLogFile(logs[i], (i == logs.size() - 1), save_manifest, edit, &amp;max_sequence); if (!s.ok()) &#123; return s; &#125; MarkFileNumberUsed的作用就是设置next_file_number_，确保next_file_number_要严格大于传入的logs[i]。即，如果小于等于传入的logs[i]，就将它设置为logs[i]+1。123456789101112 // The previous incarnation may not have written any MANIFEST // records after allocating this log number. So we manually // update the file number allocation counter in VersionSet. versions_-&gt;MarkFileNumberUsed(logs[i]); &#125; if (versions_-&gt;LastSequence() &lt; max_sequence) &#123; versions_-&gt;SetLastSequence(max_sequence); &#125; return Status::OK();&#125; VersionSet::Recover1234567Status VersionSet::Recover(bool* save_manifest) &#123; struct LogReporter : public log::Reader::Reporter &#123; Status* status; void Corruption(size_t bytes, const Status&amp; s) override &#123; if (this-&gt;status-&gt;ok()) *this-&gt;status = s; &#125; &#125;; 首先读取CURRENT文件内容，得到当前用的Manifest文件。注意，到这里为止，肯定是存在CURRENT文件的，如果不存在，DBImpl::Recover流程就已经会去创建了。12345678910// Read "CURRENT" file, which contains a pointer to the current manifest filestd::string current;Status s = ReadFileToString(env_, CurrentFileName(dbname_), &amp;current);if (!s.ok()) &#123; return s;&#125;if (current.empty() || current[current.size() - 1] != '\n') &#123; return Status::Corruption("CURRENT file does not end with newline");&#125;current.resize(current.size() - 1); 如果没找到Manifest，就返回一个错误。对于这种情况，应该也是能处理的。12345678910std::string dscname = dbname_ + "/" + current;SequentialFile* file;s = env_-&gt;NewSequentialFile(dscname, &amp;file);if (!s.ok()) &#123; if (s.IsNotFound()) &#123; return Status::Corruption("CURRENT points to a non-existent file", s.ToString()); &#125; return s;&#125; 下面就是根据Manifest文件里面的内容，读取并设置VersionSet。【Q】在哪里写入的呢？答案是在VersionEdit::EncodeTo和Writer::AddRecord里面，这个函数在LogAndApply的时候被调用。12345678910111213141516bool have_log_number = false;bool have_prev_log_number = false;bool have_next_file = false;bool have_last_sequence = false;uint64_t next_file = 0;uint64_t last_sequence = 0;uint64_t log_number = 0;uint64_t prev_log_number = 0;Builder builder(this, current_);int read_records = 0;&#123; LogReporter reporter; reporter.status = &amp;s; log::Reader reader(file, &amp;reporter, true /*checksum*/, 0 /*initial_offset*/); 下面，我们用一个while循环，从reader中读取记录。ReadRecord这个函数，将下一个record读入*record中，如果读取成功，返回true；如果EOF了，就返回false。可能会使用*scratch作为临时存储。*record是有效的，直到下一个对reader的变化操作，或者对*scratch的变化操作。123456Slice record;std::string scratch;while (reader.ReadRecord(&amp;record, &amp;scratch) &amp;&amp; s.ok()) &#123; ++read_records; VersionEdit edit; s = edit.DecodeFrom(record); Manifest里面会记录当时的Comparator（用文本编辑框打开这个文件，能看到一个类名一样的东西），VersionEdit会比较这两个是否一致。12345678if (s.ok()) &#123; if (edit.has_comparator_ &amp;&amp; edit.comparator_ != icmp_.user_comparator()-&gt;Name()) &#123; s = Status::InvalidArgument( edit.comparator_ + " does not match existing comparator ", icmp_.user_comparator()-&gt;Name()); &#125;&#125; 【Q】在LogAndApply实现中，builder.Apply之后还会跟着builder.SaveTo，这里为啥不跟了？稍等，Apply是一条记录Apply一次，SaveTo是最后全搞好了，一次SaveTo。我们往后看，就能看到对SaveTo的调用了。12345678910111213141516171819202122232425 if (s.ok()) &#123; builder.Apply(&amp;edit); &#125; if (edit.has_log_number_) &#123; log_number = edit.log_number_; have_log_number = true; &#125; if (edit.has_prev_log_number_) &#123; prev_log_number = edit.prev_log_number_; have_prev_log_number = true; &#125; if (edit.has_next_file_number_) &#123; next_file = edit.next_file_number_; have_next_file = true; &#125; if (edit.has_last_sequence_) &#123; last_sequence = edit.last_sequence_; have_last_sequence = true; &#125; &#125;&#125; 到此为止，这个文件就读取完毕了，我们释放这个文件。12345678910111213141516171819delete file;file = nullptr;if (s.ok()) &#123; if (!have_next_file) &#123; s = Status::Corruption("no meta-nextfile entry in descriptor"); &#125; else if (!have_log_number) &#123; s = Status::Corruption("no meta-lognumber entry in descriptor"); &#125; else if (!have_last_sequence) &#123; s = Status::Corruption("no last-sequence-number entry in descriptor"); &#125; if (!have_prev_log_number) &#123; prev_log_number = 0; &#125; MarkFileNumberUsed(prev_log_number); MarkFileNumberUsed(log_number);&#125; 下面就是SaveTo、Finalize、AppendVersion的流程，和LogAndApply是类似的1234567891011if (s.ok()) &#123; Version* v = new Version(this); builder.SaveTo(v); // Install recovered version Finalize(v); AppendVersion(v); manifest_file_number_ = next_file; next_file_number_ = next_file + 1; last_sequence_ = last_sequence; log_number_ = log_number; prev_log_number_ = prev_log_number; 检查是继续用现有的Manifest文件，还是重新建一个。这个可能修改descriptor_file_，从而影响到LogAndApply，但是这样的影响只会存在于Recover里面。【Q】这么处理的目的是什么呢？目的是为了解决Manifest文件过大的问题。1234567891011121314 // See if we can reuse the existing MANIFEST file. if (ReuseManifest(dscname, current)) &#123; // No need to save new manifest &#125; else &#123; *save_manifest = true; &#125; &#125; else &#123; std::string error = s.ToString(); Log(options_-&gt;info_log, "Error recovering version set with %d records: %s", read_records, error.c_str()); &#125; return s;&#125; DBImpl::RecoverLogFile【在阅读这个函数前，需要先学习VersionSet::Recover】RecoverLogFile用于读取Log，并且将应用尚未Apply到版本的Log。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log, bool* save_manifest, VersionEdit* edit, SequenceNumber* max_sequence) &#123; struct LogReporter : public log::Reader::Reporter &#123; Env* env; Logger* info_log; const char* fname; Status* status; // null if options_.paranoid_checks==false void Corruption(size_t bytes, const Status&amp; s) override &#123; Log(info_log, "%s%s: dropping %d bytes; %s", (this-&gt;status == nullptr ? "(ignoring error) " : ""), fname, static_cast&lt;int&gt;(bytes), s.ToString().c_str()); if (this-&gt;status != nullptr &amp;&amp; this-&gt;status-&gt;ok()) *this-&gt;status = s; &#125; &#125;; mutex_.AssertHeld(); // Open the log file std::string fname = LogFileName(dbname_, log_number); SequentialFile* file; Status status = env_-&gt;NewSequentialFile(fname, &amp;file); if (!status.ok()) &#123; MaybeIgnoreError(&amp;status); return status; &#125; // Create the log reader. LogReporter reporter; reporter.env = env_; reporter.info_log = options_.info_log; reporter.fname = fname.c_str(); reporter.status = (options_.paranoid_checks ? &amp;status : nullptr); // We intentionally make log::Reader do checksumming even if // paranoid_checks==false so that corruptions cause entire commits // to be skipped instead of propagating bad information (like overly // large sequence numbers). log::Reader reader(file, &amp;reporter, true /*checksum*/, 0 /*initial_offset*/); Log(options_.info_log, "Recovering log #%llu", (unsigned long long)log_number); // Read all the records and add to a memtable std::string scratch; Slice record; WriteBatch batch; int compactions = 0; MemTable* mem = nullptr; 现在，我们开始循环读取日志到record中。接着调用InsertInto方法将它写到Memtable中，这个方法原理我们在介绍DB::Write时讲解。1234567891011121314151617while (reader.ReadRecord(&amp;record, &amp;scratch) &amp;&amp; status.ok()) &#123; if (record.size() &lt; 12) &#123; reporter.Corruption(record.size(), Status::Corruption("log record too small")); continue; &#125; WriteBatchInternal::SetContents(&amp;batch, record); if (mem == nullptr) &#123; mem = new MemTable(internal_comparator_); mem-&gt;Ref(); &#125; status = WriteBatchInternal::InsertInto(&amp;batch, mem); MaybeIgnoreError(&amp;status); if (!status.ok()) &#123; break; &#125; 接着我们更新last_seq。【Q】有点奇怪，这里为啥要加Count？参考写那一部分的分析。12345const SequenceNumber last_seq = WriteBatchInternal::Sequence(&amp;batch) + WriteBatchInternal::Count(&amp;batch) - 1;if (last_seq &gt; *max_sequence) &#123; *max_sequence = last_seq;&#125; 如果Memtable内存超限了，就开启Minor Compaction。当然，这里是一个局部的Compaction，因为不需要维护版本，所以没有LogAndApply调用。因为也不会产生多余的文件，所以也没有RemoveObsoleteFiles调用。回忆一下WriteLevel0Table的实现，我们实际要做的是： 生成SSTable 计算SSTable放到那哪一层 写VersionEdit 如果需要将Memtable落盘，那么就要设置save_manifest为true。这个值是从DBImpl::Open开始一层一层传下来的。12345678910111213 if (mem-&gt;ApproximateMemoryUsage() &gt; options_.write_buffer_size) &#123; compactions++; *save_manifest = true; status = WriteLevel0Table(mem, edit, nullptr); mem-&gt;Unref(); mem = nullptr; if (!status.ok()) &#123; // Reflect errors immediately so that conditions like full // file-systems cause the DB::Open() to fail. break; &#125; &#125;&#125; 到现在为止，上面的while循环就结束了，我们释放掉这个日志文件。但是这里同样要看一下是否可以重新利用log文件fname。12345678910delete file;// See if we should keep reusing the last log file.if (status.ok() &amp;&amp; options_.reuse_logs &amp;&amp; last_log &amp;&amp; compactions == 0) &#123; assert(logfile_ == nullptr); assert(log_ == nullptr); assert(mem_ == nullptr); uint64_t lfile_size; if (env_-&gt;GetFileSize(fname, &amp;lfile_size).ok() &amp;&amp; env_-&gt;NewAppendableFile(fname, &amp;logfile_).ok()) &#123; 如果重新利用Log，就不需要走到后面的WriteLevel0Table了。12345678910111213 Log(options_.info_log, "Reusing old log %s \n", fname.c_str()); log_ = new log::Writer(logfile_, lfile_size); logfile_number_ = log_number; if (mem != nullptr) &#123; mem_ = mem; mem = nullptr; &#125; else &#123; // mem can be nullptr if lognum exists but was empty. mem_ = new MemTable(internal_comparator_); mem_-&gt;Ref(); &#125; &#125;&#125; 1234567891011 if (mem != nullptr) &#123; // mem did not get reused; compact it. if (status.ok()) &#123; *save_manifest = true; status = WriteLevel0Table(mem, edit, nullptr); &#125; mem-&gt;Unref(); &#125; return status;&#125; 文件锁PosixLockTablePosixLockTable这个类用来管理所有通过LockFile锁住的文件。需要注意的是fcntl(F_SETLK)也可以实现文件锁，但是它不能保证同一个进程中的并发访问，所以在此之外，还需要再包一层。【Q】为什么进程中还会有并发访问？在下文中解释。 123456789101112131415161718class PosixLockTable &#123; public: bool Insert(const std::string&amp; fname) LOCKS_EXCLUDED(mu_) &#123; mu_.Lock(); bool succeeded = locked_files_.insert(fname).second; mu_.Unlock(); return succeeded; &#125; void Remove(const std::string&amp; fname) LOCKS_EXCLUDED(mu_) &#123; mu_.Lock(); locked_files_.erase(fname); mu_.Unlock(); &#125; private: port::Mutex mu_; std::set&lt;std::string&gt; locked_files_ GUARDED_BY(mu_);&#125;; LockFile为了加锁，我们首先得往自己进程中的PosixLockTable locks_中加入加锁记录。如果加锁失败，说明这个锁已经被我们进程持有了，就退出。123456789101112Status LockFile(const std::string&amp; filename, FileLock** lock) override &#123; *lock = nullptr; int fd = ::open(filename.c_str(), O_RDWR | O_CREAT | kOpenBaseFlags, 0644); if (fd &lt; 0) &#123; return PosixError(filename, errno); &#125; if (!locks_.Insert(filename)) &#123; ::close(fd); return Status::IOError("lock " + filename, "already held by process"); &#125; 如果我们进程没有持有锁，再调用LockOrUnlock加文件锁。如果加锁失败，说明锁已经被其他进程占用了，这时候就要将它从locks_移除出去。123456789101112 if (LockOrUnlock(fd, true) == -1) &#123; int lock_errno = errno; ::close(fd); locks_.Remove(filename); return PosixError("lock " + filename, lock_errno); &#125; *lock = new PosixFileLock(fd, filename); return Status::OK();&#125;PosixLockTable locks_; LockOrUnlockLockOrUnlock根据传入的lock对文件进行F_SETLK操作。F_SETLK是非阻塞的，还有一个F_SETLKW函数是阻塞的。F_SETLK可以锁定文件的某些部分，在这里，设置l_start和l_len都为0，表示锁定整个文件。12345678910int LockOrUnlock(int fd, bool lock) &#123; errno = 0; struct ::flock file_lock_info; std::memset(&amp;file_lock_info, 0, sizeof(file_lock_info)); file_lock_info.l_type = (lock ? F_WRLCK : F_UNLCK); file_lock_info.l_whence = SEEK_SET; file_lock_info.l_start = 0; file_lock_info.l_len = 0; // Lock/unlock entire file. return ::fcntl(fd, F_SETLK, &amp;file_lock_info);&#125; 有关Linux进程和线程的补充说明这里需要注意，Linux中pthread库创建出来的线程可能具有相同的PID，不同的TID，我们可以从下面的代码看到。12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include &lt;sys/syscall.h&gt;#define gettid() syscall(SYS_gettid)void *start_routine(void* index) &#123; char msg[99] = ""; snprintf(msg, sizeof(msg)-1, "thd %d: getpid %d gettid %d\n", *(int*)index, getpid(), gettid()); while (1) &#123; write(1, msg, strlen(msg)); sleep(1); &#125;&#125;int main() &#123; int th1 = 1; pthread_t tid1; pthread_create(&amp;tid1, NULL, start_routine, &amp;th1); int th2 = 2; pthread_t tid2; pthread_create(&amp;tid2, NULL, start_routine, &amp;th2); const char *msg = "main: i am main\n"; while (1) &#123; write(1, msg, strlen(msg)); sleep(1); &#125; return 0;&#125;/*main: i am mainthd 1: getpid 31270 gettid 31271thd 2: getpid 31270 gettid 31272main: i am mainthd 1: getpid 31270 gettid 31271thd 2: getpid 31270 gettid 31272main: i am mainthd 1: getpid 31270 gettid 31271thd 2: getpid 31270 gettid 31272*/ 写LevelDB可以通过WriteBatch支持批量更新的功能。当然了，作为对Write函数的一个简易化封装，Put只会更新一个字段。12345Status DB::Put(const WriteOptions&amp; opt, const Slice&amp; key, const Slice&amp; value) &#123; WriteBatch batch; batch.Put(key, value); return Write(opt, &amp;batch);&#125; 写数据库的流程： 写WAL 写MemTable 更新Sequence Number 如下所示，写是可以并发的，因此会有类似于InnoDB中的组提交机制。 DBImpl::Write首先，全局有个writers_队列，维护所有的写。123456class DBImpl : public DB &#123;... std::deque&lt;Writer*&gt; writers_ GUARDED_BY(mutex_); WriteBatch* tmp_batch_ GUARDED_BY(mutex_);...&#125; 我们新创建一个DBImpl::Writer这个对象，这个对象中有一个关联到mutex_的条件变量w.cv。接着将这个Writer对象放到writers_中，然后我们等待下面的条件： w.done() 表示其他线程已经帮w写完了。 w == writers_.front() 表示这个Writer位于队头，并且抢到了锁。12345Status DBImpl::Write(const WriteOptions&amp; options, WriteBatch* updates) &#123; Writer w(&amp;mutex_); w.batch = updates; w.sync = options.sync; w.done = false; 所以当一个写线程进入时，首先先要获得锁，这个锁可能会被其他的写入(的部分阶段)持有，或者被后台Compaction(的部分阶段)线程持有。获得锁之后，它能做的其实也就是把自己的Writer挂到writers_队列上，然后如果现在不是队头，就要去等待信号量。12345MutexLock l(&amp;mutex_);writers_.push_back(&amp;w);while (!w.done &amp;&amp; &amp;w != writers_.front()) &#123; w.cv.Wait();&#125; 如果从条件变量上醒过来，还是要再检查一下有没有w.done()，因为可能是另一个条件醒过来的。123if (w.done) &#123; return w.status;&#125; 下面调用MakeRoomForWrite，如果updates是nullptr的话，force就是1，强制MakeRoomForWrite进行Compaction。【Q】什么时候updates是nullptr呢？DBImpl::TEST_CompactMemTable里面有个注释，说如果设置为nullptr，就是在催促。12// May temporarily unlock and wait.Status status = MakeRoomForWrite(updates == nullptr); 在MakeRoomForWrite之后，肯定是可以往数据库里面写东西的了。我们需要得到一个Sequence Number才能写，我们首先取出上一次写的Sequence Number。12uint64_t last_sequence = versions_-&gt;LastSequence();Writer* last_writer = &amp;w; BuildBatchGroup会合并队列里的多个写入到tmp_batch_里面。这个batch算作一次更新，具有全局唯一的一个Sequence Number，从之前递增而来。在合并的时候需要考虑： 总写入数据大小 如果有请求是sync==false了，那么就不加入sync==true的在合并结束后，BuildBatchGroup会更新last_writer，表示最后一个写入。【Q】是不是可能在Memtable有两个record，他们的Sequence Number是相同的？现在看来是有可能的，这是因为批量写的话只会有一个Sequence Number。但是假如有Count个一次性写入，那么Sequence Number会在这个之后增加Count次。有点奇怪。1234if (status.ok() &amp;&amp; updates != nullptr) &#123; // nullptr batch is for compactions WriteBatch* write_batch = BuildBatchGroup(&amp;last_writer); WriteBatchInternal::SetSequence(write_batch, last_sequence + 1); last_sequence += WriteBatchInternal::Count(write_batch); 下面是写日志的操作对应AddRecord。【Q】根据注释，这个操作是不需要加锁的，为什么呢？文章说，这样可以先让其他请求进入队列中排队。这样做是安全的，因为只有一个写，就是&amp;w。同时，可以看出这一步会给写入速度带来比较好的提升，因为只有拿到锁才能往writers_里面push。1234567891011121314// Add to log and apply to memtable. We can release the lock// during this phase since &amp;w is currently responsible for logging// and protects against concurrent loggers and concurrent writes// into mem_.&#123; mutex_.Unlock(); status = log_-&gt;AddRecord(WriteBatchInternal::Contents(write_batch)); bool sync_error = false; if (status.ok() &amp;&amp; options.sync) &#123; status = logfile_-&gt;Sync(); if (!status.ok()) &#123; sync_error = true; &#125; &#125; 数据库的通用原理，写完日志，状态OK了，才能写Memtable，对应InsertInto。123456789101112131415 if (status.ok()) &#123; status = WriteBatchInternal::InsertInto(write_batch, mem_); &#125; mutex_.Lock(); if (sync_error) &#123; // The state of the log file is indeterminate: the log record we // just added may or may not show up when the DB is re-opened. // So we force the DB into a mode where all future writes fail. RecordBackgroundError(status); &#125; &#125; if (write_batch == tmp_batch_) tmp_batch_-&gt;Clear(); versions_-&gt;SetLastSequence(last_sequence);&#125; 逐个弹出writers_里的元素，并唤起等待write的线程，直到遇到last_writer。12345678910while (true) &#123; Writer* ready = writers_.front(); writers_.pop_front(); if (ready != &amp;w) &#123; ready-&gt;status = status; ready-&gt;done = true; ready-&gt;cv.Signal(); &#125; if (ready == last_writer) break;&#125; 我们处理完writers队列中的一个项目了，应当Signal一下，通知下一个项目进来。1234567 // Notify new head of write queue if (!writers_.empty()) &#123; writers_.front()-&gt;cv.Signal(); &#125; return status;&#125; DBImpl::BuildBatchGroup12345678// REQUIRES: Writer list must be non-empty// REQUIRES: First writer must have a non-null batchWriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) &#123; mutex_.AssertHeld(); assert(!writers_.empty()); Writer* first = writers_.front(); WriteBatch* result = first-&gt;batch; assert(result != nullptr); 讨论第一个batch的大小来设置max_size： 如果比较小 就设置为size + (128 &lt;&lt; 10) 如果还可以 就设置为1 &lt;&lt; 20123456789size_t size = WriteBatchInternal::ByteSize(first-&gt;batch);// Allow the group to grow up to a maximum size, but if the// original write is small, limit the growth so we do not slow// down the small write too much.size_t max_size = 1 &lt;&lt; 20;if (size &lt;= (128 &lt;&lt; 10)) &#123; // 128 &lt;&lt; 10 == 1 &lt;&lt; 17 max_size = size + (128 &lt;&lt; 10);&#125; first是writers_队头，下面，我们就遍历整个writers_队列，直到： 如果first是non sync的话，那么我们会在遇到第一个要加入的sync请求的时候就break掉。反之，如果first是sync的话，那么可以兼容non sync的请求的。 大小超限12345678910111213141516*last_writer = first;std::deque&lt;Writer*&gt;::iterator iter = writers_.begin();++iter; // Advance past "first"for (; iter != writers_.end(); ++iter) &#123; Writer* w = *iter; if (w-&gt;sync &amp;&amp; !first-&gt;sync) &#123; // Do not include a sync write into a batch handled by a non-sync write. break; &#125; if (w-&gt;batch != nullptr) &#123; size += WriteBatchInternal::ByteSize(w-&gt;batch); if (size &gt; max_size) &#123; // Do not make batch too big break; &#125; 我们把这些batch，全部加到result里面。如果涉及多个batch，result就指向tmp_batch_，否则就指向first-&gt;batch12345678910111213 // Append to *result if (result == first-&gt;batch) &#123; // Switch to temporary batch instead of disturbing caller's batch result = tmp_batch_; assert(WriteBatchInternal::Count(result) == 0); WriteBatchInternal::Append(result, first-&gt;batch); &#125; WriteBatchInternal::Append(result, w-&gt;batch); &#125; *last_writer = w; &#125; return result;&#125; DBImpl::MakeRoomForWriteMakeRoomForWrite用来确保我们有空间写入，如果此时Memtable满了，就需要去dump成Immutable Memtable。如果现在Level0负荷过重，那么就要延迟一下写入速度。在研究这个函数时，我们要特别注意各个if条件的判断顺序，这体现了优先级。1234567// REQUIRES: mutex_ is held// REQUIRES: this thread is currently at the front of the writer queueStatus DBImpl::MakeRoomForWrite(bool force) &#123; mutex_.AssertHeld(); assert(!writers_.empty()); bool allow_delay = !force; Status s; 一进来，首先一个while循环。唔，这个功能为啥要有while？原因是因为里面要等待信号量的。还有一个原因是，当产生Immutable Memtable之后，我们需要等待它刷盘。12345while (true) &#123; if (!bg_error_.ok()) &#123; // Yield previous error s = bg_error_; break; 如果force为false，也就是不强制执行Compaction，就认为是允许延迟的。【Q】其实我没搞懂这个逻辑。如果允许延迟，并且Level0的文件数达到至少8个，那么就开始慢速写。注意，Level0层最大文件数不是4，这是个误区。当有4个文件的时候开始Compaction，当有12个文件的时候，才停止写入。慢速写的实现就是主线程睡1000ms，这个时候后台的Compaction线程是可以开始Compact的。在睡眠结束之后，要将allow_delay设为false，也就是说对于一次写，我们只慢速一次。123456789101112&#125; else if (allow_delay &amp;&amp; versions_-&gt;NumLevelFiles(0) &gt;= config::kL0_SlowdownWritesTrigger) &#123; // We are getting close to hitting a hard limit on the number of // L0 files. Rather than delaying a single write by several // seconds when we hit the hard limit, start delaying each // individual write by 1ms to reduce latency variance. Also, // this delay hands over some CPU to the compaction thread in // case it is sharing the same core as the writer. mutex_.Unlock(); env_-&gt;SleepForMicroseconds(1000); allow_delay = false; // Do not delay a single write more than once mutex_.Lock(); 下面，如果不强制Compaction，并且Memtable的大小没有超标，那么就啥都不要做，这个应该是最通常的情况。1234&#125; else if (!force &amp;&amp; (mem_-&gt;ApproximateMemoryUsage() &lt;= options_.write_buffer_size)) &#123; // There is room in current memtable break; 如果此时上一轮Immutable Memtable还没有Minor Compact完毕，那么我们就在background_work_finished_signal_这个条件变量上面等待。我们注意到在进入这个函数时是持有mutex_的，所以这个生产者消费者模式是安全的。12345&#125; else if (imm_ != nullptr) &#123; // We have filled up the current memtable, but the previous // one is still being compacted, so we wait. Log(options_.info_log, "Current memtable full; waiting...\n"); background_work_finished_signal_.Wait(); 同理，如果Level0满了，即达到12个文件了，那我们同样要在信号量上等待。1234&#125; else if (versions_-&gt;NumLevelFiles(0) &gt;= config::kL0_StopWritesTrigger) &#123; // There are too many level-0 files. Log(options_.info_log, "Too many L0 files; waiting...\n"); background_work_finished_signal_.Wait(); 对于剩余的情况，我们要将Memtable改成Immutable Memtable。同时，我们注意到这个分支并不会在最后break掉！这是因为此时有了Immutable Memtable了，我们需要等它被刷成SSTable落盘，所以至少还需要一次while循环。这个这个刷盘过程等到什么时候呢？ 对于CompactMemTable来说，至少要执行完LogAndApply之后，才会将imm_设置为nullptr。 而这个条件变量，在MaybeScheduleCompaction调用完之后会被Signal。当然，需要注意，在Major Compaction过程中，如果有Immutable Memtable需要落盘，那么还是要先执行CompactMemTable的，在这个之后，也会触发一次Signal。注意，这一次刷盘还可能会导致Level0文件达到上限，那就要等更久了。1234567891011121314151617181920212223242526 &#125; else &#123; // Attempt to switch to a new memtable and trigger compaction of old assert(versions_-&gt;PrevLogNumber() == 0); uint64_t new_log_number = versions_-&gt;NewFileNumber(); WritableFile* lfile = nullptr; s = env_-&gt;NewWritableFile(LogFileName(dbname_, new_log_number), &amp;lfile); if (!s.ok()) &#123; // Avoid chewing through file number space in a tight loop. versions_-&gt;ReuseFileNumber(new_log_number); break; &#125; delete log_; delete logfile_; logfile_ = lfile; logfile_number_ = new_log_number; log_ = new log::Writer(lfile); imm_ = mem_; has_imm_.store(true, std::memory_order_release); mem_ = new MemTable(internal_comparator_); mem_-&gt;Ref(); force = false; // Do not force another compaction if have room MaybeScheduleCompaction(); &#125; &#125; return s;&#125; 读【Q】思考 读要加锁么？ 我们首先考虑分布式共识这一块，为了实现一致读写，Raft即使是读请求，也需要走一遍LogEntry的。而ZK的话，可以选择直接读，所以未必是一致读。 当然，这个离题了。我觉得根据LevelDB的MVCC模式，其实至少有一部分是可以不加锁的。 在哪些地方可以非线性地查找？ 在非0层找SSTable时，见FindFile。 在BlockReader返回Iterator之后，可以通过Seek来二分。 在读取的时候会做缓存么？ LevelDB在Table和Block两个层面进行缓存。 在Table层面通过TableCache。 在Block层面通过BlockReader里面的table-&gt;rep_-&gt;options.block_cache分支。 DBImpl::Get123456789101112131415161718192021Status DBImpl::Get(const ReadOptions&amp; options, const Slice&amp; key, std::string* value) &#123; Status s; MutexLock l(&amp;mutex_); SequenceNumber snapshot; if (options.snapshot != nullptr) &#123; snapshot = static_cast&lt;const SnapshotImpl*&gt;(options.snapshot)-&gt;sequence_number(); &#125; else &#123; snapshot = versions_-&gt;LastSequence(); &#125; MemTable* mem = mem_; MemTable* imm = imm_; Version* current = versions_-&gt;current(); mem-&gt;Ref(); if (imm != nullptr) imm-&gt;Ref(); current-&gt;Ref(); bool have_stat_update = false; Version::GetStats stats; 可以看到，在获取了current之后，就可以解锁了。【Q】这里还取出了mem_和imm_，是不是在MVCC下面，可能同时存在多个mem_和imm_？此时，永远写最新的Memtable，但是可能会读旧的Memtable。下面就是经典的读取三部曲： 首先看Memtable 然后看Immutable Memtable 然后就去SSTable里面找，具体是调用current-&gt;Get 123456789101112131415// Unlock while reading from files and memtables&#123; mutex_.Unlock(); // First look in the memtable, then in the immutable memtable (if any). LookupKey lkey(key, snapshot); if (mem-&gt;Get(lkey, value, &amp;s)) &#123; // Done &#125; else if (imm != nullptr &amp;&amp; imm-&gt;Get(lkey, value, &amp;s)) &#123; // Done &#125; else &#123; s = current-&gt;Get(options, lkey, value, &amp;stats); have_stat_update = true; &#125; mutex_.Lock();&#125; 到此为止，锁要重新加回来。【Q】看起来读操作也会触发Compaction。12345678 if (have_stat_update &amp;&amp; current-&gt;UpdateStats(stats)) &#123; MaybeScheduleCompaction(); &#125; mem-&gt;Unref(); if (imm != nullptr) imm-&gt;Unref(); current-&gt;Unref(); return s;&#125; Version::Get辅助函数这个函数根据smallest和largest找到对应的文件。容易想到func的作用是在文件里面找key。123456void Version::ForEachOverlapping(Slice user_key, Slice internal_key, void* arg, bool (*func)(void*, int, FileMetaData*)) &#123; const Comparator* ucmp = vset_-&gt;icmp_.user_comparator(); // Search level-0 in order from newest to oldest. std::vector&lt;FileMetaData*&gt; tmp; 从Compaction一文的介绍中了解到，files_里面存放了当前Version中所有SSTable的元信息。我们首先要遍历第0层的所有文件，放到tmp里面，按照f-&gt;number排序。排完序，我们就开始查找，在文件中查找需要借助于传入的func，实际上是State::Match这个函数。12345678910111213141516tmp.reserve(files_[0].size());for (uint32_t i = 0; i &lt; files_[0].size(); i++) &#123; FileMetaData* f = files_[0][i]; if (ucmp-&gt;Compare(user_key, f-&gt;smallest.user_key()) &gt;= 0 &amp;&amp; ucmp-&gt;Compare(user_key, f-&gt;largest.user_key()) &lt;= 0) &#123; tmp.push_back(f); &#125;&#125;if (!tmp.empty()) &#123; std::sort(tmp.begin(), tmp.end(), NewestFirst); for (uint32_t i = 0; i &lt; tmp.size(); i++) &#123; if (!(*func)(arg, 0, tmp[i])) &#123; return; &#125; &#125;&#125; 下面，就可以用之前介绍过的FindFile来二分查找了。12345678910111213141516171819 // Search other levels. for (int level = 1; level &lt; config::kNumLevels; level++) &#123; size_t num_files = files_[level].size(); if (num_files == 0) continue; // Binary search to find earliest index whose largest key &gt;= internal_key. uint32_t index = FindFile(vset_-&gt;icmp_, files_[level], internal_key); if (index &lt; num_files) &#123; FileMetaData* f = files_[level][index]; if (ucmp-&gt;Compare(user_key, f-&gt;smallest.user_key()) &lt; 0) &#123; // All of "f" is past any data for user_key &#125; else &#123; if (!(*func)(arg, level, f)) &#123; return; &#125; &#125; &#125; &#125;&#125; State类State类中主要定义了从SSTable中找对应Key的函数Match。在研究之前，我们先来复习一下SSTable的格式： data block meta block meta index block index block 记录每个data block的“largest”，满足两个性质。 注意，这里的largest不是单纯的largest，而要进行一些修正，它实际上是分隔两个Data Block的最短Key， footer 记录index block和meta index block的位置 所以，我们要先通过index block去定位data block，得到这个data block。 接着，我们复习一下block的格式 record restart 额外信息 num restarts type crc32所以，我们要用LookupKey先去找restart，然后从restart开始找。 同时，我们注意由于，meta block的存在，会有一些优化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152struct State &#123; Saver saver; GetStats* stats; const ReadOptions* options; Slice ikey; FileMetaData* last_file_read; int last_file_read_level; VersionSet* vset; Status s; bool found; static bool Match(void* arg, int level, FileMetaData* f) &#123; State* state = reinterpret_cast&lt;State*&gt;(arg); if (state-&gt;stats-&gt;seek_file == nullptr &amp;&amp; state-&gt;last_file_read != nullptr) &#123; // We have had more than one seek for this read. Charge the 1st file. state-&gt;stats-&gt;seek_file = state-&gt;last_file_read; state-&gt;stats-&gt;seek_file_level = state-&gt;last_file_read_level; &#125; state-&gt;last_file_read = f; state-&gt;last_file_read_level = level; state-&gt;s = state-&gt;vset-&gt;table_cache_-&gt;Get(*state-&gt;options, f-&gt;number, f-&gt;file_size, state-&gt;ikey, &amp;state-&gt;saver, SaveValue); if (!state-&gt;s.ok()) &#123; state-&gt;found = true; return false; &#125; switch (state-&gt;saver.state) &#123; case kNotFound: return true; // Keep searching in other files case kFound: state-&gt;found = true; return false; case kDeleted: return false; case kCorrupt: state-&gt;s = Status::Corruption("corrupted key for ", state-&gt;saver.user_key); state-&gt;found = true; return false; &#125; // Not reached. Added to avoid false compilation warnings of // "control reaches end of non-void function". return false; &#125;&#125;; TableCache::Get和TableCache::FindTableTableCache这一块是一个缓存层，如果缓存中没有，才去读SSTable，并把它加到缓存里面。Get的第一步是FindTable，先介绍这个。首先在cache_里面查文件的handle，如果没找到，就新建一个，并且调用Table::Open从文件中读取。123456789101112131415161718192021Status TableCache::FindTable(uint64_t file_number, uint64_t file_size, Cache::Handle** handle) &#123; Status s; char buf[sizeof(file_number)]; EncodeFixed64(buf, file_number); Slice key(buf, sizeof(buf)); *handle = cache_-&gt;Lookup(key); if (*handle == nullptr) &#123; std::string fname = TableFileName(dbname_, file_number); RandomAccessFile* file = nullptr; Table* table = nullptr; s = env_-&gt;NewRandomAccessFile(fname, &amp;file); if (!s.ok()) &#123; std::string old_fname = SSTTableFileName(dbname_, file_number); if (env_-&gt;NewRandomAccessFile(old_fname, &amp;file).ok()) &#123; s = Status::OK(); &#125; &#125; if (s.ok()) &#123; s = Table::Open(options_, file, file_size, &amp;table); &#125; TableAndFile就是打包RandomAccessFile*和Table*。1234567891011121314 if (!s.ok()) &#123; assert(table == nullptr); delete file; // We do not cache error results so that if the error is transient, // or somebody repairs the file, we recover automatically. &#125; else &#123; TableAndFile* tf = new TableAndFile; tf-&gt;file = file; tf-&gt;table = table; *handle = cache_-&gt;Insert(key, tf, 1, &amp;DeleteEntry); &#125; &#125; return s;&#125; 下面来看Get函数，现在我们已经能得到对应的Table*了，此时调用InternalGet方法。12345678910111213Status TableCache::Get(const ReadOptions&amp; options, uint64_t file_number, uint64_t file_size, const Slice&amp; k, void* arg, void (*handle_result)(void*, const Slice&amp;, const Slice&amp;)) &#123; Cache::Handle* handle = nullptr; Status s = FindTable(file_number, file_size, &amp;handle); if (s.ok()) &#123; Table* t = reinterpret_cast&lt;TableAndFile*&gt;(cache_-&gt;Value(handle))-&gt;table; s = t-&gt;InternalGet(options, k, arg, handle_result); cache_-&gt;Release(handle); &#125; return s;&#125; Table::InternalGet12345678910Status Table::InternalGet(const ReadOptions&amp; options, const Slice&amp; k, void* arg, void (*handle_result)(void*, const Slice&amp;, const Slice&amp;)) &#123; Status s; Iterator* iiter = rep_-&gt;index_block-&gt;NewIterator(rep_-&gt;options.comparator); iiter-&gt;Seek(k); if (iiter-&gt;Valid()) &#123; Slice handle_value = iiter-&gt;value(); FilterBlockReader* filter = rep_-&gt;filter; BlockHandle handle; 首先，可以通过布隆过滤器判断这个block里面有没有。1234if (filter != nullptr &amp;&amp; handle.DecodeFrom(&amp;handle_value).ok() &amp;&amp; !filter-&gt;KeyMayMatch(handle.offset(), k)) &#123; // Not found&#125; else &#123; 由于布隆过滤器可能假阳，所以这边还需要实际Seek一下。我们先前介绍过BlockReader，这个函数返回一个Iterator。实际上是一个Block::Iter对象。当时他被用在创建TwoLevelIterator里面，这个双层迭代器实际上就是index block上的迭代器和data block上的迭代器的组合。123456789101112131415 Iterator* block_iter = BlockReader(this, options, iiter-&gt;value()); block_iter-&gt;Seek(k); if (block_iter-&gt;Valid()) &#123; (*handle_result)(arg, block_iter-&gt;key(), block_iter-&gt;value()); &#125; s = block_iter-&gt;status(); delete block_iter; &#125; &#125; if (s.ok()) &#123; s = iiter-&gt;status(); &#125; delete iiter; return s;&#125; Table::Open【这一部分可以先不读，因为所有对SSTable的读key请求，最后都是从Cache里面处理了】Table::Open负责读取SSTable到表对象Table中。123456Status Table::Open(const Options&amp; options, RandomAccessFile* file, uint64_t size, Table** table) &#123; *table = nullptr; if (size &lt; Footer::kEncodedLength) &#123; return Status::Corruption("file is too short to be an sstable"); &#125; 先读取footer。123456789char footer_space[Footer::kEncodedLength];Slice footer_input;Status s = file-&gt;Read(size - Footer::kEncodedLength, Footer::kEncodedLength, &amp;footer_input, footer_space);if (!s.ok()) return s;Footer footer;s = footer.DecodeFrom(&amp;footer_input);if (!s.ok()) return s; 再读取block。1234567891011121314151617181920212223242526 // Read the index block BlockContents index_block_contents; ReadOptions opt; if (options.paranoid_checks) &#123; opt.verify_checksums = true; &#125; s = ReadBlock(file, opt, footer.index_handle(), &amp;index_block_contents); if (s.ok()) &#123; // We've successfully read the footer and the index block: we're // ready to serve requests. Block* index_block = new Block(index_block_contents); Rep* rep = new Table::Rep; rep-&gt;options = options; rep-&gt;file = file; rep-&gt;metaindex_handle = footer.metaindex_handle(); rep-&gt;index_block = index_block; rep-&gt;cache_id = (options.block_cache ? options.block_cache-&gt;NewId() : 0); rep-&gt;filter_data = nullptr; rep-&gt;filter = nullptr; *table = new Table(rep); (*table)-&gt;ReadMeta(footer); &#125; return s;&#125; 主体函数主要就是构造一个state，然后调用ForEachOverlapping12345678910111213141516171819202122232425262728Status Version::Get(const ReadOptions&amp; options, const LookupKey&amp; k, std::string* value, GetStats* stats) &#123; stats-&gt;seek_file = nullptr; stats-&gt;seek_file_level = -1; struct State &#123; ... &#125;; State state; state.found = false; state.stats = stats; state.last_file_read = nullptr; state.last_file_read_level = -1; state.options = &amp;options; state.ikey = k.internal_key(); state.vset = vset_; state.saver.state = kNotFound; state.saver.ucmp = vset_-&gt;icmp_.user_comparator(); state.saver.user_key = k.user_key(); state.saver.value = value; ForEachOverlapping(state.saver.user_key, state.ikey, &amp;state, &amp;State::Match); return state.found ? state.s : Status::NotFound(Slice());&#125; 故障恢复Manifest损坏/丢失Reference http://luodw.cc/2015/10/30/leveldb-14/介绍WriteBatch https://zhuanlan.zhihu.com/p/340804308介绍Revocer逻辑 https://blog.csdn.net/sparkliang/article/details/9311487介绍RecoverLogFile https://izualzhy.cn/leveldb-write-read 介绍了LevelDB读写流程，我使用了它的部分图片 https://leeshine.github.io/2019/01/24/leveldb-put-get/ https://sf-zhou.github.io/leveldb/leveldb_10_details.html 讲述多线程写的demo，很值得一看 http://1feng.github.io/2016/08/24/mvcc-and-manifest/ 介绍MVCC机制，很好 https://www.cnblogs.com/cobbliu/p/6194072.html 介绍SSTable、Block的格式，一张大图，非常屌 https://blog.csdn.net/weixin_42663840/article/details/82629473 我见过最屌有关读写的注释]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LevelDB之Compaction实现]]></title>
    <url>%2F2021%2F04%2F18%2Fleveldb-compaction%2F</url>
    <content type="text"><![CDATA[本文介绍LevelDB的SSTable之间的Compaction。Compaction分两种： Minor Compaction 对应Memtable到SSTable的过程。 Major Compaction 对应SSTable文件之间的归并。涉及到两个Level的SSTable文件。 Major Compaction中还可以细分，比如是否Manual等。对于非Manual，还有seek compaction和size compaction。 在本文中，还会介绍Version和VersionEdit概念，它们有助于理解LevelDB对MVCC的实现。 同样的，文章中的【Q】表示我在阅读源码的过程中产生的疑问，有的我找到的解答，或者自己产生了思考，有的则未必清楚。 我们首先来回顾一下LevelDB的整体架构 之前提到过，当一个Memtable满了之后，会转化为Immutable Memtable。Immutable Memtable会被Dump成SSTable文件，SSTable文件是不可变的。这里GUARDED_BY(m)实际上是__attribute__(guarded_by(m))这个线程安全注解，方便编译器帮助检查有没有遗漏掉加锁的情况。123456class DBImpl : public DB &#123;... MemTable* mem_; MemTable* imm_ GUARDED_BY(mutex_); // Memtable being compacted...&#125; 前置知识LCS和STCS有两种Compacton方案：Size-Tiered Compaction Strategy(STCS)和Leveled Compaction Strategy(LCS)。 STCSMemtable刷成小sstable。当这些小的sstable达到一定个数时，会被compact成一个稍大些的sstable。当稍大些的sstable又达到一定个数时，又会被一起compact成更大的sstable。当然，如果说某些Key的更新频率比较高，那么在Compact的时候只会取最新的Sequence Number，这种情况下，可能不会增加太多。下图是STCS的一个示意，可以看到，每层的SSTable数量不变，但是大小越来越大。 LCS(Classic Leveled)STCS存在一些问题，是可以被优化的： 存储放大1 因为Compaction时，在新SSTable生成前，旧的SSTable不能删除（当然LevelDB中有Version的概念，其实更复杂点），所以可能会造成额外一倍的开销。 于是我们临机一动，我们增加SSTable数量，而控制大小不变，不就能控制这额外一倍开销的绝对数量么？ 存储放大2 如果Key更新频繁，可能导致同一个Level以及不同Level中的SSTable中存在相同的Key。这里的Key实际上就是LevelDB里面的user key，而不是带有Sequence Number的InternalKey。 【Q】为什么不同Level会存在呢？ 为此，我们就得到了LCS： 当Level0层数量达到Level0层阈值时，将这些SSTable和L1层的所有SSTable做Compaction。 实际上，具体涉及哪些SSTable，在LevelDB中控制更为精细。并且Compaction的条件也更复杂。 如果Level1层的SSTable数量还是超过L1层的阈值，再把这些超出的SSTable向上做Compaction。 除了Level0，其他层的所有SSTable中的key都是不重叠的。 下图是LCS的一个示意 我们注意到，LCS中，SSTable的大小不变，但是数量会增多，Level N+1的文件数量是Level N的10倍。【Q】这里看上去和LevelDB的实现还有区别，LevelDB里面的MaxBytesForLevel函数更多的是计算了10倍的大小，Why？这个我们在“Major Compaction流程”章节中讨论过了，每个文件大小是固定的，LevelDB通过限制每层的总大小来间接限制文件数量。这是因为我们dump的时候更方便统计大小而不是文件数量。所以，假如Level1有10个文件，Level2就有100个文件。但是key在两个level中都是均匀分布的，因此我Level1拿出一个文件出来，Level2中估计只会有10个文件和它重叠，所以我们只需要合并重叠的这些文件就行了。当然，Level0彼此重叠，所以还是emmmm。。。 LCS的缺点是写放大会比STCS显著提高。 【Q】既然LCS的写放大高了很多，为什么说基于LSM的写性能很好呢？可能是因为下面几点 SSTable是顺序写，性能好【Q】 根据RocksDB的文档，在一些情况下写放大不是很严重 首先是按key顺序的写，对于这种情况RocksDB可以优化。 其次是有skew的写，会导致只有小部分的key被更新。 Level-N相比LCS(Classic Leveled)有更高的读放大，和更小的写放大。 Tiered+Leveled常见文件需要注意的是，LevelDB是一个单机的数据库，所以实际承载的SSTable文件都位于一台机器上。 文件类型123456789enum FileType &#123; kLogFile, kDBLockFile, kTableFile, kDescriptorFile, kCurrentFile, kTempFile, kInfoLogFile // Either the current one, or an old one&#125;; kLogFile：WAL日志文件，文件名数字.log kDBLockFile：db锁文件，文件名LOCK kTableFile：SSTable文件，文件名数字.sst kDescriptorFile：Manifest文件，存储VersionEdit信息，文件名为MANIFEST-数字 对应descriptor_file_这个字段。 Manifest文件中维护了所有的SSTable的key范围，层级，以及其他的元信息。 kCurrentFile：记录当前的Manifest文件，文件名为CURRENT kTempFile：临时文件，db在修复【？】过程中会产生临时文件，文件名为数字.dbtmp kInfoLogFile：日志文件，文件名为LOG Manifest每一个VersionEdit对应Manifest里面的一个Entry，称为Session Record。其中第一条Session Record包含当时LevelDB的全量版本信息，这个应该是通过WriteSnapshot来实现的，可以看下面的介绍。 如下所示，每个Entry包含 增加的SSTable kNewFile 删除的SSTable kDeletedFile 当前Compaction的下标 kCompactPointer 日志文件编号 kLogNumber 数据库已经持久化数据项中最大的Sequence Number kLastSequence 对应的代码如下1234567891011enum Tag &#123; kComparator = 1, kLogNumber = 2, kNextFileNumber = 3, kLastSequence = 4, kCompactPointer = 5, kDeletedFile = 6, kNewFile = 7, // 8 was used for large value refs kPrevLogNumber = 9&#125;; 写Manifest的代码应该是Writer::AddRecord。读Manifest的代码，例如VersionSet::Recover。 Current记录当前的Manifest文件名。 MVCC介绍参考数据库系统中的事务 Version机制大前提，Compaction过程是通过独立线程异步并发执行的。因此可能出现压缩前后的新老SSTable并存的情况。同时，我们不能立即删除老的SSTable文件，这可能是因为这个SSTable还在被读取，而要等到老SSTable的引用计数为0才行。因此Version机制可以用来辨别这些SSTable的版本。借助于Version机制，也能实现MVCC。 新版本New-Version由Version类和VersionEdit类来描述。即VersionEdit是New-Version相对于Version的改动。1New-Version = Version + VersionEdit LevelDB将所有的Version置于一个双向链表之中，因此所有的Version组成一个名为VersionSet的集合。这个集合也代表了当前DB的状态，包含了最新的Version，以及其他正在服务的Version。 VersionEdit介绍作为桥梁作用的VersionEdit类。这个类里面的方法大部分是用来读写里面的私有成员的，所以只介绍私有成员。 std::string comparator_; uint64_t log_number_; 包含 1void SetLogNumber(uint64_t num) log文件的file number，也就是000003.log的这个3。 小于这个值的Log是可以被删除的 【Q】这个字段的作用是什么呢？ 目前来看，在Recover的时候会用到。 【Q】为什么VersionSet里面也有？ 其实VersionSet里面的才是主要的，VersionEdit里面的这个字段，是在LogAndApply的时候，由VersionSet设置过来的。 【Q】这个number，和版本的关系是什么，是一一对应的么？比如一次Compaction之后就要换个log？因为在实现上，可以看到NewFileNumber会产生log(DB::Open)和SSTable(WriteLevel0Table)文件的序列号。 uint64_t prev_log_number_;/bool has_prev_log_number_; 包括void SetPrevLogNumber(uint64_t num)这个函数。 这篇文章说prev_log_number_已经废弃了，出于兼容性才保留的。 uint64_t next_file_number_;/bool has_next_file_number_; 下一个可用的file number。VersionSet里面也有类似字段，详细介绍见VersionSet。 包含 1void SetNextFile(uint64_t num) SequenceNumber last_sequence_;/bool has_last_sequence_; SSTable 中的最大的Sequence Number。VersionSet里面也有个平行的。 bool has_comparator_; bool has_log_number_; std::vector&lt;std::pair&lt;int, InternalKey&gt;&gt; compact_pointers_; 主要用于Major Compaction的时候选择文件。first表示每个level。 【Q】在Compaction类和VersionSet类里面也有一个这个字段。它们的作用是什么呢？ DeletedFileSet deleted_files_; 1typedef std::set&lt;std::pair&lt;int, uint64_t&gt;&gt; DeletedFileSet; pair存储了level和file。表示将第level层中的file删除。 std::vector&lt;std::pair&lt;int, FileMetaData&gt;&gt; new_files_; FileMetaData存储了文件大小，以及文件中最小的Key和最大的Key。 Version相关字段 VersionSet相关 指向这个Version所属的VersionSet，以及双向链表和引用计数。 所以说每个Version只能属于一个VersionSet，这个也是很好理解的， 1234VersionSet* vset_; // VersionSet to which this Version belongsVersion* next_; // Next version in linked listVersion* prev_; // Previous version in linked listint refs_; // Number of live refs to this version SSTable相关 files_表示LevelDB中每一层中所有的SSTable的文件信息。 file_to_compact(_level)_标记下一个要Compact的文件以及属于的Level。 123456// List of files per levelstd::vector&lt;FileMetaData*&gt; files_[config::kNumLevels];// Next file to compact based on seek stats.FileMetaData* file_to_compact_;int file_to_compact_level_; 根据SaveTo函数的论述，files_[level]是有序的。 其他字段 compaction_score_计算最迫切需要Compaction的Level，所以可以决定是否需要发起Major Compaction。这个分数取决于某一层所有SSTable的大小。 NeedsCompaction会读取这个字段，计算是否需要根据Version的情况来Compaction，并呈递给MaybeScheduleCompaction。 1234// Level that should be compacted next and its compaction score.// Score &lt; 1 means compaction is not strictly needed.double compaction_score_;int compaction_level_; 相关函数 int PickLevelForMemTableOutput(const Slice&amp; smallest_user_key, const Slice&amp; largest_user_key); 给定一个Memtable里面的Key的范围，返回这个Memtable被Dump的话要放到第几层。 Compaction* PickCompaction(); 用来处理size compaction和seek compaction。 这个函数，在“Compaction主函数”这个章节介绍。 Compaction* CompactRange(int level, const InternalKey* begin, const InternalKey* end); Version::PickLevelForMemTableOutputOverlapInLevel先介绍辅助函数OverlapInLevel，作用是判断范围[smallest_user_key,largest_user_key]和level中的文件有没有Overlap。12345bool Version::OverlapInLevel(int level, const Slice* smallest_user_key, const Slice* largest_user_key) &#123; return SomeFileOverlapsRange(vset_-&gt;icmp_, (level &gt; 0), files_[level], smallest_user_key, largest_user_key);&#125; SomeFileOverlapsRangeSomeFileOverlapsRange返回files中有没有在范围[smallest_user_key,largest_user_key]中的key，是OverlapInLevel的辅助函数。disjoint_sorted_files表示传入的files里面的key是不是不相交的，一般除了Level0，其他都是不相交的。AfterFile和BeforeFile都比较FileMetaData里面的largest/smallest的user_key()字段。他们的类型是InternalKey，也就是不带Sequence Number和Value Type的。对于普通情况，对于一个文件f，如果smallest_user_key大于该文件中的最大值，或者largest_user_key小于最小值，那么认为是不重叠的。1234567891011121314151617181920bool SomeFileOverlapsRange(const InternalKeyComparator&amp; icmp, bool disjoint_sorted_files, const std::vector&lt;FileMetaData*&gt;&amp; files, const Slice* smallest_user_key, const Slice* largest_user_key) &#123; const Comparator* ucmp = icmp.user_comparator(); if (!disjoint_sorted_files) &#123; // Need to check against all files for (size_t i = 0; i &lt; files.size(); i++) &#123; const FileMetaData* f = files[i]; if (AfterFile(ucmp, smallest_user_key, f) || BeforeFile(ucmp, largest_user_key, f)) &#123; // No overlap &#125; else &#123; return true; // Overlap &#125; &#125; return false; &#125;... 如果是不相交的文件，就可以基于FindFile对files集合二分查找，所以我们看到，在某一个Level找SSTable的时候是可以二分的。可以思考一下我们用什么做二分的key呢？答案是每个file的largest。我们要找到第一个largest大于等于smallest_user_key的文件。123456789101112131415... // Binary search over file list uint32_t index = 0; if (smallest_user_key != nullptr) &#123; // Find the earliest possible internal key for smallest_user_key InternalKey small_key(*smallest_user_key, kMaxSequenceNumber, kValueTypeForSeek); index = FindFile(icmp, files, small_key.Encode()); &#125; if (index &gt;= files.size()) &#123; // beginning of range is after all files, so no overlap. return false; &#125;... 二分法找到可能存在的文件files[index]后，不要忘了在判断下这个文件实际有没有overlap。这是二分法的基本规则。123... return !BeforeFile(ucmp, largest_user_key, files[index]);&#125; 主流程1234int Version::PickLevelForMemTableOutput(const Slice&amp; smallest_user_key, const Slice&amp; largest_user_key) &#123; int level = 0;... 首先判断我们要加入的文件的[smallest_user_key,largest_user_key]和Level0有没有交叠。如果有交叠，就进不了这个if，直接放到第一层，等后面Major Compaction了。如果没有交叠，我们尝试能否将它下放到config::kMaxMemCompactLevel之前的层。【Q】为什么我们要设置上限kMaxMemCompactLevel呢？123456789101112131415161718192021... if (!OverlapInLevel(0, &amp;smallest_user_key, &amp;largest_user_key)) &#123; // Push to next level if there is no overlap in next level, // and the #bytes overlapping in the level after that are limited. InternalKey start(smallest_user_key, kMaxSequenceNumber, kValueTypeForSeek); InternalKey limit(largest_user_key, 0, static_cast&lt;ValueType&gt;(0)); std::vector&lt;FileMetaData*&gt; overlaps; while (level &lt; config::kMaxMemCompactLevel) &#123; if (OverlapInLevel(level + 1, &amp;smallest_user_key, &amp;largest_user_key)) &#123; break; &#125; // 为什么会有这个？下面讲。 if (level + 2 &lt; config::kNumLevels) &#123; // Check that file does not overlap too many grandparent bytes. ... &#125; level++; &#125; &#125; return level;&#125; 判断level + 2层情况的分支详解这里需要着重讲解一下level + 2 &lt; config::kNumLevels这个分支的含义。 作为普通人呢，我觉得判断完OverlapInLevel(level + 1,...就可以直接level++了啊，但是大佬肯定是不平凡的。大佬觉得现在我们想把文件放到level + 1层，但是要先打住，看看level + 2层是什么情况，也就对应到下面的代码。我们要计算所有重叠的文件的总大小，如果这个大小超过了阈值，那么我们就不把这个SSTable进行下放。这是防止level + 1和level + 2的重叠范围太大，导致这两层进行Compaction时涉及的SSTable过多，耗时过长。1234567891011// PickLevelForMemTableOutput中的片段代码... if (level + 2 &lt; config::kNumLevels) &#123; // Check that file does not overlap too many grandparent bytes. GetOverlappingInputs(level + 2, &amp;start, &amp;limit, &amp;overlaps); const int64_t sum = TotalFileSize(overlaps); if (sum &gt; MaxGrandParentOverlapBytes(vset_-&gt;options_)) &#123; break; &#125; &#125;... 于是，先要用GetOverlappingInputs这个函数，计算level + 2层中到底有哪些文件和[smallest_user_key,largest_user_key]有交叠，这些文件会放到overlaps里面。而TotalFileSize这个函数就是对FileMetaData::file_size求和。然后，我们和MaxGrandParentOverlapBytes返回的阈值进行比较。 GetOverlappingInputs/MaxGrandParentOverlapBytesGetOverlappingInputs的目标是找到level中和[begin,end]重叠的所有文件，并放到inputs里面。这个函数对Level0有特殊的处理。1234// Store in "*inputs" all files in "level" that overlap [begin,end]void Version::GetOverlappingInputs(int level, const InternalKey* begin, const InternalKey* end, std::vector&lt;FileMetaData*&gt;* inputs) &#123; user_begin和user_end是从InternalKey中提取出的user key。如果传入nullptr，表示在比较时begin永远小于任何key。【Q】这里为什么去找的user key而不是InternalKey呢？貌似很多地方都是找user key。在这篇文章中，作者指出了一个其实我们很容易注意到的性质，就是除了Level0，每一层Level都是有序的。进一步地，由于LevelDB使用leveled策略(LCS)，即强调一个key在每一层至多只有1条记录，不存在冗余记录。12345678910111213... assert(level &gt;= 0); assert(level &lt; config::kNumLevels); inputs-&gt;clear(); Slice user_begin, user_end; if (begin != nullptr) &#123; user_begin = begin-&gt;user_key(); &#125; if (end != nullptr) &#123; user_end = end-&gt;user_key(); &#125; const Comparator* user_cmp = vset_-&gt;icmp_.user_comparator();... 默认，我们遍历这一层的所有的文件。前面两个if分别处理文件和range完全不重叠的情况。1234567891011... for (size_t i = 0; i &lt; files_[level].size();) &#123; FileMetaData* f = files_[level][i++]; const Slice file_start = f-&gt;smallest.user_key(); const Slice file_limit = f-&gt;largest.user_key(); if (begin != nullptr &amp;&amp; user_cmp-&gt;Compare(file_limit, user_begin) &lt; 0) &#123; // "f" is completely before specified range; skip it &#125; else if (end != nullptr &amp;&amp; user_cmp-&gt;Compare(file_start, user_end) &gt; 0) &#123; // "f" is completely after specified range; skip it &#125; else &#123;... 否则就是有重叠的，我们把这个文件加入到inputs里面作为结果返回。对于PickLevelForMemTableOutput的逻辑而言，这里就到此为止了。但是GetOverlappingInputs这个函数还会在CompactRange、SetupOtherInputs这些函数中用到。此时，需要处理Level0的逻辑。【Q】且慢，我们已经逐文件遍历了啊，还会有什么问题呢？12345678910111213141516171819... inputs-&gt;push_back(f); if (level == 0) &#123; // Level-0 files may overlap each other. So check if the newly // added file has expanded the range. If so, restart search. if (begin != nullptr &amp;&amp; user_cmp-&gt;Compare(file_start, user_begin) &lt; 0) &#123; user_begin = file_start; inputs-&gt;clear(); i = 0; &#125; else if (end != nullptr &amp;&amp; user_cmp-&gt;Compare(file_limit, user_end) &gt; 0) &#123; user_end = file_limit; inputs-&gt;clear(); i = 0; &#125; &#125; &#125; &#125;&#125; 在这篇文章中，详细解释了原因。这是因为我们认为Level1的文件是比Level0要旧的，所以如果要把Level0中的某个文件f移动到Level1中，我们要把Level0中所有和fOverlap的文件都放到Level1里面。这样，实际上保证了如果我有一个Key在Level0里面，那么inputs里面会包含所有包含这个Key的文件。 进一步想，在Level0往Level1归并的时候，其实也应该看到这个过程。事实上观看PickCompaction的代码实现，我们也能看到在最后有个if (level == 0)的判断。 这个应当同样解决我们在IsTrivialMove的一个疑问，也就是为什么Level层有两个的时候，我们不能简单把其中一个文件移动到下层。 所以，当检查到user_begin在文件[file_start,file_limit]中后，需要将user_begin调整为文件的开头file_start。对user_end也是同理的。 VersionSet成员介绍 Status VersionSet::LogAndApply(VersionEdit* edit, port::Mutex* mu) 这个函数接受一个VersionEdit。 首先，函数将VersionEdit应用在current_，并借助于VersionSet::Builder生成一个新的Version。Builder类的实现是比较巧妙的，我们会在稍后来讲解。 此后，它会调用Finalize函数更新compaction_level_和compaction_score_。 此后，更新Manifest文件。主要是把VersionEdit中的内容EncodeTo到Manifest文件里面。 此后，调用AppendVersion将新版本添加到VersionSet的双向链表中，并且设置新的current_。 std::string compact_pointer_[config::kNumLevels]; 这个字段在Major Compaction过程中被用到。表示每一层上，下一次Compaction需要开始的key的位置。它要么是一个空串，要么是一个InternalKey。 【Q】在什么时候被设置呢？ 根据文章，这个compact_pointer_实际上表示这一层上一次Compact时文件的largest。 Status Recover(bool* save_manifest); 关于Recover机制，我们不在这篇文章中介绍。详见“LevelDB之流程概览”这篇文章。 有关Sequence： uint64_t LastSequence() const { return last_sequence_; } 还有个对应的SetLastSequence方法。 返回最近的Sequence Number。这个是在写入记录的时候会使用并且更新。 【Q】VersionEdit里面也有个平行的，他们之间的关系是什么呢？ 首先VersionSet的last_sequence_会随着DBImpl::Write操作更新。 当需要进行Compact的时候，会在LogAndApply中赋给VersionEdit中的对应字段。而VersionEdit的目的，似乎只是持久化这个信息。 有关日志： prev_log_number_/log_number_ 【Q】和VersionEdit里面同名字段的关系是什么？见VersionEdit的解释。 有关文件编号： next_file_number_ 包含 123456uint64_t NewFileNumber() &#123; return next_file_number_++; &#125;void ReuseFileNumber(uint64_t file_number) &#123; if (next_file_number_ == file_number + 1) &#123; next_file_number_ = file_number; &#125;&#125; 这个字段用来生成系统中下个文件的编号。VersionEdit需要在LogAndApply时传入，以persist。 【Q】这里的file number指的是SSTable的file number么？看起来并不是的，而是Manifest文件、SSTable文件啥的共用一个编号，这也是为什么一开始Log文件是0，Minifest文件是1，SetNextFile是2的原因。 manifest_file_number_; 表示Manifest文件的编号，主要在Recover时用到 疑问： VersionSet和DBImpl是一一对应的么？ 应该是的，DBImpl持有一个VersionSet*。 VersionSet::LogAndApply在前面已经简单介绍过这个函数的功能了。这个函数主要在下面几个地方用到： DB::Open 当DB启动的时候，可能需要从通过DBImpl::Recover从log中恢复一部分数据。这些数据会以VersionEdit的方式被Apply。 DBImpl::CompactMemTable Minor Compaction。 一般在下面的地方调用： BackgroundCompaction DoCompactionWork：也就是在Major Compaction的过程中也要有限处理Minor Compaction。 BackgroundCompaction的非manual情况（平凡情况） 这种情况只是将某个SSTable移动到别的层。 BackgroundCompaction的manual情况（一般情况） 需要归并。 下面这里讲解一下源码。__attribute__((exclusive_locks_required))表示检查在调用LogAndApply函数之前就要持有锁mu。因此同时只会有一个线程执行LogAndApply。12Status LogAndApply(VersionEdit* edit, port::Mutex* mu) EXCLUSIVE_LOCKS_REQUIRED(mu); 下面是把VersionSet的LogNumber传给VersionEdit。123456789101112Status VersionSet::LogAndApply(VersionEdit* edit, port::Mutex* mu) &#123; if (edit-&gt;has_log_number_) &#123; assert(edit-&gt;log_number_ &gt;= log_number_); assert(edit-&gt;log_number_ &lt; next_file_number_); &#125; else &#123; edit-&gt;SetLogNumber(log_number_); &#125; if (!edit-&gt;has_prev_log_number_) &#123; edit-&gt;SetPrevLogNumber(prev_log_number_); &#125;... 我们要把VersionSet的last_sequence_传给edit，在对VersionSet::Builder的论述中已经推断过这里的作用了。123456789101112... edit-&gt;SetNextFile(next_file_number_); edit-&gt;SetLastSequence(last_sequence_); Version* v = new Version(this); &#123; Builder builder(this, current_); builder.Apply(edit); builder.SaveTo(v); &#125; Finalize(v);... 下面的descriptor_file_就是一个Manifest文件。如果此时descriptor_log_是NULL，根据注释，这个对应到首次打开数据库的状态。我们要新建一个Manifest文件，此时DescriptorFileName产生一个&quot;/MANIFEST-%06llu&quot;格式的文件名字。通过WriteSnapshot把descriptor_log_写到新的Manifest文件里面，这个实际上就是Current Version的快照。WriteSnapshot里面也会调用EncodeTo和AddRecord。【Q】为什么有这个函数？本文之前介绍了Manifest文件的构造，里面提到第一条Session Record记录了当前数据库的全量数据，我认为这里就是实现这个性质的。【Q】注意，VersionSet::ReuseManifest也会修改这个descriptor_log_，有什么影响呢？123456789101112131415161718... // Initialize new descriptor log file if necessary by creating // a temporary file that contains a snapshot of the current version. std::string new_manifest_file; Status s; if (descriptor_log_ == nullptr) &#123; // No reason to unlock *mu here since we only hit this path in the // first call to LogAndApply (when opening the database). assert(descriptor_file_ == nullptr); new_manifest_file = DescriptorFileName(dbname_, manifest_file_number_); edit-&gt;SetNextFile(next_file_number_); s = env_-&gt;NewWritableFile(new_manifest_file, &amp;descriptor_file_); if (s.ok()) &#123; descriptor_log_ = new log::Writer(descriptor_file_); s = WriteSnapshot(descriptor_log_); &#125; &#125;... 下面，是把VersionEdit中的内容EncodeTo到Manifest文件里面。这里不是写快照了，而是写一条Log。其实Manifest文件的格式就是Log。在这里，将写文件的操作都集中在一起，期间是不要加锁的。123456789... // Unlock during expensive MANIFEST log write &#123; mu-&gt;Unlock(); // Write new record to MANIFEST log if (s.ok()) &#123; std::string record;... EncodeTo将信息按照下面的Tag分类1234567891011enum Tag &#123; kComparator = 1, kLogNumber = 2, kNextFileNumber = 3, kLastSequence = 4, kCompactPointer = 5, kDeletedFile = 6, kNewFile = 7, // 8 was used for large value refs kPrevLogNumber = 9&#125;; AddRecord将信息编码到文件中，对应的读取函数是Reader::ReadRecord1234567891011121314151617181920... edit-&gt;EncodeTo(&amp;record); s = descriptor_log_-&gt;AddRecord(record); if (s.ok()) &#123; s = descriptor_file_-&gt;Sync(); &#125; if (!s.ok()) &#123; Log(options_-&gt;info_log, "MANIFEST write: %s\n", s.ToString().c_str()); &#125; &#125; // If we just created a new descriptor file, install it by writing a // new CURRENT file that points to it. if (s.ok() &amp;&amp; !new_manifest_file.empty()) &#123; s = SetCurrentFile(env_, dbname_, manifest_file_number_); &#125; mu-&gt;Lock(); &#125;... 我们现在得到了一个新的Version即v，调用AppendVersion将它设置为current_。这个函数还会将v添加到VersionSet里面的那个双向链表里面。文章中有疑问这里遇到多线程怎么办，但LevelDB中Compact只有一条后台线程，并且这里是持有锁的。12345678910111213141516171819... // Install the new version if (s.ok()) &#123; AppendVersion(v); log_number_ = edit-&gt;log_number_; prev_log_number_ = edit-&gt;prev_log_number_; &#125; else &#123; delete v; if (!new_manifest_file.empty()) &#123; delete descriptor_log_; delete descriptor_file_; descriptor_log_ = nullptr; descriptor_file_ = nullptr; env_-&gt;RemoveFile(new_manifest_file); &#125; &#125; return s;&#125; VersionSet::AppendVersion这里dummy_versions_是VersionSet维护的环状链表头，dummy_versions_.prev_就是current_。12345678910111213141516void VersionSet::AppendVersion(Version* v) &#123; // Make "v" current assert(v-&gt;refs_ == 0); assert(v != current_); if (current_ != nullptr) &#123; current_-&gt;Unref(); &#125; current_ = v; v-&gt;Ref(); // Append to linked list v-&gt;prev_ = dummy_versions_.prev_; v-&gt;next_ = &amp;dummy_versions_; v-&gt;prev_-&gt;next_ = v; v-&gt;next_-&gt;prev_ = v;&#125; 可以通过下面的图清晰看出 VersionSet::Builder VersionSet* vset_; 在构造时传入的VersionSet。 Version* base_; 在构造时传入的，一般为current_ LevelState levels_[config::kNumLevels]; LevelState里面记录了增加和删除的文件。 void Apply(VersionEdit* edit) 将edit里面的变动应用到current_。例如要加些什么文件，写到levels_[level].added_files这个列表里面。但是我们不实际加，而是到SaveTo里面再一次性加。 【Q】为什么要这样子呢？原因有2： v-&gt;files_[level]这个是有序存储的。 void SaveTo(Version* v) 注意，从VersionSet::Recover可以看出，Applt和SaveTo并不是一对一的关系。例如我们从一个文件中多个记录里面恢复，那么每读取一个记录就要Apply一次，但最后再SaveTo。 VersionSet::Builder::Apply这个函数设置诸如levels_[level].added_files的字段，表示我们需要做什么改变。首先将VersionEdit记录的compact_pointers_应用到VersionSet。123456789// Apply all of the edits in *edit to the current state.void Apply(VersionEdit* edit) &#123; // Update compaction pointers for (size_t i = 0; i &lt; edit-&gt;compact_pointers_.size(); i++) &#123; const int level = edit-&gt;compact_pointers_[i].first; vset_-&gt;compact_pointer_[level] = edit-&gt;compact_pointers_[i].second.Encode().ToString(); &#125;... 然后把要增加和删除的文件记录到自己的levels_字段里面。12345678... // Delete files for (const auto&amp; deleted_file_set_kvp : edit-&gt;deleted_files_) &#123; const int level = deleted_file_set_kvp.first; const uint64_t number = deleted_file_set_kvp.second; levels_[level].deleted_files.insert(number); &#125;... 在增加文件的时候，需要处理allowed_seeks字段。这里的16384U有点奇怪，是啥意思？根据注释，我们假设： 一次Seek耗时10ms 读写1MB耗时10ms，也就是我们的IO速度是100MB/s 一次Compaction，假设是1MB，需要消耗25MB的IO 需要从这一层读取1MB 从下一层读取10-12MB的数据(boundaries may be misaligned) 写10-12MB的数据到下一层 这说明25次Seek的开销等于1MB数据的Compaction成本，也就是一次Seek大概摊还下来是40KB数据的压缩成本。我们做一些保留，让16KB对应一次Compaction，也就是允许更多的Seek次数。同时，我们将f-&gt;allowed_seeks最小值设为100，这样也不会一直Compaction。1234567891011121314... // Add new files for (size_t i = 0; i &lt; edit-&gt;new_files_.size(); i++) &#123; const int level = edit-&gt;new_files_[i].first; FileMetaData* f = new FileMetaData(edit-&gt;new_files_[i].second); f-&gt;refs = 1; f-&gt;allowed_seeks = static_cast&lt;int&gt;((f-&gt;file_size / 16384U)); // 16*1024 if (f-&gt;allowed_seeks &lt; 100) f-&gt;allowed_seeks = 100; levels_[level].deleted_files.erase(f-&gt;number); levels_[level].added_files-&gt;insert(f); &#125;&#125; VersionSet::Builder::SaveToSaveTo的最终影响是MaybeAddFile，也就是说将文件添加到Version里面。具体是添加到v-&gt;files_里面。12345// Save the current state in *v.void SaveTo(Version* v) &#123; BySmallestKey cmp; cmp.internal_comparator = &amp;vset_-&gt;icmp_;... 下面的循环中，我们依次处理每一层的合并。主要内容是： 将添加的文件合并到files_ 删除文件 之前介绍过base_在构造时传入，一般为CURRENT，我们就是要对base_去应用这些修改。所以，我们是1base_-&gt;files_[level] + (levels_[level].added_files - levels_[level].deleted_files) = v-&gt;files_[level] base_iter用来遍历原有的文件。12345678... for (int level = 0; level &lt; config::kNumLevels; level++) &#123; // Merge the set of added files with the set of pre-existing files. // Drop any deleted files. Store the result in *v. const std::vector&lt;FileMetaData*&gt;&amp; base_files = base_-&gt;files_[level]; std::vector&lt;FileMetaData*&gt;::const_iterator base_iter = base_files.begin(); std::vector&lt;FileMetaData*&gt;::const_iterator base_end = base_files.end();... 我们首先预留最大空间，避免到时候的频繁动态分配。但是实际上最终未必用到这个空间，因为MaybeAddFile不一定真的添加文件。下面就是插入操作，这个有点奇怪。我们先初始化了bpos，但是循环中自增的却是base_iter，for(A;B;C)里面A和C的主语不一样，很奇怪。其实bpos标记了我们要遍历的终点。具体解释一下，这个函数其实是一个归并的过程，分两步： 插入原有的base_里面的文件，这些文件要小于等于added_file std::upper_bound找到第一个大于added_file的位置bpos，也就是我们的base_iter往后遍历，不会超过bpos。 我们用MaybeAddFile插入，因为这些文件可能已经被标记删除。 插入added_file 那么这么做的好处在哪里呢？我认为是减少了比较的次数，从O(n)到了O(logn)。因为我们这里是BytewiseComparator，是两个Slice之间的比较，所以开销还是比较大的，这里是值得学习的一个Best Practice。12345678910111213141516171819... const FileSet* added_files = levels_[level].added_files; v-&gt;files_[level].reserve(base_files.size() + added_files-&gt;size()); for (const auto&amp; added_file : *added_files) &#123; // Add all smaller files listed in base_ for (std::vector&lt;FileMetaData*&gt;::const_iterator bpos = std::upper_bound(base_iter, base_end, added_file, cmp); base_iter != bpos; ++base_iter) &#123; MaybeAddFile(v, level, *base_iter); &#125; MaybeAddFile(v, level, added_file); &#125; // Add remaining base files for (; base_iter != base_end; ++base_iter) &#123; MaybeAddFile(v, level, *base_iter); &#125;... 在Debug的状态下，会去检查除Level0之外的层有没有重叠。检查方法也很简单，就是看后一个文件的smallest是不是一定严格大于前一个文件的largest。123456789101112131415161718...#ifndef NDEBUG // Make sure there is no overlap in levels &gt; 0 if (level &gt; 0) &#123; for (uint32_t i = 1; i &lt; v-&gt;files_[level].size(); i++) &#123; const InternalKey&amp; prev_end = v-&gt;files_[level][i - 1]-&gt;largest; const InternalKey&amp; this_begin = v-&gt;files_[level][i]-&gt;smallest; if (vset_-&gt;icmp_.Compare(prev_end, this_begin) &gt;= 0) &#123; std::fprintf(stderr, "overlapping ranges in same level %s vs. %s\n", prev_end.DebugString().c_str(), this_begin.DebugString().c_str()); std::abort(); &#125; &#125; &#125;#endif &#125;&#125; VersionSet::Builder::MaybeAddFile1234567891011121314void MaybeAddFile(Version* v, int level, FileMetaData* f) &#123; if (levels_[level].deleted_files.count(f-&gt;number) &gt; 0) &#123; // File is deleted: do nothing &#125; else &#123; std::vector&lt;FileMetaData*&gt;* files = &amp;v-&gt;files_[level]; if (level &gt; 0 &amp;&amp; !files-&gt;empty()) &#123; // Must not overlap assert(vset_-&gt;icmp_.Compare((*files)[files-&gt;size() - 1]-&gt;largest, f-&gt;smallest) &lt; 0); &#125; f-&gt;refs++; files-&gt;push_back(f); &#125;&#125; VersionSet::Finalize12345678void VersionSet::Finalize(Version* v) &#123; // Precomputed best level for next compaction int best_level = -1; double best_score = -1; for (int level = 0; level &lt; config::kNumLevels - 1; level++) &#123; double score;... 下面是针对第0层的特殊情况。我们知道LevelDB的第0层最多存在4个文件【Q】（我觉得未必，详见kL0_SlowdownWritesTrigger），这就是由kL0_CompactionTrigger控制的。这里使用文件数量，注释里面列了两个原因： 允许更大的写buffer，从而减少Level0 Compaction的数量。 这里的写buffer应该是options_.write_buffer_size这个东西。这个阈值控制Memtable何时转换成Immutable Memtable，以及在Recover的时候何时直接dump成SSTable。 佶屈聱牙，实际上的意思是，这个意思是，如果写buffer太大，如果我们用固定的size限制死了的话，可能Level0的文件数量会很少，比如就1个，这样会导致频繁的Level0 Compaction。 Level0的文件每次读取都会被Merge。我们不希望有很多个小文件(perhaps because of a small write-buffer setting, or very high compression ratios, or lots of overwrites/deletions)。 如果写buffer很小，这样会导致更多的Level0文件。因为Level0的文件是overlap的，所以如果数量过多，每次查询需要Seek的文件数量就越多。 123456... if (level == 0) &#123; score = v-&gt;files_[level].size() / static_cast&lt;double&gt;(config::kL0_CompactionTrigger); // ==4 &#125; else &#123;... 对于第1层以下的层，计算文件总大小，而不是文件数量了。MaxBytesForLevel的大概意思就是Level1总大小是10M，下面每一层翻10倍。12345678910111213141516... // Compute the ratio of current size to size limit. const uint64_t level_bytes = TotalFileSize(v-&gt;files_[level]); score = static_cast&lt;double&gt;(level_bytes) / MaxBytesForLevel(options_, level); &#125; if (score &gt; best_score) &#123; best_level = level; best_score = score; &#125; &#125; v-&gt;compaction_level_ = best_level; v-&gt;compaction_score_ = best_score;&#125; MaxBytesForLevel这个函数计算每一层的最大大小。123456789101112static double MaxBytesForLevel(const Options* options, int level) &#123; // Note: the result for level zero is not really used since we set // the level-0 compaction threshold based on number of files. // Result for both level-0 and level-1 double result = 10. * 1048576.0; while (level &gt; 1) &#123; result *= 10; level--; &#125; return result;&#125; 析构函数将自己从链表中移除。对于自己管理的所有文件，引用计数减一。【Q】这边不搞个原子操作么？12345678910111213141516171819Version::~Version() &#123; assert(refs_ == 0); // Remove from linked list prev_-&gt;next_ = next_; next_-&gt;prev_ = prev_; // Drop references to files for (int level = 0; level &lt; config::kNumLevels; level++) &#123; for (size_t i = 0; i &lt; files_[level].size(); i++) &#123; FileMetaData* f = files_[level][i]; assert(f-&gt;refs &gt; 0); f-&gt;refs--; if (f-&gt;refs &lt;= 0) &#123; delete f; &#125; &#125; &#125;&#125; LevelDB对MVCC的实现总结版本升级文章中论述了一次版本升级的过程，但我会批注一下具体实现的函数和逻辑 新建一个Session Record，记录状态变更信息 讨论版本升级原因 Minor Compaction或者日志replay 在Session Record中记录新增的文件信息、最新的journal编号、数据库sequence number以及下一个可用的文件编号。 Major Compaction 在Session Record中记录新增、删除的文件信息、下一个可用的文件编号即可。 通过VersionEdit生成新版本 相较于旧的版本信息，新的版本信息更改的内容为： 每一层的文件信息：在VersionSet::Builder::Apply中。 每一层的计分信息：在VersionSet::Finalize中。 将Session Record持久化 在VersionSet::Builder::SaveTo中。 讨论是否是第一条Session Record 在LogAndApply的Finalize调用之后的部分 是 新建一个Manifest文件，并将完整的版本信息全部记录进Session Record作为该Manifest的基础状态写入，同时更改Current文件，将其指向新建的Manifest。 不是 将该条Session Record进行序列化后直接作为一条记录写入即可。 将当前的Version设置为刚创建的Version 这个会修改current_的指向。这个操作应该是原子的（不然最新版本岂不是会不一致么）实际上也在mutex_的保护下。 在LogAndApply对AppendVersion的调用中。 Snapshot机制我们在这里介绍Snapshot机制，主要是为了方便说明它对Compaction的影响：导致同一个user key的不同的Sequence Number版本存在多个。 Snapshot实际上就是某个特定的Sequence Number。【Q】Sequence Number是全局递增的么？应该是这样的，在Put和Get的实现中，看到的都是读取的VersionSet::LastSequence()这个。 1234const Snapshot* DBImpl::GetSnapshot() &#123; MutexLock l(&amp;mutex_); return snapshots_.New(versions_-&gt;LastSequence());&#125; Compaction主函数总览调用路径 BackgroundCompaction BackgroundCall BGWork MaybeScheduleCompaction 会Schedule方法BGWork。 这个函数在BackgroundCall，以及诸如Get等读写方法中都会被调用。 Compaction条件 Minor Compaction 在Recover过程中ApproximateMemoryUsage检测到Memtable超限，会直接触发对Memtable的Compaction。但这个Compaction是局部的，因为我们在恢复过程中，所以不需要诸如LogAndApply这种维护Version的工作。 存在Immutable Memtable Manual Compaction CompactRange调用 size_compaction 在VersionSet::PickCompaction中检查并启动。 当Level0文件数目过多，或者某个Level的总大小过大。 在函数NeedsCompaction中判断当前Version的compaction_score_(size compaction)和file_to_compact_(seek compaction)。 seek_compaction seek次数太多。我们知道，当一个文件找不到时，就需要到高一级的Level中去查找。假如在Level(n)中没找到，但是在Level(n+1)中找到了，就认为Level(n)有一次未命中。容易发现如果未命中次数多了，就说明Level N和Level N+1 的文件overlap很厉害，这就需要通过一次Major Compaction来解决这个问题。 DBImpl类LevelDB通过class DB对外暴露C++接口，这个DB的实现就是DBImpl。 DBImpl::BackgroundCallBackgroundCall是在后台线程中执行的。1234567891011121314151617void DBImpl::BackgroundCall() &#123; MutexLock l(&amp;mutex_); assert(background_compaction_scheduled_); if (shutting_down_.load(std::memory_order_acquire)) &#123; // No more background work when shutting down. &#125; else if (!bg_error_.ok()) &#123; // No more background work after a background error. &#125; else &#123; BackgroundCompaction(); &#125; background_compaction_scheduled_ = false; // Previous compaction may have produced too many files in a level, // so reschedule another compaction if needed. MaybeScheduleCompaction();... MakeRoomForWrite函数会在background_work_finished_signal_等待Compaction结束。123... background_work_finished_signal_.SignalAll();&#125; DBImpl::MaybeScheduleCompaction函数MaybeScheduleCompaction决定是否进行Compaction。这里需要加锁，不然可能会导致开两个后台进程，而LevelDB只允许一个后台进程。12345678910111213141516void DBImpl::MaybeScheduleCompaction() &#123; mutex_.AssertHeld(); if (background_compaction_scheduled_) &#123; // Already scheduled &#125; else if (shutting_down_.load(std::memory_order_acquire)) &#123; // DB is being deleted; no more background compactions &#125; else if (!bg_error_.ok()) &#123; // Already got an error; no more changes &#125; else if (imm_ == nullptr &amp;&amp; manual_compaction_ == nullptr &amp;&amp; !versions_-&gt;NeedsCompaction()) &#123; // No work to be done &#125; else &#123; background_compaction_scheduled_ = true; env_-&gt;Schedule(&amp;DBImpl::BGWork, this); &#125;&#125; PosixEnv::Schedule这里的env_的实现实际上是一个PosixEnv。我们查看源码，原来这个后台进程只有一个started_background_thread_，一开始先检查它是否存在，如果不存在，就创建一个，然后detach掉。接下来就是一个生产者消费者模式。不过有点奇怪，是先Signal，再入队，不应该先修改条件，再Signal么。我在文章中提过陈硕大佬的一篇博客，在CV语境中，先Signal，再设置条件flag(代码里面的Case 6)也是可以的，但只限于单waiter使用。1234567891011121314151617181920void PosixEnv::Schedule( void (*background_work_function)(void* background_work_arg), void* background_work_arg) &#123; background_work_mutex_.Lock(); // Start the background thread, if we haven't done so already. if (!started_background_thread_) &#123; started_background_thread_ = true; std::thread background_thread(PosixEnv::BackgroundThreadEntryPoint, this); background_thread.detach(); &#125; // If the queue is empty, the background thread may be waiting for work. if (background_work_queue_.empty()) &#123; background_work_cv_.Signal(); &#125; background_work_queue_.emplace(background_work_function, background_work_arg); background_work_mutex_.Unlock();&#125; 下面放一下消费者的代码123456789101112131415161718192021222324void PosixEnv::BackgroundThreadMain() &#123; while (true) &#123; background_work_mutex_.Lock(); // Wait until there is work to be done. while (background_work_queue_.empty()) &#123; background_work_cv_.Wait(); &#125; assert(!background_work_queue_.empty()); auto background_work_function = background_work_queue_.front().function; void* background_work_arg = background_work_queue_.front().arg; background_work_queue_.pop(); background_work_mutex_.Unlock(); background_work_function(background_work_arg); &#125;&#125;PosixEnv::PosixEnv() : background_work_cv_(&amp;background_work_mutex_), started_background_thread_(false), mmap_limiter_(MaxMmaps()), fd_limiter_(MaxOpenFiles()) &#123;&#125; NeedsCompaction1234bool NeedsCompaction() const &#123; Version* v = current_; return (v-&gt;compaction_score_ &gt;= 1) || (v-&gt;file_to_compact_ != NULL);&#125; Compaction类定义在version_set.h文件里面。 主要成员和成员函数 std::vector&lt;FileMetaData*&gt; inputs_[2]; 表示这个Compaction涉及的两个level的文件，也就是输入。 其中level层是inputs_[0]。level + 1层是inputs_[1]，称为parents。 std::vector&lt;FileMetaData*&gt; grandparents_; level + 2层的文件，通常称为grandparents。 int level() const { return level_; } 我们将level_和level_+1层进行压缩。 int num_input_files(int which) const bool IsTrivialMove() const; 是否可以直接移动，而不涉及merge或者split操作。 bool ShouldStopBefore(const Slice&amp; internal_key); VersionEdit* edit() { return &amp;edit_; }/edit_ 这个应该很好理解，Compaction肯定会有文件增删，即使是移动，也是跨层的。所以这里需要一个VersionEdit来描述。 IsTrivialMove这个函数用来判断在Major Compaction的时候能不能直接移动老的文件到下面一层，而不归并生成新的文件，条件有三个： level层只有一个 【Q】疑问：如果level层有多个，level+1层没有，那么我直接移动到下面一层也是安全的？那么禁止这么做的目的是什么？ 检查对GetOverlappingInputs的分析，发现可能是不安全的。如果说Level0的某个文件f和Level1的文件有Overlap，那么就必须要扫描整个Level0层的所有文件，将与f有Overlap的文件都要移到下一层。 level + 1层没有 这个原因应该好理解，如果level+1层有，那么我们就得比较和这个文件有没有Overlap。 和level + 2层的overlap没有超过阈值(实际上是20M) 123456789bool Compaction::IsTrivialMove() const &#123; const VersionSet* vset = input_version_-&gt;vset_; // Avoid a move if there is lots of overlapping grandparent data. // Otherwise, the move could create a parent file that will require // a very expensive merge later on. return (num_input_files(0) == 1 &amp;&amp; num_input_files(1) == 0 &amp;&amp; TotalFileSize(grandparents_) &lt;= MaxGrandParentOverlapBytes(vset-&gt;options_));&#125; DBImpl::BackgroundCompaction这个过程是Compaction的主过程，需要全程持锁。 Minor我们首先需要去CompactMemTable，也就是Minor Compaction。这个肯定是优先级更高的，因为我们只有两个Memtable，所以我们肯定想把Immutable Memtable快速腾空。1234567void DBImpl::BackgroundCompaction() &#123; mutex_.AssertHeld(); if (imm_ != nullptr) &#123; CompactMemTable(); return; &#125; Major详见Major Compaction章节 Minor Compaction流程CompactMemTable主要流程三部分： WriteLevel0Table 将Immutable Memtable生成SSTable文件 这个文件的基本信息写到FileMetaData里面，并在最后写入VersionEdit。 注意，在Recover的过程中，这里其实也可以传入Memtable。 计算添加到哪一层 这个文件未必会放到Level0，可能会直接放到Level1甚至Level2，具体由kMaxMemCompactLevel控制。 将上面说的FileMetaData写入VersionEdit 因此这个函数的实际返回是传入的VersionEdit* edit。 LogAndApply 用我们得到的VersionEdit，去更新数据库状态，并记录。 RemoveObsoleteFiles 重置Immutable Memtable。 删除无用文件。主要包括kLogFile/kLogFile/kTableFile等。 123456789101112131415void DBImpl::CompactMemTable() &#123; mutex_.AssertHeld(); assert(imm_ != nullptr); // Save the contents of the memtable as a new Table VersionEdit edit; Version* base = versions_-&gt;current(); base-&gt;Ref(); Status s = WriteLevel0Table(imm_, &amp;edit, base); base-&gt;Unref(); if (s.ok() &amp;&amp; shutting_down_.load(std::memory_order_acquire)) &#123; s = Status::IOError("Deleting DB during memtable compaction"); &#125;... 下面，就是要把edit应用到当前的VersionSet上。【Q】SetPrevLogNumber是啥意思？为啥要设置为0呢？ 123456789101112131415161718... // Replace immutable memtable with the generated Table if (s.ok()) &#123; edit.SetPrevLogNumber(0); edit.SetLogNumber(logfile_number_); // Earlier logs no longer needed s = versions_-&gt;LogAndApply(&amp;edit, &amp;mutex_); &#125; if (s.ok()) &#123; // Commit to the new state imm_-&gt;Unref(); imm_ = nullptr; has_imm_.store(false, std::memory_order_release); RemoveObsoleteFiles(); &#125; else &#123; RecordBackgroundError(s); &#125;&#125; WriteLevel0Table在前文中，已经介绍过了WriteLevel0Table的作用，下面看实现。 首先，我们计算出一个NewFileNumber，也就是落盘时体现的文件名。关于这个函数，我们之前已经介绍过了，体现在诸如MANIFEST-xxxxx或者yyyyy.log这里的序号。 pending_outputs_中保存了所有正在Compact的SSTable文件，这些文件不能被删除。这引发了我两个问题： 什么时候会删除？ 在RemoveObsoleteFiles里面，马上就能看到了，不急不急 为什么在BuildTable之后就可以删除了？ 1234567891011Status DBImpl::WriteLevel0Table(MemTable* mem, VersionEdit* edit, Version* base) &#123; mutex_.AssertHeld(); const uint64_t start_micros = env_-&gt;NowMicros(); FileMetaData meta; meta.number = versions_-&gt;NewFileNumber(); pending_outputs_.insert(meta.number); Iterator* iter = mem-&gt;NewIterator(); Log(options_.info_log, "Level-0 table #%llu: started", (unsigned long long)meta.number);... 接着，BuildTable创建一个TableBuilder写入数据。值得注意的是，这里并没有加锁。我之前认为这是因为BuildTable里面会自带加锁，但是检查代码并没有。这可能是因为Compaction是单独的线程，诸如生成并写SSTable的过程是可以单独提出来处理的。1234567891011121314... Status s; &#123; mutex_.Unlock(); s = BuildTable(dbname_, env_, options_, table_cache_, iter, &amp;meta); mutex_.Lock(); &#125; Log(options_.info_log, "Level-0 table #%llu: %lld bytes %s", (unsigned long long)meta.number, (unsigned long long)meta.file_size, s.ToString().c_str()); delete iter; pending_outputs_.erase(meta.number);... 新生成的文件未必会放到Level0，可能会直接放到Level1。例如，如果新的SSTable文件和Level1中的文件没有重叠，那么就有可能被放到Level1，具体还需要查看Level2和新SSTable的重叠情况。因此PickLevelForMemTableOutput会生成一个level，表示放到哪一层。下面的edit-&gt;AddFile就是将这个SSTable加到当前的VersionEdit中。1234567891011121314... // Note that if file_size is zero, the file has been deleted and // should not be added to the manifest. int level = 0; if (s.ok() &amp;&amp; meta.file_size &gt; 0) &#123; const Slice min_user_key = meta.smallest.user_key(); const Slice max_user_key = meta.largest.user_key(); if (base != nullptr) &#123; level = base-&gt;PickLevelForMemTableOutput(min_user_key, max_user_key); &#125; edit-&gt;AddFile(level, meta.number, meta.file_size, meta.smallest, meta.largest); &#125;... env_实际上是封装了文件系统等操作。1234567... CompactionStats stats; stats.micros = env_-&gt;NowMicros() - start_micros; stats.bytes_written = meta.file_size; stats_[level].Add(stats); return s;&#125; RemoveObsoleteFiles搞清楚几个问题： 清理文件的范围？看env_-&gt;GetChildren的实现，应该是所有这个db下的文件。 清理文件的类型？ 12345678910111213141516171819void DBImpl::RemoveObsoleteFiles() &#123; mutex_.AssertHeld(); if (!bg_error_.ok()) &#123; // After a background error, we don't know whether a new version may // or may not have been committed, so we cannot safely garbage collect. return; &#125; // Make a set of all of the live files std::set&lt;uint64_t&gt; live = pending_outputs_; versions_-&gt;AddLiveFiles(&amp;live); std::vector&lt;std::string&gt; filenames; env_-&gt;GetChildren(dbname_, &amp;filenames); // Ignoring errors on purpose uint64_t number; FileType type; std::vector&lt;std::string&gt; files_to_delete;... 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849... for (std::string&amp; filename : filenames) &#123; if (ParseFileName(filename, &amp;number, &amp;type)) &#123; bool keep = true; switch (type) &#123; case kLogFile: keep = ((number &gt;= versions_-&gt;LogNumber()) || (number == versions_-&gt;PrevLogNumber())); break; case kDescriptorFile: // Keep my manifest file, and any newer incarnations' // (in case there is a race that allows other incarnations) keep = (number &gt;= versions_-&gt;ManifestFileNumber()); break; case kTableFile: keep = (live.find(number) != live.end()); break; case kTempFile: // Any temp files that are currently being written to must // be recorded in pending_outputs_, which is inserted into "live" keep = (live.find(number) != live.end()); break; case kCurrentFile: case kDBLockFile: case kInfoLogFile: keep = true; break; &#125; if (!keep) &#123; files_to_delete.push_back(std::move(filename)); if (type == kTableFile) &#123; table_cache_-&gt;Evict(number); &#125; Log(options_.info_log, "Delete type=%d #%lld\n", static_cast&lt;int&gt;(type), static_cast&lt;unsigned long long&gt;(number)); &#125; &#125; &#125; // While deleting all files unblock other threads. All files being deleted // have unique names which will not collide with newly created files and // are therefore safe to delete while allowing other threads to proceed. mutex_.Unlock(); for (const std::string&amp; filename : files_to_delete) &#123; env_-&gt;RemoveFile(dbname_ + "/" + filename); &#125; mutex_.Lock();&#125; Major Compaction流程【Q】思考在开始研究Major Compaction前，我们主动思考这个问题 对于Level0里面的文件，是不是可以直接和Level1中的文件Merge？ 答案是不行的，见GetOverlappingInputs的论述。 如果level中的某个文件的key的range过大，它可能和level+1层的很多文件有重合，这样的compaction写放大很重，如何解决这个问题？ 首先，这也是为什么LevelDB要分成很多层的原因，在Merge的时候，最多和下一层中的所有文件Overlap，写放大是可控的。 其次，在Compact的时候，LevelDB一直关注和level+2层的key的重叠情是否超过一定量，即MaxGrandParentOverlapBytes函数。 在ShouldStopBefore判断是否要结束当前SSTable写入，新开文件的时候，考虑当前文件和level+2的Overlap，如果过了，就新开文件。 在IsTrivialMove判断是否可以直接移动文件到下层的时候，考虑要移动的文件和level+2层的Overlap，如果过了，就不能移动。 在PickLevelForMemTableOutput选择Minor Compaction的层时，考虑这个Immutable Memtable的Overlap，如果过了，就不能放在这一层。 从level到level+1的Compaction会对level+2产生什么影响？ LevelDB中多个不相干的合并是可以并发进行的，这个的实现是怎样的？ 需要注意，Level0文件是彼此Overlap的，所以是相干的。 【Q】那么当一个Major Compaction开始的时候，是如何判定是否相干，如果不相干就不Compact的呢？从LevelDB的代码来看，只有一个后台线程进行Compact操作，所以我认为虽然在设计上LSM树是允许并行Compact的，但是LevelDB并没有实现，但RocksDB肯定是实现的。 LevelDB中，每个user key在一层中是不是只会出现一次？ 大多数情况是的，有两个例外。 首先，Level0是Overlap的，可能有多个。 其次，如果使用了Snapshot，那么在下层可能也会有user key相同，但是sequence不同的。见AddBoundaryInputs的论述。 我们往Manifest文件里面写了什么？ LevelDB有容量限制么？ 应该是没有的，但是当最下面一层变得特别大之后，Compaction的开销会很大。 LevelDB到底是限制的每一层的文件数量还是大小？ 【Q】如果限制的是总大小，如果保证生成的SSTable的大小是大致相同的？ 对于Major Compaction来说，是在DoCompactionWork里面通过下面的代码来判断的，也就是说当文件大小达到一定规模后，就会产生新的文件了。 123if (compact-&gt;builder-&gt;FileSize() &gt;= compact-&gt;compaction-&gt;MaxOutputFileSize()) &#123; status = FinishCompactionOutputFile(compact, input); 这个调用最后会转到options-&gt;max_file_size上。 LevelDB每一层的文件数量有限制么？ 首先Level0肯定有，大家说是4个么？我觉得不是。参考下面的代码，4只是表示有4个文件就开始Level0的Compaction。当文件数达到12个，才是上限，这个时候就要停止写了。 123456// Level-0 compaction is started when we hit this many files.static const int kL0_CompactionTrigger = 4;// Soft limit on number of level-0 files. We slow down writes at this point.static const int kL0_SlowdownWritesTrigger = 8;// Maximum number of level-0 files. We stop writes at this point.static const int kL0_StopWritesTrigger = 12; LevelDB底层SSTable中的数据永无出头之日么？ 怎么可能，只要数据被修改，那么就会先到Memtable里面。 Compaction是如何删除文件的？ 注意，即使遍历到有删除标记的，并且这个删除标记的序列号最大。我们也不应该尝试删除，至少要检查下面的层有没有。详见DoCompactionWork DBImpl::BackgroundCompaction下面是对Major Compaction的处理。 计算Compaction对象首先，我们要处理Manual Compaction的情况。如果manual_compaction_不是null，就触发Manual Compaction。我没看到非测试的代码里面有设置manual_compaction_的，但是leveldb_compact_range这个api会显示调用CompactRange，并且DB这个接口中也有CompactRange方法，也就是说，LevelDB对外暴露这个方法。123class LEVELDB_EXPORT DB &#123;...virtual void CompactRange(const Slice* begin, const Slice* end) = 0; 其次，我们调用PickCompaction处理size compaction和seek compaction的情况。PickCompaction会返回当前要Compact的文件，如果返回null，就啥事都不做。对于PickCompaction而言，如果既没有size compaction，又没有seek compaction，返回null。 这个过程是持锁的123456789101112131415161718192021void DBImpl::BackgroundCompaction() &#123;...// 前面是对Minor Compaction的处理 Compaction* c; bool is_manual = (manual_compaction_ != nullptr); InternalKey manual_end; if (is_manual) &#123; ManualCompaction* m = manual_compaction_; c = versions_-&gt;CompactRange(m-&gt;level, m-&gt;begin, m-&gt;end); m-&gt;done = (c == nullptr); if (c != nullptr) &#123; manual_end = c-&gt;input(0, c-&gt;num_input_files(0) - 1)-&gt;largest; &#125; Log(options_.info_log, "Manual compaction at level-%d from %s .. %s; will stop at %s\n", m-&gt;level, (m-&gt;begin ? m-&gt;begin-&gt;DebugString().c_str() : "(begin)"), (m-&gt;end ? m-&gt;end-&gt;DebugString().c_str() : "(end)"), (m-&gt;done ? "(end)" : manual_end.DebugString().c_str())); &#125; else &#123; c = versions_-&gt;PickCompaction(); &#125; 根据Compaction对象进行Compact操作经过上面的代码，我们就得到了一个Compaction* c对象。如果之前PickCompaction没给出这个c，那么就说明这一次不要Compact。如果满足IsTrivialMove条件，就可以不生成新的文件，直接将原文件移动到下一层。对于Trivial的情况我们直接更新c-&gt;edit()，不走InstallCompactionResults的逻辑了。1234567891011121314151617181920Status status;if (c == nullptr) &#123; // Nothing to do&#125; else if (!is_manual &amp;&amp; c-&gt;IsTrivialMove()) &#123; // Move file to next level assert(c-&gt;num_input_files(0) == 1); FileMetaData* f = c-&gt;input(0, 0); c-&gt;edit()-&gt;RemoveFile(c-&gt;level(), f-&gt;number); c-&gt;edit()-&gt;AddFile(c-&gt;level() + 1, f-&gt;number, f-&gt;file_size, f-&gt;smallest, f-&gt;largest); status = versions_-&gt;LogAndApply(c-&gt;edit(), &amp;mutex_); if (!status.ok()) &#123; RecordBackgroundError(status); &#125; VersionSet::LevelSummaryStorage tmp; Log(options_.info_log, "Moved #%lld to level-%d %lld bytes %s: %s\n", static_cast&lt;unsigned long long&gt;(f-&gt;number), c-&gt;level() + 1, static_cast&lt;unsigned long long&gt;(f-&gt;file_size), status.ToString().c_str(), versions_-&gt;LevelSummary(&amp;tmp));&#125; else &#123; 如果不满足IsTrivialMove条件，就是一般情况，由DoCompactionWork处理。DBImpl::CompactionState这个类又封装了Compaction，这是因为要处理两个Level之间的合并，所以要加一些额外的字段。然后我们要CleanupCompaction，这个除了清空compact对象，还需要根据compact-&gt;outputs，找到pending_outputs_里面对应的文件，并移除出pending_outputs_。我们知道compact-&gt;outputs记录了每个输出文件的元信息，而pending_outputs_记录了正在compact的文件，我们compact结束，就把这些文件移出去。在Major Compaction中，文件是在DoCompactionWork -&gt; OpenCompactionOutputFile中被加入pending_outputs_的。12345678910 CompactionState* compact = new CompactionState(c); status = DoCompactionWork(compact); if (!status.ok()) &#123; RecordBackgroundError(status); &#125; CleanupCompaction(compact); c-&gt;ReleaseInputs(); RemoveObsoleteFiles();&#125;delete c; 收尾如果是Manual的，需要清空Manual状态。12345678910111213141516171819202122 if (status.ok()) &#123; // Done &#125; else if (shutting_down_.load(std::memory_order_acquire)) &#123; // Ignore compaction errors found during shutting down &#125; else &#123; Log(options_.info_log, "Compaction error: %s", status.ToString().c_str()); &#125; if (is_manual) &#123; ManualCompaction* m = manual_compaction_; if (!status.ok()) &#123; m-&gt;done = true; &#125; if (!m-&gt;done) &#123; // We only compacted part of the requested range. Update *m // to the range that is left to be compacted. m-&gt;tmp_storage = manual_end; m-&gt;begin = &amp;m-&gt;tmp_storage; &#125; manual_compaction_ = nullptr; &#125;&#125; Version::PickCompactionsize compaction的优先级是高于seek compaction的。遍历current_-&gt;compaction_level_这一层的所有文件，找到第一个largest大于compact_pointer_[level]的文件，放到Compaction* c的inputs_[0]中。如果一轮循环下来没找到，说明所有的文件的largest都小于compact_pointer_[level]，也就是这一层所有的key都小于compact_pointer_[level]，那就把第一个文件放进去。123456789101112131415161718192021222324252627Compaction* VersionSet::PickCompaction() &#123; Compaction* c; int level; // We prefer compactions triggered by too much data in a level over // the compactions triggered by seeks. const bool size_compaction = (current_-&gt;compaction_score_ &gt;= 1); const bool seek_compaction = (current_-&gt;file_to_compact_ != nullptr); if (size_compaction) &#123; level = current_-&gt;compaction_level_; assert(level &gt;= 0); assert(level + 1 &lt; config::kNumLevels); c = new Compaction(options_, level); // Pick the first file that comes after compact_pointer_[level] for (size_t i = 0; i &lt; current_-&gt;files_[level].size(); i++) &#123; FileMetaData* f = current_-&gt;files_[level][i]; if (compact_pointer_[level].empty() || icmp_.Compare(f-&gt;largest.Encode(), compact_pointer_[level]) &gt; 0) &#123; c-&gt;inputs_[0].push_back(f); break; &#125; &#125; if (c-&gt;inputs_[0].empty()) &#123; // Wrap-around to the beginning of the key space c-&gt;inputs_[0].push_back(current_-&gt;files_[level][0]); &#125; 对于seek compaction，把要Compact的那个文件加到c-&gt;inputs_[0]就行，逻辑很简单。1234567&#125; else if (seek_compaction) &#123; level = current_-&gt;file_to_compact_level_; c = new Compaction(options_, level); c-&gt;inputs_[0].push_back(current_-&gt;file_to_compact_);&#125; else &#123; return nullptr;&#125; 对于Level0，有个特别的处理，这个参考GetOverlappingInputs函数的说明。12345678910111213c-&gt;input_version_ = current_;c-&gt;input_version_-&gt;Ref();// Files in level 0 may overlap each other, so pick up all overlapping onesif (level == 0) &#123; InternalKey smallest, largest; GetRange(c-&gt;inputs_[0], &amp;smallest, &amp;largest); // Note that the next call will discard the file we placed in // c-&gt;inputs_[0] earlier and replace it with an overlapping set // which will include the picked file. current_-&gt;GetOverlappingInputs(0, &amp;smallest, &amp;largest, &amp;c-&gt;inputs_[0]); assert(!c-&gt;inputs_[0].empty());&#125; 现在，我们已经得到了c-&gt;inputs_[0]。除了c-&gt;inputs_[0]的情况，否则c-&gt;inputs_[0]里面都只有一个文件。通过SetupOtherInputs可以计算c-&gt;inputs_[1]，也就是level+1层涉及哪些文件。1234 SetupOtherInputs(c); return c;&#125; Version::SetupOtherInputsSetupOtherInputs计算在Compaction时，level+1层涉及哪些文件。在这个函数之后，我们就得到了正确的c-&gt;inputs_数组、c-&gt;grandparents_字段，以及compact_pointer_字段。在这个函数之后，PickCompaction就结束了，BackgroundCompaction会执行后面的流程，也就是DoCompactionWork。基本的思想是：所有和level层有重叠的level+1层文件都要参与Compact。得到这些文件后，反过来看下，利用这些level+1层的文件，能不能Compact更多level层的文件？这个函数被CompactRange和PickCompaction调用，也就是所有的Major Compaction逻辑都会走到这里。 GetRange和GetRange2GetRange计算inputs_[0]/inputs_[1]的区间。GetRange2计算inputs_[0]和inputs_[1]的区间。GetRange很简单，遍历每一个文件，然后更新smallest和largest，这里注意都需要icmp_.Compare。1234567891011121314151617181920void VersionSet::GetRange(const std::vector&lt;FileMetaData*&gt;&amp; inputs, InternalKey* smallest, InternalKey* largest) &#123; assert(!inputs.empty()); smallest-&gt;Clear(); largest-&gt;Clear(); for (size_t i = 0; i &lt; inputs.size(); i++) &#123; FileMetaData* f = inputs[i]; if (i == 0) &#123; *smallest = f-&gt;smallest; *largest = f-&gt;largest; &#125; else &#123; if (icmp_.Compare(f-&gt;smallest, *smallest) &lt; 0) &#123; *smallest = f-&gt;smallest; &#125; if (icmp_.Compare(f-&gt;largest, *largest) &gt; 0) &#123; *largest = f-&gt;largest; &#125; &#125; &#125;&#125; GetRange2很简单，就直接合并inputs_[0]和inputs_[1]的内容到一个vector里面，然后调用GetRange。1234567void VersionSet::GetRange2(const std::vector&lt;FileMetaData*&gt;&amp; inputs1, const std::vector&lt;FileMetaData*&gt;&amp; inputs2, InternalKey* smallest, InternalKey* largest) &#123; std::vector&lt;FileMetaData*&gt; all = inputs1; all.insert(all.end(), inputs2.begin(), inputs2.end()); GetRange(all, smallest, largest);&#125; AddBoundaryInputsAddBoundaryInputs是一个很重要的函数，但只有很少的Blog能讲明白这个函数的来龙去脉。 翻译一下AddBoundaryInputs这个函数的注释。他提取出compaction_files里面最大的文件b1，在这里是c-&gt;inputs_[0]里面最大的文件。然后在level_files里面找到一个b2，满足b1和b2的user key是相等的，这样的b2称为boundary file。我们需要将这个b2加入到compaction_files里面，并且继续找上界。如果有两个块（应该就是SSTable）b1和b2，他们的范围分别是(l1, u1)和(l2, u2)，如果我们只Compact b1，不Compact b2，那么在读取的时候就会出错。因为它只会返回b2的结果，而永远不会返回b1的结果，因为b1在b2上层了。与此同时，我们需要注意到b2的结果可能还是一个较旧的数据，因为根据Memtable里面的介绍，Sequence Number是从新到旧来排序的。 123void AddBoundaryInputs(const InternalKeyComparator&amp; icmp, const std::vector&lt;FileMetaData*&gt;&amp; level_files, std::vector&lt;FileMetaData*&gt;* compaction_files) 【Q】看起来，这个函数做的是和GetOverlappingInputs一样的事情，他们的区别是什么呢？首先，GetOverlappingInputs的初心不是扩展边界而是计算某一层和某个range重合的文件，只是对Level0要特殊处理一下。其次，这篇文章中进行了解释。 如下图所示，两个sstable中，出现了user key相同（都为key2）但是Sequence Number不同的两个Internal Key。 所以可以看到GetOverlappingInputs的特殊处理关注的是Level0上某一个要Compact的文件中的所有key是否还会出现在其他的SSTable文件中。而AddBoundaryInputs关注的是某个Key的其他版本是否还会出现在其他的SSTable中。 【Q】这里引发了第二个疑问，为什么同一层中会出现两个相同user key的Key呢？我觉得这个可能是因为这个Key出现在两个SSTable的边界上，所以这个函数叫AddBoundaryInputs吧。 仔细回顾一下DoCompactionWork的实现，似乎是可能没处理完一个Key，就ShouldStopBefore了的，但即使这样，后面的文件里面也不会再写有关这个user key的内容了。那么究竟在什么情况下会发生这种情况呢？根据这篇文章中指出Snapshot机制会导致“同一层中会出现两个相同user key的Key”这个问题。 【Q】这里引发了第三个疑问，出现了两个user key，会不会影响读取呢？实际上只要位于同一层就不影响，因为根据Memtable里面的介绍，Sequence Number是从新到旧来排序的。我们的查找方式允许我们每一次都找到b1里面的值。 特别值得注意的是，这个问题关系到Issue 320和PR 339。AddBoundaryInputs函数也是在那个时候引进的。不过值得注意的是，这个patch在2016年就提了，但是2019年才被合进去。 SetupOtherInputs主体首先AddBoundaryInputs扩充一下c-&gt;inputs_[0]。然后获得Level N的range。然后计算Level N+1和Level N重叠的SSTable文件，并放入c-&gt;inputs_[1]。最后，计算Level N和Level N+1合并起来的range。12345678910111213void VersionSet::SetupOtherInputs(Compaction* c) &#123; const int level = c-&gt;level(); InternalKey smallest, largest; AddBoundaryInputs(icmp_, current_-&gt;files_[level], &amp;c-&gt;inputs_[0]); GetRange(c-&gt;inputs_[0], &amp;smallest, &amp;largest); current_-&gt;GetOverlappingInputs(level + 1, &amp;smallest, &amp;largest, &amp;c-&gt;inputs_[1]); // Get entire range covered by compaction InternalKey all_start, all_limit; GetRange2(c-&gt;inputs_[0], c-&gt;inputs_[1], &amp;all_start, &amp;all_limit); 下面的的代码，就是之前说的优化。如果c-&gt;inputs_[1]不为空，也就是Level N+1层有需要进行Merge的文件。我们将level中和所有和[all_start,all_limit]重叠的文件加到expoand0里面，并调用AddBoundaryInputs处理边界。12345678910111213141516171819202122232425262728293031// See if we can grow the number of inputs in "level" without// changing the number of "level+1" files we pick up.if (!c-&gt;inputs_[1].empty()) &#123; std::vector&lt;FileMetaData*&gt; expanded0; current_-&gt;GetOverlappingInputs(level, &amp;all_start, &amp;all_limit, &amp;expanded0); AddBoundaryInputs(icmp_, current_-&gt;files_[level], &amp;expanded0); const int64_t inputs0_size = TotalFileSize(c-&gt;inputs_[0]); const int64_t inputs1_size = TotalFileSize(c-&gt;inputs_[1]); const int64_t expanded0_size = TotalFileSize(expanded0); if (expanded0.size() &gt; c-&gt;inputs_[0].size() &amp;&amp; inputs1_size + expanded0_size &lt; ExpandedCompactionByteSizeLimit(options_)) &#123; InternalKey new_start, new_limit; GetRange(expanded0, &amp;new_start, &amp;new_limit); std::vector&lt;FileMetaData*&gt; expanded1; current_-&gt;GetOverlappingInputs(level + 1, &amp;new_start, &amp;new_limit, &amp;expanded1); if (expanded1.size() == c-&gt;inputs_[1].size()) &#123; Log(options_-&gt;info_log, "Expanding@%d %d+%d (%ld+%ld bytes) to %d+%d (%ld+%ld bytes)\n", level, int(c-&gt;inputs_[0].size()), int(c-&gt;inputs_[1].size()), long(inputs0_size), long(inputs1_size), int(expanded0.size()), int(expanded1.size()), long(expanded0_size), long(inputs1_size)); smallest = new_start; largest = new_limit; c-&gt;inputs_[0] = expanded0; c-&gt;inputs_[1] = expanded1; GetRange2(c-&gt;inputs_[0], c-&gt;inputs_[1], &amp;all_start, &amp;all_limit); &#125; &#125;&#125; 下面，设置一下c-&gt;grandparents_这个字段。123456// Compute the set of grandparent files that overlap this compaction// (parent == level+1; grandparent == level+2)if (level + 2 &lt; config::kNumLevels) &#123; current_-&gt;GetOverlappingInputs(level + 2, &amp;all_start, &amp;all_limit, &amp;c-&gt;grandparents_);&#125; 记录下一轮的压缩起始文件，也就是设置compact_pointer_。我们在这里立即更新，而不是等到VersionEdit被Apply的时候更新，这样当Compaction失败后，我们能下次能尝试一个不同的key range。 【Q】什么是压缩起始文件？ 查看PickCompaction函数，它会找到largest大于compact_pointer_[level]后的第一个文件。 可以发现，其实每一次要Compaction的文件就是通过compact_pointer_指定的。 【Q】在这之后，Compaction会因为什么失败？ 1234 // Update the place where we will do the next compaction for this level. compact_pointer_[level] = largest.Encode().ToString(); c-&gt;edit_.SetCompactPointer(level, largest);&#125; DBImpl::CompactionState SequenceNumber smallest_snapshot; 小于smallest_snapshot的Sequence Number是不重要的，因为我们不会为提供smallest_snapshot的snapshot。 所以，如果我们看到Sequence Number小于等于smallest_snapshot的某个S，就可以丢弃小于S的这个key的其他版本。 【Q】这里是不是在说，如果只有S这个独苗，那还是要写进去的？ std::vector&lt;Output&gt; outputs; Output* current_output() { return &amp;outputs[outputs.size() - 1]; } 保存每个输出文件的元信息。例如smallest和largest。 WritableFile* outfile; Major Compaction过程中，需要输出到level+1层的文件。注意，可能有多个这样的文件，参考ShouldStopBefore。 TableBuilder* builder; uint64_t total_bytes; DBImpl::DoCompactionWork这个对应了一般情况下的Compact过程，来自BackgroundCompaction的调用。那么这个函数做啥呢，不就是个归并排序么？且慢，我们如何处理同一个user key有不同Sequence Number呢？我们的目标肯定是只保留最新的。其中CompactionState封装了Compaction。12345678Status DBImpl::DoCompactionWork(CompactionState* compact) &#123; const uint64_t start_micros = env_-&gt;NowMicros(); int64_t imm_micros = 0; // Micros spent doing imm_ compactions Log(options_.info_log, "Compacting %d@%d + %d@%d files", compact-&gt;compaction-&gt;num_input_files(0), compact-&gt;compaction-&gt;level(), compact-&gt;compaction-&gt;num_input_files(1), compact-&gt;compaction-&gt;level() + 1); 这里要assert一下，即要压缩的Level N层是要有文件的。【Q】这个Snapshot啥回事？根据文章，如果有Snapshot，则保留大于Snapshot SN的所有Record，以及一个小于Snapshot SN的Record中，SN最大的Record。12345678assert(versions_-&gt;NumLevelFiles(compact-&gt;compaction-&gt;level()) &gt; 0);assert(compact-&gt;builder == nullptr);assert(compact-&gt;outfile == nullptr);if (snapshots_.empty()) &#123; compact-&gt;smallest_snapshot = versions_-&gt;LastSequence();&#125; else &#123; compact-&gt;smallest_snapshot = snapshots_.oldest()-&gt;sequence_number();&#125; 我们执行MakeInputIterator，得到的迭代器可以按照key大小遍历所有冲突文件中的每个KV对。1234567891011Iterator* input = versions_-&gt;MakeInputIterator(compact-&gt;compaction);// Release mutex while we're actually doing the compaction workmutex_.Unlock();input-&gt;SeekToFirst();Status status;ParsedInternalKey ikey;std::string current_user_key;bool has_current_user_key = false;SequenceNumber last_sequence_for_key = kMaxSequenceNumber; 下面这个while循环遍历刚才得到的迭代器input，进行Major Compaction。但是，且慢，每一次我们都需要先检查有没有Immatable Memtable，如果有的话，就需要先执行Minor Compaction。这也说明了Minor Compaction的优先级更高。【Q】我们看到了两个原子量的获取： shutting_down_，采用了Release-Acquire内存模型，保证了一定的并行顺序。 如果线程A Release Store，线程B Acquire Load，那么线程A中所有在Release前的(atomic或者非atomic)写，对线程B都可见。 memory_order_relaxed，采用了Relaxed内存模型。 只保证读写的原子性，不保证并发时和其他变量的顺序。 12345678910111213while (input-&gt;Valid() &amp;&amp; !shutting_down_.load(std::memory_order_acquire)) &#123; // Prioritize immutable compaction work if (has_imm_.load(std::memory_order_relaxed)) &#123; const uint64_t imm_start = env_-&gt;NowMicros(); mutex_.Lock(); if (imm_ != nullptr) &#123; CompactMemTable(); // Wake up MakeRoomForWrite() if necessary. background_work_finished_signal_.SignalAll(); &#125; mutex_.Unlock(); imm_micros += (env_-&gt;NowMicros() - imm_start); &#125; 检查当前输出文件(应当位于level+1层)是否与level+2层文件有过多冲突，如果是就要完成当前输出文件，并产生新的输出文件。12345678Slice key = input-&gt;key();if (compact-&gt;compaction-&gt;ShouldStopBefore(key) &amp;&amp; compact-&gt;builder != nullptr) &#123; status = FinishCompactionOutputFile(compact, input); if (!status.ok()) &#123; break; &#125;&#125; 下面就是判断是不是能drop，也就是和前面计算的compact-&gt;smallest_snapshot比较。正常情况下ParseInternalKey不会失败，我们跳过这个分支12345678// Handle key/value, add to state, etc.bool drop = false;if (!ParseInternalKey(key, &amp;ikey)) &#123; // Do not hide error keys current_user_key.clear(); has_current_user_key = false; last_sequence_for_key = kMaxSequenceNumber;&#125; else &#123; 下面这个if，判断的是current_user_key第一次出现的情况，包括处理完上一个user key，到达下一个user key，或者刚开始处理第一个user key的情况。我们设置last_sequence_for_key为最大，那么就永远不会触发drop。12345678if (!has_current_user_key || user_comparator()-&gt;Compare(ikey.user_key, Slice(current_user_key)) != 0) &#123; // First occurrence of this user key current_user_key.assign(ikey.user_key.data(), ikey.user_key.size()); has_current_user_key = true; last_sequence_for_key = kMaxSequenceNumber;&#125; 下面我们比较Sequence Number，如果last_sequence_for_key都小于compact-&gt;smallest_snapshot了，那么我这个key肯定更小，这是因为Sequence Number是按照降序排列的。对于这种情况，我们省点事，直接不要了。123if (last_sequence_for_key &lt;= compact-&gt;smallest_snapshot) &#123; // Hidden by an newer entry for same user key drop = true; // (A) 下一个判断复杂点，表示对于特定情况下，一个删除操作也是可以丢掉的。如果某个删除操作的版本小于快照版本，并且在更高层没有相同的user key，那么这个删除操作及其之前更早的插入操作可以同时丢弃了。123456789101112131415 &#125; else if (ikey.type == kTypeDeletion &amp;&amp; ikey.sequence &lt;= compact-&gt;smallest_snapshot &amp;&amp; compact-&gt;compaction-&gt;IsBaseLevelForKey(ikey.user_key)) &#123; // For this user key: // (1) there is no data in higher levels // (2) data in lower levels will have larger sequence numbers // (3) data in layers that are being compacted here and have // smaller sequence numbers will be dropped in the next // few iterations of this loop (by rule (A) above). // Therefore this deletion marker is obsolete and can be dropped. drop = true; &#125; last_sequence_for_key = ikey.sequence;&#125; 如果drop条件不符合，那么就写入到compact-&gt;current_output()里面，同时更新largest。同时我们关注文件大小，如果超限了，就FinishCompactionOutputFile。1234567891011121314151617181920212223242526 if (!drop) &#123; // Open output file if necessary if (compact-&gt;builder == nullptr) &#123; status = OpenCompactionOutputFile(compact); if (!status.ok()) &#123; break; &#125; &#125; if (compact-&gt;builder-&gt;NumEntries() == 0) &#123; compact-&gt;current_output()-&gt;smallest.DecodeFrom(key); &#125; compact-&gt;current_output()-&gt;largest.DecodeFrom(key); compact-&gt;builder-&gt;Add(key, input-&gt;value()); // Close output file if it is big enough if (compact-&gt;builder-&gt;FileSize() &gt;= compact-&gt;compaction-&gt;MaxOutputFileSize()) &#123; status = FinishCompactionOutputFile(compact, input); if (!status.ok()) &#123; break; &#125; &#125; &#125; input-&gt;Next();&#125; 截至现在，我们已经遍历完迭代器了。1234567891011if (status.ok() &amp;&amp; shutting_down_.load(std::memory_order_acquire)) &#123; status = Status::IOError("Deleting DB during compaction");&#125;if (status.ok() &amp;&amp; compact-&gt;builder != nullptr) &#123; status = FinishCompactionOutputFile(compact, input);&#125;if (status.ok()) &#123; status = input-&gt;status();&#125;delete input;input = nullptr; 更新状态12345678910CompactionStats stats;stats.micros = env_-&gt;NowMicros() - start_micros - imm_micros;for (int which = 0; which &lt; 2; which++) &#123; for (int i = 0; i &lt; compact-&gt;compaction-&gt;num_input_files(which); i++) &#123; stats.bytes_read += compact-&gt;compaction-&gt;input(which, i)-&gt;file_size; &#125;&#125;for (size_t i = 0; i &lt; compact-&gt;outputs.size(); i++) &#123; stats.bytes_written += compact-&gt;outputs[i].file_size;&#125; 下面，我们加锁。所以其实在遍历input这个迭代器的时候，是没有在加锁的。InstallCompactionResults是一个关键过程，它将这次Compaction的内容加入到VersionEdit里面，并且最终调用LogAndApply。内容包括什么呢？增加和删除的文件： InstallCompactionResults会调用Compaction::AddInputDeletions，需要删除的文件，包括input_[0]和input_[1] 向compact-&gt;compaction-&gt;edit()中添加compact-&gt;outputs中的所有文件 12345678910111213 mutex_.Lock(); stats_[compact-&gt;compaction-&gt;level() + 1].Add(stats); if (status.ok()) &#123; status = InstallCompactionResults(compact); &#125; if (!status.ok()) &#123; RecordBackgroundError(status); &#125; VersionSet::LevelSummaryStorage tmp; Log(options_.info_log, "compacted to: %s", versions_-&gt;LevelSummary(&amp;tmp)); return status;&#125; Reference https://bean-li.github.io/leveldb-version/ https://zhuanlan.zhihu.com/p/34674504 https://blog.csdn.net/tmshasha/article/details/47703245 https://zhuanlan.zhihu.com/p/51573929 https://leveldb-handbook.readthedocs.io/zh/latest/basic.html https://blog.lovezhy.cc/2020/08/17/LevelDB%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%EF%BC%88%E4%BA%94%EF%BC%89-%20CURRENT%E5%92%8CManifest/ https://sf-zhou.github.io/leveldb/leveldb_08_complete_process.html http://blog.jcix.top/2018-05-11/leveldb_paths/ http://bean-li.github.io/leveldb-version/ https://zhuanlan.zhihu.com/p/46718964 http://www.hootina.org/blog/articles/leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9019.html https://sf-zhou.github.io/leveldb/leveldb_08_complete_process.html 这是一个DB完整执行过程的表述。 https://www.ravenxrz.ink/archives/1ba074b9.html 介绍了Snapshot https://izualzhy.cn/leveldb-PickCompaction 解释了GetOverlappingInputs的原理 https://izualzhy.cn/leveldb-version 解释了Version的实现 http://lerencao.github.io/posts/lsm-tree-compaction-strategy/ http://www.scylladb.com/2018/01/17/compaction-series-space-amplification/ 上面两篇文章介绍STCS和LCS https://zhuanlan.zhihu.com/p/181498475 图解Compact过程 https://github.com/facebook/rocksdb/wiki/Compaction RocksDB对Compaction的讲解 https://blog.csdn.net/weixin_36145588/article/details/78064777 https://sf-zhou.github.io/leveldb/leveldb_09_compaction.html 这位同学解释了AddBoundaryInputs的来源 http://www.petermao.com/leveldb/leveldb-8-snapshot.html 介绍了snapshot机制 https://zhuanlan.zhihu.com/p/60188395 带Snapshot的Compaction，以及为什么会导致Issue 320的问题 https://zhuanlan.zhihu.com/p/360345923 也讲解了AddBoundaryInputs的来源，并且指出了快照会导致Issue 320的问题。 https://zhuanlan.zhihu.com/p/35343043 讲解VersionSet/VersionEdit里面出现的各种文件编号 https://leveldb-handbook.readthedocs.io/zh/latest/version.html 版本控制相关 https://bean-li.github.io/leveldb-manifest/ 有关Manifest文件的深入讨论 http://1feng.github.io/2016/08/24/mvcc-and-manifest/ 介绍MVCC机制，很好 https://draveness.me/database-concurrency-control/ 同样介绍了MVCC，包括乐观锁和悲观锁机制]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LevelDB之SSTable实现]]></title>
    <url>%2F2021%2F04%2F12%2Fleveldb-sstable%2F</url>
    <content type="text"><![CDATA[本文介绍LevelDB的SSTable相关功能。SSTable是LevelDB的内存数据结构。当一个Memtable满之后，会被变成Immutable Memtable，并写入SSTable Level0。Level0的SSTable是没有经过归并的，各个Key可能互相重叠。经过Compaction达到Level1之后，就是有序的了。 SSTable格式SSTable体现在后缀为.sst或者.ldb的文件。其实在官方文档中，对SSTable的格式已经有了介绍。123456789101112&lt;beginning_of_file&gt;[data block 1][data block 2]...[data block N][meta block 1]...[meta block K][metaindex block][index block][Footer] (fixed size; starts at file_size - sizeof(Footer))&lt;end_of_file&gt; data block 放KV对，是有序的（doc里面说的）。因此在查询SSTable文件的时候，也可以二分。【待确认】 关于Block的组织，我们将专门讨论。 meta block 用来快速定位key是否在data block中 metaindex block 每个metaindex block一条记录。其中K是meta block的名字，V是指向这个meta block的BlockHandle。 BlockHandle类似于指针，具有下面的结构。容易看到，这里面也用了VarInt结构。 12offset: varint64size: varint64 有两种meta block类型，filter和stats: 如果在数据库启动时指定了某个FilterPolicy，就会创建一个filter block。 统计信息 index block 每个data block一条entry。这个index block entry的.key()大于等于指向的data block最后一个K【性质1】，但是严格小于下一个data block的第一个K【性质2】。 因此，我们可以通过和index block比较来快速定位data block。 footer 包含： metaindex handle index handle padding magic number Block实现SST的构建主要集中在table_builder.h/cc和block_builder.h/cc中。SST的读取主要集中在table.h/cc和block.h/cc中。从前面可以看到，SSTable主要有两层结构，Table(SSTable)和Block(data/index等)。Table由多个Block构成，所以从Block开始分析。 BlockBuilder/Block原理BlockBuilder负责生成诸如data block、index block等所有block。Block对象负责读取这些block。 共享前缀因为BlockBuilder是有序的，所以可以使用共享前缀来节约空间，我们比较下面两种方式： 普通 12Hello WorldHello William 共享 12Hello World illiam Block的构造如下图所示 其中： shared_bytes Key的共享前缀的长度，这里的共享指的是上一个entry key_delta/unshared_bytes Key共享前缀后的剩余串和其长度 value/value_length 值的串和其长度 那么如何读呢？ 最坏状况，我们需要读到第一个Entry，考虑下面的Key 123aababc 最好状况，我们读当前的就行 12ab restart可见共享前缀会给读带来困难，因此又引入restart机制，即每隔block_restart_interval之后会去存储一次完整的key，对应的entry的位置称为restart point。在block中，会存储下所有的restart point。因为数字存储是有序的，所以我们能通过二分restart point来加速读取，具体代码在Block::Iter中。读取需求一般是给定target，要求找到第一个K大于等于target的entry。因此我们可以得到如下二分 mid &lt; target 则搜索[mid, right] mid &gt;= target 搜索[left, mid-1]因为这是一个TTT…F/T的二分，所以我们要令mid = (left + right + 1)/2 filter block在每个data block内部，借助于二分restart可以实现$log(n)$复杂度的查询，那么能在data block之间二分么？ 可以通过filter block来判断某个key是否属于该data block，实现是bloom filter。 BlockBuilder实现方法 void Add(const Slice&amp; key, const Slice&amp; value); 每一次Add的Key，必须是有序的，从小到大的。 Slice Finish(); void Reset(); BlockBuilder::Add首先是三个assert： 第一个很好理解，如果finished_，相当于已经调用了Finish或者Abandon等方法。 block_restart_interval表示每过多少个key就要设置一个restarts。设置完之后，counter_会被重置为0，所以这个不等式是成立的。 最后一个是有序性检验，要不是空的，要不新来的key要大于老的last_key_piece。123456void BlockBuilder::Add(const Slice&amp; key, const Slice&amp; value) &#123; Slice last_key_piece(last_key_); assert(!finished_); assert(counter_ &lt;= options_-&gt;block_restart_interval); assert(buffer_.empty() // No values yet? || options_-&gt;comparator-&gt;Compare(key, last_key_piece) &gt; 0); 下面判断要不要restart： 如果不要，和前一个key即last_key_比较，算出来能share多少长度。 如果要，就restart。12345678910111213size_t shared = 0;if (counter_ &lt; options_-&gt;block_restart_interval) &#123; // See how much sharing to do with previous string const size_t min_length = std::min(last_key_piece.size(), key.size()); while ((shared &lt; min_length) &amp;&amp; (last_key_piece[shared] == key[shared])) &#123; shared++; &#125;&#125; else &#123; // Restart compression restarts_.push_back(buffer_.size()); counter_ = 0;&#125;const size_t non_shared = key.size() - shared; 下面就是往buffer_里面写数据了。12345678// Add "&lt;shared&gt;&lt;non_shared&gt;&lt;value_size&gt;" to buffer_PutVarint32(&amp;buffer_, shared);PutVarint32(&amp;buffer_, non_shared);PutVarint32(&amp;buffer_, value.size());// Add string delta to buffer_ followed by valuebuffer_.append(key.data() + shared, non_shared);buffer_.append(value.data(), value.size()); 下面这个优化点也很有趣，首先last_key_保存的是一个完整的key。但是我们可以复用之前一个key的shared部分，这个是安全的。接着我们把non shared部分append上去。123456 // Update state last_key_.resize(shared); last_key_.append(key.data() + shared, non_shared); assert(Slice(last_key_) == key); counter_++;&#125; BlockBuilder::Finish为啥restarts_不用VarInt存呢？123456789Slice BlockBuilder::Finish() &#123; // Append restart array for (size_t i = 0; i &lt; restarts_.size(); i++) &#123; PutFixed32(&amp;buffer_, restarts_[i]); &#125; PutFixed32(&amp;buffer_, restarts_.size()); finished_ = true; return Slice(buffer_);&#125; Block实现 uint32_t NumRestarts() const; 之前了解过block的结构，在Block的最后，是restart点的个数。 1234inline uint32_t Block::NumRestarts() const &#123; assert(size_ &gt;= sizeof(uint32_t)); return DecodeFixed32(data_ + size_ - sizeof(uint32_t));&#125; const char* data_;/size_t size_; 也就是这个Block的指针和长度。 uint32_t restart_offset_; 表示restart的开始位置 1size_ - (1 + NumRestarts()) * sizeof(uint32_t) bool owned_; 取决于构造函数传入的BlockContents的owned_字段。 Block::IterSeek这个函数是一个二分的实现。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364void Seek(const Slice&amp; target) override &#123; // Binary search in restart array to find the last restart point // with a key &lt; target uint32_t left = 0; uint32_t right = num_restarts_ - 1; int current_key_compare = 0; if (Valid()) &#123; // If we're already scanning, use the current position as a starting // point. This is beneficial if the key we're seeking to is ahead of the // current position. current_key_compare = Compare(key_, target); if (current_key_compare &lt; 0) &#123; // key_ is smaller than target left = restart_index_; &#125; else if (current_key_compare &gt; 0) &#123; right = restart_index_; &#125; else &#123; // We're seeking to the key we're already at. return; &#125; &#125; while (left &lt; right) &#123; uint32_t mid = (left + right + 1) / 2; uint32_t region_offset = GetRestartPoint(mid); uint32_t shared, non_shared, value_length; const char* key_ptr = DecodeEntry(data_ + region_offset, data_ + restarts_, &amp;shared, &amp;non_shared, &amp;value_length); if (key_ptr == nullptr || (shared != 0)) &#123; CorruptionError(); return; &#125; Slice mid_key(key_ptr, non_shared); if (Compare(mid_key, target) &lt; 0) &#123; // Key at "mid" is smaller than "target". Therefore all // blocks before "mid" are uninteresting. left = mid; &#125; else &#123; // Key at "mid" is &gt;= "target". Therefore all blocks at or // after "mid" are uninteresting. right = mid - 1; &#125; &#125; // We might be able to use our current position within the restart block. // This is true if we determined the key we desire is in the current block // and is after than the current key. assert(current_key_compare == 0 || Valid()); bool skip_seek = left == restart_index_ &amp;&amp; current_key_compare &lt; 0; if (!skip_seek) &#123; SeekToRestartPoint(left); &#125; // Linear search (within restart block) for first key &gt;= target while (true) &#123; if (!ParseNextKey()) &#123; return; &#125; if (Compare(key_, target) &gt;= 0) &#123; return; &#125; &#125;&#125; Table实现TableBuilder对于Add/Flush/Finish/Abandon，此时Adandon和Finish不能已经被调用。 Status ChangeOptions(const Options&amp; options); 修改option，但是只有某些可以在构建之后被修改。对于那些不能修改的，会报错。 void Add(const Slice&amp; key, const Slice&amp; value); 增加一个KV对。 key is after any previously added key according to comparator，往TableBuilder里面加KV，必须是有序的？ void Flush(); 刷盘，一般不直接用。主要被用来保证两个相邻的Entry不会在同一个data block中。 Status status() const; Status Finish(); 结束当前表的构建。 void Abandon(); 表示需要丢弃当前缓存内容，并且结束表的构建。 uint64_t NumEntries() const; Add了多少次，实际上返回的是TableBuilder::Rep里面的num_entries uint64_t FileSize() const; void WriteBlock(BlockBuilder* block, BlockHandle* handle); void WriteRawBlock(const Slice&amp; data, CompressionType, BlockHandle* handle); 此外，TableBuilder持有一个Req类型的对象指针，用来隐藏相关实现。 TableBuilder::Rep具有下面的： Options options; Options index_block_options; WritableFile* file; WritableFile是一个接口，具体实现可以分为随机读写文件，顺序读写文件等。 uint64_t offset; Status status; 是ok()的返回值，表示是否发生了错误。一般，错误会在file里面的Append和Flush方法中出现。 BlockBuilder data_block; BlockBuilder index_block; std::string last_key; 每一次Add会更新这个字段。因为Add是有序的，所以实际上就表示了当前最大的key。 int64_t num_entries; 见NumEntries。 bool closed; Finish和Abandon会设置为true。 FilterBlockBuilder* filter_block; bool pending_index_entry; 当写完一个data block之后，设置pending_index_entry，表示需要更新index block。 因此这里有个不变量，当且仅当data_block为空的时候pending_index_entry才是true。也就是说当写入一个data block后（注意一个table中有多个data block），设置pending_index_entry为true，之后更新index block。 原因是直到我们见到下一个data block的第一个key的时候才能写index。这样我们可以在写index的时候用尽可能短的key。例如我们已经知道第一个data block中最大的是”the quick brown fox”，而第二个data block中最小的是”the who”。这样通过之前提到的FindShortestSeparator，我们就可以用”the r”作为index block中的entry。这个entry满足条件，即大于等于第一个block中的所有key，并且小于第二个block中的所有key。 因此，顺序是： 写一个data block 接到下一个Add请求 根据last_key和当前传入的Key，写index 正常处理该Add请求 BlockHandle pending_handle; Handle to add to index block。不是说用这个handle来写index block，而是会把这个handle里面的值写到index block里面作为index。 std::string compressed_output; TableBuilder::Add1234567void TableBuilder::Add(const Slice&amp; key, const Slice&amp; value) &#123; Rep* r = rep_; assert(!r-&gt;closed); if (!ok()) return; if (r-&gt;num_entries &gt; 0) &#123; assert(r-&gt;options.comparator-&gt;Compare(key, Slice(r-&gt;last_key)) &gt; 0); &#125; 如果pending_index_entry是true，说明之前已经写入了一个data block。于是我们就要插入index，并且清空pending_index_entry标志。这一部分原理在pending_index_entry讲解过了。12345678if (r-&gt;pending_index_entry) &#123; assert(r-&gt;data_block.empty()); r-&gt;options.comparator-&gt;FindShortestSeparator(&amp;r-&gt;last_key, key); std::string handle_encoding; r-&gt;pending_handle.EncodeTo(&amp;handle_encoding); r-&gt;index_block.Add(r-&gt;last_key, Slice(handle_encoding)); r-&gt;pending_index_entry = false;&#125; 下面是添加的逻辑，先处理filter block。123if (r-&gt;filter_block != nullptr) &#123; r-&gt;filter_block-&gt;AddKey(key);&#125; 然后设置last_key，并向当前的data block中添加KV。估算当前data block的大小，如果超过配置的阈值options.block_size就进行dump。这个估算实际上就是统计所有entry以及restart的总大小。相比Spark里面的大小估计，感觉LevelDB/Redis里面的大小估计要简单很多，感觉得益于C/C++能自己管理内存。123456789 r-&gt;last_key.assign(key.data(), key.size()); r-&gt;num_entries++; r-&gt;data_block.Add(key, value); const size_t estimated_block_size = r-&gt;data_block.CurrentSizeEstimate(); if (estimated_block_size &gt;= r-&gt;options.block_size) &#123; Flush(); &#125;&#125; TableBuilder::WriteBlockWriteBlockTable要写某个Block，首先Finish这个block，也就是说把所有restart都写到文件里面。1234void TableBuilder::WriteBlock(BlockBuilder* block, BlockHandle* handle) &#123; assert(ok()); Rep* r = rep_; Slice raw = block-&gt;Finish(); 接着，是写data block。实际写入的block_contents可能是被压缩了的，也可能是没有被压缩的。123456789101112131415161718192021222324Slice block_contents;CompressionType type = r-&gt;options.compression;// TODO(postrelease): Support more compression options: zlib?switch (type) &#123; case kNoCompression: block_contents = raw; break; case kSnappyCompression: &#123; std::string* compressed = &amp;r-&gt;compressed_output; if (port::Snappy_Compress(raw.data(), raw.size(), compressed) &amp;&amp; compressed-&gt;size() &lt; raw.size() - (raw.size() / 8u)) &#123; block_contents = *compressed; &#125; else &#123; // Snappy not supported, or compressed less than 12.5%, so just // store uncompressed form block_contents = raw; type = kNoCompression; &#125; break; &#125;&#125;WriteRawBlock(block_contents, type, handle);r-&gt;compressed_output.clear(); 清空这个block里面buffer_、restarts_等状态。12 block-&gt;Reset();&#125; TableBuilder::WriteRawBlock每一个block包含： data type 表示有没有压缩 crc32123456789101112131415161718void TableBuilder::WriteRawBlock(const Slice&amp; block_contents, CompressionType type, BlockHandle* handle) &#123; Rep* r = rep_; handle-&gt;set_offset(r-&gt;offset); handle-&gt;set_size(block_contents.size()); r-&gt;status = r-&gt;file-&gt;Append(block_contents); if (r-&gt;status.ok()) &#123; char trailer[kBlockTrailerSize]; trailer[0] = type; uint32_t crc = crc32c::Value(block_contents.data(), block_contents.size()); crc = crc32c::Extend(crc, trailer, 1); // Extend crc to cover block type EncodeFixed32(trailer + 1, crc32c::Mask(crc)); r-&gt;status = r-&gt;file-&gt;Append(Slice(trailer, kBlockTrailerSize)); if (r-&gt;status.ok()) &#123; r-&gt;offset += block_contents.size() + kBlockTrailerSize; &#125; &#125;&#125; TableBuilder::Flush前面是判断一些条件。如果说data block是空的，那么就直接返回。接着断言pending_index_entry这个是true，这个是之前提到的不变量。123456void TableBuilder::Flush() &#123; Rep* r = rep_; assert(!r-&gt;closed); if (!ok()) return; if (r-&gt;data_block.empty()) return; assert(!r-&gt;pending_index_entry); 根据pending_handle的说明，它的值会被写到index block里面。123456789 WriteBlock(&amp;r-&gt;data_block, &amp;r-&gt;pending_handle); if (ok()) &#123; r-&gt;pending_index_entry = true; r-&gt;status = r-&gt;file-&gt;Flush(); &#125; if (r-&gt;filter_block != nullptr) &#123; r-&gt;filter_block-&gt;StartBlock(r-&gt;offset); &#125;&#125; TableBuilder::FinishFinish操作用来生成一个SSTable。首先先Flush，也就是把data_block写盘。12345Status TableBuilder::Finish() &#123; Rep* r = rep_; Flush(); assert(!r-&gt;closed); r-&gt;closed = true; 什么时候不ok呢？也就是发生错误的情况。下面，写入filter block。123456BlockHandle filter_block_handle, metaindex_block_handle, index_block_handle;// Write filter blockif (ok() &amp;&amp; r-&gt;filter_block != nullptr) &#123; WriteRawBlock(r-&gt;filter_block-&gt;Finish(), kNoCompression, &amp;filter_block_handle);&#125; 如果上面的写入是成功的，接着写入meta index block。123456789101112131415// Write metaindex blockif (ok()) &#123; BlockBuilder meta_index_block(&amp;r-&gt;options); if (r-&gt;filter_block != nullptr) &#123; // Add mapping from "filter.Name" to location of filter data std::string key = "filter."; key.append(r-&gt;options.filter_policy-&gt;Name()); std::string handle_encoding; filter_block_handle.EncodeTo(&amp;handle_encoding); meta_index_block.Add(key, handle_encoding); &#125; // TODO(postrelease): Add stats and other meta blocks WriteBlock(&amp;meta_index_block, &amp;metaindex_block_handle);&#125; 如果上面的写入是成功的，接着写入index block。1234567891011// Write index blockif (ok()) &#123; if (r-&gt;pending_index_entry) &#123; r-&gt;options.comparator-&gt;FindShortSuccessor(&amp;r-&gt;last_key); std::string handle_encoding; r-&gt;pending_handle.EncodeTo(&amp;handle_encoding); r-&gt;index_block.Add(r-&gt;last_key, Slice(handle_encoding)); r-&gt;pending_index_entry = false; &#125; WriteBlock(&amp;r-&gt;index_block, &amp;index_block_handle);&#125; 如果上面的写入是成功的，接着写入footer。1234567891011121314 // Write footer if (ok()) &#123; Footer footer; footer.set_metaindex_handle(metaindex_block_handle); footer.set_index_handle(index_block_handle); std::string footer_encoding; footer.EncodeTo(&amp;footer_encoding); r-&gt;status = r-&gt;file-&gt;Append(footer_encoding); if (r-&gt;status.ok()) &#123; r-&gt;offset += footer_encoding.size(); &#125; &#125; return r-&gt;status;&#125; Table下面介绍Table类，它的作用是负责读取SSTable。 static Status Open(const Options&amp; options, RandomAccessFile* file, uint64_t file_size, Table** table); 解析传入的file。 如果成功，返回ok，并且设置*table，这是一个指针，由调用方释放。 如果失败，返回一个非ok，并且设置*table为nullptr。 Does not take ownership of “*source”, but the client must ensure that “source” remains live for the duration of the returned table’s lifetime. Iterator* NewIterator(const ReadOptions&amp;) const; uint64_t ApproximateOffsetOf(const Slice&amp; key) const; 传入一个key，返回它在文件中的大概位置。对不存在的key，返回如果存在，那么大概在的位置。 static Iterator* BlockReader(void*, const ReadOptions&amp;, const Slice&amp;); TwoLevelIterator需要这个函数，通过它来构建一个data_iter_ Status InternalGet(const ReadOptions&amp;, const Slice&amp; key, void* arg, void (*handle_result)(void* arg, const Slice&amp; k, const Slice&amp; v)); void ReadMeta(const Footer&amp; footer); void ReadFilter(const Slice&amp; filter_handle_value); Table::Rep Options options; Status status; RandomAccessFile* file; uint64_t cache_id; FilterBlockReader* filter; const char* filter_data; BlockHandle metaindex_handle; Block* index_block; Table::Open首先解析出footer。12345678910111213141516Status Table::Open(const Options&amp; options, RandomAccessFile* file, uint64_t size, Table** table) &#123; *table = nullptr; if (size &lt; Footer::kEncodedLength) &#123; return Status::Corruption("file is too short to be an sstable"); &#125; char footer_space[Footer::kEncodedLength]; Slice footer_input; Status s = file-&gt;Read(size - Footer::kEncodedLength, Footer::kEncodedLength, &amp;footer_input, footer_space); if (!s.ok()) return s; Footer footer; s = footer.DecodeFrom(&amp;footer_input); if (!s.ok()) return s; 接下来，解析index block。1234567// Read the index blockBlockContents index_block_contents;ReadOptions opt;if (options.paranoid_checks) &#123; opt.verify_checksums = true;&#125;s = ReadBlock(file, opt, footer.index_handle(), &amp;index_block_contents); 初始化rep_字段。123456789101112131415161718 if (s.ok()) &#123; // We've successfully read the footer and the index block: we're // ready to serve requests. Block* index_block = new Block(index_block_contents); Rep* rep = new Table::Rep; rep-&gt;options = options; rep-&gt;file = file; rep-&gt;metaindex_handle = footer.metaindex_handle(); rep-&gt;index_block = index_block; rep-&gt;cache_id = (options.block_cache ? options.block_cache-&gt;NewId() : 0); rep-&gt;filter_data = nullptr; rep-&gt;filter = nullptr; *table = new Table(rep); (*table)-&gt;ReadMeta(footer); &#125; return s;&#125; Table::NewIterator实际上调用NewTwoLevelIterator得到一个TwoLevelIterator。123456789Iterator* Table::NewIterator(const ReadOptions&amp; options) const &#123; return NewTwoLevelIterator( rep_-&gt;index_block-&gt;NewIterator(rep_-&gt;options.comparator), &amp;Table::BlockReader, const_cast&lt;Table*&gt;(this), options);&#125;Iterator* NewTwoLevelIterator(Iterator* index_iter, BlockFunction block_function, void* arg, const ReadOptions&amp; options); 方法NewIterator的实现如下。如果没有restart点，那么就创建一个空的迭代器，否则创建一个Block::Iter。1234567891011Iterator* Block::NewIterator(const Comparator* comparator) &#123; if (size_ &lt; sizeof(uint32_t)) &#123; return NewErrorIterator(Status::Corruption("bad block contents")); &#125; const uint32_t num_restarts = NumRestarts(); if (num_restarts == 0) &#123; return NewEmptyIterator(); &#125; else &#123; return new Iter(comparator, data_, restart_offset_, num_restarts); &#125;&#125; 两个Level的含义是： IteratorWrapper index_iter_负责查询index block，找到key所在的data block。 IteratorWrapper封装了Iterator，可以理解为一层对valid()和key()的cache。Iterator是个接口，实际类型应该是Block::Iter【待确认】。 IteratorWrapper data_iter_负责在这个block里面查找。 TwoLevelIterator BlockFunction block_function_; 由block_function_可以从一个index_iter_创建一个data_iter_。 在Table的实现中，是Table::BlockReader这个函数。我们将在后面详细分析这个函数。 void* arg_; 在Table的实现中，传入了Table* this。 const ReadOptions options_; Status status_; IteratorWrapper index_iter_; IteratorWrapper data_iter_; std::string data_block_handle_; 如果data_iter_不是null，那么data_block_handle_持有传给block_function_的那个index_iter_的值。 TwoLevelIterator::Next存在一个问题，如果我们一直data_iter_.Next()，我们迟早会碰到一个Block的右边界，这样后面迭代器就Invalid了。因此需要检查如果data_iter_当前已经失效了，那么就递增index_iter_，获取下一个data_iter_，具体实现见下面。12345void TwoLevelIterator::Next() &#123; assert(Valid()); data_iter_.Next(); SkipEmptyDataBlocksForward();&#125; TwoLevelIterator::SkipEmptyDataBlocksForward【Q】在上面说过这个函数的作用了，但是为啥这里实现是while而不是if呢？1234void TwoLevelIterator::SkipEmptyDataBlocksForward() &#123; while (data_iter_.iter() == nullptr || !data_iter_.Valid()) &#123; // Move to next block... SetDataIterator函数接受一个迭代器作为参数，如果迭代器不是空，那么就设置为data_iter_，并且释放掉原来的iter_内存。12345678... if (!index_iter_.Valid()) &#123; SetDataIterator(nullptr); return; &#125; index_iter_.Next(); InitDataBlock();... 需要注意，这里需要显式将data_iter_移动到当前data block的开头。1234... if (data_iter_.iter() != nullptr) data_iter_.SeekToFirst(); &#125;&#125; TwoLevelIterator::InitDataBlockInitDataBlock作用是从index_iter_构建（解析）出一个data block。如果index_iter_无效，那么设置data_iter_也无效。如果data_iter_不为空，并且等于之前的data_block_handle_，说明data_iter_现在就指向的这个data block，那么就跳过。否则，以index_iter_为参数，通过block_function_生成一个新的data_iter_。1234567891011121314void TwoLevelIterator::InitDataBlock() &#123; if (!index_iter_.Valid()) &#123; SetDataIterator(nullptr); &#125; else &#123; Slice handle = index_iter_.value(); if (data_iter_.iter() != nullptr &amp;&amp; handle.compare(data_block_handle_) == 0) &#123; &#125; else &#123; Iterator* iter = (*block_function_)(arg_, options_, handle); data_block_handle_.assign(handle.data(), handle.size()); SetDataIterator(iter); &#125; &#125;&#125; TwoLevelIterator::Seek首先，在index block层Seek。下面证明只要找这个index_iter_指向的data block就行，也就是说，target不会出现在(index_iter_ - 1)和(index_iter_ + 1)指向的data block里面。 因为LevelDB中的性质，Seek得到的是第一个大于等于target的指针。此时，(index_iter_ - 1)中的.key()是严格小于target的。而根据index block的【性质1】，这个index block entry指向的data block中的所有K都小于等于(index_iter_ - 1).key()。因此，(index_iter_ - 1)指向的data block里面所有的K，都小于target。 此外，index_iter_.key()是大于等于target的。 下面，还要证明(index_iter_ + 1).key()指向的data block里面的所有K都大于target。根据【性质2】我们知道index_iter_.key()会严格小于它指向的下一个data block中的所有K，根据我们上一条结论可以知道target严格小于下一个data block中的所有K，所以target如果存在的话，一定是当前data block上的。12void TwoLevelIterator::Seek(const Slice&amp; target) &#123; index_iter_.Seek(target); 接着初始化data_iter_。接着在data block层Seek。1234 InitDataBlock(); if (data_iter_.iter() != nullptr) data_iter_.Seek(target); SkipEmptyDataBlocksForward();&#125; Table::BlockReader接受三个参数： arg 这个类型设置就很奇怪，实际上是一个Table*，表示我们现在读的那个Table的上下文。 index_value 123456789101112131415161718192021222324252627282930313233343536373839404142// Convert an index iterator value (i.e., an encoded BlockHandle)// into an iterator over the contents of the corresponding block.Iterator* Table::BlockReader(void* arg, const ReadOptions&amp; options, const Slice&amp; index_value) &#123; Table* table = reinterpret_cast&lt;Table*&gt;(arg); Cache* block_cache = table-&gt;rep_-&gt;options.block_cache; Block* block = nullptr; Cache::Handle* cache_handle = nullptr; BlockHandle handle; Slice input = index_value; Status s = handle.DecodeFrom(&amp;input); // We intentionally allow extra stuff in index_value so that we // can add more features in the future. if (s.ok()) &#123; BlockContents contents; if (block_cache != nullptr) &#123; char cache_key_buffer[16]; EncodeFixed64(cache_key_buffer, table-&gt;rep_-&gt;cache_id); EncodeFixed64(cache_key_buffer + 8, handle.offset()); Slice key(cache_key_buffer, sizeof(cache_key_buffer)); cache_handle = block_cache-&gt;Lookup(key); if (cache_handle != nullptr) &#123; block = reinterpret_cast&lt;Block*&gt;(block_cache-&gt;Value(cache_handle)); &#125; else &#123; s = ReadBlock(table-&gt;rep_-&gt;file, options, handle, &amp;contents); if (s.ok()) &#123; block = new Block(contents); if (contents.cachable &amp;&amp; options.fill_cache) &#123; cache_handle = block_cache-&gt;Insert(key, block, block-&gt;size(), &amp;DeleteCachedBlock); &#125; &#125; &#125; &#125; else &#123; s = ReadBlock(table-&gt;rep_-&gt;file, options, handle, &amp;contents); if (s.ok()) &#123; block = new Block(contents); &#125; &#125; &#125; 12345678910111213 Iterator* iter; if (block != nullptr) &#123; iter = block-&gt;NewIterator(table-&gt;rep_-&gt;options.comparator); if (cache_handle == nullptr) &#123; iter-&gt;RegisterCleanup(&amp;DeleteBlock, block, nullptr); &#125; else &#123; iter-&gt;RegisterCleanup(&amp;ReleaseBlock, block_cache, cache_handle); &#125; &#125; else &#123; iter = NewErrorIterator(s); &#125; return iter;&#125; Reference https://izualzhy.cn/leveldb-block https://izualzhy.cn/leveldb-sstable]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LevelDB之Memtable实现]]></title>
    <url>%2F2021%2F04%2F09%2Fleveldb-memtable%2F</url>
    <content type="text"><![CDATA[作为LevelDB源码分析系列的第一篇文章，介绍Memtable的实现，以及其中涉及到的数据结构和辅助函数。 Memtable是LevelDB的内存数据结构。当一个Memtable满之后，会被变成Immutable Memtable，并写入SSTable Level0。 基本概念VarIntLevelDB的VarInt机制，用一个char数组存放整数，主要目的不是支持大整数，而是压缩小整数的存储空间。例如小于128的unsigned int，只要一个字节就行，但如果数比较大，。具体实现就是读char数组，如果最高位是1，那么就说明这个VarInt还没有结束，于是就接着读下一位。GetVarint32Ptr的函数签名，传入的limit表示这个VarInt数组有多长。因为VarInt最多占用5个字节，所以一般传入都是p + 5。我们需要注意，合法的limit应当始终大于p。一开始是一个优化分支，如果只有一个char，那么直接返回了，否则调用GetVarint32PtrFallback。这个函数返回的前进后的p。1234567891011121314151617181920212223242526272829inline const char* GetVarint32Ptr(const char* p, const char* limit, uint32_t* value) &#123; if (p &lt; limit) &#123; uint32_t result = *(reinterpret_cast&lt;const uint8_t*&gt;(p)); if ((result &amp; 128) == 0) &#123; *value = result; return p + 1; &#125; &#125; return GetVarint32PtrFallback(p, limit, value);&#125;const char* GetVarint32PtrFallback(const char* p, const char* limit, uint32_t* value) &#123; uint32_t result = 0; for (uint32_t shift = 0; shift &lt;= 28 &amp;&amp; p &lt; limit; shift += 7) &#123; uint32_t byte = *(reinterpret_cast&lt;const uint8_t*&gt;(p)); p++; if (byte &amp; 128) &#123; // More bytes are present result |= ((byte &amp; 127) &lt;&lt; shift); &#125; else &#123; result |= (byte &lt;&lt; shift); *value = result; return reinterpret_cast&lt;const char*&gt;(p); &#125; &#125; return nullptr;&#125; SliceSlice定义在include/leveldb/slice.h里面，可以理解为对const char*的View。 Memtable类Memtable类定义在memtable.h/cc里面。接口如下 size_t ApproximateMemoryUsage() 估计大小，在被修改的时候也可以调用。 Iterator* NewIterator() void Add(SequenceNumber seq, ValueType type, const Slice&amp; key, const Slice&amp; value) 负责插入记录。 type 普通插入type为kTypeValue。 删除操作实际上是插入type为kTypeDeletion的记录。 key bool Get(const LookupKey&amp; key, std::string* value, Status* s) 如果存在key对应的记录，返回true，并且将值存在*value上。 如果存在key被删除的记录，返回true，并且在*status存入NotFound()。 否则返回false。 这里LookupKey的设计较为复杂，稍后讲解。 void Ref() void Unref() Memtable还有下面一些成员： KeyComparator comparator_ 封装了个InternalKeyComparator，这一块后面介绍 12345struct KeyComparator &#123; const InternalKeyComparator comparator; explicit KeyComparator(const InternalKeyComparator&amp; c) : comparator(c) &#123;&#125; int operator()(const char* a, const char* b) const;&#125;; int refs_ Arena arena_ Table table_ 实际上是个跳表。 1typedef SkipList&lt;const char*, KeyComparator&gt; Table; KeyMemtable在跳表中索引的Key中存放三个数据： User Key 用户实际传入的key。 Sequence Number 1typedef uint64_t SequenceNumber; Value Type 表示是不是删除。 对于C而言，enum的大小取决于里面定义的范围。对于C++，可以显式指定实际使用的类型。 1enum ValueType &#123; kTypeDeletion = 0x0, kTypeValue = 0x1 &#125;; 这些数据是按顺序编码的，这样方便比较。 InternalKey把这些打包到一个std::string里面。ParseInternalKey把InternalKey转成ParsedInternalKey，后者可以直接读取上面三个字段。AppendInternalKey可以从ParsedInternalKey构建InternalKey。 为了方便查找，还将User Key和Sequence Number合并，组成LookupKey。 start_ 指向klength，klength表示userkey长度。注意，这里userkey也可以存放InternalKey，所以LookupKey可以表示一个Memtable Key。 1234klength varint32 &lt;-- start_userkey char[klength] &lt;-- kstart_tag uint64 &lt;-- end_ kstart_ end_ 1234567891011121314151617181920class LookupKey &#123; public: // Initialize *this for looking up user_key at a snapshot with // the specified sequence number. LookupKey(const Slice&amp; user_key, SequenceNumber sequence); LookupKey(const LookupKey&amp;) = delete; LookupKey&amp; operator=(const LookupKey&amp;) = delete; ~LookupKey(); // Return a key suitable for lookup in a MemTable. Slice memtable_key() const &#123; return Slice(start_, end_ - start_); &#125; // Return an internal key (suitable for passing to an internal iterator) Slice internal_key() const &#123; return Slice(kstart_, end_ - kstart_); &#125; // Return the user key Slice user_key() const &#123; return Slice(kstart_, end_ - kstart_ - 8); &#125;&#125;; 总结一下，一个Key中的信息包括： klength User Key Tag Sequence Number Value Type 其中： Memtable Key 1+2+3 Internal Key 2+3 User Key 2 比较我们合成了一个包含三个部分的Internal Key，如果仅仅是这样，直接比较也许还是可行的，毕竟User Key、Seq、Value Type啥的都是有层级的。但是，这些东西是用VarInt存储的，这就不好直接bitwise比较了。 Comparator接口定义在include/leveldb/comparator.h里面。包含下面一些成员 int Compare(const Slice&amp; a, const Slice&amp; b) const 比较函数 void FindShortestSeparator(std::string* start, const Slice&amp; limit) 目的是节约空间。如果*start这个字符串小于limit字符串，那么就修改*start，变成大小在*start和limit之间，但是长度最短的字符串。 其方法基于公共前缀，如果*start是helloWorld，limit是helloZookeeper，那么旧改*start为helloX，也就是后面的World不要了。 【Q】这个功能会用到哪里呢？我觉得在插入是用不上的，因为会涉及修改Key的值。 void FindShortSuccessor(std::string* key) data在开头存了对应字符串的长度。所以GetLengthPrefixedSlice会先读取长度到len里面，这个时候p前进指向了实际的字符串，然后创建一个Slice。123456static Slice GetLengthPrefixedSlice(const char* data) &#123; uint32_t len; const char* p = data; p = GetVarint32Ptr(p, p + 5, &amp;len); // +5: we assume "p" is not corrupted return Slice(p, len);&#125; MemTable::KeyComparator就是获取对应的字符串，然后调用InternalKeyComparator比较。1234567int MemTable::KeyComparator::operator()(const char* aptr, const char* bptr) const &#123; // Internal keys are encoded as length-prefixed strings. Slice a = GetLengthPrefixedSlice(aptr); Slice b = GetLengthPrefixedSlice(bptr); return comparator.Compare(a, b);&#125; 比较的顺序是: User Key升序 Sequence Number降序 这样，会倾向于找新的 ValueType降序 但考虑到Sequence Number，大概率用不到。12345678910111213int InternalKeyComparator::Compare(const Slice&amp; akey, const Slice&amp; bkey) const &#123; int r = user_comparator_-&gt;Compare(ExtractUserKey(akey), ExtractUserKey(bkey)); if (r == 0) &#123; const uint64_t anum = DecodeFixed64(akey.data() + akey.size() - 8); const uint64_t bnum = DecodeFixed64(bkey.data() + bkey.size() - 8); if (anum &gt; bnum) &#123; r = -1; &#125; else if (anum &lt; bnum) &#123; r = +1; &#125; &#125; return r;&#125; 可以看到，在InternalKeyComparator里面，还会调用user_comparator_-&gt;Compare去比较User Key。它默认是BytewiseComparator类型的。 插入现在我们有一个KV对key和value，都用Slice运载的。我们要把它放到跳表中。有点类似于Spark将K和V连续放在两个slot上，LevelDB直接将K和V编码到一起存放。因此，我们可以看到总长度encoded_len需要计算下面几部分： K的长度，用VarInt存 这里internal_key_size为啥要加上8呢？这是因为Sequence Number和Type分别占用了7个byte和1个byte。所以从User Key生成Internal Key的时候要加上这两部分。 这就是Memtable Key，相对于Internal Key多存储的一块数据。 K本身 也就是Internal Key。 V的长度 V本身1234567891011121314void MemTable::Add(SequenceNumber s, ValueType type, const Slice&amp; key, const Slice&amp; value) &#123; // Format of an entry is concatenation of: // key_size : varint32 of internal_key.size() // key bytes : char[internal_key.size()] // value_size : varint32 of value.size() // value bytes : char[value.size()] size_t key_size = key.size(); size_t val_size = value.size(); size_t internal_key_size = key_size + 8; const size_t encoded_len = VarintLength(internal_key_size) + internal_key_size + VarintLength(val_size) + val_size;... 下面，就是从Memtable里面的Arena中分配一块内存buf，然后把上面说的四个字段填进去，最后把buf添加到跳表table_里面。跳表插入只需要实现比较操作，这个之前已经定义过了。123456789101112... char* buf = arena_.Allocate(encoded_len); char* p = EncodeVarint32(buf, internal_key_size); std::memcpy(p, key.data(), key_size); p += key_size; EncodeFixed64(p, (s &lt;&lt; 8) | type); p += 8; p = EncodeVarint32(p, val_size); std::memcpy(p, value.data(), val_size); assert(p + val_size == buf + encoded_len); table_.Insert(buf);&#125; 查找首先，从LookupKey中取得memtable_key，这个是包含了4个部分的。接着获得跳表的迭代器iter，定位到第一个大于等于memkey的位置。我们得到key_ptr指向Internal Key，key_length为Internal Key的长度。1234567891011121314151617bool MemTable::Get(const LookupKey&amp; key, std::string* value, Status* s) &#123; Slice memkey = key.memtable_key(); Table::Iterator iter(&amp;table_); iter.Seek(memkey.data()); if (iter.Valid()) &#123; // entry format is: // klength varint32 // userkey char[klength] // tag uint64 // vlength varint32 // value char[vlength] // Check that it belongs to same user key. We do not check the // sequence number since the Seek() call above should have skipped // all entries with overly large sequence numbers. const char* entry = iter.key(); uint32_t key_length; const char* key_ptr = GetVarint32Ptr(entry, entry + 5, &amp;key_length); 接着我们比较Value Type，它在tag的最后一个字节。注意tag的组装方式是(seq &lt;&lt; 8) | type123456789101112131415161718 if (comparator_.comparator.user_comparator()-&gt;Compare( Slice(key_ptr, key_length - 8), key.user_key()) == 0) &#123; // Correct user key const uint64_t tag = DecodeFixed64(key_ptr + key_length - 8); switch (static_cast&lt;ValueType&gt;(tag &amp; 0xff)) &#123; case kTypeValue: &#123; Slice v = GetLengthPrefixedSlice(key_ptr + key_length); value-&gt;assign(v.data(), v.size()); return true; &#125; case kTypeDeletion: *s = Status::NotFound(Slice()); return true; &#125; &#125; &#125; return false;&#125; Reference https://izualzhy.cn/memtable-leveldb https://github.com/yingshin/leveldb_more_annotation/blob/master/db/memtable.h https://zhuanlan.zhihu.com/p/79362747 https://github.com/balloonwj/CppGuide/blob/master/articles/leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904.md]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis事务的实现]]></title>
    <url>%2F2021%2F03%2F23%2Fredis-transaction%2F</url>
    <content type="text"><![CDATA[本文详细介绍Redis事务的实现，以及涉及到主从复制的情况。由于持久化涉及Redis文件系统RIO，所以也会对RIO进行介绍。这是Redis源码分析的系列文章的第四篇，前三篇分别是 Redis底层对象实现原理分析 Redis Sentinel实现原理分析 Redis持久化机制实现 简介事务在执行期间不会主动中断，也就是说服务器在执行完事务中的所有命令之后，才会继续处理其他客户端的其他命令。需要注意的是，Redis并没有原子性。原因之一是Redis不支持事务回滚。有人说Redis不是有DISCARD的么？但这个DISCARD只是在命令入队的阶段，等到真正执行事务的时候，Redis并不支持执行到一般就退出。 multi总的来说，就是multi开始事务，最后exec提交事务或者discard放弃事务。在发送完multi后，后面发送的命令都不会被立即执行，而是返回QUEUED状态。当收到exec后，事务会将这个队列中的命令按照fifo的顺序执行。并发结果放入一个回复队列中返回给客户端。 watch在multi前监控一些key，如果这些key被修改，则事务回滚。 主要结构multiState123456789101112typedef struct multiState &#123; multiCmd *commands; int count; int cmd_flags; /* The accumulated command flags OR-ed together. So if at least a command has a given flag, it will be set in this field. */ int cmd_inv_flags; /* Same as cmd_flags, OR-ing the ~flags. so that it is possible to know if all the commands have a certain flag. */ int minreplicas; /* MINREPLICAS for synchronous replication */ time_t minreplicas_timeout; /* MINREPLICAS timeout as unixtime. */&#125; multiState; 主要涉及下面一些字段： commands 这个是multiCmd数组，表示事务中的FIFO的队列。 count multi命令的数量，表示commands的长度？ cmd_flags multiCmd12345typedef struct multiCmd &#123; robj **argv; int argc; struct redisCommand *cmd;&#125; multiCmd; redisCmd事务开始和结束的实现普通命令可以看到，在processCommand中，如果被设置了MULTI，那么就不会调用call，而是调用queueMultiCommand将指令入队。12345678910111213141516int processCommand(client *c) &#123;... if (c-&gt;flags &amp; CLIENT_MULTI &amp;&amp; c-&gt;cmd-&gt;proc != execCommand &amp;&amp; c-&gt;cmd-&gt;proc != discardCommand &amp;&amp; c-&gt;cmd-&gt;proc != multiCommand &amp;&amp; c-&gt;cmd-&gt;proc != watchCommand) &#123; queueMultiCommand(c); addReply(c,shared.queued); &#125; else &#123; call(c,CMD_CALL_FULL); c-&gt;woff = server.master_repl_offset; if (listLength(server.ready_keys)) handleClientsBlockedOnKeys(); &#125;...&#125; 开始multi指令，会给客户端打上CLIENT_MULTI这个flag。12345678void multiCommand(client *c) &#123; if (c-&gt;flags &amp; CLIENT_MULTI) &#123; addReplyError(c,"MULTI calls can not be nested"); return; &#125; c-&gt;flags |= CLIENT_MULTI; addReply(c,shared.ok);&#125; discard12345678void discardCommand(client *c) &#123; if (!(c-&gt;flags &amp; CLIENT_MULTI)) &#123; addReplyError(c,"DISCARD without MULTI"); return; &#125; discardTransaction(c); addReply(c,shared.ok);&#125; discardTransaction先调用discardTransaction清空multiCmd数组。再调用initClientMultiState清除multiState里面的其他内容。再取消所有事务相关的flag。这边的flag都是什么意思？ CLIENT_MULTI CLIENT_DIRTY_CAS 表示被watch的字段发生了修改。 CLIENT_DIRTY_EXEC 由flagTransaction产生，表示在先前操作中，出现了错误，所以不能exec。包含下面情况： rejectCommand 在下面的场景下被调用： shared.noautherr shared.oomerr shared.bgsaveerr 等等 rejectCommandFormat processCommand中，涉及Redis Cluster相关。123456void discardTransaction(client *c) &#123; freeClientMultiState(c); initClientMultiState(c); c-&gt;flags &amp;= ~(CLIENT_MULTI|CLIENT_DIRTY_CAS|CLIENT_DIRTY_EXEC); unwatchAllKeys(c);&#125; exec123456789101112void execCommand(client *c) &#123; int j; robj **orig_argv; int orig_argc; struct redisCommand *orig_cmd; int must_propagate = 0; /* Need to propagate MULTI/EXEC to AOF / slaves? */ int was_master = server.masterhost == NULL; if (!(c-&gt;flags &amp; CLIENT_MULTI)) &#123; addReplyError(c,"EXEC without MULTI"); return; &#125; 检查flags，discard掉有问题的事务： 对于CLIENT_DIRTY_CAS返回空数组 因为这个不能算作是错误，只能作为一种特殊的表现。 对于CLIENT_DIRTY_EXEC返回EXECABORT12345678910/* * A failed EXEC in the first case returns a multi bulk nil object * (technically it is not an error but a special behavior), while * in the second an EXECABORT error is returned. */if (c-&gt;flags &amp; (CLIENT_DIRTY_CAS|CLIENT_DIRTY_EXEC)) &#123; addReply(c, c-&gt;flags &amp; CLIENT_DIRTY_EXEC ? shared.execaborterr : shared.nullarray[c-&gt;resp]); discardTransaction(c); goto handle_monitor;&#125; 因为已经检查了，取消客户端对所有键的监视。因为事务中的命令在执行时可能会修改命令和命令的参数，所以为了正确地传播命令，需要备份这些命令和参数。下面开始处理multiState下面所有的multiCmd。12345678910/* Exec all the queued commands */unwatchAllKeys(c); /* Unwatch ASAP otherwise we'll waste CPU cycles */orig_argv = c-&gt;argv;orig_argc = c-&gt;argc;orig_cmd = c-&gt;cmd;addReplyArrayLen(c,c-&gt;mstate.count);for (j = 0; j &lt; c-&gt;mstate.count; j++) &#123; c-&gt;argc = c-&gt;mstate.commands[j].argc; c-&gt;argv = c-&gt;mstate.commands[j].argv; c-&gt;cmd = c-&gt;mstate.commands[j].cmd; 当我们遇到第一个不是CMD_READONLY或者CMD_ADMIN的请求时，传播multi指令。【Q】这里readonly又出现了，为啥这么特殊呢？我觉得readonly指令一般指的是get之类的不涉及修改的指令。而一旦涉及修改或者增加等的指令，我们一定要把这个变动propagate出去。这样，我们可以将MULTI/..../EXEC打包成一整个，并且AOF和Slave都具有相同的一致性和原子性的要求。为啥呢？1234567if (!must_propagate &amp;&amp; !server.loading &amp;&amp; !(c-&gt;cmd-&gt;flags &amp; (CMD_READONLY|CMD_ADMIN)))&#123; execCommandPropagateMulti(c); must_propagate = 1;&#125; ACLCheckCommandPerm主要检查权限，包含： 执行命令的权限 对某个key的权限 如果检查通过，我们就用call来执行命令。123456789101112131415int acl_keypos;int acl_retval = ACLCheckCommandPerm(c,&amp;acl_keypos);if (acl_retval != ACL_OK) &#123; addACLLogEntry(c,acl_retval,acl_keypos,NULL); addReplyErrorFormat(c, "-NOPERM ACLs rules changed between the moment the " "transaction was accumulated and the EXEC call. " "This command is no longer allowed for the " "following reason: %s", (acl_retval == ACL_DENIED_CMD) ? "no permission to execute the command or subcommand" : "no permission to touch the specified keys");&#125; else &#123; call(c,server.loading ? CMD_CALL_NONE : CMD_CALL_FULL);&#125; 因为执行后命令、命令参数可能会被改变，比如SPOP会被改写为SREM，所以这里需要更新事务队列中的命令和参数，确保Slave和AOF的数据一致性。12345 /* Commands may alter argc/argv, restore mstate. */ c-&gt;mstate.commands[j].argc = c-&gt;argc; c-&gt;mstate.commands[j].argv = c-&gt;argv; c-&gt;mstate.commands[j].cmd = c-&gt;cmd;&#125; 在这个循环结束之后，事务执行完了，我们还原命令，并且清空事务状态。1234c-&gt;argv = orig_argv;c-&gt;argc = orig_argc;c-&gt;cmd = orig_cmd;discardTransaction(c); 下面，如果我们需要propagate的话，就增加dirty。先前我们知道，在call结束之后，如果有dirty，会去触发检测是否propagate的逻辑。而call也是可以嵌套调用的。这里有一个特殊情况需要考虑。就是在multi/exec块中，这个实例突然从Master切换成了Slave（可能是来自Sentinel的SLAVEOF指令）。此时，原来Master收到的multi指令已经被传播到了replication backlog里面，但是后面的可能还没来得及传。对于这种情况，我们需要保证至少通过exec来结束这个backlog。【Q】为啥不用discard呢？1234567891011121314151617181920 /* Make sure the EXEC command will be propagated as well if MULTI * was already propagated. */ if (must_propagate) &#123; int is_master = server.masterhost == NULL; server.dirty++; if (server.repl_backlog &amp;&amp; was_master &amp;&amp; !is_master) &#123; char *execcmd = "*1\r\n$4\r\nEXEC\r\n"; feedReplicationBacklog(execcmd,strlen(execcmd)); &#125; &#125;handle_monitor: /* Send EXEC to clients waiting data from MONITOR. We do it here * since the natural order of commands execution is actually: * MUTLI, EXEC, ... commands inside transaction ... * Instead EXEC is flagged as CMD_SKIP_MONITOR in the command * table, and we do it here with correct ordering. */ if (listLength(server.monitors) &amp;&amp; !server.loading) replicationFeedMonitors(c,server.monitors,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc);&#125;]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL查询]]></title>
    <url>%2F2021%2F03%2F15%2Fmysql-query%2F</url>
    <content type="text"><![CDATA[本文介绍MySQL InnoDB下索引、查询的实现以及优化。 查询回表查询和覆盖索引什么是回表查询？InnoDB中的主键(Primary Key, PK)使用了聚簇索引，即主键索引的叶子节点存放的是行数据本身。因此通过主键进行SELECT是很快的。但是对于其他的索引，它们的叶子节点存放的是主键ID。这个是显然的，不然我每创建一个索引就得重新建立一个表结构了。在这种情况下访问行数据，就得通过主键ID去聚簇索引中再查一次，这个也就是所谓的回表查询。 看到这里不禁有一个想法，我们能不能把主键的索引做成哈希的，这样的话它的复杂度是O(1)，能减小回表开销，主要有下面的考虑： 自增主键往往规律可循，能够设计出很好的哈希函数。 因为自增索引不像银行卡号码或者手机号码那样具有实际的意义，所以B+树提供的一些范围查询的性能未必常用。 B+树毕竟是O(log n)的复杂度，如果使用哈希索引，能够提高回表查询的效率。 哈希索引更好做分区。 那有没有其他办法减少回表查询的开销呢？一个方案是通过覆盖索引(Covering Index)。 为了介绍覆盖索引，首先介绍联合索引。对于下面的语句生成的索引，可以用来加速c1、c1,c2、c1,c2,c3这三个查询。这个也是好理解的，例如我们在查询字典的时候，可以先查询第一个字母，然后再查询第二个字母；反之，没办法直接查第二个字母和第三个字母，即用不了c2,c3这样的索引。这启示我们，在设计联合索引的时候，应当把最常用或者最宽泛的条件放到最左边。1create index index_c1_c2_c3 on table1(c1,c2,c3); 通过覆盖索引，通过非聚簇索引查询数据也不需要再回表了，这得益于联合索引。例如index_c1_c2_c3就包含了c1、c2、c3这三个字段的值，那么如果我们只需要查询这些值的话，就不需要回表了。 Extra总结Using temporary需要创建临时表。 Using filesort文件排序，通常出现在不能使用索引排序的情况。一个通常的情况是使用查询索引之外的Key去做ORDER BY时。文件排序一般有几种实现方式，令被排序的键是S，主键是ref，需要返回的列是addon1、addon2、addon3，则有 (S,ref)，即original filesort algorithm，回表排序 这种方式占用空间较小，但需要在排序后根据ref回表查询，从而产生很多随机IO。 (S,addon1,addon2,addon3)，即modified filesort algorithm，不回表排序 这种方案不需要回表，但是对排序空间要求高。当然，对于诸如varchar类型的addon字段，是可以压缩(pack)一下的，但是对于搜索排序键是不行的。 具体选择哪种方案，主要是看S和所有addon字段的长度总和是否超过一定的阈值。 Using index使用覆盖索引获取所需要的数据。 Using Index Condition这个实际上运用了索引下推(Index Condition Pushdown)技术。这个技术是MySQL 5.7之后的一个优化，涉及了服务器层和存储引擎层。首先来先看下没有这个优化的select where过程： 首先读取下一行的index tuple，然后用index tuple去定位并读取整个行。 检查所有的WHERE条件，如果该条件属于这张表，就进行检测是否符合条件。在有了这个优化之后，新的过程是： 首先读取下一行的index tuple，但不需要再去读取整个行。 检查所有的WHERE条件，如果该条件属于这张表，并且能够根据当前使用的索引就能检测，就直接检测了。如果条件不满足，直接看下一行。 如果条件满足，用index tuple去定位并读取整个行。 使用刚才剩下来没有被用到的WHERE条件，检测是否符合条件。 Using where表示MySQL需要在收到存储引擎返回的结果后，对这个结果进行后过滤(Post filter)。 实验首先构造样例，在db1中创建表table1_noindex、table1、table2_noindex。对表table1创建联合索引index_c1_c2_c3和索引index_c5。123456789101112131415161718192021222324252627create DATABASE db1;use db1;drop table table1_noindex;drop table table1;create TABLE table1_noindex( id INT AUTO_INCREMENT PRIMARY KEY, c1 INT NOT NULL, c2 VARCHAR(30) NOT NULL, c3 DATE NOT NULL, c4 INT NOT NULL, c5 INT NOT NULL UNIQUE);create TABLE table2_noindex( id INT AUTO_INCREMENT PRIMARY KEY, c5 INT NOT NULL UNIQUE);CREATE TABLE table1 LIKE table1_noindex;INSERT INTO table1 SELECT * FROM table1_noindex;create index index_c1_c2_c3 on table1(c1,c2,c3);create index index_c5 on table1(c5);insert into table1 values (NULL, 3, "a", NOW(), 4, 5);insert into table1_noindex values (NULL, 3, "a", NOW(), 4, 5); 查看索引1mysql&gt; show keys from table1; 使用主键或者UNIQUE键 1234567891011121314mysql&gt; explain select * from table1 where id=1\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table1 partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 4 ref: const rows: 1 filtered: 100.00 Extra: NULL 需要注意的是，使用UNIQUE键，同样会是const类型而不是eq_ref 1234567891011121314mysql&gt; explain select c1,c5 from table1 where c5=5\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table1 partitions: NULL type: constpossible_keys: c5 key: c5 key_len: 4 ref: const rows: 1 filtered: 100.00 Extra: NULL 使用索引 Extra中的Using index表示单纯用索引即可获得所有数据，不需要回表查询，这也就是之前提到的覆盖索引。下面我们介绍覆盖索引 1234567891011121314mysql&gt; explain select c1,c2,c3 from table1 where c1=1 and c2="a"\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table1 partitions: NULL type: refpossible_keys: index_c1_c2_c3 key: index_c1_c2_c3 key_len: 96 ref: const,const rows: 1 filtered: 100.00 Extra: Using index 但是，如果我们加上c4，就必须要回表了 1234567891011121314mysql&gt; explain select c1,c4 from table1 where c1=1 and c2="a"\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table1 partitions: NULL type: refpossible_keys: index_c1_c2_c3 key: index_c1_c2_c3 key_len: 96 ref: const,const rows: 1 filtered: 100.00 Extra: NULL 此外，如果我们对索引列进行计算或者应用函数，也会导致不能使用索引 1234567891011121314mysql&gt; explain select c1,c2,c3 from table1 where c1*2=2 and c2="a"\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table1 partitions: NULL type: indexpossible_keys: index_c1_c2_c3 key: index_c1_c2_c3 key_len: 99 ref: NULL rows: 1 filtered: 100.00 Extra: Using where; Using index 使用索引下推 为了规避掉覆盖索引直接返回，我们这次用了select *。当然，也可以select索引之外的列，比如c4。 1234567891011121314mysql&gt; explain select * from table1 where c1=1 and c2 like "a*"\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table1 partitions: NULL type: rangepossible_keys: index_c1_c2_c3 key: index_c1_c2_c3 key_len: 96 ref: NULL rows: 1 filtered: 100.00 Extra: Using index condition 不使用索引 可以发现，type是个ALL，表示发生了全表扫描。 1234567891011121314mysql&gt; explain select c1,c2,c3 from table1_noindex where c1=1 and c2="a"\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table1_noindex partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 1 filtered: 100.00 Extra: Using where 破坏了最左匹配原则 这一次，type是index，这表示仍然需要进行全表扫描。但不同的是扫描是按照索引的顺序，也就是说不需要对结果排序了。 1234567891011121314mysql&gt; explain select c1,c2,c3 from table1 where c3=DATE('2012-12-21 00:00:00')\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table1 partitions: NULL type: indexpossible_keys: index_c1_c2_c3 key: index_c1_c2_c3 key_len: 99 ref: NULL rows: 1 filtered: 100.00 Extra: Using where; Using index 当然如果我们执行一下下面的语句，type又会变成ref 1create index index_c3 on table1(c3); 多表查询 1234567mysql&gt; explain select table2_noindex.c5 from table1,table2_noindex where table1.c5=table2_noindex.c5;+----+-------------+----------------+------------+--------+---------------+------+---------+---------------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+----------------+------------+--------+---------------+------+---------+---------------+------+----------+-------------+| 1 | SIMPLE | table1 | NULL | index | c5 | c5 | 4 | NULL | 1 | 100.00 | Using index || 1 | SIMPLE | table2_noindex | NULL | eq_ref | c5 | c5 | 4 | db1.table1.c5 | 1 | 100.00 | Using index |+----+-------------+----------------+------------+--------+---------------+------+---------+---------------+------+----------+-------------+ 1234567mysql&gt; explain select c1,table2_noindex.c5 from table1,table2_noindex where table1.c5=table2_noindex.c5;+----+-------------+----------------+------------+--------+---------------+------+---------+---------------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+----------------+------------+--------+---------------+------+---------+---------------+------+----------+-------------+| 1 | SIMPLE | table1 | NULL | ALL | c5 | NULL | NULL | NULL | 1 | 100.00 | NULL || 1 | SIMPLE | table2_noindex | NULL | eq_ref | c5 | c5 | 4 | db1.table1.c5 | 1 | 100.00 | Using index |+----+-------------+----------------+------------+--------+---------------+------+---------+---------------+------+----------+-------------+ Reference]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL锁]]></title>
    <url>%2F2021%2F03%2F14%2Fmysql-lock%2F</url>
    <content type="text"><![CDATA[本文介绍MySQL InnoDB下锁的实现以及优化。 【未完待续】 锁InnoDB在RR级别下，通过Next Key Lock(Record Lock+Gap Lock)提供了等价于Serializable的能力。Serializable被用在分布式事务上，即对于分布式事务，MySQL要求Serializable隔离级别。 实验实验修改自文章。1234567drop table table1;create table table1( c1 int, key index_c1(c1));insert into table1 values (1),(3),(5),(8),(11); Session1，使用for update会强制加行锁（如果存在）或者间隙锁12start transaction;select * from table1 where c1 = 8 for update; Session2123start transaction;select * from table1;insert into table1 values (6); Session2会被Session1阻塞。如果没有间隙锁，那么只会锁住c1为8的这一行。 Reference]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化机制实现]]></title>
    <url>%2F2021%2F03%2F13%2Fredis-persist%2F</url>
    <content type="text"><![CDATA[Redis持久化机制包括AOF和RDB两种： RDB保存二进制形式的数据库快照。 AOF以协议文本的方式，记录数据库写入的指令。 本文详细介绍这两种方式的实现，以及涉及到主从复制的情况。由于持久化涉及Redis文件系统RIO，所以也会对RIO进行介绍。作为Redis源码分析的系列文章，本文使用的版本和Redis底层对象实现原理分析、Redis Sentinel实现原理分析等文章是相同的。 RIOrioInitWithFile从FILE创建一个rio对象。123456void rioInitWithFile(rio *r, FILE *fp) &#123; *r = rioFileIO; r-&gt;io.file.fp = fp; r-&gt;io.file.buffered = 0; r-&gt;io.file.autosync = 0;&#125; 解释一下剩下来的两个参数： autosync 表示在写入autosync个字节之后，就进行fsync。 可以通过rioSetAutoSync函数进行设置。 bioRedis将耗时的io操作放到后台的线程来执行。因此叫做background io。 创建一个io任务可以将下列的任务给bio做 BIO_CLOSE_FILE 等于延迟了的close(2) BIO_AOF_FSYNC 等于延迟了的AOF fsync BIO_LAZY_FREE 等于延迟了的内存释放对于每一种类型，维护一个任务队列bio_jobs[type]，一个互斥量bio_jobs[type]和一个条件变量bio_newjob_cond[type])。创建io任务很简单，首先获得对应任务类型的锁，然后将任务job加到对应列表bio_jobs[type]的尾部，然后通知条件变量。12345678910111213void bioCreateBackgroundJob(int type, void *arg1, void *arg2, void *arg3) &#123; struct bio_job *job = zmalloc(sizeof(*job)); job-&gt;time = time(NULL); job-&gt;arg1 = arg1; job-&gt;arg2 = arg2; job-&gt;arg3 = arg3; pthread_mutex_lock(&amp;bio_mutex[type]); listAddNodeTail(bio_jobs[type],job); bio_pending[type]++; pthread_cond_signal(&amp;bio_newjob_cond[type]); pthread_mutex_unlock(&amp;bio_mutex[type]);&#125; 后台处理从bioInit里面可以看到，这个void *arg，实际上传入的是int类型的type。Redis会为每一种任务创建一个线程专门来处理。1234567891011121314151617181920212223void *bioProcessBackgroundJobs(void *arg) &#123; struct bio_job *job; unsigned long type = (unsigned long) arg; sigset_t sigset; /* Check that the type is within the right interval. */ if (type &gt;= BIO_NUM_OPS) &#123; serverLog(LL_WARNING, "Warning: bio thread started with wrong type %lu",type); return NULL; &#125; switch (type) &#123; case BIO_CLOSE_FILE: redis_set_thread_title("bio_close_file"); break; case BIO_AOF_FSYNC: redis_set_thread_title("bio_aof_fsync"); break; case BIO_LAZY_FREE: redis_set_thread_title("bio_lazy_free"); break; &#125; 这个函数接受一个字符串，类似”0,2,3”, “0,2-3”, “0-20:2”这样。表示设置对某些CPU的亲和性。此外，还需要让线程可以异步终止。123456redisSetCpuAffinity(server.bio_cpulist);/* Make the thread killable at any time, so that bioKillThreads() * can work reliably. */pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL); 下面是处理信号机制，在这里面需要对bio_mutex[type]加锁的。12345678pthread_mutex_lock(&amp;bio_mutex[type]);/* Block SIGALRM so we are sure that only the main thread will * receive the watchdog signal. */sigemptyset(&amp;sigset);sigaddset(&amp;sigset, SIGALRM);if (pthread_sigmask(SIG_BLOCK, &amp;sigset, NULL)) serverLog(LL_WARNING, "Warning: can't mask SIGALRM in bio.c thread: %s", strerror(errno)); 下面的循环是一个经典的生产者消费者模型，我们这个函数是消费者。因此，如果我们检查到自己的队列是空的，那么就在条件变量bio_newjob_cond[type]上面等待，我们还需要同时传入bio_mutex[type]，因为条件变量的实现需要对这个mutex加锁或者解锁。如果说队列不是空的，就读取队头，但是不实际pop，并且解锁。1234567891011121314while(1) &#123; listNode *ln; /* The loop always starts with the lock hold. */ if (listLength(bio_jobs[type]) == 0) &#123; pthread_cond_wait(&amp;bio_newjob_cond[type],&amp;bio_mutex[type]); continue; &#125; /* Pop the job from the queue. */ ln = listFirst(bio_jobs[type]); job = ln-&gt;value; /* It is now possible to unlock the background system as we know have * a stand alone job structure to process.*/ pthread_mutex_unlock(&amp;bio_mutex[type]); 下面就是根据任务类型，去做相应的工作。1234567891011121314151617181920/* Process the job accordingly to its type. */if (type == BIO_CLOSE_FILE) &#123; close((long)job-&gt;arg1);&#125; else if (type == BIO_AOF_FSYNC) &#123; redis_fsync((long)job-&gt;arg1);&#125; else if (type == BIO_LAZY_FREE) &#123; /* What we free changes depending on what arguments are set: * arg1 -&gt; free the object at pointer. * arg2 &amp; arg3 -&gt; free two dictionaries (a Redis DB). * only arg3 -&gt; free the skiplist. */ if (job-&gt;arg1) lazyfreeFreeObjectFromBioThread(job-&gt;arg1); else if (job-&gt;arg2 &amp;&amp; job-&gt;arg3) lazyfreeFreeDatabaseFromBioThread(job-&gt;arg2,job-&gt;arg3); else if (job-&gt;arg3) lazyfreeFreeSlotsMapFromBioThread(job-&gt;arg3);&#125; else &#123; serverPanic("Wrong job type in bioProcessBackgroundJobs().");&#125;zfree(job); 等我们处理完了，再把对应的节点pop出来。12345678910 /* Lock again before reiterating the loop, if there are no longer * jobs to process we'll block again in pthread_cond_wait(). */ pthread_mutex_lock(&amp;bio_mutex[type]); listDelNode(bio_jobs[type],ln); bio_pending[type]--; /* Unblock threads blocked on bioWaitStepOfType() if any. */ pthread_cond_broadcast(&amp;bio_step_cond[type]); &#125;&#125; RDBRDB机制的调用链（从下到上）如下所示： startSaving rdbSave flushAllDataAndResetRDB flushallCommand FLUSHALL指令 saveCommand SAVE指令 rdbSaveBackground bgsaveCommand BGSAVE指令 rdbSave观察函数签名，将一个结构rsi存到文件filename里面1int rdbSave(char *filename, rdbSaveInfo *rsi) 首先是尝试创建临时的rdb文件，这里先创建临时文件，可能是为了防止RDB过程执行到一半宕掉了，导致写的RDB文件不全或者有问题。这样等到确定成功再改名会好一点？1snprintf(tmpfile,256,"temp-%d.rdb", (int) getpid()); 如果文件创建失败，会产生错误日志123456serverLog(LL_WARNING, "Failed opening the RDB file %s (in server root dir %s) " "for saving: %s", filename, cwdp ? cwdp : "unknown", strerror(errno)); 下面就是真正的dump过程。首先创建一个rio对象rdb，并且调用函数startSaving12rioInitWithFile(&amp;rdb,fp);startSaving(RDBFLAGS_NONE); 这个函数根据传入的rdbflags，向Redis发送事件。有关事件模块的内容，我们不在这里进行论述。需要注意，函数中额外检查了pid，从而确定是同步RDB还是异步RDB。1234567891011void startSaving(int rdbflags) &#123; /* Fire the persistence modules end event. */ int subevent; if (rdbflags &amp; RDBFLAGS_AOF_PREAMBLE) subevent = REDISMODULE_SUBEVENT_PERSISTENCE_AOF_START; else if (getpid()!=server.pid) subevent = REDISMODULE_SUBEVENT_PERSISTENCE_RDB_START; else subevent = REDISMODULE_SUBEVENT_PERSISTENCE_SYNC_RDB_START; moduleFireServerEvent(REDISMODULE_EVENT_PERSISTENCE,subevent,NULL);&#125; 对应的rdbflags有下面的取值 RDBFLAGS_NONE 在rdbSave中调用 RDBFLAGS_AOF_PREAMBLE 是否用于AOF机制 RDBFLAGS_REPLICATION 是否用于主从复制 RDBFLAGS_ALLOW_DUP 这是一个选项 如果开启了rdb_save_incremental_fsync增量写盘，就设置一下rio的autosync字段，REDIS_AUTOSYNC_BYTES默认是32MB。容易看出，写32MB才刷盘，如果此时系统宕机，Redis的持久性是得不到保障的，这个在我们对InnoDB的介绍中也出现过。12if (server.rdb_save_incremental_fsync) rioSetAutoSync(&amp;rdb,REDIS_AUTOSYNC_BYTES); 下面是核心逻辑rdbSaveRio，我们在后面专门讨论1234if (rdbSaveRio(&amp;rdb,&amp;error,RDBFLAGS_NONE,rsi) == C_ERR) &#123; errno = error; goto werr;&#125; 下面执行fflush，将C库缓冲区写到内核缓冲区，再调用fsync强制落盘。由于RDB类似于写checkpoint而不是写日志，所以这边写完直接刷盘，不需要统计autosync。1234/* Make sure data will not remain on the OS's output buffers */if (fflush(fp) == EOF) goto werr;if (fsync(fileno(fp)) == -1) goto werr;if (fclose(fp) == EOF) goto werr; 下面调用rename转换成正式的名字，调用stopSaving(1)发送成功事件。如果rename失败，就发送失败事件，并且调用unlink删除临时文件。1234567891011121314151617181920212223 /* Use RENAME to make sure the DB file is changed atomically only * if the generate DB file is ok. */ if (rename(tmpfile,filename) == -1) &#123; char *cwdp = getcwd(cwd,MAXPATHLEN); serverLog(...); unlink(tmpfile); stopSaving(0); return C_ERR; &#125; serverLog(LL_NOTICE,"DB saved on disk"); server.dirty = 0; server.lastsave = time(NULL); server.lastbgsave_status = C_OK; stopSaving(1); return C_OK;werr: serverLog(LL_WARNING,"Write error saving DB on disk: %s", strerror(errno)); fclose(fp); unlink(tmpfile); stopSaving(0); return C_ERR; rdbSaveRio首先看一下dump.rdb的内容，他通常位于redis的安装目录下。1REDIS0006þ^@^@^AcÀ^B^@^AbÀ^A^@^AaÀ^@ÿ&lt;92&gt;?6Äx^B±Ä 照例查看函数声明。12345678int rdbSaveRio(rio *rdb, int *error, int rdbflags, rdbSaveInfo *rsi) &#123; dictIterator *di = NULL; dictEntry *de; char magic[10]; int j; uint64_t cksum; size_t processed = 0; 首先写入magic，和全局以及所有模块的辅助信息123456if (server.rdb_checksum) rdb-&gt;update_cksum = rioGenericUpdateChecksum;snprintf(magic,sizeof(magic),"REDIS%04d",RDB_VERSION);if (rdbWriteRaw(rdb,magic,9) == -1) goto werr;if (rdbSaveInfoAuxFields(rdb,rdbflags,rsi) == -1) goto werr;if (rdbSaveModulesAux(rdb, REDISMODULE_AUX_BEFORE_RDB) == -1) goto werr; 下面对于每一个数据库j，进行dump写入1234for (j = 0; j &lt; server.dbnum; j++) &#123; redisDb *db = server.db+j; dict *d = db-&gt;dict; if (dictSize(d) == 0) continue; 这里获得一个安全迭代器，也就是说在这个迭代器存在的时候是停止Rehash的。123di = dictGetSafeIterator(d);/* Write the SELECT DB opcode */ 写入RDB_OPCODE_SELECTDB这个op，并保存一些元数据： 当前db的编号 当前db的size 当前db的expires链表的size 这些元数据会通过提前写入的RDB_OPCODE_进行区分。12345678910if (rdbSaveType(rdb,RDB_OPCODE_SELECTDB) == -1) goto werr;if (rdbSaveLen(rdb,j) == -1) goto werr;/* Write the RESIZE DB opcode. */uint64_t db_size, expires_size;db_size = dictSize(db-&gt;dict);expires_size = dictSize(db-&gt;expires);if (rdbSaveType(rdb,RDB_OPCODE_RESIZEDB) == -1) goto werr;if (rdbSaveLen(rdb,db_size) == -1) goto werr;if (rdbSaveLen(rdb,expires_size) == -1) goto werr; 下面，遍历迭代器，以存储实际的数据。1234567/* Iterate this DB writing every entry */while((de = dictNext(di)) != NULL) &#123; sds keystr = dictGetKey(de); robj key, *o = dictGetVal(de); long long expire; initStaticStringObject(key,keystr); 函数getExpire是用来获取key的过期时间的，我们需要同时将过期时间也写到RDB里面。而过期时间是单独存放在db-&gt;expires里面的，所以这里需要额外取出来，再存进去。12345678910111213141516 expire = getExpire(db,&amp;key); if (rdbSaveKeyValuePair(rdb,&amp;key,o,expire) == -1) goto werr; /* When this RDB is produced as part of an AOF rewrite, move * accumulated diff from parent to child while rewriting in * order to have a smaller final write. */ if (rdbflags &amp; RDBFLAGS_AOF_PREAMBLE &amp;&amp; rdb-&gt;processed_bytes &gt; processed+AOF_READ_DIFF_INTERVAL_BYTES) &#123; processed = rdb-&gt;processed_bytes; aofReadDiffFromParent(); &#125; &#125; dictReleaseIterator(di); di = NULL; /* So that we don't release it again on error. */&#125; 下面这些代码不太清楚是什么12345678910111213141516/* If we are storing the replication information on disk, persist * the script cache as well: on successful PSYNC after a restart, we need * to be able to process any EVALSHA inside the replication backlog the * master will send us. */if (rsi &amp;&amp; dictSize(server.lua_scripts)) &#123; di = dictGetIterator(server.lua_scripts); while((de = dictNext(di)) != NULL) &#123; robj *body = dictGetVal(de); if (rdbSaveAuxField(rdb,"lua",3,body-&gt;ptr,sdslen(body-&gt;ptr)) == -1) goto werr; &#125; dictReleaseIterator(di); di = NULL; /* So that we don't release it again on error. */&#125;if (rdbSaveModulesAux(rdb, REDISMODULE_AUX_AFTER_RDB) == -1) goto werr; 最后，存入一个EOF和CRC64校验码。123456789101112131415 /* EOF opcode */ if (rdbSaveType(rdb,RDB_OPCODE_EOF) == -1) goto werr; /* CRC64 checksum. It will be zero if checksum computation is disabled, the * loading code skips the check in this case. */ cksum = rdb-&gt;cksum; memrev64ifbe(&amp;cksum); if (rioWrite(rdb,&amp;cksum,8) == 0) goto werr; return C_OK;werr: if (error) *error = errno; if (di) dictReleaseIterator(di); return C_ERR;&#125; flushAllDataAndResetRDB123456789101112131415161718192021void flushAllDataAndResetRDB(int flags) &#123; server.dirty += emptyDb(-1,flags,NULL); if (server.rdb_child_pid != -1) killRDBChild(); if (server.saveparamslen &gt; 0) &#123; /* Normally rdbSave() will reset dirty, but we don't want this here * as otherwise FLUSHALL will not be replicated nor put into the AOF. */ int saved_dirty = server.dirty; rdbSaveInfo rsi, *rsiptr; rsiptr = rdbPopulateSaveInfo(&amp;rsi); rdbSave(server.rdb_filename,rsiptr); server.dirty = saved_dirty; &#125; server.dirty++;#if defined(USE_JEMALLOC) /* jemalloc 5 doesn't release pages back to the OS when there's no traffic. * for large databases, flushdb blocks for long anyway, so a bit more won't * harm and this way the flush and purge will be synchroneus. */ if (!(flags &amp; EMPTYDB_ASYNC)) jemalloc_purge();#endif&#125; AOFAOF机制的调用链（从下到上）如下所示： feedAppendOnlyFile propagate 通常在各个模块中被带有PROPAGATE_AOF|PROPAGATE_REPL参数地调用 在key过期时，propagateExpire会被调用，从而发送过期消息给AOF。 写入feedAppendOnlyFile首先看参数，dictid实际上表示当前redis数据库的id1void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc) &#123; 下面的这些cat...Command方法，实际上都是根据操作去重新组装回命令。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748sds buf = sdsempty();robj *tmpargv[3];/* The DB this command was targeting is not the same as the last command * we appended. To issue a SELECT command is needed. */if (dictid != server.aof_selected_db) &#123; char seldb[64]; snprintf(seldb,sizeof(seldb),"%d",dictid); buf = sdscatprintf(buf,"*2\r\n$6\r\nSELECT\r\n$%lu\r\n%s\r\n", (unsigned long)strlen(seldb),seldb); server.aof_selected_db = dictid;&#125;if (cmd-&gt;proc == expireCommand || cmd-&gt;proc == pexpireCommand || cmd-&gt;proc == expireatCommand) &#123; /* Translate EXPIRE/PEXPIRE/EXPIREAT into PEXPIREAT */ buf = catAppendOnlyExpireAtCommand(buf,cmd,argv[1],argv[2]);&#125; else if (cmd-&gt;proc == setexCommand || cmd-&gt;proc == psetexCommand) &#123; /* Translate SETEX/PSETEX to SET and PEXPIREAT */ ...&#125; else if (cmd-&gt;proc == setCommand &amp;&amp; argc &gt; 3) &#123; int i; robj *exarg = NULL, *pxarg = NULL; for (i = 3; i &lt; argc; i ++) &#123; if (!strcasecmp(argv[i]-&gt;ptr, "ex")) exarg = argv[i+1]; if (!strcasecmp(argv[i]-&gt;ptr, "px")) pxarg = argv[i+1]; &#125; serverAssert(!(exarg &amp;&amp; pxarg)); if (exarg || pxarg) &#123; /* Translate SET [EX seconds][PX milliseconds] to SET and PEXPIREAT */ buf = catAppendOnlyGenericCommand(buf,3,argv); if (exarg) buf = catAppendOnlyExpireAtCommand(buf,server.expireCommand,argv[1], exarg); if (pxarg) buf = catAppendOnlyExpireAtCommand(buf,server.pexpireCommand,argv[1], pxarg); &#125; else &#123; buf = catAppendOnlyGenericCommand(buf,argc,argv); &#125;&#125; else &#123; /* All the other commands don't need translation or need the * same translation already operated in the command vector * for the replication itself. */ buf = catAppendOnlyGenericCommand(buf,argc,argv);&#125; 函数sdscatlen将buf追加到server.aof_buf末尾，类似于concat，但这个取名有点迷惑，让人觉得是category的简写。12345/* Append to the AOF buffer. This will be flushed on disk just before * of re-entering the event loop, so before the client will get a * positive reply about the operation performed. */if (server.aof_state == AOF_ON) server.aof_buf = sdscatlen(server.aof_buf,buf,sdslen(buf)); 如果BGREWRITEAOF正在进行，还需要将命令追加到重写缓存中，记录当前正在重写的AOF文件和数据库当前状态的差异。这个命令用于异步执行一个AOF文件重写操作，重写会创建一个当前AOF文件的体积优化版本。即使BGREWRITEAOF执行失败，也不会有任何数据丢失，因为旧的AOF在BGREWRITEAOF成功之前不会被修改。为什么要支持AOF重写呢？考虑下面的情形：对一个计数器调用了100次INCR，AOF文件需要使用100个条目来记录。但实际上只使用一条SET保存最后的值就行了。所以BGREWRITEAOF可以在不打断服务客户端的情况下，重建AOF文件，这个文件包含重建当前数据集所需的最少命令。 12345 if (server.aof_child_pid != -1) aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf)); sdsfree(buf);&#125; aofRewriteBufferAppend12345678910111213141516171819202122232425262728293031323334353637383940414243444546/* Append data to the AOF rewrite buffer, allocating new blocks if needed. */void aofRewriteBufferAppend(unsigned char *s, unsigned long len) &#123; listNode *ln = listLast(server.aof_rewrite_buf_blocks); aofrwblock *block = ln ? ln-&gt;value : NULL; while(len) &#123; /* If we already got at least an allocated block, try appending * at least some piece into it. */ if (block) &#123; unsigned long thislen = (block-&gt;free &lt; len) ? block-&gt;free : len; if (thislen) &#123; /* The current block is not already full. */ memcpy(block-&gt;buf+block-&gt;used, s, thislen); block-&gt;used += thislen; block-&gt;free -= thislen; s += thislen; len -= thislen; &#125; &#125; if (len) &#123; /* First block to allocate, or need another block. */ int numblocks; block = zmalloc(sizeof(*block)); block-&gt;free = AOF_RW_BUF_BLOCK_SIZE; block-&gt;used = 0; listAddNodeTail(server.aof_rewrite_buf_blocks,block); /* Log every time we cross more 10 or 100 blocks, respectively * as a notice or warning. */ numblocks = listLength(server.aof_rewrite_buf_blocks); if (((numblocks+1) % 10) == 0) &#123; int level = ((numblocks+1) % 100) == 0 ? LL_WARNING : LL_NOTICE; serverLog(level,"Background AOF buffer size: %lu MB", aofRewriteBufferSize()/(1024*1024)); &#125; &#125; &#125; /* Install a file event to send data to the rewrite child if there is * not one already. */ if (aeGetFileEvents(server.el,server.aof_pipe_write_data_to_child) == 0) &#123; aeCreateFileEvent(server.el, server.aof_pipe_write_data_to_child, AE_WRITABLE, aofChildWriteDiffData, NULL); &#125;&#125; catAppendOnlyExpireAtCommand我们抽取一个cat...Command进行分析12345678910111213141516171819sds catAppendOnlyExpireAtCommand(sds buf, struct redisCommand *cmd, robj *key, robj *seconds) &#123; long long when; robj *argv[3]; /* Make sure we can use strtoll */ seconds = getDecodedObject(seconds); when = strtoll(seconds-&gt;ptr,NULL,10); /* Convert argument into milliseconds for EXPIRE, SETEX, EXPIREAT */ if (cmd-&gt;proc == expireCommand || cmd-&gt;proc == setexCommand || cmd-&gt;proc == expireatCommand) &#123; when *= 1000; &#125; /* Convert into absolute time for EXPIRE, PEXPIRE, SETEX, PSETEX */ if (cmd-&gt;proc == expireCommand || cmd-&gt;proc == pexpireCommand || cmd-&gt;proc == setexCommand || cmd-&gt;proc == psetexCommand) &#123; when += mstime(); &#125; Redis中的引用计数规则，让人觉得有点难懂，原因是有的对象是由被调用者而不是调用者释放的，但在这里的代码基本都是由调用者释放（调用decrRefCount）的。123456789 decrRefCount(seconds); argv[0] = createStringObject("PEXPIREAT",9); argv[1] = key; argv[2] = createStringObjectFromLongLong(when); buf = catAppendOnlyGenericCommand(buf, 3, argv); decrRefCount(argv[0]); decrRefCount(argv[2]); return buf;&#125; 刷盘flushAppendOnlyFile服务器先写AOF，再返回给客户端。因为客户端进行写操作的机会是在event loop中，我们需要将所有的AOF写先缓存起来，并且在重新进入event loop前进行刷盘。目前AOF刷盘有几种策略： 每个命令刷盘一次 这也是最安全和最慢的 每秒刷盘一次(everysec) 从不刷盘 当采用everysec方式的时候，如果后台线程有在fsync，那么会延迟这次fsync，这是因为Linux上，write(2)调用也会被后台的fsync阻塞。当这种情况发生时，说明要尽快刷AOF缓存。所以会尝试在serverCron()里面刷。但是如果force是1，那么无论是否fsync，都强行写入。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184#define AOF_WRITE_LOG_ERROR_RATE 30 /* Seconds between errors logging. */void flushAppendOnlyFile(int force) &#123; ssize_t nwritten; int sync_in_progress = 0; mstime_t latency; if (sdslen(server.aof_buf) == 0) &#123; /* Check if we need to do fsync even the aof buffer is empty, * because previously in AOF_FSYNC_EVERYSEC mode, fsync is * called only when aof buffer is not empty, so if users * stop write commands before fsync called in one second, * the data in page cache cannot be flushed in time. */ if (server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp; server.aof_fsync_offset != server.aof_current_size &amp;&amp; server.unixtime &gt; server.aof_last_fsync &amp;&amp; !(sync_in_progress = aofFsyncInProgress())) &#123; goto try_fsync; &#125; else &#123; return; &#125; &#125; if (server.aof_fsync == AOF_FSYNC_EVERYSEC) sync_in_progress = aofFsyncInProgress(); if (server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp; !force) &#123; /* With this append fsync policy we do background fsyncing. * If the fsync is still in progress we can try to delay * the write for a couple of seconds. */ if (sync_in_progress) &#123; if (server.aof_flush_postponed_start == 0) &#123; /* No previous write postponing, remember that we are * postponing the flush and return. */ server.aof_flush_postponed_start = server.unixtime; return; &#125; else if (server.unixtime - server.aof_flush_postponed_start &lt; 2) &#123; /* We were already waiting for fsync to finish, but for less * than two seconds this is still ok. Postpone again. */ return; &#125; /* Otherwise fall trough, and go write since we can't wait * over two seconds. */ server.aof_delayed_fsync++; serverLog(LL_NOTICE,"Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis."); &#125; &#125; /* We want to perform a single write. This should be guaranteed atomic * at least if the filesystem we are writing is a real physical one. * While this will save us against the server being killed I don't think * there is much to do about the whole server stopping for power problems * or alike */ if (server.aof_flush_sleep &amp;&amp; sdslen(server.aof_buf)) &#123; usleep(server.aof_flush_sleep); &#125; latencyStartMonitor(latency); nwritten = aofWrite(server.aof_fd,server.aof_buf,sdslen(server.aof_buf)); latencyEndMonitor(latency); /* We want to capture different events for delayed writes: * when the delay happens with a pending fsync, or with a saving child * active, and when the above two conditions are missing. * We also use an additional event name to save all samples which is * useful for graphing / monitoring purposes. */ if (sync_in_progress) &#123; latencyAddSampleIfNeeded("aof-write-pending-fsync",latency); &#125; else if (hasActiveChildProcess()) &#123; latencyAddSampleIfNeeded("aof-write-active-child",latency); &#125; else &#123; latencyAddSampleIfNeeded("aof-write-alone",latency); &#125; latencyAddSampleIfNeeded("aof-write",latency); /* We performed the write so reset the postponed flush sentinel to zero. */ server.aof_flush_postponed_start = 0; if (nwritten != (ssize_t)sdslen(server.aof_buf)) &#123; static time_t last_write_error_log = 0; int can_log = 0; /* Limit logging rate to 1 line per AOF_WRITE_LOG_ERROR_RATE seconds. */ if ((server.unixtime - last_write_error_log) &gt; AOF_WRITE_LOG_ERROR_RATE) &#123; can_log = 1; last_write_error_log = server.unixtime; &#125; /* Log the AOF write error and record the error code. */ if (nwritten == -1) &#123; if (can_log) &#123; serverLog(LL_WARNING,"Error writing to the AOF file: %s", strerror(errno)); server.aof_last_write_errno = errno; &#125; &#125; else &#123; if (can_log) &#123; serverLog(LL_WARNING,"Short write while writing to " "the AOF file: (nwritten=%lld, " "expected=%lld)", (long long)nwritten, (long long)sdslen(server.aof_buf)); &#125; if (ftruncate(server.aof_fd, server.aof_current_size) == -1) &#123; if (can_log) &#123; serverLog(LL_WARNING, "Could not remove short write " "from the append-only file. Redis may refuse " "to load the AOF the next time it starts. " "ftruncate: %s", strerror(errno)); &#125; &#125; else &#123; /* If the ftruncate() succeeded we can set nwritten to * -1 since there is no longer partial data into the AOF. */ nwritten = -1; &#125; server.aof_last_write_errno = ENOSPC; &#125; /* Handle the AOF write error. */ if (server.aof_fsync == AOF_FSYNC_ALWAYS) &#123; /* We can't recover when the fsync policy is ALWAYS since the * reply for the client is already in the output buffers, and we * have the contract with the user that on acknowledged write data * is synced on disk. */ serverLog(LL_WARNING,"Can't recover from AOF write error when the AOF fsync policy is 'always'. Exiting..."); exit(1); &#125; else &#123; /* Recover from failed write leaving data into the buffer. However * set an error to stop accepting writes as long as the error * condition is not cleared. */ server.aof_last_write_status = C_ERR; /* Trim the sds buffer if there was a partial write, and there * was no way to undo it with ftruncate(2). */ if (nwritten &gt; 0) &#123; server.aof_current_size += nwritten; sdsrange(server.aof_buf,nwritten,-1); &#125; return; /* We'll try again on the next call... */ &#125; &#125; else &#123; /* Successful write(2). If AOF was in error state, restore the * OK state and log the event. */ if (server.aof_last_write_status == C_ERR) &#123; serverLog(LL_WARNING, "AOF write error looks solved, Redis can write again."); server.aof_last_write_status = C_OK; &#125; &#125; server.aof_current_size += nwritten; /* Re-use AOF buffer when it is small enough. The maximum comes from the * arena size of 4k minus some overhead (but is otherwise arbitrary). */ if ((sdslen(server.aof_buf)+sdsavail(server.aof_buf)) &lt; 4000) &#123; sdsclear(server.aof_buf); &#125; else &#123; sdsfree(server.aof_buf); server.aof_buf = sdsempty(); &#125;try_fsync: /* Don't fsync if no-appendfsync-on-rewrite is set to yes and there are * children doing I/O in the background. */ if (server.aof_no_fsync_on_rewrite &amp;&amp; hasActiveChildProcess()) return; /* Perform the fsync if needed. */ if (server.aof_fsync == AOF_FSYNC_ALWAYS) &#123; /* redis_fsync is defined as fdatasync() for Linux in order to avoid * flushing metadata. */ latencyStartMonitor(latency); redis_fsync(server.aof_fd); /* Let's try to get this data on the disk */ latencyEndMonitor(latency); latencyAddSampleIfNeeded("aof-fsync-always",latency); server.aof_fsync_offset = server.aof_current_size; server.aof_last_fsync = server.unixtime; &#125; else if ((server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp; server.unixtime &gt; server.aof_last_fsync)) &#123; if (!sync_in_progress) &#123; aof_background_fsync(server.aof_fd); server.aof_fsync_offset = server.aof_current_size; &#125; server.aof_last_fsync = server.unixtime; &#125;&#125; Reference]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[长沙攻略]]></title>
    <url>%2F2021%2F01%2F12%2Fmeet-in-changsha%2F</url>
    <content type="text"><![CDATA[长沙游记 D029号一早就收到Z的消息，说天鹅湖啥的地方有疫情了。 中午纠结了很久，考虑到下午两点之后退订民宿就要扣钱了，所以我先退了。下午研究了一下，定了一个全季。在携程上定很坑，要么就选择到付，这样的话我担心不一定有房，并且因为我们航班晚，所以还要交保证金。或者就选择立即付款，这样的话过了30号晚上六点钟取消的话就会扣掉所有的钱。想了想，到了明天六点钟肯定知道去不去了，所以先定了全季。晚上发现我ld周末还去了趟成都（那时候成都应该还有中风险吧）也没事，胆子大了起来。临走前，又和ld确认了一下，确实不需要备案，所以就走了。 30号早上一起来就看无锡的疫情，果然和深圳一样，没有变成中风险，但是据说无锡的部分街道已经不让公职人员走了。于是我们等Z下午的会议，看有没有不让走，如果有不让走我们就不走。开完会发现没有不让走，我咨询了一下我ld要不要报备，说如果所在城市没有中风险区就行。这样我们胆子就大了，不仅把全季退掉了，还用高于原来大概100块的价格把那个民宿又定回来了。 因为是周三健康日，所以我六点钟就走了，去上海站搭乘到无锡新区的火车。这班车感觉还是相当友好的，因为新区到机场很方便。 到了新区站发现难受了，这个三号线貌似八到十分钟一班，这也太坑了。到了机场更是坑，出口出来是1号口国际出发，被封闭了。一直往前走了半天，才到唯一的入口6号口。中途还有两个小姐姐貌似要赶九点十分的飞机，急得要死。不过进了机场发现机场好小，我们把三明治和饭团都吃掉了，酸牛奶喝掉了好几个。无锡机场安检贼严，我们的酸奶都不让带进去。 登机的时候去长沙的队伍真的是浩浩汤汤，一点不逊于旁边的深圳队伍，果然是网红城市。 D1后来想想，31号的人相比后面并不是很多了。我们从民宿出来一直往西走就能到黄兴广场了，中间还能路过化龙池文和友。后来到博物馆我才知道化龙池是个地名，我当时以为是把龙虾消化掉的意思。到了黄兴广场步行街，中间是一个辣条博物馆，当时没咋要排队，但我们急着喝茶颜悦色就没去。晚上的时候已经排了老长的队了，站在门口看了下，原来是辣条王子的营销店。 往左拐，往前走了一点，看到第一家茶颜悦色居然还没开门（后来发现我们家门口的那家盟重旁边的茶颜要到下午三点钟才开），再往前走一点，是一家开了门的，居然已经排起队了，这还没到11点呢。茶颜右边是一家罗记臭豆腐，旁边是一家黑色经典臭豆腐。黑色经典很大，是一家零售的点，不过角落里也挖了一块卖现炸的臭豆腐和大香肠的。茶颜悦色里面的广告一直在推荐旁边的黑色经典臭豆腐，但是那家店外面排队的人却稀稀拉拉。 茶颜悦色的点餐规则比较奇怪，首先你先要排队点单，点完之后会给你一个叫号器和小票，然后你可以四处闲逛等到叫号器叫号。叫号器叫到你之后，实际上你的奶茶才开始做，所以这样就保证了最新鲜的口感。我们前面的人都是疯子一样五六杯地点，所以我们要等好久。过了会，我觉得无聊，就去排旁边的黑色经典臭豆腐了。 吃完了黑色经典，我们端着奶茶继续打卡。步行街上人很杂，有个人给了个充电宝，要我去做网店测评，我以为写一个手机号就行了，但是又要做调查，我就先走了。 走到步行街的终点往右拐，开始走到小巷子里面，这边有我们要打卡的第一家店，金记糖油粑粑。到的时候这家店队已经很长了，但是因为他是直接和糖葫芦一样串起来卖，所以实际还是挺快的。吃起来也不是特别惊艳，很油，比较甜，感觉像有点酥的麻球。 接着，我们就再往前走，去杨爹甜酒。不得不说，长沙的小巷子里面还真的蛮好看的。在杨爹甜酒点了大众点评的前三。这家店似乎也是上过天天向上的（感觉天天向上真的喜欢捧长沙小吃）。招牌甜酒点了小份的，感觉就和酒酿差不多的味道。比较好吃的是酒酿梅子冻，虽然很冷，但梅子的酸味和酒的略微的刺激使得口感非常清爽。相比之下甜酒汤圆冲蛋就比较一般了，它是热的，感觉就是把蛋放到甜酒汤圆里面，和我们家里一个味道。 吃完了，感觉时候不早了，于是打算启程去长沙博物馆。幽兰拿铁喝完还有好多奶油，讲道理还是蛮好吃的，我刮了点吃掉，才扔到路边垃圾桶里面。然后就进地铁站，一样望下去，还是三四家茶颜，还有一家茶颜的外卖镖局，说是只卖外卖。Z觉得茶颜的外卖并不好（店里面的职员也是这么说的），因为奶油要新鲜啥的吧。当然，后来我们点了他家的外卖，其实还好，奶油是分开装的，非常豪华。 长沙地铁是要专门下一个APP的，然后还要交10块钱的保证金。一号线要等6分钟，差评。我们做到了北辰三角洲，居然还有折扣，这可是在深圳和上海都没有的待遇啊。 北辰三角洲出站，发现一家奈雪，好惨不提了，在走几步是一家茶颜，似乎外面没人排队，正准备感叹，远离五一广场就不要排队了，定睛一看，发现里面好多人。这边感觉是比较新的地方，建了很多长沙开头的公共设施，感觉是富人区一样，查了一下北辰奥园房价一万七，好便宜。 我们在下面走了好久，还是停车场，最后我觉得一定要上去。所以我在一个写着“食堂正常开放”的墙的台阶那边坚持爬上去，豁然开朗，眼前是一个大的广场，串联起了音乐厅、博物馆等建筑。 长沙博物馆进去实际上不要预约，查健康码就行，不过Z信号很不好，还是我帮她查的。然后就换衣服上厕所，期间我看了一下长沙博物馆的留言簿，各种逗比。查了一下，据说他们家的食堂不错（神奇），不过问博物馆说只有个咖啡厅。 长沙博物馆一共两层，我们照例走错了，从第二层开始看的。 长沙博物馆接近两个小时就逛完了，里面基本没啥人，然后Z就说应该今天去湖南博物馆的，因为明天人肯定很多。然后我就说要不我们今天先去看一部分湖南博物馆吧，结果打开一看，约满了。看了看外面的太阳，还不错，干脆去橘子洲逛逛吧。 我们骑车回到北辰三角洲，准备去之前看到的那家店买，刚进店就被告知有人点了30杯，要等一个多小时…… 于是我们直接坐地铁去了橘子洲。 考虑到时间也不早了，并且看了一下，海关站上车环岛线基本上没啥位置，所以我们坐地铁回去了。 从橘子洲回来，我们直接下了五一广场，进了新世界百货。又去排茶颜悦色了，它在下面一层，我看到有一个滑梯可以滑下去。茶颜悦色照例也是要排队的，说是50分钟，实际上最后排了半个小时。我在旁边又买了个聚美合的臭豆腐和香肠。他家的香肠还可以，但是臭豆腐太辣了。这次我们点了凤栖绿桂和抹茶菩提，都蛮好喝的。五一广场往南走就是黄兴路步行街，路的西侧有一个巨大的兰蔻的广告。这个时候路上人已经很多了，但是比后面两天人山人海比肩接踵的场景还是要好很多的。 我们的第一个目的地是邵师傅梅菜扣肉饼，这个一定要是吃黄兴路步行街的那一家，太平古街的那个感觉手艺不行，炸得焦了不少。此外还要注意，不是邵福记。口感是真的香，边边还是甜的，非常好吃，爆赞。 接着，我们去排武爹臭豆腐（虽然其实前面就两个人）。这老板感觉很闲鱼，一边炸豆腐一边刷手机。武爹臭豆腐非常非常脆，相比之下，黑色经典以多汁取胜。综合看来，黑色经典大于武爹大于聚美合，难怪只有黑色经典被大众点评推荐。 七点多在微信上面随便取了一个盟重的号，排接近300号，想着肯定是吃不到了吧。 晚上在鸽优群里闲聊，才发现大师明天也来长沙，这必定是要聚一波的了。 D2今天早上（划掉，中午）的任务是去逛湖南博物馆，看千年干尸。湖南博物馆需要提前三天预约，我们29号的时候没有落下，但其实如果没约上的话可以去买特展票，最后湖南博物馆的两个特展都蛮有趣的，我们也都买票进去看了。 来了长沙就一定要嗦粉，搜一搜长沙推荐的粉店，有刘聋子、公交新村和周记粉店。其中周记粉店就在家门口，盟重的那条巷子里面，我们居然之前没有发现，看起来我们住的民宿真的是宝藏，我真的是天才。我们去的时候周记粉店正好迎来一波小高潮，队伍一直排到门外。他家点单是在门口，也就是说，你顺着队伍迈进门口之后就能点单了，点完会给你个单子，然后你拿着它继续排队，一直排到店最里面的厨房门口取餐，去完餐就可以坐在店里吃了。一般等排到还有四五个人的时候，就可以去占一个座位了。周记粉店的粉很好吃，但是最好吃的还是他家的肉饼蛋，感觉加了茴香或者啥香料，非常好吃。 为了节约肚子，我们指点了一碗粉，所以吃完周记我们还有肚子，于是就继续吃旁边的德天顺盖码饭。所谓盖码饭感觉就是盖浇饭，但是德天顺自称是盖码饭里面的爱马仕。这话倒也说得没错，进门的时候就感觉这家店是富丽堂皇，感觉有点全聚德的感觉，旁边还给你树两对联。进去上二楼才是店面，非常宽敞明亮。我们照例指点了一碗孜然牛肉，三十几块，还是蛮贵的。端上来发现料还可以，但多的是蒜苗，肉其实也不多。口感上不是很辣，其实还是非常下饭的，适合我们干饭人，如果你没有不小心吃到尖头椒的话。 吃完饭，得赶快去湖南博物馆了，那里没地铁，我们打了辆车，不过他刚在橘子洲大桥那边送客人，所以还要十来分钟才来，于是我们顺路又逛了逛附近的巷子，发现走着走着就到了盟重烧烤，颇有点之前在曾厝垵的感觉。车来了，我们在一个十字路口等了快三个红灯，终于到了湖南博物馆了。 湖南博物馆的寄存还是比较坑的，如果把衣服寄存到寄存柜的话，就还需要再额外走一段没有空调的地方。并且出门的时候你不能直接从大厅出门，而应该在大厅里面下楼。 从刘聋子出来，Z说有一个叫果呀呀的奶茶也蛮火的，但是自己一直没看到，于是我搜了下，IFS下面就有一个啊。于是我们往黄兴步行街方向走，准备去找果呀呀。在那个能看到我爱CS的路口，Z终于买了自己想要吃的荸荠（我觉得都是别人用手剥的，真的很脏，一个都没有吃）。 人是真的多。 这个果呀呀真难找，我们走到了那个宇宙中心交叉口才发现走过了，果呀呀似乎在商场里面，于是又走回去进商场（又是一堆人堵在门口找行程码）。进入商场找了一圈没找到，我脚很酸，就坐在优衣库里面等，过了一会，Z找到了并点好了，回来接我过去。又要穿过一道查健康码的门，真的是神奇。我们在果呀呀旁边的一家Switch体验店呆了会，不得不说，自从腾讯代理Switch以来，这些Switch体验店是雨后春笋一样啊。 Z想吃紫苏桃子姜，搜了一下，发现伍厚德堂是Top的，并且我们发现伍厚德堂是一家饭店而不是小吃店，还有其他一些不错的吃的，也打算尝试一下。伍厚德堂有两家，九龙仓的那一家网上说一般，所以我们去的是坡子街的那一家。穿过那个宇宙中心十字路口，我们发现自己又看到了梅干菜扣肉饼，果断又去排了下。这时候的队和前几天已经不一样了，前面大概有十几号人。因为人比较多，所以Z一直不让我喝果呀呀，但是我是忍不住了，就开下来喝了，确实非常好喝。看到队比较长，我就先去伍厚德堂拿号。到了伍厚德堂才发现，他家火爆到暂停线下取号了。 只好回来，此时饼也买好了。我们之前买的是他推荐的12块钱的瘦肉饼，这次还买了个10块钱的扣肉饼。扣肉饼感觉会肥一些，但是一点不腻，非常好吃。因为我脚头很累，我们就开始往回走，路上看到了么子烤肉，在化龙池旁边，所以进去取了个号，我们应该是七点十分取的，要排305桌，幸亏离得比较近，我们打算先回家。到家门口的茶颜悦色又排了两杯奶茶，把取号器拿到住的宾馆里面。因为我脚很累了，所以是Z在排，我在研究么子烤肉能不能线上看进度，但扫那个二维码看不到，并且他家的线上取号也停了。我们歇了大概二十分钟就又出发去取茶颜了，然后又去么子烤肉看了下情况。店员解释说原来我没有关注那个公众号，所以它没办法给我推送，然后他说我们还好等大约两个多小时，建议我们还剩五十桌的时候过来登记健康码啥的。考虑到么子烤肉的号过得并不是很快，我们又回家瘫着歇了会。到了十点的样子，我们看还有大概90桌的样子，就又出来了，到店里发现还有七八十桌，玩了会iPad，我想要不我再去看看黑色经典吧。跑到那边发现队伍还是贼长（你们不睡觉的么），于是又回来，路上买了个荸荠。又歇了会，发现队伍还是动得非常快了，终于在十点四十的时候我们吃上了。 不过么子烤肉确实很好吃，特别是他家的蜂蜜芥末酱很棒。可惜Z去调酱料的时候已经没有了，问服务员去加货，服务员说断货了（我估计是太晚了，不想再拆一包出来）。我跑去看了看，确实罐罐都空了，只好先刮一点出来。后来想到，不妨到楼下试试运气，发现楼下的罐罐里面还有很多，我就舀了好几勺。我们照着大众点评点的，感觉都很赞。大片牛油会附上海椒干碟，沾着不算很辣，但却很有风味。五花肉是腌制好的，非常好吃，有点之前在厦门吃的高烤的感觉。超嫩黑椒牛肉粒和虾滑的量很足。桂花年糕是最后吃得，小哥会帮你浇上自带的桂花糖浆，很好吃。 D3正好大师他们住的宾馆距离伍厚德堂比较近，正好他们也没做攻略，于是他们就先去排。他们大概十点四十五到的，那边他们说只要等四个，并且11点才开门，于是我们赶快收拾收拾出发。不得不说，伍厚德堂的装修还是非常好看的，是类似民国的那种装潢，又有点欧式的风情，外面有个小喷泉台，里面还有小天井。我们进到二楼，大师已经在那边了，LP听了我的建议去买了邵师傅梅干菜扣肉饼。于是我们照着大众点评撸下去点了一些菜，然后服务员说季节原因，紫苏桃子姜不卖了。 不得不说，长沙的这些饭店是非常良心的。首先我们四个人总共才吃了200+，并且已经很饱了（可能是因为我们茶颜悦色喝多了）。其次，我们吃到一半发现桌上有个牌子说大众点评收藏送东西，有点类似于我们点的两个桃胶牛奶。于是就在上菜的时候问服务员，是不是桃胶牛奶，服务员说是的，然后我们就有点沮丧。然后结账的时候服务员真的就帮我们免掉了两个桃胶牛奶的钱，所以感觉他们还是很棒的。 吃完了我们就出发去橘子洲，一路上我们谈昨天的行程。原来大师他们昨天已经来过一趟橘子洲了，但是可能来的时候比较晚，所以沿途就有卖游览车票的人说这是最后一趟车去MZD雕塑了，于是就把他们忽悠上车了。然后到了雕塑就把他们丢下来，最后他们自己走回来了。当时天已经黑了，所以他们中途在沁园春长沙的石碑旁边拍了张很阴间的照片。 D4今天是回程的日子，早上醒来，问了问大师他们的计划，原来是刚起，也没打算去省博了。问中午要不要约饭，推荐了一家剁椒鱼头。我感觉剁椒鱼头很辣，并且也有点远，我们退房行李不好拿，所以就没有想去。我说打算去吃夏记粉店，他们也OK。到了夏记粉店，又是队伍排成长龙，比周记粉店还多。我和Z排了会，Z感觉还有很久，就先跑到几百米开外去点茶颜了。]]></content>
      <tags>
        <tag>游记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash介绍]]></title>
    <url>%2F2021%2F01%2F06%2Fbash%2F</url>
    <content type="text"><![CDATA[介绍Bash 字符串操作1s=abcdefghijk 长度12# echo $&#123;#s&#125;11 slice1234567# echo $&#123;s:1:3&#125;bcd# echo $&#123;s:1:-1&#125;bcdefghij# echo $&#123;s:-1:-1&#125;abcdefghijk# t=aaabbbccc 从头部的最长匹配，删除matching部分12# echo $&#123;t##a*b&#125;ccc 从头部最短匹配12# echo $&#123;t#a*b&#125;bbccc 失配12# echo $&#123;t#m*m&#125;aaabbbccc 尾部匹配改成% 变量 $? 上一个指令退出码 $$ 进程ID，等于BASHPID $_ 上一个命令的最后一个参数 $! 最近一个后台执行的异步命令（也就是后面加&amp;的）的进程 ID $0 shell的名称，或者运行的shell脚本的名称，大于等于10的用${10}等 $# 参数个数 $@ 空格分割的全部参数 可以循环 $@ 123for i in "$@"; do echo $idone $* $IFS分割的全部参数，貌似要echo &quot;$*&quot;才行。IFS是Internal Field Separator 注意#@和$*的行为在加引号之后不一样，&quot;$*&quot;会作为一个整体 注意区分makefile的参数$@扩展成当前规则的目的文件名，$&lt;扩展成依赖列表中的第一个依赖文件，而`$^扩展成整个依靠的列表（除掉了里面所有重复的文件名）。 下面是一个供展示的bash脚本1234567891011121314151617181920212223242526272829303132echo $0echo $1echo $-echo "SHARP"echo $#echo "AT"echo "$@"echo $@export IFS=Mecho "STAR"echo "$*"echo $*echo "For AT \""for i in "$@"; do echo $idoneecho "For AT"for i in $@; do echo $idoneecho "For STAR \""for i in "$*"; do echo $idoneecho "For STAR"for i in $*; do echo $idone 命令source在当前sh执行脚本，而sh会创建一个新的 控制if后面可以跟任意数量的命令。这时，所有命令都会执行，但是判断真伪只看最后一个命令，即使前面所有命令都失败，只要最后一个命令返回0，就会执行then的部分。12345$ if false; true; then echo 'hello world'; fihello world$ if true; then echo 'hello world'; fihello world if结构的判断条件，一般使用test命令，有三种形式。第三种形式还支持正则判断，前两种不支持。expression 为真，test命令执行成功（返回值为0）；expression为伪，test命令执行失败（返回值为1）。12345# type -a [[[[ is a shell keyword# type -a [ [ is a shell builtin[ is /usr/bin/[ 写法一 1test expression 写法二 注意，因为中括号实际上是一个命令，所以左右都要有空格 1[ expression ] 写法三 1[[ expression ]] 这种写法还支持正则表达式正则表达式[[ expr =~ regex ]] 123456789101112131415MIN_VAL=1MAX_VAL=100INT=50if [[ "$INT" =~ ^-?[0-9]+$ ]]; then if [[ $INT -ge $MIN_VAL &amp;&amp; $INT -le $MAX_VAL ]]; then echo "$INT is within $MIN_VAL to $MAX_VAL." else echo "$INT is out of range." fielse echo "INT is not an integer." &gt;&amp;2 exit 1fi 还可以使用bash自己的&amp;&amp;，这个遵循短路原则123if [ condition ] &amp;&amp; [ condition ]; then commandfi 等同样例1[[ -d "$dir_name" ]] &amp;&amp; cd "$dir_name" &amp;&amp; rm * 等同于123456789101112if [[ ! -d "$dir_name" ]]; then echo "No such directory: '$dir_name'" &gt;&amp;2 exit 1fiif ! cd "$dir_name"; then echo "Cannot cd to '$dir_name'" &gt;&amp;2 exit 1fiif ! rm *; then echo "File deletion failed. Check results" &gt;&amp;2 exit 1fi 函数函数优于脚本，低于别名123hello() &#123; echo "Hello $1"&#125; 函数与变量相关的$@、$0等，与脚本一致。]]></content>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Paxos算法]]></title>
    <url>%2F2021%2F01%2F06%2Fpaxos%2F</url>
    <content type="text"><![CDATA[本文介绍Paxos算法，包含Basic Paxos，以及Raft作者提出的一个Multi Paxos的工程化实现方案。此外，我们还就Raft作者给出的Paxos习题进行探讨。 Basic PaxosPaxos允许消息被任意延迟、丢包、重复，但不允许消息被损坏。Basic Paxos弱化了Leader的概念，而使用了Proposer的概念。Basic Paxos只对一个Value决议。这个Value实际上类似于Raft里面的一个Log Entry，即x=1或者y=42之类的。根据原版论文The part-time parliament，这里的Value即法令，类似于禁止画画或者允许自由艺术等。注意，一个Value被决定是chosen而不是accepted，即决议的过程是1propose(issue) -&gt; Accept -&gt; chosen 论证1在论证1的部分，我们从原始要求倒推出我们需要维护的不变量P2b P1我们考虑没有丢包和机器故障，并且我们假设只有一个proposer。对于这样的一个平凡情况，我们可以得到下面的要求：一个acceptor必须接受它收到的第一个proposal。 显然这个方案存在一个问题，不同的proposer可能提出不同的value，这会导致每个acceptor收到了不同的value，但其中没有一个value是占majority的。这个问题导致我们需要让acceptor去accept多于一个proposal。为了区分这些proposal，就要引入proposal number。一个Value被chosen，当具有这个Value的proposal已经被大部分的acceptor accept了。 P2经过上面的论证，我们允许choose多个proposal，但我们必须保证所有被chosen的proposal都有相同的Value，因此我们提出下面的要求：如果具有Value v的proposal被chosen了，那么对于任意更高的number的proposal，如果它被chosen，那么它就一定有Value v。 P2a我们就P2进一步推导，因为被chosen的前提是这个proposal要至少被一个acceptor Accept，所以我们可以通过满足下面这个更强的条件来满足P2：如果具有Value v的proposal被chosen了，那么对于任意更高的number的proposal，如果它被任意的accpetor Accept，那么它就一定有Value v。 P2b注意，我们仍然需要满足要求P1，这样我们可以保证我们一定能接受一些proposal。考虑下面的情况： 一个新的proposer提交了一个更高的number的proposal，但是具有不同的Value； 一个之前从来没有收到过任何proposal的acceptor收到了这个proposal； 根据要求P1，这个acceptor需要accept这个proposal； 根据要求P2a，这个acceptor不能accept这个proposal； 我们发现这里产生了矛盾，因此我们还需要继续强化要求P2a：如果具有Value v的proposal被chosen了，那么对于任意更高的number的proposal，在它被任意proposer发出时，就一定有Value v。 论证2论证2紧接着论证1，讲述如何维护P2b性质。 P2c为了方便表示，规定proposal(m,v)表示具有number n和Value v的proposal。下面我们查看P2b是如何保证自己一直成立的。 我们考虑proposal(m,v)被chosen，那么我们要证明任何number大于m的n的proposal也有Value v。证明如下：如果m被chosen，那么一定有大多数acceptor accept了这个proposal，这些acceptor属于集合C。再结合P2b，可以推出C中所有的acceptor都accept了从m到n-1的proposal，并且这些被accept的proposal都具有Value v。 对于任意包含大多数acceptor的集合S必须包含C中的至少一个成员，因此我们可以得出我们需要满足下面的要求P2c。 考虑一个proposer发出了proposal(v,n)，那么存在一个上述S，满足要求P2c： 要么S中的成员都没有accept过低于n的proposal； 要么accept的最大的小于n的proposal的Value是v。 论证3为了维护P2c，我们发现一个proposer在发出n这个proposal之前，需要检查最大的小于n的proposal，看它是否已经或者将要被某些acceptor Accept。前者是容易的，但是后者要做一个预测，并不是那么容易。 为了简化这个预测的流程，我们引入了一个提前的阶段，也就是proposer要求acceptor保证不会再去accept任何低于n的proposal了。 为此，我们得到下面的算法。 Proposer 算法 Step1proposer选择一个新的number n，发送请求Prepare(n)给某个集合中的所有acceptor。此时acceptor应该返回： 保证不再接受小于n的proposal； 目前最大的小于n的accept的proposal。 Proposer 算法 Step2如果这个proposer收到了majority的acceptor的回复，那么就可以发送一个Accept(n,v)的请求。其中n是Prepare时候的n，v的选择则遵循下面的规则： 如果没有人对v的值有proposal，那么这个proposer就可以任选v的值。这实际上对应了通常情况。 否则，就返回最大的小于n的proposal给出的v值。 文章特别强调，Prepare请求和accept请求可以发送给不同的acceptor。 Acceptor 算法 P1a一个acceptor可以安全地忽略任何的请求。 acceptor可以回应Prepare请求。 acceptor可以回应accept请求，去accept某个proposal，当且仅当它没有保证不接受这个请求，即：当且仅当一个acceptor没有回应大于n的Prepare请求，它可以接受一个n编号的accept请求。可以看出，P1是P1a的特例。 也就是说，如果回应了n+1的Prepare请求，那么： 可以accept编号是n+1的accept请求； 不能accept编号是n的accept请求； 能不能promise编号是n的Prepare请求？ 文章中指出，没有理由去回应这样的请求。因为根据上一点，连编号为n的accept请求都不会被响应了，更何况Prepare请求呢？ 同理，如果一个请求已经被accept了，那么我们也不会再去回应对应的Prepare请求了。 当然，这些只是优化点而已。 持久化要求为了维护P2c这个不变量，一个acceptor需要持久化： 自己accept的最大的proposal number； 自己回复的最大的Prepare请求的number。 此外，一个proposer可以忘记或者放弃自己的proposal，只要它不会具有相同number的另一个请求。 算法Phase 1 Proposer 选择n，发送Prepare(n)到majority个acceptor上。 Acceptor 对于Prepare(n)，如果n高于已经响应过的其他Prepare请求，则： promise不会在accept任何小于n的请求； 发送最大的小于n的accept的proposal。 Phase 2 Proposer 如果收到了majority的acceptor对自己Prepare(n)的响应，则发送Accept(n,v)请求给所有这些acceptor。这里的v的选择参见Proposer 算法 Step2一节。 Acceptor 除非自己已经回复了Prepare(n+1)或者更高的，否则acceptor需要accept请求Accept(n,v)。 Learner容易发现，因为没有Leader，所以从单一的acceptor角度，并不能很方便地去发现某个proposal是否已经被chosen了。一个平凡的方法就是每进行一次accept，就告知learner一次，不过这样的方法有很大的通信开销。考虑到learner也不会出现拜占庭错误，所以learner间可以相互通信以得到被accept的值，因此可以让每个acceptor只响应某一些learner。如果考虑到这一些learner可能失败，导致丢失acceptor信息，问题还会更复杂。此时，一个值被chosen了，但是没有learner发现。虽然learner可以再逐个询问acceptor，但只要有一个acceptor宕掉，就可能导致learner无法了解某个proposal是否得到多数同意。在这种情况下，只有当一个新的proposal被chosen的时候，learner才会再次发现。 对此，可以提出一个问题，对于n&gt;m，如果n被chosen，那么m是不是一定被chosen呢？ 活锁问题上述的Basic Paxos算法存在活锁问题。考虑 p发送Prepare(n1)； q发送Prepare(n2)，其中n2&gt;n1； 此时p不能成功地Accept(n1)了，因为acceptor保证了不会accept低于n2的请求； 于是p继续发送一个Prepare(n3)，其中n3&gt;n2； 由此开始循环往复。 因此，我们必须选出一个proposer，这个proposer起到Leader的作用，只有它可以发送proposal。在论文后面提到，这个Leader实际上还起到首要的Learner的作用。 实现acceptor的回复需要带上对应的proposal number。acceptor先持久化自己的回复，再发送给对方。下面讨论如何保证没有两个proposal的number是相同的。方法很简单，不同的proposer从不同的不相交集中取这些序号即可。每个proposer持久化自己所选取的最大的proposal number。 实现状态机使用多个服务器组成集群，每个服务器构成一个单独的状态机。因为状态机都是确定的，所以每个服务器对应的状态机的状态和输出始终是一致的。为了保证每个状态机都能执行相同的状态机命令，实现了 Basic Paxos(Ongaro)在Ongaro等的视频里面，进一步理清了Basic Paxos的相关概念。首先是Basic Paxos Instance、Server、Proposer和Acceptor的关系。一个Instance指的是Basic Paxos决定一个Value的过程。因此Basic Paxos被称为是Single decree的，因为它只决定一个值。一般一个Server同时是一个Proposer和Acceptor，Acceptor是完全被动地，处理来自Proposer的请求。一个Acceptor可能Accept不同的Value，也就是可能变票。接着，Ongaro提出一种实现Proposal Number的方案，也就是高位的Round Number和低位的Server ID。这些Round Number需要被持久化到磁盘上，以保证proposal number不会被重复使用。 下面的图表示了Basic Paxos的消息通信过程 需要注意的是，只有提出某个proposal的proposer才能知道是否已经被chosen；对于其他的proposer，必须用自己的proposal执行一遍basic paxos才行。 三种Prepare顺序讨论下面讨论Paxos中三种常见的Prepare顺序，和对应的结果。框框中的P 3.1表示收到来自Server1的Round Number为3的proposal，A 3.1 X表示收到（而不是接受）这个proposal，它的值为X。有两个proposer试图propose，分别是S1要propose值X，且S5要propose值Y。 1. 当值X已经被chosen如下图所示，当P 4.5到来时，值X已经被chosen了。 2. 当值X没有被chosen，但新的proposer能够看到我们注意S3上的A 3.1 X请求已经被Accept了，所以当S5发出P 4.5后，它会知道值已经被Accept为X了，所以它不再坚持自己要Accept的值Y，而是转而Accept值X。 3. 当值X没有被chosen，新的proposer也看不到注意此时S3上的A 3.1 X请求实际上不会被Accept，因为Prepare 4.5已经捷足先登了。 Multi Paxos(Ongaro)主要讲了几件事情： 如何维护一个Log（一系列Entry）而不是某一个Entry。 性能优化，包括两方面，但主要是借助于Leader： 去掉proposer之间存在的活锁 如果在任何一个时刻，保证只有一个proposer发请求的话，那么就不会存在活锁。 去掉冗余的Prepare请求 即对每个log而不是每个entry进行一次Prepare，这样话大部分entry可以在一轮RPC中被chosen，即执行一轮accept。 如何实现所谓的Fully Replication，即让大家都知道某个Entry已经被chosen了。 客户端协议以及状态机相关。 维护一个Log首先我们考察，当一个proposer准备新增一个entry到log时，如下图所示，当client发送一个jmp给S1时，S1选择哪一个entry呢？这可能涉及一下的情况： 在Entry1和2中，mov和add被复制到了所有机器上，并且S1已经知道被chosen了。如下图所示，用粗框子框出来了。 在Entry3中，cmp实际上已经被chosen了，但是S1并不知道。这个可能是因为S3被分区了。 下面我们就考虑S3被分区的情况： 找到第一个没有被S1知道已经chosen的entry，即firstUnchosenIndex。也就是Entry3。 根据Basic Paxos算法，对这个entry去propose一个Value为jmp的proposal。显然，这个Value是不能被accept的，因为已经有一个Acceptor接受了cmp这个值了。所以这一个Basic Paxos Instance跑完，实际上会导致cmp在Entry3中被chosen。 接着，我们回到第1步，检查下一个尚未被发现已经chosen的entry，即Entry4，并尝试propose。显然，这次jmp还是不能被accept，因为sub已经被S2上的acceptor接受了。 通过这种方式，Server可以并发处理多条来自client的请求。演讲者提到，例如第一个请求用到了Entry3，那么下一个请求可能会尝试Entry4或者Entry5等等。在这一点上我还有点疑惑，就是我们能保证client的请求在Paxos log层面是in order的么？ 但是最后这些命令需要按照log中的顺序来放到复制自动机中执行。 Leader选举需要注意的是，Paxos在有多个Leader的时候依旧能够正常运作，只是效率会受到影响；但是Raft等就必须要求有唯一的Leader。Lamport提出一种简单的办法，就是令具有最大的Server ID的proposer为Leader。接着所有的Server互相向其他Server以间隔T发送心跳包，心跳包中包含自己的Server ID。如果一个Server在2T的时间内没有收到一个具有更高的Server ID的心跳包，那么它就以Leader的方式行动，即开始处理来自client的请求，且同时执行proposer和acceptor的角色。相对应地，如果一个Server不是Leader，那么它不处理client的请求，并且只执行acceptor的角色。 演讲者后来指出，一般来说，并不会用这种方案。 减少Prepare下面讨论如何减少Prepare请求。首先，为什么要有Prepare请求呢？ 阻止具有旧的number的proposal 发现可能存在的已经被chosen的Entry 下面我们对这两点目的进行改进： 阻止具有旧的number的proposal 我们可以让proposal number和整个log关联，而不是和某个entry关联。 发现可能存在的已经被chosen的Entry acceptor不仅要返回对于当前entry的最大的proposal number，还需要检查所有当前entry之后的所有entry，如果其中没有任何proposal被accept，那么就返回noMoreAccepted。 如果一个acceptor返回了noMoreAccepted，那么后续就不再发送Prepare请求，直到某个Accept请求被拒绝。如果一个Leader从多数的acceptor处都收到了noMoreAccepted，它就不再需要发送Prepare请求了。这个状态可能会被另一个当选的Leader打破，此时旧Leader会收到被拒绝的Accept请求。 Fully Replication因为最终所有的Log Entry都需要过RSM，所以我们需要保证最终每个Server上的Log都是全的，并且他们知道哪些已经被chosen了。这通常包括两个目标： 保证Entry最终在所有的机器上被复制，但目前我们只保证了majority。 保证所有的Server都能知道某个Entry是否被chosen，目前只有对应的proposer知道。 下面是解决方案，一共有四个措施，但其实大部分措施都是为了处理就Leader宕机的情况。 Proposer需要不断地重复Accept请求（可以在后台完成），直到所有的acceptor都回复 但这个策略是不充分的，原因是考虑当Proposer宕掉时，他未必能够将所有的Entry都进行复制。 跟踪所有被chosen的Entry 每个Server对所有已经被chosen的Entry设置acceptedProposal[i]=INF，INF也是能够无缝适配协议的，因为不可能存在一个更大的proposal number了。 每个Server维护一个firstUnchosenIndex（已经在前面介绍过了）。 Proposer将自己的firstUnchosenIndex附加在Accept请求中发送 这样，一个Accept请求会类似下面 1request = Accept(proposal=3.4, index=8, value=v, firstUnchosenIndex=7) 而acceptor会对每个Entry[i]进行如下的检查，如果下面两个条件被满足，那么就将Entry[i]标记为chosen。 i &lt; request.firstUnchosenIndex acceptedProposal[i] == request.proposal 为了解释这种情况，我们查看下面的这个例子。下图中，每个格子里面的数字指的是proposal number。容易看到，在这个acceptor处理Accept请求前，这台Server上的Entry 1/2/3/5已经被chosen了。现在，来自Leader Proposer的一个Accept请求告知firstUnchosenIndex=7，这也就意味着在这个Proposer上，Entry 1到6都被chosen了。此时，我们就可以将Entry 6标记为chosen。然后我们有几个疑问： Entry 6为什么可以被标记为chosen？ 这是因为首先这个acceptor知道Entry 6也是来自于发送这个Accept的Proposer，并且它在这个Proposer上已经被chosen了。 但这还不够，有没有可能这个Proposer后面发送了关于Entry 6的具有另外一个值的Accept请求呢？我想这样的话，proposal number一定会变得更大。但既然在3.4的时候，我们就知道Entry 6已经被chosen了，那么被chosen的这个值一定就是acceptor日志里面的这个值。 Entry 4为什么不能被标记为chosen？ 因为Entry 4的值来自于另外Round的另外一个Proposer，因此我们没办法像Entry 6一样确定这个不是一个陈旧的数据。也就是说，这个accpetor知道Entry 4被chosen了，但是并不知道这个被chosen的Value是不是自己Log里面的那个Value。因为很可能这个值又被改了。 Entry 7是怎么回事？ Success RPC acceptor会在对Accept消息的返回中附带上自己的firstUnchosenIndex，当Proposer收到该acceptor返回后会将该值和自己的firstUnchosenIndex进行比较。如果acceptor的firstUnchosenIndex小于自己的，说明这个acceptor落后了，此时需要在后台发送Success RPC。 这个RPC需要包含index以告知是那个Entry被chosen了，并且附带上一个v表示被chosen的值。当Acceptor收到这个消息后，将： acceptedValue[index]=v acceptedProposal[index]=INF 返回新的firstUnchosenIndex给Proposer，Proposer会根据这个值判断是否需要再次发送Success RPC Leader缺少日志问题Client协议这一部分和Raft一样，非Leader的Server会把请求转发给Leader。同样的，Leader也会在Client提交的命令被chosen以及被RSM执行之后，才会返回。如果请求超时，例如Leader宕机了，那么Client会将命令发送给其他Server，在最终发现新Leader后，重试命令。 如何保证Exact once语义这个问题通常发生在当老Leader在执行完自己的状态机后、返回给Client前宕机。根据上面的论述，Client实际上会通过另一个Leader重试，在这种情况下，可能同样的命令就会被执行两次。 其实这种情况在我实现Raft协议的时候也遇到过。对此，演讲者建议Client对每个命令设置一个唯一的ID。每个Server上的RSM都会自己记录一下自己执行过的最新的ID。那么当RSM在执行每个命令的时候，会首先检查这个命令是否被执行过，如果被执行过了，就忽略，并且返回当时的结果。这种策略的要求是Client不挂，因为ID是由Client设置的。 配置切换习题官方习题来自于Raft作者的博客。 1下面哪些日志是可能存在的？ 这个应该是个标准情况，肯定是可以的。 也是可以的 也是可以的，Paxos容许日志缺失 也是可以的 2在Basic Paxos中，考虑在一个5节点的集群中，有三个acceptor接受了proposal(5.1, X)，在此之后，是否可能有某些机器去accept另一个Value Y呢？ 这个问题并没有在问，如果在一个时间节点中存在majority都接受了一个proposal，是不是可以立刻认为这个proposal被chosen？因为accept另一个Value的机器只会在小分区中。 注意，这里的proposal number由round_number.server_id这样的方式构成。 我们知道，只要一个acceptor回复了Prepare(5.1)，那么他就不可能去Accept(3.4,Y)或者Prepare(3.4,Y)了。所以如果这个可能发生，那么Prepare(3.4)一定要在Prepare(5.1)之前。于是，我们尝试下面的顺序： P4: Prepare(3.4) 发送到S1/S2/S3/S4/S5 S4/S5/S1和S2/S3发生分区 P1: Prepare(5.1) 发送到S4/S5/S1 因为5.1更大，所以S4/S5/S1会保证不会再accept小于5.1的请求。因为目前S4/S5/S1没有accept任何proposal，所以返回的“最大的小于n”的proposal为空。 P2: Accept(5.1,X) 发送到S4/S5/S1 P1: Accept(3.4,Y) 发送到S2/S3 由于分区，所以S2/S3没有回复Prepare(5.1)，更别说Accept(5.1,X)了。所以它能够接受请求Accept(3.4,Y)。 不过如果S2/S3从分区中恢复后，会将自己的值改成5.1对应的值么？ 3在MultiPaxos中，如果一个Server刚变成Leader，并且此时没有其他Server是Leader。进一步地，假设这个Server继续是Leader一段时间，其中chosen了一系列Entry，并且在这段时间中没有其他Server成为Leader。 这个Server最少需要发送几轮Prepare？ 我觉得最少只要一轮，在这一轮中大家都Accept了，并且返回noMoreAccepted。 这个Server最多需要发送几轮Prepare？ 这个我没啥idea，答案说统计Leader上面所有满足下面条件的Entry，那么就需要一条Prepare 还没有被Leader标记为chosen； 曾经被某个acceptor接受。这个过程通常是这样的，Leader向该这个Entry发送一个Prepare，然后发现这个Entry已经被某个acceptor接受了，因此它去促使这个Entry最终被chosen，并且在这之后去尝试去Prepare下一个Entry。这个也对应了不断递增firstUnchosenIndex，找到合适的可添加Entry的slote的过程。 4如果一个acceptor通过来自proposer的firstUnchosenIndex知道了某个Entry被chosen了，它必须先比较自己Entry里面的proposal number是不是和这个proposer匹配。说明这个比较是不是必要的，并解释。 这个肯定是必要的，原因在“Entry 4为什么不能被标记为chosen”里面解释过了。 5考虑proposal number的两个部分被对调了，即现在变成server_id.round_number，那么： 是否会影响算法的Safety 我觉得是有影响的，每个proposer会维护单独的server_id，那么对于1号机器，它的proposal number始终是小于2号机器的，无论它如何自增id。 但答案是说没有影响的，因为在MultiPaxos中只要求proposal number是唯一的，这时候因为server_id是唯一的而round_number是自增的，所以proposal number是唯一的。 是否会影响算法的Liveness 看答案，是会的。例如具有较大server_id的proposer会发送一个Prepare请求给每个acceptor，然后永远地宕机了。此时其他的proposer就无法再行动了，因为acceptor上的minProposal值对这些proposer来说太高了。 6假定一个proposer打算执行Accept(n,v1)，但在某个时间点宕掉了，如果这个proposer重启并且打算执行Accept(n,v2)，这个是否安全呢？ 这个在Paxos made simple中就明确指出是不可以的。 7在一个成功的Accept请求中，acceptor设置minProposal为n（即Accept请求中的proposal number）。描述一种场景，此时这个行为确实改变了minProposal的值，例如在这之前minProposal并不是n。描述如果没有这个操作，系统会出现问题的一个场景。 参考 Paxos Made Simple Paxos Summary The part-time parliament https://zhuanlan.zhihu.com/p/278054304 https://www.bilibili.com/video/BV1WW411a77S/?spm_id_from=333.788.videocard.13 http://oceanbase.org.cn/?p=90 yubai大佬的日志，描述了如何基于Basic Paxos去维护多个Log Entry http://oceanbase.org.cn/?p=111 yubai大佬的日志，描述了Multi Paxos]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>raft</tag>
        <tag>paxos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GCC和GLIBC编译]]></title>
    <url>%2F2020%2F12%2F13%2Fgcc-glibc-compile%2F</url>
    <content type="text"><![CDATA[GCC是C和C++的编译器，GLIBC是C库，两个是不同的Repo。编译顺序是先GCC在GLIBC，这是因为编译GLIBC时对GCC的版本有要求。 编译GCC源码在Git上可以拉下来，然后checkout到自己想要的版本1git clone git://gcc.gnu.org/git/gcc.git 需要先安装依赖，其顺序为：gmp mpfr mpc。可以通过运行下面的命令来下载这些依赖1./contrib/download_prerequisites 我的机器上的gmp的版本是够的，所以我只编译了后面两个，最终编译GCC的命令是1234mkdir bcd b../configure --enable-languages=c,c++ --with-mpc=/data/gcc-comp/mpc-1.0.3/out/ --with-mpfr=/data/gcc-comp/mpfr-3.1.4/out/ --prefix="$(pwd)/out"make -j5 这个编译过程有点慢，但是GCC不支持distcc的分布式编译。 编译GLIBC可以通过下面的命令来检查GLIBC的版本。12locate libc.astrings /usr/lib/libc.so.6 | grep GLIBC_ 我编译的是2.30版本，源码同样是在Git上拉下来12git clone git://sourceware.org/git/glibc.gitgit checkout release/2.30/master GLIBC有一系列的依赖，在configure的时候能够看出来，这里列出我手动编译的，需要在编译好后，设置对应的环境变量： make 1export MAKE=/data/gcc-comp/make-4.1/b/out/bin/make GCC 1export CC=/data/gcc-comp/gcc-9.3.0/b/out/bin/gcc AS/LD 这个都是binutil里面的组件，所以稍微不同地，是使用configure with参数的方式设置 BISON 1export BISON=/data/gcc-comp/bison-2.7/b/out/bin/bison Python 虽然configure中提到Python2也是可以的，但我试了下还是有问题，所以不如直接编译一个Python3 1export PYTHON_PROG=/data/gcc-comp/cpython/b/out/bin/python3 最终configure如下1../configure --prefix=/data/gcc-comp/glibc/b/out --with-binutils=/data/gcc-comp/binutils-2.32/b/out/bin 注意，在这些依赖之后，GLIBC对Linux系统本身也有依赖，例如下面的错误来自于Linux kernel header版本的问题。1checking installed Linux kernel header files... missing or too old! 检查/usr/include/linux/version.h，将LINUX_VERSION_CODE转成16进制，然后按照两位两位分成三段，从左到右就是这个Lineux Header的Major/Minor/Patch版本号。]]></content>
      <tags>
        <tag>C++</tag>
        <tag>GCC</tag>
        <tag>GLIBC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pthread_rwlock库的实现]]></title>
    <url>%2F2020%2F12%2F11%2Fpthread_rwlock-impl%2F</url>
    <content type="text"><![CDATA[pthread_rwlock系列函数是pthread库的读写锁函数。随着版本的不同，它的实现也不同。本篇的组织是： 前置知识 GCC的扩展内联汇编 Futex 两个版本的lowlevellock的实现 两个版本的pthread_rwlock的实现 扩展形式的GCC汇编介绍在扩展形式的GCC汇编中，可以访问C语言中定义的变量，或者跳转到C语言定义的标签处。此外，GCC扩展汇编中可以用:去delimit各个operand parameter。对于要访问的寄存器，并不一定要要显式指明，也可以留给GCC自己去选择，这可能让GCC更好去优化代码。GCC扩展内联汇编格式如下:12345asm asm-qualifiers ( AssemblerTemplate : OutputOperands : InputOperands : Clobbers : GotoLabels) OutputOperands、InputOperands等列表里面的项目会从0开始标号，并且可以使用%0、%1的方法去表示，例如对下面的代码而言，%0是old，%1是*Base，%2是Offset。123456789bool old;__asm__ ("btsl %2,%1\n\t" // Turn on zero-based bit #Offset in Base. "sbb %0,%0" // Use the CF to calculate old. : "=r" (old), "+rm" (*Base) : "Ir" (Offset) : "cc");return old; 我们看看这个语法中的几个组成部分： AssemblerTemplate 是ASM代码的模板。 OutputOperands 一个逗号分隔的列表，表示所有被这段代码修改的变量。 其中+rm、=r等表示Constraints，将在稍后介绍。 在括号中的应该是一个C语言左值。 InputOperands 表示所有被这段代码访问的表达式。 Clobbers 除了OutputOperands之外，还被这段代码修改的内容，例如 cc：eflags寄存器 memory：内存 例如我们常见的asm volatile(&quot;mfence&quot; ::: &quot;memory&quot;)用法。 GotoLabels 这段代码可能跳转到的C语言的标签。 ConstraintsSimple ConstraintsSimple Constraints都是字母或数字，表示允许其中的某一种类的操作。 r表示允许寄存器操作；m表示允许内存操作。这两个是很泛化的内存和寄存器操作。 a表示地址寄存器，f表示浮点寄存器，d表示数据寄存器。这些都对特定的处理器适用。 数字表示matching constraint ModifiersModifiers用来描述operands的读写性。 + 表示这个值在操作中会被读写。 = 表示这个值只会被写。 &amp; % Futex介绍Futex是一个系统调用。在使用Futex时，大部分的工作是在用户态完成的，只有当程序很有可能阻塞较长时间时，才会真的去使用这个系统调用。Futex值的加载、Futex值和传入的expected value的比较以及实际的阻塞都是原子的。并且，不同线程对同一个Futex值的并发操作是Total order的。 Futex调用如下所示123long futex(uint32_t *uaddr, int futex_op, uint32_t val, const struct timespec *timeout, /* or: uint32_t val2 */ uint32_t *uaddr2, uint32_t val3); 它的实现类似下面1234567static intfutex(uint32_t *uaddr, int futex_op, uint32_t val, const struct timespec *timeout, uint32_t *uaddr2, uint32_t val3)&#123; return syscall(SYS_futex, uaddr, futex_op, val, timeout, uaddr2, val3);&#125; 其中uaddr指向一个Futex值，它在32位或者64位系统上都是一个32位的值。futex_op包含两部分，要执行的操作(operation)，以及操作的option。option包含下面几个常量： FUTEX_PRIVATE_FLAG：128 【Since 2.6.22】 这个option表示这个Futex是否是被跨进程共享的。指定这个flag能够允许内核做一系列优化。 对于所有要执行的操作，提供了带_PRIVATE版本后缀的宏，其作用相当于or上了这个FUTEX_PRIVATE_FLAG。 因为这个宏在22版本之后才有，所以我们看到nptl的一些实现上会使用__ASSUME_PRIVATE_FUTEX判定Linux是否支持Private Futex这个功能。我们可以认为在22版本之后的Linux下这个宏始终是1。 12345// kernel-features.h/* Support for private futexes was added in 2.6.22. */#if __LINUX_KERNEL_VERSION &gt;= 0x020616# define __ASSUME_PRIVATE_FUTEX 1#endif FUTEX_CLOCK_REALTIME：256 【Since 2.6.28】 这个option指定timeout的计算方式 操作部分包含下面几个常量： FUTEX_WAIT：0 这个操作检查uaddr指向的值是否等于val。 如果是，那么就会睡在这个Futex上面，直到另一个FUTEXT_WAKE被调用。这个读取、比较和开始睡眠的过程是原子的。 如果不是，那么就会立即返回EAGAIN。 之所以要在这个操作里面再比较一次val，而不是直接加锁，其原因是为了防止丢失wake up事件。例如，如果在本线程准备阻塞之后，另一个线程修改了Futex的值，并且遵循了下面的时序： 对方线程先修改Futex值 对方线程执行FUTEX_WAKE 本线程执行FUTEX_WAIT那么在执行FUTEX_WAIT时同步检查val的方案就能发现Futex值变化了，并且不进入睡眠。 FUTEX_WAKE：1 这个操作唤醒最多val个睡在这个Futex上面的线程。指定INT_MAX表示唤起所有线程。 FUTEX_FD：2 【已被移除】 表示为当前Futex创建一个fd，当这个Futex发生FUTEX_WAKE调用时，这个fd被select、poll和epoll等可读。 FUTEX_REQUEUE：3 是FUTEX_CMP_REQUEUE的不带check的简化版。 FUTEX_CMP_REQUEUE：4 TODO FUTEX_WAKE_OP：5 这个操作用来支持在用户态中对多个Futex同时操作的情形。例如pthread_cond_signal的实现中需要用到两个Futex，一个用来实现Mutex，一个用来管理和CV相连的Wait queue。通过这个操作可以避免一些contention或者上下文切换。 这个op的主要过程是： 保存uaddr2的旧值到oldval，并且对uaddr2执行操作。这个操作是原子的。 唤醒uaddr上的val个线程。 如果oldval的值满足一定条件，则唤起val2个线程。 FUTEX_LOCK_PI：6 这里的PI表示”priority inheritance”，用来处理所谓的优先级倒置问题。 它的解决方案是，当一个高优先级的任务被一个低优先级任务持有的锁阻塞时，会暂时提高这个低优先级任务的优先级为高优先级，这样它就不会被对方抢占。 注意，这个”priority inheritance”的实现也必须是可传递的。也就是当这个低优先级任务在等待另一个中等优先级任务的锁的时候，所有的任务都要被提升为高优先级。 FUTEX_UNLOCK_PI：7 FUTEX_TRYLOCK_PI：8 FUTEX_WAIT_BITSET：9 FUTEX_WAKE_BITSET：10 FUTEX_WAIT_REQUEUE_PI：11 FUTEX_CMP_REQUEUE_PI：12 下面我们讨论futex调用的返回值。首先如果发生错误，就按照通常规矩，返回-1，并且设置errno。对于成功的情况，需要根据op讨论： FUTEX_WAIT 返回0表示caller被唤醒了。需要注意的是，这个0有可能是spurious wake-up，所以在这之后，仍然需要根据Futex值的具体值去判断是否继续block。我认为这也是为什么__lll_lock_wait_private的实现中有一个while循环的原因。 FUTEX_WAKE 返回唤醒了多少个waiter。 lll的GLIBC2.17版本在这个版本中，lll的实现是FUTEX。我们只看PRIVATE的部分12345678910111213141516171819202122232425// nptl/sysdeps/unix/sysv/linux/x86_64#define lll_lock(futex, private) \ (void) \ (&#123; int ignore1, ignore2, ignore3; \ if (__builtin_constant_p (private) &amp;&amp; (private) == LLL_PRIVATE) \ __asm __volatile (__lll_lock_asm_start \ ".subsection 1\n\t" \ ".type _L_lock_%=, @function\n" \ "_L_lock_%=:\n" \ "1:\tlea %2, %%" RDI_LP "\n" \ "2:\tsub $128, %%" RSP_LP "\n" \ "3:\tcallq __lll_lock_wait_private\n" \ "4:\tadd $128, %%" RSP_LP "\n" \ "5:\tjmp 24f\n" \ "6:\t.size _L_lock_%=, 6b-1b\n\t" \ ".previous\n" \ LLL_STUB_UNWIND_INFO_5 \ "24:" \ : "=S" (ignore1), "=&amp;D" (ignore2), "=m" (futex), \ "=a" (ignore3) \ : "0" (1), "m" (futex), "3" (0) \ : "cx", "r11", "cc", "memory"); \ else \... &#125;) 查看__lll_lock_wait_private函数的调用。下面两个lll_futex_wait的含义是如果futex的值是2，那么就会进行等待。那么为什么要写成两个呢？如果我们已经观察到futex是2，即已经被加锁了，那么我们就直接去wait了，否则我们可以尝试加锁。123456void__lll_lock_wait_private (int *futex)&#123; if (*futex == 2) lll_futex_wait (futex, 2, LLL_PRIVATE);... 但是加锁的过程也未必成功，可能有两个线程同时过了上面的检验，因此我们还需要进行一次判断。加锁操作是由atomic_exchange_acq调用，它会尝试将futex设置为2，并且返回原值。在while循环中，我们会判断返回的原值是否为0，如果不是0，那么说明这个锁已经被另一个线程加了，所以我们直接wait到这个锁被释放，然后在重新while一次尝试加锁。1234... while (atomic_exchange_acq (futex, 2) != 0) lll_futex_wait (futex, 2, LLL_PRIVATE);&#125; 辅助函数解释lll_futex_wait查看lll_futex_wait函数123456789#define lll_futex_wait(futex, val, private) \ lll_futex_timed_wait(futex, val, NULL, private)#define lll_futex_timed_wait(futex, val, timeout, private) \ (&#123; \ register const struct timespec *__to __asm ("r10") = timeout; \ int __status; \ register __typeof (val) _val __asm ("edx") = (val); \ 解释一下： __status这个变量在一个地址寄存器上，是这个汇编段的Output。 SYS_futex TODO futex __lll_private_flag根据传入的两个参数决定是否产生private的futex。需要注意libc和libdl中的所有的futex都应该是private的。 检查这个函数的实现，有一句很神奇的代码。这个代码的结果是，如果private设置了FUTEX_PRIVATE_FLAG位，那么就将这个位清空。要解释清楚这个问题，需要结合后面rwlock的初始化过程来看。 12# define __lll_private_flag(fl, private) \ (((fl) | FUTEX_PRIVATE_FLAG) ^ (private)) cc表示eflags寄存器也会被修改。 12345678 __asm __volatile ("syscall" \ : "=a" (__status) \ : "0" (SYS_futex), "D" (futex), \ "S" (__lll_private_flag (FUTEX_WAIT, private)), \ "d" (_val), "r" (__to) \ : "memory", "cc", "r11", "cx"); \ __status; \&#125;) atomic_exchange_acqlll的GLIBC2.30版本1234567891011121314151617181920212223242526// lowlevellock.h/* This is an expression rather than a statement even though its value is void, so that it can be used in a comma expression or as an expression that's cast to void. *//* The inner conditional compiles to a call to __lll_lock_wait_private if private is known at compile time to be LLL_PRIVATE, and to a call to __lll_lock_wait otherwise. *//* If FUTEX is 0 (not acquired), set to 1 (acquired with no waiters) and return. Otherwise, ensure that it is &gt;1 (acquired, possibly with waiters) and then block until we acquire the lock, at which point FUTEX will still be &gt;1. The lock is always acquired on return. */#define __lll_lock(futex, private) \ ((void) \ (&#123; \ int *__futex = (futex); \ if (__glibc_unlikely \ (atomic_compare_and_exchange_bool_acq (__futex, 1, 0))) \ &#123; \ if (__builtin_constant_p (private) &amp;&amp; (private) == LLL_PRIVATE) \ __lll_lock_wait_private (__futex); \ else \ __lll_lock_wait (__futex, private); \ &#125; \ &#125;))#define lll_lock(futex, private) \ __lll_lock (&amp;(futex), private) rwlock的GLIBC2.17实现INIT12345678910111213141516// pthread_rwlock_init.cint__pthread_rwlock_init (rwlock, attr) pthread_rwlock_t *rwlock; const pthread_rwlockattr_t *attr;&#123; const struct pthread_rwlockattr *iattr; iattr = ((const struct pthread_rwlockattr *) attr) ?: &amp;default_attr; memset (rwlock, '\0', sizeof (*rwlock)); rwlock-&gt;__data.__flags = iattr-&gt;lockkind == PTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NP; ... __ASSUME_PRIVATE_FUTEX这个宏表示是否支持Private Futex，在2.6.22之前是不支持的，因此我们看到在对应分支没有使用FUTEX_PRIVATE_FLAG这个宏，而是借助了THREAD_GETMEM的实现。FUTEX_PRIVATE_FLAG的值表示这个Futex是否是Private的，在之前已经介绍过。 __SHARED这个字段我觉得有点奇怪了，我不是很明白为啥Futex用Private，而pthread用Shared，正好这两个值是相反的。源码在注释里面给了下面这个转换表，容易看出来在不支持FUTEX_PRIVATE_FLAG的时候就都是0。 12345 | pshared | result | shared private | shared private |------------+-----------------+-----------------+!avail 0 | 0 0 | 0 0 | avail 0x80 | 0x80 0 | 0 0x80 | 不管怎样吧，下面我们设置_shared的值，正好和Private相反。也就是如果我们希望我们的rwlock是Private的，那么我们就清空FUTEX_PRIVATE_FLAG位；如果我们希望它是Shared，那么就设置FUTEX_PRIVATE_FLAG。这样我们xor一下就能得到Private的实际值，这实际上对应了我们先前在lll_futex_timed_wait这个函数上的困惑。12345...#ifdef __ASSUME_PRIVATE_FUTEX rwlock-&gt;__data.__shared = (iattr-&gt;pshared == PTHREAD_PROCESS_PRIVATE ? 0 : FUTEX_PRIVATE_FLAG);... 由于1234567891011...#else rwlock-&gt;__data.__shared = (iattr-&gt;pshared == PTHREAD_PROCESS_PRIVATE ? 0 : THREAD_GETMEM (THREAD_SELF, header.private_futex));#endif return 0;&#125;strong_alias (__pthread_rwlock_init, pthread_rwlock_init) LOCK1234567// pthread_rwlock_wrlock.c/* Acquire write lock for RWLOCK. */int__pthread_rwlock_wrlock (rwlock) pthread_rwlock_t *rwlock;&#123; int result = 0; 这个LIBC_PROBE定义在include/stap-probe.h里面，实际上是一个systemtap静态检查点的功能。123... LIBC_PROBE (wrlock_entry, 1, rwlock);... 下面调用lll_lock去加lowlevellock锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758... /* Make sure we are alone. */ lll_lock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared); while (1) &#123; /* Get the rwlock if there is no writer and no reader. */ if (rwlock-&gt;__data.__writer == 0 &amp;&amp; rwlock-&gt;__data.__nr_readers == 0) &#123; /* Mark self as writer. */ rwlock-&gt;__data.__writer = THREAD_GETMEM (THREAD_SELF, tid); LIBC_PROBE (wrlock_acquire_write, 1, rwlock); break; &#125; /* Make sure we are not holding the rwlock as a writer. This is a deadlock situation we recognize and report. */ if (__builtin_expect (rwlock-&gt;__data.__writer == THREAD_GETMEM (THREAD_SELF, tid), 0)) &#123; result = EDEADLK; break; &#125; /* Remember that we are a writer. */ if (++rwlock-&gt;__data.__nr_writers_queued == 0) &#123; /* Overflow on number of queued writers. */ --rwlock-&gt;__data.__nr_writers_queued; result = EAGAIN; break; &#125; int waitval = rwlock-&gt;__data.__writer_wakeup; /* Free the lock. */ lll_unlock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared); /* Wait for the writer or reader(s) to finish. */ lll_futex_wait (&amp;rwlock-&gt;__data.__writer_wakeup, waitval, rwlock-&gt;__data.__shared); /* Get the lock. */ lll_lock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared); /* To start over again, remove the thread from the writer list. */ --rwlock-&gt;__data.__nr_writers_queued; &#125; /* We are done, free the lock. */ lll_unlock (rwlock-&gt;__data.__lock, rwlock-&gt;__data.__shared); return result;&#125;weak_alias (__pthread_rwlock_wrlock, pthread_rwlock_wrlock)hidden_def (__pthread_rwlock_wrlock) 辅助函数详解THREAD_GETMEM1234567891011121314151617181920212223/* Read member of the thread descriptor directly. */# define THREAD_GETMEM(descr, member) \ (&#123; __typeof (descr-&gt;member) __value; \ if (sizeof (__value) == 1) \ asm volatile ("movb %%fs:%P2,%b0" \ : "=q" (__value) \ : "0" (0), "i" (offsetof (struct pthread, member))); \ else if (sizeof (__value) == 4) \ asm volatile ("movl %%fs:%P1,%0" \ : "=r" (__value) \ : "i" (offsetof (struct pthread, member))); \ else \ &#123; \ if (sizeof (__value) != 8) \ /* There should not be any value with a size other than 1, \ 4 or 8. */ \ abort (); \ \ asm volatile ("movq %%fs:%P1,%q0" \ : "=r" (__value) \ : "i" (offsetof (struct pthread, member))); \ &#125; \ __value; &#125;) rwlock的GLIBC2.30实现INIT123456789101112131415161718192021// pthread_rwlock_init.c/* See pthread_rwlock_common.c. */int__pthread_rwlock_init (pthread_rwlock_t *rwlock, const pthread_rwlockattr_t *attr)&#123; ASSERT_TYPE_SIZE (pthread_rwlock_t, __SIZEOF_PTHREAD_RWLOCK_T); const struct pthread_rwlockattr *iattr; iattr = ((const struct pthread_rwlockattr *) attr) ?: &amp;default_rwlockattr; memset (rwlock, '\0', sizeof (*rwlock)); rwlock-&gt;__data.__flags = iattr-&gt;lockkind; /* The value of __SHARED in a private rwlock must be zero. */ rwlock-&gt;__data.__shared = (iattr-&gt;pshared != PTHREAD_PROCESS_PRIVATE); return 0;&#125; strong_alias是C的一个别名机制，定义pthread_rwlock_init是__pthread_rwlock_init的别名。别名包括strong和weak的。1strong_alias (__pthread_rwlock_init, pthread_rwlock_init) 它的实现在libc-symbols.h中。其中，__typeof (name) aliasname定义了一个aliasname，它的类型是name的类型。12345/* Define ALIASNAME as a strong alias for NAME. */# define strong_alias(name, aliasname) _strong_alias(name, aliasname)# define _strong_alias(name, aliasname) \ extern __typeof (name) aliasname __attribute__ ((alias (#name))) \ __attribute_copy__ (name); LOCK1234567891011121314// pthread_rwlock_wrlock.c/* See pthread_rwlock_common.c. */int__pthread_rwlock_wrlock (pthread_rwlock_t *rwlock)&#123; LIBC_PROBE (wrlock_entry, 1, rwlock); int result = __pthread_rwlock_wrlock_full (rwlock, CLOCK_REALTIME, NULL); LIBC_PROBE (wrlock_acquire_write, 1, rwlock); return result;&#125;weak_alias (__pthread_rwlock_wrlock, pthread_rwlock_wrlock)hidden_def (__pthread_rwlock_wrlock) __pthread_rwlock_wrlock_full使用原子操作实现的1// pthread_rwlock_common.c Reference https://man7.org/linux/man-pages/man2/futex.2.html 附注一下，Linux的man page后面的数字序号有下面的含义： 普通命令 系统调用 库函数 特殊文件,也就是/dev下的各种设备文件 文件的格式 游戏留的 附件，或者一些全局变量 是root专用的命令 https://man7.org/linux/man-pages/man7/futex.7.html https://www.cnblogs.com/pslydff/p/7041444.html https://gohalo.me/post/program-c-gdb-deadlock-analyze-introduce.html]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>pthread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[V8引擎编译]]></title>
    <url>%2F2020%2F11%2F21%2Fv8-compile%2F</url>
    <content type="text"><![CDATA[本文介绍在一个较老的环境下编译V8引擎，并全静态地链接到既有的游戏服务上。原因是我们必需一个很新的JS引擎，从而能支持WebAssembly。经过调研，我们认为使用V8是最好的。我们的游戏服务使用GCC4.4.6，这是一个非常老的版本，甚至不能完整支持C++11标准，而即使是很老版本的V8都需要完整的C++11支持(GCC 4.8+)；进一步地最新版本的V8需要C++14标准的支持，这不仅体现在v8.h中出现了诸如std::remove_cv_t的C++14的标准库函数，还体现在C++14标准编译出来的库也没办法直接和原游戏的目标文件进行链接。因此我们的方案是将游戏中对V8强依赖的模块升级成C++14标准，主要步骤如下： 从源码构建GCC和GLIBC 从源码构建V8静态库v8_monolith.a 将V8静态库、libc++、GLIBC和游戏模块全静态链接 编译GCC和GLIBC见文章 代码拉取代码拉取值得单独开一节，因为虽然V8代码使用Git来管理的，但它却并不是传统的git clone的路数，而是需要借助gclient这个工具。gclient，包括gn等工具都在depot_tools这个包里面，我们可以通过下面的链接得到这个包1git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git 在得到这个包后，我们还需要将它加到环境路径里面以方便访问1export PATH=`pwd`/depot_tools:"$PATH" 然后，使用下面的命令拉取12fetch v8glient sync 如果出现gclient拉取问题，可以尝试修改.gclient文件如下所示12345678910solutions = [ &#123; "managed": False, "name": "src", "url": "https://chromium.googlesource.com/v8/v8.git", "custom_deps": &#123;&#125;, "deps_file": ".DEPS.git", "safesync_url": "", &#125;,] 此外，url还可以尝试取github上的地址1https://github.com/chromium/chromium.git 编译V8目前V8默认是使用Clang编译的，确实比GCC快很多，但由于我们最后还要和游戏进行链接，所以需要把工具链换成GCC。在这篇wiki中给出了从简单到复杂的不同的编译的流程。我试验下来直接用gn是最为方便的。 修改编译器V8默认的编译工具链是clang，我们要将它变成GCC。首先我们需要设置use_custom_libcxx，这个项目如果为true，就会走v8自带的编译工具，这样编译出来如果是d8还好，但我们需要静态库，这样肯定不行。1use_custom_libcxx = false 然后我们需要修改gn args，添加下面的项目，目的是禁用clang相关的宏。12is_clang = falseuse_sysroot = false 为了防止ld.gold报错，还需要开启下面的选项。1fatal_linker_warnings = false 但这么做还不够，需要在入口build/config/BUILDCONFIG.gn中，修改Linux下，is_clang为true的情况下，toolchain为GCC。否则，还是有一些代码会把is_clang的值变回true。1_default_toolchain = "//build/toolchain/linux:$target_cpu" 紧接着，我们就要修改原来的gcc toolchain，将里面的配置替换成我们刚编译得到的GCC9，具体涉及下面的修改 toolchain\gcc_toolchain.gni 这是一个模板文件，我们需要修改GCC的cc、cxx、alink和link_command这几个项目。具体说来，包括： 设置cc、cxx和ld到GCC9的bin目录下的对应程序； 这里，ld就指定为g++即可 修改extra_cppflags添加GCC对应的include文件夹的路径； 对于cc和cxx两个tool，需要在最后加上-static； 对于alink和link_command，需要加上libstdc++.a。 config\c++\BUILD.gn 参照toolchain\gcc_toolchain.gni修改cflags_cc和ldflags。 去掉snapshotsnapshot技术是V8为了提高Context的加载速度引入的优化，将V8启动后的内存布局和JS函数预编译好的二进制对象写到专门的文件shapshot_blob.bin和natives_blob.bin中，并在每一次初始化的时候直接加载，以减少重复编译消耗。修改gn args，添加1v8_use_external_startup_data = false 生成v8静态库首先生成ninja构建文件1gn gen out.gn/x64.debug/ 修改gn args，添加1v8_monolithic = true 然后使用下面的命令生成静态库，注意后面的-j不能加得太大，因为在编译比如torque的时候GCC会占用比较大的内存，如果并行度很高，可能就编不出来1ninja -C out.gn/x64.debug/ v8_monolith -j2 静态链接通过下面的命令可以静态链接V8的Hello world程序。1$(GCC_ROOT)/bin/g++ samples/bench.cpp -o bench -isystem$(GLIBC_ROOT)/include/ -I. -Iinclude -isystem$(GLIBC) -nodefaultlibs -DV8_COMPRESS_POINTERS -static $(V8_OBJ)/libv8_monolith.a -Wl,--start-group $(GCC_ROOT)/lib64/libstdc++.a $(GLIBC_ROOT)/lib/libpthread.a $(GLIBC_ROOT)/lib/libdl.a $(GLIBC_ROOT)/lib/libm.a $(GLIBC_ROOT)/lib/librt.a $(GCC_GCC)/libgcc.a $(GCC_GCC)/libgcc_eh.a $(GCC_GCC)/libcommon.a $(GLIBC_ROOT)/lib/libc.a -Wl,--end-group 附注2558版本2558版本是一个较老的版本，它是使用Make和GYP来构建的。由于它同样需要移动语义，所以也要C++11的支持。主要涉及下面的修改 build/standalone.gypi 设置$(snapshot)为off。 设置clang%为1。 Hello world链接过程 1g++ -pthread -fuse-ld=gold -fuse-ld=gold -m64 -m64 -rdynamic -rdynamic -Wl,--threads -Wl,--thread-count=4 -Wl,--threads -Wl,--thread-count=4 -o hello -Wl,--start-group hello-world.o out_libs/libv8_libplatform.a out_libs/libicui18n.a out_libs/libicuuc.a out_libs/libv8_base.a out_libs/libv8_libbase.a out_libs/libicudata.a out_libs/libv8_nosnapshot.a -Wl,--end-group -ldl -lrt]]></content>
      <tags>
        <tag>C++</tag>
        <tag>V8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git基础概念和基础命令]]></title>
    <url>%2F2020%2F10%2F29%2Fgit-basic%2F</url>
    <content type="text"><![CDATA[下面的一些git命令，在使用时常常不知所以，容易混淆，其实原因是对git的机制并不了解，因此在本文中介绍相关。 reset hard/soft/mixed 123$ git reset --hard$ git reset --mixed$ git reset --soft fetch/pull 12$ git fetch$ git pull reset/revert diff cached/HEAD 12345$ git diff --cached$ git diff --staged$ git diff HEAD$ git diff HEAD~1$ git diff HEAD^ 基本概念图Git的工作区域注意，图中的Stage和Index是同一个东西。下图中，最后一个diff应该为diff --cached 注意，Git中的branch实际上可以看做是一些列commit的集合。commit是按照repo全局的，这可以最大程度实现复用。 HEADHEAD实际上是指向当前分支的指针。观察.git/HEAD，可以发现1ref: refs/heads/master 接着打开.git/refs/heads/master，可以发现1fc30ecc0525b71b0f6bf1ce20fe793aa731ae66c 执行git log，可以发现存在指向性关系HEAD -&gt; master -&gt; fc30ecc12git logcommit fc30ecc0525b71b0f6bf1ce20fe793aa731ae66c (HEAD -&gt; master) 容易想到切换分支指令git checkout就是通过改变HEAD来实现的。 checkout相关切换分支使用git checkout指令。加上-b参数可以基于当前分支创建新分支并切换，相当于整合了git branch命令。checkout的指令和reset指令有些类似我们还可以指定某个文件进行checkout，其中-q表示quiet。1git checkout [-q] [&lt;commit id&gt;] [--] &lt;paths&gt; 如果我们需要把Index/Stage里面的东西checkout到工作目录中，可以1git checkout-index -a -f 其中-a表示全部文件，-f表示会强制覆盖已存在的文件。可以看出git对所有涉及变动本地目录的操作都很谨慎。 加上-- &lt;path&gt;就可以checkout单个的文件。需要注意的是，现在checkout就可以直接从Stage/Index检出单个文件了。1git checkout -- 1.txt rebase相关merge相关git merge用法几种merge策略Git使用的是三路合并，分别是要合并的两方a和b，和这两方的共同祖先c。通过和共同祖先比较，能够自动解决一些冲突，原因如下： 假如a对c中的某个文件1.txt进行了修改，而b没有。如果直接合并a和b，我们并不知道是否该采用这个修改； 但如果我们参照c去合并a和b，就可以发现b对c上的1.txt并没有修改，所以应该接受a对1.txt的修改。 RecursiveRecursive是默认策略，这种策略只能同时合并两个分支，如果需要同时合并多个分支，就需要反复进行两两合并。这里反复有点奇怪，难道不是n-1次么？接着往下看。显而易见，在合并时，我们序号回溯两个分支A和B的共同祖先，从而确定解决冲突的起点。但在Git中，两个分支可能存在有多个共同祖先，即Criss-Cross现象。我们考虑下面的操作方式： 在master上提交c0 在master上checkout出分支feature1，并在feature1上提交c1 在master上提交c2 在master上checkout出分支feature2 在feature2上merge分支feature1，产生提交c3 此时feature2（指向c3）的祖先是master（指向c2）和feature1（指向c1） 在master上提交c4 将feature1合并到master，产生提交c5 此时会导致Criss-Cross现象。我们来分析一下合并之后的情况： feature1目前指向c1，c1的祖先是c0。 feature2目前指向c3，它的祖先是c2和c1。 master目前指向c5，它的祖先是c4和c1。由于c4的祖先是c2，所以feature2和master有两个共同祖先c1和c2。 下面，我们尝试合并master和feature2。Recursive策略是，首先合并master和feature2的共同祖先，即c1和c2，得到一个虚拟祖先，然后在进行合并。 我们还可以指定不同的diff-algorithm1git merge origin/master -s recursive -X diff-algorithm=patience 例如patience策略就能够产生更加优雅的合并结果，例如更好地匹配大括号。 ResolveResolve策略是Recursive出现之前旧的合并策略。 OursOctopus这个策略能够同时合并多个分支，但是如果出现需要手工解决的冲突，就会失败。 diff相关实验：有关diff我们进行如下操作： init仓库，新建文件1.txt 变更1.txt的内容为2，并add+commit 变更1.txt的内容为3，并add，不commit 变更1.txt的内容为4，不做任何操作 下面进行检查： git diff --cached 比较Index和HEAD 12345678910$ git diff --cacheddiff --git a/1.txt b/1.txtindex d8263ee..e440e5c 100644--- a/1.txt+++ b/1.txt@@ -1 +1 @@-2\ No newline at end of file+3\ No newline at end of file git diff 比较working directory和Index 12345678910$ git diffdiff --git a/1.txt b/1.txtindex e440e5c..bf0d87a 100644--- a/1.txt+++ b/1.txt@@ -1 +1 @@-3\ No newline at end of file+4\ No newline at end of file git diff HEAD 比较working directory和HEAD 12345678910$ git diff HEADdiff --git a/1.txt b/1.txtindex d8263ee..bf0d87a 100644--- a/1.txt+++ b/1.txt@@ -1 +1 @@-2\ No newline at end of file+4\ No newline at end of file git diff HEAD --cached 比较Index和HEAD 12345678910$ git diff HEAD --cacheddiff --git a/1.txt b/1.txtindex d8263ee..e440e5c 100644--- a/1.txt+++ b/1.txt@@ -1 +1 @@-2\ No newline at end of file+3\ No newline at end of file git diff/apply 将HEAD到working的修改输出到patch文件。然后我们回退到HEAD并apply发现会恢复到working中的结果。当然，reset会导致Index区被清空？ 123$ git diff HEAD &gt; patch$ git reset --hard$ git apply patch 那么我们是否可以用HEAD到working，发现会报错 12345$ git diff HEAD &gt; patch$ git reset --mixed$ git apply patcherror: patch failed: 1.txt:1error: 1.txt: patch does not apply reset相关git reset命令修改branch，即指向最新commit的指针HEAD，并不修改任何commit。reset可以带有三个参数： --hard参数会改变HEAD、index(stage)和working directory --mixed参数会改变HEAD、index(stage) --soft参数只会改变HEAD 实验：有关resetStep 1本实验说明soft reset不会改变working directory。 首先我们在空目录执行 1git init 我们创建a.txt，并且填写其内容为1 我们执行 123git add .git commit -m"a=1"git log 得到输出 12345commit 6bd3de7a2b1637dcb686f72af415c5d48f4d5dc2 (HEAD -&gt; master)Author: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Fri Oct 30 22:46:37 2020 +0800 a=1 修改a.txt的内容为2 执行 1git reset --soft 查看a.txt的内容为2 这说明a.txt没有被reset掉 Step 2本实验说明soft reset不会改变index 此时，a.txt的内容仍然为2 执行 1git diff --cached a.txt 可以看到，a.txt已经被提交到了index里面 123456789diff --git a/a.txt b/a.txtindex 56a6051..d8263ee 100644--- a/a.txt+++ b/a.txt@@ -1 +1 @@-1\ No newline at end of file+2\ No newline at end of file 执行 1git reset --soft 检查a.txt的内容仍然为2 Step 3本实验说明soft reset能改变Repo 此时a.txt的内容仍然为2，执行 1git commit -m"a=2" 检查git log 可以看到，a=2已经进入了Repo 1234567891011commit c0a4d93cb05eb39e149ff50d9b7e54257a51234b (HEAD -&gt; master)Author: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Fri Oct 30 23:03:53 2020 +0800 a=2commit 6bd3de7a2b1637dcb686f72af415c5d48f4d5dc2Author: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Fri Oct 30 22:46:37 2020 +0800 a=1 执行 HEAD~1表示HEAD向前一个版本。 1git reset --soft HEAD~1 检查git log 发现a=2的提交被回退了 12345commit 6bd3de7a2b1637dcb686f72af415c5d48f4d5dc2 (HEAD -&gt; master)Author: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Fri Oct 30 22:46:37 2020 +0800 a=1 检查a.txt 发现内容还是2，没有变。说明即使回退了Repo，也不会改变工作区。 执行 1git checkout 检查a.txt 发现值内容还是2，这个和图2似乎有矛盾。其实应该要加一个-f 1git checkout -f bisect相关实验：有关bisectLinux内核易于维护的一个原因就是因为Linus要求每一个commit只做一件事，所以他能够通过git bisect快速地二分出错误的提交。 执行下面语句，得到10个提交12345git initfor i in &#123;1..10&#125;do echo "print '$i'" &gt; p.py &amp;&amp; git add . &amp;&amp; git commit -m"p $i"done 我们的目标是找到第一个打印出大于等于5的错误提交。我们写一个predicate脚本1234567# test.shprinted=$(python p.py)if [ $printed -lt 5 ]; then exit 0; # goodelse exit 1; # badfi 执行下面语句，自动查找到第一个故障提交1234git bisect startgit statusgit bisect bad HEADgit bisect good HEAD~9 下面执行git bisect run，可以得到以下输出1234567891011121314151617$ git bisect run ./test.shrunning ./test.shBisecting: 1 revision left to test after this (roughly 1 step)[552b511a6d14f48a258338527fb6532a6852d1c2] p 3running ./test.shBisecting: 0 revisions left to test after this (roughly 0 steps)[53c92c7bd287ae1cc06a0ff1eeb57f6bb9525424] p 4running ./test.sh6254d17800fc63757fd6b478e80db23480aec6f7 is the first bad commitcommit 6254d17800fc63757fd6b478e80db23480aec6f7Author: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Mon Nov 9 22:56:36 2020 +0800 p 5:100644 100644 06cfe93d366cdbd541402affbcbf2305c1d7409b a6b723841de0d34ba0a7d30e7ba3b16ff48ad8e4 M p.pybisect run success Reference https://git-scm.com/book/zh/v2/Git-%E5%B7%A5%E5%85%B7-%E9%AB%98%E7%BA%A7%E5%90%88%E5%B9%B6 https://morningspace.github.io/tech/git-merge-stories-2/ https://blog.walterlv.com/post/git-merge-strategy.html#resolve]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVN从源码构建]]></title>
    <url>%2F2020%2F10%2F21%2Fsubversion-compile%2F</url>
    <content type="text"><![CDATA[本文讲解SVN从源码的构建流程，和其中遇到的一些问题。 在install依赖库的时候通过configure --prefix指定install路径，其他项目引用依赖库的时候--with-来指定依赖库的install路径。 详细命令apr1234wget http://mirror.bit.edu.cn/apache//apr/apr-1.7.0.tar.gz./buildconf./configure --prefix=/root/subversion_build/third/aprmake -j5 &amp;&amp; make install apr-util12345wget http://mirror.bit.edu.cn/apache//apr/apr-util-1.6.1.tar.gz./buildconf --with-apr=../apr-1.7.0./configure --prefix=/root/subversion_build/third/apr-util --with-apr=/root/subversion_build/third/apr/yum install expat-develmake -j5 &amp;&amp; make install qlite123wget http://www.sqlite.org/2017/sqlite-autoconf-3210000.tar.gz./configure --prefix=/root/subversion_build/third/sqlitemake -j5 &amp;&amp; make install scons12wget http://prdownloads.sourceforge.net/scons/scons-2.5.0.tar.gzpython setup.py install openssl1234wget https://www.openssl.org/source/old/1.0.1/openssl-1.0.1u.tar.gz./config --prefix=/root/subversion_build/third/openssl -fPIC no-gostmake dependmake install serfserf主要是为了提供http方式的checkoutserf编译会有问题，需要参考本文做一些修改。123456wget https://www.apache.org/dist/serf/serf-1.3.9.tar.bz2sed -i 's/OPENSSL_VERSION_NUMBER &gt;= 0x10100000L/OPENSSL_VERSION_NUMBER &gt;= 0x10100000L \&amp;\&amp; !defined(LIBRESSL_VERSION_NUMBER)/' buckets/ssl_buckets.csed -i 's/OPENSSL_VERSION_NUMBER &gt;= 0x10100000L/OPENSSL_VERSION_NUMBER &gt;= 0x10100000L \&amp;\&amp; !defined(LIBRESSL_VERSION_NUMBER)/' test/server/test_sslserver.cscons -cscons PREFIX=/usr/local/serf APR=/root/subversion_build/third/apr/bin/apr-1-config APU=/root/subversion_build/third/apr-util/bin/apu-1-config OPENSSL=/root/subversion_build/third/openssl/scons install subversion这里需要将openss和serf加到PKG_CONFIG_PATH里面，否则会导致configure失败。此外，还有可能出现expat缺失的问题，这个最好不要从源码编译了，因为--with-expat的配置有点麻烦。我们可以直接下载expact-devel包即可。123export PKG_CONFIG_PATH=/usr/local/serf/lib/pkgconfig:/root/subversion_build/third/openssl/lib/pkgconfig./configure --with-apr=/root/subversion_build/third/apr --with-apr-util=/root/subversion_build/third/apr-util/ --with-sqlite=/root/subversion_build/third/sqlite --with-lz4=internal --with-utf8proc=internal --with-serf=/usr/local/serf --enable-mod-activationmake -j5 &amp;&amp; make install 如果出现12# svn --versionsvn: error while loading shared libraries: libserf-1.so.1: cannot open shared object file: No such file or directory 则1ln -s /usr/local/serf/lib/libserf-1.so.1.3.0 /usr/lib64/libserf-1.so.1 注意pkg-config返回错误码，而不是打印，所以最好加上--print-errors获取错误，如1/usr/bin/pkg-config /usr/local/serf/lib/pkgconfig/serf-1.pc --exists --print-errors]]></content>
      <tags>
        <tag>SVN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Sentinel实现原理分析]]></title>
    <url>%2F2020%2F10%2F18%2Fredis-sentinel%2F</url>
    <content type="text"><![CDATA[Sentinel(哨兵)监控Redis集群中Master状态，是Redis 的高可用性解决方案。它监视一系列Master-Slave集群（和其他Sentinel）。当某个Master下线时，自动将该Master下的某个Slave升级为Master。 Sentinel的代码阅读难度相对较大，这是因为它是时钟驱动的一个状态机，所以在逻辑上有点不是很连贯。本文使用的版本和Redis底层对象实现原理分析这篇文章是相同的。有一些基础知识也在这篇文章中列出。 本文中【接上】暗示这个逻辑其实不属于父标题，但是和上面的标题成时序关系，例如上一个标题是Request的产生逻辑，下一个就是对端对Request的处理逻辑，下一个就是对对端Response的处理逻辑。 本文中Master指的是Redis主从复制中的主节点；(Sentinel) Leader指的是FailOver流程中选举出来的领头的Sentinel。 Redis主从复制详见文章 总览Sentinel用法与常见命令表示监控一个叫mymaster的服务器，其IP:Port为127.0.0.1:6379，并且这个Master要Failover至少需要2个。但注意这里的2并不是下确界，除了这个约束，还需要有满足majority的限制条件。1sentinel monitor mymaster 127.0.0.1 6379 2 down-after-milliseconds表示经过这一段时间，如果服务器没有对Sentinel的PING进行回复，或者一直返回无效回复（注意，回复错误也是有效回复），那么就会被标记为SDOWN。1sentinel down-after-milliseconds mymaster 60000 failover-timeout表示故障恢复的超时时间。1sentinel failover-timeout mymaster 180000 parallel-syncs表示在执行故障转移时，最多可以有多少Slave同时对新Master进行同步，数字越小，完成故障转移所需的时间就越长。1sentinel parallel-syncs mymaster 1 常用结构/模块在本章节中，主要介绍两个基础对象，即全局上下文sentinelState和当前Sentinel对其监视的每个对象的描述类sentinelRedisInstance。 sentinelRedisInstance每个被监视的Redis实例都会创建一个sentinelRedisInstance结构，它具有flag分别标注了实例的状态。可以看到123#define SRI_MASTER (1&lt;&lt;0)#define SRI_SLAVE (1&lt;&lt;1)#define SRI_SENTINEL (1&lt;&lt;2) SDOWN表示主观下线，即被一个Sentinel认为下线。ODOWN是客观下线，表示被Sentinel集群认为下线。如果另一个Sentinel觉得某个Master节点SDOWN了，那么它会通知我，并且让我把这个Master节点也设置为SDOWN么？是的，可以查看sentinelAskMasterStateToOtherSentinels函数。12#define SRI_S_DOWN (1&lt;&lt;3) /* Subjectively down (no quorum). */#define SRI_O_DOWN (1&lt;&lt;4) /* Objectively down (confirmed by others). */ SRI_MASTER_DOWN和SRI_S_DOWN有什么区别呢？SRI_MASTER_DOWN表示对方Sentinel关于Master有没有宕机的投票结果。SRI_S_DOWN表示我自己认为有没有SDOWN。12345#define SRI_MASTER_DOWN (1&lt;&lt;5) /* A Sentinel with this flag set thinks that its master is down. */#define SRI_FAILOVER_IN_PROGRESS (1&lt;&lt;6) /* Failover is in progress for this master. */#define SRI_PROMOTED (1&lt;&lt;7) /* Slave selected for promotion. */ 下面三个是和Reconf有关的Flag，我们在稍后进行考虑。12345#define SRI_RECONF_SENT (1&lt;&lt;8) /* SLAVEOF &lt;newmaster&gt; sent. */#define SRI_RECONF_INPROG (1&lt;&lt;9) /* Slave synchronization in progress. */#define SRI_RECONF_DONE (1&lt;&lt;10) /* Slave synchronized with new master. */#define SRI_FORCE_FAILOVER (1&lt;&lt;11) /* Force failover with master up. */#define SRI_SCRIPT_KILL_SENT (1&lt;&lt;12) /* SCRIPT KILL already sent on -BUSY */ sentinelRedisInstance相关参数解释 runid runid是类似183af86ac492235bf97739bcdad0353f1d4e61df的串，在后面的实验中可以看到。 注意，如果需要获得当前Sentinel进程的runid，通过sentinel.myid来访问。在3.0版本前，可以通过server.runid来访问。其中server是 1extern struct redisServer server; sentinel.myid在sentinelIsRunning中被getRandomHexChars函数设置，似乎新版本中，使用Sentinel独立的runid了。 name ri-&gt;runid和ri-&gt;name是两个不同概念。 对于Master节点来说，表示这个Sentinel中Master节点的名字，这个名字是在配置文件里面用SENTINEL monitor设置的。 对于Slave和Sentinel节点来说，这个是自动设置的。在createSentinelRedisInstance中可以看到，Slave的name是ip:port;从sentinelProcessHelloMessage可以看到，Sentinel的name是runid。 masters、slaves、sentinels这三个dict的key是name。 parallel_syncs 在执行故障转移操作时，可以同时对新的Master进行同步的Slave数量。通过下面命令进行设置。 1SENTINEL parallel-syncs &lt;master-name&gt; &lt;number&gt; leader 如果这个Instance是Master，那么leader表示将负责对这个Master进行FailOver的Sentinel的runid。 如果这个Instance是Sentinel，那么leader就是被选举出来的Sentinel Leader的runid。 对于非SRI_MASTER_DOWN情况，这个不生效。 pending_commands in-flight的命令的数量。即发出还未收到回复。 failover_state 注意，还有个flags中的标签SRI_FAILOVER_IN_PROGRESS。这两个标签都只对Master的Instance是有意义的。 addr 表示Master的addr，是一个sentinelAddr *。 master 我们需要区分ri-&gt;master和另外一个sentinel.masters。 首先，ri-&gt;master只在这个Instance是Slave的时候有效，表示这个Slave对应的Master；而sentinel.masters表示这个Sentinel监控的所有Master实例。 我们需要记住一点，整个进程里面做事的第一人称“我”是这个Sentinel，因此只有在sentinel.masters这个全局单例中才会看到我们监视了哪些Master。 master-&gt;failover_epoch、master-&gt;config_epoch、master-&gt;leader_epoch和sentinel.current_epoch 我们需要区分这三者，以及sentinelState中的current_epoch的区别： master-&gt;failover_epoch 表示这次FailOver开始时的Epoch。当某个Sentinel进程决定调用sentinelStartFailover开始FailOver时，它需要自增自己的current_epoch，并且同步给failover_epoch。 master-&gt;config_epoch 在sentinelProcessHelloMessage中根据比较自己的和远端的config_epoch的大小，进行配置更新。 master-&gt;leader_epoch leader_epoch和leader是联合使用的，表示当前Sentinel认为的处理这个Master的FailOver过程的Leader，发起竞选的epoch。 sentinel.current_epoch 因为一个Sentinel可能处理若干个Master的FailOver过程，所以sentinel.current_epoch作为当前Sentinel的epoch。这有点类似于Raft里面Term的机制。 这是Sentinel自己的属性，而failover_epoch作为当前被监视的Master的epoch，两个是无法一一对应的。所以说导致有这两个看上去若即若离的对象。 在sentinelProcessHelloMessage里面会更新。 role_reported 注意，我们通过flag &amp; SRI_MASTER判断是不是Master。 但是这个是在INFO里面上报的信息。 如果role发生变化了，就需要更新role_reported_time。 如果说原来的role是SRI_SLAVE，还需要更新slave_conf_change_time。 各种索引/遍历sentinelRedisInstance的函数梳理Redis Sentinel提供了多个函数用来索引/遍历sentinelRedisInstance getSentinelRedisInstanceByAddrAndRunID 根据ip:port和runid来寻找Instance，这个要三个都相等。但是如果指定了runid或者ip为NULL，那么它也可以不参与比较。 其原理是获得dict *instances的迭代器，然后遍历一次以比较。 sentinelGetMasterByName 这个是根据name找，所以直接是dictFind+dictGetValue sentinelRedisInstanceLookupSlave 这个是根据Slave的ip:port，从Master的slaves里面找对应的Instance。 看上去这类似getSentinelRedisInstanceByAddrAndRunID也要遍历，但由于Slave的特殊取名规则，所以事实上直接生成name，dictFind即可。 各种time梳理Instance last_pub_time last_hello_time 我们上一次从Pub/Sub听到这个Sentinel的Hello时间（所以只对SRI_SENTINEL有效）。 在sentinelProcessHelloMessage里面更新。 last_master_down_reply_time 对SENTINEL is-master-down的最后一次回复的时间。 s_down_since_time/o_down_since_time down_after_period info_refresh role_reported_time slave_conf_change_time master_link_down_time slave_reconf_sent_time failover_state_change_time 故障转移中状态变更的时间 failover_start_time 下一次FailOver开启时间，一般更新于： 当我们投了票：sentinelVoteLeader 当我们开启了FailOver：sentinelStartFailover failover_delay_logged Link cc_conn_time/pc_conn_time pc_last_activity last_avail_time 上次对端对我们发送的PING进行回复的时间，注意这个回复我们要认为是合法的才计算。 act_ping_time 根据注释，最后一个PING发出的时间，如果为0，表示刚收到一个PONG，还没有来得及发送PING，详见后文的介绍。 last_ping_time 根据注释，是我们上一次发送PING的时间。 相比act_ping_time，它的作用是避免在一段时间内发送较多的PING。 last_pong_time last_reconn_time 各种timeout梳理 failover_timeout 默认为3分钟的故障转移超时时间。 election_timeout 是默认值和failover_timeout之间的最小值。 sentinelState类和sentinel对象sentinelState是一个全局单例，表示全局上下文，我们一般用sentinel.*来访问这个单例的字段。1234struct sentinelState &#123; char myid[CONFIG_RUN_ID_SIZE+1]; /* This sentinel ID. */ uint64_t current_epoch; /* Current epoch. */... masters是从实例名到sentinelRedisInstance指针的映射。12345678... dict *masters; int tilt; /* Are we in TILT mode? */ int running_scripts; /* Number of scripts in execution right now. */ mstime_t tilt_start_time; /* When TITL started. */ mstime_t previous_time; /* Last time we ran the time handler. */ list *scripts_queue; /* Queue of user scripts to execute. */... 如果给定announce_ip:announce_port，那么在gossip（实际上就是发送Hello消息）的时候，会用这个地址而不是基于anetSockName函数检测的本地地址。1234... char *announce_ip; int announce_port;... 用来支持SIMULATE-FAILURE命令。12345... unsigned long simfailure_flags; /* Failures simulation. */ int deny_scripts_reconfig; /* Allow SENTINEL SET ... to change script paths at runtime? */&#125; sentinel; 【辨析】sentinelState和sentinelRedisInstance的区别在阅读源码的过程中，有一个混淆点，也就是说具有SRI_SENTINEL标识的sentinelRedisInstance和sentinelState有什么区别呢？其实，sentinelState表示这个Sentinel进程的描述的Sentinel的上下文，而各个sentinelRedisInstance表示这个Sentinel进程监视的所有实例，为了监视这些实例，需要从本进程创建连接。而具有SRI_SENTINEL标识的sentinelRedisInstance就表示这个进程监视的Sentinel实例。 初始化消息INFO消息这个消息是由哨兵节点发送给Master/Slave的，目的是： 发现Slave节点 确认主从关系 这个消息会用sentinelRefreshInstanceInfo这个大函数来处理。 PING消息检查实例（Master/Slave/Sentinel）是否超时/返回错误，从而决定是否进入SDOWN状态。 PUB/SUB __sentinel__:hello 频道现在，我们有了INFO来检测节点的复杂状态，PING来检测节点心跳。那么如何让所有检测当前Master的Sentinel来互相发现和交流和交流呢？因此，有了这个用来广播Hello的频道__sentinel__:hello，其作用是： 广播自己(Sentinel)的存在 发送Master的当前配置给其他Sentinel用于同步 【一个疑问】看sentinelReconnectInstance的代码，Sentinel并没有订阅__sentinel__:hello频道啊？Redis文档中却强调 Every Sentinel is subscribed to the Pub/Sub channel __sentinel__:hello of every master and replica, looking for unknown sentinels. When new sentinels are detected, they are added as sentinels of this master. （注意，这里的replica应该是由于zz正确的关系改名的，其实就是Slave。） 我在爆栈网提了个问题。 但其实这个原因是这样的，sentinelReconnectInstance的代码表示这个Sentinel没有订阅自己所监视的Sentinel的__sentinel__:hello频道，它是订阅的自己监视的Master/Slave的__sentinel__:hello频道。 这个消息的格式是：120 1 2 3 4 5 6 7sentinel_ip,sentinel_port,sentinel_runid,current_epoch,master_name,master_ip,master_port,master_config_epoch 这个协议在sentinelSendHello中通过PUBLISH命令发送，每个Sentinel在sentinelProcessHelloMessage里面处理这些消息。 此外，注意sentinelEvent这类事件机制，也可能通过PUB/SUB的方式广播，但不属于hello频道了。客户端可以订阅Sentinel的其他消息，例如配置变更信息1+switch-master &lt;master name&gt; &lt;oldip&gt; &lt;oldport&gt; &lt;newip&gt; &lt;newport&gt; 连接相比3.0版本，目前版本的Redis把连接相关的逻辑都放到了instanceLink里面。Redis Sentinel会对每个Instance维护2个Hiredis连接cc和pc，其中cc用于发送命令，而pc用来做Pub/Sub。为什么不直接用一个连接呢？有一种解释是为了防止command连接断开时，丢失广播的消息。123typedef struct instanceLink &#123; redisAsyncContext *cc; /* Hiredis context for commands. */ redisAsyncContext *pc; /* Hiredis context for Pub / Sub. */ 此外，如果我们用过redis-cli，就会发现，在键入PUBLISH命令之后，整个cli会被阻塞，从而无法再发送其他命令。但通过Hiredis客户端访问时，使用非Async命令，其实也不会阻塞。123456789101112131415161718192021222324#include "server.h"#include "hiredis.h"#include "async.h"#include &lt;ctype.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/wait.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;adapters/libev.h&gt;int main()&#123; redisContext * ctx = redisConnect("127.0.0.1", 6379); redisReply * reply = redisCommand(ctx, "SUBSCRIBE hello"); printf("retval %d %d\n",reply-&gt;len,reply-&gt;elements); for(int i = 0; i &lt; reply-&gt;elements; i++)&#123; printf("==&gt; %s\n", reply-&gt;element[i]-&gt;str); &#125; reply = redisCommand(ctx,"set a 1"); reply = redisCommand(ctx, "set a"); printf("retval 2 %d %d\n",reply-&gt;len,reply-&gt;elements); redisFree(ctx);&#125; 通过Async指令，也不会123456789101112131415void getCallback(redisAsyncContext *c, void *r, void *privdata) &#123; redisReply *reply = r; if (reply == NULL) return; printf("argv[%s]: %s\n", (char*)privdata, reply-&gt;str); redisAsyncDisconnect(c);&#125;int main () &#123; uv_loop_t* loop = uv_default_loop(); redisAsyncContext *c = redisAsyncConnect("127.0.0.1", 6379); redisLibuvAttach(c,loop); redisAsyncCommand(c, NULL, NULL, "subscribe"); redisAsyncCommand(c, NULL, NULL, "SET key a", argv[argc-1], strlen(argv[argc-1])); uv_run(loop, UV_RUN_DEFAULT); return 0;&#125; 提供Makefile如下，注意需要配置uv、ev和lua-devel12345pubsub_test: pubsub_test.c $(REDIS_SERVER_NAME) $(REDIS_CHECK_AOF_NAME) $(REDIS_LD) $(FINAL_CFLAGS) pubsub_test.c -o pubsub_test ../deps/hiredis/libhiredis.a ../deps/lua/src/liblua.a -lpthread -luv -lev $(FINAL_LIBS)p2ubsub_test: p2ubsub_test.c $(REDIS_SERVER_NAME) $(REDIS_CHECK_AOF_NAME) $(REDIS_LD) $(FINAL_CFLAGS) p2ubsub_test.c -o p2ubsub_test ../deps/hiredis/libhiredis.a ../deps/lua/src/liblua.a -lpthread -luv -lev $(FINAL_LIBS) 连接的概述连接需要解决这三个问题： 如何连接到监视的Master？ 我们会创建到我们监视的Master的cc/pc连接。 其中，cc连接表示Client连接，pc连接表示PubSub连接。 如何连接到监视的Slave？ 我们会创建到我们监视的Slave的cc/pc连接。 可是，我们如何发现某个Master的新的Slave的呢？答案是通过监视的Master的INFO命令的返回来获取的，我们可以在源码中搜索&quot;+slave&quot;来追踪这个过程。 如何连接到监视的Sentinel？ 我们会创建到我们监视的Sentinel的cc连接，不会创建pc连接。 答案是通过__sentinel__:hello来获取的。在sentinelReconnectInstance函数中会用SUBSRIBE订阅所有的Master/Slave的连接。这个命令的回调是sentinelReceiveHelloMessages，每当有消息过来，这个函数会被触发，从而来更新Sentinel。 连接的基础：HiredisSentinel使用Hiredis中提供的Async系列方法进行通信。1234// deps/hiredis/async.hredisAsyncContext *redisAsyncConnectBind(const char *ip, int port, const char *source_addr);int redisAsyncCommand(redisAsyncContext *ac, redisCallbackFn *fn, void *privdata, const char *format, ...); 初始化Link使用下面方式进行初始化123456/* Create a not yet connected link object. */instanceLink *createInstanceLink(void) &#123; instanceLink *link = zmalloc(sizeof(*link)); link-&gt;refcount = 1;... 我们讨论下到底在哪些情况下disconnected会为1： link刚创建 link被关闭：instanceLinkCloseConnection link出错：instanceLinkConnectionError 12345678910... link-&gt;disconnected = 1; link-&gt;pending_commands = 0; link-&gt;cc = NULL; link-&gt;pc = NULL; link-&gt;cc_conn_time = 0; link-&gt;pc_conn_time = 0; link-&gt;last_reconn_time = 0; link-&gt;pc_last_activity = 0;... 将act_ping_time设置为现在的时间，即使我们现在既没有建立连接，也没有ping。这个常用在我们没有连接成功时产生超时。1234567... link-&gt;act_ping_time = mstime(); link-&gt;last_ping_time = 0; link-&gt;last_avail_time = mstime(); link-&gt;last_pong_time = mstime(); return link;&#125; 解析地址createSentinelAddr这个函数用来把hostname:port解析为sentinelAddr*，稍后将会设置到ri-&gt;addr上。12345678910111213141516171819202122/* Create a sentinelAddr object and return it on success. * On error NULL is returned and errno is set to: * ENOENT: Can't resolve the hostname. * EINVAL: Invalid port number. */sentinelAddr *createSentinelAddr(char *hostname, int port) &#123; char ip[NET_IP_STR_LEN]; sentinelAddr *sa; if (port &lt; 0 || port &gt; 65535) &#123; errno = EINVAL; return NULL; &#125; if (anetResolve(NULL,hostname,ip,sizeof(ip)) == ANET_ERR) &#123; errno = ENOENT; return NULL; &#125; sa = zmalloc(sizeof(*sa)); sa-&gt;ip = sdsnew(ip); sa-&gt;port = port; return sa;&#125; sentinelReconnectInstance每一次sentinelHandleRedisInstance的事件都会调用sentinelReconnectInstance来尝试Reconnect（如果断线了的话）。在sentinelReconnectInstance函数中，在3.0版本中，检查如果对sentinelRedisInstance *ri尚未建立有网络连接，则调用redisAsyncConnect等函数建立网络连接。但现在进行了一些修改。注意，只要cc和pc之间有一个连接断掉了，那么ri-&gt;link-&gt;disconnected就是true了。这里补充说明一下，在3.0版本中，断线是作为一个单独的flag即SRI_DISCONNECTED展示的。但在目前版本中，整个连接相关的都放在link里面了，因此ri-&gt;link-&gt;disconnected也在里面。12void sentinelReconnectInstance(sentinelRedisInstance *ri) &#123; if (ri-&gt;link-&gt;disconnected == 0) return; port == 0是无效地址，那么你一开始在createSentinelAddr里面判断一下不就行了么？我想这个应该是因为port = 0表示内核为我们分配一个端口，在TCP/IP层面是有意义的，但是我们这里赋予了port = 0特殊的意义，在下面sentinelProcessHelloMessage的讲解中会进行说明。123... if (ri-&gt;addr-&gt;port == 0) return; /* port == 0 means invalid address. */... 我们对断线重连也要设置interval，为SENTINEL_PING_PERIOD。1234567... instanceLink *link = ri-&gt;link; mstime_t now = mstime(); if (now - ri-&gt;link-&gt;last_reconn_time &lt; SENTINEL_PING_PERIOD) return; ri-&gt;link-&gt;last_reconn_time = now;... 下面处理cc连接123456789101112131415161718... /* Commands connection. */ if (link-&gt;cc == NULL) &#123; link-&gt;cc = redisAsyncConnectBind(ri-&gt;addr-&gt;ip,ri-&gt;addr-&gt;port,NET_FIRST_BIND_ADDR); if (!link-&gt;cc-&gt;err &amp;&amp; server.tls_replication &amp;&amp; (instanceLinkNegotiateTLS(link-&gt;cc) == C_ERR)) &#123; sentinelEvent(LL_DEBUG,"-cmd-link-reconnection",ri,"%@ #Failed to initialize TLS"); instanceLinkCloseConnection(link,link-&gt;cc); &#125; else if (link-&gt;cc-&gt;err) &#123; sentinelEvent(LL_DEBUG,"-cmd-link-reconnection",ri,"%@ #%s", link-&gt;cc-&gt;errstr); instanceLinkCloseConnection(link,link-&gt;cc); &#125; else &#123; link-&gt;pending_commands = 0; link-&gt;cc_conn_time = mstime(); link-&gt;cc-&gt;data = link; redisAeAttach(server.el,link-&gt;cc);... 下面是两个回调函数，它们的作用都是在连接失败的时候调用instanceLinkConnectionError，将这个连接置为NULL，并且设置disconnected12345678910111213... redisAsyncSetConnectCallback(link-&gt;cc, sentinelLinkEstablishedCallback); redisAsyncSetDisconnectCallback(link-&gt;cc, sentinelDisconnectCallback); sentinelSendAuthIfNeeded(ri,link-&gt;cc); sentinelSetClientName(ri,link-&gt;cc,"cmd"); /* Send a PING ASAP when reconnecting. */ sentinelSendPing(ri); &#125; &#125;... 对于Master和Slave节点，我们处理pc连接。这里我有点疑问，Sentinel肯定需要连接PubSub的发送Hello消息和配置的啊，为啥这里不初始化pc，甚至Sentinel之间都不用pc呢？首先，我们注意到在sentinelSendHello中，SENTINEL_HELLO_CHANNEL这个通道的消息是通过cc而不是pc发送的。12345678910111213141516171819202122232425... /* Pub / Sub */ if ((ri-&gt;flags &amp; (SRI_MASTER|SRI_SLAVE)) &amp;&amp; link-&gt;pc == NULL) &#123; link-&gt;pc = redisAsyncConnectBind(ri-&gt;addr-&gt;ip,ri-&gt;addr-&gt;port,NET_FIRST_BIND_ADDR); if (!link-&gt;pc-&gt;err &amp;&amp; server.tls_replication &amp;&amp; (instanceLinkNegotiateTLS(link-&gt;pc) == C_ERR)) &#123; sentinelEvent(LL_DEBUG,"-pubsub-link-reconnection",ri,"%@ #Failed to initialize TLS"); &#125; else if (link-&gt;pc-&gt;err) &#123; sentinelEvent(LL_DEBUG,"-pubsub-link-reconnection",ri,"%@ #%s", link-&gt;pc-&gt;errstr); instanceLinkCloseConnection(link,link-&gt;pc); &#125; else &#123; int retval; link-&gt;pc_conn_time = mstime(); link-&gt;pc-&gt;data = link; redisAeAttach(server.el,link-&gt;pc); redisAsyncSetConnectCallback(link-&gt;pc, sentinelLinkEstablishedCallback); redisAsyncSetDisconnectCallback(link-&gt;pc, sentinelDisconnectCallback); sentinelSendAuthIfNeeded(ri,link-&gt;pc); sentinelSetClientName(ri,link-&gt;pc,"pubsub"); /* Now we subscribe to the Sentinels "Hello" channel. */... 下面的命令发出一个SUBSCRIBE __sentinel__:hello指令，并且用sentinelReceiveHelloMessages作为回调。真相水落石出，原来pc端口是专门用来接收Hello信息的。12345678910111213141516171819... retval = redisAsyncCommand(link-&gt;pc, sentinelReceiveHelloMessages, ri, "%s %s", sentinelInstanceMapCommand(ri,"SUBSCRIBE"), SENTINEL_HELLO_CHANNEL); if (retval != C_OK) &#123; /* If we can't subscribe, the Pub/Sub connection is useless * and we can simply disconnect it and try again. */ instanceLinkCloseConnection(link,link-&gt;pc); return; &#125; &#125; &#125; /* Clear the disconnected status only if we have both the connections * (or just the commands connection if this is a sentinel instance). */ if (link-&gt;cc &amp;&amp; (ri-&gt;flags &amp; SRI_SENTINEL || link-&gt;pc)) link-&gt;disconnected = 0;&#125;... 连接断线和宕机有什么区别？我们首先看看link-&gt;disconnected什么时候是1： 刚创建连接 关闭连接调用instanceLinkCloseConnection releaseInstanceLink sentinelUpdateSentinelAddressInAllMasters sentinelResetMaster sentinelReconnectInstance sentinelCheckSubjectivelyDown【？】 instanceLinkConnectionError sentinelLinkEstablishedCallback sentinelDisconnectCallback 入口Redis的时钟中断处理例程serverCron被server.hz为时间间隔触发。在这个函数中会异步处理很多逻辑，例如： 【databasesCron】主动expire key，当然也有在look up的时候lazy expire的，这个lazy逻辑我们介绍过 Software watchdog：watchdogScheduleSignal 更新一些统计，例如cronUpdateMemoryStats 【databasesCron】调用dictRehashMilliseconds 触发BGSAVE/AOF 【clientsCron】客户端超时 【replicationCron】Replication相关 run_with_period表示每隔多少秒执行一次。12345678// server.h#define run_with_period(_ms_) if ((_ms_ &lt;= 1000/server.hz) || !(server.cronloops%((_ms_)/(1000/server.hz))))int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) &#123;int j;...if (server.sentinel_mode) sentinelTimer();&#125; sentinelTimer是Sentinel的主例程。1234567void sentinelTimer(void) &#123; sentinelCheckTiltCondition(); sentinelHandleDictOfRedisInstances(sentinel.masters); sentinelRunPendingScripts(); sentinelCollectTerminatedScripts(); sentinelKillTimedoutScripts();... 我们持续变更Redis的”timer interrupt”的频率，这样每个Sentinel的频率都是不同的。这种不确定性避免了Sentinel在同一个时间启动，同一时间发起投票，从而导致脑裂。当然，后面还会看到在设置failover_start_time时，给每个选举epoch也设置了不同的时长，这应该是也是避免此类问题的一个思路。我们的CONFIG_DEFAULT_HZ默认是10，表示一秒钟触发10次。123... server.hz = CONFIG_DEFAULT_HZ + rand() % CONFIG_DEFAULT_HZ;&#125; 主体流程综述这些流程的时间线可能是互相重叠的。 检测S/ODOWN流程 定期发送心跳 发送是在sentinelSendPeriodicCommands中。 检查有没有SDOWN sentinelCheckSubjectivelyDown 注意，SDOWN的检测对Master、Slave和Sentinel都起作用。 一般SDOWN有几种情况： 连接超时 取决于ri-&gt;link-&gt;act_ping_time距离现在的时间。 连接关闭 取决于断线，即ri-&gt;link-&gt;disconnected后，ri-&gt;link-&gt;last_avail_time距离现在的时间。 Master报告要变成Slave，但是在一定时间内没有完成这个过程 也就是说ri-&gt;role_reported是Slave，但是ri-&gt;flags还是SRI_MASTER 如果是Master，检查有没有ODOWN 在发现了SDOWN之后，Sentinel要做下面的事： 发起的Sentinel询问其他Sentinel节点它们有没有觉这个节点SDOWN了 sentinelAskMasterStateToOtherSentinels 实际上就是发送is-master-down-by-addr命令，但这里参数里面不带自己的runid，而是传入*。 其他Sentinel节点回复消息(投票) 在sentinelCommand里面对sentinelAskMasterStateToOtherSentinels的回复。 发起的Sentinel处理投票消息 sentinelReceiveIsMasterDownReply 发起的Sentinel统计票数 sentinelHandleRedisInstance里面的第二个sentinelCheckObjectivelyDown 如何判断是否ODOWN，实际上就是统计具有SRI_MASTER_DOWN标签的实例数量。 【Q】如果是Slave/Sentinel，为什么不需要？我们判断ODOWN的目的是决定是否对一个节点进行FailOver操作。但是我们实际上并不需要对Slave和Sentinel进行FailOver。例如，一个Slave挂掉了，对于Sentinel的充其量无非就是不选择这个节点来promote了。 FailOver流程基于官方文档整理： 检查Master是否已经ODOWN 同上面的流程 检查自己是否需要开启FailOver 这一部分是在sentinelStartFailoverIfNeeded中实现的，这个函数被sentinelHandleRedisInstance调用。 在这里需要检查master-&gt;failover_timeout*2的要求，对于下面的两种情况就不能发起选举 如果自己在这个时间内投过票 【Q】这是在哪里检查？这个应该是sentinelVoteLeader里面会设置failover_start_time 如果自己在这个时间内发起过FailOver 自增current_epoch进行，并开始竞选。 这一部分逻辑以sentinelStartFailover开始，它设置FailOver状态SRI_FAILOVER_IN_PROGRESS，从而开启FailOver状态机。 之后FailOver状态机函数sentinelFailoverStateMachine会发挥作用。 然后，发送带runid的is-master-down-by-addr，这要和ODOWN状态的is-master-down-by-addr进行区分。 更新failover_start_time，这个和election_timeout一并用来控制选举超时时刻。 竞选部分 详见“选举流程”的说明。 如果竞选失败，则在master-&gt;failover_timeout*2之后，重新尝试竞选。 如果竞选成功，则 选出一个Slave，并将它升级为Master 这个选出的Slave被存放到promoted_slave里面。 详情见下面“选择合适的Slave”的说明。 在选定Slave之后，FailOver状态切换为SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE。 向被选中的Slave即promoted_slave发送SLAVEOF NO ONE，让它转变为Master 在发送完SLAVEOF之后，FailOver状态会被切换到SENTINEL_FAILOVER_STATE_WAIT_PROMOTION。 然后，我们会在sentinelRefreshInstanceInfo中监听这个节点的变化，如果这个转换是成功的，那么我们会看到role的转换。那么我们就可以将状态切换到SENTINEL_FAILOVER_STATE_RECONF_SLAVES了。否则，在sentinelFailoverWaitPromotion中就会让这个FailOver过程失败掉。 通知所有Sentinel更新配置 通过Pub/Sub，将更新后的配置传播给所有其他Sentinel，其他Sentinel对它们自己的配置进行更新。 【Q】应该通过这个函数来处理sentinelForceHelloUpdateForMaster。 通知所有Slave更新Master 向已下线Master的其他Slave发送SLAVEOF host port命令，让它们去复制新的Master。 【Q】应该是sentinelFailoverReconfNextSlave 当所有Slave都已经开始复制新的Master时，Leader终止这次FailOver操作。 对应于sentinelFailoverSwitchToPromotedSlave。主要是重新设置master和master-&gt;slaves到新的地址。期间会调用到sentinelResetMaster，这个函数会重置failover_state。 选举流程选举流程是嵌套在FailOver流程中的，但是又自成体系，所以拿出来单独说： 检查自己是否可以竞选【同FailOver流程的相同步骤】 自增current_epoch进行，并开始竞选【同FailOver流程的相同步骤】 在这里需要发送带runid的is-master-down-by-addr，表示请求其他Sentinel投票。 给自己投票 这是在sentinelVoteLeader里面的。 设置master-&gt;leader和master-&gt;leader_epoch为自己。这里leader是在master下面的一个变量，这也暗指，Sentinel能同时处理多个Master的FailOver。 其他Sentinel处理Candidate的is-master-down-by-addr 在sentinelCommand的某个分支下面： 处理是否自己觉得SDOWN了。 如果是竞选消息，那么会调用sentinelVoteLeader来投票。 Candidate在sentinelFailoverWaitStart中自旋，调用sentinelGetLeader统计票数，如果成功，会成为了Leader，进入下面FailOver的流程 如果在超时时间election_timeout内，Candidate没有获得超过quorum，自己的这次选举就失败了。 如果在超时时间内，没有一个Candidate获得更多的票数，那么等待master-&gt;failover_timeout*2后，Candidate增加epoch重新投票。由于failover_start_time在设置时会被随机增加一个值，所以导致选举超时的时间也是不定的。 与Raft协议不同，Leader并不会把自己成为Leader的消息发给其他Sentinel。 其他Sentinel等待Leader从Slave选出Master后，检测到新的Master正常工作后，就会去掉客观下线的标识，从而不需要进入故障转移流程 容易看出选举流程借鉴了Raft的思想，但其中还是有相当的区别： Sentinel将选举和“RSM/日志”分开了，“维护RSM/日志”的是Master/Slave，而进行选举的是Sentinel。 换句话说，Sentinel管的是别的集群的FailOver，而不是自己的。 选举Sentinel Leader和选择合适的Slave是分开的逻辑。 Sentinel Leader选举只考虑epoch，并不需要在is-master-down-by-addr中附上自己要Select成为新Master的Slave。 在Leader选举过程中，有两个共识需要达成：某个Master是否SDOWN/ODOWN；选择哪个Leader。 当Sentinel Leader被选出来之后，由它独自处理FailOver流程，包含Select Slave部分。 一个Sentinel节点能够处理多个Master-Slave集群的FailOver，而Raft协议只能处理自己集群的FailOver。 所以说，我们能看到epoch，比如leader_epoch、current_epoch啥的。详见“sentinelRedisInstance”这一章节中，对四个epoch的辨析。 在Raft中，Candidate竞选失败后，会过随机的时间后重新竞选，这个在Redis中并没有发现。 选择合适的Slave这个过程，是由选举出来的Leader单独负责的。 需要辨析的点 master-&gt;leader_epoch和sentinel.current_epoch 见之前“sentinelRedisInstance”这一章节中，对四个epoch的辨析。 Sentinel机制的风险12min-replicas-to-write 1min-replicas-max-lag 10 例程详解“主体流程综述”中已经概括了FailOver等流程的主要内容了，本章节对源码进行说明。由于sentinelTimer基本上包括了Redis Sentinel的所有逻辑，所以我们单独开一个章节来讲。 sentinelCheckTiltCondition判定是否要进入TILT模式。当程序发现两次sentinelTimer之间的时间差为负值或者大于SENTINEL_TILT_TRIGGER = 2000时，就会进入 TILT 模式。这通常意味着： Sentinel进程被阻塞：需要载入的数据（？）大、机器IO繁重、进程被信号停止 系统时钟出现了问题 对于这种情况，会设置tilt=1，此时这个sentinel就会罚站SENTINEL_TILT_PERIOD这么长时间。 sentinelHandleDictOfRedisInstances这个其实是Sentinel的主要逻辑。它会遍历监视的所有节点（包括Master、Slave和其他Sentinel），首先执行sentinelHandleRedisInstance。如果发现这个节点是SRI_MASTER，则对它的所有Slave和Sentinel也调用这个函数。注意这个函数并不是一个DFS或者递归。事实上他最多就两层，唯一的嵌套就是对于每个Master，找到它所有的Slave和监视它的所有Sentinel。1234567891011121314151617181920void sentinelHandleDictOfRedisInstances(dict *instances) &#123; dictIterator *di; dictEntry *de; sentinelRedisInstance *switch_to_promoted = NULL; /* There are a number of things we need to perform against every master. */ di = dictGetIterator(instances); while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *ri = dictGetVal(de); sentinelHandleRedisInstance(ri); if (ri-&gt;flags &amp; SRI_MASTER) &#123; sentinelHandleDictOfRedisInstances(ri-&gt;slaves); sentinelHandleDictOfRedisInstances(ri-&gt;sentinels); if (ri-&gt;failover_state == SENTINEL_FAILOVER_STATE_UPDATE_CONFIG) &#123; switch_to_promoted = ri; &#125; &#125; &#125;... 当一个Slave在SENTINEL_FAILOVER_STATE_UPDATE_CONFIG时，说明此时所有Slave已经完成同步，要进行配置更新。此时需要调用sentinelFailoverSwitchToPromotedSlave函数。这个是FailOver自动机的最后一步，我们将它迁移到后面进行讲解。12345... if (switch_to_promoted) sentinelFailoverSwitchToPromotedSlave(switch_to_promoted); dictReleaseIterator(di);&#125; sentinelHandleRedisInstance 监控部分1234567/* Perform scheduled operations for the specified Redis instance. */void sentinelHandleRedisInstance(sentinelRedisInstance *ri) &#123; /* ========== MONITORING HALF ============ */ /* Every kind of instance */ sentinelReconnectInstance(ri); sentinelSendPeriodicCommands(ri);... sentinelReconnectInstance见上文连接部分 sentinelSendPeriodicCommandssentinelSendPeriodicCommands负责向sentinelRedisInstance *ri发送命令。这里的注释说link是一个instanceLink对象。这个对象的作用是为了节约hiredis连接建立的数量，如果有5个Sentinel监视100个Master，那么会创建5个连接而不是500个连接。这一段有点令人费解，因为就算是这5个Sentinel共享链接，那也要它们两两互联的5*4共同对外的100个连接啊？这个查看sentinelTryConnectionSharing会得到解答。TODO1234567891011/* Send periodic PING, INFO, and PUBLISH to the Hello channel to * the specified master or slave instance. */void sentinelSendPeriodicCommands(sentinelRedisInstance *ri) &#123; mstime_t now = mstime(); mstime_t info_period, ping_period; int retval; /* Return ASAP if we have already a PING or INFO already pending, or * in the case the instance is not properly connected. */ if (ri-&gt;link-&gt;disconnected) return;... 因为INFO/PING/PUBLISH都不是极端重要的指令，所以我们对pending_commands设定了一个上限SENTINEL_MAX_PENDING_COMMANDS。当然还有一个兜底的情况就是当命令太多了，连接就会断掉触发重连。12345...// SENTINEL_MAX_PENDING_COMMANDS = 100 if (ri-&gt;link-&gt;pending_commands &gt;= SENTINEL_MAX_PENDING_COMMANDS * ri-&gt;link-&gt;refcount) return;... 如果ri是一个Slave节点，并且它对应的Master节点出于ODOWN，或者FAILOVER状态，或者，那么我们应该加快发送INFO的频率到1000ms一次，否则就是SENTINEL_INFO_PERIOD = 10000ms，此时Slaves中会有被其他Sentinel或者sysadmin提升为Master的情况。此外，当master_link_down_time不等于0（应该是Slave从Master断开了，导致Replication过程中断），也要更频繁的INFO，从而有一个更加清楚的断连时间记录。12345678910... if ((ri-&gt;flags &amp; SRI_SLAVE) &amp;&amp; ((ri-&gt;master-&gt;flags &amp; (SRI_O_DOWN|SRI_FAILOVER_IN_PROGRESS)) || (ri-&gt;master_link_down_time != 0))) &#123; info_period = 1000; &#125; else &#123; info_period = SENTINEL_INFO_PERIOD; &#125;... 下面设置PING指令的间隔。down_after_period表示实例经过down_after_period之后会被认为SDOWN。这个值等于master-&gt;down_after_period，如果自己是Master的话，就取SENTINEL_DEFAULT_DOWN_AFTER = 3000012345678... /* We ping instances every time the last received pong is older than * the configured 'down-after-milliseconds' time, but every second * anyway if 'down-after-milliseconds' is greater than 1 second. */ // #define SENTINEL_PING_PERIOD 1000 ping_period = ri-&gt;down_after_period; if (ping_period &gt; SENTINEL_PING_PERIOD) ping_period = SENTINEL_PING_PERIOD;... 下面调用redisAsyncCommand对发送INFO，我们不需要向Sentinel发送INFO，这是因为我们不需要知道Sentinel的Slave和主从关系（其实也没有）。如果info_refresh为0表示我们从来没收到过INFO消息。123456789101112... /* Send INFO to masters and slaves, not sentinels. */ if ((ri-&gt;flags &amp; SRI_SENTINEL) == 0 &amp;&amp; (ri-&gt;info_refresh == 0 || (now - ri-&gt;info_refresh) &gt; info_period)) &#123; retval = redisAsyncCommand(ri-&gt;link-&gt;cc, sentinelInfoReplyCallback, ri, "%s", sentinelInstanceMapCommand(ri,"INFO")); if (retval == C_OK) ri-&gt;link-&gt;pending_commands++; &#125;... 下面是发送PING，我们同样也要PING。相比3.0版本，现在对于last_ping_time超过ping_period/2的情况也会发送PING了。这样的目的是什么呢？1234567... /* Send PING to all the three kinds of instances. */ if ((now - ri-&gt;link-&gt;last_pong_time) &gt; ping_period &amp;&amp; (now - ri-&gt;link-&gt;last_ping_time) &gt; ping_period/2) &#123; sentinelSendPing(ri); &#125;... 下面通过PubSub发送一个Hello消息。这个消息是为了达成在“消息”章节中提到的两个目标。我们将在后面详细解读。123456... /* PUBLISH hello messages to all the three kinds of instances. */ if ((now - ri-&gt;last_pub_time) &gt; SENTINEL_PUBLISH_PERIOD) &#123; sentinelSendHello(ri); &#125;&#125; 【接上】sentinelInfoReplyCallbackINFO命令的回复会被注册到来处理123456789101112void sentinelInfoReplyCallback(redisAsyncContext *c, void *reply, void *privdata) &#123; sentinelRedisInstance *ri = privdata; instanceLink *link = c-&gt;data; redisReply *r; if (!reply || !link) return; link-&gt;pending_commands--; r = reply; if (r-&gt;type == REDIS_REPLY_STRING) sentinelRefreshInstanceInfo(ri,r-&gt;str);&#125; 这个函数的主干实际上就是调用sentinelRefreshInstanceInfo，这个函数超级大，用来解析INFO返回的信息，我们不在这里全部列举出来。在sentinelFailoverWaitPromotion等地方，我们会将这个函数中涉及的相关部分拎出来讲。 sentinelSendHello这个函数通过Pub/Sub发送Hello指令到ri，完成“消息”章节中提到的两个目标。消息的格式如下。1sentinel_ip,sentinel_port,sentinel_runid,current_epoch,master_name,master_ip,master_port,master_config_epoch 如果PUBLISH指令成功入队，那么就返回成功。在3.0版本中，通过anetSockName直接获得ip，直接用server.port。但在这里会复杂一点。123456789101112131415161718192021222324int sentinelSendHello(sentinelRedisInstance *ri) &#123; char ip[NET_IP_STR_LEN]; char payload[NET_IP_STR_LEN+1024]; int retval; char *announce_ip; int announce_port; sentinelRedisInstance *master = (ri-&gt;flags &amp; SRI_MASTER) ? ri : ri-&gt;master; sentinelAddr *master_addr = sentinelGetCurrentMasterAddress(master); if (ri-&gt;link-&gt;disconnected) return C_ERR; /* Use the specified announce address if specified, otherwise try to * obtain our own IP address. */ if (sentinel.announce_ip) &#123; announce_ip = sentinel.announce_ip; &#125; else &#123; if (anetSockName(ri-&gt;link-&gt;cc-&gt;c.fd,ip,sizeof(ip),NULL) == -1) return C_ERR; announce_ip = ip; &#125; if (sentinel.announce_port) announce_port = sentinel.announce_port; else if (server.tls_replication &amp;&amp; server.tls_port) announce_port = server.tls_port; else announce_port = server.port;... 下面我们生成要广播的配置，其格式是12sentinel_ip,sentinel_port,sentinel_runid,current_epoch ,master_name ,master_ip ,master_port ,master_config_epochannounce_ip,announce_port,sentinel.myid ,sentinel.current_epoch,master-&gt;name,master_addr-&gt;ip,master_addr-&gt;port,master-&gt;config_epoch 下面就是执行一个PUBLISH命令。有趣的是这个PUBLISH是通过cc而不是pc发送的。123456789101112131415161718... /* Format and send the Hello message. */ snprintf(payload,sizeof(payload), "%s,%d,%s,%llu," /* Info about this sentinel. */ "%s,%s,%d,%llu", /* Info about current master. */ announce_ip, announce_port, sentinel.myid, (unsigned long long) sentinel.current_epoch, /* --- */ master-&gt;name,master_addr-&gt;ip,master_addr-&gt;port, (unsigned long long) master-&gt;config_epoch); retval = redisAsyncCommand(ri-&gt;link-&gt;cc, sentinelPublishReplyCallback, ri, "%s %s %s", sentinelInstanceMapCommand(ri,"PUBLISH"), SENTINEL_HELLO_CHANNEL,payload); if (retval != C_OK) return C_ERR; ri-&gt;link-&gt;pending_commands++; return C_OK;&#125; 【接上】sentinelReceiveHelloMessages1234567891011121314151617181920212223242526272829/* This is our Pub/Sub callback for the Hello channel. It's useful in order * to discover other sentinels attached at the same master. */void sentinelReceiveHelloMessages(redisAsyncContext *c, void *reply, void *privdata) &#123; sentinelRedisInstance *ri = privdata; redisReply *r; UNUSED(c); if (!reply || !ri) return; r = reply; /* Update the last activity in the pubsub channel. Note that since we * receive our messages as well this timestamp can be used to detect * if the link is probably disconnected even if it seems otherwise. */ ri-&gt;link-&gt;pc_last_activity = mstime(); /* Sanity check in the reply we expect, so that the code that follows * can avoid to check for details. */ if (r-&gt;type != REDIS_REPLY_ARRAY || r-&gt;elements != 3 || r-&gt;element[0]-&gt;type != REDIS_REPLY_STRING || r-&gt;element[1]-&gt;type != REDIS_REPLY_STRING || r-&gt;element[2]-&gt;type != REDIS_REPLY_STRING || strcmp(r-&gt;element[0]-&gt;str,"message") != 0) return; /* We are not interested in meeting ourselves */ if (strstr(r-&gt;element[2]-&gt;str,sentinel.myid) != NULL) return; sentinelProcessHelloMessage(r-&gt;element[2]-&gt;str, r-&gt;element[2]-&gt;len);&#125; sentinelProcessHelloMessage这个函数会处理包括新Sentinel发现、Sentinel地址变更、TODO之类的逻辑。这个函数在Master/Slave实例中处理收到的Hello信息，或者sent directly to this sentinel via the (fake) PUBLISH command of Sentinel.再次复习一下消息的格式120 1 2 3 4 5 6 7sentinel_ip,sentinel_port,sentinel_runid,current_epoch,master_name,master_ip,master_port,master_config_epoch 下面看具体函数，主要过程是： 找到监控的master 尝试加入新Sentinel 检查runid 检查ip:port 尝试更新current_epoch 123456789void sentinelProcessHelloMessage(char *hello, int hello_len) &#123; int numtokens, port, removed, master_port; uint64_t current_epoch, master_config_epoch; char **token = sdssplitlen(hello, hello_len, ",", 1, &amp;numtokens); sentinelRedisInstance *si, *master; if (numtokens == 8) &#123; /* Obtain a reference to the master this hello message is about */... 首先根据master_name找到我们Sentinel中对应的Instance对象master，如果找不到，就忽略这个请求。【Q】 TODO所以我蛮好奇这个频道像一个大杂烩一样的，会不会造成处理的开销；抑或，我们可以对每一个Master建立一个单独的频道，因为Pub/Sub是允许pattern matching的。12345678... master = sentinelGetMasterByName(token[4]); if (!master) goto cleanup; /* Unknown master, skip the message. */ /* First, try to see if we already have this sentinel. */ port = atoi(token[1]); master_port = atoi(token[6]);... 定位到这个Hello消息涉及的Master节点后，我们尝试更新监视这个Master的Sentinel列表。于是，我们去找符合sentinel_ip:sentinel_port和master_name的Sentinel节点si。这里si是一个sentinelRedisInstance，表示sentinel_ip:sentinel_port这个Sentinel节点，也就是我们消息的发送方。123456... si = getSentinelRedisInstanceByAddrAndRunID( master-&gt;sentinels,token[0],port,token[2]); current_epoch = strtoull(token[3],NULL,10); master_config_epoch = strtoull(token[7],NULL,10);... 如果没找到，说明这是一个新发现的Sentinel，我们需要加到master-&gt;sentinels里面。在加入之前，需要做一些额外处理。首先，要移除掉所有具有相同runid的Sentinel，也就是说，可能有runid相同的Sentinel，但是他们的ip:port不同。这是因为可能同一个Sentinel的地址变了，我们要以runid为准来区分不同的Sentinel。这个过程需要扫一遍master-&gt;sentinels。1234567... if (!si) &#123; /* If not, remove all the sentinels that have the same runid * because there was an address change, and add the same Sentinel * with the new address back. */ removed = removeMatchingSentinelFromMaster(master,token[2]);... removeMatchingSentinelFromMaster函数会返回removed表示实际上移除了多少个节点。123456... if (removed) &#123; sentinelEvent(LL_NOTICE,"+sentinel-address-switch",master, "%@ ip %s port %d for %s", token[0],port,token[2]); &#125; else &#123;... 之前，我们检查了是否有runid相同的实例。然后，我们还要检查sentinels中是否还有ip:port相同的Sentinel实例。123456789... /* Check if there is another Sentinel with the same address this * new one is reporting. What we do if this happens is to set its * port to 0, to signal the address is invalid. We'll update it * later if we get an HELLO message. */ sentinelRedisInstance *other = getSentinelRedisInstanceByAddrAndRunID( master-&gt;sentinels, token[0],port,NULL);... 如果有的话，我们要把这个旧的实例的port改为0，从而表示这个地址是Invalid的。然后，我们要调用sentinelUpdateSentinelAddressInAllMasters对other进行修改，这个修改的目的是把所有Master中other这个Sentinel的连接断开。12345678... if (other) &#123; sentinelEvent(LL_NOTICE,"+sentinel-invalid-addr",other,"%@"); other-&gt;addr-&gt;port = 0; /* It means: invalid address. */ sentinelUpdateSentinelAddressInAllMasters(other); &#125; &#125;... 新建一个runid的token[2]的Sentinel，并使用请求发来的sentinel_ip:sentinel_port作为地址。token[2]是传过来的runid，在createSentinelRedisInstance中会被设置成Sentinel的name。createSentinelRedisInstance函数会直接把si加到master-&gt;sentinel里面。12345... /* Add the new sentinel. */ si = createSentinelRedisInstance(token[2],SRI_SENTINEL, token[0],port,master-&gt;quorum,master);... 下面这个函数就是之前提到的500个连接复用到5个的函数。123456789... if (si) &#123; if (!removed) sentinelEvent(LL_NOTICE,"+sentinel",si,"%@"); /* The runid is NULL after a new instance creation and * for Sentinels we don't have a later chance to fill it, * so do it now. */ si-&gt;runid = sdsnew(token[2]); sentinelTryConnectionSharing(si);... 下面又一次调用sentinelUpdateSentinelAddressInAllMasters，其目的是和上面的sentinelUpdateSentinelAddressInAllMasters是类似的。但是上面的调用是用来处理!removed的情况下，如果还有ip:port相同的实例的情况。而这个是处理remove的情况，也就是说已经找到一个runid相同的。123456... if (removed) sentinelUpdateSentinelAddressInAllMasters(si); sentinelFlushConfig(); &#125; &#125;... 接着，我们需要尝试通过对端的current_epoch来更新自己的current_epoch。123456789... /* Update local current_epoch if received current_epoch is greater.*/ if (current_epoch &gt; sentinel.current_epoch) &#123; sentinel.current_epoch = current_epoch; sentinelFlushConfig(); sentinelEvent(LL_WARNING,"+new-epoch",master,"%llu", (unsigned long long) sentinel.current_epoch); &#125;... master_config_epoch字段，来源于其他Sentinel在发消息时传输的自己的master-&gt;config_epoch字段。通过比较远端的和自己的master-&gt;config_epoch，如果我们的较小，则需要更新Master的配置信息。123456... /* Update master info if received configuration is newer. */ if (si &amp;&amp; master-&gt;config_epoch &lt; master_config_epoch) &#123; // 我们同样将`config_epoch`同步到最新。 master-&gt;config_epoch = master_config_epoch;... 如果我们发现对方传来的Master的地址token[5]:master_port和我们的地址master-&gt;addr是不同的，就TODO。123456789101112131415161718192021222324252627282930... if (master_port != master-&gt;addr-&gt;port || strcmp(master-&gt;addr-&gt;ip, token[5])) &#123; sentinelAddr *old_addr; sentinelEvent(LL_WARNING,"+config-update-from",si,"%@"); sentinelEvent(LL_WARNING,"+switch-master", master,"%s %s %d %s %d", master-&gt;name, master-&gt;addr-&gt;ip, master-&gt;addr-&gt;port, token[5], master_port); old_addr = dupSentinelAddr(master-&gt;addr); sentinelResetMasterAndChangeAddress(master, token[5], master_port); sentinelCallClientReconfScript(master, SENTINEL_OBSERVER,"start", old_addr,master-&gt;addr); releaseSentinelAddr(old_addr); &#125; &#125; /* Update the state of the Sentinel. */ if (si) si-&gt;last_hello_time = mstime(); &#125;cleanup: sdsfreesplitres(token,numtokens);&#125;... sentinelUpdateSentinelAddressInAllMasters当我们发现某一个Sentinel在Hello信息中报告了一个新的地址，我们就需要在所有Master中更新这个Sentinel的上下文，并进行重连。返回有多少地址发生了重连。123456789int sentinelUpdateSentinelAddressInAllMasters(sentinelRedisInstance *ri) &#123; serverAssert(ri-&gt;flags &amp; SRI_SENTINEL); dictIterator *di; dictEntry *de; int reconfigured = 0; di = dictGetIterator(sentinel.masters); while((de = dictNext(di)) != NULL) &#123;... 这个用法看起来很奇怪，C语言里面的逗号表达式的含义是从左到右执行，并且以最后一个表达式的值作为返回值。我们展开来得到的是sentinelRedisInstance *master = ((de)-&gt;v.val), *match，可是我们还是不知道match是在哪里定义的。所123... sentinelRedisInstance *master = dictGetVal(de), *match;... 以我猜想它实际上是可以拆成下面这两行12sentinelRedisInstance *master = dictGetVal(de);sentinelRedisInstance *match; 下面，我们查找这个Master中所有runid相等的Sentinel，并把它们关掉。123456789101112131415... match = getSentinelRedisInstanceByAddrAndRunID(master-&gt;sentinels, NULL,0,ri-&gt;runid); /* If there is no match, this master does not know about this * Sentinel, try with the next one. */ if (match == NULL) continue; /* Disconnect the old links if connected. */ if (match-&gt;link-&gt;cc != NULL) instanceLinkCloseConnection(match-&gt;link,match-&gt;link-&gt;cc); if (match-&gt;link-&gt;pc != NULL) instanceLinkCloseConnection(match-&gt;link,match-&gt;link-&gt;pc); if (match == ri) continue; /* Address already updated for it. */... 释放原来的地址match-&gt;addr，复制新的地址ri-&gt;addr。这个地址包含addr和port。123456789101112 /* Update the address of the matching Sentinel by copying the address * of the Sentinel object that received the address update. */ releaseSentinelAddr(match-&gt;addr); match-&gt;addr = dupSentinelAddr(ri-&gt;addr); reconfigured++; &#125; dictReleaseIterator(di); if (reconfigured) sentinelEvent(LL_NOTICE,"+sentinel-address-update", ri, "%@ %d additional matching instances", reconfigured); return reconfigured;&#125; sentinelTryConnectionSharing这个函数尝试为传入的ri（它必须是一个Sentinel）分享已有的link，被分享的连接来自于我们这个Sentinel已有的对这个Master的连接。有点难懂，我们先看下实现。这个函数会遍历所有的Master Instance，即sentinel.masters。一旦我们找到ri-&gt;master对应的实例，我们就复用这个实例的连接。12345678910111213141516171819202122232425262728293031323334353637383940414243/* * This function will attempt to share the instance link we already have * for the same Sentinel in the context of a different master, with the * instance we are passing as argument. * * This way multiple Sentinel objects that refer all to the same physical * Sentinel instance but in the context of different masters will use * a single connection, will send a single PING per second for failure * detection and so forth. * * Return C_OK if a matching Sentinel was found in the context of a * different master and sharing was performed. Otherwise C_ERR * is returned. */int sentinelTryConnectionSharing(sentinelRedisInstance *ri) &#123; serverAssert(ri-&gt;flags &amp; SRI_SENTINEL); dictIterator *di; dictEntry *de; if (ri-&gt;runid == NULL) return C_ERR; /* No way to identify it. */ if (ri-&gt;link-&gt;refcount &gt; 1) return C_ERR; /* Already shared. */ di = dictGetIterator(sentinel.masters); while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *master = dictGetVal(de), *match; /* We want to share with the same physical Sentinel referenced * in other masters, so skip our master. */ if (master == ri-&gt;master) continue; match = getSentinelRedisInstanceByAddrAndRunID(master-&gt;sentinels, NULL,0,ri-&gt;runid); if (match == NULL) continue; /* No match. */ if (match == ri) continue; /* Should never happen but... safer. */ /* We identified a matching Sentinel, great! Let's free our link * and use the one of the matching Sentinel. */ releaseInstanceLink(ri-&gt;link,NULL); ri-&gt;link = match-&gt;link; match-&gt;link-&gt;refcount++; dictReleaseIterator(di); return C_OK; &#125; dictReleaseIterator(di); return C_ERR;&#125; 【接上】sentinelPublishReplyCallback这个命令的回调主要用来更新last_pub_time1234567891011121314void sentinelPublishReplyCallback(redisAsyncContext *c, void *reply, void *privdata) &#123; sentinelRedisInstance *ri = privdata; instanceLink *link = c-&gt;data; redisReply *r; if (!reply || !link) return; link-&gt;pending_commands--; r = reply; /* Only update pub_time if we actually published our message. Otherwise * we'll retry again in 100 milliseconds. */ if (r-&gt;type != REDIS_REPLY_ERROR) ri-&gt;last_pub_time = mstime();&#125; sentinelHandleRedisInstance 处理部分首先是对tilt的处理。1234567 /* ============== ACTING HALF ============= */ if (sentinel.tilt) &#123; if (mstime()-sentinel.tilt_start_time &lt; SENTINEL_TILT_PERIOD) return; sentinel.tilt = 0; sentinelEvent(LL_WARNING,"-tilt",NULL,"#tilt mode exited"); &#125;... 下面检查是否是SDOWN状态1234... /* Every kind of instance */ sentinelCheckSubjectivelyDown(ri);... 如果是Master的话，需要通过sentinelCheckObjectivelyDown查看是否进入的ODOWN状态，并设置对应的SRI_O_DOWN位。在这之后，就需要通过sentinelStartFailoverIfNeeded查看是否需要启动FailOver了。我们需要注意，每一次的主循环，无论是不是在FailOver/SDOWN状态，都会对监视的所有Master节点执行sentinelCheckObjectivelyDown、sentinelFailoverStateMachine、sentinelAskMasterStateToOtherSentinels这几个函数，所以在这些函数里面会看到，他们都会去判断是否是FailOver/ODOWN/SDOWN。12345... /* Masters and slaves */ if (ri-&gt;flags &amp; (SRI_MASTER|SRI_SLAVE)) &#123; /* Nothing so far. */ &#125; 【Q】sentinelAskMasterStateToOtherSentinels会被以SENTINEL_ASK_FORCED和SENTINEL_NO_FLAGS这两个参数调用两次。可以发现，只要执行了sentinelStartFailoverIfNeeded并返回true，那sentinelStartFailover肯定已经被调用过了。这也就意味着此时已经ODOWN了，并且在FailOver了。为什么还要调用这个函数，问对方是不是is-master-down-by-addr呢？ 调用A：sentinelStartFailoverIfNeeded返回值为true 调用A的那一次是因为我们开启了FailOver，此时我们非常确定ODOWN了，所以加上了SENTINEL_ASK_FORCED。 调用B：在sentinelFailoverStateMachine之后再调用一次 调用B是routine work，这是必要的。比如说一个Sentinel发现SDOWN了，此时并不一定要开启FailOver，所以他需要通过这一个sentinelCheckObjectivelyDown，去询问其他Sentinel是不是这个节点DOWN掉了。收集到的SRI_MASTER_DOWN会被sentinelCheckObjectivelyDown用来判定是不是发生了ODOWN。 如果集群状态正常的话，因为ODOWN条件不满足，在函数调用的开始就会被abort掉，我们不用担心副作用。 123456789 /* Only masters */ if (ri-&gt;flags &amp; SRI_MASTER) &#123; sentinelCheckObjectivelyDown(ri); if (sentinelStartFailoverIfNeeded(ri)) sentinelAskMasterStateToOtherSentinels(ri,SENTINEL_ASK_FORCED); sentinelFailoverStateMachine(ri); sentinelAskMasterStateToOtherSentinels(ri,SENTINEL_NO_FLAGS); &#125;&#125; sentinelCheckSubjectivelyDown这个函数用来判断是不是SDOWN。我们判断Sentinel、Master和Slave是不是SDOWN。 首先是计算上次PING之后的未响应时间。这里比3.0的代码多了一个ri-&gt;link-&gt;disconnected的判断，这个是为什么呢？last_avail_time在收到对PING的三个合法回复的时候会进行更新。act_ping_time表示最后一个PING发出的时间，如果为0，表示刚收到一个PONG（见sentinelPingReplyCallback函数），并且还没有发出下一个PING。对应地，还有一个last_ping_time，这个不会在收到PONG的时候置0。12345678void sentinelCheckSubjectivelyDown(sentinelRedisInstance *ri) &#123; mstime_t elapsed = 0; if (ri-&gt;link-&gt;act_ping_time) elapsed = mstime() - ri-&gt;link-&gt;act_ping_time; else if (ri-&gt;link-&gt;disconnected) elapsed = mstime() - ri-&gt;link-&gt;last_avail_time;... 如果检测到连接的活跃度(activity)很低，也就是说长时间没有反应，那么考虑断开，等待下一轮重连。这里重新连接是sentinelReconnectInstance控制的。首先检查cc连接的活跃度，如果连接了至少SENTINEL_MIN_LINK_RECONNECT_PERIOD，并且仍然有一个pending了一半超时时间的PING，那么调用instanceLinkCloseConnection关闭连接。1234567891011121314... // #define SENTINEL_MIN_LINK_RECONNECT_PERIOD 15000 if (ri-&gt;link-&gt;cc &amp;&amp; (mstime() - ri-&gt;link-&gt;cc_conn_time) &gt; SENTINEL_MIN_LINK_RECONNECT_PERIOD &amp;&amp; ri-&gt;link-&gt;act_ping_time != 0 &amp;&amp; /* There is a pending ping... */ /* The pending ping is delayed, and we did not receive * error replies as well. */ (mstime() - ri-&gt;link-&gt;act_ping_time) &gt; (ri-&gt;down_after_period/2) &amp;&amp; (mstime() - ri-&gt;link-&gt;last_pong_time) &gt; (ri-&gt;down_after_period/2)) &#123; instanceLinkCloseConnection(ri-&gt;link,ri-&gt;link-&gt;cc); &#125;... 然后检查pc连接的活跃度，如果连接了超过SENTINEL_MIN_LINK_RECONNECT_PERIOD，并且在SENTINEL_PUBLISH_PERIOD * 3时间内没有再有活动。12345678910... // #define SENTINEL_PUBLISH_PERIOD 2000 if (ri-&gt;link-&gt;pc &amp;&amp; (mstime() - ri-&gt;link-&gt;pc_conn_time) &gt; SENTINEL_MIN_LINK_RECONNECT_PERIOD &amp;&amp; (mstime() - ri-&gt;link-&gt;pc_last_activity) &gt; (SENTINEL_PUBLISH_PERIOD*3)) &#123; instanceLinkCloseConnection(ri-&gt;link,ri-&gt;link-&gt;pc); &#125;... 下面就是SDOWN判断了，如果下面两个条件满足，设置SDOWN这个flag 对方Instance无应答这里的down_after_period即如下，默认是30秒。 1sentinel down-after-milliseconds mymaster 60000 目前我们认为该Instance是Master但它报告它将成为Slave但经过down_after_period和两个SENTINEL_INFO_PERIOD之后，这个操作仍然没有完成。 123456789101112131415... if (elapsed &gt; ri-&gt;down_after_period || (ri-&gt;flags &amp; SRI_MASTER &amp;&amp; ri-&gt;role_reported == SRI_SLAVE &amp;&amp; mstime() - ri-&gt;role_reported_time &gt; (ri-&gt;down_after_period+SENTINEL_INFO_PERIOD*2))) &#123; /* Is subjectively down */ if ((ri-&gt;flags &amp; SRI_S_DOWN) == 0) &#123; sentinelEvent(LL_WARNING,"+sdown",ri,"%@"); ri-&gt;s_down_since_time = mstime(); ri-&gt;flags |= SRI_S_DOWN; &#125;&#125; else &#123;... 否则移除SDOWN状态。注意，经过搜寻源码，只有这个地方会移除SRI_S_DOWN这个标签。12345678... /* Is subjectively up */ if (ri-&gt;flags &amp; SRI_S_DOWN) &#123; sentinelEvent(LL_WARNING,"-sdown",ri,"%@"); ri-&gt;flags &amp;= ~(SRI_S_DOWN|SRI_SCRIPT_KILL_SENT); &#125; &#125;&#125; sentinelCheckObjectivelyDown注意这里的ODOWN使用的是weak quorum，这里的weak体现在票数统计是在给定时间范围内，而不是在某个时间点上达成一致。这里可以了解一下strong quorum algorithm和流言协议(Gossip)。下面这个循环遍历所有Sentinel，并且统计具有SRI_MASTER_DOWN的数量，是否达到master-&gt;quorum。【Q】容易看到，这里是直接算quorum了，那么是在哪里请求投票的呢？答案是sentinelAskMasterStateToOtherSentinels，后面会讲。1234567891011121314151617void sentinelCheckObjectivelyDown(sentinelRedisInstance *master) &#123; dictIterator *di; dictEntry *de; unsigned int quorum = 0, odown = 0; if (master-&gt;flags &amp; SRI_S_DOWN) &#123; /* Is down for enough sentinels? */ quorum = 1; /* the current sentinel. */ /* Count all the other sentinels. */ di = dictGetIterator(master-&gt;sentinels); while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *ri = dictGetVal(de); if (ri-&gt;flags &amp; SRI_MASTER_DOWN) quorum++; &#125; dictReleaseIterator(di);... 如果票数达标，就设置ODOWN。1234... if (quorum &gt;= master-&gt;quorum) odown = 1; &#125;... 对于ODOWN的情况，需要调用sentinelEvent事件发送到日志、PubSub，以及用户提醒脚本，然后在本地也要进行设置。123456789 /* Set the flag accordingly to the outcome. */ if (odown) &#123; if ((master-&gt;flags &amp; SRI_O_DOWN) == 0) &#123; sentinelEvent(LL_WARNING,"+odown",master,"%@ #quorum %d/%d", quorum, master-&gt;quorum); master-&gt;flags |= SRI_O_DOWN; master-&gt;o_down_since_time = mstime(); &#125;... 对从ODOWN恢复的情况，要同理进行恢复。12345678... &#125; else &#123; if (master-&gt;flags &amp; SRI_O_DOWN) &#123; sentinelEvent(LL_WARNING,"-odown",master,"%@"); master-&gt;flags &amp;= ~SRI_O_DOWN; &#125; &#125;&#125; 检查quorum参数目前版本提供一个ckquorum命令用来判断Quorum的数量是否合法。首先统计有多少能够使用的Sentinel节点。voters表示从Master中记录的sentinels数量，加上自己。然后遍历所有的Sentinel，统计出没有SDOWN和ODOWN的节点的数量为usable。12345678910111213141516int sentinelIsQuorumReachable(sentinelRedisInstance *master, int *usableptr) &#123; dictIterator *di; dictEntry *de; int usable = 1; /* Number of usable Sentinels. Init to 1 to count myself. */ int result = SENTINEL_ISQR_OK; int voters = dictSize(master-&gt;sentinels)+1; /* Known Sentinels + myself. */ di = dictGetIterator(master-&gt;sentinels); while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *ri = dictGetVal(de); if (ri-&gt;flags &amp; (SRI_S_DOWN|SRI_O_DOWN)) continue; usable++; &#125; dictReleaseIterator(di);... 如果需要的quorum数量大于usable，说明quorum永远达不到，返回错误。123... if (usable &lt; (int)master-&gt;quorum) result |= SENTINEL_ISQR_NOQUORUM;... 如果usable没有达到多数，那么就说明这个决议即使达成也是无效力的。12345... if (usable &lt; voters/2+1) result |= SENTINEL_ISQR_NOAUTH; if (usableptr) *usableptr = usable; return result;&#125; 注意，对于quorum至少要占voters绝对多数的控制在sentinelGetLeader下面。 sentinelStartFailoverIfNeeded在判断完ODOWN之后，就需要判断是否要启动故障转移(FailOver)过程。在执行前，需要判断是否满足三个条件。 再次检查是否ODOWN 如果这个Master在FailOver过程中，我们没必要再重启一个FailOver 如果刚FailOver完，也不进行FailOver这个时间是master-&gt;failover_timeout*2，其中master-&gt;failover_timeout默认值是SENTINEL_DEFAULT_FAILOVER_TIMEOUT =(60*3*1000)，是3分钟。【Q】这点也许是为了防止过于频繁的进行FailOver操作，但是既然故障了，又不FailOver那怎么办呢？这里的意思应该是此时这个Sentinel已收到了其他Sentinel的那票，说明其他Sentinel正在FailOver，所以要等待这么长时间再FailOver。这个有点类似于Raft里面的Election Timeout机制。 下面查看代码，这对应了前两点条件1234567int sentinelStartFailoverIfNeeded(sentinelRedisInstance *master) &#123; /* We can't failover if the master is not in O_DOWN state. */ if (!(master-&gt;flags &amp; SRI_O_DOWN)) return 0; /* Failover already in progress? */ if (master-&gt;flags &amp; SRI_FAILOVER_IN_PROGRESS) return 0;... 如上面所讲，第三个条件将“CD时间”设置在了master-&gt;failover_timeout*2，也就是说，要满足failover_start_time之后这么久时间才能开启FailOver。那么failover_start_time是在哪里被设置的呢？可以参考上文的说明。 1234567891011121314151617181920.../* Last failover attempt started too little time ago? */ if (mstime() - master-&gt;failover_start_time &lt; master-&gt;failover_timeout*2) &#123; if (master-&gt;failover_delay_logged != master-&gt;failover_start_time) &#123; time_t clock = (master-&gt;failover_start_time + master-&gt;failover_timeout*2) / 1000; char ctimebuf[26]; ctime_r(&amp;clock,ctimebuf); ctimebuf[24] = '\0'; /* Remove newline. */ master-&gt;failover_delay_logged = master-&gt;failover_start_time; serverLog(LL_WARNING, "Next failover delay: I will not start a failover before %s", ctimebuf); &#125; return 0;...&#125; 在三个return之后，到了FailOver的执行过程。需要注意的是，执行FailOver的Sentinel不一定是发起FailOver的Sentinel，这是因为FailOver总是由Sentinel里面的Leader执行的。但当FailOver发起之后会导致选举，所以可能到时候Leader也换掉了。这个和Raft中有点不一样，Raft中新Leader是不能提交老Leader的日志条目的。 1234... sentinelStartFailover(master); return 1;&#125; 下面查看函数sentinelStartFailover，这个函数被执行的时候我们可以assert现在这个Master是ODOWN了。12345void sentinelStartFailover(sentinelRedisInstance *master) &#123; serverAssert(master-&gt;flags &amp; SRI_MASTER);master-&gt;failover_state = SENTINEL_FAILOVER_STATE_WAIT_START;... 首先，会更新failover_state字段，我们来看看这个字段的取值都是什么： SENTINEL_FAILOVER_STATE_NONE：没有在FailOver SENTINEL_FAILOVER_STATE_WAIT_START：等待开始FailOver SENTINEL_FAILOVER_STATE_SELECT_SLAVE：选择一个Slave作为新Master，即promoted_slave。 SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE：向该Slave发送SLAVEOF指令以成为Master SENTINEL_FAILOVER_STATE_WAIT_PROMOTION：向剩余Slave发送SLAVEOF指令，让它们跟随新Master SENTINEL_FAILOVER_STATE_RECONF_SLAVES：让剩余Slave开始复制新Master SENTINEL_FAILOVER_STATE_UPDATE_CONFIG：此时所有Slave已经完成同步，需要进行配置更新。这里的配置更新指的是当前Sentinel节点上的master和master-&gt;slaves等的配置。 下面继续查看源码，会自增sentinel.current_epoch并赋值给Master的failover_epoch，这个类似于Raft中任期的概念。1234567... master-&gt;flags |= SRI_FAILOVER_IN_PROGRESS; master-&gt;failover_epoch = ++sentinel.current_epoch; sentinelEvent(LL_WARNING,"+new-epoch",master,"%llu", (unsigned long long) sentinel.current_epoch); sentinelEvent(LL_WARNING,"+try-failover",master,"%@");... 接着，我们要更新被FailOver的Master节点的failover_start_time。这里随机一个FailOver开始时间，类似Raft中的（Follower变成Candidate的？TODO）随机超时时间。12345... // #define SENTINEL_MAX_DESYNC 1000 master-&gt;failover_start_time = mstime()+rand()%SENTINEL_MAX_DESYNC; master-&gt;failover_state_change_time = mstime();&#125; sentinelAskMasterStateToOtherSentinels这个函数有下面功能： 遍历所有Sentinel 清理过期状态 判断是否要询问这个Sentinel有关ODOWN的信息。 发送不带自己runid的is-master-down-by-addr消息，目的是确认是否ODOWN 发送带自己runid的is-master-down-by-addr消息，目的是竞选 如果这个Sentinel认为Master已下线（即SDOWN），会向其他Sentinel发送SENTINEL is-master-down-by-addr命令，尝试获得足够的票数，将Master标记为ODOWN状态，并开启FailOver。这个函数会被以SENTINEL_ASK_FORCED和SENTINEL_NO_FLAGS这两个参数调用两次，原因在上文解释过了。 12345#define SENTINEL_ASK_FORCED (1&lt;&lt;0)void sentinelAskMasterStateToOtherSentinels(sentinelRedisInstance *master, int flags) &#123; dictIterator *di; dictEntry *de;... 我们遍历所有的Sentinel。12345678... di = dictGetIterator(master-&gt;sentinels); while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *ri = dictGetVal(de); mstime_t elapsed = mstime() - ri-&gt;last_master_down_reply_time; char port[32]; int retval;... 如果在5秒内都没有收到这个Sentinel对SENTINEL is-master-down-by-addr的回复，那么就清理这个Sentinel的投票状态，因为这个状态可能过期了。清理过程是清除SRI_MASTER_DOWN标记，并且将ri-&gt;leader清空。这里再提一下，Sentinel的ri-&gt;leader只有在有SRI_MASTER_DOWN标记时有效力，指向自己投票的Sentinel Leader。不要误以为始终指向当前的Leader，这个和Raft不一样，Sentinel只有在FailOver时候才会选举。【Q】TODO 容易看到，这里处理了Sentinel超时的情况，但我们在前面看到，Sentinel节点也会判断其他Sentinel的SDOWN情况，为啥这里不用SDOWN来判断呢？12345678...// #define SENTINEL_ASK_PERIOD 1000 if (elapsed &gt; SENTINEL_ASK_PERIOD*5) &#123; ri-&gt;flags &amp;= ~SRI_MASTER_DOWN; sdsfree(ri-&gt;leader); ri-&gt;leader = NULL; &#125;... 只有在满足下面三种情况下才询问这个Sentinel： Master必须具有SRI_S_DOWN这个flag。 显然，如果我自己都不觉得SDOWN，那为啥还要问是不是ODOWN呢？ 【Q】我们有必要在这里重复检查一下么？ 必须能够连接到这个Sentinel。 【Q】我们知道，如果认为SRI_S_DOWN了，那么也要关闭连接。而SDOWN对Master、Slave和Sentinal都检查的。为什么这里还需要检查呢？ 我们仔细看sentinelCheckSubjectivelyDown的实现，其实里面不仅处理了SDOWN的情况。断开连接实际上对应了包括连接超时和不活跃之类的情况。 除非SENTINEL_ASK_FORCED，否则我们要在SENTINEL_ASK_PERIOD时间内都没有收到ri的SENTINEL is-master-down的回复，我们才会再次询问。 1234567... if ((master-&gt;flags &amp; SRI_S_DOWN) == 0) continue; if (ri-&gt;link-&gt;disconnected) continue; if (!(flags &amp; SENTINEL_ASK_FORCED) &amp;&amp; mstime() - ri-&gt;last_master_down_reply_time &lt; SENTINEL_ASK_PERIOD) continue;... 下面是具体询问流程，实际上就是发送一个SENTINEL is-master-down-by-addr指令。注意，redisAsyncCommand中指定了处理回复的回调函数为sentinelReceiveIsMasterDownReply，方便我们跟踪流程。我们会发送自己的sentinel.current_epoch，对应到对端拿到的req_epoch。12345678910... /* Ask */ ll2string(port,sizeof(port),master-&gt;addr-&gt;port); retval = redisAsyncCommand(ri-&gt;link-&gt;cc, sentinelReceiveIsMasterDownReply, ri, "%s is-master-down-by-addr %s %s %llu %s", sentinelInstanceMapCommand(ri,"SENTINEL"), master-&gt;addr-&gt;ip, port, sentinel.current_epoch,... 如果启动了FailOver，那么把自己的sentinel.myid发出去，竞选FailOver Leader，否则就发送*，表示我们仅仅去监测有没有ODOWN。1234567... (master-&gt;failover_state &gt; SENTINEL_FAILOVER_STATE_NONE) ? sentinel.myid : "*"); if (retval == C_OK) ri-&gt;link-&gt;pending_commands++; &#125; dictReleaseIterator(di);&#125; 【接上】对sentinelAskMasterStateToOtherSentinels的回复对端对sentinelAskMasterStateToOtherSentinels发来的is-master-down-by-addr消息的处理过程直接在sentinelCommand里面，主要是两点内容： 首先返回这个Sentinel有没有觉得SDOWN。 如果这是一个竞选请求，调用sentinelVoteLeader来计算是否投票。 首先复习一下这个请求的格式。1SENTINEL is-master-down-by-addr ip port current_epoch runid 其中ip:port是我们要检查的Master的地址。Note that the command will not check by name but just by master, in theory different Sentinels may monitor differnet masters with the same name.current-epoch需要被用来判断我们是否能够对选举FailOver Leader进行投票。每个Sentinel每个epoch只能投一票。如果runid为*，表示我们并没有向这个Sentinel请求投票，否则设置为我们想要它投票的runid。 下面看具体代码12345678910111213141516// 在sentinelCommand函数中sentinelRedisInstance *ri;long long req_epoch;uint64_t leader_epoch = 0;char *leader = NULL;long port;int isdown = 0;if (c-&gt;argc != 6) goto numargserr;if (getLongFromObjectOrReply(c,c-&gt;argv[3],&amp;port,NULL) != C_OK || getLongLongFromObjectOrReply(c,c-&gt;argv[4],&amp;req_epoch,NULL) != C_OK) return;ri = getSentinelRedisInstanceByAddrAndRunID(sentinel.masters, c-&gt;argv[2]-&gt;ptr,port,NULL); 首先是返回有没有觉得SDOWN。如果没有处于tilt状态，那么满足下面的情况下，我们返回1 如果我们检查到节点SDOWN了 并且这个节点还是Master 12345/* It exists? Is actually a master? Is subjectively down? It's down. * Note: if we are in tilt mode we always reply with "0". */if (!sentinel.tilt &amp;&amp; ri &amp;&amp; (ri-&gt;flags &amp; SRI_S_DOWN) &amp;&amp; (ri-&gt;flags &amp; SRI_MASTER)) isdown = 1; 如果is-master-down-by-addr这个请求带了runid参数，说明这是一个带竞选的信息，此时会调用sentinelVoteLeader来Vote。1234567/* Vote for the master (or fetch the previous vote) if the request * includes a runid, otherwise the sender is not seeking for a vote. */if (ri &amp;&amp; ri-&gt;flags &amp; SRI_MASTER &amp;&amp; strcasecmp(c-&gt;argv[5]-&gt;ptr,"*")) &#123; leader = sentinelVoteLeader(ri,(uint64_t)req_epoch, c-&gt;argv[5]-&gt;ptr, &amp;leader_epoch);&#125; 回复内容包含三点。这个shared实际上是在server.c中定义的struct sharedObjectsStruct shared;，可以理解成一种共享小对象。1234567/* Reply with a three-elements multi-bulk reply: * down state, leader, vote epoch. */addReplyArrayLen(c,3);addReply(c, isdown ? shared.cone : shared.czero);addReplyBulkCString(c, leader ? leader : "*");addReplyLongLong(c, (long long)leader_epoch);if (leader) sdsfree(leader); sentinelVoteLeadersentinelVoteLeader函数对应了Raft中Follower投票的逻辑。这个函数返回一个char*，表示这个节点投票支持的，执行master这个节点FailOver过程的Leader，即master-&gt;leader。容易看出，Sentinel能同时处理多个Master的FailOver。 这个函数的调用方有两个： 当对端收到带竞选的is-master-down-by-addr信息时 当自己开启竞选时 这个发生在后面的sentinelGetLeader中 这个函数的参数是req_epoch和req_runid，表示处理req_runid这一台Sentinel在req_epoch的投票请求。此外，leader_epoch是用来返回的，表示我们投出来的master-&gt;leader是哪个epoch的。这里的req_epoch的取值规则如下： 如果是对方发来的is-master-down-by-addr，那么值是对方的sentinel.current_epoch。 如果是自己的请求，那么是ri-&gt;failover_epoch，这里的ri是我们正在处理的Master节点。 投票逻辑如下： 如果自己已经投了 如果是一个来自较新的epoch的投票请求 需要满足： 他发过来的req_epoch严格大于我自己的master-&gt;leader_epoch，这里leader_epoch表示我刚才vote的Leader是哪个epoch的。 这个是对Master的epoch的判定。 他发过来的req_epoch大于等于我自己的sentinel.current_epoch。 这个是对Sentinel的epoch的判定。 否则 返回自己原来投的票。 这通常发生在，有多个Sentinel同时竞选，而我已经给比req_epoch更高的epoch投过票了，那么返回在这个更高的epoch投的票。 如果暂时不能投票（TODO 对应什么情况呢？）就返回NULL 如果还没有投: 设置master-&gt;leader为req_runid，也是函数的返回值 设置master-&gt;leader_epoch和leader_epoch的值为sentinel.current_epoch 12345678910111213/* Vote for the sentinel with 'req_runid' or return the old vote if already * voted for the specified 'req_epoch' or one greater. * * If a vote is not available returns NULL, otherwise return the Sentinel * runid and populate the leader_epoch with the epoch of the vote. */char *sentinelVoteLeader(sentinelRedisInstance *master, uint64_t req_epoch, char *req_runid, uint64_t *leader_epoch) &#123; if (req_epoch &gt; sentinel.current_epoch) &#123; sentinel.current_epoch = req_epoch; sentinelFlushConfig(); sentinelEvent(LL_WARNING,"+new-epoch",master,"%llu", (unsigned long long) sentinel.current_epoch); &#125;... 如果，当前Sentinel节点记录的Master的epoch是陈旧的，并且Sentinel节点自己的current_epoch不领先于req_epoch，那么说明这是一个来自于较新的epoch的投票请求，我们应该投票。12345678910... if (master-&gt;leader_epoch &lt; req_epoch &amp;&amp; sentinel.current_epoch &lt;= req_epoch) &#123; sdsfree(master-&gt;leader); master-&gt;leader = sdsnew(req_runid); master-&gt;leader_epoch = sentinel.current_epoch; sentinelFlushConfig(); sentinelEvent(LL_WARNING,"+vote-for-leader",master,"%s %llu", master-&gt;leader, (unsigned long long) master-&gt;leader_epoch);... 下面，如果我们没有投票给自己，就需要设置failover_start_time。这里的myid指的是自己的runid，在3.0版本，是用的server.runid，可以参考前文的说明。failover_start_time为当前时间，再加上随机值的偏移。这在前面提到过，作用是为了实现类似于Raft中的随机超时时间。12345678... if (strcasecmp(master-&gt;leader,sentinel.myid)) master-&gt;failover_start_time = mstime()+rand()%SENTINEL_MAX_DESYNC; &#125; *leader_epoch = master-&gt;leader_epoch; return master-&gt;leader ? sdsnew(master-&gt;leader) : NULL;&#125; 【接上】sentinelReceiveIsMasterDownReply我们看看Sentinel如何处理sentinelAskMasterStateToOtherSentinels的返回结果，即投票结果。下面是一些Sanity检查，可以跳过直接看主干。 12345678910111213141516171819/* Receive the SENTINEL is-master-down-by-addr reply, see the * sentinelAskMasterStateToOtherSentinels() function for more information. */void sentinelReceiveIsMasterDownReply(redisAsyncContext *c, void *reply, void *privdata) &#123; sentinelRedisInstance *ri = privdata; instanceLink *link = c-&gt;data; redisReply *r; if (!reply || !link) return; link-&gt;pending_commands--; r = reply; /* Ignore every error or unexpected reply. * Note that if the command returns an error for any reason we'll * end clearing the SRI_MASTER_DOWN flag for timeout anyway. */ if (r-&gt;type == REDIS_REPLY_ARRAY &amp;&amp; r-&gt;elements == 3 &amp;&amp; r-&gt;element[0]-&gt;type == REDIS_REPLY_INTEGER &amp;&amp; r-&gt;element[1]-&gt;type == REDIS_REPLY_STRING &amp;&amp; r-&gt;element[2]-&gt;type == REDIS_REPLY_INTEGER) &#123;... 首先看第一个参数element[0]，表示对Master是否宕机的Reply。12345678... ri-&gt;last_master_down_reply_time = mstime(); if (r-&gt;element[0]-&gt;integer == 1) &#123; ri-&gt;flags |= SRI_MASTER_DOWN; &#125; else &#123; ri-&gt;flags &amp;= ~SRI_MASTER_DOWN; &#125;... 第二个参数element[1]，如果不是&quot;*&quot;，表示对方投票了，此时更新ri的投票结果r-&gt;element[1]-&gt;str到ri-&gt;leader。123456789101112131415... if (strcmp(r-&gt;element[1]-&gt;str,"*")) &#123; /* If the runid in the reply is not "*" the Sentinel actually * replied with a vote. */ sdsfree(ri-&gt;leader); if ((long long)ri-&gt;leader_epoch != r-&gt;element[2]-&gt;integer) serverLog(LL_WARNING, "%s voted for %s %llu", ri-&gt;name, r-&gt;element[1]-&gt;str, (unsigned long long) r-&gt;element[2]-&gt;integer); ri-&gt;leader = sdsnew(r-&gt;element[1]-&gt;str); ri-&gt;leader_epoch = r-&gt;element[2]-&gt;integer; &#125; &#125;&#125; sentinelFailoverStateMachine这个函数是FailOver状态机的入口，每次时钟循环都会调用一次。他负责处理除了SENTINEL_FAILOVER_STATE_NONE和SENTINEL_FAILOVER_STATE_UPDATE_CONFIG（实际上是一头一尾）的所有命令。每一次状态转移都需要更新failover_state_change_time，这个时间会在一些地方被用来处理Abort逻辑。 这个函数需要在SRI_FAILOVER_IN_PROGRESS下才会运行，这个位是由sentinelStartFailover设置的。主要内容是一个dispatch的逻辑，根据当前FailOver状态机的状态ri-&gt;failover_state去执行对应的函数。 我们容易看出，状态机状态为X的时候，表示前一个状态对应的行为已经完成，但是当前状态的行为并不一定完成。也就是状态X表示正在做X，而不是X已经做完了，这应该是状态机设计的时候一个比较通用的做法吧。 1234567void sentinelFailoverStateMachine(sentinelRedisInstance *ri) &#123; serverAssert(ri-&gt;flags &amp; SRI_MASTER); if (!(ri-&gt;flags &amp; SRI_FAILOVER_IN_PROGRESS)) return; switch(ri-&gt;failover_state) &#123;... 这个函数发送sentinalSignal： -failover-abort-not-elected +elected-leader和+failover-state-select-slave 可能到达状态： SENTINEL_FAILOVER_STATE_NONE SENTINEL_FAILOVER_STATE_SELECT_SLAVE 12345... case SENTINEL_FAILOVER_STATE_WAIT_START: sentinelFailoverWaitStart(ri); break;... 这个函数发送sentinalSignal： -failover-abort-no-good-slave +selected-slave和+failover-state-send-slaveof-noone 可能到达状态： SENTINEL_FAILOVER_STATE_NONE SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE 12345... case SENTINEL_FAILOVER_STATE_SELECT_SLAVE: sentinelFailoverSelectSlave(ri); break;... 这个函数发送sentinalSignal： -failover-abort-slave-timeout +failover-state-wait-promotion 可能到达状态： SENTINEL_FAILOVER_STATE_NONE SENTINEL_FAILOVER_STATE_WAIT_PROMOTION 12345... case SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE: sentinelFailoverSendSlaveOfNoOne(ri); break;... 这个函数发送sentinalSignal： -failover-abort-slave-timeout 可能到达状态： SENTINEL_FAILOVER_STATE_NONE 12345... case SENTINEL_FAILOVER_STATE_WAIT_PROMOTION: sentinelFailoverWaitPromotion(ri); break;... 这个函数发送sentinalSignal： 自己 -slave-reconf-sent-timeout +slave-reconf-sent sentinelFailoverDetectEnd +failover-end-for-timeout +failover-end +slave-reconf-sent-be 可能到达状态： SENTINEL_FAILOVER_STATE_UPDATE_CONFIG 123456... case SENTINEL_FAILOVER_STATE_RECONF_SLAVES: sentinelFailoverReconfNextSlave(ri); break; &#125;&#125; sentinelFailoverWaitStart首先检查自己是不是这个epoch的FailOver的Leader，这个通常伴随着选举的过程，在选举过程中，Candidate会在这边自旋，并调用sentinelGetLeader统计票数。TODO 加一个Demo。注意之前提到过，FailOver的发起者不一定是FailOver的执行者。这个过程涉及调用sentinelGetLeader函数，可能会触发选举。这里的ri是我们正在处理的master节点所对应的Instance。12345678910/* ---------------- Failover state machine implementation ------------------- */void sentinelFailoverWaitStart(sentinelRedisInstance *ri) &#123; char *leader; int isleader; /* Check if we are the leader for the failover epoch. */ leader = sentinelGetLeader(ri, ri-&gt;failover_epoch); isleader = leader &amp;&amp; strcasecmp(leader,sentinel.myid) == 0; sdsfree(leader);... 如果我自己不是Leader，并且这个FailOver不是由SENTINEL FAILOVER命令触发的强制FailOver，那么就不进行下面的FailOver流程。这个逻辑很简单，Raft中发起AppendEntries也都是由Leader来发起的。1234567... if (!isleader &amp;&amp; !(ri-&gt;flags &amp; SRI_FORCE_FAILOVER)) &#123; int election_timeout = SENTINEL_ELECTION_TIMEOUT; /* The election timeout is the MIN between SENTINEL_ELECTION_TIMEOUT * and the configured failover timeout. */... 如果超过了election_timeout，我们会直接Abort整个FailOver过程。1234567891011... if (election_timeout &gt; ri-&gt;failover_timeout) election_timeout = ri-&gt;failover_timeout; /* Abort the failover if I'm not the leader after some time. */ if (mstime() - ri-&gt;failover_start_time &gt; election_timeout) &#123; sentinelEvent(LL_WARNING,"-failover-abort-not-elected",ri,"%@"); sentinelAbortFailover(ri); &#125; return; &#125;... 否则切换状态到SENTINEL_FAILOVER_STATE_SELECT_SLAVE，也就是说从Slave中挑选一个新的Master。12345678... sentinelEvent(LL_WARNING,"+elected-leader",ri,"%@"); if (sentinel.simfailure_flags &amp; SENTINEL_SIMFAILURE_CRASH_AFTER_ELECTION) sentinelSimFailureCrash(); ri-&gt;failover_state = SENTINEL_FAILOVER_STATE_SELECT_SLAVE; ri-&gt;failover_state_change_time = mstime(); sentinelEvent(LL_WARNING,"+failover-state-select-slave",ri,"%@");&#125; 【接上】sentinelGetLeader这个函数用来返回给定的epoch对应的Leader。这里的epoch实际上是ri-&gt;failover_epoch，也就是当前进程需要FailOver的Master的failover_epoch。【Q】为什么不用sentinel.current_epoch呢？我认为这是因为同一个Sentinel可能处理若干个Master的FailOver过程，所以sentinel.current_epoch和ri-&gt;failover_epoch不能一一对应。扫描这个Master下面的所有Sentinel，检查对于epoch是否存在一个Leader。为了成为Leader，我们需要有majority的节点都投票给这个Leader，参与投票的节点由上次SENTINEL RESET的指定。一个问题是，Leader选举是在什么时候开始的呢？我们需要注意的是sentinelGetLeader这个函数并不是只会触发一遍，而是在整个sentinelTimer上都会进行调用。在第一次调用的时候，肯定是一票都没有，winner是NULL，此时就给自己投一票，同时函数sentinelAskMasterStateToOtherSentinels会发送is-master-down-by-addr给另外一方。12345678910char *sentinelGetLeader(sentinelRedisInstance *master, uint64_t epoch) &#123; dict *counters; dictIterator *di; dictEntry *de; unsigned int voters = 0, voters_quorum; char *myvote; char *winner = NULL; uint64_t leader_epoch; uint64_t max_votes = 0;... 首先，断言一下Master是ODOWN状态，并且FailOver在进行中1234... serverAssert(master-&gt;flags &amp; (SRI_O_DOWN|SRI_FAILOVER_IN_PROGRESS)); counters = dictCreate(&amp;leaderVotesDictType,NULL);... 下面这个循环，对于每一个Sentinel选出的Leader，我们都投上一票。看起来这个很奇怪，感觉和墙头草一样？其实不然，这里“投上一票”的表述并不准确。ri-&gt;leader实际上记录了这个Sentinel的投票结果，因此我认为这个循环实际上是记录了每一个Sentinel到底得了多少票。所以不是“投上一票”，而是记上一票。123456789101112... voters = dictSize(master-&gt;sentinels)+1; /* All the other sentinels and me.*/ /* Count other sentinels votes */ di = dictGetIterator(master-&gt;sentinels); while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *ri = dictGetVal(de); if (ri-&gt;leader != NULL &amp;&amp; ri-&gt;leader_epoch == sentinel.current_epoch) sentinelLeaderIncr(counters,ri-&gt;leader); &#125; dictReleaseIterator(di);... 在遍历统计完投票情况后，检查谁胜出，必须满足下面的条件的，才会成为winner。 绝对多数 必须大于master-&gt;quorum 123456789101112... di = dictGetIterator(counters); while((de = dictNext(di)) != NULL) &#123; uint64_t votes = dictGetUnsignedIntegerVal(de); if (votes &gt; max_votes) &#123; max_votes = votes; winner = dictGetKey(de); &#125; &#125; dictReleaseIterator(di);... 现在需要再统计一下自己的票数。如果自己没投票，那么就投给winner；如果没有winner，就投给自己sentinel.myid。【Q】如果作为竞选的发起方，这里是走哪条路径的呢？我觉得根据上面的讨论，因为一开始协议刚发出去，一票都没有，肯定还没有决出winner，所以还是投自己一票的。123456... if (winner) myvote = sentinelVoteLeader(master,epoch,winner,&amp;leader_epoch); else myvote = sentinelVoteLeader(master,epoch,sentinel.myid,&amp;leader_epoch);... 上面只是发送Vote消息，sentinelLeaderIncr函数是自增counters的计数，这个发生在本地，把自己的一票也加上去。如果投票之后的票数比最大票数要大，那么更换Leader。12345678910... if (myvote &amp;&amp; leader_epoch == epoch) &#123; uint64_t votes = sentinelLeaderIncr(counters,myvote); if (votes &gt; max_votes) &#123; max_votes = votes; winner = myvote; &#125; &#125;... 下面检查winner的票数是否满足quorum和master-&gt;quorum12345678910... voters_quorum = voters/2+1; if (winner &amp;&amp; (max_votes &lt; voters_quorum || max_votes &lt; master-&gt;quorum)) winner = NULL; winner = winner ? sdsnew(winner) : NULL; sdsfree(myvote); dictRelease(counters); return winner;&#125; sentinelFailoverSelectSlave这个函数用来选择需要promote成Master的Slave。主要逻辑是调用sentinelSelectSlave，然后根据他的返回值，去进行一些周边的处理，例如状态机的切换。从原来所有的Slave中，挑选一个作为新的Master，如果没有合格的新Master，那么返回NULL。这里同样有个sentinelAbortFailover的分支来处理选不到的情况。123void sentinelFailoverSelectSlave(sentinelRedisInstance *ri) &#123; sentinelRedisInstance *slave = sentinelSelectSlave(ri);... 下面就是设置slave-&gt;flags，设置ri-&gt;promoted_slave12345678910111213141516... /* We don't handle the timeout in this state as the function aborts * the failover or go forward in the next state. */ if (slave == NULL) &#123; sentinelEvent(LL_WARNING,"-failover-abort-no-good-slave",ri,"%@"); sentinelAbortFailover(ri); &#125; else &#123; sentinelEvent(LL_WARNING,"+selected-slave",slave,"%@"); slave-&gt;flags |= SRI_PROMOTED; ri-&gt;promoted_slave = slave; ri-&gt;failover_state = SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE; ri-&gt;failover_state_change_time = mstime(); sentinelEvent(LL_NOTICE,"+failover-state-send-slaveof-noone", slave, "%@"); &#125;&#125; sentinelSelectSlave首先是计算能接受的Slave和Master之间的Replication断连的最大时长，超过这个时间的Slave我们不考虑，从而保证数据库的时效性。down_after_period表示在这段时间后会被认为短连了，所以max_master_down_time等于Master的SDOWN到现在的时间，加上十倍的down_after_period。这个计算方式很神奇。因为从当前Sentinel来看，Master已经处于下线状态，所以正常来说，Slave与Master之间的连接断开时间不应该超过down-after-period * 10。这听上去有点像黑魔法，不过这个判断的原理是这样的：当Master下线之后，Master和Slave的连接就会断开，但只要先下线的是Master而不是Slave，即连接断开是由Master而不是Slave造成的，那么Master和Slave之间的连接断开时间就不会太长。不过这只是一个辅助手段，因为最终我们都会使用复制偏移量来挑选Slave。12345678910111213sentinelRedisInstance *sentinelSelectSlave(sentinelRedisInstance *master) &#123; sentinelRedisInstance **instance = zmalloc(sizeof(instance[0])*dictSize(master-&gt;slaves)); sentinelRedisInstance *selected = NULL; int instances = 0; dictIterator *di; dictEntry *de; mstime_t max_master_down_time = 0; if (master-&gt;flags &amp; SRI_S_DOWN) max_master_down_time += mstime() - master-&gt;s_down_since_time; max_master_down_time += master-&gt;down_after_period * 10;... 下面开始遍历所有的Slave来生成候选集instance，需要满足下面的条件： 不能SDOWN或者ODOWN 不能短连 Link不能超时 slave-&gt;slave_priority不能为0。这个值是从INFO得到的，默认为SENTINEL_DEFAULT_SLAVE_PRIORITY = 100 对PING(5xPERIOD)/INFO(3xPERIOD)的回复不能超时 和Master的Replication断连的时长不能超过上面的计算值 1234567891011121314151617181920212223... di = dictGetIterator(master-&gt;slaves); while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *slave = dictGetVal(de); mstime_t info_validity_time; if (slave-&gt;flags &amp; (SRI_S_DOWN|SRI_O_DOWN)) continue; if (slave-&gt;link-&gt;disconnected) continue; if (mstime() - slave-&gt;link-&gt;last_avail_time &gt; SENTINEL_PING_PERIOD*5) continue; if (slave-&gt;slave_priority == 0) continue; /* If the master is in SDOWN state we get INFO for slaves every second. * Otherwise we get it with the usual period so we need to account for * a larger delay. */ if (master-&gt;flags &amp; SRI_S_DOWN) info_validity_time = SENTINEL_PING_PERIOD*5; else info_validity_time = SENTINEL_INFO_PERIOD*3; if (mstime() - slave-&gt;info_refresh &gt; info_validity_time) continue; if (slave-&gt;master_link_down_time &gt; max_master_down_time) continue; instance[instances++] = slave; &#125;... 下面，我们对候选集进行排序，然后选到最优的12345678910... dictReleaseIterator(di); if (instances) &#123; qsort(instance,instances,sizeof(sentinelRedisInstance*), compareSlavesForPromotion); selected = instance[0]; &#125; zfree(instance); return selected;&#125; compareSlavesForPromotion主要比较优先级分为下面几个： slave_priority越小的 slave_repl_offset(replication offset)越大的，这表示从服务器的偏移量 runid字母序越小的 123456789101112131415161718192021222324/* * * Basically if runid is the same, the slave that processed more commands * from the master is selected. * * The function returns the pointer to the selected slave, otherwise * NULL if no suitable slave was found. */int compareSlavesForPromotion(const void *a, const void *b) &#123; sentinelRedisInstance **sa = (sentinelRedisInstance **)a, **sb = (sentinelRedisInstance **)b; char *sa_runid, *sb_runid; if ((*sa)-&gt;slave_priority != (*sb)-&gt;slave_priority) return (*sa)-&gt;slave_priority - (*sb)-&gt;slave_priority; /* If priority is the same, select the slave with greater replication * offset (processed more data from the master). */ if ((*sa)-&gt;slave_repl_offset &gt; (*sb)-&gt;slave_repl_offset) &#123; return -1; /* a &lt; b */ &#125; else if ((*sa)-&gt;slave_repl_offset &lt; (*sb)-&gt;slave_repl_offset) &#123; return 1; /* a &gt; b */ &#125;... 因为一下老的slave没有publishrunid，所以这里将其设置为NULL，默认NULL的字母序最大12345678... sa_runid = (*sa)-&gt;runid; sb_runid = (*sb)-&gt;runid; if (sa_runid == NULL &amp;&amp; sb_runid == NULL) return 0; else if (sa_runid == NULL) return 1; /* a &gt; b */ else if (sb_runid == NULL) return -1; /* a &lt; b */ return strcasecmp(sa_runid, sb_runid);&#125; sentinelFailoverSendSlaveOfNoOne这个函数负责对要提升的节点发送SLAVEOF NO ONE，让它提升为Master。如果link-&gt;disconnected，那么不断重试直到超时failover_timeout，触发sentinelAbortFailover。ri-&gt;promoted_slave是在sentinelFailoverSelectSlave被设置的。1234567891011void sentinelFailoverSendSlaveOfNoOne(sentinelRedisInstance *ri) &#123; int retval; if (ri-&gt;promoted_slave-&gt;link-&gt;disconnected) &#123; if (mstime() - ri-&gt;failover_state_change_time &gt; ri-&gt;failover_timeout) &#123; sentinelEvent(LL_WARNING,"-failover-abort-slave-timeout",ri,"%@"); sentinelAbortFailover(ri); &#125; return; &#125;... 调用sentinelSendSlaveOf，传入NULL表示让这个ri-&gt;promoted_slave执行SLAVEOF NO ONE为Master。12345678... retval = sentinelSendSlaveOf(ri-&gt;promoted_slave,NULL,0); if (retval != C_OK) return; sentinelEvent(LL_NOTICE, "+failover-state-wait-promotion", ri-&gt;promoted_slave,"%@"); ri-&gt;failover_state = SENTINEL_FAILOVER_STATE_WAIT_PROMOTION; ri-&gt;failover_state_change_time = mstime();&#125; sentinelSendSlaveOf这个命令先发送SLAVEOF。再发送CONFIG REWRITE，从而在可能的情况下将配置刷到配置上。可能的情况指Redis支持写Config，并且这个服务器是从Config文件启动的。1234567891011/* * The command returns C_OK if the SLAVEOF command was accepted for * (later) delivery otherwise C_ERR. The command replies are just * discarded. */int sentinelSendSlaveOf(sentinelRedisInstance *ri, char *host, int port) &#123; char portstr[32]; int retval; ll2string(portstr,sizeof(portstr),port);... 如果host是NULL，发送SLAVEOF NO ONE，让这台机器变为Master。12345678... /* If host is NULL we send SLAVEOF NO ONE that will turn the instance * into a master. */ if (host == NULL) &#123; host = "NO"; memcpy(portstr,"ONE",4); &#125;... 出于安全因素，我们要开启一个事务，这个也是相比3.0升级的地方。包含： SLAVEOF 重新配置 Disconnect all clients (but this one sending the commnad)，从而触发ask-master-on-reconnection协议（？） 注意CLIENT KILL TYPE &lt;type&gt;这个指令从2.8才开始有的。不过往低版本的发并没有为题，因为CLIENT是一个variadic command，所以不会被认为是错误，所以事务不会失败。 123456789101112131415161718192021222324252627282930313233... retval = redisAsyncCommand(ri-&gt;link-&gt;cc, sentinelDiscardReplyCallback, ri, "%s", sentinelInstanceMapCommand(ri,"MULTI")); if (retval == C_ERR) return retval; ri-&gt;link-&gt;pending_commands++; retval = redisAsyncCommand(ri-&gt;link-&gt;cc, sentinelDiscardReplyCallback, ri, "%s %s %s", sentinelInstanceMapCommand(ri,"SLAVEOF"), host, portstr); if (retval == C_ERR) return retval; ri-&gt;link-&gt;pending_commands++; retval = redisAsyncCommand(ri-&gt;link-&gt;cc, sentinelDiscardReplyCallback, ri, "%s REWRITE", sentinelInstanceMapCommand(ri,"CONFIG")); if (retval == C_ERR) return retval; ri-&gt;link-&gt;pending_commands++; for (int type = 0; type &lt; 2; type++) &#123; retval = redisAsyncCommand(ri-&gt;link-&gt;cc, sentinelDiscardReplyCallback, ri, "%s KILL TYPE %s", sentinelInstanceMapCommand(ri,"CLIENT"), type == 0 ? "normal" : "pubsub"); if (retval == C_ERR) return retval; ri-&gt;link-&gt;pending_commands++; &#125; retval = redisAsyncCommand(ri-&gt;link-&gt;cc, sentinelDiscardReplyCallback, ri, "%s", sentinelInstanceMapCommand(ri,"EXEC"));... 我们不通过命令的返回值来检查实际执行效果，而是观察下一个INFO。123456... if (retval == C_ERR) return retval; ri-&gt;link-&gt;pending_commands++; return C_OK;&#125; sentinelFailoverWaitPromotion这个函数只负责处理失败的情况。对于成功的情况，我们是在监视INFO返回值的sentinelRefreshInstanceInfo函数里面看的。12345678910/* We actually wait for promotion indirectly checking with INFO when the * slave turns into a master. */void sentinelFailoverWaitPromotion(sentinelRedisInstance *ri) &#123; /* Just handle the timeout. Switching to the next state is handled * by the function parsing the INFO command of the promoted slave. */ if (mstime() - ri-&gt;failover_state_change_time &gt; ri-&gt;failover_timeout) &#123; sentinelEvent(LL_WARNING,"-failover-abort-slave-timeout",ri,"%@"); sentinelAbortFailover(ri); &#125;&#125; sentinelRefreshInstanceInfo 角色变化部分函数sentinelRefreshInstanceInfo作用是解析INFO命令的返回值，通过它来更新节点从Slave到Master的变化。这个函数很长，我们只节选需要的部分来进行讲解。下面的代码，可以解析出这个节点认为自己的角色，是Master还是Slave。1234567// sentinelRefreshInstanceInfovoid sentinelRefreshInstanceInfo(sentinelRedisInstance *ri, const char *info) &#123;... /* role:&lt;role&gt; */ if (sdslen(l) &gt;= 11 &amp;&amp; !memcmp(l,"role:master",11)) role = SRI_MASTER; else if (sdslen(l) &gt;= 10 &amp;&amp; !memcmp(l,"role:slave",10)) role = SRI_SLAVE;··· 跳过后面一堆代码，看到下面这个if。现在ri在我的视野里是Slave，但是它却宣告自己是Master了。1234··· /* Handle slave -&gt; master role switch. */ if ((ri-&gt;flags &amp; SRI_SLAVE) &amp;&amp; role == SRI_MASTER) &#123;... 这是怎么回事呢？如果ri就是我们钦定的要成为Master的节点，并且我们Master确实在FailOver，并且我们的FailOver的状态确实是SENTINEL_FAILOVER_STATE_WAIT_PROMOTION，这就说明我们对promoted_slave的提升动作成功了，于是我们就可以进入下一步流程，即切换到状态为SENTINEL_FAILOVER_STATE_RECONF_SLAVES。其实这些检查就是我们确定了Slave已经被Reconf为Master了，对应的失败情况，就是sentinelFailoverWaitPromotion中看到的。我们要将Master的config_epoch设置为Master的failover_epoch，这一步的原因是我们将config_epoch同步为我们赢得选举胜利从而进行FailOver的epoch，这样如果没有一个更大的epoch的话，就会强迫其他Sentinel更新Config。12345678... if ((ri-&gt;flags &amp; SRI_PROMOTED) &amp;&amp; (ri-&gt;master-&gt;flags &amp; SRI_FAILOVER_IN_PROGRESS) &amp;&amp; (ri-&gt;master-&gt;failover_state == SENTINEL_FAILOVER_STATE_WAIT_PROMOTION)) &#123; ri-&gt;master-&gt;config_epoch = ri-&gt;master-&gt;failover_epoch;... 下面更新failover_state12345678910111213... ri-&gt;master-&gt;failover_state = SENTINEL_FAILOVER_STATE_RECONF_SLAVES; ri-&gt;master-&gt;failover_state_change_time = mstime(); sentinelFlushConfig(); sentinelEvent(LL_WARNING,"+promoted-slave",ri,"%@"); if (sentinel.simfailure_flags &amp; SENTINEL_SIMFAILURE_CRASH_AFTER_PROMOTION) sentinelSimFailureCrash(); sentinelEvent(LL_WARNING,"+failover-state-reconf-slaves", ri-&gt;master,"%@"); sentinelCallClientReconfScript(ri-&gt;master,SENTINEL_LEADER, "start",ri-&gt;master-&gt;addr,ri-&gt;addr);... sentinelForceHelloUpdateForMaster这个函数会强制发送一个”Hello”信息到所有关联到ri-&gt;master的Redis和Sentinel Instance。从技术上来说，这个并不需要，因为我们每隔SENTINEL_PUBLISH_PERIOD都会向所有Instance发送一个消息。但是当一个Sentinel更新了配置之后，尽快发送总是好的。注意虽然Sentinel我们没有设置pc，但是它实际上是通过cc去sentinelSendHello的。123... sentinelForceHelloUpdateForMaster(ri-&gt;master);... 否则，一个Slave意外地变成了Master，此时如果我们的主服务器看起来正常，并且ri在wait_time时间内没有SDOWN或者ODOWN（？），我们要强制它变回Slave。这个通常是因为重启，或者之前下线的Master突然上线了。但在这之前，我们需要等待一段时间，让它可以接收新配置（指什么呢？）。对于这种情况，兜底选项是啥呢？如果啥都没有，那么这边就会超时，导致上面sentinelFailoverWaitPromotion失败。但什么情况下会有这个分支呢？1234567891011121314151617... &#125; else &#123; mstime_t wait_time = SENTINEL_PUBLISH_PERIOD*4; if (!(ri-&gt;flags &amp; SRI_PROMOTED) &amp;&amp; sentinelMasterLooksSane(ri-&gt;master) &amp;&amp; sentinelRedisInstanceNoDownFor(ri,wait_time) &amp;&amp; mstime() - ri-&gt;role_reported_time &gt; wait_time) &#123; int retval = sentinelSendSlaveOf(ri, ri-&gt;master-&gt;addr-&gt;ip, ri-&gt;master-&gt;addr-&gt;port); if (retval == C_OK) sentinelEvent(LL_NOTICE,"+convert-to-slave",ri,"%@"); &#125; &#125; &#125; 看一下服务器正常的条件： 它在我们眼里是Master 它自己也说自己是Master 它还没有SDOWN或者ODOWN 1234567int sentinelMasterLooksSane(sentinelRedisInstance *master) &#123; return master-&gt;flags &amp; SRI_MASTER &amp;&amp; master-&gt;role_reported == SRI_MASTER &amp;&amp; (master-&gt;flags &amp; (SRI_S_DOWN|SRI_O_DOWN)) == 0 &amp;&amp; (mstime() - master-&gt;info_refresh) &lt; SENTINEL_INFO_PERIOD*2;&#125; sentinelFailoverReconfNextSlave这个函数调用来自于FailOver状态机的SENTINEL_FAILOVER_STATE_RECONF_SLAVES这个状态。它的主要功能是所有剩余的似乎还没有更新配置的Slave发送SLAVE OF指令，也就是让他们去跟随新的Master，即promoted_slave。我们对指令的发送进行限流，同时只能存在master-&gt;parallel_syncs条in-flight的指令。这里的“似乎没有更新配置”指的是具有以下这个条件slave-&gt;flags &amp; (SRI_RECONF_SENT|SRI_RECONF_INPROG)，其实就表示已经在更新过程中，但是没更新完。1234567/* Send SLAVE OF &lt;new master address&gt; to all the remaining slaves that * still don't appear to have the configuration updated. */void sentinelFailoverReconfNextSlave(sentinelRedisInstance *master) &#123; dictIterator *di; dictEntry *de; int in_progress = 0;... 下面这个循环统计已经在更新过程中的Slave数量到in_progress里面。12345678910... di = dictGetIterator(master-&gt;slaves); while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *slave = dictGetVal(de); if (slave-&gt;flags &amp; (SRI_RECONF_SENT|SRI_RECONF_INPROG)) in_progress++; &#125; dictReleaseIterator(di);... 下面，我们又遍历一次循环，在这个循环里面，如果in_progress的数量还小于设定的master-&gt;parallel_syncs，我们将尝试对新的Slave发送SLAVE OF指令。我感觉每一次Tick都跑这个遍历，开销是不是有点大呢？其实不然，因为这个循环还要做其他事情，反倒是上一个循环也许可以优化下，比如说搞一个全局的in_progress？1234567891011... di = dictGetIterator(master-&gt;slaves); while(in_progress &lt; master-&gt;parallel_syncs &amp;&amp; (de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *slave = dictGetVal(de); int retval; // 跳过已经完成配置的Slave if (slave-&gt;flags &amp; (SRI_PROMOTED|SRI_RECONF_DONE)) continue;... 如果对这个Slave已经发送了SLAVE OF，但是这个Slave还是停留在这个状态，我们就认为它已经被Reconf了。这个处理正确么？注释的解释是Sentinel能够在稍后检测出这个Slave被错误地配置了，并且进行修复。【Q】这个过程在哪里呢？12345678910... if ((slave-&gt;flags &amp; SRI_RECONF_SENT) &amp;&amp; (mstime() - slave-&gt;slave_reconf_sent_time) &gt; SENTINEL_SLAVE_RECONF_TIMEOUT) &#123; sentinelEvent(LL_NOTICE,"-slave-reconf-sent-timeout",slave,"%@"); slave-&gt;flags &amp;= ~SRI_RECONF_SENT; slave-&gt;flags |= SRI_RECONF_DONE; &#125;... 对于过程中，或者断连了的节点，我们跳过。123456... /* Nothing to do for instances that are disconnected or already * in RECONF_SENT state. */ if (slave-&gt;flags &amp; (SRI_RECONF_SENT|SRI_RECONF_INPROG)) continue; if (slave-&gt;link-&gt;disconnected) continue;... 对于剩下来的情况，我们发送命令。12345678910111213... /* Send SLAVEOF &lt;new master&gt;. */ retval = sentinelSendSlaveOf(slave, master-&gt;promoted_slave-&gt;addr-&gt;ip, master-&gt;promoted_slave-&gt;addr-&gt;port); if (retval == C_OK) &#123; slave-&gt;flags |= SRI_RECONF_SENT; slave-&gt;slave_reconf_sent_time = mstime(); sentinelEvent(LL_NOTICE,"+slave-reconf-sent",slave,"%@"); in_progress++; &#125; &#125; dictReleaseIterator(di); 下面的sentinelFailoverDetectEnd检查如果所有的Slave都被配置了，则切换到SENTINEL_FAILOVER_STATE_UPDATE_CONFIG。123 /* Check if all the slaves are reconfigured and handle timeout. */ sentinelFailoverDetectEnd(master);&#125; 【Q】和sentinelFailoverSwitchToPromotedSlave的区别在哪里？详见后面对sentinelFailoverSwitchToPromotedSlave的介绍。 阶段 sentinelFailoverSwitchToPromotedSlave的处理阶段是SENTINEL_FAILOVER_STATE_UPDATE_CONFIG，而这个函数是SENTINEL_FAILOVER_STATE_RECONF_SLAVES。 【Q】SRI_RECONF_SENT和SRI_RECONF_INPROG的区别是什么？我们可以看到SRI_RECONF_有三个子状态SRI_RECONF_SENT、SRI_RECONF_INPROG、SRI_RECONF_DONE，是从左到右递进的。在我们调用sentinelSendSlaveOf后，会设置SRI_RECONF_SENT。在我们在sentinelRefreshInstanceInfo中检测到这个Slave指向的Master的地址等于新Master即ri-&gt;master-&gt;promoted_slave的地址时，会取消SRI_RECONF_SENT，设置SRI_RECONF_INPROG。123456789101112131415161718// sentinelRefreshInstanceInfo... /* Detect if the slave that is in the process of being reconfigured * changed state. */ if ((ri-&gt;flags &amp; SRI_SLAVE) &amp;&amp; role == SRI_SLAVE &amp;&amp; (ri-&gt;flags &amp; (SRI_RECONF_SENT|SRI_RECONF_INPROG))) &#123; /* SRI_RECONF_SENT -&gt; SRI_RECONF_INPROG. */ if ((ri-&gt;flags &amp; SRI_RECONF_SENT) &amp;&amp; ri-&gt;slave_master_host &amp;&amp; strcmp(ri-&gt;slave_master_host, ri-&gt;master-&gt;promoted_slave-&gt;addr-&gt;ip) == 0 &amp;&amp; ri-&gt;slave_master_port == ri-&gt;master-&gt;promoted_slave-&gt;addr-&gt;port) &#123; ri-&gt;flags &amp;= ~SRI_RECONF_SENT; ri-&gt;flags |= SRI_RECONF_INPROG; sentinelEvent(LL_NOTICE,"+slave-reconf-inprog",ri,"%@"); &#125; 因为此时状态已经是SRI_RECONF_INPROG，所以当Slave到Master（肯定是新的而不是旧的）的连接是SENTINEL_MASTER_LINK_STATUS_UP时，切换到SRI_RECONF_DONE。这个是通过INFO消息中的master_link_status:字段来获得的。12345678910 /* SRI_RECONF_INPROG -&gt; SRI_RECONF_DONE */ if ((ri-&gt;flags &amp; SRI_RECONF_INPROG) &amp;&amp; ri-&gt;slave_master_link_status == SENTINEL_MASTER_LINK_STATUS_UP) &#123; ri-&gt;flags &amp;= ~SRI_RECONF_INPROG; ri-&gt;flags |= SRI_RECONF_DONE; sentinelEvent(LL_NOTICE,"+slave-reconf-done",ri,"%@"); &#125; &#125;... 当然，后面我们还会看到因为超时等原因设置为SRI_RECONF_DONE等flag的。 sentinelFailoverDetectEnd这个函数用来判断是否这个Master的所有Slave的同步都已经完成，此时，master还表示当前Fail的Master。下面的两个条件，主要是： 检查是否有合法的master-&gt;promoted_slave 主要检查是不是SDOWN，不过为啥不检查是否ODOWN呢？ 具有Reconf完成的flag，或者SDOWN 【Q】为什么Slave发生SDOWN是可以接受的呢？ 1234567891011121314151617181920212223void sentinelFailoverDetectEnd(sentinelRedisInstance *master) &#123; int not_reconfigured = 0, timeout = 0; dictIterator *di; dictEntry *de; mstime_t elapsed = mstime() - master-&gt;failover_state_change_time; /* We can't consider failover finished if the promoted slave is * not reachable. */ if (master-&gt;promoted_slave == NULL || master-&gt;promoted_slave-&gt;flags &amp; SRI_S_DOWN) return; /* The failover terminates once all the reachable slaves are properly * configured. */ di = dictGetIterator(master-&gt;slaves); while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *slave = dictGetVal(de); if (slave-&gt;flags &amp; (SRI_PROMOTED|SRI_RECONF_DONE)) continue; if (slave-&gt;flags &amp; SRI_S_DOWN) continue; not_reconfigured++; &#125; dictReleaseIterator(di);... 下面是日经的超时检测，在前面的状态机中超时就经常会导致sentinelAbortFailover。但是我们会忽略未完成的Slave，这个可能也是Sentinel可以在后面进行修复吧。12345678... /* Force end of failover on timeout. */ if (elapsed &gt; master-&gt;failover_timeout) &#123; not_reconfigured = 0; timeout = 1; sentinelEvent(LL_WARNING,"+failover-end-for-timeout",master,"%@"); &#125;... 如果此时，发现都Reconf了，那么就更新状态为SENTINEL_FAILOVER_STATE_UPDATE_CONFIG。1234567... if (not_reconfigured == 0) &#123; sentinelEvent(LL_WARNING,"+failover-end",master,"%@"); master-&gt;failover_state = SENTINEL_FAILOVER_STATE_UPDATE_CONFIG; master-&gt;failover_state_change_time = mstime(); &#125;... 但是，如果超时的话，就需要再发送一次？1234567891011121314151617181920212223242526 /* If I'm the leader it is a good idea to send a best effort SLAVEOF * command to all the slaves still not reconfigured to replicate with * the new master. */ if (timeout) &#123; dictIterator *di; dictEntry *de; di = dictGetIterator(master-&gt;slaves); while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *slave = dictGetVal(de); int retval; if (slave-&gt;flags &amp; (SRI_PROMOTED|SRI_RECONF_DONE|SRI_RECONF_SENT)) continue; if (slave-&gt;link-&gt;disconnected) continue; retval = sentinelSendSlaveOf(slave, master-&gt;promoted_slave-&gt;addr-&gt;ip, master-&gt;promoted_slave-&gt;addr-&gt;port); if (retval == C_OK) &#123; sentinelEvent(LL_NOTICE,"+slave-reconf-sent-be",slave,"%@"); slave-&gt;flags |= SRI_RECONF_SENT; &#125; &#125; dictReleaseIterator(di); &#125;&#125; sentinelFailoverSwitchToPromotedSlave【Q】和sentinelFailoverReconfNextSlave的关系是什么呢？见对sentinelFailoverReconfNextSlave的论述。 这个函数主要负责配置更新。什么是配置呢？ 于是将旧的Master即master移出表，并把新的Slave即master-&gt;promoted_slave加进去，其中master-&gt;promoted_slave指向被提升为新Master的Slave。1234/* This function is called when the slave is in * SENTINEL_FAILOVER_STATE_UPDATE_CONFIG state. In this state we need * to remove it from the master table and add the promoted slave instead. */void sentinelFailoverSwitchToPromotedSlave(sentinelRedisInstance *master) &#123; 这里的ref表示最新的Master。123456789 sentinelRedisInstance *ref = master-&gt;promoted_slave ? master-&gt;promoted_slave : master; sentinelEvent(LL_WARNING,"+switch-master",master,"%s %s %d %s %d", master-&gt;name, master-&gt;addr-&gt;ip, master-&gt;addr-&gt;port, ref-&gt;addr-&gt;ip, ref-&gt;addr-&gt;port); sentinelResetMasterAndChangeAddress(master,ref-&gt;addr-&gt;ip,ref-&gt;addr-&gt;port);&#125; sentinelResetMasterAndChangeAddresssentinelFailoverSwitchToPromotedSlave实际上是FailOver自动机的最后一步。主要逻辑是sentinelResetMasterAndChangeAddress，这个函数用来设置Master的ip:port，但保持Master名字不变，并最终调用sentinelResetMaster。sentinelResetMaster函数会重置master这个sentinelRedisInstance对象。与此同时，failover_state这个状态也会被清空成SENTINEL_FAILOVER_STATE_NONE。这个函数通常用来处理+switch-master消息，检索源码，我们确实看到所有+switch-master的sentinelEvent后面都会有这个函数。这个函数返回错误，当ip:port不能被resolve。123456int sentinelResetMasterAndChangeAddress(sentinelRedisInstance *master, char *ip, int port) &#123; sentinelAddr *oldaddr, *newaddr; sentinelAddr **slaves = NULL; int numslaves = 0, j; dictIterator *di; dictEntry *de; newaddr是最新的Master的地址。12newaddr = createSentinelAddr(ip,port);if (newaddr == NULL) return C_ERR; 我们遍历原来Master的所有Slave，如果这些Slave的指向的Master地址slave-&gt;addr还没有更新，我们就将它加入slaves列表中，等待后续更新。123456789101112/* Make a list of slaves to add back after the reset. * Don't include the one having the address we are switching to. */di = dictGetIterator(master-&gt;slaves);while((de = dictNext(di)) != NULL) &#123; sentinelRedisInstance *slave = dictGetVal(de); if (sentinelAddrIsEqual(slave-&gt;addr,newaddr)) continue; slaves = zrealloc(slaves,sizeof(sentinelAddr*)*(numslaves+1)); slaves[numslaves++] = createSentinelAddr(slave-&gt;addr-&gt;ip, slave-&gt;addr-&gt;port);&#125;dictReleaseIterator(di); 如果Master的地址变了，我们就要把老Master放到slaves列表中。12345678/* If we are switching to a different address, include the old address * as a slave as well, so that we'll be able to sense / reconfigure * the old master. */if (!sentinelAddrIsEqual(newaddr,master-&gt;addr)) &#123; slaves = zrealloc(slaves,sizeof(sentinelAddr*)*(numslaves+1)); slaves[numslaves++] = createSentinelAddr(master-&gt;addr-&gt;ip, master-&gt;addr-&gt;port);&#125; 下面，我们重置Master指针指向的对象，并且将slaves列表中的对象加到这个新的Master中。123456789101112131415161718192021222324 /* Reset and switch address. */ sentinelResetMaster(master,SENTINEL_RESET_NO_SENTINELS); oldaddr = master-&gt;addr; master-&gt;addr = newaddr; master-&gt;o_down_since_time = 0; master-&gt;s_down_since_time = 0; /* Add slaves back. */ for (j = 0; j &lt; numslaves; j++) &#123; sentinelRedisInstance *slave; slave = createSentinelRedisInstance(NULL,SRI_SLAVE,slaves[j]-&gt;ip, slaves[j]-&gt;port, master-&gt;quorum, master); releaseSentinelAddr(slaves[j]); if (slave) sentinelEvent(LL_NOTICE,"+slave",slave,"%@"); &#125; zfree(slaves); /* Release the old address at the end so we are safe even if the function * gets the master-&gt;addr-&gt;ip and master-&gt;addr-&gt;port as arguments. */ releaseSentinelAddr(oldaddr); sentinelFlushConfig(); return C_OK;&#125; 实验配置我们的配置如下（推荐用自己编译的Redis，否则Redis服务会自动重启，需要用/etc/init.d/redis-server stop关闭）123Master localhost 6379Slave1 localhost 6479Slave2 localhost 6579 Slave对于Slave11234# redis2.confreplicaof 127.0.0.1 6379port 6479pidfile /var/run/redis_6479.pid 运行12./src/redis-server redis2.conf &amp;redis-cli -h 127.0.0.1 -p 6479 对于Slave2同理INFO一下主节点12345678910# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=6479,state=online,offset=27029,lag=1slave1:ip=127.0.0.1,port=6579,state=online,offset=27559,lag=0master_repl_offset:27559repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:27558 Sentinel对于Sentinel2，我们配置如下。注意log文件配置相对路径似乎会打印不了log12345port 26479logfile "/tmp/sentinel2.log"daemonize yespidfile /var/run/redis-sentinel2.pidsentinel monitor mymaster 127.0.0.1 6379 2 其他如法炮制1./src/redis-sentinel sentinel.conf 启动后可以，注意我们可以看到runid，他是一个十六进制的串183af86ac492235bf97739bcdad0353f1d4e61df12345678910$ redis-cli -p 26379127.0.0.1:26379&gt; sentinel masters1) 1) "name" 2) "mymaster" 3) "ip" 4) "127.0.0.1" 5) "port" 6) "6379" 7) "runid" 8) "183af86ac492235bf97739bcdad0353f1d4e61df" 还可以INFO一下12345678127.0.0.1:26379&gt; info sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=mymaster,status=ok,address=127.0.0.1:6379,slaves=2,sentinels=3 但似乎没有办法从Master找到其他的Sentinel。注意，如果有Duplicated master name.的错误，可以考虑删除掉conf下面这段自动生成的代码。这是因为sentinelFlushConfig函数会触发对conf的回写。12345678910111213protected-mode nouser default on nopass ~* +@allsentinel known-replica mymaster 127.0.0.1 6479sentinel known-sentinel mymaster 127.0.0.1 26479 0833444de1d44b73ce6382af2ff0aeb21951b19asentinel known-sentinel mymaster 127.0.0.1 26379 2ddc47e7af3cebe8b1642127ed72002bb918550csentinel monitor mymaster 127.0.0.1 6379 2sentinel config-epoch mymaster 0sentinel leader-epoch mymaster 0sentinel known-replica mymaster 127.0.0.1 6579sentinel known-replica mymaster 127.0.0.1 6479sentinel known-sentinel mymaster 127.0.0.1 26479 0833444de1d44b73ce6382af2ff0aeb21951b19asentinel known-sentinel mymaster 127.0.0.1 26379 2ddc47e7af3cebe8b1642127ed72002bb918550csentinel current-epoch 0 测试正常FailOver现在我们Kill掉Master Sentinel1观察Sentinel1，它被选举为Leader1234510467:X 22 Oct 2020 04:27:19.771 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo10467:X 22 Oct 2020 04:27:19.771 # Redis version=999.999.999, bits=64, commit=00000000, modified=0, pid=10467, just started10467:X 22 Oct 2020 04:27:19.771 # Configuration loaded10468:X 22 Oct 2020 04:27:19.772 * Increased maximum number of open files to 10032 (it was originally set to 1024).10468:X 22 Oct 2020 04:27:19.772 * Running mode=sentinel, port=26379. 调用sentinelIsRunning生成myid。123410468:X 22 Oct 2020 04:27:19.773 # Sentinel ID is 2ddc47e7af3cebe8b1642127ed72002bb918550c10468:X 22 Oct 2020 04:27:19.773 # +monitor master mymaster 127.0.0.1 6379 quorum 210468:X 22 Oct 2020 04:29:33.291 # +sdown master mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:33.353 # +odown master mymaster 127.0.0.1 6379 #quorum 2/2 调用sentinelStartFailover。1210468:X 22 Oct 2020 04:29:33.353 # +new-epoch 110468:X 22 Oct 2020 04:29:33.353 # +try-failover master mymaster 127.0.0.1 6379 通过sentinelVoteLeader投了自己一票，这也会产生一条消息。110468:X 22 Oct 2020 04:29:33.355 # +vote-for-leader 2ddc47e7af3cebe8b1642127ed72002bb918550c 1 sentinelReceiveIsMasterDownReply回调中收到了其他两个Sentinel的投票。1210468:X 22 Oct 2020 04:29:33.358 # 0833444de1d44b73ce6382af2ff0aeb21951b19a voted for 2ddc47e7af3cebe8b1642127ed72002bb918550c 110468:X 22 Oct 2020 04:29:33.359 # 568af73c42a5dbdeb4dfcdfc7545a63226b8d626 voted for 2ddc47e7af3cebe8b1642127ed72002bb918550c 1 sentinelFailoverWaitStart在sentinelGetLeader中的轮询结束了，进入下面的failover-state-select-slave。1210468:X 22 Oct 2020 04:29:33.426 # +elected-leader master mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:33.426 # +failover-state-select-slave master mymaster 127.0.0.1 6379 选择了6579这个Slave1234567891011121310468:X 22 Oct 2020 04:29:33.489 # +selected-slave slave 127.0.0.1:6579 127.0.0.1 6579 @ mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:33.489 * +failover-state-send-slaveof-noone slave 127.0.0.1:6579 127.0.0.1 6579 @ mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:33.548 * +failover-state-wait-promotion slave 127.0.0.1:6579 127.0.0.1 6579 @ mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:34.235 # +promoted-slave slave 127.0.0.1:6579 127.0.0.1 6579 @ mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:34.235 # +failover-state-reconf-slaves master mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:34.291 * +slave-reconf-sent slave 127.0.0.1:6479 127.0.0.1 6479 @ mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:34.485 # -odown master mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:35.326 * +slave-reconf-inprog slave 127.0.0.1:6479 127.0.0.1 6479 @ mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:35.326 * +slave-reconf-done slave 127.0.0.1:6479 127.0.0.1 6479 @ mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:35.389 # +failover-end master mymaster 127.0.0.1 637910468:X 22 Oct 2020 04:29:35.389 # +switch-master mymaster 127.0.0.1 6379 127.0.0.1 657910468:X 22 Oct 2020 04:29:35.389 * +slave slave 127.0.0.1:6479 127.0.0.1 6479 @ mymaster 127.0.0.1 657910468:X 22 Oct 2020 04:29:35.389 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6579 Sentinel1观察Sentinel2，它是一个Follower1234567810473:X 22 Oct 2020 04:27:22.770 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo10473:X 22 Oct 2020 04:27:22.770 # Redis version=999.999.999, bits=64, commit=00000000, modified=0, pid=10473, just started10473:X 22 Oct 2020 04:27:22.770 # Configuration loaded10474:X 22 Oct 2020 04:27:22.771 * Increased maximum number of open files to 10032 (it was originally set to 1024).10474:X 22 Oct 2020 04:27:22.772 * Running mode=sentinel, port=26479.10474:X 22 Oct 2020 04:27:22.772 # Sentinel ID is 0833444de1d44b73ce6382af2ff0aeb21951b19a10474:X 22 Oct 2020 04:27:22.772 # +monitor master mymaster 127.0.0.1 6379 quorum 210474:X 22 Oct 2020 04:29:33.357 # +new-epoch 1 投票给了Sentinel1110474:X 22 Oct 2020 04:29:33.358 # +vote-for-leader 2ddc47e7af3cebe8b1642127ed72002bb918550c 1 即使已经票，Follower还是会执行sentinelCheckSubjectivelyDown和sentinelCheckObjectivelyDown的1210474:X 22 Oct 2020 04:29:33.395 # +sdown master mymaster 127.0.0.1 637910474:X 22 Oct 2020 04:29:33.457 # +odown master mymaster 127.0.0.1 6379 #quorum 3/2 在sentinelStartFailoverIfNeeded函数中，发现已经有人在FailOver了（这是因为自己刚投完票），所以不会开启。110474:X 22 Oct 2020 04:29:33.457 # Next failover delay: I will not start a failover before Thu Oct 22 04:35:33 2020 在PubSub中获得最新配置，处理函数sentinelProcessHelloMessage110474:X 22 Oct 2020 04:29:34.291 # +config-update-from sentinel 2ddc47e7af3cebe8b1642127ed72002bb918550c 127.0.0.1 26379 @ mymaster 127.0.0.1 6379 12310474:X 22 Oct 2020 04:29:34.291 # +switch-master mymaster 127.0.0.1 6379 127.0.0.1 657910474:X 22 Oct 2020 04:29:34.291 * +slave slave 127.0.0.1:6479 127.0.0.1 6479 @ mymaster 127.0.0.1 657910474:X 22 Oct 2020 04:29:34.291 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6579 FailOver完毕的配置观察最后的配置1234567# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=mymaster,status=ok,address=127.0.0.1:6579,slaves=2,sentinels=3 在当前版本下，还可以借助sentinel simfailure_flags命令模拟Crash。 Reference https://cloud.tencent.com/developer/article/1021467 https://wenfh2020.com/2020/06/15/redis-sentinel-master-down/ 这个讲解比较完整]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>raft</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELF文件链接和装载]]></title>
    <url>%2F2020%2F09%2F17%2Felf-format%2F</url>
    <content type="text"><![CDATA[本篇将主要结合CSAPP介绍ELF文件的格式，常用的分析工具，以及Linux程序链接和装载的流程。 一个Demomain.c1234567void swap();int buf[2] = &#123;1, 2&#125;;int main()&#123; swap(); return 0;&#125; swap.c1234567891011extern int buf[];int * bufp0 = &amp;buf[0];int * bufp1;void swap()&#123; int t; bufp1 = &amp;buf[1]; t = *bufp0; *bufp0 = *bufp1; *bufp1 = t;&#125; 构建项目，注意为了吻合CSAPP的Demo，需要指定32位模式，在一些编译器上还需要指定-no-pie，见后文说明123gcc -m32 -g -o p main.c swap.cgcc -m32 -g -c -o main.o main.cgcc -m32 -g -c -o swap.o swap.c 附上readelf -a p记录注意，里面有很多省略号，代表大块的0，这个可以通过-z来强制显示。附上objdump -x -D -s p记录 我们的系统和编译器是123456789DISTRIB_ID=UbuntuDISTRIB_RELEASE=16.04DISTRIB_CODENAME=xenialDISTRIB_DESCRIPTION="Ubuntu 16.04 LTS"g++ (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609Copyright (C) 2015 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 为了支持m32，需要安装gcc-multilib123apt install gcc-multilibgcc -no-pie -fPIC -m32 -g -o pic pic.cgcc -m32 -static -g -o nopic pic.c 对于gcc-multilib的安装，如果出现下面的错误，查看是否自己的apt版本有问题，我是因为在Ubuntu16上面用来了Ubuntu14的/etc/apt/sources.list1234The following packages have unmet dependencies: libc6-dev-i386 : Depends: libc6-i386 (= 2.19-0ubuntu6.15) but it is not going to be installed Depends: libc6-dev (= 2.19-0ubuntu6.15) but 2.23-0ubuntu11.2 is to be installed Recommends: gcc-multilib but it is not going to be installed 编译，这里C库默认是动态链接的，如果要静态链接需要指定-static。此外，某些版本会自动开启PIE，这样readelf会显示是DYN而不是EXEC，objdump无法得到绝对地址，这样就无法调试了，所以要指定-no-pie。 ELF结构Header可以通过readelf -h读取ELF头部。其中： REL一般是.o等待重定位的文件 DYN一般是动态库 EXEC一般是可执行文件 两个头部表段头部表，program header table，在内存中。可以通过readelf -l指令查看段头部表。节头部表，section header table，在二进制文件中。可以通过readelf -S指令查看节头部表，注意不要和-s选项混用，后者是查询符号表的。需要注意的是，这里段头部表和节头部表的中文语义似乎不明确，比如在自我修养一书中就称Section Header Table为段表，因此下面尽量避免使用这两个词，而是用program表和section表代替。 Program表查看program表，发现有两个LOAD段，分别对应了下面的02和03两个段（从0开始数），一般来说只有这两个段会被加载到内存。第一个段包含了.text、.rodata等，这些段是只读的，所以Flags有R，并且代码段.text是可执行的，所以Flags还有E。这个Entry point对应程序入口，即_start函数，可以通过例如ld -e来修改。1234567891011121314151617181920212223242526272829$ readelf -l pElf file type is EXEC (Executable file)Entry point 0x8048301There are 9 program headers, starting at offset 52Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flg Align PHDR 0x000034 0x08048034 0x08048034 0x00120 0x00120 R E 0x4 INTERP 0x000154 0x08048154 0x08048154 0x00013 0x00013 R 0x1 [Requesting program interpreter: /lib/ld-linux.so.2] LOAD 0x000000 0x08048000 0x08048000 0x005b4 0x005b4 R E 0x1000 LOAD 0x000f08 0x08049f08 0x08049f08 0x0011c 0x00124 RW 0x1000 DYNAMIC 0x000f14 0x08049f14 0x08049f14 0x000e8 0x000e8 RW 0x4 NOTE 0x000168 0x08048168 0x08048168 0x00044 0x00044 R 0x4 GNU_EH_FRAME 0x0004a0 0x080484a0 0x080484a0 0x00034 0x00034 R 0x4 GNU_STACK 0x000000 0x00000000 0x00000000 0x00000 0x00000 RW 0x10 GNU_RELRO 0x000f08 0x08049f08 0x08049f08 0x000f8 0x000f8 R 0x1 Section to Segment mapping: Segment Sections... 00 01 .interp 02 .interp .note.ABI-tag .note.gnu.build-id .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rel.dyn .rel.plt .init .plt .plt.got .text .fini .rodata .eh_frame_hdr .eh_frame 03 .init_array .fini_array .jcr .dynamic .got .got.plt .data .bss 04 .dynamic 05 .note.ABI-tag .note.gnu.build-id 06 .eh_frame_hdr 07 08 .init_array .fini_array .jcr .dynamic .got 介绍一下列名： Type 表示类型。 对于LOAD类型来说，内存大小不可能小于文件大小。但是有时候在内存中会分配多于文件大小的空间。其实这一部分就对应了BSS段所占用的空间。我们可以结合Section表的来观察，首先，我们找到.bss的大小是0x8，然后我们找到第二个LOAD段的大小是0x124，而0x124-0x8的差值0x11c就是LOAD段的FileSiz。 Offset 表示这个Segment在文件中的偏移。 VirtAddr 表示Segment的第一个字节在进程虚拟地址空间中的起始位置，应该就是VMA（TODO 确认一下）。 对于动态链接的共享库，可以在运行时通过dl_iterate_phdr函数来判断当前库，和库里面的每个Segment被加载到的真实地址。 PhysAddr 就是LMA，一般和VirtAddr是一样的。 FileSiz 表示Segment在文件中占用的长度，它是可能为0的。 MemSiz 表示Segment在内存中占用的长度，它也可能为0。 Align 表示对齐。 在进程运行时，可以通过cat proc/.../maps来看到进程p的其他VMA，例如[heap]、[stack]、[vdso]等。诸如00:00 0的字段表示主设备号、次设备号和文件节点号。1cat /proc/`ps aux | grep -w p | grep -v grep | grep -v gdb | awk '&#123;print $2&#125;'`/maps 对于[stack]而言它们都是0，表示这些Segment没有被映射到文件中。这种VMA称为Anonymous Virtual Memory Area。 Section表我们可以查看对应的section表。需要注意的是这里是静态ELF的表。动态ELF，例如SO文件的表会多一些字段。12345678910111213141516171819202122232425262728293031323334353637383940414243444546$ readelf -S pThere are 37 section headers, starting at offset 0x1c4c:Section Headers: [Nr] Name Type Addr Off Size ES Flg Lk Inf Al [ 0] NULL 00000000 000000 000000 00 0 0 0 [ 1] .interp PROGBITS 08048154 000154 000013 00 A 0 0 1 [ 2] .note.ABI-tag NOTE 08048168 000168 000020 00 A 0 0 4 [ 3] .note.gnu.build-i NOTE 08048188 000188 000024 00 A 0 0 4 [ 4] .gnu.hash GNU_HASH 080481ac 0001ac 000020 04 A 5 0 4 [ 5] .dynsym DYNSYM 080481cc 0001cc 000040 10 A 6 1 4 [ 6] .dynstr STRTAB 0804820c 00020c 000045 00 A 0 0 1 [ 7] .gnu.version VERSYM 08048252 000252 000008 02 A 5 0 2 [ 8] .gnu.version_r VERNEED 0804825c 00025c 000020 00 A 6 1 4 [ 9] .rel.dyn REL 0804827c 00027c 000008 08 A 5 0 4 [10] .rel.plt REL 08048284 000284 000008 08 AI 5 24 4 [11] .init PROGBITS 0804828c 00028c 000023 00 AX 0 0 4 [12] .plt PROGBITS 080482b0 0002b0 000020 04 AX 0 0 16 [13] .plt.got PROGBITS 080482d0 0002d0 000008 00 AX 0 0 8 [14] .text PROGBITS 080482e0 0002e0 0001a2 00 AX 0 0 16 [15] .fini PROGBITS 08048484 000484 000014 00 AX 0 0 4 [16] .rodata PROGBITS 08048498 000498 000008 00 A 0 0 4 [17] .eh_frame_hdr PROGBITS 080484a0 0004a0 000034 00 A 0 0 4 [18] .eh_frame PROGBITS 080484d4 0004d4 0000e0 00 A 0 0 4 [19] .init_array INIT_ARRAY 08049f08 000f08 000004 00 WA 0 0 4 [20] .fini_array FINI_ARRAY 08049f0c 000f0c 000004 00 WA 0 0 4 [21] .jcr PROGBITS 08049f10 000f10 000004 00 WA 0 0 4 [22] .dynamic DYNAMIC 08049f14 000f14 0000e8 08 WA 6 0 4 [23] .got PROGBITS 08049ffc 000ffc 000004 04 WA 0 0 4 [24] .got.plt PROGBITS 0804a000 001000 000010 04 WA 0 0 4 [25] .data PROGBITS 0804a010 001010 000014 00 WA 0 0 4 [26] .bss NOBITS 0804a024 001024 000008 00 WA 0 0 4 [27] .comment PROGBITS 00000000 001024 000035 01 MS 0 0 1 [28] .debug_aranges PROGBITS 00000000 001059 000040 00 0 0 1 [29] .debug_info PROGBITS 00000000 001099 00010f 00 0 0 1 [30] .debug_abbrev PROGBITS 00000000 0011a8 000102 00 0 0 1 [31] .debug_line PROGBITS 00000000 0012aa 000071 00 0 0 1 [32] .debug_str PROGBITS 00000000 00131b 00009e 01 MS 0 0 1 [33] .debug_ranges PROGBITS 00000000 0013b9 000010 00 0 0 1 [34] .shstrtab STRTAB 00000000 001af4 000158 00 0 0 1 [35] .symtab SYMTAB 00000000 0013cc 0004f0 10 36 54 4 [36] .strtab STRTAB 00000000 0018bc 000238 00 0 0 1Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings) I (info), L (link order), G (group), T (TLS), E (exclude), x (unknown) O (extra OS processing required) o (OS specific), p (processor specific) 介绍一下几个段名： .symtab 是一个符号表，包含引用的函数和全局变量的信息。符号表并不一定需要-g选项才会生成。可是在readelf -l p上面我们并没有看到有.symtab。其实执行readelf -S p就能看到了。我觉得可能是因为readelf -l只显示会被装载到内存中的段，而.symtab是静态符号表，不需要被装载。反观.dynsym就会被装载到内存中。 .debug_* 这个段才是真正由-g生成的。 .line 是C中的行号和机器地址的对照表。 .dynamic 如果说，我们的程序连C库和C++库都是静态链接的，那么它就不会有dynamic段。例如，我们开启了-static。 .rel.text和.rel.data 用来记录在.text中遇到的外部符号，例如printf函数的位置；对应的还有.rel.data服务于.data。 容易看出，对于静态的可执行文件来说，是不存在这两个字段的，因为已经没有什么需要重定位的了。 .strtab 字符串表。 .shstrtab 是段表字符串表。包含段名等信息。可以通过下面命令来查看字符串表的内容。 12345678910111213141516171819202122$ readelf -x33 pHex dump of section '.shstrtab': 0x00000000 002e7379 6d746162 002e7374 72746162 ..symtab..strtab 0x00000010 002e7368 73747274 6162002e 696e7465 ..shstrtab..inte 0x00000020 7270002e 6e6f7465 2e414249 2d746167 rp..note.ABI-tag 0x00000030 002e6e6f 74652e67 6e752e62 75696c64 ..note.gnu.build 0x00000040 2d696400 2e676e75 2e686173 68002e64 -id..gnu.hash..d 0x00000050 796e7379 6d002e64 796e7374 72002e67 ynsym..dynstr..g 0x00000060 6e752e76 65727369 6f6e002e 676e752e nu.version..gnu. 0x00000070 76657273 696f6e5f 72002e72 656c2e64 version_r..rel.d 0x00000080 796e002e 72656c2e 706c7400 2e696e69 yn..rel.plt..ini 0x00000090 74002e70 6c742e67 6f74002e 74657874 t..plt.got..text 0x000000a0 002e6669 6e69002e 726f6461 7461002e ..fini..rodata.. 0x000000b0 65685f66 72616d65 5f686472 002e6568 eh_frame_hdr..eh 0x000000c0 5f667261 6d65002e 696e6974 5f617272 _frame..init_arr 0x000000d0 6179002e 66696e69 5f617272 6179002e ay..fini_array.. 0x000000e0 64796e61 6d696300 2e646174 61002e62 dynamic..data..b 0x000000f0 7373002e 636f6d6d 656e7400 2e646562 ss..comment..deb 0x00000100 75675f61 72616e67 6573002e 64656275 ug_aranges..debu 0x00000110 675f696e 666f002e 64656275 675f6162 g_info..debug_ab 0x00000120 62726576 002e6465 6275675f 6c696e65 brev..debug_line 0x00000130 002e6465 6275675f 73747200 ..debug_str. .dynsym 是动态符号表。可以通过readelf -sD查看动态符号表。 符号表.symtab中往往也会包括动态符号，但动态符号表中只有动态符号。 .got、.got.plt和.plt 【相关详细说明，见后文】 这两个表是用来在装载动态链接库的时候寻找动态符号实际的位置的。 这三个表可以通过objdump -D来查看，注意这里是-D而不是-d，这是因为-D能够反汇编所有Section。可以通过objdump -R查看GOT中的重定位项。 .plt中列出了所有的@plt为后缀的“函数”，所以这个段也是可执行的。 .rel.dyn和.rel.plt 对应于.rel.data和.rel.text，相当于动态链接的重定位表。.rel.dyn用来修正位于.got段和数据段中的地址，实际上是对数据引用的修正。.rel.plt修正.got.plt段中的地址，实际上是对函数引用的修正。 但事情也不绝对，事实上导入函数的重定位入口可能出现在.rel.dyn中。这种情况一般发生在我们只使用-shared而不用-fPIC编译我们的SO文件时，那我们在这当中导入的外部函数，比如printf就会在.rel.dyn中，并且类型也变成了R_386_PC32。 我们在Ubuntu 16.04.7，使用gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609，去编译SO，指令 1gcc -shared -fPIC -m32 -g -c -o test_printf.so test_printf.c 如果我们用了-fPIC，有 123456Relocation section '.rel.text' at offset 0x4bc contains 4 entries: Offset Info Type Sym.Value Sym. Name00000008 00001102 R_386_PC32 00000000 __x86.get_pc_thunk.ax0000000d 0000120a R_386_GOTPC 00000000 _GLOBAL_OFFSET_TABLE_00000018 00000509 R_386_GOTOFF 00000000 .rodata00000020 00001304 R_386_PLT32 00000000 printf 而不使用，有 1234Relocation section '.rel.text' at offset 0x414 contains 2 entries: Offset Info Type Sym.Value Sym. Name0000000c 00000501 R_386_32 00000000 .rodata00000011 00000f02 R_386_PC32 00000000 printf 可以看出，确实变成了R_386_PC32。 但是SO文件里面似乎都没有.rel.dyn段，并且也没.got或者.got.plt段，也许这两个段只会在可执行文件中出现，而不会在动态链接库中出现？这是因为错误加了-c，去掉-c重新看一下 1gcc -shared -fPIC -m32 -g -o test_printf.so test_printf.c 如果用了-fPIC有 123456789101112131415Relocation section '.rel.dyn' at offset 0x35c contains 9 entries: Offset Info Type Sym.Value Sym. Name00001efc 00000008 R_386_RELATIVE 00001f00 00000008 R_386_RELATIVE 00002010 00000008 R_386_RELATIVE 00001fe8 00000106 R_386_GLOB_DAT 00000000 _ITM_deregisterTMClone00001fec 00000306 R_386_GLOB_DAT 00000000 __cxa_finalize@GLIBC_2.1.300001ff0 00000406 R_386_GLOB_DAT 00000000 __gmon_start__00001ff4 00000b06 R_386_GLOB_DAT 00002014 mya00001ff8 00000506 R_386_GLOB_DAT 00000000 _Jv_RegisterClasses00001ffc 00000606 R_386_GLOB_DAT 00000000 _ITM_registerTMCloneTaRelocation section '.rel.plt' at offset 0x3a4 contains 1 entries: Offset Info Type Sym.Value Sym. Name0000200c 00000207 R_386_JUMP_SLOT 00000000 printf@GLIBC_2.0 否则有 1234567891011121314Relocation section '.rel.dyn' at offset 0x35c contains 12 entries: Offset Info Type Sym.Value Sym. Name00000540 00000008 R_386_RELATIVE 00001f10 00000008 R_386_RELATIVE 00001f14 00000008 R_386_RELATIVE 0000200c 00000008 R_386_RELATIVE 00000537 00000b01 R_386_32 00002010 mya0000054d 00000b01 R_386_32 00002010 mya00000545 00000202 R_386_PC32 00000000 printf@GLIBC_2.000001fec 00000106 R_386_GLOB_DAT 00000000 _ITM_deregisterTMClone00001ff0 00000306 R_386_GLOB_DAT 00000000 __cxa_finalize@GLIBC_2.1.300001ff4 00000406 R_386_GLOB_DAT 00000000 __gmon_start__00001ff8 00000506 R_386_GLOB_DAT 00000000 _Jv_RegisterClasses00001ffc 00000606 R_386_GLOB_DAT 00000000 _ITM_registerTMCloneTa .init和.fini 可以用来执行C++中全局/静态变量的构造或者析构操作。 Section Headers的Type具有下面的几种情况： NULL： 一般是Nr=0的Type PROGBITS：代码段和数据段 .interp、.init、.fini .plt、.plt.got、.got .text .data、.rodata SYMTAB：符号表 .symtab段 STRTAB：字符串表 .strtab和.dynstr段等 RELA：重定位表 HASH：符号表的哈希表 DYNAMIC：动态链接信息 .dynamic段 NOTE： NOBITS： .bss段 REL：重定位信息 .rel.dyn和.rel.plt段 SHLIB DYNSYM .dynsym段 当程序真正被加载到Linux内存中时，呈现下面的布局。可以看到，栈是从高往低增长的，ESP是栈顶；堆是由低往高增长的，由brk限制。 符号表查看main.o的符号表，首先介绍一下结构。 Ndx 表示符号所在的Section。取值为 ABS 也就是readelf -S看到的Nr序号。 COM 表示是一个COMMON块类型的符号，例如未初始化的全局符号。参考下面的bufp1。 COMMON块听起来很熟悉，其实也确实来自Fortran的一个概念。 UND 表示是一个未定义的符号，通常说明是在这个文件中被引用，但定义在其他文件中。 Bind GLOBAL表示全局符号。LOCAL表示局部符号。WEAK表示弱引用。 注意，弱引用和弱符号的概念还有区别。弱符号在C++中static关键字的用法这篇文章中已经有了讲解，即强符号包含函数和已初始化的全局变量；弱符号包括未初始化的全局变量。可以通过__attribute__((weak))annotate（自我修养里面用的是定义）一个符号是弱符号。 可以通过__attribute__((weakref))定义对一个外部函数的引用是弱引用。对于弱引用，在链接期如果找不到它的定义，不会报错，而是赋一个0或者其他便于识别的值，如果在运行期还找不到定义，才会出错。 弱引用的一个作用是，我们可以声明一个pthread_create函数为弱引用，然后我们在运行期判定pthread_create的地址是否为0，来判断是否是多线程程序。 Type NOTYPE，未知类型。 OBJECT，数据对象。 FUNC，函数或者其他可执行代码。 SECTION，表示一个Section，此时这个符号的Bind一定是LOCAL。 可以通过objdump -t p打印出符号表来看到。 FILE，文件名，此时这个符号的Bind一定是LOCAL，并且Ndx一定是一个ABS序号。 Vis 发现其中的swap符号对应是UND的，表示是在本模块中引用了，但是未定义（其实在swap.o中定义了）的符号。1234567$ readelf -s main.o Num: Value Size Type Bind Vis Ndx Name ... 13: 00000000 8 OBJECT GLOBAL DEFAULT 3 buf 14: 00000000 36 FUNC GLOBAL DEFAULT 1 main 15: 00000000 0 NOTYPE GLOBAL DEFAULT UND swap 而buf对应了Ndx为3，我们查看Section表，3表示.data段。123456789$ readelf -S main.oSection Headers: [Nr] Name Type Addr Off Size ES Flg Lk Inf Al [ 0] NULL 00000000 000000 000000 00 0 0 0 [ 1] .text PROGBITS 00000000 000034 000024 00 AX 0 0 1 [ 2] .rel.text REL 00000000 0003a0 000008 08 I 18 1 4 [ 3] .data PROGBITS 00000000 000058 000008 00 WA 0 0 4 [ 4] .bss NOBITS 00000000 000060 000000 00 WA 0 0 1 下面我们再看看swap.o的符号表，这里出现了一个COM，表示是未初始化的符号。12345Num: Value Size Type Bind Vis Ndx Name 13: 00000000 4 OBJECT GLOBAL DEFAULT 3 bufp0 14: 00000000 0 NOTYPE GLOBAL DEFAULT UND buf 15: 00000004 4 OBJECT GLOBAL DEFAULT COM bufp1 16: 00000000 54 FUNC GLOBAL DEFAULT 1 swap 我觉得bufp1的应该是在bss段，即Ndx=4，但是这边给出的是COMMON段。因为bss也是自称被用来存放未初始化的全局变量的段。但事实上我们通过实验可以得到下面的结果12345678910111213141516// 在Ubuntu 18.04下// bss.cstatic int aaa = 0; // bssstatic int bbb = 1; // dataint ccc; // commonint ddd = 0; // bssint eee = 1; // dataint f();extern int ex;int call()&#123; f(); ex = 1;&#125;__attribute__((weak)) w1 = 1;__attribute__((weak)) w0 = 0;__attribute__((weak)) w; 为什么int ccc不行呢？我们nm一下，这里的ccc确实是一个C标记。1234567891011121314$ nm bss.o00000004 b aaa // 小写表示local00000000 d bbb00000000 T call // T表示在text段00000004 C ccc // C表示在common段中00000000 B ddd // B表示出现在bss段中00000004 D eee // D表示在data段中 U ex U f U _GLOBAL_OFFSET_TABLE_00000000 T __x86.get_pc_thunk.ax00000008 V w00000004 V w000000008 V w1 但是当我们将这个bss.c生成可执行文件（可能要去掉诸如f等未定义符号，并且加上main）后，在看ccc的标记，发现变成了B。12345$ nm bss00002024 b aaa00002008 d bbb00002014 B __bss_start00002028 B ccc 所以可以看出，Common段实际上是一个中间状态。链接器会按照取size最大的原则去merge同名的弱符号，或者取强符号。这个中间状态是必要的，因为编译器无法知道符号的类型，所以即使说要在编译期在bss段分配空间，我们也不知道要分配多大的。只有当链接器找到弱符号的所有出现之后，我们才能确切知道。 链接两步链接(Two-phase linking)： 分配空间和地址 收集每个目标文件各个段的信息。 构建全局符号表。 解析符号和重定位符号 可以通过objdump -h命令查看每个段的地址。其中： VMA(Virtual Memory Address) 表示虚拟地址，也就是这个段在程序运行时候的地址。 LMA(Load Memory Address) 表示加载地址，也就是我们把这些段里面的内容复制到内存的某个地址处。容易想到，程序加载到哪里，程序就在哪里运行啊，所以VMA应该等于LMA。但是这个有特例。在一些嵌入式系统中，程序被加载在ROM中。即使我们可以在ROM中执行.text段的代码，我们也不能在ROM中修改.data段的数据，更何况ROM的读取速度要慢于RAM。因此我们不可避免地需要将程序从ROM中的LMA，复制到RAM中的VMA上。 File Off 12345678910p: file format elf32-i386Sections:Idx Name Size VMA LMA File off Algn 0 .interp 00000013 08048154 08048154 00000154 2**0 CONTENTS, ALLOC, LOAD, READONLY, DATA... 13 .text 000001c2 080482e0 080482e0 000002e0 2**4 CONTENTS, ALLOC, LOAD, READONLY, CODE... VMA和File Off并不一定相等，比如对目标文件而言： 对于可执行文件 事实上，如果我们readelf -x14 p，查看.text的段的内容的话，我们也能看到它起始地址。 12Hex dump of section '.text': 0x080482e0 31ed5e89 e183e4f0 50545268 a0840408 1.^.....PTRh.... 对应地，查看Section表，发现地址也已经被确定了。 123$ readelf -S pSection Headers: [14] .text PROGBITS 080482e0 0002e0 0001a2 00 AX 0 0 16 对于目标文件 objdump -h一下main.o，可以看到它的起始地址是0x0，而File Off是所以这里的地址是0x0000003c。 1234Sections:Idx Name Size VMA LMA File off Algn 0 .text 00000024 00000000 00000000 00000034 2**0 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 对应地，观察main.o里面的Section表，发现代码段的地址仍然为空； 123456$ readelf -S main.oSection Headers: [Nr] Name Type Addr Off Size ES Flg Lk Inf Al [ 0] NULL 00000000 000000 000000 00 0 0 0 [ 1] .text PROGBITS 00000000 000034 000024 00 AX 0 0 1 [ 2] .rel.text REL 00000000 0003a0 000008 08 I 18 1 4 使用readelf -x1 main.o看一下，发现起始地址是0，因此不是以File Off为基准的。 123Hex dump of section '.text': NOTE: This section has relocations against it, but these have NOT been applied to this dump. 0x00000000 8d4c2404 83e4f0ff 71fc5589 e55183ec .L$.....q.U..Q.. 重定向本节，我们查看静态链接的重定向问题。对于静态链接而言，重定向只发生在静态链接期。我们可以看到对于swap.o或者main.o来说，是存在.rel.text相关字段的；但是对最终形成的可执行文件p来说，是不存在上述字段的。 目标观察p文件观察最终结果./p的汇编。注意，在我的Ubuntu 18.04.5和GCC 7.5.0上面实际上会看到main的地址并不是8028开头的，这个可能是因为开启了PIE，我们可以通过-no-pie禁用掉。 下面介绍一下call指令，它通过e8来识别，具有一个操作数0a 01 00 00。它的行为是将下一条地址0x80482f6压栈，然后跳转到被调用的函数swap的第一条命令0x8048400处。可是，0x8048400这个地址是怎么算出来的呢？我们注意到0x80482f6+0x010a=0x8048400，所以call命令的参数是相对于EIP寄存器的偏移，给的是相对地址而不是绝对地址。我们现在有问题1：为什么是以下一条指令的EIP0x80482f6而不是当前的0x80482f1为基准计算呢？123456789101112131415161718$ objdump -d pDisassembly of section .text:080482e0 &lt;main&gt;: 80482e0: 8d 4c 24 04 lea 0x4(%esp),%ecx 80482e4: 83 e4 f0 and $0xfffffff0,%esp 80482e7: ff 71 fc pushl -0x4(%ecx) 80482ea: 55 push %ebp 80482eb: 89 e5 mov %esp,%ebp 80482ed: 51 push %ecx 80482ee: 83 ec 04 sub $0x4,%esp 80482f1: e8 0a 01 00 00 call 8048400 &lt;swap&gt; 80482f6: 83 c4 04 add $0x4,%esp 80482f9: 31 c0 xor %eax,%eax 80482fb: 59 pop %ecx 80482fc: 5d pop %ebp 80482fd: 8d 61 fc lea -0x4(%ecx),%esp 8048300: c3 ret 观察main.o文件接着，我们观察main.o的汇编。这里call的偏移是0xfffffffc(-4)，经过计算就是16-4=12，对应的是fc ff ff ff的开头。我们现在有问题2：这个跳转非常奇怪，为什么相对位移是-4呢？1234567891011121314151617181920$ objdump -d main.omain.o: file format elf32-i386Disassembly of section .text:00000000 &lt;main&gt;: 0: 8d 4c 24 04 lea 0x4(%esp),%ecx 4: 83 e4 f0 and $0xfffffff0,%esp 7: ff 71 fc pushl -0x4(%ecx) a: 55 push %ebp b: 89 e5 mov %esp,%ebp d: 51 push %ecx e: 83 ec 04 sub $0x4,%esp 11: e8 fc ff ff ff call 12 &lt;main+0x12&gt; 16: b8 00 00 00 00 mov $0x0,%eax 1b: 83 c4 04 add $0x4,%esp 1e: 59 pop %ecx 1f: 5d pop %ebp 20: 8d 61 fc lea -0x4(%ecx),%esp 23: c3 ret 现象总结可以看到，从不可执行的main.o到可执行的./p，发生了两个显著的变化。 左边的地址对应了main.o的代码实际被加载的地址，我们知道32位程序默认会被加载到0x8048000处。 右边call的地址，从0xfffffffc(-4)变为了0x8048400，这个对应了swap的实际装载地址 从objdump中可以看到，0x8048400处确实是会swap的代码 12345678910$ objdump -d p08048400 &lt;swap&gt;: 8048400: a1 20 a0 04 08 mov 0x804a020,%eax 8048405: 8b 0d 1c a0 04 08 mov 0x804a01c,%ecx 804840b: c7 05 28 a0 04 08 1c movl $0x804a01c,0x804a028 8048412: a0 04 08 8048415: 8b 10 mov (%eax),%edx 8048417: 89 08 mov %ecx,(%eax) 8048419: 89 15 1c a0 04 08 mov %edx,0x804a01c 804841f: c3 ret 计算过程下面我们来看看，目标的1和2是如何得到的。 代码主要的一个过程是*refaddr=*refptr，即我们应该算得0x80482f2位置的地址应当是0a 01 00 00。为此我们需要计算下面两个指标： refaddr refaddr表示需要修改的call的参数的地址。 *refptr *refptr表示call参数的最新值。 重定位表对于每个需要被重定位的ELF段，都需要有一个重定位表，例如.text的重定位表就是.rel.text段。我们可以通过readelf -r查看重定位表。注意，对于静态可执行文件来说，是没有.rel.text和.rel.data段的，因为他们需要的符号都被静态链接了。介绍一个各列的含义： Offset 这个重定位条目需要修改的地址相对于所处段段头的偏移。 Info 低8位：重定位条目的类型。例如下面的0x02。 高24位：重定位条目的符号在符号表中的下标。例如下面的0x00000f。 我们可以检查一下swap在符号表中的位置，果然是15。 12345$ readelf -s main.o Num: Value Size Type Bind Vis Ndx Name ... 15: 00000000 0 NOTYPE GLOBAL DEFAULT UND swap Type 包含两种： R_386_PC32=2：相对寻址 1S + A - P 其中S是swap的绝对地址，是0x08048400。 A是0xfffffffc(-4)，也就是*refptr的旧值0xfffffffc(-4)。 P是被修正位置的地址，也就是call参数的位置，即0x80482f1。我们将在*refptr的具体计算过程中详细讨论。 R_386_32=1：绝对寻址 1S + A Sym.Value 我们查看重定位条目表.rel.text，它提供了三个信息： 需要修改的重定位地址refaddr相对于main的段头的偏移量是12。 R_386_PC32表示重定位一个32位的相对地址的引用。特别地，还有一种R_386_32表示绝对地址。对于动态链接，还有更多的重定位类型，我们先不提。 把重定位地址refaddr处的值改成程序swap处的地址。 12345$ readelf -r main.oRelocation section '.rel.text' at offset 0x3a0 contains 1 entries: Offset Info Type Sym.Value Sym. Name00000012 00000f02 R_386_PC32 00000000 swap 具体计算refaddr计算refaddr，它等于ADDR(s) + r.offset等于ADDR(main) + r.offset，从前面的objdump的结果可以看到0x080482e0 + 0x12为0x80482f2，与实际结果吻合。 *refptr计算*refptr，我们用swap的绝对地址减去基址的值得到。swap绝对地址可以从objdump看到，是0x8048400，而call命令的地址是0x80482f1，所以*refptr的值是10x8048400 - 0x80482f1 = 0x10f 不对啊，之前看到实际的命令的参数是0x10a啊？没错，我们还需要减去A。这里提供另一个理解方式，因为基址是0x80482f2+4=0x80482f6，正好是下一条指令的开头。而这又是因为EIP(即PC)始终是指向下一条待执行的指令，所以计算偏移的时候，我们需要以此时实际EIP指向的位置来加上call指定的偏移。而0xfffffffc=-4这个值正好帮助EIP跳过自己占用的四个字节，这也解答了我们的问题2。 动态链接动态链接机制概述根据thegreenplace上的这篇文章，在解决加载动态链接库中的重定向问题时，通常有两种办法： 基于PIC机制 这个机制是目前主流且通用的，对应了-fPIC -shared的编译模式。 基于Load-time Relocation机制 这个机制对应了-shared的编译模式。 GOT机制概述我们考虑动态链接的场景，程序依赖的外部程序并没有在静态链接期链接到可执行文件中，而需要在运行期动态加载。负责这个过程的动态加载器由INTERP段指定，Linux上的默认值为/lib/ld-linux.so.2。动态加载器是GLIBC的一部分，它的版本号往往和GLIBC的版本号一样，当GLIBC升级时，需要手动指定/lib/ld-linux.so.2这个文件到新的路径。为什么能够保证兼容性，可以查看后面的论述。123456789101112131415$ readelf -l pProgram Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flg Align... INTERP 0x000154 0x08048154 0x08048154 0x00013 0x00013 R 0x1 [Requesting program interpreter: /lib/ld-linux.so.2]$ objdump -s -j ".interp" pp: file format elf32-i386Contents of section .interp: 8048154 2f6c6962 2f6c642d 6c696e75 782e736f /lib/ld-linux.so 8048164 2e3200 .2. 在确定动态符号的地址时，动态链接器有两个选择： 直接模仿静态链接器一样修改代码，不过这个是不现实的，我们从前文知道，.text段是只读的。 将地址放在可读可写的数据段中，并在.text中用代码加载正确地址。这个对应了我们后面提到的GOT表。 PICPIC的意思是位置无关代码，在之前看到的call命令肯定是位置无关的，因为它的参数是相对EIP的偏移，那么有什么代码是位置相关的呢？这包含两部分： 调用外部过程 引用全局变量 据此，我们可以将模块中的地址引用分为下面四种方式，我们将讨论着四种方式的重定位方式。 模块内函数调用 不需要重定位。 模块内数据访问 需要通过get_pc_thunk函数（实际上可能叫__x86.get_pc_thunk.ax）来获得PC的地址，这是因为32位程序数据的相对寻址没有相对于PC的寻址方式。原理是调用call会把下一条指令的地址压到栈顶，即esp指向位置。 模块间数据访问 将地址相关的部分放到数据段里面。特别地，这些数据段对于不同的程序都有不同的副本，这也是显然的，因为他们肯定不一定相同，不然为啥不直接放代码段里面。 这时候我们引入全局偏移表GOT，并将符号的地址放在全局偏移表GOT中。例如，当需要访问变量b时，首先查找GOT中对应的条目，再根据条目列出的地址来索引到变量正确的位置。因此在构建时，我们实际上确定的是GOT相对于当前指令的偏移。GOT位于.got段，可以通过objdump -R查看GOT中的重定位项。 模块间函数调用 实际上也可以通过类似3的办法来解决，即call *(%eax)这样。但考虑到函数的加载数量是比较大的，实际实现上面采用了延迟绑定的技术，通过PLT表来实现，从而实现了延迟加载。 Global Symbol Interposition问题 这个问题主要是除了模块内部的静态变量（比如局部变量、具有内部链接性的static等），还有一种引用是在module.c中对extern int global这样的引用，其中global被定义在共享对象中。没有办法确定是定义在同模块的另一个.o里面，还是在共享库中。此时，如果module.c是可执行文件的一部分，因为可执行文件不是PIC的，那么必然会在bss段给global创建一个副本，对这种情况，就需要将共享对象中的global指向这个副本。如果module.c在共享对象中，那么它肯定也是按照PIC编译的，此时就会按照模块间引用的方式生成代码。 如何判断一个ELF文件是PIC的呢？根据爆栈网，可以用下面的办法判断一个目标文件是不是PIC的。但下面的评论也指出了对SO，以及对-m32编译选项是不适用的。1readelf --relocs foo.o | egrep '(GOT|PLT|JU?MP_SLOT)' PLT机制概述PLT将对于函数引用的实际地址从.got中拆出，放到了.got.plt表中。因此.got中保存全局变量引用的地址，.got.plt保存全局函数引用的地址。.got.plt的前三个条目有特殊意义： .dynamic段地址 本模块ID _dl_runtime_resolve函数地址。这个函数负责绑定模块A中的f函数。 .got.plt后面的条目就是每个被import的函数的实际地址。 PLT机制的过程是如下代码（来自自我修养一书）所示，这代码位于.plt段。首先，通过GOT中的索引进行跳转。如果这个索引条目已经加载了bar的正确地址，那么就会自然跳转到对应位置。否则，会调到push n指令处。12bar@plt:jmp *(bar@GOT) push连同_dl_runtime_resole的这一小段代码实际上就是去加载bar的正确地址，并且修改GOT表。123push npush moduleIDjump _dl_runtime_resole .dynamic段.dynamic段看上去像是属于这个so文件的“文件头”，可以通过readelf -d swap.so来查看.dynamic段的信息。 (INIT) .init地址 (FINI) .fini地址 (INIT_ARRAY) (INIT_ARRAYSZ) (FINI_ARRAY) (FINI_ARRAYSZ) (GNU_HASH) 动态的.hash (STRTAB) .dynstr地址，可以对应到readelf -S的结果。 (SYMTAB) .dynsym地址，可以对应到readelf -S的结果。 (STRSZ) .dynstr大小 (SYMENT) (PLTGOT) (RELA) 动态重定位表.rel.dyn地址。 (RELASZ) readelf -S里面.rela.dyn项目的Size。 (RELAENT) readelf -S里面.rela.dyn项目的EntSize。 (RELACOUNT) 动态重定位表数量 (NULL) 动态链接重定位可以通过readelf -r xxx.so查看动态重定位表。相比静态链接，动态连接多了一些重定位类型： R_386_JUMP_SLOT 这个类型的条目，对应的重定位Offset指向的位置在.got.plt中，实际上指向了.got.plt表中对应函数条目的地址。 例如，在动态加载时，我们查到printf的地址为X，我们就知道要把这个地址填到动态重定位表中Sym.Name为printf的条目中Offset所指向的位置，这个位置位于.got.plt表中。我们回想.got.plt表的结构，前三个项目分别是.dynamic段地址、模块ID和_dl_runtime_resolve地址，所以这个Offset应该至少是从第四个条目开始的。 TODO 补充一下printf的例子 R_386_GLOB_DAT 这种类型的条目，对应的重定位Offset指向的位置在.got中，与R_386_JUMP_SLOT很类似 R_386_RELATIVE 这种类型的重定位即Rebasing。这种方式的出现，是因为上面论述的四种动态重定位方式还不够周全。我们考虑某个共享对象中有如下的代码： 12static int a;static int* p = &amp;a; 这段代码中，它是一个模块内的数据访问，比如如果我们仅仅去访问a，那么按照上面的论述，是可以通过相对地址来访问的。 但现在问题复杂了，p持有a的指针，这是一个绝对地址。容易发现，当共享对象被加载到不同的程序中时，a的地址是会变化的，但我们必须在装载时把这个地址算出来，这个就是R_386_RELATIVE重定位要做的事情。 在编译时，共享对象的地址是从0开始的，我们记录此时a的偏移是B，此时p的值应该是B；当共享对象被装载到A处时，此时p的值应该是A+B了。因此，R_386_RELATIVE标记出来的这些符号在装载时都需要加上一个A的值，才成为最终结果。 有关动态链接器ld-linux ld-linux是静态链接的 Load-time Relocation实验实验设置12gcc -shared -m32 -g -o swap_no_pic.so swap.cgcc -m32 -g -o no_pic main.c swap.c PIC实验实验设置下面编译一个最简单的程序12345#include &lt;stdio.h&gt;int main()&#123; puts("Hello, world!");&#125; 我们添加下面两个选项，以得到一个位置无关的swap.so。 -fPIC创建位置无关代码 -shared创建共享库 1gcc -fPIC -m32 -g -o swap_no_shared.so swap.c 生成动态链接库123gcc -shared -fPIC -m32 -g -o swap.so swap.cgcc -fPIC -m32 -g -S -o main_pic.s main.c gcc -fPIC -m32 -g -c -o main_pic.o main.c 生成可执行程序1gcc -fPIC -m32 -g -o p_pic main.c swap.c 注意，在编译动态库的时候，不能加-c，否则链接器就不工作，会导致一系列问题。例如一些重定位项在.rel.text中，而不是在.rel.dyn中。 执行下面语句的编译结果1gcc -shared -fPIC -m32 -g -o swap.so swap.c readelf -a swap.soobjdump -x -D -s swap.so 实验过程下面我们以具体的实验来学习PLT机制。反编译动态链接的结果，发现实际调用的是puts@plt这个函数123456789101112131415161718192021222324252627282930(gdb) disass mainDump of assembler code for function main: 0x0804840b &lt;+0&gt;: lea 0x4(%esp),%ecx 0x0804840f &lt;+4&gt;: and $0xfffffff0,%esp 0x08048412 &lt;+7&gt;: pushl -0x4(%ecx) 0x08048415 &lt;+10&gt;: push %ebp 0x08048416 &lt;+11&gt;: mov %esp,%ebp 0x08048418 &lt;+13&gt;: push %ebx 0x08048419 &lt;+14&gt;: push %ecx 0x0804841a &lt;+15&gt;: call 0x8048447 &lt;__x86.get_pc_thunk.ax&gt; 0x0804841f &lt;+20&gt;: add $0x1be1,%eax ; $_GLOBAL_OFFSET_TABLE_, %eax 0x08048424 &lt;+25&gt;: sub $0xc,%esp 0x08048427 &lt;+28&gt;: lea -0x1b30(%eax),%edx ; leal .LC0@GOTOFF(%eax), %edx 0x0804842d &lt;+34&gt;: push %edx 0x0804842e &lt;+35&gt;: mov %eax,%ebx 0x08048430 &lt;+37&gt;: call 0x80482e0 &lt;puts@plt&gt; 0x08048435 &lt;+42&gt;: add $0x10,%esp 0x08048438 &lt;+45&gt;: mov $0x0,%eax 0x0804843d &lt;+50&gt;: lea -0x8(%ebp),%esp 0x08048440 &lt;+53&gt;: pop %ecx 0x08048441 &lt;+54&gt;: pop %ebx 0x08048442 &lt;+55&gt;: pop %ebp 0x08048443 &lt;+56&gt;: lea -0x4(%ecx),%esp 0x08048446 &lt;+59&gt;: ret End of assembler dump.disass 0x8048447Dump of assembler code for function __x86.get_pc_thunk.ax: 0x08048447 &lt;+0&gt;: mov (%esp),%eax 0x0804844a &lt;+3&gt;: ret 我们附上了main.s的代码用来对照12345678910111213141516171819202122$ cat main_pic.smain: leal 4(%esp), %ecx andl $-16, %esp pushl -4(%ecx) pushl %ebp movl %esp, %ebp pushl %ebx pushl %ecx call __x86.get_pc_thunk.ax ; call 10 &lt;main+0x10&gt; ; call 8048407 &lt;__x86.get_pc_thunk.ax&gt; addl $_GLOBAL_OFFSET_TABLE_, %eax ; add $0x1,%eax ; add $0x1c11,%eax movl %eax, %ebx call swap@PLT ; call 1c &lt;main+0x1c&gt; ; call 804840b &lt;swap&gt; movl $0, %eax popl %ecx popl %ebx popl %ebp leal -4(%ecx), %esp ret__x86.get_pc_thunk.ax: movl (%esp), %eax ret 看看puts@plt的实现，看起来是两个jmp和一个push，这个很奇怪。123456(gdb) disass putsDump of assembler code for function puts@plt: 0x080482e0 &lt;+0&gt;: jmp *0x804a00c 0x080482e6 &lt;+6&gt;: push $0x0 0x080482eb &lt;+11&gt;: jmp 0x80482d0End of assembler dump. 这些地址都是啥呢？检查Section表，发现第一个jmp落在.got.plt段上，而第二个jmp落在.plt段上。【结合上面的介绍，第一个jmp应该是@plt的到吗】1234(gdb) info symbol 0x804a00c_GLOBAL_OFFSET_TABLE_ + 12 in section .got.plt(gdb) info symbo 0x80482d0No symbol matches 0x80482d0. 这.plt所在的段是可读可执行不可写的，可以认为是一段代码。而.got.plt所在的段是可写的，也就是在运行时会被更新。123456789101112$ readelf -S picThere are 36 section headers, starting at offset 0x1a94:Section Headers: [Nr] Name Type Addr Off Size ES Flg Lk Inf Al [ 9] .rel.dyn REL 08048290 000290 000008 08 A 5 0 4 [10] .rel.plt REL 08048298 000298 000010 08 AI 5 24 4 [12] .plt PROGBITS 080482d0 0002d0 000030 04 AX 0 0 16 [13] .plt.got PROGBITS 08048300 000300 000008 00 AX 0 0 8 [14] .text PROGBITS 08048310 000310 0001a2 00 AX 0 0 16 [23] .got PROGBITS 08049ffc 000ffc 000004 04 WA 0 0 4 [24] .got.plt PROGBITS 0804a000 001000 000014 04 WA 0 0 4 第一个jmp查看第一个jmp的代码，发现没有啥意义，其实这个只是一个地址查询表，我们打印出来是一个要跳转的地址0x8049f141234567(gdb) disass 0x804a00cDump of assembler code for function _GLOBAL_OFFSET_TABLE_: 0x0804a000: adc $0x9f,%alEnd of assembler dump.(gdb) print /x *0x804a00c$1 = 0x80482e6 而这个地址恰好对应了puts@plt的下一行代码12(gdb) info symbol 0x80482e6puts@plt + 6 in section .plt 第二个jmp接着，我们入栈了一个0x0，接着jmp到0x80482d0，这个似乎不好直接disass，于是我们采用下面的办法。12(gdb) disass x80482d0No function contains specified address. 发现这边没有函数信息，于是强行disass一波，现在有了。看起来，我们入栈了一个0x804a004之后，又jmp到了*0x804a008这个位置。12345678910111213(gdb) disass 0x80482d0,0x080482f0Dump of assembler code from 0x80482d0 to 0x80482f0: 0x080482d0: pushl 0x804a004 0x080482d6: jmp *0x804a008 0x080482dc: add %al,(%eax) 0x080482de: add %al,(%eax) 0x080482e0 &lt;puts@plt+0&gt;: jmp *0x804a00c 0x080482e6 &lt;puts@plt+6&gt;: push $0x0 0x080482eb &lt;puts@plt+11&gt;: jmp 0x80482d0End of assembler dump.(gdb) print /x *0x804a008$3 = 0x0 我们发现*0x804a008居然是0。很奇怪，难道是没有运行的缘故？于是我们打断点，并执行12345678910(gdb) b *0x080482e0b *0x080482e6b *0x080482ebrun...sCannot find bounds of current functionprint /x *0x804a008$1 = 0xf7fee000 发现执行完之后，这里竟然有值了！但依然没有函数名，对这种情况，我们可以安装一个debug版本的glibc来解决12ldd ./pie # 确定版本apt install libc6-dbg:i386 这样在gdb里面就可以add symbol上面1add-symbol-file /usr/lib/debug/lib/x86_64-linux-gnu/ld-2.27.so 0xf7fd6ab0 这个值实际上是_dl_runtime_resolve的函数。这个函数主要内容就是入栈5个参数，然后调用_dl_fixup，最后再弹出栈。123456789101112(gdb) disass 0xf7fee000Dump of assembler code for function _dl_runtime_resolve: 0xf7fee000 &lt;+0&gt;: push %eax 0xf7fee001 &lt;+1&gt;: push %ecx 0xf7fee002 &lt;+2&gt;: push %edx 0xf7fee003 &lt;+3&gt;: mov 0x10(%esp),%edx 0xf7fee007 &lt;+7&gt;: mov 0xc(%esp),%eax 0xf7fee00b &lt;+11&gt;: call 0xf7fe77e0 &lt;_dl_fixup&gt; 0xf7fee010 &lt;+16&gt;: pop %edx 0xf7fee011 &lt;+17&gt;: mov (%esp),%ecx 0xf7fee014 &lt;+20&gt;: mov %eax,(%esp) 0xf7fee017 &lt;+23&gt;: mov 0x4(%esp),%eax ret的操作数指定了在弹出返回地址后，需要释放的字节/字数量。通常，这些字节/字被是作为调用的输入12 0xf7fee01b &lt;+27&gt;: ret $0xcEnd of assembler dump. 我们还可以从重定向表中，可能找到0x0804a00c这偏移对应的表项。12345678910$ readelf -r picRelocation section '.rel.dyn' at offset 0x290 contains 1 entries: Offset Info Type Sym.Value Sym. Name08049ffc 00000206 R_386_GLOB_DAT 00000000 __gmon_start__Relocation section '.rel.plt' at offset 0x298 contains 2 entries: Offset Info Type Sym.Value Sym. Name0804a00c 00000107 R_386_JUMP_SLOT 00000000 puts@GLIBC_2.00804a010 00000307 R_386_JUMP_SLOT 00000000 __libc_start_main@GLIBC_2.0 动态链接库版本和SO-NAME为什么依赖的so文件通常都是libname.so.6，但是实际上它会指向libname.so.6.0.23这样的库呢？下面将解答。 动态链接库的版本如下所示1libname.so.x.y.z 其中： 主版本号x 不同的主版本号的动态链接库是不兼容的。这通常暗示着在系统中需要保留旧版本的so库，否则依赖旧版本的libname的程序可能无法运行。 次版本号y 表示增量升级。会增加新符号，但不会改变旧符号。因此，高的y会自然兼容低版本的y。正因为如此，我们不需要指定次版本号，我们升级系统的so到最新版本就行，反正不会影响老版本。 发布版本号 当然，诸如libc和ld并不采用上面的命名方式。 Reference http://flint.cs.yale.edu/cs422/doc/ELF_Format.pdf CSAPP 程序员的自我修养—链接、装载与库 https://stackoverflow.com/questions/64872385/why-readelf-dont-show-symtab https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/readelf.html]]></content>
      <tags>
        <tag>编译原理</tag>
        <tag>Linux</tag>
        <tag>ELF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark ML库简析]]></title>
    <url>%2F2020%2F05%2F15%2Fspark-ml-lib%2F</url>
    <content type="text"><![CDATA[讨论Spark上分布式机器学习库的实现。Spark的机器学习库主要分为ml和mllib，其中ml较新，本文主要围绕ml来讲。ml和mllib底层会用到Breeze库（类似于numpy的线性代数库）和BLAS（Basic Linear Algebra Subroutines，更基础的线性代数库），在这里也进行介绍。 LR回归的实现总体实现ml库的整个训练和预测过程可以用下面三行代码来概括123val classifier = new LogisticRegression()val model：LogisticRegressionModel = classifier.fit(train)val predictions = model.transform(test) 训练过程LogisticRegression类的训练入口是fit。fit首先定义在基类Predictor.scala中，它会首先做一些事情，比如转换labelCol的类型到Double，然后调用train。train会返回一个Model，但在Predictor中并没有实现，而是交付给子类来实现。LogisticRegression类的train是自己实现的。主要包括下面几个部分。 校验打印参数 参数包含下面的一些列名 1labelCol, weightCol, featuresCol, predictionCol, rawPredictionCol, probabilityCol 这里的weightCol可以给样本指定权重，用来解决数据不平衡问题。详见balanceDataset的实现。 还包括下面的一些训练用参数 1regParam, elasticNetParam, standardization, threshold, maxIter, tol, fitIntercept 计算summarizer和labelSummarizer 可以得到一些基础信息，比如直方图、特征数量、特征的均值方差和数量，class数量。其中直方图(histogram)，大概内容类似[0: 34.0, 1: 66.0]，意味着分类1拥有34样本，分类2有66个样本。均值(mean)大概内容类似[0: -0.03327765069036007 ]。 根据这些信息还会判断任务类型，是不是多类的（设置isMultinomial） 计算coefficientMatrix、interceptVector和objectiveHistory 这是主要过程，分别是返回系数矩阵、偏置值向量和loss之类的东西。 返回值是(denseCoefficientMatrix.compressed,interceptVec.compressed,arrayBuilder.result()) 计算summaryModel、probabilityColName、predictionColName 模型表示模型存储首先Model会继承一个org.apache.spark.ml.util.MLWritable。这样就支持model.save()方法。另外，可以通过MLWriter来保存，对应model.write.overwrite().save() 预测过程LogisticRegressionModel的transform方法实际上实现在ProbabilisticClassificationModel里面，最终会调用predictRaw计算rawPrediction列。predictRaw和下面提到的一些方法都定义在ClassificationModel里面，不过是虚的。1234567if ($(rawPredictionCol).nonEmpty) &#123; val predictRawUDF = udf &#123; (features: Any) =&gt; predictRaw(features.asInstanceOf[FeaturesType]) &#125; outputData = outputData.withColumn(getRawPredictionCol, predictRawUDF(col(getFeaturesCol))) numColsOutput += 1&#125; 然后再调用predictProbability或者raw2probability计算probability列，这个列是一个Vector，表示每一个label的probability，加起来是等于1的（见ProbabilisticClassificationModel里面的注释）。所有继承了ProbabilisticClassifier的分类器都会有在这一列。123456789101112if ($(probabilityCol).nonEmpty) &#123; val probUDF = if ($(rawPredictionCol).nonEmpty) &#123; udf(raw2probability _).apply(col($(rawPredictionCol))) &#125; else &#123; val probabilityUDF = udf &#123; (features: Any) =&gt; predictProbability(features.asInstanceOf[FeaturesType]) &#125; probabilityUDF(col($(featuresCol))) &#125; outputData = outputData.withColumn($(probabilityCol), probUDF) numColsOutput += 1&#125; 然后再调用raw2prediction或者probability2prediction或者predict计算prediction列。 训练过程详解Summary过程首先使用MetadataUtils.getNumClasses来获得Class数量。1234567val numClasses = MetadataUtils.getNumClasses(dataset.schema($(labelCol))) match &#123; case Some(n: Int) =&gt; require(n &gt;= histogram.length, s"Specified number of classes $n was " + s"less than the number of unique labels $&#123;histogram.length&#125;.") n case None =&gt; histogram.length&#125; MetadataUtils是一个私有对象，里面会计算得到labelSchema对应的Attribute，然后来判断有多少类。Attribute对象的实现比较复杂，单独提到后面讲。1234567def getNumClasses(labelSchema: StructField): Option[Int] = &#123; Attribute.fromStructField(labelSchema) match &#123; case binAttr: BinaryAttribute =&gt; Some(2) case nomAttr: NominalAttribute =&gt; nomAttr.getNumValues case _: NumericAttribute | UnresolvedAttribute =&gt; None &#125;&#125; 接着判断是否是多类分类任务，主要是根据family的值来判断，再根据numClasses的值来校验。family可以取下面的值: auto（默认值） 自动根据class数量选择，如果numClasses == 1 || numClasses == 2，则是binomial，否则是multinomial binomial 基于pivoting的LR multinomial softmax的LR，不基于pivoting12345678910111213141516171819@Since("2.1.0")final val family: Param[String] = new Param(this, "family", "The name of family which is a description of the label distribution to be used in the " + s"model. Supported options: $&#123;supportedFamilyNames.mkString(", ")&#125;.", (value: String) =&gt; supportedFamilyNames.contains(value.toLowerCase(Locale.ROOT)))/** @group getParam */@Since("2.1.0")def getFamily: String = $(family)val isMultinomial = getFamily.toLowerCase(Locale.ROOT) match &#123; case "binomial" =&gt; require(numClasses == 1 || numClasses == 2, s"...") false case "multinomial" =&gt; true case "auto" =&gt; numClasses &gt; 2 case other =&gt; throw new IllegalArgumentException(s"Unsupported family: $other")&#125;val numCoefficientSets = if (isMultinomial) numClasses else 1 优化过程主要是创建了损失函数costFun，并对于这个损失函数使用优化器进行优化。123456789101112131415val regParamL1 = $(elasticNetParam) * $(regParam)val regParamL2 = (1.0 - $(elasticNetParam)) * $(regParam)val getAggregatorFunc = new LogisticAggregator(bcFeaturesStd, numClasses, $(fitIntercept), multinomial = isMultinomial)(_)val regularization = if (regParamL2 != 0.0) &#123; val shouldApply = (idx: Int) =&gt; idx &gt;= 0 &amp;&amp; idx &lt; numFeatures * numCoefficientSets Some(new L2Regularization(regParamL2, shouldApply, if ($(standardization)) None else Some(getFeaturesStd)))&#125; else &#123; None&#125;val costFun = new RDDLossFunction(instances, getAggregatorFunc, regularization, $(aggregationDepth))val states = optimizer.iterations(new CachedDiffFunction(costFun), new BDV[Double](initialCoefWithInterceptMatrix.toArray)) 首先来看损失函数RDDLossFunction的类定义。首先ClassTag用来实现保障类型擦除后类型安全的功能。12345678private[ml] class RDDLossFunction[ T: ClassTag, Agg &lt;: DifferentiableLossAggregator[T, Agg]: ClassTag]( instances: RDD[T], getAggregator: (Broadcast[Vector] =&gt; Agg), regularization: Option[DifferentiableRegularization[Vector]], aggregationDepth: Int = 2) extends DiffFunction[BDV[Double]] &#123; 12345678910111213141516 override def calculate(coefficients: BDV[Double]): (Double, BDV[Double]) = &#123; val bcCoefficients = instances.context.broadcast(Vectors.fromBreeze(coefficients)) val thisAgg = getAggregator(bcCoefficients) val seqOp = (agg: Agg, x: T) =&gt; agg.add(x) val combOp = (agg1: Agg, agg2: Agg) =&gt; agg1.merge(agg2) val newAgg = instances.treeAggregate(thisAgg)(seqOp, combOp, aggregationDepth) val gradient = newAgg.gradient val regLoss = regularization.map &#123; regFun =&gt; val (regLoss, regGradient) = regFun.calculate(Vectors.fromBreeze(coefficients)) BLAS.axpy(1.0, regGradient, gradient) regLoss &#125;.getOrElse(0.0) bcCoefficients.destroy() (newAgg.loss + regLoss, gradient.asBreeze.toDenseVector) &#125;&#125; 优化器LBGFS牛顿法的特点是收敛很快，但是运用牛顿法需要计算二阶偏导数，而且目标函数的Hesse矩阵可能非正定。对此，可以使用拟牛顿法，也就是用不包含二阶导数的矩阵近似牛顿法中的Hesse矩阵的逆矩阵。 是一种一阶方法。由于构造近似矩阵的方法不同，因而出现不同的拟牛顿法，BFGS是其中一种。因为BFGS仍然存在较大的内存占用。因此有了LBFGS算法，其中L指的是Limited的意思。下面，简单查看一下LBFGS的代码，可以发现，它继承了FirstOrderMinimizer优化器，印证了LBFGS是一个一阶方法。123class LBFGS[T](convergenceCheck: ConvergenceCheck[T], m: Int)(implicit space: MutableInnerProductModule[T, Double]) extends FirstOrderMinimizer[T, DiffFunction[T]](convergenceCheck) with SerializableLogging &#123; OWLQNOWL-QN(Orthant-Wise Limited-Memory Quasi-Newton)算法，该算法是基于L-BFGS算法的可用于求解L1正则的算法。 Loss函数treeAggregateseqOp操作会聚合各分区中的元素，然后combOp操作把所有分区的聚合结果再次聚合，两个操作的初始值都是zeroValue。treeAggregate和aggregate的区别是，aggregate在每个分区处理完之后就直接交给Driver合并了，但treeAggregate会在Executor直接树形地Aggregate。12345678910val sc = spark.sparkContextval rdd = sc.parallelize(1 to 100000).repartition(6)val start = System.currentTimeMillis();val reduceResult = rdd.reduce&#123;(x, y) =&gt; x + y&#125;val endReduce = System.currentTimeMillis();val aggregateResult = rdd.aggregate(0)((x, y) =&gt; x + y, (x, y) =&gt; x + y)val endAgg = System.currentTimeMillis();val treeAggregateResult = rdd.treeAggregate(0)((x, y) =&gt; x + y, (x, y) =&gt; x + y)val endTreeAgg = System.currentTimeMillis();println(s"reduceResult $&#123;reduceResult&#125; $&#123;(endReduce-start).toString&#125; aggregateResult $&#123;aggregateResult&#125; $&#123;(endAgg-endReduce).toString&#125; treeAggregateResult $&#123;treeAggregateResult&#125; $&#123;(endTreeAgg-endAgg).toString&#125;") 在六台机器上跑了，耗时如下1reduceResult 705082704 7073 aggregateResult 705082704 831 treeAggregateResult 705082704 755 BLAS库BLAS库的选择Spark的BLAS库实现在mllib/linalg下面。其底层借助于com.github.fommil.netlib，而netelib有两个BLAS库的实现，其中f2jBLAS是从Fortran代码翻译到Java里面的，nativeBLAS是用系统原生的。两个库的使用规则如下所示，至于为什么，参考爆栈网的解释的意思是f2j的实现在Level较低的情况的性能要更好一点。1234567private[mllib] def getBLAS(vectorSize: Int): NetlibBLAS = &#123; if (vectorSize &lt; nativeL1Threshold) &#123; f2jBLAS &#125; else &#123; nativeBLAS &#125;&#125; 这里的Level，指的是BLAS函数分为三个Level，Level越高，计算越复杂。Level1是向量之间的操作，Level2是 向量和矩阵之间的操作，Level3是矩阵和矩阵之间的操作。 axpy和Vector的实现axpy指的是线代里面的$y = a * x$这样的操作。axpy里面根据是否稀疏，进行讨论。对于DenseVector会直接调用daxpy。这里daxpy的d不是dense，而是指double，对应的saxpy指的是单精度，还有caxpy代表复数单精度和zaxpy代表复数双精度。对于SparseVector则要首先进行解码为DenseVector。SparseVector 用两个数组，一个记录原始向量中非零元素的值，另一个记录非零元素对应到原始向量的位置。这有点类似于一维的COO表示形式。 但不是所有的计算都需要转换为DenseVector的，例如向量的dot就不需要。观摩下面的代码发现，稀疏向量x中为0的列就不需要乘了。事实上有人进行了比较，Sparse算得快，但是构造慢。其中nnz表示number of nonzero entries。1234567891011121314private def dot(x: SparseVector, y: DenseVector): Double = &#123; val xValues = x.values val xIndices = x.indices val yValues = y.values val nnz = xIndices.length var sum = 0.0 var k = 0 while (k &lt; nnz) &#123; sum += xValues(k) * yValues(xIndices(k)) k += 1 &#125; sum&#125; gemm和Matrix的实现gemm，即通用矩阵乘（GEMM，General Matrix Multiplication），其公式为$ C = alpha * A * B + beta * C $，其定义如下。其中A大小$m*k$，B大小$k*n$，C大小$m*n$，且C.isTransposed必须是false。根据A是否为Dense，可以分为2个版本。123def gemm(alpha: Double, A: Matrix, B: DenseMatrix, beta: Double, C: DenseMatrix): Unit = &#123; 这里的Matrix同样分为Dense和Sparse。isTransposed表示有没有进行过转置。我理解用这个的原因是为了实现lazy的转置。DenseMatrix的四要素是numRows、numCols、 values和isTransposed，values是一维数组，因为我们可以通过numRows和numCols找到定位。SparseMatrix是六要素，多了colPtrs和rowIndices，values是一维数组，按列存储，实际上就是Compressed Sparse Columns(CSC)格式存储，如果isTransposed是true，那么就按照Compressed Sparse Row(CSR)存储。以isTransposed为false的情况为例，colPtrs表示每一列的起始在values中的位置，rowIndices表示在values中的每一个元素在是这一列中的第几行。 下面展示一下CSC的表示方法，例如矩阵1234561.0 0.0 4.00.0 3.0 5.02.0 0.0 6.0values=[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]rowIndices=[0, 2, 1, 0, 1, 2]colPointers=[0, 2, 3, 6] 下面看gemm的实现，首先要对A是不是Dense进行讨论，对Dense而言是平凡的，调用dgemm就行了。对于Spark而言，需要根据A和B有没有transpose过的四种情况进行讨论。下面我们来看A是Sparse，B是Dense对应的gemm重载下的四种情况。 首先来看A和B都没有转置的情况，我们现在是需要用A的对应行乘以B的对应列，可以看做左边的矩阵的每一列，分别去乘上右边矩阵对应的行，得到n个矩阵，然后我们将它们对应位置加起来就能得到C。这种方式可以参考我的MIT线性代数的学习报告 首先先要放缩一下C，这样我们的列乘行的操作可以直接在C.values上面累加，节约空间。123if (beta != 1.0) &#123; getBLAS(C.values.length).dscal(C.values.length, beta, C.values, 1)&#125; 下面是主体，包含两个循环。外层循环变量colCounterForB每轮递增，用来枚举到B的所有列nB，内层循环变量colCounterForA用来枚举A的所有列12345678910111213141516171819202122232425262728293031while (colCounterForB &lt; nB) &#123; var colCounterForA = 0 // The column of A to multiply with the row of B // kB=B行数=A列数kA // 因为按列存储，BStart表示第colCounterForB列开始的位置。 // 因为B是Dense的，所以可以直接乘 val Bstart = colCounterForB * kB // mA = A行数 // Cstart表示第colCounterForB列开始的位置，是对C而言的，且C有mA行 val Cstart = colCounterForB * mA while (colCounterForA &lt; kA) &#123; // 计算C的第colCounterForB列上所有行的部分值 var i = AcolPtrs(colCounterForA) val indEnd = AcolPtrs(colCounterForA + 1) // indEnd-i表示第colCounterForA列有多少个元素 // Avals(i)于对CSC格式的A的行进行遍历 // BVal是B的第colCounterForB列第colCounterForA行 // 遍历A的colCounterForA列上的每个行元素 // 可以看到，Cstart在内层循环是不变的，所以对Cstart对应的第colCounterForB列的操作会重复kA次 val Bval = Bvals(Bstart + colCounterForA) * alpha while (i &lt; indEnd) &#123; // Cvals是c.values // 对于A的colCounterForA上的每个行元素，加到C的对应位置上面，注意C是Dense的。 // 这Avals(i)相当于对CSC格式的行进行遍历 Cvals(Cstart + ArowIndices(i)) += Avals(i) * Bval i += 1 &#125; colCounterForA += 1 &#125; colCounterForB += 1&#125; 现在来看A转置B没有转置的情况，。我们现在是需要用A的对应行乘以B的对应列。因为A被转置了，所以问题实际上变简单了，因为A转置后的行，实际上就是A转置前的列，在物理上是连续存储的。因为我们恰恰需要的是A转置后的行，所以实际可以当做转置前的列来处理。 1234567891011121314151617181920212223242526272829// colCounterForB在每个while后递增，枚举到B的所有列nBwhile (colCounterForB &lt; nB) &#123; var rowCounterForA = 0 // mA=A行数，因为按列存储，表示第colCounterForB列开始的位置 val Cstart = colCounterForB * mA // kA=A列数=B行数kB，实际上是B的第colCounterForB列开始的位置 val Bstart = colCounterForB * kA // rowCounterForA枚举A的所有行 while (rowCounterForA &lt; mA) &#123; // 目标：设置C的第colCounterForB列第rowCounterForA行的元素 var i = AcolPtrs(rowCounterForA) val indEnd = AcolPtrs(rowCounterForA + 1) // i和indEnd表示A的第rowCounterForA行有多少元素， // 稀疏矩阵A的其他行是0，所以就可以不管了 var sum = 0.0 while (i &lt; indEnd) &#123; // 因为B是Dense的，这里要算一下实际的坐标， // 我们要知道B的是第colCounterForB列，对应到就是A的第colCounterForB行， // 所以查询ArowIndices表就能知道对应的行便宜 sum += Avals(i) * Bvals(Bstart + ArowIndices(i)) i += 1 &#125; val Cindex = Cstart + rowCounterForA Cvals(Cindex) = beta * Cvals(Cindex) + sum * alpha rowCounterForA += 1 &#125; colCounterForB += 1&#125; 有gemm就有gemv，也就是C变成Vector了。除此之外，还有对于各种不同m的特化实现。例如SYMV是对称矩阵乘法，TRMV是三角矩阵乘法。com.github.fommil.netlib.BLAS里面有dgbmv带状矩阵，dsbmv，dtrmv等。此外，这些在Breeze库里面也有提供。 启发 transpose可以做到lazy，但得是对二维特化的 矩阵可以Sparse存储 矩阵和多维数组最好单独实现 Breeze库breeze库是一个类似numpy的线性代数库其中BDM是一个Matrix，BDV是一个Vector，其实都是别名import breeze.linalg.{DenseMatrix =&gt; BDM} 其他代码Attribute对象Attribute继承自AttributeFactory这个object（原来伴生对象也能继承），主要是从StructField生成Attribute对象。StructField是构成StructType的成员。12345678910111213141516171819202122232425262728293031323334353637383940414243def fromStructField(field: StructField): Attribute = decodeStructField(field, false)// 下面这个函数主要就是从filed.metadata中解析得到Attribute对象private[ml] def decodeStructField(field: StructField, preserveName: Boolean): Attribute = &#123; require(field.dataType.isInstanceOf[NumericType]) val metadata = field.metadata val mlAttr = AttributeKeys.ML_ATTR // 值为ML_ATTR if (metadata.contains(mlAttr)) &#123; // 是使用metadata里面的名字，还是field.name的名字 val attr = fromMetadata(metadata.getMetadata(mlAttr)) if (preserveName) &#123; attr &#125; else &#123; // Copy with a new name attr.withName(field.name) &#125; &#125; else &#123; UnresolvedAttribute &#125;&#125;private[attribute] override def fromMetadata(metadata: Metadata): Attribute = &#123; import org.apache.spark.ml.attribute.AttributeKeys._ val attrType = if (metadata.contains(TYPE)) &#123; metadata.getString(TYPE) &#125; else &#123; AttributeType.Numeric.name &#125; // 首先得到一个AttributeFactory，然后结合metadata得到一个Attribute getFactory(attrType).fromMetadata(metadata)&#125;private def getFactory(attrType: String): AttributeFactory = &#123; if (attrType == AttributeType.Numeric.name) &#123; NumericAttribute &#125; else if (attrType == AttributeType.Nominal.name) &#123; NominalAttribute &#125; else if (attrType == AttributeType.Binary.name) &#123; BinaryAttribute &#125; else &#123; throw new IllegalArgumentException(s"Cannot recognize type $attrType.") &#125;&#125; Reference]]></content>
      <tags>
        <tag>Spark</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[福州游记]]></title>
    <url>%2F2020%2F05%2F05%2Ffuzhou-travel%2F</url>
    <content type="text"><![CDATA[由于疫情因素，原本的深圳之行最终改为了福州之行。我们分别从深圳和无锡出发，在福州站汇合。 出发前准备至少在4月18号之前，深圳市宝安区和广州市白云越秀两区一直是黄色风险，并且之前海南省确实也对广州过来的游客采取了相关措施。因此我们考虑了南京、上海、无锡、长沙、福州等多个选项，最终选择了福州。主要原因是之前公司的同事有回去过龙岩，说只要八闽健康码就行，并且各自的路程也是相近的，都是六个小时之内。 Apr 30D2304的火车，20.51到达福州站。A座，看不到大海。出站要检查八闽健康码或者微信扫码自助报备，我的八闽健康码这时候加载不出来了，搞了半天才通过微信的途径报备成功。南出站口出站，出站口很小，还要自己手动搬箱子上楼。因为太晚了，出门打了滴滴，叫我们在黄金大酒店门口等他，于是旁边又是一堆拉客的司机问我们走不走，果断拒了。福州还是比较热的，我们到住的小区门口是九点半还多了，下午在火车站点的外卖刚开始送，时间正正好。进小区门，门卫看我们推着箱子就要登记（看起来和之前回深圳一样，不推箱子他也不管），相关信息写一下，身份证拍个照片就行。进去之后找了半天一单元，果然是三栋楼里面的最后一栋呢，运气贼差。住的地方在32楼的民宿，这是一个复式的公寓，有上下两层，我们是在一楼，大门的钥匙放在外面的一个机械密码锁里面外面的门是一个转齿轮的密码锁，里面的门锁的下面插着把钥匙（好不安全，幸亏我及时发现了）。那个民宿里面有个投影仪很不错，我们又点了一个捞化的外卖（罗汉肉和海鲜）就去看电影。途中，我们发现自己房间里面的WIFI没有用所以只能用流量，当然，在几天后我发现投影连接的是楼上的WIFI，既然如此楼上WIFI肯定是有用的，所以我成功破解了楼上的WIFI。电影里面有在线观看的，是要额外冲爱奇艺或者腾讯会员的，连续包月的话要12块钱一个月，我们肯定不是这种前人栽树后人乘凉的人，所以就先看U盘（之前以为是房东送的，后来发现是Z自己带的）里面的什么隐形人，好像是个恐怖片吧。不过后来发现可以通过WIFI投影手机，所以后来也没怎么依赖这个东西。看了没一会，第一个外卖到了，感觉就是细面，一个里面是肉，一个里面是鱿鱼啥的，很鲜。我们吃了一会又去看了，但是十点二十的时候第二个外卖又到了，这下大家都没心思吃饭了。 May 1之前预约了12.00-16.00的福建博物院，所以早上起来，我们先去附近的耳聋伯，后来发现，什么达道牛肉、连江锅边啥的都在这里。我们是骑车过去的，但是后面发现在一个地方不好过马路，就走过去了，穿过一个像金富商业街一样的破落服装城就到了耳聋伯。吃了花生汤、汤圆和一个带着生僻字的东西。吃完耳聋伯，就走到地铁站，坐地铁到屏山站，已经是11:46了。我们扫了辆摩拜骑过去，我发现我手机里面有七块五包五一节的活动，但是Z的手机里面没有，所以最后他还是花的现金。停车在西湖公园的南门，我们打算从西湖公园逛过去，路上看到一棵超级粗的树，以为是什么百年名木，但旁边也没啥文物古迹的标识。博物院过了一座桥就到了，但是那是另外一个场馆，我们真正要去的场馆是要往西走的。逛完博物院，就顺路逛一下西湖公园。买了个菠萝吃。不知不觉逛出了公园，又从另外一个地方重新进了公园，还看到反方向有大熊猫展览啥的。路上看到有人在吃椰子，也想吃，但是没找到。在西湖公园的一个廊下面聊了会天（喂了一会蚊子），接着就顺路逛出公园，骑车前往三坊七巷。西湖公园到三坊七巷骑车大约9分钟吧，我们尝试从林觉民和冰心故居旁边的那个雅道巷过去的，不过发现似乎不行，所以又绕了一会，从南后街的正门进的。第一站是那个网红星巴克，它里面有个内庭院，还有个阁楼，阁楼上有个人在看内科学，学医好惨。然后我们看到了永和鱼丸，但是知乎上说永和鱼丸三坊七巷上的不正宗，要去道山路吃，所以我们没去吃，然后看到了同利肉燕，过去吃了一个三拼的。逛进了三坊七巷的一个收费景点，在外面只看到说要预约，就匆匆进去了，结果说是付费景点，一个人20。似乎是个园林，人特别少里面有个戏台子，然后就是几进庭院。后院有个门建得离地三尺，不知道是干什么用的。路过钢琴巷，发现被拉上了路障，不让进。我们又逛了一个南后街主路上的一个免费领票的博物馆，外面排了五六个人的队，前进很慢，因为都要量体温，登记信息啥的。领票的地方是出口，进口在左边一点，进去是一些从三坊七巷出来，我们打算看花巷教堂，本来打算走过去的，后来发现快四点半了，可能要关门，就骑车过去了。后来发现多虑了，这教堂门没开，问了后面的保安说不知道，要我们去大路上的门看看，又绕回去看了下，发现有个告示说不开放。不过很快Z发现东百11楼是个露台，可以俯瞰三坊七巷和花巷教堂的全景。于是我们就进到东百，发现MAC在卖王者荣耀联名款，不过怎么去到11楼呢？No idea，不过刚才吃货说要先去喝厝内小眷村，那我们先去好吃呗。从东百出来是一个变态的天桥，我们选择多走一点（并没有）过马路。买好奶茶了，重新回到东百，找到了电梯，我们上到了10楼。一进门一股食物的味道，像二招一样。但是通往11楼的电梯立刻就呈现在眼前了，大家都装作称赞Z聪明的样子。从东百平台下来后，因为一些特殊的原因，我们选择回到宾馆休息。晚上我们出来去逛了上下杭，因为就在我们宾馆旁边。不过这个景点似乎只开发了一半，一开始走的一段路很是无聊，黑灯瞎火，突然转了一个弯就豁然开朗，同利肉燕啥的店也在这里有分店，再转一个弯，感觉就有点像丽江古城或者平江路一样了。一道小河从中穿过，沿路两侧有各种酒吧和店面。水位很低，因此河堤岸内侧有很多五颜六色的灯光，从仿古的围栏根部还往下喷着水汽，搞得整个水面都很朦胧，花里胡哨。饿了，准备吃连江锅边，但是发现关门了，所以最后吃了达道牛肉。我们点了一碗牛肉面套餐，一碗牛杂，总共只花了31块，真的是便宜。感觉在深圳一碗牛肉面就得这么多了吧。。。拿到手，肉也是惊喜地多。吃完达道牛肉，就沿着八一七南路逛到中州岛。这一片感觉就像英武路一样，很多低档商业。闽江上很多湍流，感觉掉下去都不好游泳。往江的东边看去，是一些CBD样子的高楼的内透。过了解放桥北段，到了中州岛，岛上两边有奇怪的建筑，带着上世纪对时髦的理解的建筑，如今像是鬼城一样。解放大桥南段感觉好虚，一辆汽车开过的时候，路面都在晃。 我们宾馆旁边的地铁站也值得提一下，从C出口出去是一个杉杉的广告，上面很多互联网的职位。难道福州也有相关产业？ May 2中午起床直接打车去老福州徐记。主要是考虑到同样都有海蛎饼、BJW、南煎肝之类的东西，但是老福州徐记相比井榕大酒店和旺达小吃店要上档次一些。这家店人气非常旺，我们要在外面等位，同时我们可以先点菜。因为BJW要做20分钟才能做好，所以我们可以先点BJW。有三种佛跳墙，一种是最屌的卖819，次一点的是400+的，最便宜的是100+的民间佛跳墙。听到我们在问分量，于是推荐我们一个300+的佛跳墙，它的分量大概是老佛跳墙的1/4，但是价格是1/3。吃完，我们爬了会于山。于山上有个状元峰，但是我们只有榜眼。逛着就下去了，期间听了渣男和女朋友之间的虐恋故事和一个柏拉图恋爱的故事。因为太热了，我们最终还是逃回了地铁站，并且我前往鼓山的建议也没有得到采纳，于是我们在地铁站里面漫无目的乱走，从一个出口出来发现就到了东百了。于是又去三坊七巷逛了下昨天没去成的只能同时接待五个人的传统手工技艺博物馆。搞完了去买了个叫红瓶的奶茶，据说有跳跳糖，但我们买的那个款式没有，感觉就是和老福州徐记里面一样的那个大红袍奶茶。旁边一个大叔大妈看到我们点了两杯34块说我们好有缘分，他们三倍34块。喝完奶茶，我们去了林则徐祠堂，这个昨天就想去了，但是我走错了路，所以就没去，其实也就是。里面超级大，每次都在门边立一个牌子说出口在那边，但实际上我们过了超级多的门才出去。从林则徐祠堂出来，走到一个唐城宋街博物馆附近（打完车才发现，本来还准备去的），决定打车去福道。福道基本上都是3和5一进一出，我们听从了小红书还是马蜂窝的三进五出，但其实发现五进三出的人更多。我们到那边是五点一刻，花了十来分钟，还是蛮快的。下了车，去旁边的便利店买了水，我们走了一段上坡路就到了福道入口。保安随手一指，让我们往右边走，于是看到一段楼梯，大概有五六层。我们走了一圈，并没有发现有电梯，只好硬着头皮走上去。不得不说，福道比深圳光明的那个步道，或者香蜜公园的那个彩虹天桥要宏伟很多了，从3号到5号的距离得有7公里左右。它整个是高架的，有的纯粹凌空中搭建，但也有一部分是依山而建。每隔几百米，会有一个亭子，或者一段遮雨棚供人休息。中途还下了一场雨，这场雨来得真是仓促，瞬间就铺天盖地，和在深圳一样。不过大家都躲到的福道中间的休息凉亭上了。然而狂风还是卷着雨丝进来，坐在旁边的椅子上的我们书包都湿了。继续往前走，天黑了下来，福道两边亮起了黄色的灯，不同于我们家里那个彩虹桥，我们还是蛮喜欢这个温馨的黄色的，比那些花里胡哨的七彩渐变要好多了。从福道出来，我们打车去吃林记沙茶面。他那边是可以点菜加料的，因此我们点了两碗不同的料，里面有什么活肉、爆汁鱼丸、海带、千页豆腐和一些海鲜。这个沙茶面和我们在厦门吃的似乎不太一样，里面芝麻酱要浓很多，有点热干面的感觉。买了个椰子，发现有个元气森林的气泡水很好喝。回家发现走错路了，于是就骑自行车。选了一辆自行车，刚下过雨，坐垫上有水，想想这也就算了，掏出餐巾纸擦了擦，完事了推出来，发现脚蹬子掉了。我也是服了。。。 May 3中午起床，去吃了连江锅边，老板是一个戴着眼镜的比较热心的老奶奶，讲解我们什么是锅边的提问。原来锅边就是一种类似将肠粉切成一块一块的东西，我们合起来点了一碗。进了地铁站，又开始纠结到底要玩什么，搜了大众点评，发现有个撸鸭子的，又在东百，那又得过去。撸鸭子的地方在另一个门面，里面超级冷。撸完鸭子，开始好吃打卡。首先莓超疯奶茶，然后去吃了木金肉丸，也在三坊七巷。居然要测体温和登记，我们只点了两个肉丸，也往里面坐，没一会老板就丢给我们两个小纸袋。然后我们去道山路吃了永和鱼丸，因为小红书上说三坊七巷的不好吃。吃完了Z说吃撑了，要消消食，所以我们去爬了旁边的乌石山。乌石山上面也没啥，就是很多古人题写的碑文。我们试图从南边下山，不过下来发现没有出口，只好再爬上来。Z气死了，说要是再看到那个山顶的小区就要打死我。不过所幸我们最终还是找到了出口，近似从原路返回，从北面下了山。从乌石山下来已经是快五点半了，过马路扫了辆车（这货永远都不充值，结果亏得一匹，果然是理财专家）准备去买福鼎肉片。按照地图到了锦巷旁的小区，发现并没有找到，倒是发现一个很神奇的烂尾楼。在附近买了点杨梅，又绕进小区细细搜索一下（疫情期间管理好不严格啊），还是没找到，于是就放弃去刘小姐的古早味买车轮饼了。我们直接ride and takeaway走了，Z还买了点凤梨酥啥的。然后我们就穿过八一七路去买光头麻薯，然后我发现我走错了路，因为达明美食街被改成步行街不让自行车进了，我们应该直接走八一七路进去而不是走杨桥进去，然后Z又要上厕所，于是又过马路。上完厕所，推车过马路，刚停好，就被一个大妈拉住了，说这边不让停。不过你这一点标识都没有，是不是有点不教而诛呢？ May 4在大众点评上搜到一个说是福州排名第二的餐厅，是一家泰国菜叫泰蒲。貌似只开到中午两点，于是急急忙忙打车过去，结果路上堵+红绿灯花了快20分钟，还有点热。入口比较隐蔽，不过有大的招牌指路，所以我们还是轻松到了二楼，一进去果然要等11桌，坐在外面吃虾片，看B站新发的后浪。出来已经是三点了，但天还是很热，正好Z要搞什么鬼推荐信，所以就坐地铁回家了，下了地铁，风开始吹了。我们在宾馆搞推荐信搞到五点多，于是骑车去江心公园打算看葫芦弟弟儿童书店。我们骑车上了1号晚上看到的那个三县洲大桥，然后下来拐到江心公园。一进门有个平台，可以登高望远。 绕着江心公园闲逛，看到了葫芦兄弟，不过关门了。昨天就破解了楼上的WIFI，不过今天手机投影又出了问题，连不上投影仪了。捣鼓了半天，发现是手机和投影仪连的不是一个wifi，可能我们刚才把电影投在楼上的房间上了，好尴尬。。。看了会利刃出鞘，但其实啥都没看。。。晚上外卖又点了福鼎肉片。 May 5早上退房，打车到华塑小区吃东南亚菜，那边的什么阿宝阿川啥的都没有开业，店员说要等到十月份才会开张。。。总算明白攻略上时间凑巧是什么意思了。。。原来对日期而不是时间说的。我们在印尼妈妈那里吃了冰粉（感觉就是黑色的龟苓膏）和印尼肠粉，在旁边的烧烤摊吃了烤串，又进去点了个福鼎肉片。]]></content>
      <tags>
        <tag>游记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Python处理Excel和Word]]></title>
    <url>%2F2020%2F04%2F06%2FPython-excel-word%2F</url>
    <content type="text"><![CDATA[微软的Office系列具有非常厉害的技术，但产品具有极高的学习成本，例如在查找替换这一项，它不支持标准的正则表达式（毕竟是wysiwyg嘛，也要考虑样式），但不是基于正则表达式定制，而是自己另辟蹊径，这就有点让人难受了。而内置的Word VBA的相关文档和Demo又很少，基本要靠录制宏来现学现卖，而录制宏生成的代码过于adhoc，难以泛化，所以这时候借助于Python来处理相关文档就显得比较有意义。 Word VBA实例以下面这个为例，为了将一个小数转成百分数表示，我们先要搜索0.([0-9]{2})([0-9]@)^13这个串，其中^13表示换行符，@表示一个以上的字符或者表达式，类似于非贪心的+，在这里不太清楚@和*的行为有什么区别。 12345678910111213141516Sub DoReplace()With ActiveDocument.Range.Find .ClearFormatting .Replacement.ClearFormatting .Forward = True .Format = False .Wrap = wdFindContinue .MatchWildcards = True .Text = "0.([0-9]&#123;2&#125;)([0-9]@)^13" .Replacement.Text = "\1.\2%^p" ' 到这里为止，加上了百分比符号 .Execute Replace:=wdReplaceAll .Text = "0([0-9].[0-9]@%)" ' 去掉前面的0 .Replacement.Text = "\1" .Execute Replace:=wdReplaceAllEnd WithEnd Sub WordWord上的操作主要依赖docx这个库。我们用一个Document维护一个文档。一个文档由很多的段落组成，可以用下面的办法进行枚举。12for p in doc.paragraphs: print p 需要注意的是，paragraph是一个getter/setter方法12345678910111213# document.py@propertydef paragraphs(self): # _body是一个_Body对象，而后者继承了BlockItemContainer return self._body.paragraphs# blkcntnr.py@propertydef paragraphs(self): """ A list containing the paragraphs in this container, in document order. Read-only. """ return [Paragraph(p, self) for p in self._element.p_lst] 一个paragraph由很多个run组成，如果单纯设置或者访问paragraph.text，会丢掉格式。123456789101112# paragraph.py@propertydef text(self): text = '' for run in self.runs: text += run.text return text@text.setterdef text(self, text): self.clear() self.add_run(text) 加图片document.add_picture，会先在document的最后加上一个paragraph和run，在这个run里面加上picture123def add_picture(self, image_path_or_stream, width=None, height=None): run = self.add_paragraph().add_run() return run.add_picture(image_path_or_stream, width, height) Excel+Pandas可以通过Pandas来操作Excel，这里详见Pandas的介绍 Reference https://python-docx.readthedocs.io/en/latest/]]></content>
      <tags>
        <tag>python</tag>
        <tag>word</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OAuth2.0标准简析]]></title>
    <url>%2F2020%2F04%2F01%2Foauth2.0%2F</url>
    <content type="text"><![CDATA[以第三方接入的视角，讲解OAuth2.0协议。 Authorization Code方式Authorization Code方式主要涉及用户、第三方和Auth。在官方给到的图中，用户是人，通过UA（一般是浏览器）来交互，第三方是Client，Auth是Authorization Server。 用户请求第三方的受保护资源，因此第三方会将用户重定向到Auth。这个重定向请求会带着第三方的id、requested scope、local state和一个重定向URI。 用户通过UA访问Auth的页面进行登录。 假设登录成功，那么Auth会把UA的页面跳转到之前传给它的重定向URI。这个重定向请求会带上一个authorization code和之前传过来的local state，被发送到第三方的服务器。 在收到这个请求后，第三方会使用这个code去找Auth要最后的Access Token。需要注意的是，这一次的请求和之前的不同，不都是通过UA的跳转来实现的，而是由第三方的后台单独去请求的。这个请求包含code，用来获取code时传入的重定向URI。并且在另外的协议和通常实现中还要包含secret。 Auth验证第三方、code和重定向URI。如果验证通过，则返回Access Token。 Implicit方式URL中的#号称为Flagment。它的一个特性是它会出现在浏览器的地址栏里面，而不会随着HTTP请求发出去。例如下面的URL中，show会出现在GET中，但notshow不会。但在这个页面中，可以通过location.hash来读取notshow的内容。1xxx.com/login?show=1#notshow=2 因此这个机制可以实现在跳转前后的两个页面之间传递信息。例如当我们请求Oauth2.0标准的这个页面https://tools.ietf.org/html/draft-ietf-oauth-v2-21#page-20，那么我们实际上是请求https://tools.ietf.org/html/draft-ietf-oauth-v2-21这个URL，然后等页面加载完毕后，这个页面上的内容会读取page-20从而定位到第20页。12https://graph.qq.com/oauth2.0/show?which=Login&amp;display=pc&amp;client_id=iii&amp;response_type=token&amp;scope=all&amp;redirect_uri=xxx.com/loginhttp://xxx.com/login?#access_token=yyy&amp;expires_in=7776000 Reference https://tools.ietf.org/html/draft-ietf-oauth-v2-21#page-20 https://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html https://www.chrisyue.com/security-issue-about-oauth-2-0-you-should-know.html]]></content>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python HTTP Server实现详解]]></title>
    <url>%2F2020%2F03%2F18%2Fpython-httpserver%2F</url>
    <content type="text"><![CDATA[本文讲解Python 2.7版本上的HTTP Server的实现。 钻研这个代码主要是因为线上出现了一个这样的问题。123456789101112Traceback (most recent call last):File "xxx.py", line 3245, in __init__BaseHTTPRequestHandler.__init__(self, A, B, C)File "/usr/lib64/python2.7/SocketServer.py", line 649, in __init__self.handle()File "/usr/lib64/python2.7/BaseHTTPServer.py", line 340, in handleself.handle_one_request()File "/usr/lib64/python2.7/BaseHTTPServer.py", line 310, in handle_one_requestself.raw_requestline = self.rfile.readline(65537)File "/usr/lib64/python2.7/socket.py", line 476, in readlinedata = self._sock.recv(self._rbufsize)error: [Errno 104] Connection reset by peer 一开始我是怀疑HTTP1.0的Server不能正确响应HTTP1.1的请求，但后来发现Python2.7对HTTP1.1的实现也就是是否设置close_connection字段的问题，结果看了一圈代码，没发现这个库会在套接口被关闭之后会再处理读取这个套接口。事实上，只有在TCPServer.server_close函数中才会调用self.socket.close()方法，而socket.close()方法也是唯一会将self._sock清空的。 一个请求的路由首先介绍一下打交道最多的BaseHTTPRequestHandler，在里面需要用户自己定义对每个请求的处理方法，例如要实现do_GET、do_POST等。这个东西实际上是每个请求都会创建一个，所以我们需要把全局用到的东西写到类成员里面。BaseHTTPRequestHandler的继承链是BaseRequestHandler -&gt; StreamRequestHandler -&gt; BaseHTTPRequestHandler。 Server的继承链是BaseServer -&gt; TCPServer -&gt; HTTPServer 从Server到HandlerBaseServer(TCPServer).process_request -&gt; BaseServer(TCPServer).finish_request -&gt; BaseRequestHandler.__init__这个调用链解释了请求从Server到Handler的过程。可以看出，在finish_request中会直接创建一个RequestHandlerClass的实例，这个对应的就是我们继承实现的BaseHTTPRequestHandler。 123456789101112131415161718192021222324class BaseServer: def process_request(self, request, client_address): """Call finish_request. Overridden by ForkingMixIn and ThreadingMixIn. """ self.finish_request(request, client_address) self.shutdown_request(request) def finish_request(self, request, client_address): """Finish one request by instantiating RequestHandlerClass.""" self.RequestHandlerClass(request, client_address, self) class BaseRequestHandler: def __init__(self, request, client_address, server): self.request = request # 这是一个socket._socketobject对象，也就是一个套接口 self.client_address = client_address # 这是一个(addr, port)的tuple self.server = server # 这是Server对象 self.setup() try: self.handle() finally: self.finish() 在StreamRequestHandler中handle和finish被重写，在这里设置wfile和rfile。 123456789101112131415161718192021class StreamRequestHandler(BaseRequestHandler): def setup(self): self.connection = self.request if self.timeout is not None: self.connection.settimeout(self.timeout) if self.disable_nagle_algorithm: self.connection.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, True) self.rfile = self.connection.makefile('rb', self.rbufsize) self.wfile = self.connection.makefile('wb', self.wbufsize) def finish(self): if not self.wfile.closed: try: self.wfile.flush() except socket.error: # A final socket error may have occurred here, such as # the local error ECONNABORTED. pass self.wfile.close() self.rfile.close() Handler下面是BaseRequestHandler.__init__的实现，主要涉及setup()和handle()方法。setup()继承自StreamRequestHandler。123456789def setup(self): self.connection = self.request if self.timeout is not None: self.connection.settimeout(self.timeout) if self.disable_nagle_algorithm: self.connection.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, True) self.rfile = self.connection.makefile('rb', self.rbufsize) self.wfile = self.connection.makefile('wb', self.wbufsize) handle()代码如下，可以看到，当开启HTTP1.1后，close_connection会变成0，此时会一直handle_one_request。只有当收到的HTTP请求中也是HTTP1.1的，并且Connection: Keep-Alive时候close_connection才会变为0。当超时、Connection: Close、请求为空时，close_connection会变成1。1234567def handle(self): """Handle multiple requests if necessary.""" self.close_connection = 1 self.handle_one_request() while not self.close_connection: self.handle_one_request() handle_one_request这个是实际处理HTTP的逻辑注意self.rfile.readline可能会阻塞。readline参数接受一个表示size的字段，格式类似GET /login_validate?username=aaa&amp;password=bbb HTTP/1.1\r\n。如果读到的过长，会返回414错误，表示请求的URL过长。12345678910111213141516171819202122232425262728293031323334def handle_one_request(self): """Handle a single HTTP request. You normally don't need to override this method; see the class __doc__ string for information on how to handle specific HTTP commands such as GET and POST. """ try: self.raw_requestline = self.rfile.readline(65537) if len(self.raw_requestline) &gt; 65536: self.requestline = '' self.request_version = '' self.command = '' self.send_error(414) return if not self.raw_requestline: self.close_connection = 1 return if not self.parse_request(): # An error code has been sent, just exit return mname = 'do_' + self.command if not hasattr(self, mname): self.send_error(501, "Unsupported method (%r)" % self.command) return method = getattr(self, mname) method() self.wfile.flush() #actually send the response if not already done. except socket.timeout, e: #a read or a write timed out. Discard this connection self.log_error("Request timed out: %r", e) self.close_connection = 1 return]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Innodb学习笔记]]></title>
    <url>%2F2020%2F02%2F13%2Finnodb-learn%2F</url>
    <content type="text"><![CDATA[本文是有关InnoDB实现原理的读书笔记，主要包含： 《MySQL技术内幕(InnoDB存储引擎)第2版》 《MySQL内核：INNODB存储引擎 卷一》 在本文中，主要介绍下面内容： MySQL/InnoDB的配置和搭建 MySQL/InnoDB的宏观架构 MySQL/InnoDB的日志，以及事务中涉及到日志相关的部分 在本文中，不会详细介绍： 刷脏页机制 MVCC机制 索引机制和索引页的维护 MySQL服务器 配置InnoDB的源码可以在MySQL项目中获取，具体是在storage/innobase下面。 首先需要执行下面两行，以便创建服务12mysqld --initialize --user=mysql --consolemysqld -install 然后net start mysql，如果出现下面的错误，表示mysql没有初始化，例如data文件夹就没有被正式创建，要使用mysqld --initialize-insecure来初始化1234MySQL 服务正在启动 .MySQL 服务无法启动。服务没有报告任何错误。 MySQL体系结构与存储引擎MySQL主要架构MySQL的架构如下图所示 可以通过SHOW ENGINES命令来查看当前MySQL支持的存储引擎。也可以查找information_schema架构下的ENGINE表来实现。 InnoDB的表存储于ibd文件中，通过MVCC实现高并发性，并实现了SQL标准规定的四种隔离级别，默认级别是RR。 MyISAM不支持事务和表锁，但支持全文索引，主要面向OLAP。MyISAM在MYD中存储表数据，在MYI中存储表索引。 InnoDB主要架构InnoDB的主要架构如下所示。 其中主线程中主要根据数据库状态运行主循环(loop)、后台循环(backgroup loop)、刷新循环(flush loop)和暂停循环(suspend loop)四个循环。 若干IO Thread主要分为四类：read、write、insert buffer和log IO，在当前版本下，可以通过innodb_read_io_threads等参数进行设置。Purge Thread用来回收已经使用并分配的UNDO页，当设置innodb_purge_threads大于0时，该线程会启动，从而减轻主线程负担。Page Cleaner Thread用来刷新脏页，它也是为了减轻主线程负担。 Log为了便于理解，先要介绍一些前置知识，这些知识在第3、4章等章节中。MySQL中有binlog、slowlog、error log、查询日志等日志形式。具体到存储引擎层，InnoDB又有redo log和undo log。 Slow log通过show variables like &#39;log_error&#39;\G可以获得error log的存储位置，error log可以定位一些严重的错误，例如MySQL无法启动等问题。slowlog可以定位下面的一些问题: 查询时间超过阈值 1show variables like 'long_query_time'\G 没有通过索引的查询 1show variables like 'log_queries_not_using_indexes'\G 用来限制每分钟最大的2的数量 1show variables like 'log_throttle_queries_not_using_indexes'\G slowlog的相关信息可以在mysql数据库的slow_log表下面看到，可以通过mysqldumpslow进行展示。 查询日志查询日志存储了所有对MySQL的请求信息。 binlogbinlog在MySQL 5.1之后的版本引入，记录了MySQL对数据库进行更改的所有操作。可以通过show master status\G获得binlog的存储位置。binlog可以被用来恢复数据、主从复制以及审计(audit)，例如统计是否有对数据库的攻击。当sync_binlog==0时，由底层文件系统控制对binlog缓存的刷新。对于InnoDB而言，它将binlog统一写到一块缓存中，等事务提交之后，直接将缓冲中的binlog写入binlog文件，该缓冲大小由binlog_cache_size决定，默认为32K，并且是基于会话的。可以通过mysqlbinlog查看当前的binlog。 redo/undo log和binlog不一样，redo/undo log是物理日志，记录了数据页的修改，而binlog是逻辑日志，记录了事务的原始逻辑。redo/undo log在事务执行过程中随时写入，而binlog是在事务commit前写入的。 Redo log简介InnoDB通过force log at commit机制实现事务的持久性。即当事务提交的时候，要首先将redo log（而不是undo log）写入文件进行持久化。这里注意，一般redo log会先被写到内存中的缓冲区内，但提交的时候强制刷盘。盘实际上是一次fsync操作，确保位于内核高速缓冲区的数据被磁盘。特别地，如果我们不希望使用文件系统的缓存，需要设置O_DIRECT启用直接IO/裸IO，从用户空间直接将写到磁盘（比如说DMA）上。此外，还有一个O_SYNC，这个表示write操作在操作系统将所有数据发送给磁盘之后才能返回。当然了，通过设置innodb_flush_log_at_trx_commit为0，可以不让InnoDB在每次提交事务的时候都fsync，这样的话就依赖于其他两个定时和剩余空间的条件了。当MySQL宕机后，可能会丢失1秒内的事务。特别地，这个值还可以被设为2，此时数据会被写到内核高速缓存中，但不会立即刷入磁盘，在这种情况下，只要系统不宕机，那么MySQL宕机后的安全性也是能得到保证的。 undo log简介以及和redo log的比较redo log实际上可以保证事务的Duration特性。相应地undo log记录数据被修改前的值，实际上保证事务的Isolation特性。undo log常用的地方是： 事务失败时rollback MVCC功能 在InnoDB中每个SQL语句执行前都会得到一个read view，其中主要保存了当前活跃（没有commit）的事务的ID号。根据数据库的Isolation特性，这些事务对本事务是不可见的。 通过读undo log链可以看到该条记录的历史版本，可以实现不同事务版本号都拥有自己独立的快照数据版本。 读写和刷盘通过redo log可以在宕机恢复后恢复已提交的事务，如果没有redo log，就需要在事务commit时完成所有的刷脏页操作。但这个对性能是一个损伤，有了redo log，就可以把日志记到磁盘上，然后异步刷脏页了。通过undo log可以在宕机恢复后回滚未提交的事务，如果有了undo log，在事务提交前也可以刷脏页了。 redo log基本上顺序写的，但是undo log需要随机读写。redo log存储于形如ib_logfile*的文件里面。此外，redo log是在4GB的空间中循环写的，所以没有归档的功能。如果需要归档，就要借助于类似ib_arch_log_形式的归档重做日志，该日志始终是对ib_logfile1这个文件进行归档。InnoDB一般先会把redo log写到位于内存中的缓冲区内，然后在下面三种情况下进行刷新 每隔一秒 每个事务提交时 redo log缓冲池剩余空间小于1/2 binlog和redo/undo log的协同工作两阶段提交2PC需要特别注意，2PC不是2PL。其实我们在专门的文章中已经介绍过原始版本的2PC和3PC算法了，我们将研究这个算法在MySQL中的应用。 在同时出现有binlog和redo log日志时，如何提交事务呢？是先写哪个log？在故障恢复时，以哪个log为准？此外，还要考虑到binlog还被用来进行MySQL的主从复制，这使得Master库的数据实际依赖于redo log，而Slave库的数据实际依赖于binlog，问题更加复杂。例如Master写了binlog，然后还没有写redo log就宕机了，但是这个binlog已经被传给Slave执行了，那主从不一致就会发生。 因此，我们需要设计一套合适的提交流程，两阶段提交innodb_support_xa被用来解决这个问题。此时MySQL会把这个普通事务作为XA事务来处理，但是这个XA事务并不是分布式事务，而是作为内部XA事务。内部XA事务用于同一实例下跨多引擎事务，由Binlog作为协调者，比如在一个存储引擎提交时，需要将提交信息写入二进制日志，这就是一个分布式内部XA事务，只不过二进制日志的参与者是MySQL本身。而对外部XA而言，应用程序是协调者。 MySQL的两阶段提交的实现ha_commit_trans是： 写redo log，并标记该事务处于prepare状态 实际上，是调用下层引擎提供的prepare方法。并且会获取prepare_commit_mutex锁。 【Q】此时需要落盘么，还是到第3步落盘？应该是这一步就要落盘了。 【Q】事务的状态会被写到redo log里面么？ 此时Duration得到了保障，但是该状态下的事务对其他事务是不可见的。 写binlog，binlog和redo/undo log共用一个XID标记唯一事务。 注意binlog也需要落盘。 标记事务处于commit状态 【Q】这里应该也会写redo log的吧？ 返回客户端 因此，我们可以回答上面的问题： 先写哪个log？顺序是先redolog再binlog。 以哪个log为准？以binlog为准，如果binlog上没有记录，说明事务没有提交。 为了保障Crash Safe，需要保证“双1”，也就是之前提到的innodb_flush_log_at_trx_commit和sync_binlog都要设置为1。 【存疑】在崩溃恢复时，从InnoDB的角度来说，需要检查redo log： 如果标记了commit，则commit。那么要不要检查binlog了呢？我认为不需要，因为binlog必然是有的，不然为啥redo log能变成commit呢？ 如果标记了prepare，则检查binlog，如果该日志存在并且完整，则commit，否则rollback。对于这一步，有说是恢复到prepare的。 如果还没有prepare，则回滚。 从MySQL执行的角度来说： 扫描最后一个binlog，提取XID 这是因为事务不会跨binlog，并且binlog rotate的时候会刷盘。 扫描redo log中所有处于prepare状态的XID，和binlog中最后一个XID比较。如果存在即提交，否则回滚。 Group Commit Bug上面的过程中，“双1”的要求导致性能是下降的。然而，叫做Group Commit Bug的问题会加重这一点。 首先介绍Group Commit呢。因为fsync的代价很大，所以InnoDB实现了Group Commit技术，也就是将多次事务提交通过一次fsync刷回磁盘。也就是将所有要fsync的事务加入一个队列，由队头的线程负责将队列中所有的事务都一次fsync掉。在这个过程完成之后，队伍中的所有线程都被唤醒，完成自己的事务提交工作。可以看出，通过Group Commit，可以实现“并发”提交多个事务。 然后我们可以得到一个观察，在Group Commit时binlog和redo log日志的顺序未必是相同的。就如下面这张著名的图一样，事务的执行顺序是1/2/3，binlog也是按照这个顺序提交的。但是因为2PC并没有约束不同事务的提交顺序，所以InnoDB可以按照2/3/1的顺序提交。在“On-line Backup Taken”后，Slave的备份中会没有T1的提交记录。 可以看出，二阶段提交能够保证同一个事务的redo log和binlog的顺序一致性问题，但是无法解决多个事务提交顺序一致性的问题。为此，在5.5之前版本的MySQL的做法是在prepare时就获取prepare_commit_mutex锁，并且在事务commit之后再释放。这就导致了prepare、写log、commit这个过程全部是串行的，Group Commit名存实亡。这也就是这个bug的核心内容。 Binary Log Group Commit(BLGC)技术5.6方案将原来2PC中的commit拆分为三个阶段： flush 多线程按照进入顺序将binlog从缓存写到文件，但不刷盘。 sync 将文件中的binlog一次性刷盘。 commit 各个线程按顺序，作commit（这是一个InnoDB过程）。 这三个阶段各自维护一个队列，第一个进入队列的线程成为Leader，和原先的Group Commit一样，代理队列中的所有线程完成该阶段的任务，然后把这个队列全部移动到下个队列中。如果下个队列是非空的，那么Leader需要把自己变成下个队列的Follower。 5.7方案在5.6的逻辑中，每个事务独立做prepare，并且write/sync redo log，这一部分可能成为性能瓶颈。在5.7版本中，将redo log刷盘的实际推迟到了flush阶段，放到写binlog文件操作前。这样redo log也能实现按Group批量写了。 这种方案的流程： flush 刷盘redo log。 写binlog，不刷盘。 如果在这个阶段发生宕机，因为binlog未必刷盘，是易失的，所以可能会导致该组事务rollback。 sync binlog刷盘。 通过binlog_group_commit_sync_delay和binlog_group_commit_sync_no_delay_count在时间和数量上控制刷盘。 在这个阶段后，因为binlog已经刷盘，所以在宕机后要提交事务。 commit 依次Commit该组事务。 由于binlog已经刷盘，所以这个过程并不需要刷盘。 得到如下图所示的2PC过程简图。 LSNLSN(log sequence number)是InnoDB中的一个长度为8字节的数，表示每个redo log的编号，具体来说，表示事务写入到redo log的字节总量，有点类似于TCP里面的Sequence Number。下面show status语句中的这些数字，就是LSN。1234&gt; show engine innodb status\GLog sequence number 19739600 表示当前最新的redo log（一般在缓冲区内）的LSNLog buffer assigned up to 19739600 Log buffer completed up to 19739600 下面written和flushed的差别，就是写了多少和刷新多少的区别，由于至少保证了每秒都fsync，所以两者差距应该不大。12Log written up to 19739600Log flushed up to 19739600 表示已经刷到磁盘上的redo log的LSN 下面的这些项目，描述了刷脏页和建立检查点的进度。123Added dirty pages up to 19739600 Pages flushed up to 19739600 表示已经刷到磁盘上数据页的最高的LSNLast checkpoint at 19739600 表示Checkpoint上的最高LSN LSN存在于redo log、数据页和checkpoint中。在数据页中的LSN，即FIL_PAGE_LSN，表示该页最后刷新时的LSN。同理，checkpoint中也会存放目前已经刷新到的LSN。因为在数据库宕机后，会从checkpoint往后开始刷脏页，所以如果检查点LSN和redo log文件的LSN是相同的，表示所有的刷脏页工作都完成了，就不需要再刷脏页恢复了。 页InnoDB将数据按层次划分为表空间、segment、extent、page。其中页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小一般为16KB，但可以通过innodb_page_size进行设置。当16KB的页放不下时，就可能发生行溢出，此时数据放在未压缩BLOB页中。 在InnoDB中，页包括 索引页(B-tree Node) 因为MySQL使用聚簇索引，所以实际上索引页就是数据页。 undo页 系统页 事务数据页 插入缓冲位图页 未压缩BLOB页 压缩BLOB页 数据页的构成如下图所示 缓冲池InnoDB设有缓冲池，用来存放从磁盘中读到的页，在缓冲池中的页一般称为逻辑页(page)，在硬盘上的页一般称为物理页(block)。在读取页时，首先会尝试从缓冲池中查找，否则读磁盘上的页。通常，缓冲池中的缓存页类型有索引页、数据页、undo页、insert buffer、adaptive hash index、锁信息lock info、数据字典信息。InnoDB将innodb_buffer_pool_instances设置为大于1，此时可以得到多个缓冲池实例。缓冲池中的Database pages通过LRU算法进行管理（但adaptive hash index、lock信息、insert buffer等信息并没有放在缓冲池中），将最近使用的页放在最前面。InnoDB为LRU加入了midpoint位置，新读到的页会先放到midpoint，而不是LRU首部，在midpoint之前的称为new列表，之后的称为old列表。当数据库启动时，LRU是空的，这时候首先需要从Free列表中查找可用的空闲页，放到LRU中，否则使用LRU算法淘汰列表末尾的页。可以通过SHOW ENGINE INNODB STATUS观察LRU列表和Free列表的情况。例如，可以通过Buffer pool hit rate（实际没找到在哪里）缓冲池命中率，如果命中率较低的话，需要观察是不是因为全表扫描引起的LRU列表被污染的问题。还可以通过information_schema.INNODB_BUFFER_POOL_STATS观察缓冲池的运行状态。 插入缓冲(Insert Buffer)我们知道，聚簇索引下，表中相邻行存储的物理顺序和逻辑顺序是一致的，因此一张表只能有一个聚簇索引，InnoDB的聚集索引按照主键进行聚集。但是，辅助索引是非聚簇索引，对于它们的插入或更新操作，就可能会导致随机读写，从而产生性能问题。因此，InnoDB引入了插入缓冲，此时不是将数据直接插入到索引页中，而是先判断要插入的索引页是否在缓冲池中，若在，则直接插入；若不在，则先放入到一个insert buffer对象中，这样就可以先返回了。在后台线程中将insert buffer更新(merge)到辅助索引上。插入缓冲的好处是能将同索引页多个插入合并到一个操作中完成，类似这种多次写合并成一次写的操作，在InnoDB的实现中是非常常见的优化，例如Group Commit等功能实际上也是基于同样的优化思路。 插入缓冲需要满足以下的条件： 执行插入或者更新的是非聚簇索引 索引不是unique的 反过来想，如果可以是unique的，那么在插入的时候就需要保证此时这个键还没有，而这就要去查索引了。本来插入缓冲引进就是为了避免查索引的，这下每次都要查了，就是南辕北辙，所以插入缓冲是不能对unique适用的。 Change BufferCheckpoint刷脏InnoDB使用Checkpoint的机制将buffer pool中的脏页刷新回磁盘，这样可以抑制redo log和缓冲池的不断增长，同时避免在宕机后通过redo log重头开始恢复造成很大的恢复开销。 Checkpoint分为Sharp和Fuzzy。Sharp会刷buffer pool里面所有的脏页，并且记录下最新的已提交事务的LSN。Sharp产生数据库在某一时刻的一致性数据，如果在运行时发生，会严重降低可用性，因此一般在数据库关闭时用。 Fuzzy只会刷新一部分脏页。Fuzzy主要分为以下情况 主线程以一定时间间隔刷新脏页 FLUSH_LRU_LIST 当LRU列表中的空闲也不够时，需要移除掉尾端的页，如果这些页是脏页的话，需要做checkpoint。从MySQL 5.6版本后，这个过程由Page cleaner线程执行。 Async/Sync Dirty Page too much 这个很直接，当缓冲池里面的脏页太多的时候，就会触发Checkpoint。 doublewrite刷盘的过程存在partial write的问题。因为InnoDB的页大小(16KB)通常大于操作系统的页大小(4KB)，因此刷盘的过程往往不是原子的。例如当写完第一个4K块之后系统因为停电而宕机，这一块的page数据就会被破坏。 那么redo log能够解决问题么？并不能，因为page已经损坏了，我们怎么知道用什么redo log来恢复这个page呢？【Q】也许可以从某一个checkpoint读取redo log来恢复了？ 为了解决这个问题，InnoDB引入双写(doublewrite)策略。也就是在刷盘时，先将脏页写到内存中的2MB大小的doublewrite buffer上。接着doublewrite buffer会分两次，每次写1MB到共享表空间，并且立刻刷盘。在doublewrite刷盘结束之后，在将doublewrite buffer的数据写入真正的数据文件上。 文章指出，在启用主从复制的时候，从库上可以关闭doublewrite功能。 Reference https://blog.csdn.net/b1303110335/article/details/51174540 https://www.cnblogs.com/softidea/p/5977860.html https://zhuanlan.zhihu.com/p/349420901 https://zhuanlan.zhihu.com/p/101571164 MYSQL内核：INNODB存储引擎 卷一 MySQL技术内幕(InnoDB存储引擎)第2版 https://dev.mysql.com/doc/refman/5.7/en/index-condition-pushdown-optimization.html https://www.cnblogs.com/xibuhaohao/p/10899586.html http://zhongmingmao.me/2019/01/15/mysql-redolog-binlog/ https://blog.csdn.net/m0_45406092/article/details/112949294 http://keithlan.github.io/2018/07/24/mysql_group_commit/ https://www.zhihu.com/question/413276827/ https://sq.163yun.com/blog/article/188020255134334976 https://www.cnblogs.com/zhoujinyi/p/3435982.html https://cseweb.ucsd.edu/classes/sp16/cse291-e/applications/ln/lecture8.html https://www.cnblogs.com/zhoujinyi/p/5257558.html https://zhuanlan.zhihu.com/p/343449447 https://opensource.actionsky.com/20190404-mgr/ http://jockchou.github.io/blog/2015/07/23/innodb-architecture.html http://jockchou.github.io/blog/2015/07/23/innodb-doublewrite-buffer.html]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性代数复习————以MIT18.06为指导]]></title>
    <url>%2F2020%2F01%2F15%2Flinear-alg%2F</url>
    <content type="text"><![CDATA[本文从MIT的线代教程的角度重新学习线性代数。 前置定义线性组合(Linear combination)是线性代数中具有如下形式的表达式。其中$v_i$为任意类型的项，$a_{i}$为标量。这些标量称为线性组合的系数或权。$$w=a_{1}v_{1}+a_{2}v_{2}+a_{3}v_{3}+\cdots +a_{n}v_{n}$$ 方程组的几何解释以下面的方程进行讨论$$\begin{equation}\begin{bmatrix} 2 &amp; -1 \\ -1 &amp; 2 \\\end{bmatrix}\begin{bmatrix} x \\ y \\\end{bmatrix}=\begin{bmatrix} 0 \\ 3 \\\end{bmatrix}\end{equation}$$首先可以从行向量的角度来看待，它是平面内两条线的交点。同时还可以从列向量的角度来看待，如何对两个列向量进行线性组合，从而得到右边的向量。$$\begin{equation}x\begin{bmatrix} 2 \\ -1 \\\end{bmatrix}+y\begin{bmatrix} -1 \\ 2 \\\end{bmatrix}=\begin{bmatrix} 0 \\ 3 \\\end{bmatrix}\end{equation}$$ 考察方程$Ax=b$是否有界，等价于所有列的线性组合能否填满整个空间。 矩阵消元考虑下面的方程$$\begin{equation}\begin{bmatrix} 1&amp;2&amp;1 \\ 3&amp;8&amp;1 \\ 0&amp;4&amp;1 \\\end{bmatrix}x=\begin{bmatrix} 2 \\ 12 \\ 2 \\\end{bmatrix}\end{equation}$$ 首先消元，做成上三角矩阵$U$。方法就是首先选定first pivot主元，位于第一行第一列的1，然后将下面的(2, 1)和(3, 1)都消掉。如果主元是0，就换行。如果通过换行不能得到三个主元，那么这个矩阵就是坏的。行列式是所有主元元素的乘积（这个我听课的时候没听到）下面是回代，即通过增广矩阵(augment matrix)，将$Ax=b$变成$Ux=C$。我们定义$E_{21}$表示能够对位置(2, 1)进行消元的矩阵，它应该是 $$\begin{equation}\begin{bmatrix} 1&amp;0&amp;0\\ -3&amp;1&amp;0 \\ 0&amp;0&amp;1 \\\end{bmatrix}\end{equation}$$同理，我们还有$E_{32}$，那么我们就能够构成整个消元的过程，容易看到，变换是满足结合律的$$U = (E_{32} (E_{21} A))$$我们可以组合起来得到，这里的$E$是一个初等矩阵$$U = E A$$ 转置(permutation)，左乘表示行变换，右乘表示列变换。因此我们常常看到有$x^T A x$这样的变换方式，这种实际上是二次型，对行和列都会进行变换。$$\begin{equation}\begin{bmatrix} 0&amp;1 \\ 1&amp;0 \\\end{bmatrix}\begin{bmatrix} a&amp;b \\ c&amp;d \\\end{bmatrix}=\begin{bmatrix} c&amp;d \\ a&amp;b \\\end{bmatrix}\end{equation}$$ $$\begin{equation}\begin{bmatrix} a&amp;b \\ c&amp;d \\\end{bmatrix}\begin{bmatrix} 0&amp;1 \\ 1&amp;0 \\\end{bmatrix}=\begin{bmatrix} b&amp;c \\ d&amp;a\\\end{bmatrix}\end{equation}$$ 矩阵乘法和逆矩阵本章首先提出了矩阵乘法的五种看待方法，考虑矩阵乘法$A B = C$，其大小分别为$(m \times n) \times (n \times p) = (m \times p)$。$$A =\begin{equation}\begin{bmatrix} 1&amp;3 \\ 2&amp;7 \\\end{bmatrix}\end{equation}$$ 第一种方法是最传统的，左边的行乘上右边的列，我们得到的是一个点。第二种方法看做左边的矩阵，分别去乘上右边矩阵的每一列，这样得到$m$个列向量，然后我们把它们拼起来就能得到$C$第三种方法看做左边的矩阵的每一行，分别去乘上右边矩阵，这样得到$p$的行向量，然后我们把它们拼起来就能得到$C$第四种方法看做左边的矩阵的每一列，分别去乘上右边矩阵对应的行，得到$n$个矩阵，然后我们将它们对应位置加起来就能得到$C$第五种方法是分块矩阵。 对于方阵而言，左逆等于右逆$A^{-1} A = I = A A^{-1}$。一个可逆矩阵就是非奇异的non singular。 LU分解逆矩阵的特性，这个只要注意到$AA^{-1}=I$就可以了，教授用了一个经典的比喻，就是穿衣服先穿里面的，再穿外面的；那么脱衣服也要先脱里面的，再脱外面的。$$(AB)^{-1} = B^{-1}A^{-1}$$证明如下，然后用结合律就行了$$(AB) B^{-1} A^{-1}$$这其实反映了把矩阵作为变换的一种角度的思考，类似地，还有$$(AB)^T = B^T A^T$$另外一个性质是$$(A^T)^{-1} = (A^{-1})^{T}$$证明是$$(AA^{-1})^{T} = (A^{-1})^T A^T = I$$关于逆和转置的性质，可以进一步从范畴论上来描述，但我目前还没怎么看懂。 LU分解将一个矩阵分解为一个下三角矩阵L和一个上三角矩阵U的乘积，有时需要再乘上一个置换矩阵P，作为PLU分解。 转置与向量空间置换矩阵$P$是对行重排的$I$，共有$n!$种。具有性质$P^{-1} = P^T$对称矩阵定义是$A^T = A$，容易得到$R^T R$是对称的，证明就是用上一章提到的性质就行。 vector space表示向量空间，它需要对加法和数乘封闭。subspace表示子空间。0向量一定在子空间里面，因为任何一个向量和0数乘都是0向量，而向量空间对数乘是封闭的。两个子空间的交集一定是子空间，可以想象三维空间里面的一条线是一个子空间，那么两条线的交点一定也在这个三维空间里面。证明的话就是$$x \in U \wedge x \in V \\y \in U \wedge y \in V \\x + y \in U \\x + y \in V \\x + y \in (U \cap V) \\$$ 两个子空间的并集不一定是子空间，可以想象我们用两个坐标轴做加法可以张成一个平面，但平面上的向量并不都在两个坐标轴上面。 线性空间column space表示列空间。主要用来描述$Ax = b$这个方程的解。列空间是由矩阵$A$的所有列向量生成的$R^m$上的子空间，记作$C(A)$。矩阵$A$的列空间$C(A)$中的所有向量均为矩阵$A$中列向量的某种线性组合，都为$R^m$上的向量（即$m$维向量）。那么显而易见的就是说当$b$在$A$的列空间中时， 这个方程有解。null space表示零空间。主要用来描述$Ax = 0$这个方程的解。 Reference https://zh.wikipedia.org/wiki/%E8%A1%8C%E7%A9%BA%E9%97%B4%E4%B8%8E%E5%88%97%E7%A9%BA%E9%97%B4 https://zh.wikipedia.org/wiki/LU%E5%88%86%E8%A7%A3 特征向量]]></content>
      <tags>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异星工厂常用命令介绍]]></title>
    <url>%2F2019%2F12%2F22%2Ffactorio-cmd%2F</url>
    <content type="text"><![CDATA[本文主要介绍异星工厂常用的Lua命令，以及异星工厂服务器的搭建 服务器搭建首先，我们最好创建一个单独的账户gamemaster1adduser gamemaster 然后我们从这个连接下载对应版本的factorio服务端(headless)，它是一个压缩包。1tar -xvJf factorio_headless_x64_xxx.tar.xz 解压之后的文件夹主要有bin、config、data、mods、saves、temp这几个目录。bin下面就是一个factorio的可执行文件。config里面是一些服务器的配置信息，这些信息大多与游戏性能相关，我们一般不在这里进行修改。data文件夹比较重要，里面server-settings.example.json中包含了服务器的一些设置信息，比如是否允许作弊，是否开启房间密码，游戏自动保存的时间间隔等，这里面必须要设置的是username和password字段，这个是在factorio游戏里面你自己创建的账户。map-gen-settings.example.json则用来描述生成地图的配置，例如是否是和平模式，各种资源的多少等。通过下面的命令创建新的世界1/home/gamemaster/factorio/bin/x64/factorio --create /home/gamemaster/factorio/saves/initial.zip --map-gen-settings /home/gamemaster/factorio/data/map-gen-settings.json --map-settings /home/gamemaster/factorio/data/map-settings.json 通过下面的命令启动服务器1nohup /home/gamemaster/factorio/bin/x64/factorio --server-settings /home/gamemaster/factorio/data/server-settings.example.json --start-server-load-latest --console-log /home/gamemaster/Factorio.log &amp; 命令相关通过下面脚本可以获得当前所有可以insert的物品1for name, _ in pairs(game.item_prototypes) do; game.write_file("item_names.txt", name.."\n", true); end 通过下面的脚本可以集齐一套神装12345678910111213141516171819local player = game.playerplayer.insert&#123;name="power-armor-mk2", count = 1&#125;local p_armor = player.get_inventory(5)[1].gridp_armor.put(&#123;name = "fusion-reactor-equipment"&#125;)p_armor.put(&#123;name = "fusion-reactor-equipment"&#125;)p_armor.put(&#123;name = "fusion-reactor-equipment"&#125;)p_armor.put(&#123;name = "energy-shield-mk2-equipment"&#125;)p_armor.put(&#123;name = "energy-shield-mk2-equipment"&#125;)p_armor.put(&#123;name = "energy-shield-mk2-equipment"&#125;)p_armor.put(&#123;name = "energy-shield-mk2-equipment"&#125;)p_armor.put(&#123;name = "energy-shield-mk2-equipment"&#125;)p_armor.put(&#123;name = "energy-shield-mk2-equipment"&#125;)-- 外骨骼，可选配 p_armor.put(&#123;name = "exoskeleton-equipment"&#125;)-- 夜视模块，可选配 p_armor.put(&#123;name = "night-vision-equipment"&#125;)p_armor.put(&#123;name = "personal-laser-defense-equipment"&#125;)p_armor.put(&#123;name = "personal-laser-defense-equipment"&#125;)p_armor.put(&#123;name = "personal-roboport-mk2-equipment"&#125;)p_armor.put(&#123;name = "battery-mk2-equipment"&#125;)p_armor.put(&#123;name = "battery-mk2-equipment"&#125;) 下面列出了一些物品的获取命令123456789101112131415161718192021222324252627game.player.insert&#123;name="construction-robot", count = 100&#125;game.player.insert&#123;name="pipe", count = 100000&#125;game.player.insert&#123;name="pipe-to-ground", count = 100000&#125;game.player.insert&#123;name="coal", count = 100000&#125;game.player.insert&#123;name="iron-plate", count = 100000&#125;game.player.insert&#123;name="rail", count = 10000&#125;game.player.insert&#123;name="long-handed-inserter", count = 100000&#125;game.player.insert&#123;name="stack-filter-inserter", count = 100000&#125;game.player.insert&#123;name="rail-chain-signal", count = 1000&#125;game.player.insert&#123;name="substation", count = 1000&#125;game.player.insert&#123;name="big-electric-pole", count = 1000&#125;game.player.insert&#123;name="logistic-chest-storage", count = 100&#125;game.player.insert&#123;name="grenade", count = 100&#125;game.player.insert&#123;name="cliff-explosives", count = 100&#125;game.player.insert&#123;name="locomotive", count = 2&#125;game.player.insert&#123;name="train-stop", count = 100&#125;game.player.insert&#123;name="laser-turret", count = 1000&#125;game.player.insert&#123;name="express-transport-belt", count = 100000&#125;game.player.insert&#123;name="express-underground-belt", count = 100000&#125;game.player.insert&#123;name="express-splitter", count = 100000&#125;game.player.insert&#123;name="electric-mining-drill", count = 100&#125;game.player.insert&#123;name="stone-brick", count = 10000&#125;game.player.insert&#123;name="copper-plate", count = 10000&#125;game.player.insert&#123;name="stone", count = 10000&#125;game.player.insert&#123;name="rocket-launcher", count = 2&#125;game.player.insert&#123;name="roboport", count = 100&#125;game.player.insert&#123;name="explosive-rocket", count = 100&#125; 修改人物奔跑速度1/c game.player.character.character_running_speed_modifier = 3 修改和平模式1/c game.player.surface.peaceful_mode = true 开启作弊1/c game.player.cheat_mode=true 清空污染1/c game.player.surface.clear_pollution() 彻底关闭污染1/c game.map_settings.pollution.enabled = false]]></content>
      <tags>
        <tag>游戏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[multiprocessing模块实现]]></title>
    <url>%2F2019%2F11%2F23%2Fmultiprocessing-implement%2F</url>
    <content type="text"><![CDATA[在文章中介绍了multiprocessing模块用法，下面将详细介绍这个模块的实现。其内容包括： Manager conenction.Pipe ManagerManager对象会使用一个Server进程来维护需要共享的对象，而其他进程需要通过Proxy来访问这些共享对象。 SyncManager和BaseManagerregister当我们调用multiprocessing.Manager()时，实际上创建了一个SyncManager，并调用它的start。在start中，会创建一个子进程来维护共享对象。123456789101112# __init__.pydef Manager(): ''' Returns a manager associated with a running server process The managers methods such as `Lock()`, `Condition()` and `Queue()` can be used to create shared objects. ''' from multiprocessing.managers import SyncManager m = SyncManager() m.start() return m 我们可以通过SyncManager.dict()等方法创建共享对象，并返回其代理。我们首先来查看它的实现。123456789101112131415class SyncManager(BaseManager): ''' Subclass of `BaseManager` which supports a number of shared object types. The types registered are those intended for the synchronization of threads, plus `dict`, `list` and `Namespace`. The `multiprocessing.Manager()` function creates started instances of this class. '''SyncManager.register('Queue', Queue.Queue)SyncManager.register('dict', dict, DictProxy)SyncManager.register('Iterator', proxytype=IteratorProxy, create_method=False)... 从源码上看，SyncManager继承了一个BaseManager，通过register方法在这之中添加了对不同类型共享对象的支持。1234# 'dict', dict, DictProxy@classmethoddef register(cls, typeid, callable=None, proxytype=None, exposed=None, method_to_typeid=None, create_method=True): 这个函数主要是围绕传入的几个参数的，我们结合整个函数的源码看这些参数的作用。 cls类似于成员函数里的self，用来在类里面表示自己 typeid是一个字符串，对应于”Queue”/“dict”等 callable用来创建typeid对应的对象，对应于上面的Queue.Queue和dict等。如果一个manager实例通过from_address()创建，或者create_method参数时False的，那么callable就可以被设置为None proxytype是BaseProxy的子类，用来创建一个用来访问这个共享对象的代理，如果设置为None，就会默认使用Autoproxy 12if proxytype is None: proxytype = AutoProxy exposed用来限定proxy上的这个方法名字是不是public的。 如果请求访问一个没有exposed的接口，那么就会AttributeError并且调用fallback_func。 12345678910111213141516171819202122# 来自serve_client方法try: ... if methodname not in exposed: raise AttributeError( 'method %r of %r object is not in exposed=%r' % (methodname, type(obj), exposed) ) ...except AttributeError: if methodname is None: msg = ('#TRACEBACK', format_exc()) else: try: fallback_func = self.fallback_mapping[methodname] result = fallback_func( self, conn, ident, obj, *args, **kwds ) msg = ('#RETURN', result) except Exception: msg = ('#TRACEBACK', format_exc())... 如果指定exposed为None，那么就会使用proxytype._exposed_，如果proxytype._exposed_也是None，那么就使用这个共享对象的所有的public方法 1234567891011exposed = exposed or getattr(proxytype, '_exposed_', None)def all_methods(obj): temp = [] for name in dir(obj): func = getattr(obj, name) if hasattr(func, '__call__'): temp.append(name) return tempdef public_methods(obj): return [name for name in all_methods(obj) if name[0] != '_'] method_to_typeid 这个是一个dict，列出了所有返回值是一个proxy的方法。如果没有指定，那么就使用proxytype._method_to_typeid_，如果仍然为空，那么所有的返回值都按值复制。我们可以参考下面的方法 12345678910111213141516# 在BaseManager.register中method_to_typeid = method_to_typeid or \ getattr(proxytype, '_method_to_typeid_', None)if method_to_typeid: for key, value in method_to_typeid.items(): assert type(key) is str, '%r is not a string' % key assert type(value) is str, '%r is not a string' % value# 在全局空间PoolProxy._method_to_typeid_ = &#123; 'apply_async': 'AsyncResult', 'map_async': 'AsyncResult', 'imap': 'Iterator', 'imap_unordered': 'Iterator' &#125; create_method 是一个布尔量，默认True。要不要创建一个和typeid同名的方法，并且用这个方法来通知Server进程创建一个共享对象并返回一个proxy。这个只有对Iterator类是False的，也就是说Manager不想提供一个接口让你显式创建一个Iterator。 12345if create_method: def temp(self, *args, **kwds): ... temp.__name__ = typeid setattr(cls, typeid, temp) 这个if分支中实际上是创建了一个temp函数，并且通过setattr将这个temp函数注册为cls中的typeid的方法。这样当我们在调用manager.XXX()时，就会执行这个temp里面的内容。我们将在后面深入探讨这个代码。 register函数除了和几个参数有关的代码之外，剩下就这几行代码了，它们的作用就是将描述这个typeid的信息打包，存储到_registry中。123456if '_registry' not in cls.__dict__: cls._registry = cls._registry.copy()cls._registry[typeid] = ( callable, exposed, method_to_typeid, proxytype ) 我们打印一下register完所有类的cls._registry为JoinableQueue,Namespace,BoundedSemaphore,Iterator,Lock,list,RLock,Queue,Array,dict,Pool,Semaphore,Value,Event,Condition 创建共享对象（Client）这一章节的开始，我们来看register函数中是如何创建共享对象的，主要过程就是通读一下register后面的代码和_create函数的实现。在创建完共享对象之后，这个共享对象就可以看做是远程对象（稍后将讲解的Server端）的一个代理。if create_method中创建的temp入口方法的主要功能是： 先通过_create通知Server创建一个共享变量，并返回其唯一标识token 创建一个连接到这个token的proxy，这个proxy还作为这个函数的返回值 decref，有关引用计数的问题将在Server章节中讨论 123456789101112131415# managers.pyif create_method: def temp(self, *args, **kwds): util.debug('requesting creation of a shared %r object', typeid) # exp就是之前提到的exposed token, exp = self._create(typeid, *args, **kwds) proxy = proxytype( token, self._serializer, manager=self, authkey=self._authkey, exposed=exp ) conn = self._Client(token.address, authkey=self._authkey) dispatch(conn, None, 'decref', (token.id,)) return proxy temp.__name__ = typeid setattr(cls, typeid, temp) _create首先查看_create这个方法，首先不得不提的是它接受一堆*args和**kwds的参数，这两个鬼东西它自己不用，而是传给dispatch，而dispatch也不用，而是直接send出去。下面来看流程，首先创建了一个_Client类型的变量conn。By the way，那么Server在哪里呢，稍后解释。12345678# managers.pydef _create(self, typeid, *args, **kwds): ''' Create a new shared object; return the token and exposed tuple ''' assert self._state.value == State.STARTED, 'server not yet started' conn = self._Client(self._address, authkey=self._authkey) ... 我们查看__init__方法得知，这个实际上就是一个套接字。特别地，如果机器支持AF_UNIX的话，会使用UNIX Domain Socket来进行同一主机上的IPC，省去了网络协议栈的层层封装等流程。但从中也能看出，实际上BaseManager在设计上是能够跨机器进行通信的123456789101112131415161718192021# managers.py# BaseManager.__init__self._serializer = serializer # 默认值是pickleself._Listener, self._Client = listener_client[serializer]# 全局listener_client = &#123; 'pickle' : (connection.Listener, connection.Client), 'xmlrpclib' : (connection.XmlListener, connection.XmlClient) &#125; # connection.pydefault_family = 'AF_INET'families = ['AF_INET']if hasattr(socket, 'AF_UNIX'): default_family = 'AF_UNIX' families += ['AF_UNIX']if sys.platform == 'win32': default_family = 'AF_PIPE' families += ['AF_PIPE'] 在创建好conn之后，就会通过dispatch调用conn.send发送一个对methodname为”create”的调用，并且在参数表头部附上当前的typeid。当这个调用被传到Server类时，会调用Server.create方法，在Server子进程空间中创建一个共享对象，这个将在下一节讲解有关Server部分中提到。1234567# 继续是_create函数 ... try: id, exposed = dispatch(conn, None, 'create', (typeid,)+args, kwds) finally: conn.close() return Token(typeid, self._address, id), exposed dispatch函数下面介绍这个大boss，dispatch函数。12345678910111213141516171819202122232425# dispatch函数def dispatch(c, id, methodname, args=(), kwds=&#123;&#125;): ''' Send a message to manager using connection `c` and return response ''' # 这里的c就是从_create传过来的conn，是一个_Client对象 c.send((id, methodname, args, kwds)) kind, result = c.recv() if kind == '#RETURN': return result raise convert_to_error(kind, result)def convert_to_error(kind, result): if kind == '#ERROR': return result elif kind == '#TRACEBACK': assert type(result) is str return RemoteError(result) elif kind == '#UNSERIALIZABLE': assert type(result) is str return RemoteError('Unserializable message: %s\n' % result) else: return ValueError('Unrecognized message type')class RemoteError(Exception): def __str__(self): return ('\n' + '-'*75 + '\n' + str(self.args[0]) + '-'*75) 接着dispatch函数就调用conn.recv()获取返回值。返回值的kind一共有#RETURN、#ERROR、#TRACEBACK、#UNSERIALIZABLE四种。如果当前的dispatch调用返回正常的话，他应该会拿到一个exposed，包含了共享对象中所能够调用的所有方法名。 在调用dispatch函数之后，_create就返回了一个Token类型和从dispatch拿到的exposed。Token的定义如下，被用来唯一确定一个共享对象。123456789101112131415161718class Token(object): ''' Type to uniquely indentify a shared object ''' __slots__ = ('typeid', 'address', 'id') def __init__(self, typeid, address, id): (self.typeid, self.address, self.id) = (typeid, address, id) def __getstate__(self): return (self.typeid, self.address, self.id) def __setstate__(self, state): (self.typeid, self.address, self.id) = state def __repr__(self): return 'Token(typeid=%r, address=%r, id=%r)' % \ (self.typeid, self.address, self.id) proxy在调用_create通知Server创建完共享对象之后，temp函数就创建一个proxy来代理这个远程的共享对象，这里的proxytype是由register函数中传入的，一般是AutoProxy，我们将在后面详细介绍。1234proxy = proxytype( token, self._serializer, manager=self, authkey=self._authkey, exposed=exp ) 创建共享对象（Server）上面的内容是Client部分的初始化过程，下面我们查看Server部分。需要注意的是，虽然是Server/Client结构，但是因为Manager的Server和Client都在一台机器上，并且由同样的代码进行管理，所以在形式上和传统的Socket是不一样的。由于Server是作为一个子进程存在，并且这个子进程和Server本身都是由BaseManager来管理的，并且也需要通过BaseManager提供的方法来操控。所以我们可以看到很多Server部分的工作是在BaseManager而不是Server内部处理的。根据文档，一旦BaseManager被创建，就需要调用start或者get_server().serve_forever()来确保这个manager是和一个进程关联的。查看代码可以发现，这个start是在__init__.py上面被调用的123456789101112# __init__.pydef Manager(): ''' Returns a manager associated with a running server process The managers methods such as `Lock()`, `Condition()` and `Queue()` can be used to create shared objects. ''' from multiprocessing.managers import SyncManager m = SyncManager() m.start() return m 因此要了解Server如何被创建，就要先看BaseManager是如何被创建的。 构造函数首先来全面查看一下BaseManager的构造函数12345678910# managers.pydef __init__(self, address=None, authkey=None, serializer='pickle'): if authkey is None: authkey = current_process().authkey self._address = address # XXX not final address if eg ('', 0) self._authkey = AuthenticationString(authkey) self._state = State() self._state.value = State.INITIAL self._serializer = serializer # 默认是pickle self._Listener, self._Client = listener_client[serializer] 我们查看一下authkey的相关实现，由于其中涉及了不少Process相关的实现，在这里暂时不提123456789101112131415161718# process.pydef current_process(): return _current_process class _MainProcess(Process): def __init__(self): self._identity = () self._daemonic = False self._name = 'MainProcess' self._parent_pid = None self._popen = None self._counter = itertools.count(1) self._children = set() self._authkey = AuthenticationString(os.urandom(32)) self._tempdir = None_current_process = _MainProcess()del _MainProcess start方法我们查看BaseManager.start方法，首先创建了一个Process，并通过connection.Pipe和这个子进程进行通信。关于这个管道的实现，在后面进行说明。1234567891011121314151617181920212223# managers.pydef start(self, initializer=None, initargs=()): ''' Spawn a server process for this manager object ''' assert self._state.value == State.INITIAL if initializer is not None and not hasattr(initializer, '__call__'): raise TypeError('initializer must be a callable') # pipe over which we will retrieve address of server reader, writer = connection.Pipe(duplex=False) # spawn process which runs a server self._process = Process( target=type(self)._run_server, args=(self._registry, self._address, self._authkey, self._serializer, writer, initializer, initargs), ) ident = ':'.join(str(i) for i in self._process._identity) self._process.name = type(self).__name__ + '-' + ident self._process.start() ... self._registry 这个就是之前在register方法中保存下来的_registry字典。 self._address来自于BaseManager的__init__ self._authkey来自于BaseManager的__init__ 下面暂停对start的阅读，而step in查看Process中执行的主函数_run_server，可以看到在这个方法中： 首先执行initializer，这个initializer是start在args里面传进来的，如果是从__init__.py调用的，那么就是None 创建一个Server对象_Server 向管道里面写入server.address，这个会被在主进程的reader读取 调用serve_forever12345678910111213141516171819@classmethoddef _run_server(cls, registry, address, authkey, serializer, writer, initializer=None, initargs=()): ''' Create a server, report its address and run it ''' if initializer is not None: initializer(*initargs) # create server server = cls._Server(registry, address, authkey, serializer) # inform parent process of the server's address writer.send(server.address) writer.close() # run the manager util.info('manager serving at %r', server.address) server.serve_forever() 关于Server类，我们稍后来查看，现在我们继续看完start123456789101112131415# 继续start方法 ... # get address of server writer.close() self._address = reader.recv() reader.close() # register a finalizer self._state.value = State.STARTED self.shutdown = util.Finalize( self, type(self)._finalize_manager, args=(self._process, self._address, self._authkey, self._state, self._Client), exitpriority=0 ) 额外说明一下，这里的shutdown在__exit__中被调用。这里的__enter__和__exit__被用来实现with1234def __enter__(self): return selfdef __exit__(self, exc_type, exc_val, exc_tb): self.shutdown() 实际上，util.Finalize是调用type(self)._finalize_manager，使用type(self)是因为_finalize_manager是一个类方法。一般涉及到Process有关的函数，都不能是带有上下文的，而必须是自由函数。在_finalize_manager中主要就是先创建一个_Client，向Server进程self._process发送shutdown指令，接着尝试join这个进程。如果在0.2秒之后这个进程还在的话，就尝试去terminate它。从Process源码来看，它是始终有terminate这个方法的，不知道为啥还需要hasattr来判断下。12345678910111213141516171819202122232425262728293031@staticmethoddef _finalize_manager(process, address, authkey, state, _Client): ''' Shutdown the manager process; will be registered as a finalizer ''' if process.is_alive(): util.info('sending shutdown message to manager') try: conn = _Client(address, authkey=authkey) try: dispatch(conn, None, 'shutdown') finally: conn.close() except Exception: pass process.join(timeout=0.2) if process.is_alive(): util.info('manager still alive') if hasattr(process, 'terminate'): util.info('trying to `terminate()` manager process') process.terminate() process.join(timeout=0.1) if process.is_alive(): util.info('manager still alive after terminate') state.value = State.SHUTDOWN try: del BaseProxy._address_to_local[address] except KeyError: pass Server先前围绕BaseManager类讨论了Server部分的初始化和析构。现在我们来看Server这个对象，以便了解它具体负责的内容。首先，照例是构造函数，包含了和套接口API很像的Listener。后面的id_to_obj就是Server所维护的所有共享对象了。id_to_obj是一个dict，它的key是由&#39;%x&#39; % id(obj)来生成的，之所以需要转换成字符串类型是因为xmlrpclib这个库只支持32位的int，所以用str保险一点（当然之前提到，实际用的是pickle）。id_to_refcount则用来标记每个obj的生命周期。12345678910111213141516171819202122# managers.pyclass Server(object): ''' Server class which runs in a process controlled by a manager object ''' public = ['shutdown', 'create', 'accept_connection', 'get_methods', 'debug_info', 'number_of_objects', 'dummy', 'incref', 'decref'] def __init__(self, registry, address, authkey, serializer): assert isinstance(authkey, bytes) self.registry = registry self.authkey = AuthenticationString(authkey) Listener, Client = listener_client[serializer] # do authentication later self.listener = Listener(address=address, backlog=16) self.address = self.listener.address self.id_to_obj = &#123;'0': (None, ())&#125; self.id_to_refcount = &#123;&#125; self.mutex = threading.RLock() self.stop = 0 回忆前面的内容，Client会调用dispatch(conn, None, &#39;create&#39;, (typeid,)+args, kwds)来通知子进程创建一个共享对象。看源码显而易见，肯定最终是调用Server.create这个方法的，但在这之前，会经过一个serve_client方法分发的过程。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# managers.pydef accept_connection(self, c, name): ''' Spawn a new thread to serve this connection ''' threading.current_thread().name = name c.send(('#RETURN', None)) self.serve_client(c) def serve_client(self, conn): ''' Handle requests from the proxies in a particular process/thread ''' util.debug('starting server thread to service %r', threading.current_thread().name) recv = conn.recv send = conn.send id_to_obj = self.id_to_obj while not self.stop: try: methodname = obj = None request = recv() ident, methodname, args, kwds = request obj, exposed, gettypeid = id_to_obj[ident] if methodname not in exposed: raise AttributeError( 'method %r of %r object is not in exposed=%r' % (methodname, type(obj), exposed) ) function = getattr(obj, methodname) try: res = function(*args, **kwds) except Exception, e: msg = ('#ERROR', e) else: typeid = gettypeid and gettypeid.get(methodname, None) if typeid: rident, rexposed = self.create(conn, typeid, res) token = Token(typeid, self.address, rident) msg = ('#PROXY', (rexposed, token)) else: msg = ('#RETURN', res) except AttributeError:... Proxy下面我们来看Proxy部分的实现。在SyncManager.register(&#39;dict&#39;, dict, DictProxy)中用到的DictProxy是由MakeProxyType来生成的，这个函数就是一个创建类的简易的“宏”。它创建名字为name的类，继承自BaseProxy，并且传入一个tuple作为这个子类所拥有的方法。对于每个方法，实际调用BaseProxy里面的_callmethod来执行。12345678910111213141516171819202122232425262728DictProxy = MakeProxyType('DictProxy', ( '__contains__', '__delitem__', '__getitem__', '__len__', '__setitem__', 'clear', 'copy', 'get', 'has_key', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values' ))def MakeProxyType(name, exposed, _cache=&#123;&#125;): ''' Return an proxy type whose methods are given by `exposed` ''' exposed = tuple(exposed) try: return _cache[(name, exposed)] except KeyError: pass dic = &#123;&#125; for meth in exposed: # 直接eval`def`语句来创建这个方法 exec '''def %s(self, *args, **kwds): return self._callmethod(%r, args, kwds)''' % (meth, meth) in dic # exec ... in 用法 # 输入(类名、基类、类内定义的命名空间变量的字典)，返回新的类型 ProxyType = type(name, (BaseProxy,), dic) ProxyType._exposed_ = exposed _cache[(name, exposed)] = ProxyType return ProxyType 下面，我们来看看BaseProxy这个类是如何通过_callmethod转发方法的。可以看到，BaseProxy通过self._tls.connection.send()这个方法将需要调用的方法发送出去，看起来这个_tls就是个套接口了。1234567891011121314151617181920212223242526272829def _callmethod(self, methodname, args=(), kwds=&#123;&#125;): ''' Try to call a method of the referrent and return a copy of the result ''' try: conn = self._tls.connection except AttributeError: util.debug('thread %r does not own a connection', threading.current_thread().name) self._connect() conn = self._tls.connection conn.send((self._id, methodname, args, kwds)) kind, result = conn.recv() if kind == '#RETURN': return result elif kind == '#PROXY': exposed, token = result proxytype = self._manager._registry[token.typeid][-1] token.address = self._token.address proxy = proxytype( token, self._serializer, manager=self._manager, authkey=self._authkey, exposed=exposed ) conn = self._Client(token.address, authkey=self._authkey) dispatch(conn, None, 'decref', (token.id,)) return proxy raise convert_to_error(kind, result) 我们查看BaseProxy的初始化部分，看看_tls是何方神圣123456789101112131415161718192021222324252627282930313233343536373839404142434445class BaseProxy(object): ''' A base for proxies of shared objects ''' _address_to_local = &#123;&#125; # 能在Fork后正常工作的锁 _mutex = util.ForkAwareThreadLock() def __init__(self, token, serializer, manager=None, authkey=None, exposed=None, incref=True): BaseProxy._mutex.acquire() try: tls_idset = BaseProxy._address_to_local.get(token.address, None) if tls_idset is None: tls_idset = util.ForkAwareLocal(), ProcessLocalSet() BaseProxy._address_to_local[token.address] = tls_idset finally: BaseProxy._mutex.release() # self._tls is used to record the connection used by this # thread to communicate with the manager at token.address self._tls = tls_idset[0] # self._idset is used to record the identities of all shared # objects for which the current process owns references and # which are in the manager at token.address self._idset = tls_idset[1] self._token = token self._id = self._token.id self._manager = manager self._serializer = serializer self._Client = listener_client[serializer][1] if authkey is not None: self._authkey = AuthenticationString(authkey) elif self._manager is not None: self._authkey = self._manager._authkey else: self._authkey = current_process().authkey if incref: self._incref() util.register_after_fork(self, BaseProxy._after_fork) 补充Manager的Util部分看看这个ForkAwareThreadLock实现1234567891011121314151617181920212223242526class ForkAwareThreadLock(object): def __init__(self): self._reset() # 在每次fork之后都要reset register_after_fork(self, ForkAwareThreadLock._reset) def _reset(self): self._lock = threading.Lock() self.acquire = self._lock.acquire self.release = self._lock.releasedef register_after_fork(obj, func): _afterfork_registry[(_afterfork_counter.next(), id(obj), func)] = obj# 弱引用键的映射类。 当不再有对键的强引用时字典中的条目将被丢弃。_afterfork_registry = weakref.WeakValueDictionary()def _run_after_forkers(): # 在fork之后执行 items = list(_afterfork_registry.items()) items.sort() for (index, ident, func), obj in items: try: func(obj) except Exception, e: info('after forker raised exception %s', e) 这里需要跟踪fork之后锁的原因是The child process is created with a single thread–the one that called fork()，因此可能拥有锁的子线程并不在子进程之中。可以发现，在fork之后，会执行_run_after_forkers方法，这个方法会遍历出_afterfork_registry中的所含有lock，并且将它们换成新的threading.Lock() connection.Pipe实现可以想象，根据是否是POSIX系统分为了两种实现。根据sys.platform来判断系统类型。 POSIX对于POSIX系统，借助socketpair实现双向管道，pipe实现单向管道。相比于popen和pclose，socketpair直接提供了一个双向的读写管道。我们知道可以通过dup2来进行重定向，例如dup2(f, STDOUT_FILENO)可以将标准输出指向文件f。那么这里为什么要复制一份s1.fileno()并来创建一个_multiprocessing.Connection对象呢？123456789101112131415161718192021import multiprocessingimport _multiprocessingimport socketdef Pipe(duplex=True): ''' Returns pair of connection objects at either end of a pipe ''' if duplex: s1, s2 = socket.socketpair() s1.setblocking(True) s2.setblocking(True) c1 = _multiprocessing.Connection(os.dup(s1.fileno())) c2 = _multiprocessing.Connection(os.dup(s2.fileno())) s1.close() s2.close() else: fd1, fd2 = os.pipe() c1 = _multiprocessing.Connection(fd1, writable=False) c2 = _multiprocessing.Connection(fd2, readable=False) return c1, c2 要想研究这个问题，需要查看_multiprocessing.Connection这个用C实现的模块。通过观察_multiprocessing下面的目录结构可以看出，它会在c文件里面写上一堆特化的实现，然后在最后#include connection.h来做一个公共的实现。从#define CONNECTION_NAME &quot;Connection&quot;可以看出，_multiprocessing.Connection实际上是socket_connection。分析一个模块，首先要找它的PyMODINIT_FUNC函数、PyMethodDef结构、PyModuleDef结构。但_multiprocessing.Connection被定义为一个对象，所以我们分析它的PyVarObject_HEAD_INIT(NULL, 0)的定义。可以看到，它的初始化方法是connection_new。 我们尝试了下面的代码，发现在Linux下面抛出IOError: [Errno 9] Bad file descriptor的错误。因此可以猜测到s1和s2在销毁时会释放自己的fd，这里提前复制一份出来是单纯为了复用这两个fd。 WINDOWS对于WINDOWS系统，借助于CreateNamedPipe实现。 注意事项multiprocessing.Manager()的dict()不可以嵌套，也就是说下面的语句实际上会报错1234567891011121314151617def inner(metainfo): metainfo['mvp_info']["a"] = 123 print metainfo['mvp_info']["a"]if __name__ == "__main__": global global_manager global_manager = multiprocessing.Manager() metainfo = global_manager.dict() metainfo['mvp_info'] = global_manager.dict() metainfo['mvp_info']["a"] = 100 print metainfo['mvp_info']["a"] p = Process(target=inner, args=(metainfo, )) p.start() p.join() print metainfo['mvp_info']["a"] Reference]]></content>
      <tags>
        <tag>多线程</tag>
        <tag>Python</tag>
        <tag>并行计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用matplotlib制作动态图表]]></title>
    <url>%2F2019%2F08%2F10%2Fpython-matplotlib-animation%2F</url>
    <content type="text"><![CDATA[Matploblib是Python生态中最为常用的绘图工具。然而这款工具不仅可以绘制静态图，还能借助于类似X11转发功能实现远程show。特别地，Maplotlib还可以绘制动态图，并导出成GIF。 配置出现outfile must be *.htm or *.html错误，需要显式指定Writer，代码如下所示123Writer = animation.writers['ffmpeg']writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)line_ani.save('lines.mp4', writer=writer) 出现RuntimeError: No MovieWriters available!，说明没有装好ffmpeg，可以使用conda install -c conda-forge ffmpeg。 绘制线条坐标FuncAnimation在没有Matplotlib前，去查看散点图的简便做法是将CSV格式的坐标文件放到Excel里面，然后绘制散点图。配合筛选功能我们可以较为轻松地得到一个动态的形状。我们稍后发现，借助于matplotlib.animation库，我们可以直接生成动画。Animation的主体函数是如下所示。1animation.FuncAnimation(fig, update, init_func=init, frames=tot) update是最为关键的方法，它接受一个参数t，表示这是第几帧画面。 绘制线条或散点绘制多个曲线/散点上面的方法只能绘制一条曲线，或者散点，我们可以创建多个matplotlib.lines.Line2D，并且作为tuple返回，从而绘制多条曲线。 Reference https://stackoverflow.com/questions/49133207/python-matplotlib-funcanimation-saving https://stackoverflow.com/questions/13316397/matplotlib-animation-no-moviewriters-available https://stackoverflow.com/questions/33275189/how-can-i-make-points-of-a-python-plot-appear-over-time]]></content>
      <tags>
        <tag>python</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark和SparkSQL]]></title>
    <url>%2F2019%2F08%2F06%2Fspark-sql%2F</url>
    <content type="text"><![CDATA[Spark是MapReduce的下一代的分布式计算框架。相比更早期的MapReduce的Job和Task的两层，Spark更为灵活，其执行粒度分为Application、Job、Stage和Task四个层次。本文写作基于Spark 2.4.4版本的源码。 【TLDR】本来写文章确实是简练清楚为最佳，不过我发现Spark架构实在是很庞大，其中涉及到的一些架构知识我觉得都很有启发意义，因此这篇文章就被我写得很长。为了简化论述，我将部分细节放到了源码中作为注释，因此正文中是主要内容。 【注】本篇文章经授权已被腾讯技术工程知乎号和微信收录。 Spark CoreRDDRDD(Resilient Distributed Dataset)，即弹性数据集是Spark中的基础结构。RDD是distributive的、immutable的，可以存在在内存中，也可以被缓存。对RDD具有转换操作和行动操作两种截然不同的操作。转换(Transform)操作从一个RDD生成另一个RDD，但行动(Action)操作会去掉RDD的壳。例如take是行动操作，返回的是一个数组而不是RDD了，在Scala中可以看到。 12345678scala&gt; var rdd1 = sc.makeRDD(Seq(10, 4, 2, 12, 3))rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[40] at makeRDD at :21 scala&gt; rdd1.take(1)res0: Array[Int] = Array(10) scala&gt; rdd1.take(2)res1: Array[Int] = Array(10, 4) 转换操作是Lazy的，直到遇到一个Action操作，Spark才会生成关于整条链的执行计划并执行。这些Action操作将一个Spark Application分为了多个Job。常见的Action操作包括：reduce、collect、count、take(n)、first、takeSample(withReplacement, num, [seed])、takeOrdered(n, [ordering])、saveAsTextFile(path)、saveAsSequenceFile(path)、saveAsObjectFile(path)、countByKey()、foreach(func)。我们需要注意的是，有一些Transform操作也会得到一个Job，例如sortBy，这是因为这个Job是用来初始化RangePartitioner，然后Sample输入RDD的partition边界的，和sortBy的业务无关，在实践中所占用的时间也是远小于实际占用的时间的。 RDD的常见成员 def getPartitions: Array[Partition]：获得这个RDD的所有分区，由Partition的子类来描述 def compute(partition: Partition, context: TaskContext): Iterator[T] def getDependencies: Seq[Dependency[_]]：用来获取依赖关系包含ShuffleDependency、OneToOneDependency、RangeDependency等。 part: PartitionerPartitioner是一个abstract class，具有numPartitions: Int和getPartition(key: Any): Int两个方法。通过继承Partitioner可以自定义分区的实现方式，目前官方提供的有RangePartitioner和HashPartitioner等。HashPartitioner是默认分区器，对key的hashCode取模，得到其对应的RDD分区的值。注意这里的hashCode可能还是个坑，例如Java里面数组的hashCode并不蕴含数组内容的信息，所以可能相同的数组被分到不同的分区。如果我们有这样的需求，就需要自定义分区器。RangePartitioner会从整个RDD中Sample出一些Key。Sample的Key的数量是基于生成的子RDD的partition数量来计算的，默认是每个partition取20个，再乘以分区数，最懂不超过1e6个。得到总共要sample多少个之后，我们要乘以3，再平摊到父RDD上。乘以三的意思是便于判断Data skew，如果父RDD的某个partition的数量大于了乘以3之后平摊的值，就可以认为这个partition偏斜了，需要丢这些partition进行重新抽样。 def getPreferredLocations(partition: Partition): Seq[String] 常见RDDRDD是一个抽象类abstract class RDD[T] extends Serializable with Logging，在Spark中有诸如ShuffledRDD、HadoopRDD等实现。每个RDD都有对应的compute方法，用来描述这个RDD的计算方法。需要注意的是，这些RDD可能被作为某些RDD计算的中间结果，例如CoGroupedRDD，对应的，例如MapPartitionsRDD也可能是经过多个RDD变换得到的，其决定权在于所使用的算子。我们来具体查看一些RDD。 ParallelCollectionRDD 这个RDD由parallelize得到 12scala&gt; val arr = sc.parallelize(0 to 1000)arr: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:24 HadoopRDD 1class HadoopRDD[K, V] extends RDD[(K, V)] with Logging FileScanRDD 这个RDD一般从spark.read.text(...)语句中产生，所以实现在sql模块中。 12345class FileScanRDD( @transient private val sparkSession: SparkSession, readFunction: (PartitionedFile) =&gt; Iterator[InternalRow], @transient val filePartitions: Seq[FilePartition]) extends RDD[InternalRow](sparkSession.sparkContext, Nil) &#123; MapPartitionsRDD 1class MapPartitionsRDD[U, T] extends RDD[U] 这个RDD是map、mapPartitions、mapPartitionsWithIndex操作的结果。 注意，在较早期的版本中，map会得到一个MappedRDD，filter会得到一个FilteredRDD、flatMap会得到一个FlatMappedRDD，不过目前已经找不到了，统一变成MapPartitionsRDD 123456scala&gt; val a3 = arr.map(i =&gt; (i+1, i))a3: org.apache.spark.rdd.RDD[(Int, Int)] = MapPartitionsRDD[2] at map at &lt;console&gt;:25scala&gt; val a3 = arr.filter(i =&gt; i &gt; 3)a3: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[4] at filter at &lt;console&gt;:25scala&gt; val a3 = arr.flatMap(i =&gt; Array(i))a3: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[5] at flatMap at &lt;console&gt;:25 join操作的结果也是MapPartitionsRDD，这是因为其执行过程的最后一步flatMapValues会创建一个MapPartitionsRDD 12345678scala&gt; val rdd1 = sc.parallelize(Array((1,1),(1,2),(1,3),(2,1),(2,2),(2,3)))rdd1: org.apache.spark.rdd.RDD[(Int, Int)] = ParallelCollectionRDD[8] at parallelize at &lt;console&gt;:24scala&gt; val rdd2 = sc.parallelize(Array((1,1),(1,2),(1,3),(2,1),(2,2),(2,3)))rdd2: org.apache.spark.rdd.RDD[(Int, Int)] = ParallelCollectionRDD[9] at parallelize at &lt;console&gt;:24scala&gt; val rddj = rdd1.join(rdd2)rddj: org.apache.spark.rdd.RDD[(Int, (Int, Int))] = MapPartitionsRDD[12] at join at &lt;console&gt;:27 ShuffledRDD ShuffledRDD用来存储所有Shuffle操作的结果，其中K、V很好理解，C是Combiner Class。 1class ShuffledRDD[K, V, C] extends RDD[(K, C)] 以groupByKey为例 12345scala&gt; val a2 = arr.map(i =&gt; (i+1, i))a2: org.apache.spark.rdd.RDD[(Int, Int)] = MapPartitionsRDD[2] at map at &lt;console&gt;:25scala&gt; a2.groupByKeyres1: org.apache.spark.rdd.RDD[(Int, Iterable[Int])] = ShuffledRDD[3] at groupByKey at &lt;console&gt;:26 注意，groupByKey需要K是Hashable的，否则会报错。 1234567scala&gt; val a2 = arr.map(i =&gt; (Array.fill(10)(i), i))a2: org.apache.spark.rdd.RDD[(Array[Int], Int)] = MapPartitionsRDD[2] at map at &lt;console&gt;:25scala&gt; a2.groupByKeyorg.apache.spark.SparkException: HashPartitioner cannot partition array keys. at org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1.apply(PairRDDFunctions.scala:84) at org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1.apply(PairRDDFunctions.scala:77) CoGroupedRDD 1class CoGroupedRDD[K] extends RDD[(K, Array[Iterable[_]])] 首先，我们需要了解一下什么是cogroup操作，这个方法有多个重载版本。如下所示的版本，对this或other1或other2的所有的key，生成一个RDD[(K, (Iterable[V], Iterable[W1], Iterable[W2]))，表示对于这个key，这三个RDD中所有值的集合。容易看到，这个算子能够被用来实现Join和Union（不过后者有点大材小用了） 12def cogroup[W1, W2](other1: RDD[(K, W1)], other2: RDD[(K, W2)], partitioner: Partitioner) : RDD[(K, (Iterable[V], Iterable[W1], Iterable[W2]))] UnionRDD 1class UnionRDD[T] extends RDD[T] UnionRDD一般通过union算子得到 12scala&gt; val a5 = arr.union(arr2)a5: org.apache.spark.rdd.RDD[Int] = UnionRDD[7] at union at &lt;console&gt;:27 CoalescedRDD 常见RDD外部函数Spark在RDD之外提供了一些外部函数，它们可以通过隐式转换的方式变成RDD。 PairRDDFunctions 这个RDD被用来处理KV对，相比RDD，它提供了groupByKey、join等方法。以combineByKey为例，他有三个模板参数，从RDD过来的K和V以及自己的C。相比reduce和fold系列的(V, V) =&gt; V，这多出来的C使combineByKey更灵活，通过combineByKey能够将V变换为C。需要注意的是，这三个函数将来在ExternalSorter里面还将会被看到。 123456789def combineByKey[C]( createCombiner: V =&gt; C, mergeValue: (C, V) =&gt; C, mergeCombiners: (C, C) =&gt; C, partitioner: Partitioner, mapSideCombine: Boolean = true, serializer: Serializer = null): RDD[(K, C)] = &#123; //实现略&#125; OrderedRDDFunctions 这个用来提供sortByKey、filterByRange等方法。 Spark的架构概览Spark在设计上的一个特点是它和下层的集群管理是分开的，一个Spark Application可以看做是由集群上的若干进程组成的。因此，我们需要区分Spark中的概念和下层集群中的概念，例如我们常见的Master和Worker是集群中的概念，表示节点；而Driver和Executor是Spark中的概念，表示进程。根据爆栈网，Driver可能位于某个Worker节点中，或者位于Master节点上，这取决于部署的方式 在官网上给了这样一幅图，详细阐明了Spark集群下的基础架构。SparkContext是整个Application的管理核心，由Driver来负责管理。SparkContext负责管理所有的Executor，并且和下层的集群管理进行交互，以请求资源。 在Stage层次及以上接受DAGScheduler的调度，而TaskScheduler则调度一个Taskset。在Spark on Yarn模式下，CoarseGrainedExecutorBackend和Executor一一对应，它是一个独立于Worker主进程之外的一个进程，我们可以jps查看到。而Task是作为一个Executor启动的一个线程来跑的，一个Executor中可以跑多个Task。在实现上，CoarseGrainedExecutorBackend继承了ExecutorBackend这个trait，作为一个IsolatedRpcEndpoint，维护Executor对象实例，并通过创建的DriverEndpoint实例的与Driver进行交互。在进程启动时，CoarseGrainedExecutorBackend调用onStart()方法向Driver注册自己，并产生一条&quot;Connecting to driver&quot;的INFO。CoarseGrainedExecutorBackend通过DriverEndpoint.receive方法来处理来自Driver的命令，包括LaunchTask、KillTask等。这里注意一下，在scheduler中有一个CoarseGrainedSchedulerBackend，里面实现相似，在看代码时要注意区分开。 有关Executor和Driver的关系，下面这张图更加直观，需要说明的是，一个Worker上面也可能跑有多个Executor，每个Task也可以在多个CPU核心上面运行 Spark上下文在代码里我们操作一个Spark任务有两种方式，通过SparkContext，或者通过SparkSession SparkContext方式 SparkContext是Spark自创建来一直存在的类。我们通过SparkConf直接创建SparkContext 12val sparkConf = new SparkConf().setAppName("AppName").setMaster("local")val sc = new SparkContext(sparkConf).set("spark.some.config.option", "some-value") SparkSession方式 SparkSession是在Spark2.0之后提供的API，相比SparkContext，他提供了对SparkSQL的支持（持有SQLContext），例如createDataFrame等方法就可以通过SparkSession来访问。 在builder.getOrCreate()的过程中，虽然最终得到的是一个SparkSession，但实际上内部已经创建了一个SparkContext，并由这个SparkSession持有。 1234567891011121314151617181920212223val spark: SparkSession = SparkSession.builder() // 得到一个Builder.master("local").appName("AppName").config("spark.some.config.option", "some-value").getOrCreate() // 得到一个SparkSession// SparkSession.scalaval sparkContext = userSuppliedContext.getOrElse &#123; val sparkConf = new SparkConf() options.foreach &#123; case (k, v) =&gt; sparkConf.set(k, v) &#125; // set a random app name if not given. if (!sparkConf.contains("spark.app.name")) &#123; sparkConf.setAppName(java.util.UUID.randomUUID().toString) &#125; SparkContext.getOrCreate(sparkConf) // Do not update `SparkConf` for existing `SparkContext`, as it's shared by all sessions.&#125;applyExtensions( sparkContext.getConf.get(StaticSQLConf.SPARK_SESSION_EXTENSIONS).getOrElse(Seq.empty), extensions)session = new SparkSession(sparkContext, None, None, extensions) SparkEnvSparkEnv持有一个Spark实例在运行时所需要的所有对象，包括Serializer、RpcEndpoint（在早期用的是Akka actor）、BlockManager、MemoryManager、BroadcastManager、SecurityManager、MapOutputTrackerMaster/Worker等等。SparkEnv由SparkContext创建，并在之后通过伴生对象SparkEnv的get方法来访问。在创建时，Driver端的SparkEnv是SparkContext创建的时候调用SparkEnv.createDriverEnv创建的。Executor端的是其守护进程CoarseGrainedExecutorBackend创建的时候调用SparkEnv.createExecutorEnv方法创建的。这两个方法最后都会调用create方法 123456789101112131415161718192021222324// Driver端private[spark] def createSparkEnv( conf: SparkConf, isLocal: Boolean, listenerBus: LiveListenerBus): SparkEnv = &#123; SparkEnv.createDriverEnv(conf, isLocal, listenerBus, SparkContext.numDriverCores(master, conf))&#125;_env = createSparkEnv(_conf, isLocal, listenerBus)SparkEnv.set(_env)// Executor端// CoarseGrainedExecutorBackend.scalaval env = SparkEnv.createExecutorEnv(driverConf, arguments.executorId, arguments.bindAddress, arguments.hostname, arguments.cores, cfg.ioEncryptionKey, isLocal = false)env.rpcEnv.setupEndpoint("Executor", backendCreateFn(env.rpcEnv, arguments, env))arguments.workerUrl.foreach &#123; url =&gt; env.rpcEnv.setupEndpoint("WorkerWatcher", new WorkerWatcher(env.rpcEnv, url))&#125;env.rpcEnv.awaitTermination()// SparkEnv.scala// create函数val blockManager = new BlockManager(...) Spark的任务调度Spark的操作可以分为两种，Transform操作是lazy的，而Action操作是Eager的。每一个Action会产生一个Job。Spark的Transform操作可以分为宽依赖(ShuffleDependency)和窄依赖(NarrowDependency)操作两种，其中窄依赖还有两个子类OneToOneDependency和RangeDependency。窄依赖操作表示父RDD的每个分区只被子RDD的一个分区所使用，例如union、map、filter等的操作；而宽依赖恰恰相反。宽依赖需要shuffle操作，因为需要将父RDD的结果需要复制给不同节点用来生成子RDD，有关ShuffleDependency将在下面的Shuffle源码分析中详细说明。当DAG的执行中出现宽依赖操作时，Spark会将其前后划分为不同的Stage，在下一章节中将具体分析相关代码。这里需要注意的一点是coalesce这样的操作也是窄依赖，因为它涉及的输入分区是有限的。 在Stage之下，就是若干个Task了。这些Task也就是Spark的并行单元，通常来说，按照当前Stage的最后一个RDD的分区数来计算，每一个分区都会启动一个Task来进行计算。我们可以通过rdd.partitions.size来获取一个RDD有多少个分区。一般来说，初始的partition数是在HDFS中文件block的数量。 Task具有两种类型，ShuffleMapTask和ResultTask。其中ResultTask是ResultStage的Task，也就是最后一个Stage的Task。 下面提出几个有趣的问题： Job是可并行的么？ 官网指出，within each Spark application, multiple “jobs” (Spark actions) may be running concurrently if they were submitted by different threads。所以如果你用多线程跑多个Action，确实是可以的。这也是容易理解的，因为跑一个Action相当于就是向Spark的DAGScheduler去提交一个任务嘛。 Stage是可并行的么？ 可以。Stage描述了宽依赖间的RDD的变化过程，而RDD的变化总体上是一个DAG。因此我们可以认识到，对于两个NarrowDependency的Stage，它们确实是可以并行的。 启动一个任务Executor12345678910111213141516private[spark] class Executor( executorId: String, executorHostname: String, env: SparkEnv, userClassPath: Seq[URL] = Nil, isLocal: Boolean = false, uncaughtExceptionHandler: UncaughtExceptionHandler = new SparkUncaughtExceptionHandler) extends Logging &#123; def launchTask(context: ExecutorBackend, taskDescription: TaskDescription): Unit = &#123; val tr = new TaskRunner(context, taskDescription) runningTasks.put(taskDescription.taskId, tr) threadPool.execute(tr) &#125;... TaskRunner123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241class TaskRunner( execBackend: ExecutorBackend, private val taskDescription: TaskDescription) extends Runnable &#123; override def run(): Unit = &#123; threadId = Thread.currentThread.getId Thread.currentThread.setName(threadName) val threadMXBean = ManagementFactory.getThreadMXBean val taskMemoryManager = new TaskMemoryManager(env.memoryManager, taskId) val deserializeStartTime = System.currentTimeMillis() val deserializeStartCpuTime = if (threadMXBean.isCurrentThreadCpuTimeSupported) &#123; threadMXBean.getCurrentThreadCpuTime &#125; else 0L Thread.currentThread.setContextClassLoader(replClassLoader) val ser = env.closureSerializer.newInstance() logInfo(s"Running $taskName (TID $taskId)") execBackend.statusUpdate(taskId, TaskState.RUNNING, EMPTY_BYTE_BUFFER) var taskStartTime: Long = 0 var taskStartCpu: Long = 0 startGCTime = computeTotalGcTime() try &#123; // Must be set before updateDependencies() is called, in case fetching dependencies // requires access to properties contained within (e.g. for access control). Executor.taskDeserializationProps.set(taskDescription.properties) updateDependencies(taskDescription.addedFiles, taskDescription.addedJars) task = ser.deserialize[Task[Any]]( taskDescription.serializedTask, Thread.currentThread.getContextClassLoader) task.localProperties = taskDescription.properties task.setTaskMemoryManager(taskMemoryManager) // If this task has been killed before we deserialized it, let's quit now. Otherwise, // continue executing the task. val killReason = reasonIfKilled if (killReason.isDefined) &#123; // Throw an exception rather than returning, because returning within a try&#123;&#125; block // causes a NonLocalReturnControl exception to be thrown. The NonLocalReturnControl // exception will be caught by the catch block, leading to an incorrect ExceptionFailure // for the task. throw new TaskKilledException(killReason.get) &#125; // The purpose of updating the epoch here is to invalidate executor map output status cache // in case FetchFailures have occurred. In local mode `env.mapOutputTracker` will be // MapOutputTrackerMaster and its cache invalidation is not based on epoch numbers so // we don't need to make any special calls here. if (!isLocal) &#123; logDebug("Task " + taskId + "'s epoch is " + task.epoch) env.mapOutputTracker.asInstanceOf[MapOutputTrackerWorker].updateEpoch(task.epoch) &#125; // Run the actual task and measure its runtime. taskStartTime = System.currentTimeMillis() taskStartCpu = if (threadMXBean.isCurrentThreadCpuTimeSupported) &#123; threadMXBean.getCurrentThreadCpuTime &#125; else 0L var threwException = true val value = Utils.tryWithSafeFinally &#123; val res = task.run( taskAttemptId = taskId, attemptNumber = taskDescription.attemptNumber, metricsSystem = env.metricsSystem) threwException = false res &#125; &#123; val releasedLocks = env.blockManager.releaseAllLocksForTask(taskId) val freedMemory = taskMemoryManager.cleanUpAllAllocatedMemory() if (freedMemory &gt; 0 &amp;&amp; !threwException) &#123; val errMsg = s"Managed memory leak detected; size = $freedMemory bytes, TID = $taskId" if (conf.getBoolean("spark.unsafe.exceptionOnMemoryLeak", false)) &#123; throw new SparkException(errMsg) &#125; else &#123; logWarning(errMsg) &#125; &#125; if (releasedLocks.nonEmpty &amp;&amp; !threwException) &#123; val errMsg = s"$&#123;releasedLocks.size&#125; block locks were not released by TID = $taskId:\n" + releasedLocks.mkString("[", ", ", "]") if (conf.getBoolean("spark.storage.exceptionOnPinLeak", false)) &#123; throw new SparkException(errMsg) &#125; else &#123; logInfo(errMsg) &#125; &#125; &#125; task.context.fetchFailed.foreach &#123; fetchFailure =&gt; // uh-oh. it appears the user code has caught the fetch-failure without throwing any // other exceptions. Its *possible* this is what the user meant to do (though highly // unlikely). So we will log an error and keep going. logError(s"TID $&#123;taskId&#125; completed successfully though internally it encountered " + s"unrecoverable fetch failures! Most likely this means user code is incorrectly " + s"swallowing Spark's internal $&#123;classOf[FetchFailedException]&#125;", fetchFailure) &#125; val taskFinish = System.currentTimeMillis() val taskFinishCpu = if (threadMXBean.isCurrentThreadCpuTimeSupported) &#123; threadMXBean.getCurrentThreadCpuTime &#125; else 0L // If the task has been killed, let's fail it. task.context.killTaskIfInterrupted() val resultSer = env.serializer.newInstance() val beforeSerialization = System.currentTimeMillis() val valueBytes = resultSer.serialize(value) val afterSerialization = System.currentTimeMillis() // Deserialization happens in two parts: first, we deserialize a Task object, which // includes the Partition. Second, Task.run() deserializes the RDD and function to be run. task.metrics.setExecutorDeserializeTime( (taskStartTime - deserializeStartTime) + task.executorDeserializeTime) task.metrics.setExecutorDeserializeCpuTime( (taskStartCpu - deserializeStartCpuTime) + task.executorDeserializeCpuTime) // We need to subtract Task.run()'s deserialization time to avoid double-counting task.metrics.setExecutorRunTime((taskFinish - taskStartTime) - task.executorDeserializeTime) task.metrics.setExecutorCpuTime( (taskFinishCpu - taskStartCpu) - task.executorDeserializeCpuTime) task.metrics.setJvmGCTime(computeTotalGcTime() - startGCTime) task.metrics.setResultSerializationTime(afterSerialization - beforeSerialization) // Expose task metrics using the Dropwizard metrics system. // Update task metrics counters executorSource.METRIC_CPU_TIME.inc(task.metrics.executorCpuTime) ... executorSource.METRIC_MEMORY_BYTES_SPILLED.inc(task.metrics.memoryBytesSpilled) // Note: accumulator updates must be collected after TaskMetrics is updated val accumUpdates = task.collectAccumulatorUpdates() // TODO: do not serialize value twice val directResult = new DirectTaskResult(valueBytes, accumUpdates) val serializedDirectResult = ser.serialize(directResult) val resultSize = serializedDirectResult.limit() // directSend = sending directly back to the driver val serializedResult: ByteBuffer = &#123; if (maxResultSize &gt; 0 &amp;&amp; resultSize &gt; maxResultSize) &#123; logWarning(s"Finished $taskName (TID $taskId). Result is larger than maxResultSize " + s"($&#123;Utils.bytesToString(resultSize)&#125; &gt; $&#123;Utils.bytesToString(maxResultSize)&#125;), " + s"dropping it.") ser.serialize(new IndirectTaskResult[Any](TaskResultBlockId(taskId), resultSize)) &#125; else if (resultSize &gt; maxDirectResultSize) &#123; val blockId = TaskResultBlockId(taskId) env.blockManager.putBytes( blockId, new ChunkedByteBuffer(serializedDirectResult.duplicate()), StorageLevel.MEMORY_AND_DISK_SER) logInfo( s"Finished $taskName (TID $taskId). $resultSize bytes result sent via BlockManager)") ser.serialize(new IndirectTaskResult[Any](blockId, resultSize)) &#125; else &#123; logInfo(s"Finished $taskName (TID $taskId). $resultSize bytes result sent to driver") serializedDirectResult &#125; &#125; setTaskFinishedAndClearInterruptStatus() execBackend.statusUpdate(taskId, TaskState.FINISHED, serializedResult) &#125; catch &#123; case t: TaskKilledException =&gt; logInfo(s"Executor killed $taskName (TID $taskId), reason: $&#123;t.reason&#125;") val (accums, accUpdates) = collectAccumulatorsAndResetStatusOnFailure(taskStartTime) val serializedTK = ser.serialize(TaskKilled(t.reason, accUpdates, accums)) execBackend.statusUpdate(taskId, TaskState.KILLED, serializedTK) case _: InterruptedException | NonFatal(_) if task != null &amp;&amp; task.reasonIfKilled.isDefined =&gt; val killReason = task.reasonIfKilled.getOrElse("unknown reason") logInfo(s"Executor interrupted and killed $taskName (TID $taskId), reason: $killReason") val (accums, accUpdates) = collectAccumulatorsAndResetStatusOnFailure(taskStartTime) val serializedTK = ser.serialize(TaskKilled(killReason, accUpdates, accums)) execBackend.statusUpdate(taskId, TaskState.KILLED, serializedTK) case t: Throwable if hasFetchFailure &amp;&amp; !Utils.isFatalError(t) =&gt; val reason = task.context.fetchFailed.get.toTaskFailedReason if (!t.isInstanceOf[FetchFailedException]) &#123; // there was a fetch failure in the task, but some user code wrapped that exception // and threw something else. Regardless, we treat it as a fetch failure. val fetchFailedCls = classOf[FetchFailedException].getName logWarning(s"TID $&#123;taskId&#125; encountered a $&#123;fetchFailedCls&#125; and " + s"failed, but the $&#123;fetchFailedCls&#125; was hidden by another " + s"exception. Spark is handling this like a fetch failure and ignoring the " + s"other exception: $t") &#125; setTaskFinishedAndClearInterruptStatus() execBackend.statusUpdate(taskId, TaskState.FAILED, ser.serialize(reason)) case CausedBy(cDE: CommitDeniedException) =&gt; val reason = cDE.toTaskCommitDeniedReason setTaskFinishedAndClearInterruptStatus() execBackend.statusUpdate(taskId, TaskState.KILLED, ser.serialize(reason)) case t: Throwable =&gt; // Attempt to exit cleanly by informing the driver of our failure. // If anything goes wrong (or this was a fatal exception), we will delegate to // the default uncaught exception handler, which will terminate the Executor. logError(s"Exception in $taskName (TID $taskId)", t) // SPARK-20904: Do not report failure to driver if if happened during shut down. Because // libraries may set up shutdown hooks that race with running tasks during shutdown, // spurious failures may occur and can result in improper accounting in the driver (e.g. // the task failure would not be ignored if the shutdown happened because of premption, // instead of an app issue). if (!ShutdownHookManager.inShutdown()) &#123; val (accums, accUpdates) = collectAccumulatorsAndResetStatusOnFailure(taskStartTime) val serializedTaskEndReason = &#123; try &#123; ser.serialize(new ExceptionFailure(t, accUpdates).withAccums(accums)) &#125; catch &#123; case _: NotSerializableException =&gt; // t is not serializable so just send the stacktrace ser.serialize(new ExceptionFailure(t, accUpdates, false).withAccums(accums)) &#125; &#125; setTaskFinishedAndClearInterruptStatus() execBackend.statusUpdate(taskId, TaskState.FAILED, serializedTaskEndReason) &#125; else &#123; logInfo("Not reporting error to driver during JVM shutdown.") &#125; // Don't forcibly exit unless the exception was inherently fatal, to avoid // stopping other tasks unnecessarily. if (!t.isInstanceOf[SparkOutOfMemoryError] &amp;&amp; Utils.isFatalError(t)) &#123; uncaughtExceptionHandler.uncaughtException(Thread.currentThread(), t) &#125; &#125; finally &#123; runningTasks.remove(taskId) &#125; &#125; private def hasFetchFailure: Boolean = &#123; task != null &amp;&amp; task.context != null &amp;&amp; task.context.fetchFailed.isDefined &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108private[spark] abstract class Task[T]( val stageId: Int, val stageAttemptId: Int, val partitionId: Int, @transient var localProperties: Properties = new Properties, // The default value is only used in tests. serializedTaskMetrics: Array[Byte] = SparkEnv.get.closureSerializer.newInstance().serialize(TaskMetrics.registered).array(), val jobId: Option[Int] = None, val appId: Option[String] = None, val appAttemptId: Option[String] = None, val isBarrier: Boolean = false) extends Serializable &#123; ... /** * Called by [[org.apache.spark.executor.Executor]] to run this task. * * @param taskAttemptId an identifier for this task attempt that is unique within a SparkContext. * @param attemptNumber how many times this task has been attempted (0 for the first attempt) * @return the result of the task along with updates of Accumulators. */ final def run( taskAttemptId: Long, attemptNumber: Int, metricsSystem: MetricsSystem): T = &#123; SparkEnv.get.blockManager.registerTask(taskAttemptId) // TODO SPARK-24874 Allow create BarrierTaskContext based on partitions, instead of whether // the stage is barrier. val taskContext = new TaskContextImpl( stageId, stageAttemptId, // stageAttemptId and stageAttemptNumber are semantically equal partitionId, taskAttemptId, attemptNumber, taskMemoryManager, localProperties, metricsSystem, metrics) context = if (isBarrier) &#123; new BarrierTaskContext(taskContext) &#125; else &#123; taskContext &#125; InputFileBlockHolder.initialize() TaskContext.setTaskContext(context) taskThread = Thread.currentThread() if (_reasonIfKilled != null) &#123; kill(interruptThread = false, _reasonIfKilled) &#125; new CallerContext( "TASK", SparkEnv.get.conf.get(APP_CALLER_CONTEXT), appId, appAttemptId, jobId, Option(stageId), Option(stageAttemptId), Option(taskAttemptId), Option(attemptNumber)).setCurrentContext() try &#123; runTask(context) &#125; catch &#123; case e: Throwable =&gt; // Catch all errors; run task failure callbacks, and rethrow the exception. try &#123; context.markTaskFailed(e) &#125; catch &#123; case t: Throwable =&gt; e.addSuppressed(t) &#125; context.markTaskCompleted(Some(e)) throw e &#125; finally &#123; try &#123; // Call the task completion callbacks. If "markTaskCompleted" is called twice, the second // one is no-op. context.markTaskCompleted(None) &#125; finally &#123; try &#123; Utils.tryLogNonFatalError &#123; // Release memory used by this thread for unrolling blocks SparkEnv.get.blockManager.memoryStore.releaseUnrollMemoryForThisTask(MemoryMode.ON_HEAP) SparkEnv.get.blockManager.memoryStore.releaseUnrollMemoryForThisTask( MemoryMode.OFF_HEAP) // Notify any tasks waiting for execution memory to be freed to wake up and try to // acquire memory again. This makes impossible the scenario where a task sleeps forever // because there are no other tasks left to notify it. Since this is safe to do but may // not be strictly necessary, we should revisit whether we can remove this in the // future. val memoryManager = SparkEnv.get.memoryManager memoryManager.synchronized &#123; memoryManager.notifyAll() &#125; &#125; &#125; finally &#123; // Though we unset the ThreadLocal here, the context member variable itself is still // queried directly in the TaskRunner to check for FetchFailedExceptions. TaskContext.unset() InputFileBlockHolder.unset() &#125; &#125; &#125; &#125; ... 失败重试 spark.yarn.maxAppAttempts YARN申请资源的重试次数。 spark.yarn.max.executor.failuresSpark应用程序的最大Executor失败次数，默认numExecutors*2。 Spark的存储管理为了实现与底层细节的解耦，Spark的存储基于BlockManager给计算部分提供服务。类似于Driver和Executor，BlockManager机制也分为BlockManagerMaster和BlockManager。Driver上的BlockManagerMaster对于存在与Executor上的BlockManager统一管理。BlockManager只是负责管理所在Executor上的Block。BlockManagerMaster和BlockManager都是在SparkEnv中创建的， 123456789101112131415161718192021222324252627282930313233343536373839// Mapping from block manager id to the block manager's information.val blockManagerInfo = new concurrent.TrieMap[BlockManagerId, BlockManagerInfo]()val blockManagerMaster = new BlockManagerMaster( registerOrLookupEndpoint( BlockManagerMaster.DRIVER_ENDPOINT_NAME, new BlockManagerMasterEndpoint( rpcEnv, isLocal, conf, listenerBus, // 是否使用ExternalShuffleService读取持久化在磁盘上的数据 if (conf.get(config.SHUFFLE_SERVICE_FETCH_RDD_ENABLED)) &#123; externalShuffleClient &#125; else &#123; None &#125;, blockManagerInfo)), registerOrLookupEndpoint( BlockManagerMaster.DRIVER_HEARTBEAT_ENDPOINT_NAME, new BlockManagerMasterHeartbeatEndpoint(rpcEnv, isLocal, blockManagerInfo)), conf, isDriver)val blockTransferService = new NettyBlockTransferService(conf, securityManager, bindAddress, advertiseAddress, blockManagerPort, numUsableCores, blockManagerMaster.driverEndpoint)// NB: blockManager is not valid until initialize() is called later.val blockManager = new BlockManager( executorId, rpcEnv, blockManagerMaster, serializerManager, conf, memoryManager, mapOutputTracker, shuffleManager, blockTransferService, securityManager, externalShuffleClient) Driver节点和Executor节点的BlockManager之间的交互可以使用下图来描述，在此就不详细说明。 BlockId和BlockInfo抽象类BlockId被用来唯一标识一个Block，具有全局唯一的名字，通常和一个文件相对应。BlockId有着确定的命名规则，并且和它实际的类型有关。如果它是用来Shuffle的ShuffleBlockId，那么他的命名就是1String = "shuffle_" + shuffleId + "_" + mapId + "_" + reduceId 抑或它是用来Broadcast的BroadcastBlockId，他的命名就是1"broadcast_" + broadcastId + (if (field == "") "" else "_" + field) 或者它是一个RDD，它的命名就是1"rdd_" + rddId + "_" + splitIndex 通过在Spark.log里面跟踪这些block名字，我们可以了解到当前Spark任务的执行和存储情况。 BlockInfo中的level项表示这个block的存储级别。12345// BlockInfoManager.scalaprivate[storage] class BlockInfo( val level: StorageLevel, val classTag: ClassTag[_], val tellMaster: Boolean) &#123; 持久化Spark提供了如下的持久化级别，其中选项为useDisk、useMemory、useOffHeap、deserialized、replication，分别表示是否采用磁盘、内存、堆外内存、反序列化以及持久化维护的副本数。其中反序列化为false时（好绕啊），会对对象进行序列化存储，能够节省一定空间，但同时会消耗计算资源。需要注意的是，cache操作是persist的一个特例，等于MEMORY_ONLY的persist。所有的广播对象都是MEMORY_AND_DISK的存储级别1234567891011121314object StorageLevel extends scala.AnyRef with scala.Serializable &#123; val NONE = new StorageLevel(false, false, false, false) val DISK_ONLY = new StorageLevel(true, false, false, false) val DISK_ONLY_2 = new StorageLevel(true, false, false, false, 2) val MEMORY_ONLY = new StorageLevel(false, true, false, true) // 默认存储类别 val MEMORY_ONLY_2 = new StorageLevel(false, true, false, true, 2) val MEMORY_ONLY_SER = new StorageLevel(false, true, false, false) val MEMORY_ONLY_SER_2 = new StorageLevel(false, true, false, false, 2) val MEMORY_AND_DISK = new StorageLevel(true, true, false, true) val MEMORY_AND_DISK_2 = new StorageLevel(true, true, false, true, 2) val MEMORY_AND_DISK_SER = new StorageLevel(true, true, false, false) val MEMORY_AND_DISK_SER_2 = new StorageLevel(true, true, false, false, 2) val OFF_HEAP = new StorageLevel(true, true, true, false, 1)&#125; 想在Spark任务完成之后检查每一个RDD的缓存状况是比较困难的，虽然在Spark EventLog中，我们也能看到在每一个RDD的RDD Info中有一个StorageLevel的条目。RDDInfo的源码建议我们可以通过(Use Disk||Use Memory)&amp;&amp;NumberofCachedPartitions这样的条件来判断一个RDD到底有没有被cache。但实际上，似乎EventLog里面的NumberofCachedPartitions、Memory Size、Disk Size永远是0，这可能是只能在执行过程中才能看到这些字段的值，毕竟WebUI的Storage标签就只在执行时能看到。不过(Use Disk||Use Memory)在cache调用的RDD上是true的，所以可以以这个RDD为根做一个BFS，将所有不需要计算的RDD找出来。 CheckpointSave相对于持久化，这里指的是保存数据到文件或者数据表。 RDD的overwrite问题一个蛋疼的事情是RDD的诸如saveAsTextFile不能够像DF的API一样直接指定overwrite为true，导致无法复写的情况。为此，需要借助于hdfs的API手动来判断是否exist。123456789val conf = new org.apache.hadoop.conf.Configuration()// 注意，可能需要手动指定集群，因为Spark的默认集群可能不对，// 届时可能产生Wrong FS的错误val fs = FileSystem.get(new java.net.URI("hdfs根"), conf)// val fs = FileSystem.get(sc.hadoopConfiguration)val path = new org.apache.hadoop.fs.Path("需要删除的目录")if (fs.exists(path))&#123; fs.delete(path, true)&#125; RDD的save问题saveAsTextFile会写到多个文件里面，如下所示，如果我们save到这个文件夹，那么会在下面创建_SUCCESS、part-000000这样的文件那么我们读的时候，比较方便的是用下面的方法1spark.read.text(path).rdd.collect().mkString("") 但这样会导致读出来的string周围有中括号包起来。因此要用下面的办法去掉12345text = if(textRaw.endsWith("]"))&#123; textRaw.substring(1, textRaw.length - 1)&#125;else&#123; textRaw&#125; 不过，我们有另一种办法，就是绕过spark，而直接用hadoop的api来读取。123456val conf: Configurationval path = new Path(fileName)val fileSystem = path.getFileSystem(conf)val writer = new BufferedWriter(new OutputStreamWriter(fileSystem.create(path)))writer.write(s)writer.close() BlockInfoManagerBlockInfoManager用来管理Block的元信息，例如它维护了所有BlockId的BlockInfo信息infos: mutable.HashMap[BlockId, BlockInfo]。不过它最主要的功能还是为读写Block提供锁服务 本地读Block本地读方法位于BlockManager.scala中，从前叫getBlockData，现在叫getLocalBlockData，名字更易懂了。getLocalBlockData的主要内容就对Block的性质进行讨论，如果是Shuffle的，那么就借助于ShuffleBlockResolver。ShuffleBlockResolver是一个trait，它有两个子类IndexShuffleBlockResolver和ExternalShuffleBlockResolver，它们定义如何从一个logical shuffle block identifier（例如map、reduce或shuffle）中取回Block。这个类维护Block和文件的映射关系，维护index文件，向BlockStore提供抽象。12345678910111213141516171819// BlockManager.scalaoverride def getLocalBlockData(blockId: BlockId): ManagedBuffer = &#123; if (blockId.isShuffle) &#123; // 如果这个BlockId是Shuffle的，那么就通过shuffleManager的shuffleBlockResolver来获取BlockData shuffleManager.shuffleBlockResolver.getBlockData(blockId) &#125; else &#123; // 否则使用getLocalBytes getLocalBytes(blockId) match &#123; case Some(blockData) =&gt; new BlockManagerManagedBuffer(blockInfoManager, blockId, blockData, true) case None =&gt; // If this block manager receives a request for a block that it doesn't have then it's // likely that the master has outdated block statuses for this block. Therefore, we send // an RPC so that this block is marked as being unavailable from this block manager. reportBlockStatus(blockId, BlockStatus.empty) throw new BlockNotFoundException(blockId.toString) &#125; &#125;&#125; 我们看getLocalBytes函数，它带锁地调用doGetLocalBytes12345def getLocalBytes(blockId: BlockId): Option[BlockData] = &#123; logDebug(s"Getting local block $blockId as bytes") assert(!blockId.isShuffle, s"Unexpected ShuffleBlockId $blockId") blockInfoManager.lockForReading(blockId).map &#123; info =&gt; doGetLocalBytes(blockId, info) &#125;&#125; 上面的这一段代码会在spark.log中产生类似下面的Log，我们由此可以对Block的用途，存储级别等进行分析。123419/11/26 17:24:52 DEBUG BlockManager: Getting local block broadcast_3_piece0 as bytes19/11/26 17:24:52 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_3_piece019/11/26 17:24:52 TRACE BlockInfoManager: Task -1024 acquired read lock for broadcast_3_piece019/11/26 17:24:52 DEBUG BlockManager: Level for block broadcast_3_piece0 is StorageLevel(disk, memory, 1 replicas) doGetLocalBytes负责根据Block的存储级别，以最小的代价取到序列化后的数据。从下面的代码中可以看到，Spark认为序列化一个对象的开销是高于从磁盘中读取一个已经序列化之后的对象的开销的，因为它宁可从磁盘里面取也不愿意直接从内存序列化。12345678910111213141516171819202122232425262728293031323334private def doGetLocalBytes(blockId: BlockId, info: BlockInfo): BlockData = &#123; val level = info.level logDebug(s"Level for block $blockId is $level") // 如果内容是序列化的，先尝试读序列化的到内存和磁盘。 // 如果内容是非序列化的，尝试序列化内存中的对象，最后抛出异常表示不存在 if (level.deserialized) &#123; // 因为内存中是非序列化的，尝试能不能先从磁盘中读到非序列化的。 if (level.useDisk &amp;&amp; diskStore.contains(blockId)) &#123; // Note: Spark在这里故意不将block放到内存里面，因为这个if分支是处理非序列化块的， // 这个块可能被按照非序列化对象的形式存在内存里面，因此没必要在在内存里面存一份序列化了的。 diskStore.getBytes(blockId) &#125; else if (level.useMemory &amp;&amp; memoryStore.contains(blockId)) &#123; // 不在硬盘上，就序列化内存中的对象 new ByteBufferBlockData(serializerManager.dataSerializeWithExplicitClassTag( blockId, memoryStore.getValues(blockId).get, info.classTag), true) &#125; else &#123; handleLocalReadFailure(blockId) &#125; &#125; else &#123; // 如果存在已经序列化的对象 if (level.useMemory &amp;&amp; memoryStore.contains(blockId)) &#123; // 先找内存 new ByteBufferBlockData(memoryStore.getBytes(blockId).get, false) &#125; else if (level.useDisk &amp;&amp; diskStore.contains(blockId)) &#123; // 再找磁盘 val diskData = diskStore.getBytes(blockId) maybeCacheDiskBytesInMemory(info, blockId, level, diskData) .map(new ByteBufferBlockData(_, false)) .getOrElse(diskData) &#125; else &#123; handleLocalReadFailure(blockId) &#125; &#125;&#125; Spark的内存管理在Spark 1.6之后，内存管理模式发生了大变化，从前版本的内存管理需要通过指定spark.memory.useLegacyMode来手动启用，因此在这里只对之后的进行论述。 Spark内存布局如下图所示，Spark的堆内存空间可以分为Spark托管区、用户区和保留区三块。其中保留区占300MB，是固定的。托管区的大小由spark.memory.fraction节制，而1 - spark.memory.fraction的部分用户区。这个值越小，就越容易Spill或者Cache evict。这个设置的用途是将internal metadata、user data structures区分开来。从而减少对稀疏的或者不常出现的大对象的大小的不准确估计造成的影响（限定词有点多，是翻译的注释、、、）。默认spark.memory.fraction是0.6。123// package.scalaprivate[spark] val MEMORY_FRACTION = ConfigBuilder("spark.memory.fraction") .doc("...").doubleConf.createWithDefault(0.6) Spark的托管区又分为Execution和Storage两个部分。其中Storage主要用来缓存RDD、Broadcast之类的对象，Execution被用来存Mapside的Shuffle数据。Storage和Execution共享的内存，spark.storage.storageFraction（现在应该已经改成了spark.memory.storageFraction）表示对eviction免疫的Storage部分的大小，它的值越大，Execution内存就越小，Task就越容易Spill。反之，Cache就越容易被evict。默认spark.memory.storageFraction是0.5。123// package.scalaprivate[spark] val MEMORY_STORAGE_FRACTION = ConfigBuilder("spark.memory.storageFraction") .doc("...").doubleConf.checkValue(v =&gt; v &gt;= 0.0 &amp;&amp; v &lt; 1.0, "Storage fraction must be in [0,1)").createWithDefault(0.5) Storage可以借用任意多的Execution内存，直到Execution重新要回。此时被Cache的块会被从内存中evict掉（具体如何evict，根据每个Block的存储级别）。Execution也可以借用任意多的Storage的，但是Execution的借用不能被Storage驱逐，原因是因为实现起来很复杂。我们在稍后将看到，Spark没有一个统一的资源分配的入口。 除了堆内内存，Spark还可以使用堆外内存。为什么要有这个东西呢？原因是提高内存使用率、提高Shuffle时排序的效率等。由于Spark任务的性质，使用堆外内存能够更精细化地管理，而不需要通过JVM里面的GC，并且序列化数据的占用空间也可以被精确计算。此外，序列化也能节省内存开销。堆外内存在Spark 2.0之后由Tachyon迁移到了JDK Unsafe API实现。可通过配置spark.memory.offHeap.enabled参数启用堆外内存，并由spark.memory.offHeap.size参数设定堆外空间的大小。除了没有other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。 MemoryManagerSpark中负责文件管理的类是MemoryManager，它是一个抽象类，被SparkEnv持有。在1.6版本后引入的UnifiedMemoryManager是它的一个实现。12// SparkEnv.scalaval memoryManager: MemoryManager = UnifiedMemoryManager(conf, numUsableCores) UnifiedMemoryManager实现了诸如acquireExecutionMemory等方法来分配内存。通过在acquireExecutionMemory时传入一个MemoryMode可以告知是从堆内请求还是从堆外请求。需要注意的是，这类的函数并不像malloc一样直接去请求一段内存，并返回内存的地址，而是全局去维护每个Task所使用的内存大小。每一个Task在申请内存（new对象）之前都会去检查一下自己有没有超标，否则就去Spill。也就是说MemoryManager实际上是一个外挂式的内存管理系统，它不实际上托管内存，整个内存还是由JVM管理的。对Task的Execution内存使用进行跟踪的这个机制被实现ExecutionMemoryPool中，如下面的代码所示。123// ExecutionMemoryPool.scala // 保存每一个Task所占用的内存大小private val memoryForTask = new mutable.HashMap[Long, Long]() 当然，有ExecutionMemoryPool就也有StorageMemoryPool，他们都不出所料继承了MemoryPool。而以上这些Pool最后都被MemoryManager所持有。123456789// MemoryManager.scala@GuardedBy("this")protected val onHeapStorageMemoryPool = new StorageMemoryPool(this, MemoryMode.ON_HEAP)@GuardedBy("this")protected val offHeapStorageMemoryPool = new StorageMemoryPool(this, MemoryMode.OFF_HEAP)@GuardedBy("this")protected val onHeapExecutionMemoryPool = new ExecutionMemoryPool(this, MemoryMode.ON_HEAP)@GuardedBy("this")protected val offHeapExecutionMemoryPool = new ExecutionMemoryPool(this, MemoryMode.OFF_HEAP) 请求内存的流程我们知道，在Shuffle操作中有两个内存使用大户ExecutorSorter和ExternalAppendOnlyMap，都继承了Spillable，从而实现了在内存不足时进行Spill。我们查看对应的maybeSpill方法，它调用了自己父类MemoryConsumer中的acquireExecutionMemory方法。由于从代码注释上看似乎MemoryConsumer包括它引用到的TaskMemoryManager类都与Tungsten有关，所以我们将在稍后进行研究。目前只是列明调用过程，因为如果其中涉及要向Spark托管内存请求分配，最终调用的还是UnifiedMemoryManager中的对应方法。1234567891011121314151617181920212223// Spillable.scala// 在maybeSpill方法中val granted = acquireMemory(amountToRequest)// MemoryConsumer.scalapublic long acquireMemory(long size) &#123; long granted = taskMemoryManager.acquireExecutionMemory(size, this); used += granted; return granted;&#125;// TaskMemoryManager.javapublic long acquireExecutionMemory(long required, MemoryConsumer consumer) &#123; assert(required &gt;= 0); assert(consumer != null); MemoryMode mode = consumer.getMode(); synchronized (this) &#123; long got = memoryManager.acquireExecutionMemory(required, taskAttemptId, mode); ...// Executor.scala// TaskMemoryManager中的memoryManager，其实就是一个UnifiedMemoryManagerval taskMemoryManager = new TaskMemoryManager(env.memoryManager, taskId) 下面，我们来看acquireExecutionMemory的详细实现。它前面会首先根据memoryMode选择使用的MemoryPool，是堆内的，还是堆外的。然后它会有个函数maybeGrowExecutionPool，用来处理在需要的情况下从Storage部分挤占一些内存回来。我们可以在稍后详看这个方法。现在，我们发现acquireExecutionMemory会往对应的MemoryPool发一个调用acquireMemory。1234567891011// UnifiedMemoryManager.scalaoverride private[memory] def acquireExecutionMemory( ... // 实际上是一个ExecutionMemoryPool executionPool.acquireMemory( numBytes, taskAttemptId, maybeGrowExecutionPool, () =&gt; computeMaxExecutionPoolSize)&#125;// MemoryManager.scala@GuardedBy("this")protected val onHeapExecutionMemoryPool = new ExecutionMemoryPool(this, MemoryMode.ON_HEAP) 由于我们讨论的场景就是请求堆内的执行内存，所以就进入ExecutionMemoryPool.scala查看相关代码。在Spark中，会尝试保证每个Task能够得到合理份额的内存，而不是让某些Task的内存持续增大到一定的数量，然后导致其他人持续地Spill到Disk。如果有N个任务，那么保证每个Task在Spill前可以获得至少1 / 2N的内存，并且最多只能获得1 / N。因为N是持续变化的，所以我们需要跟踪活跃Task集合，并且持续在等待Task集合中更新1 / 2N和1 / N的值。这个是借助于同步机制实现的，在1.6之前，是由ShuffleMemoryManager来仲裁的。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// ExecutionMemoryPool.scala // 保存每一个Task所占用的内存大小private val memoryForTask = new mutable.HashMap[Long, Long]()private[memory] def acquireMemory( numBytes: Long, taskAttemptId: Long, maybeGrowPool: Long =&gt; Unit = (additionalSpaceNeeded: Long) =&gt; Unit, computeMaxPoolSize: () =&gt; Long = () =&gt; poolSize): Long = lock.synchronized &#123; assert(numBytes &gt; 0, s"invalid number of bytes requested: $numBytes") // TODO: clean up this clunky method signature // 如果我们没有Track到这个Task，那么就加到memoryForTask if (!memoryForTask.contains(taskAttemptId)) &#123; memoryForTask(taskAttemptId) = 0L // 通知wait集合中的Task更新自己的numTasks lock.notifyAll() &#125; // TODO: simplify this to limit each task to its own slot // 尝试寻找，直到要么我们确定我们不愿意给它内存（因为超过1/N）了， // 或者我们有足够的内存提供。注意我们保证每个Task的1/2N的底线 while (true) &#123; val numActiveTasks = memoryForTask.keys.size val curMem = memoryForTask(taskAttemptId) // 在每一次迭代中，首先尝试从Storage借用的内存中拿回部分内存。 // 这是必要的，否则可能发生竞态，此时新的Storage Block会再把这个Task需要的执行内存拿回来。 maybeGrowPool(numBytes - memoryFree) // maxPoolSize是内存池扩容之后可能的最大大小。 // 通过这个值，可以计算所谓的1/N和1/2N具体有多大。在计算时必须考虑可能被释放的内存（例如evicting cached blocks），否则就会导致SPARK-12155的问题 val maxPoolSize = computeMaxPoolSize() val maxMemoryPerTask = maxPoolSize / numActiveTasks val minMemoryPerTask = poolSize / (2 * numActiveTasks) // 最多再给这么多内存 val maxToGrant = math.min(numBytes, math.max(0, maxMemoryPerTask - curMem)) // 实际上能给这么多内存 val toGrant = math.min(maxToGrant, memoryFree) // 虽然我们尝试让每个Task尽可能得到1/2N的内存， // 但由于Task数量是动态变化的，可能在N增长前，老的Task就把内存吃完了 // 所以如果我们给不了这么多内存的话，就让它睡在wait上面 if (toGrant &lt; numBytes &amp;&amp; curMem + toGrant &lt; minMemoryPerTask) &#123; logInfo(s"TID $taskAttemptId waiting for at least 1/2N of $poolName pool to be free") lock.wait() &#125; else &#123; memoryForTask(taskAttemptId) += toGrant return toGrant &#125; &#125; 0L // Never reached&#125; Tungsten内存管理机制Tungsten不依赖于Java对象，所以堆内和堆外的内存分配都可以支持。序列化时间相比原生的要加快很多。其优化主要包含三点： Memory Management and Binary Processing Cache-aware computation Code generation 这个是为了解决在Spark 2.0之前SparkSQL使用的Volcano中大量的链式next()导致的性能（虚函数等）问题。 在内存管理部分，能看到诸如TaskMemoryManager.java的文件；在稍后的Shuffle部分，能看到诸如UnsafeWriter.java的文件。这些Java文件在实现上就有对Tungsten的使用，因为用到了sun.misc.Unsafe的API，所以使用Tungsten的shuffle又叫Unsafe shuffle。 在MemoryManager中持有了Tungsten内存管理机制的核心类tungstenMemoryAllocator: MemoryAllocator。并设置了tungstenMemoryMode指示其分配内存的默认位置，如果MEMORY_OFFHEAP_ENABLED是打开的且MEMORY_OFFHEAP_SIZE是大于0的，那么默认使用堆外内存。 TaskMemoryManagerTaskMemoryManager这个对象被用来管理一个Task的堆内和对外内存分配，因此它能够调度一个Task中各个组件的内存使用情况。当组件需要使用TaskMemoryManager提供的内存时，他们需要继承一个MemoryConsumer类，以便向TaskMemoryManager请求内存。TaskMemoryManager中集成了普通的内存分配机制和Tungsten内存分配机制。 普通分配acquireExecutionMemory我们跟踪TaskMemoryManager.acquireExecutionMemory相关代码，它先尝试从MemoryManager直接请求内存12345678910// TaskMemoryManager.scalapublic long acquireExecutionMemory(long required, MemoryConsumer consumer) &#123; assert(required &gt;= 0); assert(consumer != null); MemoryMode mode = consumer.getMode(); // 如果我们在分配堆外内存的页，并且受到一个对堆内内存的请求， // 那么没必要去Spill，因为怎么说也只是Spill的堆外内存。 // 不过现在改这个风险很大。。。。 synchronized (this) &#123; long got = memoryManager.acquireExecutionMemory(required, taskAttemptId, mode); 如果请求不到，那么先尝试让同一个TaskMemoryManager上的其他的Consumer Spill，以减少Spill频率，从而减少Spill出来的小文件数量。主要是根据每个Consumer的内存使用排个序，从而避免重复对同一个Consumer进行Spill，导致产生很多小文件。123456789101112... if (got &lt; required) &#123; TreeMap&lt;Long, List&lt;MemoryConsumer&gt;&gt; sortedConsumers = new TreeMap&lt;&gt;(); for (MemoryConsumer c: consumers) &#123; if (c != consumer &amp;&amp; c.getUsed() &gt; 0 &amp;&amp; c.getMode() == mode) &#123; long key = c.getUsed(); List&lt;MemoryConsumer&gt; list = sortedConsumers.computeIfAbsent(key, k -&gt; new ArrayList&lt;&gt;(1)); list.add(c); &#125; &#125;... 现在，我们对排序得到的一系列sortedConsumers进行spill，一旦成功释放出内存，就立刻向MemoryManager去请求这些内存，相关代码没啥可看的，故省略。如果内存还是不够，就Spill自己，如果成功了，就向MemoryManager请求内存。1234567891011121314151617181920... // call spill() on itself if (got &lt; required) &#123; try &#123; long released = consumer.spill(required - got, consumer); if (released &gt; 0) &#123; logger.debug("Task &#123;&#125; released &#123;&#125; from itself (&#123;&#125;)", taskAttemptId, Utils.bytesToString(released), consumer); got += memoryManager.acquireExecutionMemory(required - got, taskAttemptId, mode); &#125; &#125; catch (ClosedByInterruptException e) &#123; ... &#125; &#125; consumers.add(consumer); logger.debug("Task &#123;&#125; acquired &#123;&#125; for &#123;&#125;", taskAttemptId, Utils.bytesToString(got), consumer); return got; &#125;&#125; Tungsten分配allocatePageTaskMemoryManager还有个allocatePage方法，用来获得MemoryBlock，这个是通过Tungsten机制分配的。TaskMemoryManager使用了类似操作系统中分页的机制来操控内存。每个“页”，也就是MemoryBlock对象，维护了一段堆内或者堆外的内存。页的总数由PAGE_NUMBER_BITS来决定，即对于一个64位的地址，高PAGE_NUMBER_BITS（默认13）位表示一个页，而后面的位表示在页内的偏移。当然，如果是堆外内存，那么这个64位就直接是内存地址了。有关使用分页机制的原因在TaskMemoryManager.java有介绍，我暂时没看懂。 需要注意的是，即使使用Tungsten分配，仍然不能绕开UnifiedMemoryManager机制的管理，所以我们看到在allocatePage方法中先要通过acquireExecutionMemory方法注册，请求到逻辑内存之后，再通过下面的方法请求物理内存123456// TaskMemoryManager.scalalong acquired = acquireExecutionMemory(size, consumer);if (acquired &lt;= 0) &#123; return null;&#125;page = memoryManager.tungstenMemoryAllocator().allocate(acquired); Spark Job执行流程分析Job阶段下面我们通过一个RDD上的Action操作count，查看Spark的Job是如何运行和调度的。特别注意的是，在SparkSQL中，Action操作有不同的执行流程，所以宜对比着看。count通过全局的SparkContext.runJob启动一个Job，这个函数转而调用DAGScheduler.runJob。Utils.getIteratorSize实际上就是遍历一遍迭代器，以便统计count。1234567891011// RDD.scaladef count(): Long = sc.runJob(this, Utils.getIteratorSize _).sum// Utils.scaladef getIteratorSize(iterator: Iterator[_]): Long = &#123; var count = 0L while (iterator.hasNext) &#123; count += 1L iterator.next() &#125; count&#125; 在参数列表里面的下划线_的作用是将方法转为函数，而方法和函数的定义和区别可参考我的另一篇文章。下面查看runJob函数。比较有趣的是clean函数，它调用ClosureCleaner.clean方法，这个方法用来清理$outer域中未被引用的变量。因为我们要将闭包func序列化，并从Driver发送到Executor上面。序列化闭包的过程就是为每一个闭包生成一个可序列化类，在生成时，会将这个闭包所引用的外部对象也序列化。容易发现，如果我们为了使用外部对象的某些字段，而序列化整个对象，那么开销是很大的，因此通过clean来清除不需要的部分以减少序列化开销。此外，getCallSite用来生成诸如s&quot;$lastSparkMethod at $firstUserFile:$firstUserLine&quot;这样的字符串，它实际上会回溯调用栈，找到第一个不是在Spark包中的函数，即$lastSparkMethod，它是导致一个RDD创建的函数，比如各种Transform操作、sc.parallelize等。123456789101112131415161718192021222324// SparkContext.scaladef runJob[T, U: ClassTag]( rdd: RDD[T], func: (TaskContext, Iterator[T]) =&gt; U, partitions: Seq[Int], resultHandler: (Int, U) =&gt; Unit): Unit = &#123; if (stopped.get()) &#123; throw new IllegalStateException("SparkContext has been shutdown") &#125; val callSite = getCallSite val cleanedFunc = clean(func) logInfo("Starting job: " + callSite.shortForm) if (conf.getBoolean("spark.logLineage", false)) &#123; logInfo("RDD's recursive dependencies:\n" + rdd.toDebugString) &#125; dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get) progressBar.foreach(_.finishAll()) // CheckPoint机制 rdd.doCheckpoint()&#125;private[spark] def clean[F &lt;: AnyRef](f: F, checkSerializable: Boolean = true): F = &#123; ClosureCleaner.clean(f, checkSerializable) f&#125; 我们发现，传入的func只接受一个Iterator[_]参数，但是其形参声明却是接受TaskContext和Iterator[T]两个参数。这是为什么呢？这是因为runJob有不少重载函数，例如下面的这个1234567def runJob[T, U: ClassTag]( rdd: RDD[T], func: Iterator[T] =&gt; U, partitions: Seq[Int]): Array[U] = &#123; val cleanedFunc = clean(func) runJob(rdd, (ctx: TaskContext, it: Iterator[T]) =&gt; cleanedFunc(it), partitions)&#125; 下面我们查看DAGScheduler.runJob函数，它实际上就是调用submitJob，然后等待Job执行的结果。由于Spark的DAGScheduler是基于事件循环的，它拥有一个DAGSchedulerEventProcessLoop类型的变量eventProcessLoop，不同的对象向它post事件，然后在它的onReceive循环中会依次对这些事件调用处理函数。我们需要注意的是partitions不同于我们传入的rdd.partitions，前者是一个Array[Int]，后者是一个Array[Partition]。并且在逻辑意义上，前者表示需要计算的partition，对于如first之类的Action操作来说，它只是rdd的所有partition的一个子集，我们将在稍后的submitMissingTasks函数中继续看到这一点。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263def runJob[T, U](...): Unit = &#123; val start = System.nanoTime val waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties) // 下面就是在等了 ThreadUtils.awaitReady(waiter.completionFuture, Duration.Inf) waiter.completionFuture.value.get match &#123; case scala.util.Success(_) =&gt; logInfo("Job %d finished: %s, took %f s".format (waiter.jobId, callSite.shortForm, (System.nanoTime - start) / 1e9)) case scala.util.Failure(exception) =&gt; logInfo("Job %d failed: %s, took %f s".format (waiter.jobId, callSite.shortForm, (System.nanoTime - start) / 1e9)) // SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler. val callerStackTrace = Thread.currentThread().getStackTrace.tail exception.setStackTrace(exception.getStackTrace ++ callerStackTrace) throw exception &#125;&#125;def submitJob[T, U]( rdd: RDD[T], // target RDD to run tasks on，就是被执行count的RDD func: (TaskContext, Iterator[T]) =&gt; U, // 在RDD每一个partition上需要跑的函数 partitions: Seq[Int], callSite: CallSite, // 被调用的位置 resultHandler: (Int, U) =&gt; Unit, properties: Properties): JobWaiter[U] = &#123; // 检查是否在一个不存在的分区上创建一个Task val maxPartitions = rdd.partitions.length partitions.find(p =&gt; p &gt;= maxPartitions || p &lt; 0).foreach &#123; p =&gt; throw new IllegalArgumentException( "Attempting to access a non-existent partition: " + p + ". " + "Total number of partitions: " + maxPartitions)&#125; // jobId是从后往前递增的 val jobId = nextJobId.getAndIncrement() if (partitions.isEmpty) &#123; val time = clock.getTimeMillis() // listenerBus是一个LiveListenerBus对象，从DAGScheduler构造时得到，用来做event log // SparkListenerJobStart定义在SparkListener.scala文件中 listenerBus.post(SparkListenerJobStart(jobId, time, Seq[Info](), SerializationUtils.clone(properties))) listenerBus.post(SparkListenerJobEnd(jobId, time, JobSucceeded)) // 如果partitions是空的，那么就直接返回 return new JobWaiter[U](this, jobId, 0, resultHandler) &#125; assert(partitions.nonEmpty) val func2 = func.asInstanceOf[(TaskContext, Iterator[_]) =&gt; _] val waiter = new JobWaiter[U](this, jobId, partitions.size, resultHandler) // 我们向eventProcessLoop提交一个JobSubmitted事件 eventProcessLoop.post(JobSubmitted( jobId, rdd, func2, partitions.toArray, callSite, waiter, SerializationUtils.clone(properties))) waiter&#125;// DAGSchedulerEvent.scalaprivate[scheduler] case class JobSubmitted( jobId: Int, finalRDD: RDD[_], func: (TaskContext, Iterator[_]) =&gt; _, partitions: Array[Int], callSite: CallSite, listener: JobListener, properties: Properties = null) extends DAGSchedulerEvent 下面我们具体看看对JobSubmitted的响应123456789101112131415161718192021222324// DAGScheduler.scalaprivate[scheduler] def handleJobSubmitted(...) &#123; var finalStage: ResultStage = null // 首先我们尝试创建一个`finalStage: ResultStage`，这是整个Job的最后一个Stage。 try &#123; // func: (TaskContext, Iterator[_]) =&gt; _ // 下面的语句是可能抛BarrierJobSlotsNumberCheckFailed或者其他异常的， // 例如一个HadoopRDD所依赖的HDFS文件被删除了 finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite) &#125; catch &#123; ...// DAGScheduler.scalaprivate def createResultStage(...): ResultStage = &#123; checkBarrierStageWithDynamicAllocation(rdd) checkBarrierStageWithNumSlots(rdd) checkBarrierStageWithRDDChainPattern(rdd, partitions.toSet.size) val parents = getOrCreateParentStages(rdd, jobId) val id = nextStageId.getAndIncrement() val stage = new ResultStage(id, rdd, func, partitions, parents, jobId, callSite) stageIdToStage(id) = stage updateJobIdStageIdMaps(jobId, stage) stage&#125; 这里createResultStage所返回的ResultStage继承了Stage类。Stage类有个rdd参数，对ResultStage而言就是finalRDD，对ShuffleMapStage而言就是ShuffleDependency.rdd12345// DAGScheduler.scaladef createShuffleMapStage[K, V, C]( shuffleDep: ShuffleDependency[K, V, C], jobId: Int): ShuffleMapStage = &#123; val rdd = shuffleDep.rdd ... 下面我们来看看checkBarrierStageWithNumSlots这个函数，因为它会抛出BarrierJobSlotsNumberCheckFailed这个异常，被handleJobSubmitted捕获。这个函数主要是为了检测是否有足够的slots去运行所有的barrier task。屏障调度器是Spark为了支持深度学习在2.4.0版本所引入的一个特性。它要求在barrier stage中同时启动所有的Task，当任意的task执行失败的时候，总是重启整个barrier stage。这么麻烦是因为Spark希望能够在Task中提供一个barrier以供显式同步。1234567891011121314151617181920212223242526272829303132333435363738394041424344// DAGScheduler.scalaprivate def checkBarrierStageWithNumSlots(rdd: RDD[_]): Unit = &#123; val numPartitions = rdd.getNumPartitions val maxNumConcurrentTasks = sc.maxNumConcurrentTasks if (rdd.isBarrier() &amp;&amp; numPartitions &gt; maxNumConcurrentTasks) &#123; throw new BarrierJobSlotsNumberCheckFailed(numPartitions, maxNumConcurrentTasks) &#125;&#125;// DAGScheduler.scala ... case e: BarrierJobSlotsNumberCheckFailed =&gt; // If jobId doesn't exist in the map, Scala coverts its value null to 0: Int automatically. // barrierJobIdToNumTasksCheckFailures是一个ConcurrentHashMap，表示对每个BarrierJob上失败的Task数量 val numCheckFailures = barrierJobIdToNumTasksCheckFailures.compute(jobId, (_: Int, value: Int) =&gt; value + 1) ... if (numCheckFailures &lt;= maxFailureNumTasksCheck) &#123; messageScheduler.schedule( new Runnable &#123; override def run(): Unit = eventProcessLoop.post(JobSubmitted(jobId, finalRDD, func, partitions, callSite, listener, properties)) &#125;, timeIntervalNumTasksCheck, TimeUnit.SECONDS ) return &#125; else &#123; // Job failed, clear internal data. barrierJobIdToNumTasksCheckFailures.remove(jobId) listener.jobFailed(e) return &#125; case e: Exception =&gt; logWarning("Creating new stage failed due to exception - job: " + jobId, e) listener.jobFailed(e) return &#125; // Job submitted, clear internal data. barrierJobIdToNumTasksCheckFailures.remove(jobId) ... 下面开始创建Job。ActiveJob表示在DAGScheduler里面运行的一个Job。12345678910111213141516171819// DAGScheduler.scala ... val job = new ActiveJob(jobId, finalStage, callSite, listener, properties) clearCacheLocs() // 在这里会打印四条日志，这个可以被用来在Spark.log里面定位事件 logInfo("Got job %s (%s) with %d output partitions".format( job.jobId, callSite.shortForm, partitions.length)) logInfo("Final stage: " + finalStage + " (" + finalStage.name + ")") logInfo("Parents of final stage: " + finalStage.parents) logInfo("Missing parents: " + getMissingParentStages(finalStage)) ... val stageIds = jobIdToStageIds(jobId).toArray val stageInfos = stageIds.flatMap(id =&gt; stageIdToStage.get(id).map(_.latestInfo)) listenerBus.post(SparkListenerJobStart(job.jobId, jobSubmissionTime, stageInfos, properties)) // 从最后一个stage开始调用submitStage submitStage(finalStage)&#125; Job只负责向“叶子”Stage要结果，而之前Stage的运行是由DAGScheduler来调度的。这是因为若干Job可能共用同一个Stage的计算结果，所以将某个Stage强行归属到某个Job是不符合Spark设计逻辑的。我这么说的原因有一下两点 在下面的论述中可以看到，在getMissingParentStages中会调用getOrCreateShuffleMapStage去取某个Stage。 根据爆栈网，Stage中定义了一个jobIds，它是一个HashSet，也暗示了其可以被复用。 1234private[scheduler] abstract class Stage(...) extends Logging &#123; ... /** Set of jobs that this stage belongs to. */ val jobIds = new HashSet[Int] Stage阶段Stage是如何划分的呢？又是如何计算Stage之间的依赖的？我们继续查看submitStage这个函数，对于一个Stage，首先调用getMissingParentStages看看它的父Stage能不能直接用，也就是说这个Stage的rdd所依赖的所有父RDD能不能直接用，如果不行的话，就要先算父Stage的。在前面的论述里，我们知道，若干Job可能共用同一个Stage的计算结果，而不同的Stage也可能依赖同一个RDD。12345678910111213141516171819202122232425private def submitStage(stage: Stage) &#123; // 找到这个stage所属的job val jobId = activeJobForStage(stage) if (jobId.isDefined) &#123; logDebug("submitStage(" + stage + ")") if (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123; // 如果依赖之前的Stage，先列出来，并且按照id排序 val missing = getMissingParentStages(stage).sortBy(_.id) logDebug("missing: " + missing) if (missing.isEmpty) &#123; // 运行这个Stage logInfo("Submitting " + stage + " (" + stage.rdd + "), which has no missing parents") submitMissingTasks(stage, jobId.get) &#125; else &#123; // 先提交所有的parent stage for (parent &lt;- missing) &#123; submitStage(parent) &#125; waitingStages += stage &#125; &#125; &#125; else &#123; abortStage(stage, "No active job for stage " + stage.id, None) &#125;&#125; 下面具体查看getMissingParentStages这个函数，可以看到，Stage的计算链是以最后一个RDD为树根逆着向上遍历得到的，而这个链条的终点要么是一个ShuffleDependency，要么是一个所有分区都被缓存了的RDD。123456789101112131415161718192021222324252627282930313233343536private def getMissingParentStages(stage: Stage): List[Stage] = &#123; val missing = new HashSet[Stage] val visited = new HashSet[RDD[_]] val waitingForVisit = new ListBuffer[RDD[_]] // 这里是个**DFS**，栈是手动维护的，主要是为了防止爆栈 waitingForVisit += stage.rdd def visit(rdd: RDD[_]): Unit = &#123; if (!visited(rdd)) &#123; visited += rdd val rddHasUncachedPartitions = getCacheLocs(rdd).contains(Nil) if (rddHasUncachedPartitions) &#123; // 如果这个RDD有没有被缓存的Partition，那么它就需要被计算 for (dep &lt;- rdd.dependencies) &#123; // 我们检查这个RDD的所有依赖 dep match &#123; case shufDep: ShuffleDependency[_, _, _] =&gt; // 我们发现一个宽依赖，因此我们创建一个新的Shuffle Stage，并加入到missing中（如果不存在） // 由于是宽依赖，所以我们不需要向上找了 val mapStage = getOrCreateShuffleMapStage(shufDep, stage.firstJobId) if (!mapStage.isAvailable) &#123; missing += mapStage &#125; case narrowDep: NarrowDependency[_] =&gt; // 如果是一个窄依赖，就加入到waitingForVisit中 // prepend是在头部加，+=是在尾部加 waitingForVisit.prepend(narrowDep.rdd) &#125; &#125; &#125; &#125; &#125; while (waitingForVisit.nonEmpty) &#123; visit(waitingForVisit.remove(0)) &#125; missing.toList&#125; Task阶段下面是重头戏submitMissingTasks，这个方法负责生成TaskSet，并且将它提交给TaskScheduler低层调度器。partitionsToCompute计算有哪些分区是待计算的。根据Stage类型的不同，findMissingPartitions的计算方法也不同。1234567891011121314151617181920212223242526272829303132// DAGScheduler.scalaprivate def submitMissingTasks(stage: Stage, jobId: Int) &#123; logDebug("submitMissingTasks(" + stage + ")") // First figure out the indexes of partition ids to compute. val partitionsToCompute: Seq[Int] = stage.findMissingPartitions() ...// ResultStage.scalaoverride def findMissingPartitions(): Seq[Int] = &#123; val job = activeJob.get (0 until job.numPartitions).filter(id =&gt; !job.finished(id))&#125;// ActiveJob.scalaval numPartitions = finalStage match &#123; // 对于ResultStage，不一定得到当前rdd的所有分区，例如first()和lookup()的Action， // 因此这里是r.partitions而不是r.rdd.partitions case r: ResultStage =&gt; r.partitions.length case m: ShuffleMapStage =&gt; m.rdd.partitions.length&#125;// ShuffleMapStage.scalaoverride def findMissingPartitions(): Seq[Int] = &#123; mapOutputTrackerMaster .findMissingPartitions(shuffleDep.shuffleId) .getOrElse(0 until numPartitions)&#125;// MapOutputTrackerMaster.scaladef findMissingPartitions(shuffleId: Int): Option[Seq[Int]] = &#123; shuffleStatuses.get(shuffleId).map(_.findMissingPartitions())&#125; 这个outputCommitCoordinator是由SparkEnv维护的OutputCommitCoordinator对象，它决定到底谁有权利向HDFS写数据。在Executor上的请求会通过他持有的Driver的OutputCommitCoordinatorEndpoint的引用发送给Driver处理123456789101112131415161718// DAGScheduler.scala ... // Use the scheduling pool, job group, description, etc. from an ActiveJob associated // with this Stage val properties = jobIdToActiveJob(jobId).properties runningStages += stage // 在检测Tasks是否serializable之前，就要SparkListenerStageSubmitted， // 如果不能serializable，那就在这**之后**给一个SparkListenerStageCompleted stage match &#123; case s: ShuffleMapStage =&gt; outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - 1) case s: ResultStage =&gt; outputCommitCoordinator.stageStart( stage = s.id, maxPartitionId = s.rdd.partitions.length - 1) &#125; ... 用getPreferredLocs计算每个分区的最佳计算位置，它实际上是调用getPreferredLocsInternal这个函数。这个函数是一个关于visit: HashSet[(RDD[_], Int)]的递归函数，visit用(rdd, partition)元组唯一描述一个分区。getPreferredLocs的计算逻辑是这样的： 如果已经visit过了，就返回Nil 如果是被cached的，通过getCacheLocs返回cache的位置 如果RDD有自己的偏好位置，例如输入RDD，那么使用rdd.preferredLocations返回它的偏好位置 如果还没返回，但RDD有窄依赖，那么遍历它的所有依赖项，返回第一个具有位置偏好的依赖项的值 理论上，一个最优的位置选取应该尽可能靠近数据源以减少网络传输，但目前版本的Spark还没有实现12345678910111213141516171819202122// DAGScheduler.scala ... val taskIdToLocations: Map[Int, Seq[TaskLocation]] = try &#123; stage match &#123; case s: ShuffleMapStage =&gt; partitionsToCompute.map &#123; id =&gt; (id, getPreferredLocs(stage.rdd, id))&#125;.toMap case s: ResultStage =&gt; partitionsToCompute.map &#123; id =&gt; val p = s.partitions(id) (id, getPreferredLocs(stage.rdd, p)) &#125;.toMap &#125; &#125; catch &#123; case NonFatal(e) =&gt; // 如果有非致命异常就创建一个新的Attempt，并且abortStage（这还不致命么） stage.makeNewStageAttempt(partitionsToCompute.size) listenerBus.post(SparkListenerStageSubmitted(stage.latestInfo, properties)) abortStage(stage, s"Task creation failed: $e\n$&#123;Utils.exceptionString(e)&#125;", Some(e)) runningStages -= stage return &#125; ... 下面，我们开始attempt这个Stage，我们需要将RDD对象和依赖通过closureSerializer序列化成taskBinaryBytes，然后广播得到taskBinary。当广播变量过大时，会产生一条Broadcasting large task binary with size的INFO。12345678910111213141516171819202122232425262728293031323334353637383940// DAGScheduler.scala ... stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq) // 如果没有Task要执行，实际上就是skip了，那么就没有Submission Time这个字段 if (partitionsToCompute.nonEmpty) &#123; stage.latestInfo.submissionTime = Some(clock.getTimeMillis()) &#125; listenerBus.post(SparkListenerStageSubmitted(stage.latestInfo, properties)) // TODO: 也许可以将`taskBinary`放到Stage里面以避免对它序列化多次。 // 一堆注释看不懂 var taskBinary: Broadcast[Array[Byte]] = null var partitions: Array[Partition] = null try &#123; var taskBinaryBytes: Array[Byte] = null // taskBinaryBytes and partitions are both effected by the checkpoint status. We need // this synchronization in case another concurrent job is checkpointing this RDD, so we get a // consistent view of both variables. RDDCheckpointData.synchronized &#123; taskBinaryBytes = stage match &#123; case stage: ShuffleMapStage =&gt; JavaUtils.bufferToArray(closureSerializer.serialize((stage.rdd, stage.shuffleDep): AnyRef)) case stage: ResultStage =&gt; // 注意这里的stage.func已经被ClosureCleaner清理过了 JavaUtils.bufferToArray(closureSerializer.serialize((stage.rdd, stage.func): AnyRef)) &#125; partitions = stage.rdd.partitions &#125; ... // 广播 taskBinary = sc.broadcast(taskBinaryBytes) &#125; catch &#123; // In the case of a failure during serialization, abort the stage. case e: NotSerializableException =&gt; abortStage(stage, "Task not serializable: " + e.toString, Some(e)) runningStages -= stage ... &#125; 下面，我们根据Stage的类型生成Task。123456789101112131415161718192021222324252627282930// DAGScheduler.scala ... val tasks: Seq[Task[_]] = try &#123; val serializedTaskMetrics = closureSerializer.serialize(stage.latestInfo.taskMetrics).array() stage match &#123; case stage: ShuffleMapStage =&gt; stage.pendingPartitions.clear() partitionsToCompute.map &#123; id =&gt; val locs = taskIdToLocations(id) val part = partitions(id) stage.pendingPartitions += id new ShuffleMapTask(stage.id, stage.latestInfo.attemptNumber, taskBinary, part, locs, properties, serializedTaskMetrics, Option(jobId), Option(sc.applicationId), sc.applicationAttemptId, stage.rdd.isBarrier()) &#125; case stage: ResultStage =&gt; partitionsToCompute.map &#123; id =&gt; val p: Int = stage.partitions(id) val part = partitions(p) val locs = taskIdToLocations(id) new ResultTask(stage.id, stage.latestInfo.attemptNumber, taskBinary, part, locs, id, properties, serializedTaskMetrics, Option(jobId), Option(sc.applicationId), sc.applicationAttemptId, stage.rdd.isBarrier()) &#125; &#125; &#125; catch &#123; ... &#125; 我们将生成的tasks包装成一个TaskSet，并且提交给taskScheduler。12345678// DAGScheduler.scala ... if (tasks.nonEmpty) &#123; logInfo(s"Submitting $&#123;tasks.size&#125; missing tasks from $stage ($&#123;stage.rdd&#125;) (first 15 " + s"tasks are for partitions $&#123;tasks.take(15).map(_.partitionId)&#125;)") taskScheduler.submitTasks(new TaskSet( tasks.toArray, stage.id, stage.latestInfo.attemptNumber, jobId, properties)) &#125; else &#123; 如果tasks是空的，说明任务就已经完成了，打上DEBUG日志，并且调用submitWaitingChildStages1234567891011121314151617 // Because we posted SparkListenerStageSubmitted earlier, we should mark // the stage as completed here in case there are no tasks to run markStageAsFinished(stage, None) stage match &#123; case stage: ShuffleMapStage =&gt; logDebug(s"Stage $&#123;stage&#125; is actually done; " + s"(available: $&#123;stage.isAvailable&#125;," + s"available outputs: $&#123;stage.numAvailableOutputs&#125;," + s"partitions: $&#123;stage.numPartitions&#125;)") markMapStageJobsAsFinished(stage) case stage : ResultStage =&gt; logDebug(s"Stage $&#123;stage&#125; is actually done; (partitions: $&#123;stage.numPartitions&#125;)") &#125; submitWaitingChildStages(stage) &#125;&#125; ShuffleShuffle机制是Spark Core的核心内容。在Stage和Stage之间，Spark需要Shuffle数据。这个流程包含上一个Stage上的Shuffle Write，中间的数据传输，以及下一个Stage的Shuffle Read。如下图所示 Shuffle类操作常常发生在宽依赖的RDD之间，这类算子需要将多个节点上的数据拉取到同一节点上进行计算，其中存在大量磁盘IO、序列化和网络传输开销，它们可以分为以下几点来讨论。当Spark中的某个节点故障之后，常常需要重算RDD中的某几个分区。对于窄依赖而言，父RDD的一个分区只对应一个子RDD分区，因此丢失子RDD的分区，重算整个父RDD分区是必要的。而对于宽依赖而言，父RDD会被多个子RDD使用，而可能当前丢失的子RDD只使用了父RDD中的某几个分区的数据，而我们仍然要重新计算整个父RDD，这造成了计算资源的浪费。当使用Aggregate类（如groupByKey）或者Join类这种Shuffle算子时，如果选择的key上的数据是倾斜(skew)的，会导致部分节点上的负载增大。对于这种情况除了可以增加Executor的内存，还可以重新选择分区函数（例如在之前的key上加盐）来平衡分区。Shuffle Read操作容易产生OOM，其原因是尽管在BlockStoreShuffleReader中会产生外部排序的resultIter，但在这之前，ExternalAppendOnlyMap先要从BlockManager拉取数据(k, v)到自己的currentMap中，如果这里的v很大，那么就会导致Executor的OOM问题。可以从PairRDDFunctions的文档中佐证这一点。在Dataset中并没有reduceByKey，原因可能与Catalyst Optimizer的优化有关，但考虑到groupByKey还是比较坑的，感觉这个举措并不明智。 Map side combineMap side combine指的是将聚合操作下推到每个计算节点，在这些节点上预先聚合(Aggregate)，将预聚合的结果拉到Driver上进行最终的聚合。这有点类似于Hadoop的Combine操作，目的是为了减少通信，以及为了通信产生的序列化反序列化开销。 Map side combine可以体现在一些新的算子的替换，例如groupByKey -&gt; reduceByKey。 Shuffle考古在Spark0.8版本前，Spark只有Hash Based Shuffle的机制。在这种方式下，假定Shuffle Write阶段（有的也叫Map阶段）有W个Task，在Shuffle Read阶段（有的也叫Reduce阶段）有R个Task，那么就会产生W*R个文件，分别表示从W中某个Task传递到R中的某个Task。这样的坏处是对文件系统产生很大压力，并且IO也差（随机读写）。由于这些文件是先全量在内存里面构造，再dump到磁盘上，所以Shuffle在Write阶段就很可能OOM。 为了解决这个问题，在Spark 0.8.1版本加入了File Consolidation，以求将W个Task的输出尽可能合并。现在，Executor上的每一个执行单位都生成自己独一份的文件。假定所有的Executor总共有C个核心，每个Task占用T个核心，那么总共有C/T个执行单位。考虑极端情况，如果C==T，那么任务实际上是串行的，所以写一个文件就行了。因此，最终会生成C/T*R个文件。 但这个版本仍然没有解决OOM的问题。虽然对于reduce这类操作，比如count，因为是来一个combine一个，所以只要你的V不是数组，一般都没有较大的内存问题。但有的时候我们可能会强行把结果concat成一个数组。考虑执行groupByKey这样的操作，在Read阶段，每个Task需要得到得到自己负责的key对应的所有value，而Shuffle Write产生的是若干很大的文件，里面的key是杂乱无章的。如果我们需要得到一个key对应的所有value，那么我们就需要遍历这个文件，将key和对应的value全部存放在一个结构比如HashMap中，并进行合并。因此，我们必须保证这个HashMap足够大。既然如此，我们很容易想到一个基于外部排序的方案，我们为什么不能对key进行外排呢？确实在Hadoop MapReduce中会做归并排序，因此Reducer侧的数据按照key组织好的了。但Spark在下一个版本才这么做。 在Spark 0.9版本之后，引入了ExternalAppendOnlyMap，通过这个结构，SparkShuffle在combine的时候如果内存不够，就能Spill到磁盘，并在Spill的时候进行排序。当然，内存还是要能承载一个KV的，我们将在稍后的源码分析中深入研究这个问题。 终于在Spark1.1版本之后引入了Sorted Based Shuffle。此时，Shuffle Write阶段会按照Partition ID以及key对记录进行排序。同时将全部结果写到一个数据文件中，同时生成一个索引文件，Shuffle Read的Task可以通过该索引文件获取相关的数据。 在Spark 1.5，Tungsten内存管理机制成为了Spark的默认选项。如果关闭spark.sql.tungsten.enabled，Spark将采用基于Kryo序列化的列式存储格式。 常见对象关系简介 ShuffleManager/SortShuffleManagerShuffleManager是一个Trait，它的两个实现就是org.apache.spark.shuffle.hash.HashShuffleManager和org.apache.spark.shuffle.sort.SortShuffleManager。 如果partition的数量小于spark.shuffle.sort.bypassMergeThreshold，并且我们不需要做map side combine，那么就使用BypassMergeSortShuffleHandle。输出numPartitions个文件，并且在最后merge起来。这么做可以避免普通流程中对Spill的文件进行序列化和反序列化的过程。不好的是需要同时打开多个文件，并且导致很多内存分配。 如果可以进行序列化，就使用SerializedShuffleHandle。 否则就使用BaseShuffleHandle。 12345678910111213141516171819202122private[spark] class SortShuffleManager(conf: SparkConf) extends ShuffleManager with Logging &#123;... /** * Obtains a [[ShuffleHandle]] to pass to tasks. */ override def registerShuffle[K, V, C]( shuffleId: Int, numMaps: Int, dependency: ShuffleDependency[K, V, C]): ShuffleHandle = &#123; if (SortShuffleWriter.shouldBypassMergeSort(conf, dependency)) &#123; new BypassMergeSortShuffleHandle[K, V]( shuffleId, numMaps, dependency.asInstanceOf[ShuffleDependency[K, V, V]]) &#125; else if (SortShuffleManager.canUseSerializedShuffle(dependency)) &#123; // Otherwise, try to buffer map outputs in a serialized form, since this is more efficient: new SerializedShuffleHandle[K, V]( shuffleId, numMaps, dependency.asInstanceOf[ShuffleDependency[K, V, V]]) &#125; else &#123; // Otherwise, buffer map outputs in a deserialized form: new BaseShuffleHandle(shuffleId, numMaps, dependency) &#125; &#125; shouldBypassMergeSort主要判断下面几点： 是否有Map Side Combine Partition的数量是否小于bypassMergeThreshold 1234567891011private[spark] object SortShuffleWriter &#123; def shouldBypassMergeSort(conf: SparkConf, dep: ShuffleDependency[_, _, _]): Boolean = &#123; // We cannot bypass sorting if we need to do map-side aggregation. if (dep.mapSideCombine) &#123; false &#125; else &#123; val bypassMergeThreshold: Int = conf.getInt("spark.shuffle.sort.bypassMergeThreshold", 200) dep.partitioner.numPartitions &lt;= bypassMergeThreshold &#125; &#125;&#125; canUseSerializedShuffle主要判断下面几点： 是否支持序列化文件 是否允许Map-side Combine 1234567891011121314151617181920212223242526272829303132333435private[spark] object SortShuffleManager extends Logging &#123; /** * The maximum number of shuffle output partitions that SortShuffleManager supports when * buffering map outputs in a serialized form. This is an extreme defensive programming measure, * since it's extremely unlikely that a single shuffle produces over 16 million output partitions. * */ val MAX_SHUFFLE_OUTPUT_PARTITIONS_FOR_SERIALIZED_MODE = PackedRecordPointer.MAXIMUM_PARTITION_ID + 1 /** * Helper method for determining whether a shuffle should use an optimized serialized shuffle * path or whether it should fall back to the original path that operates on deserialized objects. */ def canUseSerializedShuffle(dependency: ShuffleDependency[_, _, _]): Boolean = &#123; val shufId = dependency.shuffleId val numPartitions = dependency.partitioner.numPartitions if (!dependency.serializer.supportsRelocationOfSerializedObjects) &#123; log.debug(s"Can't use serialized shuffle for shuffle $shufId because the serializer, " + s"$&#123;dependency.serializer.getClass.getName&#125;, does not support object relocation") false &#125; else if (dependency.mapSideCombine) &#123; log.debug(s"Can't use serialized shuffle for shuffle $shufId because we need to do " + s"map-side aggregation") false &#125; else if (numPartitions &gt; MAX_SHUFFLE_OUTPUT_PARTITIONS_FOR_SERIALIZED_MODE) &#123; log.debug(s"Can't use serialized shuffle for shuffle $shufId because it has more than " + s"$MAX_SHUFFLE_OUTPUT_PARTITIONS_FOR_SERIALIZED_MODE partitions") false &#125; else &#123; log.debug(s"Can use serialized shuffle for shuffle $shufId") true &#125; &#125;&#125; Shuffle完，产生多少个分区呢？这取决于具体的Partitioner，默认是200个。如果指定了Partitioner，通常是有产生Shuffle的时候计算的。例如coalesce会产生一个包装ShuffledRDD的CoalescedRDD。1234val SHUFFLE_PARTITIONS = buildConf("spark.sql.shuffle.partitions") .doc("The default number of partitions to use when shuffling data for joins or aggregations.") .intConf .createWithDefault(200) Shuffle Read端源码分析Shuffle Read一般位于一个Stage的开始，这时候上一个Stage会给我们留下一个ShuffledRDD。在它的compute方法中会首先取出shuffleManager: ShuffleManager。12345override def compute(split: Partition, context: TaskContext): Iterator[(K, C)] = &#123; val dep = dependencies.head.asInstanceOf[ShuffleDependency[K, V, C]] val metrics = context.taskMetrics().createTempShuffleReadMetrics() SparkEnv.get.shuffleManager // 由SparkEnv维护的ShuffleManager... 接着，我们调用shuffleManager.getReader方法返回一个BlockStoreShuffleReader，它用来读取[split.index, split.index + 1)这个区间内的Shuffle数据。接着，它会调用SparkEnv.get.mapOutputTracker的getMapSizesByExecutorId方法。getMapSizesByExecutorId返回一个迭代器Iterator[(BlockManagerId, Seq[(BlockId, Long, Int)])]，表示对于某个BlockManagerId，它所存储的Shuffle Write中间结果，包括BlockId、大小和index。具体实现上，这个方法首先从传入的dep.shuffleHandle中获得当前Shuffle过程的唯一标识shuffleId，然后它会从自己维护的shuffleStatuses中找到shuffleId对应的MapStatus，它应该有endPartition-startPartition这么多个。接着，对这些MapStatus，调用convertMapStatuses获得迭代器。在compute中，实际上就只取当前split这一个Partition的Shuffle元数据。1234... .getReader(dep.shuffleHandle, split.index, split.index + 1, context, metrics) // 返回一个BlockStoreShuffleReader .read().asInstanceOf[Iterator[(K, C)]]&#125; ShuffleManager通过调用BlockStoreShuffleReader.read返回一个迭代器Iterator[(K, C)]。在BlockStoreShuffleReader.read方法中，首先得到一个ShuffleBlockFetcherIterator123456// BlockStoreShuffleReader.scalaoverride def read(): Iterator[Product2[K, C]] = &#123; val wrappedStreams = new ShuffleBlockFetcherIterator( ... ) // 返回一个ShuffleBlockFetcherIterator .toCompletionIterator // 返回一个Iterator[(BlockId, InputStream)] ShuffleBlockFetcherIterator用fetchUpToMaxBytes()和 fetchLocalBlocks()分别读取remote和local的Block。在拉取远程数据的时候，会统计bytesInFlight、reqsInFlight等信息，并使用maxBytesInFlight和maxReqsInFlight节制。同时，为了允许5个并发同时拉取数据，还会设置targetRemoteRequestSize = math.max(maxBytesInFlight / 5, 1L)去请求每次拉取数据的最大大小。通过ShuffleBlockFetcherIterator.splitLocalRemoteBytes，现在改名叫partitionBlocksByFetchMode函数，可以将blocks分为Local和Remote的。关于两个函数的具体实现，将单独讨论。1234567891011121314151617181920val serializerInstance = dep.serializer.newInstance()// Create a key/value iterator for each streamval recordIter = wrappedStreams.flatMap &#123; case (blockId, wrappedStream) =&gt; serializerInstance.deserializeStream(wrappedStream).asKeyValueIterator&#125;// Update the context task metrics for each record read.// CompletionIterator相比普通的Iterator的区别就是在结束之后会调用一个completion函数// CompletionIterator通过它伴生对象的apply方法创建，传入第二个参数即completionFunctionval metricIter = CompletionIterator[(Any, Any), Iterator[(Any, Any)]]( recordIter.map &#123; record =&gt; readMetrics.incRecordsRead(1) record &#125;, context.taskMetrics().mergeShuffleReadMetrics())// An interruptible iterator must be used here in order to support task cancellationval interruptibleIter = new InterruptibleIterator[(Any, Any)](context, metricIter)... 经过一系列转换，我们得到一个interruptibleIter。接下来，根据是否有Map Side Combine对它进行聚合。这里的dep来自于BaseShuffleHandle对象，它是一个ShuffleDependency。在前面Spark的任务调度中已经提到，ShuffleDependency就是宽依赖。1234567891011121314151617// BlockStoreShuffleReader.scala ... val aggregatedIter: Iterator[Product2[K, C]] = if (dep.aggregator.isDefined) &#123; if (dep.mapSideCombine) &#123; // We are reading values that are already combined val combinedKeyValuesIterator = interruptibleIter.asInstanceOf[Iterator[(K, C)]] dep.aggregator.get.combineCombinersByKey(combinedKeyValuesIterator, context) &#125; else &#123; // We don't know the value type, but also don't care -- the dependency *should* // have made sure its compatible w/ this aggregator, which will convert the value // type to the combined type C val keyValuesIterator = interruptibleIter.asInstanceOf[Iterator[(K, Nothing)]] dep.aggregator.get.combineValuesByKey(keyValuesIterator, context) &#125; &#125; else &#123; interruptibleIter.asInstanceOf[Iterator[Product2[K, C]]] &#125; 这里的aggregator是Aggregator[K, V, C]，这里的K、V和C与熟悉combineByKey的是一样的。需要注意的是，在combine的过程中借助了ExternalAppendOnlyMap，这是之前提到的在Spark 0.9中引入的重要特性。通过调用insertAll方法能够将interruptibleIter内部的数据添加到ExternalAppendOnlyMap中，并在之后更新MemoryBytesSpilled、DiskBytesSpilled、PeakExecutionMemory三个统计维度，这也是我们在Event Log中所看到的统计维度。12345678910111213141516171819202122232425262728293031// Aggregator.scalacase class Aggregator[K, V, C] ( createCombiner: V =&gt; C, mergeValue: (C, V) =&gt; C, mergeCombiners: (C, C) =&gt; C) &#123; def combineValuesByKey( iter: Iterator[_ &lt;: Product2[K, V]], context: TaskContext): Iterator[(K, C)] = &#123; val combiners = new ExternalAppendOnlyMap[K, V, C](createCombiner, mergeValue, mergeCombiners) combiners.insertAll(iter) updateMetrics(context, combiners) combiners.iterator &#125; def combineCombinersByKey( iter: Iterator[_ &lt;: Product2[K, C]], context: TaskContext): Iterator[(K, C)] = &#123; val combiners = new ExternalAppendOnlyMap[K, C, C](identity, mergeCombiners, mergeCombiners) // 同上 &#125; /** Update task metrics after populating the external map. */ private def updateMetrics(context: TaskContext, map: ExternalAppendOnlyMap[_, _, _]): Unit = &#123; Option(context).foreach &#123; c =&gt; c.taskMetrics().incMemoryBytesSpilled(map.memoryBytesSpilled) c.taskMetrics().incDiskBytesSpilled(map.diskBytesSpilled) c.taskMetrics().incPeakExecutionMemory(map.peakMemoryUsedBytes) &#125; &#125;&#125; 在获得Aggregate迭代器之后，最后一步，我们要进行排序，这时候就需要用到ExternalSorter这个对象。1234567891011121314151617// BlockStoreShuffleReader.scala... val resultIter = dep.keyOrdering match &#123; case Some(keyOrd: Ordering[K]) =&gt; val sorter = new ExternalSorter[K, C, C](context, ordering = Some(keyOrd), serializer = dep.serializer) sorter.insertAll(aggregatedIter) context.taskMetrics().incMemoryBytesSpilled(sorter.memoryBytesSpilled) context.taskMetrics().incDiskBytesSpilled(sorter.diskBytesSpilled) context.taskMetrics().incPeakExecutionMemory(sorter.peakMemoryUsedBytes) // Use completion callback to stop sorter if task was finished/cancelled. context.addTaskCompletionListener[Unit](_ =&gt; &#123; sorter.stop() &#125;) CompletionIterator[Product2[K, C], Iterator[Product2[K, C]]](sorter.iterator, sorter.stop()) case None =&gt; aggregatedIter &#125; Spillable从常见对象关系简介图中可以发现，其实Spillable是一个核心类，它定义了内存不够时的溢出行为。查看定义，发现它继承了MemoryConsumer。12private[spark] abstract class Spillable[C](taskMemoryManager: TaskMemoryManager) extends MemoryConsumer(taskMemoryManager) with Logging &#123; 另一点有趣的是这个C没有任何诸如上下界的约束，我以为Spark这边会至少给能Spill的容器一点约束啥的。在这里，我们先来分析一下它的几个主要方法。 maybeSpill这是Spillable的主要逻辑，负责调用其他的抽象方法。我们将在单独的章节论述SizeTracker如何估计集合大小，先看具体的Spill过程，可以梳理出shouldSpill==true的情况 elementsRead % 32 == 0 currentMemory &gt;= myMemoryThreshold，其中后者默认值为spark.shuffle.spill.initialMemoryThreshold = 5 * 1024 * 1024，随着内存的分配会不断增大。前者为当前估计的Collection的内存大小。 通过acquireMemory请求的内存不足以扩展到2 * currentMemory的大小，关于这一步骤已经在内存管理部分详细说明了，在这就不详细说了1234567891011121314151617181920// Spillable.scalaprotected def maybeSpill(collection: C, currentMemory: Long): Boolean = &#123; var shouldSpill = false if (elementsRead % 32 == 0 &amp;&amp; currentMemory &gt;= myMemoryThreshold) &#123; val amountToRequest = 2 * currentMemory - myMemoryThreshold // 调用对应MemoryConsumer的acquireMemory方法，先尝试获得内存 val granted = acquireMemory(amountToRequest) myMemoryThreshold += granted // 如果当前的Collection的内存大于myMemoryThreshold，就说明内存没有被分配足够，这时候要启动spill流程。 shouldSpill = currentMemory &gt;= myMemoryThreshold &#125; shouldSpill = shouldSpill || _elementsRead &gt; numElementsForceSpillThreshold ... // MemoryConsumer.scalapublic long acquireMemory(long size) &#123; long granted = taskMemoryManager.acquireExecutionMemory(size, this); used += granted; return granted;&#125; 下面就是真正Spill的过程了，其实就是调用可能被重载的spill函数。注意_memoryBytesSpilled就是我们在Event Log里面看到的Memory Spill的统计量，他表示在Spill之后我们能够释放多少内存 12345678910111213// Spillable.scala ... // Actually spill if (shouldSpill) &#123; _spillCount += 1 // 统计Spill的次数 logSpillage(currentMemory) spill(collection) // 这个方法有对应的重载 _elementsRead = 0 // 重置强制Spill计数器_elementsRead _memoryBytesSpilled += currentMemory releaseMemory() &#125; shouldSpill&#125; protected def spill(collection: C): Unit由子类自己实现的逻辑。 override def spill(size: Long, trigger: MemoryConsumer): Long来自MemoryConsumer的接口，会调用forceSpill。 protected def forceSpill(): Boolean这个完全由子类来实现。一个容易想到的问题是，spill和forceSpill有啥区别呢？前者嘛，肯定是被maybeSpill调用的，而后者，根据注释，是会被TaskMemoryManager调用的。当这个任务没有足够多的内存的时候，会调用override def spill(size: Long, trigger: MemoryConsumer): Long这个方法，而这个方法会调用forceSpill。 logSpillage 123456@inline private def logSpillage(size: Long) &#123; val threadId = Thread.currentThread().getId logInfo("Thread %d spilling in-memory map of %s to disk (%d time%s so far)" .format(threadId, org.apache.spark.util.Utils.bytesToString(size), _spillCount, if (_spillCount &gt; 1) "s" else ""))&#125; 其实按道理，只要用到继承了Spillalbe的类，那么就会在Spark.log里面看到相应的log字符串，但我观察了一下，并没有看到在Shuffle密集任务里面看到有过多的Spill。只有观察到UnsafeExternalSorter里面有Thread 102 spilling sort data of 1664.0 MB to disk(0 time so far) 当然，Spillable也不是一上来就Spill的，也会有个先申请内存的过程。这体现了在maybeSpill中，会先尝试调用自己MemoryConsumer基类的acquireMemory方法尝试获得足够数量的内存。12345678910111213// Initial threshold for the size of a collection before we start tracking its memory usage// For testing onlyprivate[this] val initialMemoryThreshold: Long = SparkEnv.get.conf.get(SHUFFLE_SPILL_INITIAL_MEM_THRESHOLD)// Force this collection to spill when there are this many elements in memory// For testing onlyprivate[this] val numElementsForceSpillThreshold: Int = SparkEnv.get.conf.get(SHUFFLE_SPILL_NUM_ELEMENTS_FORCE_SPILL_THRESHOLD)// Threshold for this collection's size in bytes before we start tracking its memory usage// To avoid a large number of small spills, initialize this to a value orders of magnitude &gt; 0@volatile private[this] var myMemoryThreshold = initialMemoryThreshold SizeTracker上面，我们讲解了Spillable的特点，在这一章节中，我们继续介绍Spillable过程中用到的SizeTracker的实现。我们知道非序列化对象在内存存储上是不连续的，我们需要通过遍历迭代器才能知道对象的具体大小，而这个开销是比较大的。因此，通过SizeTracker我们可以得到一个内存空间占用的估计值，从来用来判定是否需要Spill。首先在每次集合更新之后，会调用afterUpdate，当到达采样的阈值nextSampleNum之后，会takeSample。1234567// SizeTracker.scalaprotected def afterUpdate(): Unit = &#123; numUpdates += 1 if (nextSampleNum == numUpdates) &#123; takeSample() &#125;&#125; 需要注意，这里不是每一次都要takeSample一次，原因是这个计算开销还是蛮大的（主要是下面要讲的estimate方法）。我们查看定义123456789101112/** * A general interface for collections to keep track of their estimated sizes in bytes. * We sample with a slow exponential back-off using the SizeEstimator to amortize the time, * as each call to SizeEstimator is somewhat expensive (order of a few milliseconds). */private[spark] trait SizeTracker &#123; import SizeTracker._ /** * Controls the base of the exponential which governs the rate of sampling. * E.g., a value of 2 would mean we sample at 1, 2, 4, 8, ... elements. */ private val SAMPLE_GROWTH_RATE = 1.1 在开头，提到一个exponential back-off。这里的exponential back-off实际上就是每次更新后，随着numUpdates的增大，会更新nextSampleNum，导致调用的次数也会越来越不频繁。而这个nextSampleNum的值是numUpdates*SAMPLE_GROWTH_RATE，默认值是1.1。takeSample函数中第一句话就涉及多个对象，一个一个来看。1234// SizeTracker.scalaprivate def takeSample(): Unit = &#123; samples.enqueue(Sample(SizeEstimator.estimate(this), numUpdates)) ... SizeEstimator.estimate的实现类似去做一个state队列上的BFS。12345678private def estimate(obj: AnyRef, visited: IdentityHashMap[AnyRef, AnyRef]): Long = &#123; val state = new SearchState(visited) state.enqueue(obj) while (!state.isFinished) &#123; visitSingleObject(state.dequeue(), state) &#125; state.size&#125; visitSingleObject来具体做这个BFS，会特殊处理Array类型。我们不处理反射，因为反射包里面会引用到很多全局反射对象，这个对象又会应用到很多全局的大对象。同理，我们不处理ClassLoader，因为它里面会应用到整个REPL。反正ClassLoaders和Classes是所有对象共享的123456789101112131415161718192021private def visitSingleObject(obj: AnyRef, state: SearchState): Unit = &#123; val cls = obj.getClass if (cls.isArray) &#123; visitArray(obj, cls, state) &#125; else if (cls.getName.startsWith("scala.reflect")) &#123; &#125; else if (obj.isInstanceOf[ClassLoader] || obj.isInstanceOf[Class[_]]) &#123; // Hadoop JobConfs created in the interpreter have a ClassLoader. &#125; else &#123; obj match &#123; case s: KnownSizeEstimation =&gt; state.size += s.estimatedSize case _ =&gt; val classInfo = getClassInfo(cls) state.size += alignSize(classInfo.shellSize) for (field &lt;- classInfo.pointerFields) &#123; state.enqueue(field.get(obj)) &#125; &#125; &#125;&#125; 然后我们创建一个Sample，并且放到队列samples中123private object SizeTracker &#123; case class Sample(size: Long, numUpdates: Long)&#125; 下面的主要工作就是计算一个bytesPerUpdate123456789101112131415 ... // Only use the last two samples to extrapolate // 如果sample太多了，就删除掉一些 if (samples.size &gt; 2) &#123; samples.dequeue() &#125; val bytesDelta = samples.toList.reverse match &#123; case latest :: previous :: tail =&gt; (latest.size - previous.size).toDouble / (latest.numUpdates - previous.numUpdates) // If fewer than 2 samples, assume no change case _ =&gt; 0 &#125; bytesPerUpdate = math.max(0, bytesDelta) nextSampleNum = math.ceil(numUpdates * SAMPLE_GROWTH_RATE).toLong&#125; 我们统计到上次估算之后经历的update数量，并乘以bytesPerUpdate，即可得到总大小123456// SizeTracker.scaladef estimateSize(): Long = &#123; assert(samples.nonEmpty) val extrapolatedDelta = bytesPerUpdate * (numUpdates - samples.last.numUpdates) (samples.last.size + extrapolatedDelta).toLong&#125; AppendOnlyMap赋值下面的代码是AppendOnlyMap.changeValue的实现，它接受一个updateFunc用来更新一个指定K的值。updateFunc接受第一个布尔值，用来表示是不是首次出现这个key。我们需要注意，AppendOnlyMap里面null是一个合法的键，但同时null又作为它里面的哈希表的默认填充，因此它里面有个对null特殊处理的过程。也就是说，如果key是null，会提前将它替换为一个nullValue的值，这个key不会存放到哈希表data里面。这里介绍一下null.asInstanceOf[V]的花里胡哨的语法，123456789101112131415161718192021222324252627282930313233343536373839404142434445// AppendOnlyMap.scala// 这里的nullValue和haveNullValue是用来单独处理k为null的情况的，下面会详细说明private var haveNullValue = falseprivate var nullValue: V = null.asInstanceOf[V]def changeValue(key: K, updateFunc: (Boolean, V) =&gt; V): V = &#123; // updateFunc就是从insertAll传入的update assert(!destroyed, destructionMessage) val k = key.asInstanceOf[AnyRef] if (k.eq(null)) &#123; if (!haveNullValue) &#123; // 如果这时候还没有null的这个key，就新创建一个 incrementSize() &#125; nullValue = updateFunc(haveNullValue, nullValue) haveNullValue = true return nullValue &#125; var pos = rehash(k.hashCode) &amp; mask var i = 1 while (true) &#123; // 乘以2的原因是他按照K1 V1 K2 V2这样放的 val curKey = data(2 * pos) if (curKey.eq(null)) &#123; // 如果对应的key不存在，就新创建一个 // 这也是为什么前面要单独处理null的原因，这里的null被用来做placeholder了 // 可以看到，第一个参数传的false，第二个是花里胡哨的null val newValue = updateFunc(false, null.asInstanceOf[V]) data(2 * pos) = k data(2 * pos + 1) = newValue.asInstanceOf[AnyRef] incrementSize() return newValue &#125; else if (k.eq(curKey) || k.equals(curKey)) &#123; // 又是从Java继承下来的花里胡哨的特性 val newValue = updateFunc(true, data(2 * pos + 1).asInstanceOf[V]) data(2 * pos + 1) = newValue.asInstanceOf[AnyRef] return newValue &#125; else &#123; // 再散列 val delta = i pos = (pos + delta) &amp; mask i += 1 &#125; &#125; null.asInstanceOf[V] // Never reached but needed to keep compiler happy&#125; 下面，我们看看incrementSize的实现，这是一个很经典的以2为底的递增的内存分配。当目前元素数量达到(LOAD_FACTOR * capacity)后，就考虑扩容。12345678910111213/** Increase table size by 1, rehashing if necessary */private def incrementSize(): Unit = &#123; curSize += 1 if (curSize &gt; growThreshold) &#123; growTable() &#125;&#125;private val LOAD_FACTOR = 0.7private var capacity = nextPowerOf2(initialCapacity)private var mask = capacity - 1private var curSize = 0private var growThreshold = (LOAD_FACTOR * capacity).toInt 迭代器我们先来看看destructiveSortedIterator的实现，相比它提供的另一个iterator方法，这个方法同样返回一个Iterator，但是经过排序的。这里destructive的意思是inplace的，会改变原来的容器的状态，因此它不需要使用额外的内存。1234567891011121314151617181920212223242526272829303132333435363738394041// AppendOnlyMap.scala/*** Return an iterator of the map in sorted order. This provides a way to sort the map without* using additional memory, at the expense of destroying the validity of the map.*/def destructiveSortedIterator(keyComparator: Comparator[K]): Iterator[(K, V)] = &#123; destroyed = true var keyIndex, newIndex = 0 // 下面这个循环将哈希表里面散乱的KV对压缩到最前面 while (keyIndex &lt; capacity) &#123; if (data(2 * keyIndex) != null) &#123; data(2 * newIndex) = data(2 * keyIndex) data(2 * newIndex + 1) = data(2 * keyIndex + 1) newIndex += 1 &#125; keyIndex += 1 &#125; // 因为nullValue不会存放到哈希表data里面，所以这里除了netIndex，如果说有null的话，还要额外加上1。 assert(curSize == newIndex + (if (haveNullValue) 1 else 0)) new Sorter(new KVArraySortDataFormat[K, AnyRef]).sort(data, 0, newIndex, keyComparator) // 这是一个经典的iterator的实现，在后面我们也会看到非常类似的写法 new Iterator[(K, V)] &#123; var i = 0 var nullValueReady = haveNullValue // 如果没遍历完newIndex，或者nullValue还没遍历到，那么都有next。 def hasNext: Boolean = (i &lt; newIndex || nullValueReady) def next(): (K, V) = &#123; if (nullValueReady) &#123; // 每次都优先返回nullValue nullValueReady = false (null.asInstanceOf[K], nullValue) &#125; else &#123; val item = (data(2 * i).asInstanceOf[K], data(2 * i + 1).asInstanceOf[V]) i += 1 item &#125; &#125; &#125;&#125; ExternalAppendOnlyMap我们查看ExternalAppendOnlyMap的实现。ExternalAppendOnlyMap拥有一个currentMap管理在内存中存储的键值对们。和一个DiskMapIterator的数组spilledMaps，表示Spill到磁盘上的键值对们。12@volatile private[collection] var currentMap = new SizeTrackingAppendOnlyMap[K, C]private val spilledMaps = new ArrayBuffer[DiskMapIterator] 插入下面，我们来看insertAll这个方法，这个方法也就是将一些KV对，加入ExternalAppendOnlyMap中。这里的currentMap是一个SizeTrackingAppendOnlyMap。这个东西实际上就是一个AppendOnlyMap，不过给它加上了统计数据大小的功能，主要是借助于SizeTracker中afterUpdate和resetSamples两个方法。123456789101112131415161718192021222324252627282930313233343536// ExternalAppendOnlyMap.scaladef insertAll(entries: Iterator[Product2[K, V]]): Unit = &#123; if (currentMap == null) &#123; throw new IllegalStateException( "Cannot insert new elements into a map after calling iterator") &#125; // 我们复用update函数，从而避免每一次都创建一个新的闭包（编程环境这么恶劣的么。。。） var curEntry: Product2[K, V] = null val update: (Boolean, C) =&gt; C = (hadVal, oldVal) =&gt; &#123; if (hadVal) // 如果不是第一个V，就merge，类似于reduce的func // mergeValue: (C, V) =&gt; C, mergeValue(oldVal, curEntry._2) else // 如果是第一个V，就新建一个C，类似于return函数 // createCombiner: V =&gt; C, createCombiner(curEntry._2) &#125; while (entries.hasNext) &#123; curEntry = entries.next() // SizeTracker的特性 val estimatedSize = currentMap.estimateSize() if (estimatedSize &gt; _peakMemoryUsedBytes) &#123; _peakMemoryUsedBytes = estimatedSize &#125; if (maybeSpill(currentMap, estimatedSize)) &#123; // 如果发生了Spill，就重新创建一个currentMap currentMap = new SizeTrackingAppendOnlyMap[K, C] &#125; // key: K, updateFunc: (Boolean, C) =&gt; C currentMap.changeValue(curEntry._1, update) addElementsRead() &#125;&#125; 可以看出，在insertAll中主要做了两件事情： 遍历curEntry &lt;- entries，并通过传入的update函数进行Combine 在内部存储上，AppendOnlyMap，包括后面将看到的一些其他KV容器，都倾向于将(K, V)对放到哈希表的相邻两个位置，这样的好处应该是避免访问时再进行一次跳转。有关changeValue的实现，我们已经在AppendOnlyMap上进行了讨论。 估计currentMap的当前大小，并调用currentMap.maybeSpill向磁盘Spill。Spill相关的过程，我们已经在Spillable相关章节进行了说明 读出下面查看ExternalAppendOnlyMap.iterator这个方法，可以发现如果spilledMaps都是空的，也就是没有Spill的话，就返回内存里面currentMap的iterator，否则就返回一个ExternalIterator。对于第一种情况，会用SpillableIterator包裹一下。这个类在很多地方有定义，包括ExternalAppendOnlyMap.scala，ExternalSorter.scala里面。在当前使用的实现中，它实际上就是封装了一下Iterator，使得能够spill，转换成CompletionIterator等。我们稍后来看一下这个迭代器的实现。对于第二种情况，ExternalIterator比较有趣，将在稍后进行讨论。12345678910111213141516// ExternalAppendOnlyMap.scalaoverride def iterator: Iterator[(K, C)] = &#123; ... if (spilledMaps.isEmpty) &#123; // 如果没有发生Spill destructiveIterator(currentMap.iterator) &#125; else &#123; // 如果发生了Spill new ExternalIterator() &#125;&#125;def destructiveIterator(inMemoryIterator: Iterator[(K, C)]): Iterator[(K, C)] = &#123; readingIterator = new SpillableIterator(inMemoryIterator) readingIterator.toCompletionIterator&#125; 而currentMap.iterator实际上就是一个朴素无华的迭代器的实现。12345678910111213141516// AppendOnlyMap.scaladef nextValue(): (K, V) = &#123; if (pos == -1) &#123; // Treat position -1 as looking at the null value if (haveNullValue) &#123; return (null.asInstanceOf[K], nullValue) &#125; pos += 1 &#125; while (pos &lt; capacity) &#123; if (!data(2 * pos).eq(null)) &#123; return (data(2 * pos).asInstanceOf[K], data(2 * pos + 1).asInstanceOf[V]) &#125; pos += 1 &#125; null&#125; Spill细节和SpillableIterator的实现而Spill实际上是走的spillMemoryIteratorToDisk函数 ExternalIterator下面我们来看ExternalAppendOnlyMap中ExternalIterator的实现。它是一个典型的外部排序的实现，有一个PQ用来merge。不过这次的迭代器换成了destructiveSortedIterator，sorted的意思就是我们都是排序的了。这个道理也是显而易见的，不sort一下，我们怎么和硬盘上的数据做聚合呢？123456789101112131415// ExternalAppendOnlyMap.scalaval mergeHeap = new mutable.PriorityQueue[StreamBuffer]val sortedMap = destructiveIterator(currentMap.destructiveSortedIterator(keyComparator))// 我们得到一个Array的迭代器val inputStreams = (Seq(sortedMap) ++ spilledMaps).map(it =&gt; it.buffered)inputStreams.foreach &#123; it =&gt; val kcPairs = new ArrayBuffer[(K, C)] // 读完所有具有所有相同hash(key)的序列，并创建一个StreamBuffer // 需要注意的是，由于哈希碰撞的原因，里面可能有多个key readNextHashCode(it, kcPairs) if (kcPairs.length &gt; 0) &#123; mergeHeap.enqueue(new StreamBuffer(it, kcPairs)) &#125;&#125; destructiveSortedIterator的实现已经在AppendOnlyMap中进行了介绍。下面我们来看看实现的ExternalAppendOnlyMap.next()接口函数，它是外部排序中的一个典型的归并过程。我们需要注意的是minBuffer是一个StreamBuffer，维护一个hash(K), V的ArrayBuffer，类似H1 V1 H1 V2 H2 V3这样的序列，而不是我们想的(K, V)流。因此其中是可能有哈希碰撞的。我们从mergeHeap中dequeue出来的StreamBuffer是当前hash(K)最小的所有K的集合。1234567891011121314151617181920212223242526272829303132333435363738394041// ExternalAppendOnlyMap.scalaoverride def next(): (K, C) = &#123; if (mergeHeap.isEmpty) &#123; // 如果堆是空的，就再见了 throw new NoSuchElementException &#125; // Select a key from the StreamBuffer that holds the lowest key hash // mergeHeap选择所有StreamBuffer中最小hash的，作为minBuffer val minBuffer = mergeHeap.dequeue() // minPairs是一个ArrayBuffer[T]，表示这个StreamBuffer维护的所有KV对 val minPairs = minBuffer.pairs val minHash = minBuffer.minKeyHash // 从一个ArrayBuffer[T]中移出Index为0的项目 val minPair = removeFromBuffer(minPairs, 0) // 得到非哈希的 (minKey, minCombiner) val minKey = minPair._1 var minCombiner = minPair._2 assert(hashKey(minPair) == minHash) // For all other streams that may have this key (i.e. have the same minimum key hash), // merge in the corresponding value (if any) from that stream val mergedBuffers = ArrayBuffer[StreamBuffer](minBuffer) while (mergeHeap.nonEmpty &amp;&amp; mergeHeap.head.minKeyHash == minHash) &#123; val newBuffer = mergeHeap.dequeue() // 如果newBuffer的key和minKey相等的话（考虑哈希碰撞），就合并 minCombiner = mergeIfKeyExists(minKey, minCombiner, newBuffer) mergedBuffers += newBuffer &#125; // Repopulate each visited stream buffer and add it back to the queue if it is non-empty mergedBuffers.foreach &#123; buffer =&gt; if (buffer.isEmpty) &#123; readNextHashCode(buffer.iterator, buffer.pairs) &#125; if (!buffer.isEmpty) &#123; mergeHeap.enqueue(buffer) &#125; &#125; (minKey, minCombiner)&#125; ExternalSorterExternalSorter的作用是对输入的(K, V)进行排序，以产生新的(K, C)对，排序过程中可选择进行combine，否则输出的C == V。需要注意的是ExternalSorter不仅被用在Shuffle Read端，也被用在了Shuffle Write端，所以在后面会提到Map-side combine的概念。ExternalSorter具有如下的参数，在给定ordering之后，ExternalSorter就会按照它来排序。在Spark源码中建议如果希望进行Map-side combining的话，就指定ordering，否则就可以设置ordering为null1234567private[spark] class ExternalSorter[K, V, C]( context: TaskContext, aggregator: Option[Aggregator[K, V, C]] = None, partitioner: Option[Partitioner] = None, ordering: Option[Ordering[K]] = None, serializer: Serializer = SparkEnv.get.serializer) extends Spillable[WritablePartitionedPairCollection[K, C]](context.taskMemoryManager()) 由于ExternalSorter支持有combine和没有combine的两种模式，因此对应设置了两个对象。map = new PartitionedAppendOnlyMap[K, C]，以及buffer = new PartitionedPairBuffer[K, C]。其中，PartitionedAppendOnlyMap就是一个SizeTrackingAppendOnlyMap，支持按key进行combine。PartitionedPairBuffer则继承了WritablePartitionedPairCollection，由于不需要按照key进行combine，所以它的实现接近于一个Array。 相比之前的aggregator，ExternalSorter不仅能aggregate，还能sort。ExternalSorter在Shuffle Read和Write都有使用，而ExternalAppendOnlyMap只有在Shuffle Read中使用。所以为啥不直接搞一个ExternalSorter而是还要在前面垫一个ExternalAppendOnlyMap呢？为此，我们总结比较一下这两者：首先，在insertAll时，ExternalAppendOnlyMap是一定要做combine的，而ExternalSorter可以选择是否做combine，为此还有PartitionedAppendOnlyMap和PartitionedPairBuffer两种数据结构。其次，在做排序时，ExternalAppendOnlyMap默认对内存中的对象不进行排序，只有当要Spill的时候才会返回AppendOnlyMap.destructiveSortedIterator的方式将内存里面的东西有序写入磁盘。在返回迭代器时，如果没有发生Spill，那么ExternalAppendOnlyMap返回没有经过排序的currentMap，否则才通过ExternalIterator进行排序。而对ExternalSorter而言排序与否在于有没有指定ordering。如果进行排序的话，那么它会首先考虑Partition，再考虑Key。 插入ExternalSorter.insertAll方法和之前看到的ExternalAppendOnlyMap方法是大差不差的，他也会对可以聚合的特征进行聚合，并且TODO上还说如果聚合之后的reduction factor不够明显，就停止聚合。根据是否定义了aggregator，会分别采用之前提到的map和buffer来承载加入的数据。1234567891011121314151617181920212223242526272829// ExternalSorter.scaladef insertAll(records: Iterator[Product2[K, V]]): Unit = &#123; // TODO: stop combining if we find that the reduction factor isn't high val shouldCombine = aggregator.isDefined if (shouldCombine) &#123; // Combine values in-memory first using our AppendOnlyMap val mergeValue = aggregator.get.mergeValue val createCombiner = aggregator.get.createCombiner var kv: Product2[K, V] = null val update = (hadValue: Boolean, oldValue: C) =&gt; &#123; if (hadValue) mergeValue(oldValue, kv._2) else createCombiner(kv._2) &#125; while (records.hasNext) &#123; addElementsRead() kv = records.next() map.changeValue((getPartition(kv._1), kv._1), update) maybeSpillCollection(usingMap = true) &#125; &#125; else &#123; // Stick values into our buffer while (records.hasNext) &#123; addElementsRead() val kv = records.next() buffer.insert(getPartition(kv._1), kv._1, kv._2.asInstanceOf[C]) maybeSpillCollection(usingMap = false) &#125; &#125;&#125; 容易看出，这里面用到maybeSpillCollection来尝试管理内存，这个应该是和spill相关的，我们检查一下其实现，发现其实就是一个代理，对于是否使用map的情况，进行了分类讨论。而maybeSpill就是Spillable里面的定义了。123456789101112131415161718private def maybeSpillCollection(usingMap: Boolean): Unit = &#123; var estimatedSize = 0L if (usingMap) &#123; estimatedSize = map.estimateSize() if (maybeSpill(map, estimatedSize)) &#123; map = new PartitionedAppendOnlyMap[K, C] &#125; &#125; else &#123; estimatedSize = buffer.estimateSize() if (maybeSpill(buffer, estimatedSize)) &#123; buffer = new PartitionedPairBuffer[K, C] &#125; &#125; if (estimatedSize &gt; _peakMemoryUsedBytes) &#123; _peakMemoryUsedBytes = estimatedSize &#125;&#125; Shuffle Write端源码分析Shuffle Write端的实现主要依赖ShuffleManager中的ShuffleWriter对象，目前使用的ShuffleManager是SortShuffleManager，因此只讨论它。它是一个抽象类，主要有SortShuffleWriter、UnsafeShuffleWriter、BypassMergeSortShuffleWriter等实现。 SortShuffleWriter12345678private[spark] abstract class ShuffleWriter[K, V] &#123; /** Write a sequence of records to this task's output */ @throws[IOException] def write(records: Iterator[Product2[K, V]]): Unit /** Close this writer, passing along whether the map completed */ def stop(success: Boolean): Option[MapStatus]&#125; SortShuffleWriter的实现可以说很简单了，就是将records放到一个ExternalSorter里面，然后创建一个ShuffleMapOutputWriter。shuffleExecutorComponents实际上是一个LocalDiskShuffleExecutorComponents。ShuffleMapOutputWriter是一个Java接口，实际上被创建的是LocalDiskShuffleMapOutputWriter12345678910111213141516171819// SortShuffleWriteroverride def write(records: Iterator[Product2[K, V]]): Unit = &#123; sorter = if (dep.mapSideCombine) &#123; new ExternalSorter[K, V, C]( context, dep.aggregator, Some(dep.partitioner), dep.keyOrdering, dep.serializer) &#125; else &#123; // 如果不需要进行mapSideCombine，那么我们传入空的aggregator和ordering， // 我们在map端不负责对key进行排序，统统留给reduce端吧 new ExternalSorter[K, V, V]( context, aggregator = None, Some(dep.partitioner), ordering = None, dep.serializer) &#125; sorter.insertAll(records) // Don't bother including the time to open the merged output file in the shuffle write time, // because it just opens a single file, so is typically too fast to measure accurately // (see SPARK-3570). val mapOutputWriter = shuffleExecutorComponents.createMapOutputWriter( dep.shuffleId, mapId, dep.partitioner.numPartitions) ... 紧接着，调用ExternalSorter.writePartitionedMapOutput将自己维护的map或者buffer（根据是否有Map Side Aggregation）写到mapOutputWriter提供的partitionWriter里面。其过程用到了一个叫destructiveSortedWritablePartitionedIterator的迭代器，相比destructiveSortedIterator，它是多了Writable和Partitioned两个词。前者的意思是我可以写到文件，后者的意思是我先按照partitionId排序，然后在按照给定的Comparator排序。接着就是commitAllPartitions，这个函数调用writeIndexFileAndCommit。1234// ... sorter.writePartitionedMapOutput(dep.shuffleId, mapId, mapOutputWriter) val partitionLengths = mapOutputWriter.commitAllPartitions() MapStatus被用来保存Shuffle Write操作的metadata。12345678910111213... mapStatus = MapStatus(blockManager.shuffleServerId, partitionLengths, mapId)&#125;// LocalDiskShuffleMapOutputWriter.java@Overridepublic long[] commitAllPartitions() throws IOException &#123; ... cleanUp(); File resolvedTmp = outputTempFile != null &amp;&amp; outputTempFile.isFile() ? outputTempFile : null; blockResolver.writeIndexFileAndCommit(shuffleId, mapId, partitionLengths, resolvedTmp); return partitionLengths;&#125; writeIndexFileAndCommit负责为传入的文件dataTmp创建一个索引文件，并原子地提交。注意到，到当前版本，每一个执行单元只会生成一份数据文件和一份索引。12// IndexShuffleBlockResolver.javadef writeIndexFileAndCommit(shuffleId: Int, mapId: Long, lengths: Array[Long], dataTmp: File): Unit 根据writeIndexFileAndCommit的注释，getBlockData会来读它写的块，这个getBlockData同样位于我们先前介绍过的IndexShuffleBlockResolver类中。 BypassMergeSortShuffleWriter下面我们来看看BypassMergeSortShuffleWriter的实现。它到底Bypass了什么东西呢？其实是sort和aggregate。 UnsafeShuffleWriterSortShuffleManager还有一个子类是UnsafeShuffleWriter。UnsafeShuffleWriter使用ShuffleExternalSorter进行排序，而SortShuffleWriter使用ExternalSorter对象。UnsafeShuffleWriter使用TaskMemoryManager作内存分配，而SortShuffleWriter没有明确指定。 fetchLocalBlocks和fetchUpToMaxBytes的实现简单说明一下fetchLocalBlocks和fetchUpToMaxBytes的实现123456789101112131415161718// ShuffleBlockFetcherIterator.scalaprivate[this] val localBlocks = scala.collection.mutable.LinkedHashSet[BlockId]()private[this] def fetchLocalBlocks() &#123; logDebug(s"Start fetching local blocks: $&#123;localBlocks.mkString(", ")&#125;") val iter = localBlocks.iterator while (iter.hasNext) &#123; val blockId = iter.next() try &#123; val buf = blockManager.getBlockData(blockId) ...// BlockManager.scalaoverride def getBlockData(blockId: BlockId): ManagedBuffer = &#123; if (blockId.isShuffle) &#123; // 需要通过ShuffleBlockResolver来获取 shuffleManager.shuffleBlockResolver.getBlockData(blockId.asInstanceOf[ShuffleBlockId]) &#125; else &#123; getLocalBytes(blockId) match &#123; Spark分布式部署方式Spark自有部署方式最常用的其实是单机模式也就是spark-submit --master local，这里local是默认选项。在程序执行过程中，只会生成一个SparkSubmit进程，不会产生Master和Worker节点，也不依赖Hadoop。当然，Windows里面可能需要winutils这个工具的，但也是直接下载，而不需要装Hadoop。在集群化上，Spark可以部署在On Yarn和On Mesos、K8S和Standalone上面，而又分别对应了Cluster和Client两种deploy mode。 首先是Spark自带Cluster Manager的Standalone Client模式，也是我们最常用的集群测试模式，需要启动Master和Slave节点，但仍然不依赖Hadoop。1./bin/spark-submit --master spark://localhost:7077 --class org.apache.spark.examples.SparkPi ./examples/jars/spark-examples_2.11-2.4.4.jar 100 下面一种是Spark自带Cluster Manager的Standalone Cluster模式，一字之差，还是有不同的，用下面的方式启动1./bin/spark-submit --master spark://wl1:6066 --deploy-mode cluster # 默认cluster 上面两种的配置一般修改Spark的spark-defaults.conf和spark-env.sh也就可以了，不涉及hadoop。此外，还有Connection Reset的情况，这个需要打开Connection Reset。 YarnSpark跑在yarn上面，这个还依赖hadoop集群，但Spark不需要自己提供Master和Worker了。Yarn同样提供了Cluster和Client两种模式，如下所示12./bin/spark-submit --master yarn-cluster./bin/spark-submit --master yarn-client Yarn Cluster就是通常使用的部署方式，此时Spark Driver是运行在Yarn的ApplicationMaster上的，而Client方式的Driver是在任务提交机上面运行，ApplicationMaster只负责向ResourceManager申请Executor需要的资源。 我们在Spark的WebUI中常常看到诸如Container、ApplicationMaster、ResourceMaster、NodeManager这些东西，其实他们都是Yarn里面的常见概念。具体的联系可以结合下面的图来看，ResourceMaster是YARN集群的Master，负责管理整个集群的资源，而NodeManager就是YARN集群的Slave，每个Node上面都会跑一个NodeManager。而每个Node上面又可以有很多个Container。对应到Spark中，一般来说一个Driver或一个Executor跑在Yarn的一个Container里面，而ApplicationMaster是一个特殊的Container，一般为后缀_00001的container。每个SparkContext对应一个ApplicationMaster，每个Executor对应一个Container。 YARN视角的架构： ResourceMaster NodeManager Container ApplicationMaster：类似于Spark Driver，对应一个SparkContext Container 普通的Spark Executor Container 普通的Spark Executor NodeManager Container Container SparkSQLSparkSQL由4个项目组成，分别为Spark Core、Spark Catalyst、Spark Hive和Spark Hive ThriftServer。我们主要和前两者打交道，Core中就是SparkSQL的核心，包括Dataset等类的实现。Catalyst是Spark的水晶优化器。 DataFrame和Dataset我们可以将RDD看为一个分布式的容器M[T]，我们对T是未知的。而事实上我们处理数据集往往就是个来自HBase或者其他数据仓库大宽表。如果使用RDD会导致很多的拆箱和装箱的操作。并且由于T是一个黑盒，Spark也很难对RDD的计算进行优化。为此，Spark推出了SparkSQL来解决这个问题。而SparkSQL的一个核心机制就是DataFrame和Dataset。 在Spark1.0中，DataFrame可以看做RDD[Row]，但在Spark2.0对Dataset和DataFrame进行了统一，DataFrame可以看做一个Dataset[Row]，所以，我们主要以Dataset来研究对象。 创建DataFrame借助于Scala提供的implicit机制，我们可以从Seq创建DataFrame12345678import org.apache.spark.sql.types.&#123;DoubleType, LongType, IntegerType, StringType, StructField, StructType&#125;import org.apache.spark.sql.functions.&#123;concat, lit, udf&#125;import org.apache.spark.sql.&#123;Row&#125;import org.apache.spark.sql.catalyst.expressions.&#123;GenericRow, GenericRowWithSchema&#125;case class Person(name: String, age: Long, money: Long)import spark.implicits._val df = Seq(("Calvin", 18, 1000)).toDF("name", "age", "money") 但是，我们不能从一个DataFrame通过map到一个Row的方式得到另一个DataFrame1234val df2 = df.map(row =&gt; Row(row.getAs[String]("name")))&lt;console&gt;:32: error: Unable to find encoder for type org.apache.spark.sql.Row. An implicit Encoder[org.apache.spark.sql.Row] is needed to store org.apache.spark.sql.Row instances in a Dataset. Primitive types (Int, String, etc) and Product types (case classes) are supported by importing spark.implicits._ Support for serializing other types will be added in future releases. val df2 = df.map(row =&gt; Row(row.getAs[String]("name"))) 我们还可以通过createDataFrame从RDD创建一个DataFrame，因为RDD没有schema，所以我们要显式提供一个schema。12345val schemaString="name,age,money"val schema = StructType(schemaString.split(",").map(fieldName =&gt; StructField(fieldName, StringType, true)))val sqlcontext = new org.apache.spark.sql.SQLContext(sc)val r = sc.parallelize(Seq(Person("Calvin", 18, 1000))).map(a =&gt; Row(a.name, a.age, a._3))val df = sqlcontext.createDataFrame(r, schema) 而这个schema可以通过下面的方法得到123var schema = new StructType() .add(StructField("string1", StringType, true)) // 可能为null .add(StructField("long1", LongType)) // 不可能为null 这里的StructType和StringType等都是SparkSQL所提供的ADT，它们都继承AbstractDataType，例如LongType的继承链是LongType-&gt;IntegralType-&gt;NumericType-&gt;AtomicType-&gt;DataType-&gt;AbstractDataType。StructField是add方法的参数，用来描述一个类型。包含四个成员，如下所示1234case class StructField(String name, DataType dataType, boolean nullable, Metadata metadata) 当然，还有一些从外部数据源构造DataFrame的工具，如下所示，这里的路径是Driver本地路径12spark.read.json(...)spark.read.csv(...) 此外，Spark还可以从Hive、MySQL、HBase、Avro, Parquet, Kafka等数据源中读取数据。 从RDD到DF/DSRDD可以通过下面代码中的一个隐式转换 得到一个DatasetHolder，接着借助于DatasetHolder中提供的toDS和toDF来实现到DataFrame和Dataset的转换。123implicit def rddToDatasetHolder[T : Encoder](rdd: RDD[T]): DatasetHolder[T] = &#123; DatasetHolder(_sqlContext.createDataset(rdd))&#125; 其实在上面文件里面还定义了一系列隐式转换所需要的Encoder，例如对于大多数的case class都需要调用newProductArrayEncoder。有关这部分的进一步说明，可以查看文章 同样，从Dataset/DataFrame到RDD可以通过调用.rdd方法来轻松得到。不过这个操作是Action么？在爆栈网上有相关讨论1，认为不是Action但有开销；和相关讨论2，认为是无开销的。我们查看具体代码123456lazy val rdd: RDD[T] = &#123; val objectType = exprEnc.deserializer.dataType rddQueryExecution.toRdd.mapPartitions &#123; rows =&gt; rows.map(_.get(0, objectType).asInstanceOf[T]) &#125;&#125; 从DF到DS从DF到DS的转换需要指定一个Encoder1val ds = df.as[Person] 从DS到DF123456789101112@scala.annotation.varargsdef toDF(colNames: String*): DataFrame = &#123; require(schema.size == colNames.size, "The number of columns doesn't match.\n" + s"Old column names ($&#123;schema.size&#125;): " + schema.fields.map(_.name).mkString(", ") + "\n" + s"New column names ($&#123;colNames.size&#125;): " + colNames.mkString(", ")) val newCols = logicalPlan.output.zip(colNames).map &#123; case (oldAttribute, newName) =&gt; Column(oldAttribute).as(newName) &#125; select(newCols : _*)&#125; RowRow是SparkSQL的基石。它实际上是一个trait，我们经常使用是它的子类GenericRow和GenericRowWithSchema，而Row的内部实现则是InternalRow。GenericRow是Row从apply创建时的默认构造。它没有schema。在GenericRowWithSchema中重新实现了filedIndex这个函数，允许我们使用row.getAsString这样的方法。在上面的讨论中已经提到，我们不能从一个DataFrame通过map到一个Row的方式得到另一个DataFrame；反而可以从一个Seq得到。其原因就是因为DataFrame有schema而Row没有。我们通过下面的实验来检查从一个Seq到DataFrame`的转换1val df = Seq(("Calvin", 18, 1000)).toDF("name", "age", "money") GenericRow是Row从apply创建时的默认构造。它没有schema。在GenericRowWithSchema中重新实现了filedIndex这个函数，允许我们使用row.getAs[String](&quot;colName&quot;)这样的方法。如果经常使用SparkSQL的API会发现我们不能从一个DataFrame通过map到一个Row的方式得到另一个DataFrame；反而可以从一个Seq得到，我们甚至可以通过Seq(...).toDF(columns)方法来得到一个其原因就是因为DataFrame有schema而Row没有。我们通过下面的实验来检查从一个Seq到DataFrame的转换123456789val ds = Seq(Person("Calvin", 22, 1)).toDSval ds2 = Seq(Person("Neo", 23, 1)).toDSval dfj = ds.union(ds2)val dsj_fail = dfj.toDS // 注意DataFrame没有toDS方法，toDS是由RDD转DS用的val dsj = dfj.as[Person]val ds3 = Seq(("Calvin", 22, 1)).toDSval ds4 = Seq(("Neo", 23, 1)).toDSval dfj2 = ds3.union(ds4) 有关Row和GenericRowWithSchema之间的转换，我们可以进行下面的实验12345678910// 复用之前的头部val df = Seq(Person("Calvin", 22, 100), Person("Neo", 33, 300)).toDF// df的schemascala&gt; df.schemares2: org.apache.spark.sql.types.StructType = StructType(StructField(name,StringType,true), StructField(age,LongType,false), StructField(money,LongType,false))// 第1行的schemascala&gt; df.take(1)(0).schemares3: org.apache.spark.sql.types.StructType = StructType(StructField(name,StringType,true), StructField(age,LongType,false), StructField(money,LongType,false)) DataFrame里面的Row不是单纯的Row，而是GenericRowWithSchema，相比之前的Row，要多了Schema。123456789101112131415// 查看type，发现是GenericRowWithSchema而不是Rowscala&gt; df.take(1)(0).getClass.getSimpleNameres5: String = GenericRowWithSchema// 增加一列scala&gt; val r = Row.unapplySeq(df.take(1)(0)).get.toArray ++ Seq("SZ")r: Array[Any] = Array(Calvin, 22, 100, SZ)// 对应增加一列schemascala&gt; val nsch = df.take(1)(0).schema.add(StructField("addr",StringType,true))nsch: org.apache.spark.sql.types.StructType = StructType(StructField(name,StringType,true), StructField(age,LongType,false), StructField(money,LongType,false), StructField(addr,StringType,true))// 创建一个新SchemaRowscala&gt; val row_sch = new GenericRowWithSchema(r, nsch)row_sch: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema = [Calvin,22,100,SZ] 只有GenericRowWithSchema有，因此我们可以创建一个GenericRowWithSchema，其实现在org.apache.spark.sql.catalyst.expressions.{GenericRow, GenericRowWithSchema}。 为什么不能在map函数中返回Row熟悉map函数的人往往比较熟悉下面的函数签名1fmap :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b 因此容易写出下面的代码123df.map&#123; case Row(...) =&gt; Row(...)&#125; 乍一看，很有道理啊，f就是Dataset，a和b都是Row，是一个很准确的代码了，但一编译发现少什么Encoder，这是怎么回事呢？这篇文章给了答案。 Column从上文中可以看到，DataFrame中的数据依旧是按照行组织的，通过外挂了一个schema，我们能够有效地识别列。在这种情况下对行的改动是容易的，但是如何对列进行改动呢？一般有两种办法 借助于withColumn1234val df = Seq(Person("Calvin", 22, 100), Person("Neo", 33, 300)).toDF// 通过cast函数进行类型转换，concat函数进行字符串连接df.withColumn("name2", concat($"name", $"age".cast(StringType))).show()df.withColumn("name2", $"age"+$"money").show() 当然，在$表达式之外，我们还可以使用udf，甚至带条件地进行withColumn123// 除了$表达式，还可以使用udfval addMoneyUDF = udf((age: Long, money: Long) =&gt; age + money)df.withColumn("name2", addMoneyUDF($"age", $"money")) 特别需要注意的是withColumn是存在性能开销的。如果我们在代码里频繁（例如使用一个for循环）withColumn，那么就可能出现一个Job结束，而下一个Job迟迟不开始的情况。如果我们将日志等级设置为TRACE，可以看到代码中也存在了很多Batch Resolution的情况。这是因为较深层次的依赖会导致SparkSQL不能分清到底需要缓存哪些数据以用来恢复，因此只能全部缓存。另外文章中还表示会造成大量的Analyzes开销。1234567891011// Analyzer.scalaBatch("Resolution", fixedPoint, ResolveTableValuedFunctions :: new ResolveCatalogs(catalogManager) :: ResolveInsertInto :: ResolveRelations :: ResolveReferences ::... ResolveRandomSeed :: TypeCoercion.typeCoercionRules(conf) ++ extendedResolutionRules : _*), 此外，伴随着withColumn的是UDF或者UDAF的使用，在Spark the definitive一书中指出，这类的算子容易导致OOM等问题。该书中还指出UDF会强迫将数据转换成JVM里面的对象，并且在一次查询中可能重复转换多次，这会产生很大的性能开销。 KeyValueGroupedDataset和RelationalGroupedDataset不同于RDD的相关方法，DataFrame系列的groupBy和groupByKey会返回两个不同的类型，RelationalGroupedDataset和KeyValueGroupedDataset。一般来说，虽然groupByKey更为灵活，能够生成自定义的key用来group，但KeyValueGroupedDataset只提供相对较少的操作，所以最好还是使用groupby。另外，在group操作之后就没有诸如union的操作，我们需要再显式map回DataFrame。 SparkSQL语法和用法SparkSQL和DataFrame的交互一个简单的问题是，在SQL中引用一个DataFrame呢？一个简单的做法是创建一个视图，即通过createOrReplaceTempView。 SparkSQL的上下文SparkSQL的上下文通过SQLContext维护，它由一个SparkSession持有，并指向其所有者，以及所有者维护的SparkContext。在Spark 2.0之后，大部分SparkSQL的逻辑工作被迁移到了SparkSession中，所以这个类可以被看做是一个兼容性的封装。12345class SQLContext private[sql](val sparkSession: SparkSession) extends Logging with Serializable &#123; private[sql] def sessionState: SessionState = sparkSession.sessionState private[sql] def sharedState: SharedState = sparkSession.sharedState private[sql] def conf: SQLConf = sessionState.conf SharedStateSharedState保存不同session的共享状态，包括下面几个对象 warehousePath conf, hadoopConf cacheManager这是SQLContext 的支持类，会自动保存query的查询结果。这样子查询在执行过程中，就可以使用这些查询结果。 statusStore externalCatalog globalTempViewManager一个线程安全的类，用来管理global temp view，并提供create、update、remove等原子操作来管理这些view。 SessionStateSessionState则包含了这个Session中相关的组件1234567891011121314151617181920212223private[sql] class SessionState( sharedState: SharedState, val conf: SQLConf, val experimentalMethods: ExperimentalMethods, val functionRegistry: FunctionRegistry, val udfRegistration: UDFRegistration, catalogBuilder: () =&gt; SessionCatalog, val sqlParser: ParserInterface, // 是一个ParserInterface实现 analyzerBuilder: () =&gt; Analyzer, optimizerBuilder: () =&gt; Optimizer, val planner: SparkPlanner, val streamingQueryManager: StreamingQueryManager, val listenerManager: ExecutionListenerManager, resourceLoaderBuilder: () =&gt; SessionResourceLoader, createQueryExecution: LogicalPlan =&gt; QueryExecution, createClone: (SparkSession, SessionState) =&gt; SessionState, val columnarRules: Seq[ColumnarRule]) &#123; // The following fields are lazy to avoid creating the Hive client when creating SessionState. lazy val catalog: SessionCatalog = catalogBuilder() lazy val analyzer: Analyzer = analyzerBuilder() lazy val optimizer: Optimizer = optimizerBuilder() lazy val resourceLoader: SessionResourceLoader = resourceLoaderBuilder() 构建SparkSession时，Spark内部会构造SessionState，SessionState会构造Parser，Analyzer，Catalog，Optimizer，Planner还有逻辑计划转化为执行计划的方法。SessionState的具体构建如下所示12345678910111213141516171819202122/** * State isolated across sessions, including SQL configurations, temporary tables, registered * functions, and everything else that accepts a [[org.apache.spark.sql.internal.SQLConf]]. * If `parentSessionState` is not null, the `SessionState` will be a copy of the parent. * * This is internal to Spark and there is no guarantee on interface stability. * * @since 2.2.0 */@Unstable@transientlazy val sessionState: SessionState = &#123; parentSessionState .map(_.clone(this)) .getOrElse &#123; val state = SparkSession.instantiateSessionState( SparkSession.sessionStateClassName(sparkContext.conf), self) initialSessionOptions.foreach &#123; case (k, v) =&gt; state.conf.setConfString(k, v) &#125; state &#125;&#125; 这里的SparkSession.sessionStateClassName(sparkContext.conf)具体有两个取值，在使用Hive的时候，是org.apache.spark.sql.hive.HiveSessionStateBuilder，否则是org.apache.spark.sql.internal.SessionStateBuilder，作为in-memory。instantiateSessionState会具体构建sessionState12345678910111213private def instantiateSessionState( className: String, sparkSession: SparkSession): SessionState = &#123; try &#123; // invoke `new [Hive]SessionStateBuilder(SparkSession, Option[SessionState])` val clazz = Utils.classForName(className) val ctor = clazz.getConstructors.head ctor.newInstance(sparkSession, None).asInstanceOf[BaseSessionStateBuilder].build() &#125; catch &#123; case NonFatal(e) =&gt; throw new IllegalArgumentException(s"Error while instantiating '$className':", e) &#125;&#125; 而最终是通过一个BaseSessionStateBuilder的子类来构建的，我们以HiveSessionStateBuilder为例介绍。1234567891011121314151617181920// HiveSessionStateBuilder.scala and BaseSessionStateBuilder.scaladef build(): SessionState = &#123; new SessionState( session.sharedState, conf, experimentalMethods, functionRegistry, udfRegistration, () =&gt; catalog, sqlParser, () =&gt; analyzer, () =&gt; optimizer, planner, () =&gt; streamingQueryManager, listenerManager, () =&gt; resourceLoader, createQueryExecution, createClone, columnarRules)&#125; SparkSQL的架构总览总而言之，SparkSQL的解析与运行流程类似于一般SQL的解析与运行流程，包含： 将SQL解析得到一个逻辑计划，它是一颗AST。SparkSQL的执行目标就是树根的值，在计算过程中，父节点的计算依赖于子节点的计算结果。通过Analyzer去Resolve，通过Optimizer去优化 将逻辑计划转换为物理计划。首先需要为逻辑计划中的节点选择一个最优的物理计划（同样的逻辑计划可能对应多个物理计划），然后需要生成一个可执行的执行计划。 调用执行计划生成的RDD的action方法提交一个Job LogicPlan类逻辑计划的对应实现是Logical Plan继承了QueryPlan[LogicalPlan]。自己又拥有三个子类BinaryNode/UnaryNode和LeafNode，然后有产生了OrderPreservingUnaryNode等子类。这些Node被另一些子类所继承，这些basicLogicalOperators描述了包括Project/Filter/Sample/Union/Join/Limit等操作。 SparkPlan类物理计划的对应实现是SparkPlan，和LogicalPlan一样，他同样继承了QueryPlan[SparkPlan]。例如逻辑计划Project就可能产生一个ProjectExec的物理计划。 处理流程首先祭出一张图。 从图中可以看到，SparkSQL首先会对SQL进行Parse，得到一个Unresolved LogicalPlan。这里Unresolved的意思是诸如变量名和表名这些东西是不确定的。Catalog就是描述了SQLContext里面的诸如表之类的对象。在生产环境中，一般由 Hive Metastore提供Catalog 服务。 在Analyzer的阶段借助于Catalog来决议得到LogicalPlan，将Unresolved LogicalPlan决议为Logical Plan。 通过Optimizer，对Logical Plan进行优化。Catalyst主要做的是RBO，但诸如华为等公司和机构也有提出过CBO的方案。 逻辑计划不能被直接执行，它需要通过QueryPlanner.plan得到一系列物理计划，并选择其中一个。QueryPlanner是一个抽象类，它有可以有许多子类实现，这些子类负责将一系列strategies应用到输入的Logical Plan上，订得到一系列candidates: Seq[PhysicalPlan]123456789101112// QueryPlanner.scalaabstract class QueryPlanner[PhysicalPlan &lt;: TreeNode[PhysicalPlan]] &#123; /** A list of execution strategies that can be used by the planner */ def strategies: Seq[GenericStrategy[PhysicalPlan]] def plan(plan: LogicalPlan): Iterator[PhysicalPlan] = &#123; // Obviously a lot to do here still... // Collect physical plan candidates. val candidates = strategies.iterator.flatMap(_(plan)) ... 在得到物理计划后，会调用prepareForExecution得到一个可执行的executedPlan。1234// QueryExecution.scalaprotected def prepareForExecution(plan: SparkPlan): SparkPlan = &#123; preparations.foldLeft(plan) &#123; case (sp, rule) =&gt; rule.apply(sp) &#125;&#125; 在Spark2.0前，SparkSQL的主要是采用的Volcano查询引擎模型。Volcano是一种经典的基于行的流式迭代模型(Row-Based Streaming Iterator Model)，它在例如Oracle、SQL Server、MySQL等方面都有使用。在Volcano模型中，查询计划树由这些算子组成。这些算子可以看做迭代器，每一次的next()调用，会返回一行(Row)。这next()调用实际上作用在下层算子上，它们把这个下层的输出看做一个表。Volcano具有一些性能方面的缺点，例如next()调用深度可能很深，而每次调用都是虚的，所以有很大的查阅虚表的开销，这给编译器做inline，或者CPU做分支预测都带来了困难。此外，Volcano有很好的pipeline性能，能节约内存，但每获得一次数据，都需要最顶层驱动一次，这雪上加霜。因此在Spark2.0之后加入了WholeStageCodegen机制和ExpressionCodegen机制。 SparkSQL的解析流程SparkSQL API的执行流程和RDD一样，Dataset同样只在Action操作才会计算。假设现在已经生成了物理计划，我们选取最典型的count()来研究，以查看物理计划是如何执行的。可以看到，count操作实际上会执行plan.executeCollect()，而这里的plan是一个SparkPlan，qe是一个QueryExecution。1234567891011121314151617// Dataset.scaladef count(): Long = withAction("count", groupBy().count().queryExecution) &#123; plan =&gt; plan.executeCollect().head.getLong(0)&#125;private def withAction[U](name: String, qe: QueryExecution)(action: SparkPlan =&gt; U) = &#123; SQLExecution.withNewExecutionId(sparkSession, qe, Some(name)) &#123; qe.executedPlan.foreach &#123; plan =&gt; plan.resetMetrics() &#125; action(qe.executedPlan) &#125;&#125;private def withNewExecutionId[U](body: =&gt; U): U = &#123; SQLExecution.withNewExecutionId(sparkSession, queryExecution)(body)&#125; QueryExecution用来描述整个SQL执行的上下文，从如下示例中可以看出，它维护了从Unsolved Logical Plan到Physical Plan的整个转换流程。1234567891011121314151617181920scala&gt; val ds = Seq(Person("Calvin", 22, 1)).toDSds: org.apache.spark.sql.Dataset[Person] = [name: string, age: bigint ... 1 more field]scala&gt; val fds = ds.filter(p =&gt; p.age&gt;1)fds: org.apache.spark.sql.Dataset[Person] = [name: string, age: bigint ... 1 more field]scala&gt; ds.queryExecutionres9: org.apache.spark.sql.execution.QueryExecution === Parsed Logical Plan ==LocalRelation [name#3, age#4L, money#5L]== Analyzed Logical Plan ==name: string, age: bigint, money: bigintLocalRelation [name#3, age#4L, money#5L]== Optimized Logical Plan ==LocalRelation [name#3, age#4L, money#5L]== Physical Plan ==LocalTableScan [name#3, age#4L, money#5L] 那么，count()做的就是对qe做一些手脚，然后调用qe.executedPlan.executeCollect().head.getLong(0)。于是我们查看executeCollect()这个方法，他实际上就是execute和collect两部分。execute部分实际上是对getByteArrayRdd的一个调用，得到一个RDD。而collect部分就是调用byteArrayRdd.collect()，这个操作会触发RDD的Action操作，从而提交一个Job。整个函数最终返回一个ArrayBuffer[InternalRow]。12345678910111213// SparkPlan.scaladef executeCollect(): Array[InternalRow] = &#123; // byteArrayRdd是一个RDD[(Long, Array[Byte])] val byteArrayRdd = getByteArrayRdd() val results = ArrayBuffer[InternalRow]() byteArrayRdd .collect() .foreach &#123; countAndBytes =&gt; decodeUnsafeRows(countAndBytes._2).foreach(results.+=) &#125; results.toArray&#125; getByteArrayRdd的作用是将一系列UnsafeRow打包成一个Array[Byte]以方便序列化，这个Array[Byte]的结构是[size] [bytes of UnsafeRow] [size] [bytes of UnsafeRow] ... [-1]。12345678910111213141516171819202122private def getByteArrayRdd(n: Int = -1): RDD[(Long, Array[Byte])] = &#123; execute() // 得到一个RDD[InternalRow]了 .mapPartitionsInternal &#123; iter =&gt; var count = 0 val buffer = new Array[Byte](4 &lt;&lt; 10) // 4K val codec = CompressionCodec.createCodec(SparkEnv.get.conf) val bos = new ByteArrayOutputStream() val out = new DataOutputStream(codec.compressedOutputStream(bos)) // `iter.hasNext` may produce one row and buffer it, we should only call it when the limit is // not hit. while ((n &lt; 0 || count &lt; n) &amp;&amp; iter.hasNext) &#123; val row = iter.next().asInstanceOf[UnsafeRow] out.writeInt(row.getSizeInBytes) row.writeToStream(out, buffer) count += 1 &#125; out.writeInt(-1) out.flush() out.close() Iterator((count, bos.toByteArray)) &#125;&#125; 可以看到getByteArrayRdd中调用了execute方法，execute继而调用doExecute，得到一个RDD[InternalRow]。1234567final def execute(): RDD[InternalRow] = executeQuery &#123; if (isCanonicalizedPlan) &#123; throw new IllegalStateException("A canonicalized plan is not supposed to be executed.") &#125; doExecute()&#125;protected def doExecute(): RDD[InternalRow] 由于SparkPlan是一个抽象类，所以这里的doExecute()没有看到实现，具体的实现根据其操作对象的不同分布在objects.scala上。 那么execute()调用链的终点是什么呢？显然它一定是一个LeafNode的子类。而通过上面的解析可以看到，我们最终得到的一个物理计划是一个LocalTableScanExec，它继承于LeafNodeExec。 ## map操作分析在Dataset中，同样提供了诸如map之类的算子，不过它们的实现是从Dataset和DataFrame之间的变换了。123456789101112131415161718192021222324252627282930313233343536def map[U : Encoder](func: T =&gt; U): Dataset[U] = withTypedPlan &#123; MapElements[T, U](func, logicalPlan)&#125;object MapElements &#123; def apply[T : Encoder, U : Encoder]( func: AnyRef, child: LogicalPlan): LogicalPlan = &#123; val deserialized = CatalystSerde.deserialize[T](child) val mapped = MapElements( func, implicitly[Encoder[T]].clsTag.runtimeClass, implicitly[Encoder[T]].schema, CatalystSerde.generateObjAttr[U], deserialized) CatalystSerde.serialize[U](mapped) &#125;&#125;case class MapElements( func: AnyRef, argumentClass: Class[_], argumentSchema: StructType, outputObjAttr: Attribute, child: LogicalPlan) extends ObjectConsumer with ObjectProducerobject TypedFilter &#123; def apply[T : Encoder](func: AnyRef, child: LogicalPlan): TypedFilter = &#123; TypedFilter( func, implicitly[Encoder[T]].clsTag.runtimeClass, implicitly[Encoder[T]].schema, UnresolvedDeserializer(encoderFor[T].deserializer), child) &#125;&#125; Spark性能调优一般来说，Spark可能出现瓶颈的地方有内存、网络和CPU，对于上面的这些问题，宜分为Driver和Executor两块进行考虑内存方面的向硬盘的溢写、从gc.log中看到的GC的猛增、节点的未响应和OOM。网络问题的主要场景是诸如Shuffle类的操作涉及在多个节点上传输，节点之间Connection reset by peer。 Spark常见性能问题和选项总体列表 诊断 现象 解决方案 Executor内存不足 Driver端ExecutorLostFailure，Executor端gc.log显示大量GC和FullGC 需要考虑Shuffle Read数据过大，或者数据倾斜。对于前者，可以考虑增加分区数或者换个Partitioner，增加Executor内存，增加Executor数量，减少Executor上的Task并行度，提前Filter，使用序列化。 Executor内存不足 Local Bytes Read+Remote Bytes Read很大 考虑是Shuffle Read的问题，同上。需要注意的是当使用groupBy系列算子时，可能一个KV对就很大的，所以增加Executor内存会更保险 Driver内存不足 Driver端gc.log显示大量GC和FullGC，spark.log中DAGScheduler相关log显示collect算子耗时过长 考虑增大Driver内存，避免collect大量数据 Driver内存不足 Driver端gc.log显示大量GC和FullGC 减少UDF的使用，减少诸如withColumn的使用 Driver内存不足 Driver端gc.log显示大量GC和FullGC，Driver的spark.log中出现大量BlockManagerInfo: Added broadcast，并且剩余内存较少，Executor的spark.log中出现TorrentBroadcast: Reading broadcast事件且耗时过长 减少broadcast的数据量 数据倾斜 部分Task Retry比较多 repartition 数据倾斜 少数Task耗时显著高于平均值 考虑换个Partitioner，扩大spark.shuffle.file.buffer、spark.reducer.maxSizeInFlight、spark.shuffle.memoryFraction，打开spark.shuffle.consolidateFiles 分区过多 Task执行的时间都很短，但整个Stage耗时较长 使用coalesce减少分区数 分区过少 Task执行的时间都很长 使用repartition增加分区数 Shuffle Spill 大部分Task执行时间长，但计算量不大 增加partition数量，增大Executor内存 Shuffle Write过大 部分节点出现FetchFailedException错误 RDD重复计算 通过Eventlog，追踪Cached的RDD。在同Stage中一个RDD被Cache，那么它的子RDD也会被Cache 持久化该RDD或使用SparkSQL改写 HDFS IO过大 当并行Task过多时，会导致HDFS读取瓶颈 RM界面显示Tracking URL: UNASSIGNED 目前App还没启动运行 RM界面显示State: ACCEPTED 计算开销较大 减少UDF和UDAF的使用；减少不必要的排序 集群缺少资源 状态是ACCEPTED而不是RUNNING。Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources 修改资源 替代性算子为了避免由于Shuffle操作导致的性能问题，常用的解决方案是使用map-side-combine的算子。这个思路就是先将聚合操作下推到每个节点本地，再将每个节点上的聚合结果拉到同一节点上进行聚合，这样能够显著减少通信量。这种方法的常见实践就是采用如下所示的一些替代性算子: 原算子 替代算子 备注 groupByKey reduceByKey/aggregateByKey reduceByKey aggregateByKey 当reduceByKey的输入和输出不一致时，创建临时对象（例如从T变为List[T]）有额外开销 aggregate treeAggregate 根据实验，treeAggregate具有更好的效率 foreach foreachPartitions filter filter+coalesce repartition+sort repartitionAndSortWithinPartitions repartition coalesce 如果目标分区数量小于当前分区数量 flatMap-join-groupBy cogroup 避免pack和unpack group操作 需要注意的是，减少Shuffle未必就是好的，例如对于coalesce而言，如果产生文件过少，很可能导致Executor空转，并且某些Executor OOM的问题，这就类似于说不患寡而患不均。 使用DataFrame API使用DataFrame API在下面的几个方面有性能优势。 Spark Catalyst优化器能够进行优化 Tungsten优化器的引入带来了三点性能提升（见上文） 有关Persist的优化方案根据RDD Programming Guide，即使是RDD（DF的话有优化器另说）Spark也可能会自动做persist，具体是发生在Shuffle过程中，这样可以避免在某个Node失败之后还要重新计算全部。但是对于肯定需要复用的数据，显式persist并没有坏处。这里需要注意的是我们要尽量提高RDD的复用程度。一般来说，如果内存中能够全部放下对象，选择默认的MEMORY_ONLY级别能够最大程度利用CPU，否则就需要考虑使用序列化的MEMORY_ONLY_SER存储。当内存再不够时，就需要考虑将其持久化到磁盘上，但这会带来较高的时间代价。虽然在Spark的较新版本中，通过Unsafe Shuffle可以直接对序列化之后的对象进行sort shuffle，但这不是通用的。 一些CaseTask RetryLolLegsTsFeature.scala我们可以看到，在优化前Job4耗时1.6h，并且Fail了不少。点进去看一下，发现这个Job里面7重试了两次，花了1h了。点进去这个Stage看看，他实际上就是一个rdd.join函数的调用。我们可以看到，某个任务的时间达到了1.0h，而其他任务的耗时都在2min左右，因此可以认为这里分区有问题。因此，我们在这里重新repartition了一下，现在运行时间缩小到了44min。 Spark日志Spark会记录Event log，并在History Server或者Spark UI中供访问调试使用。 HistoryServerSpark提供了History Server以保存Event Log，以便追踪历史任务的性能。History Server部署在18080，可以使用WebUI，也可以使用18080的/api/vi/application的api来请求json版本。这种方式需要在运行前手动export SPARK_MASTER_HOST=localhost（会被诸如start-master.sh等文件访问修改）或者sh ./sbin/start-master.sh -h localhost &amp;&amp; ./sbin/start-slave.sh spark://localhost:7077可以通过-h指定localhost。不然可能Slave会连不上localhost，因为他会访问你的电脑名字，例如CALVINNEO-MB0:7077而不是localhost。在spark-defaults.conf中，有关Event Log的配置项有两种，一个是在HDFS上，一个是在硬盘上。12345# 硬盘spark.eventLog.enabled truespark.eventLog.dir hdfs://localhost:9000/user/spark/appHist# HDFSspark.history.fs.logDirectory .../spark-2.4.4-bin-hadoop2.7/conf/history/spark-events 这个在磁盘上，供给History Server用，但是实际上和HDFS的内容是一样的。需要注意的是，一旦spark.eventLog.enabled被设置为True，就需要保证9000是可以访问的，不然可能会报错。 spark log在每个节点的spark.log记载了这个节点的Spark日志，其中日志从低到高有TRACE、DEBUG、INFO、WARN、ERROR、FATAL等级别。INFO是默认级别。 gc log在每个节点的gc.log上记载有这个节点JVM的GC情况 常用调试方法 查看RDD的分区数 1rdd.partitions.size 查看RDD的logical plan 1rdd.toDebugString 查看queryExecution 1d.queryExecution 查看schema 1d.printSchema 查看查询计划 1df.explain Spark on YARN的配置参数在Spark1.2之后，Spark on YARN就已经支持动态资源分配了，当然这个机制在后面的版本中进行了迭代，我们以2.x版本为主进行介绍。主要参考了文章。 Executor数量有下面的一些字段需要考虑： spark.dynamicAllocation.maxExecutors/minExecutors num-executors spark.dynamicAllocation.initialExecutors 首先可以通过spark.dynamicAllocation.maxExecutors和spark.dynamicAllocation.minExecutors来限定最大和最小的Executor数量。一开始Spark会启动num-executors数量个节点，我们可以设置一个较多的Executor节点执行一个小型任务，并跟踪INFO yarn.YarnAllocator，可以发现，最终会减少Executor需要的数量。此外，还有个spark.dynamicAllocation.initialExecutors，根据我的实践，如果同时设定num-executors和spark.dynamicAllocation.initialExecutors，那么后者的优先级通常会更高。我的实践是采用了下面的配置1--conf spark.dynamicAllocation.minExecutors=2 --conf spark.dynamicAllocation.maxExecutors=20 --conf spark.dynamicAllocation.enabled=true --conf spark.dynamicAllocation.initialExecutors=3 --conf spark.dynamicAllocation.maxExecutors=10 --num-executors 0 --driver-memory 1g --executor-memory 1g --executor-cores 2 结果发现，一开始启动了3个Executor，最后变成了2个。我猜想这是因为如果打开了dynamicAllocation，那么spark.dynamicAllocation相关配置就会更高优先级，而num-executors实际上是一个较为陈旧的配置。我在爆栈网上提了个问题，希望有人能证实我的思想。 与此同时，当设置了spark.dynamicAllocation.minExecutors后，就不能设置spark.dynamicAllocation.initialExecutors或者spark.executor.instances/num-executors。【Q】如果它的值小于spark.dynamicAllocation.minExecutors，对于这种情况会尝试请求spark.dynamicAllocation.minExecutors这么多个Executor。1220/07/09 15:53:29 WARN Utils: spark.dynamicAllocation.initialExecutors less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.20/07/09 15:53:29 WARN Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs. initialExecutors的设置数量，我司设置是最大数量maxExecutors(然而对外叫num-executors)的平方根。 文章指出，一旦num-executors或者spark.dynamicAllocation.minExecutors配置了，并且实际被分配了，那么就永远不会少于这个数量了，但在上面的实践中感觉并不是这样。根据知乎，应该spark.dynamicAllocation.minExecutors是下限。 当Executor空闲超过spark.dynamicAllocation.executorIdleTimeout，那么就会被移出，可以设置spark.dynamicAllocation.cachedExecutorIdleTimeout来避免移除缓存了数据的Executor。当有Task等待时间超过spark.dynamicAllocation.schedulerBacklogTimeout后，会加入新的Executor。一般来说，如果一个Executor空闲60s后将被移出，而如果有Task在backlog中等待1s将会新增Executor。 需要注意的是，并不是Spark集群得不到spark.dynamicAllocation.minExecutors个节点他就不能运行了。事实上Spark任务在Accepted到Running的阶段，Yarn只会先分配给driver这一个container，然后再由Driver来申请它需要的Executor，这个过程也能从上面的log中看出。 Executor内存和CPU对于yarn来说，每个Node有NodeManager负责管理。NodeManager主要有两个配置： yarn.nodemanager.resource.memory-mb表示每个node上，每个Container能够最多跑的内存。 需要注意的是--executor-memory/spark.executor.memory不能和YARN中的yarn.nodemanager.resource.memory-mb直接对应，原因是Spark可以请求一些堆外内存，因此实际上要请求(1+spark.yarn.executor.memoryOverhead) * spark.executor.memory这么多的内存，这个Overhead的比例大概在7%左右。然后YARN实际分配的内存也会多一点，具体有yarn.scheduler.minimum-allocation-mb 和 yarn.scheduler.increment-allocation-mb控制。 yarn.nodemanager.resource.cpu-vcores表示每个node上，每个Container能够最多跑的核。这里的vcore应该是YARN的调度概念，申请5个executor-cores，等于要YARN调度5个vcore。 这里需要注意的是，每个NodeManager自己最好也要保留一个核，比如说我们给每个Executor分配3个核，那么在一台16核的机器上，我们正好可以分配5台机器，剩下来的一个核心给NodeManager。 Driver内存主要考虑collect的大小 Spark常见问题的解决方案不得不说，Spark的相关问题很多还是比较难调试的，这是因为Spark它的错误日志在打印堆栈时往往喜欢打印它的内部状态，我们很难根据它的内部状态去trace到底是我们的什么操作导致它产生这个问题。并且Spark上处理的数据量规模一般都很大，并且都跑在诸如YARN托管的集群上，这个给Spark调试带了了更大的麻烦。 变量在节点之间共享当我们需要在节点间共享变量，例如将某个字符串从Driver发送到Executor上时，需要这个变量能够被序列化。特别地，有一个经典的Bug就是Map#mapValues不能被序列化，这个解决方案是在mapValues之后再map(identity)一下。特别需要注意的是因为RDD是分布式存储的，所以不能够直接当做变量处理，例如下面的代码是不能够使用的。对于这种情况，要么是将其中一个小RDD广播，要不就是将两个RDD去做个JOIN。在SparkSQL中，JOIN操作会被视情况优化为广播。123rdd1.map&#123; rdd2.filter(...)&#125; scala.collection.mutable.WrappedArray$ofRef cannot be cast to Integer根据SoF，这个错误就是把Array改成Seq就好了。 Extracting Seq[(String,String,String)] from spark DataFrame这个错误发生在我们想往一个Row里面放一个类型为Seq的字段的时候。根据SoF，我们可以通过以下的方式来复现这个问题。我们创建了一个以Record为元素的Row，里面有一个content_processed，它的类型是Seq[Feature])，现在我们希望将Record里面的id字段搞掉，我们可以写出这样的代码123456789101112131415import org.apache.spark.sql.Rowcase class Feature(lemma: String, pos_tag: String, ne_tag: String)case class Record(id: Long, content_processed: Seq[Feature])val df = Seq( Record(1L, Seq( Feature("ancient", "jj", "o"), Feature("olympia_greece", "nn", "location") ))).toDFval seems_right = df.map(row =&gt; row.getAs[Seq[Feature]]("content_processed"))// res10: org.apache.spark.sql.Dataset[Seq[Feature]] = [value: array&lt;struct&lt;lemma:string,pos_tag:string,ne_tag:string&gt;&gt;]val err = seems_right.first 当我们对得到的seems_right执行Action触发计算时，就会得到错误12java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to $line67.$read$$iw$$iw$Feature at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.serializefromobject_doConsume_0$(Unknown Source) 这个原因还是上面提到的Row的缺陷。其解决方案是借助于Dataset将Row转换为其他的数据结构，例如本命的Record，或者一个能够pattern match这个Record类的数据结构，例如(Long, Seq[(String, String, String)])12df.as[Record].map(_.content_processed).firstdf.as[(Long, Seq[(String, String, String)])].map(_._2).first 考虑集群机器的问题集群中有些机器是Power PC(PPC)，这些机器可能会去报错12(Possible cause: can't load Power PC 64 LE-bit .so on a AARCH64-bit platform) at java.lang.ClassLoader$NativeLibrary.load(Native Method) 这时候需要设置spark.blacklist.enabled=true把它们blacklist掉。 Spark SQL编写技巧详见Spark相关机制详解中JOIN相关的章节。 Spark的其他组件的简介GraphXGraphX是基于Spark实现的一个图计算框架，能够对图进行建模。GraphX内置了一些实用的方法，如PageRank、SCC等，同时也提供了Pregel算法的API，我们可以利用Pregel来实现自己的一些图算法。目前GraphX似乎还没有实用的Python API，比较方便的是借助Scala。 ML和MLLibML和MLLib是Spark机器学习库的两个不同实现。其中MLLib是较老的基于RDD的实现，而ML是较新的基于Dataset的实现 StreamingSpark相关机制详解JOIN相关Spark有三种Join方式，ShuffledHashJoin、BroadcastHashJoin、SortMergeJoin等。这三种方式都会涉及到数据的传输，所以JOIN的代价是比较大的。前两种属于HashJoin的范畴，HashJoin一般就是将小表做为BuildTable，将大表作为ProbeTable。BuildTable采用Hash进行索引，在JOIN时，对大表进行遍历，并在BuildTable中进行查找JOIN。后一种SortMergeJoin一般是对于两个大表而言的，将两个表都进行排序，然后采用类似归并排序的办法进行JOIN。问题是，这个过程是怎么并行的呢？一个简单的想法是如果我们Sort时候保证两个表的相同的Key都出现在一个Partition里面，那么对这个Partition做merge，就可以得到完整的结果。Spark是这样做的么？是的，Spark会先做一次Shuffle，把可能被JOIN的Key先划分到一个分区里面。 Repartition相关我们知道，rdd.repartition只是rdd.coalesce的别名，所以我们讨论后者。按照惯例，先上代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// RDD.scala/** * Return a new RDD that is reduced into `numPartitions` partitions. * * This results in a narrow dependency, e.g. if you go from 1000 partitions * to 100 partitions, there will not be a shuffle, instead each of the 100 * new partitions will claim 10 of the current partitions. If a larger number * of partitions is requested, it will stay at the current number of partitions. * * However, if you're doing a drastic coalesce, e.g. to numPartitions = 1, * this may result in your computation taking place on fewer nodes than * you like (e.g. one node in the case of numPartitions = 1). To avoid this, * you can pass shuffle = true. This will add a shuffle step, but means the * current upstream partitions will be executed in parallel (per whatever * the current partitioning is). * * @note With shuffle = true, you can actually coalesce to a larger number * of partitions. This is useful if you have a small number of partitions, * say 100, potentially with a few partitions being abnormally large. Calling * coalesce(1000, shuffle = true) will result in 1000 partitions with the * data distributed using a hash partitioner. The optional partition coalescer * passed in must be serializable. */def coalesce(numPartitions: Int, shuffle: Boolean = false, partitionCoalescer: Option[PartitionCoalescer] = Option.empty) (implicit ord: Ordering[T] = null) : RDD[T] = withScope &#123; require(numPartitions &gt; 0, s"Number of partitions ($numPartitions) must be positive.") if (shuffle) &#123; /** Distributes elements evenly across output partitions, starting from a random partition. */ val distributePartition = (index: Int, items: Iterator[T]) =&gt; &#123; var position = new Random(hashing.byteswap32(index)).nextInt(numPartitions) items.map &#123; t =&gt; // Note that the hash code of the key will just be the key itself. The HashPartitioner // will mod it with the number of total partitions. position = position + 1 (position, t) &#125; &#125; : Iterator[(Int, T)] // include a shuffle step so that our upstream tasks are still distributed new CoalescedRDD( new ShuffledRDD[Int, T, T]( mapPartitionsWithIndexInternal(distributePartition, isOrderSensitive = true), new HashPartitioner(numPartitions)), numPartitions, partitionCoalescer).values &#125; else &#123; new CoalescedRDD(this, numPartitions, partitionCoalescer) &#125;&#125; 首先，对于有Shuffle的情况，是CoalescedRDD里面套了一个ShuffledRDD。首先来看这个ShuffledRDD，是用的HashPartitioner，这个是用key.hashCode,去模numPartitions来进行分区的，很简单。ShuffledRDD的主要逻辑在mapPartitionsWithIndexInternal函数，它会去mapPartitions，然后加上一个表示分区索引的index。这个index是怎么指定的呢？实际上是distributePartition来做的，这个函数接受一个Int，和一个Iterator[T]，表示一个分区里面所有的元素。这个函数是随机的，也就是对每个原有分区里面的项目，将它们随机分到某个分区里面，因此它并不保证原来相邻的条目最后还是会落到相邻的机器上。这里Internal的意思就是不会去调用sc.clean(f)。下面看看distributePartition的具体实现，首先scala.util.hashing.byteswap32是一个积性Hash函数，积性函数是满足f(ab)=f(a)f(b)的函数。不过我算了一下，也没看出来哪里是积性函数了。12scala.util.hashing.byteswap32(100) * scala.util.hashing.byteswap32(2) scala.util.hashing.byteswap32(200) 后来看了下wikipedia才知道，这里说的应该是乘法哈希，只是一种哈希算法，类似的还有除法哈希（就是mod）和Fibonacci哈希。这个产生[0..M-1]区间内的哈希值公式是1hash(key) = floor((k A mod W)/(W/M) ) 其中：通常设置M为 2 的幂次方，W为计算机字长大小（也为2的幂次方），a为一个非常接近于W的数。它的关键思想是提取关键字k中间的几位数字。 不过无论如何，这里只是做一个随机数种子，.nextInt(numPartitions)返回一个0到n之间的随机数。下面来看这个CoalescedRDD，它有和ShuffledRDD同样的numPartitions。这个partitionCoalescer实际上是Empty，最后用的是DefaultPartitionCoalescer。主要用在CoalescedRDD.getPartitions里面。12345678910111213141516171819202122/** * [performance] Spark's internal mapPartitionsWithIndex method that skips closure cleaning. * It is a performance API to be used carefully only if we are sure that the RDD elements are * serializable and don't require closure cleaning. * * @param preservesPartitioning indicates whether the input function preserves the partitioner, * which should be `false` unless this is a pair RDD and the input * function doesn't modify the keys. * @param isOrderSensitive whether or not the function is order-sensitive. If it's order * sensitive, it may return totally different result when the input order * is changed. Mostly stateful functions are order-sensitive. */private[spark] def mapPartitionsWithIndexInternal[U: ClassTag]( f: (Int, Iterator[T]) =&gt; Iterator[U], preservesPartitioning: Boolean = false, isOrderSensitive: Boolean = false): RDD[U] = withScope &#123; new MapPartitionsRDD( this, (_: TaskContext, index: Int, iter: Iterator[T]) =&gt; f(index, iter), preservesPartitioning = preservesPartitioning, isOrderSensitive = isOrderSensitive)&#125; 其中withScope的实现是1234567/** * Execute a block of code in a scope such that all new RDDs created in this body will * be part of the same scope. For more detail, see &#123;&#123;org.apache.spark.rdd.RDDOperationScope&#125;&#125;. * * Note: Return statements are NOT allowed in the given body. */private[spark] def withScope[U](body: =&gt; U): U = RDDOperationScope.withScope[U](sc)(body) 它的作用是在给定代码块中创建的RDD具有相同的RDDOperationScope。withScope就像是一个 AOP（面向切面编程），嵌入到所有RDD 的转换和操作的函数中，RDDOperationScope会把调用栈记录下来，用于绘制Spark UI的 DAG（有向无环图，可以理解为 Spark 的执行计划）。实际上withScope就类似一个代理，为什么要做代理，是因为RDDOpertionScope需要输出一些调试信息。这有点类似于Haskell的Debug.trace一样。 Persist相关unpersist流程可以看到，同样是向BlockManagerMaster要求removeRdd。123456// SparkContext.scalaprivate[spark] def unpersistRDD(rddId: Int, blocking: Boolean): Unit = &#123; env.blockManager.master.removeRdd(rddId, blocking) persistentRdds.remove(rddId) // 这是一个ConcurrentMap listenerBus.post(SparkListenerUnpersistRDD(rddId)) // 前面提到过的，做Event log&#125; 下面就是从BlockManagerMaster里面去掉所有属于这个RDD的块。可以看到，它往所有的BlockManagerSlave发送RemoveRdd消息。123456789101112// BlockManagerMaster.scaladef removeRdd(rddId: Int, blocking: Boolean): Unit = &#123; val future = driverEndpoint.askSync[Future[Seq[Int]]](RemoveRdd(rddId)) future.failed.foreach(e =&gt; logWarning(s"Failed to remove RDD $rddId - $&#123;e.getMessage&#125;", e) )(ThreadUtils.sameThread) if (blocking) &#123; timeout.awaitResult(future) &#125;&#125;// BlockManagerMessages.scalacase class RemoveRdd(rddId: Int) extends ToBlockManagerSlave 有一次，我们遇到了这样的错误12345678910111220/08/01 13:00:17 ERROR YarnClusterScheduler: Lost executor 144 on xxx: Executor heartbeat timed out after 305856 ms20/08/01 13:00:21 ERROR YarnClusterScheduler: Lost executor 144 on xxx: Container container_xxx_01_000145 exited from explicit termination request.20/08/01 14:03:04 ERROR ApplicationMaster: User class threw exception: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [300 seconds]. This timeout is controlled by spark.network.timeoutorg.apache.spark.rpc.RpcTimeoutException: Futures timed out after [300 seconds]. This timeout is controlled by spark.network.timeout at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47) at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62) at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58) at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76) at org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:131) at org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1844) at org.apache.spark.rdd.RDD.unpersist(RDD.scala:217) Demo可以通过df.explain看物理查询计划 Reference https://zhuanlan.zhihu.com/p/67068559 http://www.jasongj.com/spark/rbo/ https://www.kancloud.cn/kancloud/spark-internals/45243 https://www.jianshu.com/p/4c5c2e535da5 http://jerryshao.me/2014/01/04/spark-shuffle-detail-investigation/ https://github.com/hustnn/TungstenSecret https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-shuffle-UnsafeShuffleWriter.html https://blog.k2datascience.com/batch-processing-apache-spark-a67016008167 https://stackoverflow.com/questions/45553492/spark-task-memory-allocation/45570944 https://0x0fff.com/spark-architecture-shuffle/ https://0x0fff.com/spark-memory-management/ https://www.slideshare.net/databricks/memory-management-in-apache-spark https://www.linuxprobe.com/wp-content/uploads/2017/04/unified-memory-management-spark-10000.pdf https://www.xiaoheidiannao.com/215670.html https://zhuanlan.zhihu.com/p/101797149 https://mp.weixin.qq.com/s/M29AdSNy90ZoWFO6yP967Q?st=4E4EC5032168C875055B8539D8DF21E00C9505E1A359D84092C936E0CCA66518CF3DD79D1F951211AD4E74EE77C357659C0CF2B38EB5D901EEFFBBB7D1D22FF17B8290AF97D9EA29EF49B69C161D5B249ADA7B55585031E1A95FD955BBDF5FD4FFC52F892F43219C7C42DE53661D9EE72F5049491A75C067E71791364C162E767ECF5B3EE162E7D58566458BB0B55F100D4463EFD264C0E118CF40622573B62E87F319989CFEF3656FB8325659A3E1C2&amp;vid=1688850523686960&amp;cst=A4500263DF343A71C6A77F0747F6E08A9AAD04329A7D1B94AC827AA2C31F1654BE4E436938CB546B8839565025E35997&amp;deviceid=24b21599-d5ef-4ce4-9465-be2e176a6aaf&amp;version=3.1.7.3005&amp;platform=win]]></content>
      <tags>
        <tag>Scala</tag>
        <tag>Spark</tag>
        <tag>SparkSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Scala语言进行编程]]></title>
    <url>%2F2019%2F08%2F06%2Fscala-lang%2F</url>
    <content type="text"><![CDATA[Scala和Kotlin、Clojure等一样是一种jvm语言，传说其复杂度可与C++一较高下。用下来感觉并不舒服，例如其中的implicit特性，能够减少很多代码的冗余，但另一方面，又会导致代码对新手而言的可读性变差。这篇文章拆分自我从前的文章《使用Scala进行Spark-GraphX编程》。 括号通常，小括号()表示表达式和函数调用，大括号{}表示代码块。例如在.map({})中的大括号即表示一个代码块。特别地，代码块也是一个表达式，所以下面的代码也是成立的1( &#123; var x = 0; while (x &lt; 10) &#123; x += 1&#125;; x &#125; % 5) + 1 同时，括号也是可以省略的。根据Scala Style Guide，在Scala中，一个无参方法在调用时可以省略小括号。这里注意，如果函数带一个是隐式参数或者默认参数，那么就不能带空括号。那么如何区分obj.attribute是字段还是方法呢？对此，Scala有统一访问原则(Uniform Access Principle, UAP)，也就是指代码不因为属性是通过字段实现还是方法实现而受影响。因此实际上Scala只有两个命名空间，类型和值。 容器 Array/Seq/List这三个都可以表示线性表，那么他们的区别是什么呢？首先，Array实际上明确对应了Java里面的数组。例如下面的代码的返回值就是int[]。1Array(1,2).getClass.getSimpleName 在Java中，我们显然不会把原生数组和容器类型搞混，那么为什么在Scala中，我们就会有这样的困惑呢？原因是 Implicit在Scala中，可以通过implicit关键字修饰方法/变量、参数、类，对应实现隐式视图和隐式参数。其中隐式视图和隐式参数可以对应到泛型约束中的视图界定和上下文界定。 隐式视图隐式视图可以实现隐式Casting。如下面的代码所示，错误的原因是没有办法将Double转为Complex，所以和其他例如C++等语言类似，这里需要一个隐式转换。1234567891011121314case class Complex(r: Double, i: Int) &#123; def +(c: Complex) = Complex(r+c.r, i+c.i) def +(d: Double) = Complex(r+d, i) override def toString() = r + "_" + i&#125;val c = Complex(1, 2)println((c + 1).toString()) // 2.0_2println((1 + c).toString()) // Errorprintln(Complex(1, 0) + c) // OK// 视图绑定要求t能够隐式转换为Complexdef printComplex[T &lt;% Complex](t: T) = &#123;println(t.toString)&#125;printComplex(1.0) 如下所示，implicitConvert负责Double到Complex的隐式转换1implicit def implicitConvert(x: Double) = Complex(1.0, 0) 此外，隐式视图还可以使用目标类的方法来扩展原类的方法。 隐式参数首先，Scala提供默认函数值，如123def addInt(a: Int, b: Int = 1) : Int = &#123; return a + b&#125; 但另一种机制implicit parameter会更为灵活。implicit parameter的用法如下面所示，我们可以为类型People提供一个默认值，这样当我们在调用getName时，就可以给出参数p。123456789case class People(name: String)&#123; &#125;implicit val ip = People("Calvin")def getName(implicit p: People) = p.namedef getNameExplicit(p: People) = p.namegetNamegetNameExplicit(People("Calvin")) 可以看到，在一定程度上，默认函数可以起到和隐式参数一样的效果，那么为什么还会存在这个特性呢？我们来查看下面这些问题 implicit value使用的场合 爆栈网上的这篇文章指出，implicit value是针对类型而言的，所以不应该对一个常见的类型是提供一个implicit值，例如给String提供一个implicit值。此外，定义implicit值的时候，最好定义在伴生对象里面，而我们对String的伴生对象显然是没有控制权的。 为什么prefer implicit value呢？ 这篇文章讲解了为啥默认参数(DPV)是一个bad practice，包含下面几点： DPV会让调用者觉得函数的语义不明显 DPV会让柯里化和Partial Application的行为变得奇怪 DPV会降低便利度 DPV会加大refactor难度 另外，implicit参数还可以和ClassTag一同使用，来实现保障类型擦除后类型安全的功能 函数与方法函数与方法Scala中的函数和方法的区分让人费解。笼统地来说，函数由val定义，是一个继承了Trait的类的对象。方法由def定义，是组成类的一部分。因为方法是不可以被赋值的，所以需要通过下划线将函数转为方法，然后进行复制。这个类似于一个eta变换。12345def func(a:Long, b:Long) = &#123; a+b&#125;func.getClass // 错误(func _).getClass // 返回class Playground$$Lambda$6823/1662832692: Class[T] 另外，有时候不通过下划线也能对方法进行赋值。1234567891011class Cls () &#123; def func(input:Int) = &#123; input + 1 &#125;&#125;val cls = new Cls()cls.func(1)val arr = Array(1,2,3,4,5)arr.map(cls.func _).foreach(println)arr.map(cls.func).foreach(println) 柯里化Scala函数都是柯里函数，因此支持链式地调用，也支持偏/部分应用。注意偏/部分应用(Partial Applied Function)和偏/部分函数(Partial Function)是两个概念。Scala中的Partia Function是一个Trait，类型为PartialFunction[A,B]，它接收一个类型为A的参数，返回一个类型为B的结果。而我们现在论述的是偏应用12val p_func = func(_, 2)p_func(3) // 5 高阶函数使用compose可以实现复合函数12scala&gt; (((x: Int) =&gt; x + 1) compose ((y: Int) =&gt; y * 2)).apply( 11 )res1: Int = 23 模式匹配Scala使用case来实现类似guard的机制。 解构绑定Scala可以利用样本类case class来实现对象的解构绑定。case class实际上可以看做对class的语法糖，根据Scala的说明，case class的使用场景就是用来做Structured binding的。 apply和unapplyapply可以把对象当函数用unapply用于unbind一个case class到诸如Seq的结构上 继承和泛型目前，继承和泛型在一起讲，因为这两个特性经常一起使用。 with和extendScala支持通过with去混入(mixin)某个trait。也就是如下的代码，看起来很像带实现的Java的interface，又像分主次的C++的多继承。12345678910abstract class A &#123; val message: String&#125;class B extends A &#123; val message = "I'm an instance of class B"&#125;trait C extends A &#123; def loudMessage = message.toUpperCase()&#125;class D extends B with C 通过mixin，还可以表示类型，例如Transformer with HasFeaturesCol with HasPredictionCol with MLWritable 逆变与协变逆变(contravariant)和协变(covariant)是在泛型类语境下的。假设B extends A，也就是B是A的子类。根据里氏替代原则，在不声明逆变协变的情况下，默认是不变的，也就是C[A]和C[B]是雷锋和雷峰塔的关系。那么协变C[+T]场景下C[B]是C[A]的子类。一个常见的例子是Cat是Animal的子类，那么我们也自然希望List[Cat]是List[Animal]的子类，这样我们的List[Animal]可以接受诸如List[Dog]、List[Cat]之类的参数。然而在逆变C[-T]场景下，C[A]是C[B]的子类了。看起来反直觉，但实际上是有作用的。例如我们定义了函数Action[Animal]和Action[Cat]，顾名思义，我们认为Action[Animal]能够正确处理Animal[Cat]，因此我们的Action[Cat]能够接受Action[Animal]作为参数是合理的。 案例解析12object Predef extends scala.LowPriorityImplicits with scala.DeprecatedPredef &#123; type Map[A, +B] = scala.collection.immutable.Map[A, B] 逆变和协变类型不能被设置为var之前写Flow啥的时候，发现下面的代码是不能编译的。123class C [+T] &#123; var v : T = _&#125; 根据爆栈网，这种做法其实就是不被允许的。最后我们的方案是直接把Flow的类型参数去掉了，这也导致了我们想取东西的时候需要asInstanceOf[T]一下 类型擦除在C++中，下面的代码似乎是没有问题的。我们调用getData()，如果此时data是null，那么返回一个新的T()。但Scala里面是会报错的，原因是此时不知道T的类型信息。可是，我明明在new ObjectProxy[CalvinClass]里面传了啊，为啥我还不知道呢？123456789101112131415class ObjectProxy[+T](val data:T) extends Serializable&#123; def getData() = &#123; if(data == null)&#123; new T() &#125;else&#123; data &#125; &#125;&#125;object ObjectProxy&#123; def main(args: Array[String]): Unit = &#123; val calvinProxy = new ObjectProxy[CalvinClass](null) &#125;&#125; 按照往常我提了个问题，原因显然和Scala的类型擦除机制有关。首先在C++里面，对于模板，是会生成独一份的代码的，但是Java会么？其实在代码中定义的List&lt;object&gt;和List&lt;String&gt;等类型，在编译后JVM看到的只是List，而泛型附加的类型信息对JVM来说是不可见的。既然不可见类型信息，我们又没有办法从传入的参数null中推导得到类型信息，那就只能报错了。改正方法很简单，把new替换成下面的就行，并且让ObjectProxy继承ClassTag[T]。这里的ClassTag[T]用来保存被擦除的类型信息。1implicitly[ClassTag[T]].runtimeClass.newInstance().asInstanceOf[T] 下界与上界类型下界形如U &gt;: T，表示U是T的父类，反之，类型上界S &lt;: T，表示S是T的子类。这个符号的箭头方向永远指向孩子，可以理解为孩子永远是小的，所以小于号指向他。通常来说，协变常常被用在容器类、返回值上。逆变通常被用在函数和参数上。根据Luca Cardelli规则，就是对输入类型是逆变的，对输出类型是协变的。直观地说，也就是我们可以返回一个更精确的类型（例如返回Object的子类String），接受一个更宽泛的类型。那么这里那里有“泛型”呢？其实我们可以假定一个父类P中有个返回Object的方法，而子类C有个返回String的方法，可以看到P :&gt; C且Object :&gt; String，于是协变的关系从这里得到了。虽然参数设为逆变导致我们可以接受更为宽泛的泛型类。所以我们通过类型下界来限定我们接受的参数U必须是T的父类。1234567class Consumer[+T](t: T) &#123; // covariant type T occurs in contravariant position in type T of value t def use(t: T) = &#123;&#125;&#125;class Consumer[+T](t: T) &#123; def use[U &gt;: T](u : U) = &#123;println(u)&#125;&#125; 反射常见类型获取函数123456789101112131415161718import scala.reflect.runtime.universe._abstract class A &#123; val message: String&#125;class B extends A &#123; val message = "I'm an instance of class B"&#125;val b = new B;println(typeOf[B]) // Playground.BtypeOf[B]println(classOf[B]) // class Playground$AclassOf[B]b.getClassprintln(b.getClass == classOf[B]) // trueprintln(1.getClass) // intprintln(b.getClass) // class Playground$Bprintln(b.getClass.getSimpleName) // Bprintln(b.getClass.getCanonicalName) // Playground.B 下面的情况比较奇特，展示了List[Int]和List[String]具有相同的Class，但Array[Int]和Array[String]的，其本质原因是Array对应了Java中的原生数组，而List是Scala下面的对trait Seq的一个实现。事实上，List下的Class相同但Type不同，而Array下的Class和Type都不同。1234567891011121314import scala.reflect.runtime.universe._println(List[Int](1).getClass == List[Double](1.0).getClass) // Trueprintln(List[Int](1).getClass.getCanonicalName) // scala.collection.immutable.$colon$colonprintln(classOf[List[Int]]) // class scala.collection.immutable.Listprintln(classOf[List[String]]) // class scala.collection.immutable.Listprintln(typeOf[List[Int]]) // List[Int]println(typeOf[List[String]]) // List[String]println(Array[Int](1).getClass == Array[Double](1.0).getClass) // Falseprintln(Array[Int](1).getClass.getCanonicalName) // int[]println(classOf[Array[Int]]) // class [Iprintln(classOf[Array[String]]) // class [Ljava.lang.String;println(typeOf[Array[Int]]) // Array[Int]println(typeOf[Array[String]]) // Array[String] Scala的坑迭代器Scala的迭代器求size之后会自动到尾部的。123456789// OKval it1 = Iterator(1,2,3,4)val sz1 = it1.sizeit1.next()// Errorval it2 = List(1,2,3,4).iteratorit2.sizeit2.next() split这个应该是诸如php之类的所有从String去split的函数都会涉及的问题，也就是说到底多个splitter连续出现是什么行为。123"1,2,,,,,".split(",").length // 2: Int"1,2,,,,,".split(",", -1).length // 7: Int 但是这样还是有问题，因为&quot;&quot;.split(&quot;&quot;).length会等于1。12345678def getStringArray(k :String, splitter:String):Array[String] = &#123; val s = k .asInstanceOf[String].trim s.split(splitter, -1)&#125;getStringArray("", ",").length // 1getStringArray("a", ",").length // 1getStringArray("a,b", ",").length // 2 Reference https://docs.scala-lang.org/zh-cn/tour/tour-of-scala.html https://www.zhihu.com/question/35339328 https://scastie.scala-lang.org/ https://stackoverflow.com/questions/27414991/contravariance-vs-covariance-in-scala https://twitter.github.io/scala_school/zh_cn/advanced-types.html https://colobu.com/2015/05/19/Variance-lower-bounds-upper-bounds-in-Scala/ https://www.zybuluo.com/zhanjindong/note/34147]]></content>
      <tags>
        <tag>Scala</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关西攻略]]></title>
    <url>%2F2019%2F06%2F18%2Fkensai%2F</url>
    <content type="text"><![CDATA[毕业旅行和大佬一同前往日本关西游玩，一共去了京都、奈良和大阪三个地方。这篇游记首先介绍首次去日本需要注意的一些事项，然后会简述一下我们的行程和看法。 交通综述首先日本的地铁、火车什么的统称电车。而至于叫JR还是叫近铁、南海电车、京都地下铁、大阪地下铁，其区别是在运营的公司不同。因此在不同公司的线路之间换乘时，需要和每个公司单独计费。因此行程很短时，频繁更换线路会导致多付很多起步价的钱。初次来关西，搜索攻略会遇到诸如ICOCA、KTP、大阪周游券之类的东西，在这里进行介绍。ICOCA是一个储值卡，没有任何优惠，主要可以方便买票不用付现金，还有就是提供类似上海地铁那种1号线换3/4号线的这种算钱方式。需要注意的是，日本的电车可能会跨线运营。例如在京都地铁东西线的终点站太秦天神川可以坐火车到琵琶湖滨大津方向（我后来在Google上搜到的）。我们当时已经坐到了去滨大津方向的车上，我一看不对，这车怎么是前后座位而不是地铁的那种侧向座位呢？进而发现对面月台开过来一辆车，而上面也写着六地藏，而我们直到这也是东西线的另一头终点站，于是我们赶紧跳下列车，到了对面。去滨大津的车开走后，又两个中国小姐姐跑过来问到底在哪里乘车，我熟练地回答到我们是刚从对面过来的。。。为了避免这种情况，我们需要根据地铁站里面的时刻表去判断到底这辆车是去哪里的，或者通过这辆车的屏幕上的终点站等来确定。这种现象在乘坐往返关西机场和大阪市的之间的列车时是非常需要注意的。 关西机场从关西机场降落，前往大阪或京都的一个好方案是提前在淘宝购买自取的ICOCA+HARUKA套餐，该套餐包含一个有500押金+1500额度的ICOCA和一个单程的关空特急HARUKA。关空特急即关西空港特急的简称，对应的非特急是关空快速+JR大阪环状线+JR京都线。我们买的从ICOCA+到京都的HARUKA的关西机场自取套餐需要大概250人民币，但是如果单买HARUKA，从关西机场到天龙寺就需要1710日元了。 我觉得如果从关西机场往返的话从京都往南玩是比较好的，这样购物可以放在大阪的最后一天，方便去机场，并且大阪作为海滨城市，还是非常适合在前面强度较大的行程之后进行较为放松的旅途的。从大阪回程可以考虑坐关空快速，这列车还是可能会比较挤的，住在天王寺的可能有没有座位的风险。此外，关空快速在日根野站会进行神奇的分离，此时前面四节车厢会前往关西机场，后面四节车厢会前往和歌山。所以很建议回程的时候坐在第四号车厢，看看怎么分离的。我们在天王寺站乘坐JR线到关西空港。天王寺的JR站比较大，有16个站台，其中1-8，包括15/16都可以前往关西空港。这指的是列车可能停靠在这些站台，所以如果想尽快乘车，应当注意大厅大屏幕和语音广播查看最近一班车在上面站台。 关西机场的部分登机闸口需要通过小火车抵达，所以在逛免税店的同时也要注意时间。 香港机场由于签证的不确定性，我们11号出发，在6号晚上才捡漏定了从香港中转的最后两张机票HX221-HX632-HX613-HX216。这套机票才人均2021，不过需要10号在南京住一晚，17在香港住一晚。在南京原本准备住那个机场睡吧，不过改变主意加了点钱住了亚朵，早上提前3小时（实际没必要）打滴滴到了机场。17号在香港的一夜是比较痛苦的，因为我们飞机1.30才落地，我们又没准备港币。因此即使在Airbnb上能够订到在东涌大概400+的宾馆，但仍然不敢去住，这是因为同伴只问了能不能接机，没问能不能送机，而我们的飞机早上起飞是比较早的。网上很多在香港机场睡觉的攻略是在候机大厅，这可能需要入境香港。由于我们是在香港机场的中转候机厅，也不清楚怎么去一号二号航站楼，所以我们直接选择了转机通道，通过安检到了楼上出发层。网传香港机场过夜是很冷的，但实际上带一件衬衫去铺盖就以足够，因为他们晚上会调小或者关闭冷气。候机区的部分位置有那种135度的硬背躺椅，能够勉强一睡。 吃喝综述日本的吃喝特别贵，去饭店的话主要有拉面、定食包括各种天妇罗鸡排猪排等、各类寿司店、烤肉、大阪烧、寿喜锅、鳗鱼饭之类的。因为我同伴不能吃生的，并且我很穷，所以包括很多怀石料理、寿司店啥的我们都没有去。在这里，我推荐大家去日本前都配备一点美食推荐的软件，因为大众点评上面会少很多那种街边小点之类的商家。有些店我们感觉还不错，不过由于不知道里面的东西和价格，所以就不怎么敢进去吃了。日本实施垃圾分类，街头普遍没有垃圾桶。比较多的是随处可见的贩售机旁边的只能扔喝完饮料瓶的垃圾桶。一般扔垃圾的话，一是扔到你购买的店铺的垃圾桶里面，二是坐电车，然后扔到电车站的垃圾桶里面。 京都(11-13)我们的宾馆是AIRBNB找的叫东寺别馆的民宿，在去之前我已经在Google地图上演练了一番，根据AIRBNB上“旁边是TOSHIBA”的说明找到了，并发现这个前面有一棵树挡着门口，也算是地标了。从京都站吃完饭打算走过去才发现这条路上有好多叫东寺的馆，什么东寺本馆啥的。后来靠对Google街景的印象才找到。进公寓的时候需要过两道自动的玻璃门，应该是为了保暖吧，一楼有清洁工的办公室和一个自动贩卖机。我们在三楼。在京都，非常建议购买一个两日的巴士卡，虽然只能坐巴士和京都的区区两条地铁，但考虑到容错性，这个本钱是一定能收回来的。在京都我们就坐错过两次公交，一次是玩完银阁寺回来，要走一个叫银阁寺道的车站上车去清水寺。地图（在旅游全程我都以为是Google地图，等到回来发现一直能使用才意识到是苹果地图）给我们指了一个东西方向路上的站台，而这个站实际上没有我们要等的公交车。最后还是车站上的一个老奶奶比划了一下，说我们要去同交叉路口的另一条南北向的路上去乘车。第二次是去金阁寺的路上，地图要我们坐快速202，但我们坐了202，结果停了很多小站，而且到了二条往北之后路线都不对了。我们重新下来坐了个巴士，结果地图又给导到金阁寺町，幸亏这里离金阁寺景点也没有几步路。巴士卡在京都站的市巴士地下铁案内所买就行，可以买完到地面上坐100路往清水寺或者银阁寺走，一个是到银阁寺前站，一个是到五条坂/清水道。清水寺、银阁寺和伏见稻荷大社基本位于京都市东面，从北往南分布。由于买巴士卡的时候会送一张纸质的地图，上面画了京都市大部分景点的所在位置，所以还是很方便的。100路超级挤，当时上车就开始排队了，本以为要排很久，但下一班车很快就来了。不过上去以后发现车上更挤，但大多数人都在清水寺就下车了，到银阁寺的比较少。倒是车上后来上了一些日本初高中生，并且在大声讲话，倒是原来车上的外国人不怎么讲话。其实我们在京都游玩的时候常常看到成群结对的日本中小学生，有的时候比国外游客还多。后来知道这是因为日本学生常常在暑假进行修学旅行。在车上有个妹子问我到清水寺怎么走，我拿出地图给他指了指，然后表示从苹果地图上看到清水寺关门了，不知道还能不能进去。到了银阁寺，走过一段砂石路（日本的神社寺庙很喜欢用砂石路而不是砖石路）便到了售票亭。银阁寺的门票是一个用毛笔写的帖子，很是漂亮。银阁寺的景点非常小。在往清水寺走的路（清水道）上，人慢慢多了起来。路边是林立的小店，有个店叫八ッ橋，好像还是个连锁的很有趣，让我想起老家的八字桥茶叶店。我们遇到一个一个人从上海过来的穿和服的妹子，要我们帮她拍照。我假装要买御守（实际上也买了）甩掉了妹子，然后发现旁边有一个100日元的项目，说是脱下鞋子扶着栏杆从一个楼梯往下走，然后看到一个发光的石头对它许愿啥的。我们跟着一群日本中学生后面进去，里面有个妹子显得很害怕，其他人一直在安慰她（反正我是这么觉着的，虽然在出口有个男的还扮鬼吓唬了下妹子）。进去之后发现不允许拍照的规定简直就是搞笑，这绝对是我见过的最黑的地方了，黑的我发昏。从清水寺出来，发现来时的路旁边有一个坂本龙马的墓地，可惜在反方向了。从金阁寺到岚山的巴士非常玄学，地图上指示坐59路可以到一个叫广泽池·佛大广泽校前的地方，然后走到嵯峨岚山驿，但是我们的59路实际上到了山越中町的一个山里的地方就拐进一个类似停车场的地方停了。我们只能走另一条59转11的路线，其中为了确定方向我们问了一堆日本人，不过大家都完全不了解。岚山小火车是从トロッコ嵯峨到トロッコ龟冈，其中トロッコ嵯峨可以对接到岚电岚山站或者JR岚山，其中JR岚山要近一些，但是岚电岚山那边要繁华一点。小火车快到站时，又看到下面农田里面的人群向我们挥手。从トロッコ龟冈站出来，发现这里荒得一批，只有一个巴士应该是去漂流的。于是我们果断往JR马堀方向走。坐上JR，发现其实是刚才的回头路，只不过观光小火车走的是老线，贴着崖壁走，而JR是新线，隧道多一点，但是也快很多。到了JR嵯峨岚山站时，又看到了来时候的火车站。。。我们在花园站下，然后走一段路去东西线终点站，这样能够省一点钱。在路上穿过大街小巷。同伴发现日本的电线杆上都贴了反光条，觉得这个是日本很人文的一个方面。从京都御苑出来就直奔八坂神社，晚上的八坂神社还是很好看的。那边是祗园地区，非常繁华，我觉得是除了京都站之外的另一个比较好觅食的地方。我们一边逛，一边用大众点评找吃的。晚上我用大众点评找的鳗鱼饭饭店叫かね正的店，拐到了一个阴森的小巷子里面，不敢进去，同伴后来发现这家店今天也停业了（京都是喜欢今天烧鳗鱼饭的都停业么），于是又换了同伴推荐的一家叫炭橹的店。这家店点了人均4000日元的鳗鱼套餐。应该是我觉得在日本吃过最好吃的鳗鱼饭了，它把鳗鱼烧得非常地脆，配上芥末和胡椒粉（有点檀木香），非常好吃。逛完花见小路，我们就乘坐巴士回宾馆。乘巴士途中见到一个穿白色斗笠拄着个拐杖的人上车（后来在奈良车站外面也看到了，这个人应该是修行者），气场超级强大。车快到宾馆的前一站，应该是这个人按了下车键，不过起身比较慢的原因，司机以为没人就关门了。这个人大喝一声XXXX，于是门又开了，这个人从容地在满车人的目光中下车了。 奈良(14)相比京都处处是景点，行程难以规划，奈良的路线简单粗暴很多，并且可以安排在从京都到大阪的路上进行游览。因为我们住在京都近铁东寺站附近，而近铁奈良是离奈良公园最近的电车站，所以在行程上我们走近铁是非常便利的。我们早上先退了房，然后走到旁边的东寺近铁站坐近铁直接到终点站近铁奈良站。在奈良站我们要给自己的IOOCA充值，这个不出站就可以充值了。出了站很容易就能找到储物柜，我当时带了一个书包和一个蓝色的登机箱，这种箱子一般至少要放600yen的柜子了。特别地，一般日本电车站的柜子最大是700的。并且我们去的时候正值大阪G20开会前，看到布告说在开会的前两天开始这些柜子就不给你用了。特别地，柜子只收100yen的硬币，但是我不可以找柜子对面的寿司店老板换，而只能到旁边的両替机上换。出了近铁站，走两步就到了奈良公园了。人行道上就开始出现小群的鹿。有的小鹿非常凶猛，在奈良博物馆旁边的广场上，一只小鹿直接咬上了我的衣服。路过平安神社时，同伴看到有人在洗手，便说自己也要去试试，结果发现这个要先买票。。。其实说到洗手，日本的神社在路边一般都会有一些水池，上面放一些木勺给你舀水洗手，不过这个洗手的地方是有点像咱们厕所里面自动冲小便池一排竹管。我们从一处台阶上去，眼前突然一片开朗，宛如置身在草原一般，这就是若草山。离开奈良去大阪的时候，因为我们民宿在天王寺（JR寺田町站）附近，所以坐JR反而方便。不过由于Google地图上近铁奈良和JR奈良靠的很近导致我们进了近铁的站，因此死活找不到自己要去的那个方向。最后还是问了人工售票的小哥哥，才搞清楚要在一个叫鹤桥的地方Change。鹤桥的日语很长，我们一遍进站台，一遍念叨，旁边路过一个中学生非常热情地帮我们指出了去鹤桥的电车。这辆车蛮快的，过了生驹，下一站就直接是鹤桥了。我们在鹤桥转乘JR线到寺田町站下。虽然近铁和JR是两个不同公司，但我们换乘只过了一次闸机，也就是一次闸机完成了近铁的出站和JR的进站。出了站，照例就是找宾馆。绕了一圈，通过找街区编号的方式找到了宾馆，原来我们的宾馆离寺田町超级近的啊，白走了半天！进大门就要输密码，然后要用自助吧台上的平板电脑扫描一下自己的护照以便完成登记。然后我们发现这个宾馆只能把鞋子放到一楼专门的地方然后光脚上去。整个二楼个楼道和公共走廊弥漫着一股塑胶跑道的气味，在公共区域有专门的淋浴间和洗衣房，我们以为没有独卫了，结果进门发现还是有的，并且是厕所在左，洗澡间在右，洗手台在中间的分离式设计，马桶同样是可以冲水的。晚上在房间里面看电视，这边的电视频道非常少，就十来个频道，甚至遥控器都是特制的，在9号键之后还有10、11和12的键。电视里面在卖地。 大阪(15-17)大阪建议采用1+1的方式购买乘车券。抽出一天时间买一个600（节假日）或800（工作日）的地铁券，逛逛那些不能用周游卡白嫖的景点，比如海游馆、USJ啥的。第二天买个2700的周游券专门白嫖和购物。大阪的交通可以记住红色的御堂筋线地铁，这条地铁串联了从南到北的几个重要地点：新大阪-梅田(JR大阪)-心斋桥-难波(なんば)-天王寺。虽然我们的宾馆离寺田町很近，我们还是去了天王寺站。在大阪的第一天，我们没有买周游卡，而是买了大阪地铁的One day pass。主要是考虑那天行程有大阪城，用周游卡不太划算。在大阪的第二天，我们选择买了那个一天的周游卡，这是因为我们估算了一下景点感觉想玩的一天能搞定，第二个是一日券可以坐一些私铁（虽然最后我们全程是地铁）。在昨天晚上，我们在天王寺站问了售票员这票哪里买，结果那售票员叫我们等会，然后在办公室里面翻出来给我们，于是我们怪不好意思地说能不能明天去买。结果今天早上我们迷路了并没有找到昨天的小姐姐，所以我们就随便找了一个售票员。那个售票员不太懂英文，比划了半天听懂一个Master，加上他又使劲和我笔画里面的驿长室，于是我们直接越过检票机进去找驿长。过程很顺利，得到的周游卡是一个包装精美的信封，里面有本体和一张大阪地图，上面画了周游卡适用的所有景点的位置。早上起来，终于见到了我们的房东，是两个妹子，非常热情，问我们从哪里来和今天行程，我说我们打算逛逛大阪城。她们纷纷夸我口语好，我很感动，但是考虑到整个旅程中和日本人英语交流的感受，我觉得还是不要当真为好。。。先坐的是道顿堀的水上观光船，售票点在那个堂吉诃德的摩天轮下面，我们昨天已经考察过了，所以轻车熟路。预约了时间之后，我们就直接上了船，讲解员阿姨亲切地过来帮我们拍照。船行主要是绕着那条河转一圈，让你看看大阪的桥。期间讲解员一直在用日语说笑话？反正我是听不懂。船行过程中，两岸的人一直在朝我们友好地挥手，这我们在前几天的行程中也是一直体验到的，但是竟然有一个中学生追着船和我们打招呼，这让我觉得很意外和有趣。果然关西地区的人要比关东地区的要热情很多的啊！船转过弯来，讲解员问船上有哪些人，结果中韩新欧所有。接着她就教了几句关西腔，比如谢谢おおきに，多少钱なんぼ这类的。接着我们绕了一圈想找剩下的几个船，走日本桥那边到了河对岸，发现一个人正在接来船，便上去问这个是不是WONDER CRUISE，那人英语不错，又看面相应该是从印度这类地方过来留学的人。他说这里是PIRATES OF OSAKA，然后这个和WONDER CRUISE还不冲突，售票亭就在前面。我们想了想就过去预订了一个九点半的票。这时候时间不早了，同伴就想去吃饭了。结果我们找到一家在御堂筋旁边的10楼的烤肉店。这家店在一个唐吉坷德的楼上，不过我们坐电梯只能按到9楼，也就是叫すたみな太郎的店。从电梯下来，问了堂吉诃德门口的保安(?)，他热情地说坐电梯就行啦，还准备帮我们进去按，我们没懂他说没意思，想着应该是说坐对面的电梯吧，于是又试了一次，还是只能到9楼。再下来，那个小哥说那家店不开。。。所以虽然心斋桥道顿堀这里吃的很多，但我们并没有成功觅食，所以我说我们还不如坐WONDER CRUISE去别的地方吃饭呢，于是我们绕回到刚才PIRATES OF OSAKA小哥在的地方，在附近换了WONDER的票。不得不说，这艘船真的蛮有趣的，我们一路沿着阪神高速下面的河走，看到了更多的桥，并且经过了一个船闸。我们在船靠岸的一个电车站的商场里面看到一家鳗鱼饭，同伴有点想吃，不过我不太想吃重复的，便又在大众点评上看了一家，好不容易走过去发现这家店也太便宜点了吧，果断放弃，回去吃鳗鱼饭。这家鳗鱼饭烧得有点嫩了，感觉没有上次的好吃。吃完饭，准备去大阪城坐御座船。结果只剩两个场次的各一个座位，只好悻悻离去。下面就是去梅田附近了。我选了个绢谷幸二的博物馆和梅田蓝天大厦观景台，他们其实都在梅田大厦上面，只是要从不同的塔上去。出了电车站，发现这里和香港有点像，通过很多的天桥将各个商业中心连接在一起。有个商城卖很多数码产品，包括天文望远镜啥的也都有，看了看，价格其实还蛮贵的。那边好像在搞什么隧道之类的工程，我们过街要穿过一段看起来是临时的道路，旁边用铁丝网隔开。但相比中国的工地而言要感觉很多，既没有满天的灰尘，也没有满地的杂草。绢谷幸二的博物馆感觉差强人意，我们需要寄存行李，然后在入口处看一段短片（居然还是3D的）。然后里面有很多作品，我们吃了没有文化的亏，都没有能够看懂。。。 17号是在大阪的第三天，也是我们的返程日。早上又看了会电视，里面在放街头采访。]]></content>
      <tags>
        <tag>游记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的重要科学计算库Pandas]]></title>
    <url>%2F2019%2F05%2F16%2Fpandas%2F</url>
    <content type="text"><![CDATA[Pandas库用来实现对CSV的快速处理，其在numpy之上提供了index和column机制。 类型系统1df.dtypes 得到 如果显示类型为object，则可能是混杂的类型 Series对象的相关性质相关成员1df = pd.DataFrame([[1, 2], [3, 4]], index=['aa', 'bb'], columns=['a', 'b']) name 表示这个Series的名字。如果Series是从pd.Series构建的，等于传入的name参数的值，默认为空。如果是从DataFrame得到的，对应的是column或者index的值。 index 输入输出输入可以使用下面的方式实现条件加载，其中lambda chunk读取chunk这个DataFrame，判断它最后一行的id值，如果小于MAXN就继续读下一个。123chunks = pd.read_csv(xxx, sep=',', skiprows=0, chunksize = 200)chunks = itertools.takewhile(lambda chunk: int(chunk['id'].iloc[-1]) &lt; MAXN, chunks)df = pd.concat(chunks) 【这个方案不行，chunk.index.get_indexer_for只是返回局部的index，所以还得用一个全局的tot来标记】当然，如果没有id这一列，而只要单纯的前maxn列，则可以1chunks = itertools.takewhile(lambda chunk: (chunk.index.get_indexer_for(chunk.index) &lt; maxn).any(), chunks) 其中的chunk.index.get_indexer_for可以换成1df.index.get_loc(index_name) 输出12with pd.option_context('display.max_rows', None, 'display.max_columns', None): print pd 以Excel表形式输出可以借助于pd.ExcelWriter组件来将DataFrame输出成Excel表。首先创建一个writer1writer = pd.ExcelWriter(u"&#123;&#125;.xlsx".format(name), engine='xlsxwriter') 然后导出到一个sheet中，注意sheet_name的长度是有限制的1df.to_excel(writer, sheet_name=sheet_name) 我们可以通过writer对已经导入的进行进一步修改。在下面的代码中，我们创建了一个图标chart_cmp，这个图标中包含了predict和real两个系列的数据，分别位于B列的第2到42行，和C列的2到42行。12345678workbook = writer.bookworksheet = writer.sheets[sheet_name]chart_cmp = workbook.add_chart(&#123;'type': 'line'&#125;)chart_cmp.add_series(&#123;'name': u"predict", 'values': '=&#123;&#125;!$&#123;&#125;$&#123;&#125;:$&#123;&#125;$&#123;&#125;'.format(sheet_name, "B", 2, "B", 42)&#125;)chart_cmp.add_series(&#123;'name': u"sreal", 'values': '=&#123;&#125;!$&#123;&#125;$&#123;&#125;:$&#123;&#125;$&#123;&#125;'.format(sheet_name, "C", 2, "C", 42), 'y2_axis': 1&#125;) 接着，我们可以指定主要坐标轴和次要坐标轴。1234chart_cmp.set_y_axis(&#123;'min': 0.4, 'max': 0.6&#125;)chart_cmp.set_y2_axis(&#123;'min': 0, 'max': 1&#125;)worksheet.insert_chart('F2', chart_cmp)writer.save() 交互原生数组和DataFrame转换可以通过一个字典创建DataFrame，这时候传入的字典是按照列来组织的。可以指定数据和列名（甚至index）创建DataFrame，这时候传入的数组是按照行来组织的。123456df = pd.DataFrame(data=[[1,2,3],[10,20,30]], columns=["a", "b", "c"])&gt;&gt;&gt; df&gt;&gt;&gt; df a b c0 1 2 31 10 20 30 ndarray和DataFrame转换从DataFrame到ndarray可以用12df.valuesdf.to_numpy() 调试查看所有的列，注意直接输出d.columns会返回一个Index，不是简写的，所以很难看。1d.columns.values 不限制打印行数1234pd.set_option('display.max_rows', None)pd.set_option('display.max_columns', None)pd.set_option('display.width', None)pd.set_option('display.max_colwidth', -1) 索引与选择Axis和numpy一样，Pandas的axis表示受影响的是哪一列。我们可以这样去记忆，假如一个三维的DF，我们求sum(axis = 1)，那么必然是axis这一列没了，压成了scalar。那么我们往回带入到二维的情况，axis = 0时，相当于行被压没了123456789&gt;&gt;&gt; df = pd.DataFrame([[1,2],[3,4]])&gt;&gt;&gt; df 0 10 1 21 3 4&gt;&gt;&gt; df.sum(axis=0)0 41 6dtype: int64 对于二维数组的concat，那么就是axis=1受影响，也就是两个列拼在一起1pd.concat([c1, c2], axis = 1)) 选择loc的标签选择.loc主要有几点用法。 首先可以接受一个Label，或者一个Label数组，或者一个Range。用来索引DataFrame中的某一行 12345678import pandas as pdimport numpy as npdf = pd.DataFrame([[1, 2], [3, 4], [5,6]], index=['a', 'c', 'b'], columns=['a', 'b'])&gt;&gt;&gt; df a ba 1 2c 3 4b 5 6 使用loc[]，得到一个Series，表示选择的row。 123&gt;&gt;&gt; df.loc["a"]a 1b 2 使用loc[[]]，得到一个DataFrame，表示所有选择的row。 1234567&gt;&gt;&gt; df.loc[["a"]] a ba 1 2&gt;&gt;&gt; df.loc[["a", "b"]] a ba 1 2b 5 6 可以选择从&#39;a&#39;到&#39;c&#39;之间的行。 1234&gt;&gt;&gt; df.loc['a':'c'] a ba 1 2c 3 4 我们可以同时传入两个维度 如果这里面有一个是Label，那么就会降一维，如果是一个List或者Range，那么维数就不变。 得到一个Series 12345&gt;&gt;&gt; df.loc['a':'b', 'a']a 1c 3b 5Name: a, dtype: int64 得到一个DataFrame 12345&gt;&gt;&gt; df.loc[:, ['b']] ba 2c 4b 6 得到一个Series 123&gt;&gt;&gt; df.loc['a', ['b']]b 2Name: a, dtype: int64 我们可以传入一个Bool数组，作为Mask，表示需要哪些行和列 下面的代码中，我们选择的是第0/2行、第1列，由于我们是通过List来调用的，所以返回的是DataFrame。 1234&gt;&gt;&gt; df.loc[[True, False, True], [False, True]] ba 2b 6 我们也可以指定一个较短的数组，后面会默认是False。同样得到DataFrame。 123&gt;&gt;&gt; df.loc[[True, False], [False, True]] ba 2 对Series的补充说明 此外，loc也可以用在Series上，这时候我们得到Scalar 12s.loc['B'] # 得到一个numpy.float64s['B'] # 得到一个numpy.float64 中括号__getitem____getitem__的作用和loc有差别。我们进行下面的比较。可以发现，当传入一个Label时，loc默认这个Label是行，而__getitem__默认是列12345&gt;&gt;&gt; df = pd.DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['a', 'b'])&gt;&gt;&gt; df a ba 1 2b 3 4 对于loc，返回的是a这一行1234&gt;&gt;&gt; df.loc["a"]a 1b 2Name: a, dtype: int64 对于__getitem__，返回的是a这一列123&gt;&gt;&gt; df["a"]a 1b 3 当我们传入一个List of Labels的时候，情况也是相同的。12345678&gt;&gt;&gt; df.loc[["a"]] a ba 1 2&gt;&gt;&gt; df[["a"]] aa 1b 3Name: a, dtype: int64 条件选择可以通过以下的方式进行条件选择，或者判断有多少项满足条件。 借助于Bool数组一个简单的方法就是借助于Bool数组去Mask，这也是数据处理中常见到的用法。123456&gt;&gt;&gt; df['a'] == 1a Trueb False&gt;&gt;&gt; df.loc[df['a'] == 1] a ba 1 2 通过下面的方法可以计算DataFrame某一列中满足某些条件的有多少个1234567891011df = pd.DataFrame(&#123;"class":[1,1,1,2,2], "value":[1,2,3,4,5]&#125;)# 或者df[df['class']==1]，见后面对`__getitem__`的讨论&gt;&gt;&gt; df[df.loc[:,'class']==1] class value0 1 11 1 22 1 3&gt;&gt;&gt; df[df.loc[:,'class']==1].sum()class 3value 6dtype: int64 借助于where当我们需要计算Series的某一行满足条件的有多少个时，可以使用where来做。下面语句的意思是过滤df里面大于1的值，如果有不满足条件的，那么就将它的值改为1001df.where(df &gt; 1, 100) 特别地，where还有简化版，下面两个函数分别将未匹配的和匹配的改为NaN。123456789101112131415s = pd.Series(range(5))&gt;&gt;&gt; s.where(s &gt; 0)0 NaN1 1.02 2.03 3.04 4.0dtype: float64&gt;&gt;&gt; s.mask(s &gt; 0)0 0.01 NaN2 NaN3 NaN4 NaNdtype: float64 因此我们可以用下面的语句来计算满足条件的个数1s.where(condition).count() 复杂条件选择可以使用&amp;和|等符号。需要注意，Python中的in不再使用，需要替换成.isin。例如判断group的field系列里面是否有值是在lst之中的。1df['field'].isin(lst) 当需要判断单个值的时候会简单点，例如判断在group的field系列里面是否存在0这个值。10 in group['field'].values ix得到一个Series1df.ix[0] 比较在条件选择时涉及比较问题，我们分类讨论，设置1df = pd.DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['a', 'b']) 与None比较在比较1df == None 会产生如下的错误，所以1TypeError: Could not compare [None] with block values 要使用1df is None 这也是在Python中常常需要注意的一点 使用Callable123456&gt;&gt;&gt; df.loc[lambda df: df.a &gt; 2, :] a bb 3 4&gt;&gt;&gt; df.loc[lambda df: df["a"] &gt; 2, lambda df: df["b"] &gt; 3] bb 4 使用Apply/Transform对于更复杂的情况，我们可以借助于DataFrame.apply，能接收一个自定义化的函数。具体参看下文 iloc相比loc，iloc提供了通过从绝对位置开始，而不是根据label的索引方式。 增删改查数组合并/连接append和concate默认是纵向连接，也就是结果中column是不变的，但是row变多了。merge默认是横向连接，也就是column变多了，但row不变。 append在数组连接的时候，需要特别注意索引的问题。在进行concat/append的时候，要非常注意索引。如果我们希望实现类似numpy一样的数组合并，那么最好对合并的每一项都进行.reset_index(drop=True)。 下面的代码会报错TypeError: Can only append a Series if ignore_index=True or if the Series has a name。12345df = pd.DataFrame(&#123;'A' : [1, 2, 3], 'B': [4, 5, 6]&#125;, index = [1, 2, 3])df2 = pd.DataFrame(&#123;'A' : [1, 2, 3], 'B': [4, 5, 6]&#125;)ser = pd.Series([7, 8])df.append(ser)df2.append(ser) 那我们加上name可以么？我们发现，append是默认添加一行的，但我们的Series不带columns属性。所以尽管我们预期的是将7和8添加到66行的A和B列上，但实际上新的DataFrame多了两列。1234567&gt;&gt;&gt; ser = pd.Series([7, 8], name=66)&gt;&gt;&gt; df.append(ser) A B 0 10 1.0 4.0 NaN NaN1 2.0 5.0 NaN NaN2 3.0 6.0 NaN NaN66 NaN NaN 7.0 8.0 于是解决方案应运而生，我们重置一下Column就可以了。这个方法就是将矩阵转置，然后去重置Index，然后再转置回来。1234567&gt;&gt;&gt; df = df.T.reset_index(drop=True).T&gt;&gt;&gt; df.append(ser) 0 10 1 41 2 52 3 666 7 8 事实上我们构造一个DataFrame，会更简单。但是由于DataFrame的构造函数在这里是以列为基础的，所以下面的语句写起来并不舒服。1234567&gt;&gt;&gt; delta_df = pd.DataFrame(&#123;'A': [7], 'B' : [8]&#125;, index=[66])&gt;&gt;&gt; df.append(delta_df) A B1 1 42 2 53 3 666 7 8 特别地，当我们添加的Series长度和原来的DataFrame不同时，会自动进行扩展。123456789&gt;&gt;&gt; df = pd.DataFrame(np.random.randn(1, 3)).T.reset_index(drop=True).T&gt;&gt;&gt; df.append(pd.Series([5]).reset_index(drop=True), ignore_index=True) 0 1 20 -1.737655 0.016943 -1.1318911 5.000000 NaN NaN&gt;&gt;&gt; df.append(pd.Series([5,6,7,8]).reset_index(drop=True), ignore_index=True) 0 1 2 30 -1.737655 0.016943 -1.131891 NaN1 5.000000 6.000000 7.000000 8.0 concate另一个用来做数据合并的是concat，它相当于是append的升级版。我们最好将concat理解成关于Index的Join而不是简单的拼接。pd.concate可以指定ignore_index参数控制是否对concate之后的数组重新编号。 mergejoin增加append删除drop可以通过drop来删除列，这样的删除不是inplace的。当然，我们也可以指定inplace参数。12df = pd.DataFrame([[1, 2], [3, 4], [5,6]], index=['a', 'c', 'b'], columns=['a', 'b'])df.drop(columns=["a"]) 注意上面的columns不能省略，也不能直接通过指定axis=...的方式省略，否则会出现下面的错误。1KeyError: "['a'] not found in axis". 同理，我们可以用下面的命令删除行12df.drop(index=["a", "b"])df.drop("a", axis = 0) pop这个函数是返回被pop的列（作为Series），同时inplace地去掉被pop的列。这个函数可定制范围比较小，不能接受数组。1234567891011&gt;&gt;&gt; df = pd.DataFrame([[1, 2], [3, 4], [5,6]], index=['a', 'c', 'b'], columns=['a', 'b'])&gt;&gt;&gt; df.pop("a")a 1c 3b 5Name: a, dtype: int64&gt;&gt;&gt; df ba 2c 4b 6 遍历可以使用iteritems来遍历Series12345678910ser = pd.Series(np.random.randn(4), index = [2, 3, 4, 5])for x in ser.iteritems(): print x```Python返回得到`(index, scalar)`组成的tuple。```Python(2L, -0.6139561000254863)(3L, 0.5896349094946916)(4L, 0.38098846567708866)(5L, -0.5556287680764356) 下面的代码对DataFrame按列进行遍历123df = pd.DataFrame(np.random.randn(2, 2), columns=['A', 'B'], index = [2, 3])for x in df.iteritems(): print x 返回得到(column, Series)组成的tuple。123456('A', 2 0.6370963 1.376316Name: A, dtype: float64)('B', 2 -0.6981153 1.403478Name: B, dtype: float64) 对GroupBy对象进行遍历的结果情形将在GroupBy中单独讨论。 替换根据Pattern替换可以使用to_replace函数 查找替换swap可以借助于loc来实现列与列之间的交换，如下1df.loc[:, [col1, col2]] = df.loc[:, [col2, col1]].values Map系列操作基于ApplyDemo设置1df = pd.DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['a', 'b']) Apply的声明如下1DataFrame.apply(self, func, axis=0, raw=False, result_type=None, args=(), **kwds)[source] 其中： raw为True表示传入的是ndarray，否则是pd.Series result_type 通过Apply查找DataFrame.apply函数方法接收一个axis，表示这个函数会对哪一个轴去apply。例如在下面的语句中，当axis为1时，就是对列去apply。这时候就会遍历所有的行，对于每一行row的所有列去应用lambda函数。1234def P(x): print("---&gt;", x) return Truedf[df.apply(P, axis=1)] 可以看到，每一次遍历是针对的一行中的所有的列。123456789('---&gt;', a 1b 2Name: a, dtype: int64)('---&gt;', a 3b 4Name: b, dtype: int64) a ba 1 2b 3 4 如果我们需要找到所有的行中，对应row[&#39;a&#39;]的值在[3, 4]中的所有row，那么可以使用下面的方法。123&gt;&gt;&gt; df[df.apply(lambda row: row['a'] in [3, 4], axis=1)] # 得到一个DataFrame a bb 3 4 通过Apply变换在找到之后，我们就可以单独对这些列进行变换，例如我们需要将每一列中所有大于等于2的class的值设置为0，除了where，还可以用下面的办法123456789101112131415df = pd.DataFrame(&#123;"class":[1,1,1,2,2], "value":[1,2,3,4,5]&#125;)def handle(row): if row["class"] &gt;= 2: return row else: row["class"] = 0 return row &gt;&gt;&gt; df.apply(handle, axis = 1) class value0 0 11 0 22 0 33 2 44 2 5 上面的做法实际上是对每一个row去map，修改对应的column项目的值，那么能不能把column选出来进行apply呢？执行下面的函数12345def handle_item(item): if item &gt;= 2: return item return 0df["class"].apply(handle_item) 我们发现输出如下，并且再打印df，也是和原来一样的，所以apply是不是inplace的。1234560 01 02 03 24 2Name: class, dtype: int64 实现安全除法我们可以基于apply实现安全除法，当除数是0时，设置默认值0.512345678910df = pd.DataFrame(&#123;"a":[1,1], "b":[0,2]&#125;)def sdiv(row): if row["b"] == 0: return pd.Series([0.5]) return pd.Series(row["a"] / row["b"]) &gt;&gt;&gt; df.apply(sdiv, axis = 1) 00 0.51 0.0 注意Series.apply没有axis参数，所以如果传入的话会报错1TypeError: &lt;lambda&gt;() got an unexpected keyword argument 'axis' 在Apply过程中获得全局信息有的时候，我们需要知道回调函数中传入的row的的相对Index和绝对Index，这个如何来做呢？ TransformAggregate/Reduce系列操作下面的方法可以求出某些列的值12345df = pd.DataFrame([[1,2,3],[10,20,30]], columns=["a", "b", "c"])&gt;&gt;&gt; df[["a", "c"]].sum(axis = 1)0 41 40dtype: int64 或者我们可以借助apply1234&gt;&gt;&gt; df[["a", "c"]].apply(lambda x: x.sum(), axis=1)0 41 40dtype: int64 groupby在Pandas中，对整行和整列进行处理是简单的，但有时我们需要对局部的行或者列进行某些处理，而对另外的行或者列进行另外的处理。一个简单的思路是将需要分开处理的逻辑放到不同的group里面进行处理，除了filter出来之外，另一种方法是groupby。 相关参数1df = pd.DataFrame([[1, 2], [2, 3], [1, 4], [1, 3]], index=['aa', 'bb', 'cc', 'dd'], columns=['a', 'b']) 1DataFrame.groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs) group_keys as_index 默认为False。 groupby的返回值是DataFrameGroupBy或者SeriesGroupBy GroupBy对象相关字段 ngroups 获知到底有多少个group产生。 12345&gt;&gt;&gt; g.ngroups2&gt;&gt;&gt; g.groups&#123;(1L, 2L): Int64Index([0], dtype='int64'), (3L, 4L): Int64Index([1], dtype='int64')&#125; 遍历groupby会返回一个GroupBy对象，我们可以对该对象进行遍历，得到的每一项是(key, group)这样的tuple。key表示我们用来groupby的key，如果我们选择一个key来groupby，那么key就是一个scalar，否则，key就是一个tuple。group是一个DataFrame。1234567&gt;&gt;&gt; df = pd.DataFrame([[1,2],[3,4]], columns=["a", "b"])&gt;&gt;&gt; df a b0 1 21 3 4&gt;&gt;&gt; df.groupby(["a"])&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000000005E53668&gt; 下面的代码对df的a这个column进行groupby，可以看出g中仍然包含了a这个column。12345678&gt;&gt;&gt; g = df.groupby(["a"])&gt;&gt;&gt; for i in g:... print i...(1L, a b0 1 2)(3L, a b1 3 4) 还可以指定多个column12345678&gt;&gt;&gt; g = df.groupby(["a", "b"])&gt;&gt;&gt; for i in g:... print i...((1, 2), a b0 1 2)((3, 4), a b1 3 4) 组内编号还有一个常见场景是对GroupBy之后的每个组内的元素进行编号。可以通过GroupBy.cumcount函数来实现。 过滤可以基于DataFrameGroupBy.filter进行过滤，但得到的就是一个DataFrame，原来的GroupBy语义会被去掉。 随机算法取样Reference https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html?highlight=dataframegroupby https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.where.html https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html]]></content>
      <tags>
        <tag>python</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异星工厂铁路建造技巧介绍]]></title>
    <url>%2F2019%2F04%2F28%2Ffactorio-railway%2F</url>
    <content type="text"><![CDATA[异星工厂(Factorio)是一款有趣的游戏，随着游戏进程的发展，通过铁路实现超远距离的快速矿物货运的方式相比传送带和物流机器人有着稳定（高速运行的火车相比虫子可以说是无敌）、快速的特点。目前有关异星工厂铁路介绍的相关资料鱼龙混杂，缺乏系统性。为此，我总结了火车建造中的常见场景，并针对这些场景设计了对应的建造思路，以便玩家能够尽快建设自己的铁路物流系统。 火车站的设置铁轨本身是没有方向的，但火车站是有方向的，火车仅能够停靠右边的火车站。如下图所示，在放置火车站时，黄色箭头指向了该火车站服务的范围。在许多时候出现的“找不到路径”的问题就是因为火车站和火车头是反方向的。 为了一条铁轨两个方向的来车都能在一个位置停靠，可以如下图所示在两个方向设置两个火车站，并且将这两个火车站取相同的名字。 信号灯的行为信号灯分为红绿灯（常规铁路信号）和连锁灯（连锁铁路信号）两种。其中红绿灯用来将铁路分为若干闭塞区间，每段闭塞区间中只允许一辆火车通行，连锁灯用来将前方红绿灯的信号向后传播，从而允许后方列车根据前方情况提前行动，让出自己的一部分铁路资源，从而避免铁路死锁。注意，车站并不能划分闭塞区间，所以我们需要在车站旁边显式放置信号灯。特别地，连锁信号灯除了红黄绿之外还有一种蓝色。蓝色的信号灯发生在自己的前方区段同时具有红灯和绿灯的情况下。如下图所示，蓝色的连锁信号灯管控图右侧的上下两个红绿灯，这些红绿灯分别为红色和绿色，那么总管这两个道口的连锁信号灯即显示为蓝色。当来车经过蓝色信号灯时，它会判断如果自己能从后方的绿色信号灯通过，那么就出发，否则就立即停止在这个信号灯处。这里的立即表示一旦火车确认自己无法到达，就会立即停止移动。如下图所示，火车虽然无法到达最右边的火车站，但它原则上是能够通过第一个蓝色连锁灯直到停止在第二个蓝色连锁灯之前的，但它选择在第一个蓝色连锁灯前停止。铁轨本身是没有方向的，但在加入信号灯后，可以使某段铁轨只接受一个方向的来车。如下图所示，在放置了一个红绿灯和连锁灯后，铁路被设定为往地图左侧单向通行的。在下图中，火车可以通过信号灯，这是因为信号灯是绿色的。在信号灯左侧为红线，这里的红线不是对应于红灯的红，而是对铁路区间的一种标记，不同颜色标记的铁轨属于不同闭塞区间。在下图中，使用了相向的两个红绿灯将铁路分成了三个区间，可以看到在相向红绿灯的划分模式下这些区间就不具有方向属性了。整个铁轨被无副作用地分成了三个闭塞区间。 单线单向铁路与多线单向铁路的切换向主线汇入当支线汇入或汇出主线时，会产生单线单向铁路与多线单向铁路的切换问题。如下图所示，主线上从左往右设有两个火车站A和B。两列火车竞争地汇入主线。目前前面的火车已经进入主线，此时红绿灯1显示为红色，这阻止了后面列车的继续前进入主线。前面列车仍然可以前进如站B，这是因为它的前方并没有阻碍，所以红绿灯2是绿色的。随着前方列车进入车站B，红绿灯1便会先变绿，后方列车进入区间并到达站A，红绿灯1重新变红。 由主线分出由主线分出是另一种情况，常见于装卸货系统的终端。如下图所示，我们将铁路终端的两个火车站都命名为C，这样当我们可以将火车驶入任意空闲的火车站C。目前，上方岔道的红绿灯与主线红绿灯之间有一辆火车，这导致主线的列车无法进入火车站。对于以上问题，我们需要将红绿灯从主线上移出，放入每个支线的入口处，这样就可以实现从主线到支线的分流。另一种办法是将主线上的红绿灯改为连锁灯。 单线双向铁路与双线双向铁路的切换限于资源的有限，大多数时候只能在家里和矿区终端修建双线铁路，而大部分的路程都要修单线铁路，在处理双线铁路和单线铁路的交界处时的思路是将该单线铁路当做一整段闭塞区间来处理。此时这个单线铁路中只允许一辆列车通过，否则很难避免相撞，我们不能想当然地觉得先来后到鱼贯而行就行，因为列车不一定是匀速的、速度相同的。如下图所示，左侧为双线段，其上支线接受往左驶出单线段的列车，下支线接受往右驶入单线段的列车。容易看到，目前单线段中存在一辆列车，因此驶入支线的红绿灯为红，表示后方列车无法进入单线段，而驶出段红绿灯为绿，否则单线段中的列车无法回到双线段中。 长单线铁路的避让车道在前面提到，所有的单线段中都只能容纳一辆列车，否则很难避免相撞，但对于一个长的单线，如果一次只能容纳一辆列车，那么势必是浪费资源的，为此我们需要设置避让车道，从而增加长单线铁路的吞吐量。如图所示，下方的支线铁路为长单线铁路的主线，而上方的一段则为避让车道。我们希望当单线铁路中有列车时，左向的列车会进入避让车道等待，等到右向列车通过后再进入主线行驶。当右向列车重新进入主线后，主前方不再出现挡道的左向车辆。为此，我们首先通过信号灯3和4将中间这段铁轨变为双线双向，从而往左的走上面避让车道，往右的走下面主线。为了使得最后的铁路重新回到单线双向，我们使用信号灯1取消铁轨的方向性。这里还需要说明一下连锁灯3的作用，当不使用连锁灯3时，火车遇到1处的红灯会停下，但这导致了火车头会阻塞一部分的主线，从而两辆车形成死锁。为此，我们使用连锁灯复制了1处的红灯信号，将其往后传递，这样左向的列车可以完整地停泊在避让车道中。 单线双向铁路的交叉（不涉及互通）单线铁路的交叉问题主要涉及两个方面，第一个是对交叉点的保护，第二个是对单线上双向列车的保护。对于第一个问题是很好解决的，我们依葫芦画瓢，使用一圈红绿灯将交叉路口保护起来即可。如下图所示，交叉口被独立为一个红色区间进行保护。第二个问题就显得不是那么轻而易举，如下图所示，当十字路口中出现相向而行的两辆列车时，整条路就被堵起来了。解决这个问题的方案等价于在交叉口的两边建立避让车道。下图中将红绿灯处的信号传播到避让车道和主线的交汇处，从而阻止左向的列车驶出避让车道。但是对于这种情况，当左边的车还未驶入交叉口的时候，右边的车可能错误地驶出避让车道。针对这种情况，我们使用如下图所示的方案进行解决。注意到左向的红绿灯被换为了连锁灯，这样可以尽快将交叉口对面的情况传递过来。由于右向没有避让车道，是优先于左向的，所以这里只采用红绿灯以避免与垂直方向的来车相撞。这里给出了一个完整版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 双线双向铁路的交叉（不涉及互通）双线双向铁路的交叉可以看做四个单线单向铁路的交叉，这些交叉还不涉及一条线上不同方向车的互相避让，因此很简单，本文给出实现如下10eNqdmdtO20AURf9lnh00c8Zzy3f0raqqABa1BE6UOKgI8e+1cysxO/LZPEEgWTn32T7zbu6f981m23a9Wb6b9mHd7czy57vZtU/d6nn8W/+2aczStH3zYirTrV7GV9tV+2w+KtN2j81fs3QfvyrTdH3bt83x84cXb7+7/ct9sx3ecPnkw3772jwuDoDKbNa74TPrbvyigbMIlXkbfkgY2I/ttnk4/jN+VF+QokN6TPSA6C/EXT/Anv70t8zMJ6hcQxOA1lpoxEwHmEEZTeeOTFfmmVHHLBciYCR1AJ2cODXi5Ks6W5xqEVDsXThz7iYJrgG36Lj5igo4zmodHd9520+nbQt3Drub7wsn+izUJ+yk5gRhPZ9cgU7X3wHN2xf0WEtgIzsUVFR9p0SCmtVUJvFFTSXSJeoWIpIlTgtlLFX3ExFU8eSxoIKqO4soVQn0rINtL/EbnHnr1I3EzBLJurk8tjEay0hcCNFGJ1PzvLrwVntU1pdDzd4p1JV3/JS2KO9elBYW0kBPi4Si0Qj+fxONfneLXb/e3J5KdlJN1RCu1fF388Mb9AVBZ3gi4xFJcVOwtvGJ7lOcd6WIc0L6qe4jsbCNkPitrVKIycnWoGDyHZRRIGthE4IxXuei+LOHCMJrtwg59KGCMZE2B+rwmq55jMm0OfCorAtrDsQEsqj9/HAMdE3D2RBENWPPQn2csZ+mao2mavAqZL4AP3t6hReIr8mUYL8D1YOThAREpDsAlwrbAJhC1z9so8CWP6REy+qtOB/uSD6wl3kFF4UNGhyF0ZNBw5SaEr5lXkrHQB7XcV5Kx8iK3jxVFtBUen0FD9qYScGrM66wcjdp1G6yukl89vdanl3NTYfmZnKc2FXFIgkndRNWuoltGZjuVJM6V+diYJd4X55EEJU+LbC2T+kbnHnrMrvBU1ELucDTQLMl93cqqCPXdyqokNs7FdRzyzsVs+Z2dypm4FZ3KmbkNncqZuIWdypmJqcbbvVceMysbcWSWzsVlH42wYvKIuxJO452xeWT506tAxVx2EeRG26Sl4guKVykLhGnRCS4SyKnt1gFNFO30eLnVXwpzG30lAivXazlBs3Ucz/eyR9u7ZefLvkr89psd0f5lpNIdsWmoUD+AfZ7ciM= 单线铁路的丁字互通一个简单的单线铁轨的丁字换乘如下图所示，但它是可能产生死锁的。下图中前往R1和R3互相对峙，导致中间三角被前往R3的列车占用，进而导致本可以正常前往R1的列车无法进入三角。考虑到一般丁字互通来源于对一条单线铁轨引入了分叉，所以我们可以在分叉点往第三个方向用红绿灯保护起来。这样子等于牺牲了来往第三个方向火车的通畅度。一个完整的解决方案需要进行两个改造。第一点，我们需要将中间的三角形拆分为三个独立区段，这样位于三角形一个角的拥塞不会阻塞这个角所对的边的正常运行。但这种情况仍然不能阻止R1-&gt;R2和R2-&gt;R1的对向列车阻塞在R1或R2的入口处。如下图所示，分别前往R1和R2的两辆列车在R2入口处形成对峙，而R1&lt;-&gt;R3向的列车仍然可以正常行驶。经过进一步思考，我们发现下图中用红色标注的铁路线是唯一的沟通R1和R2的线路（互斥条件）；一个从R1出发前往R2的列车首先已经锁住了R1这个火车站，为了前往R2，它又需要锁住R1-&gt;R2整条线（请求与保持条件）；即使当本列车到达R2之后，R1站仍然被锁住（不可剥夺条件）；此时从R2站又有一辆列车希望前往R1站（等待链条件）。因此这是一个典型的死锁场景，考虑到后三个条件是固定的约束，所以最好的办法是破坏第一个条件，也就是部分引入双线（避让车道）。 下图中展示了使用避让车道情况下的一个死锁问题，此时最左边的车（停在S2）即将前往S3、S1、S2，最右边的车（停在S3）即将前往S1、S2、S3，中间的车即将前往S2、S1、S3。即目前的线路是S2-&gt;S3、S3-&gt;S1、X-&gt;S2使用避让车道情时需要小心避免活锁问题。如下图所示，左边列车从S2到S1，上面列车从S1到S2，右边列车从S3到S1。我们以左边和上边的列车为例进行考虑，左边的列车要往上走，上边的列车要往左走，这两个方向是冲突的。根据连锁灯的性质，当前路不通时，列车会立即停止，于是两列火车都停在三角形的入口之外。事实上我们发现如果允许其中一列列车进入三角区，那么就会让出一条路线供另一列列车到达目的地了。因此，解决这种活锁的方案是采用FIFO的方法，赋予某一个方向的线路以优先权。在下图中，我们设置优先流动方向为顺时针，并修改了三角形左上边的部分连锁灯灯为红绿灯，如图所示。 在更改了三条边之后，最终的方案蓝图如下所示10eNqdnN1OG0kQRt9lrm00Xf3Pa+RyFa0IWIklYhCYaKOId1+Dx2BMwZwvdyEJxzVdVd1VXZ/nz/Dt+mF1e7febIfzP8P68mZzP5z/82e4X3/fXFw//d329+1qOB/W29XPYTFsLn4+/XR3sb4eHhfDenO1+m84D49fF8Nqs11v16v97z//8PvfzcPPb6u73X94+c3Lh7tfq6vlM2Ax3N7c737nZvP0QTtOXAy/h/Nl6jv01fpudbn/t/K4eEc0RgzBR0YHGV+Q99sd7fuP7QfQcWKWt8zqMBNlhuRDgwPN7NmXh+WM88gCl7O+IB1I1eyK+a1dyUE2un7Laf1i8yzr2uOdWpYdZBhl04pnWggyJ7kckznmctQ02GHmFytJG4D1+cwKWdsBTpnmMYuarqcP7+0rocqeGV3PvCbDE2azvN/e3DqQMj1wO0mvxe7jL/Z/Hr6EwfuErlpqbrrZyCy1I0vnbDPtDLEKzhA5ZcxNYVNTxtJ8fFvSdlML87u8ZfmB3b3Gisxx9xqTM8PczDD5mAh+3MrxH9yAiPLZENx1jvLZENx1jnKgB3edY3xTAS4vfzwn975WfM/KZ3lPq2fZxSXVLNdrMUtW2bFVswVIlEPdjwhaG022hfkzNTZtgwjgYeX4d8M2yeHvRm0Kkl/r5Nfx1K3eTpjUjHDzIWn5MH5koVc1JJ4c7ZkKzpSURSaobpKaIL6vq3aEgpozNQ2ZQNTAPmJZ9zmX52uQPEJkyR7S80jmp0bYPzpoZLOp0AQsjWLsuNtNxplinmFe7OSsIUnTzvOk7iv4BrzCC6hiHtS1lFdTwbClXYWW+fgpo3Sq9nnHlyAdqn3+TC04cZL32K6RUUMCnxfabdT+jAyg2yj0niq/MD0Kz5upKd/VrrPhWKpKbSAcceK4Ce66umvI02f3/FJ5eRYmqs2vaA0ydZxf0oqzp7lMb01rFJkG1pRXa2GignqtZpkKKrZaxCoQmVpVKLG0/VW/GewMXODW/hY+2zC+x3oL0Uat7AyglG1BZIJatuHMCoKhUYUSS3lu2UQFBW3LMhVUtK2oZTKytcpUYmvTitwACufWRSaonDvOqMAN7UGFEktNrKJA/dijWEWBKrfTai9XbqeQT9OKgrahF5kK+oZe1WYE2Sr3TcjWrhX7oZDZ5ShCQQsRxiBOz5ipplKRrfzmwaZrK9BVhDGp2AD6ijBmtVth1uqtFbK2ij1LI2Eg9lY2kijAuRUEU7kyIAi2CjoBm7CgawuCbMB8a90Y4CqCQzfIrE0yFlmbtY7QRhIGRYQaiQKcW0ExtalUZGtXbzyNSEls1C7hDTRtgaoLDtfwp1BXTSLoC6bbWSNyEi43WOYkrCsuCoOwrlirFoR1LdrAt08NvBkZDQZBlWBNcBud15qyFF29IUK2cgHD1G+iCIswyYKQuFzaYIqlsOkyxdKkRK2FD4PW91hmkqs8RcFJi1zeCLDMFYdFLe3S4TrO0hkJ5SOJxOf3caEcwJHc84Uo3SK2D+G+V+EtYizaaiQmocsjcGd03Zl4QVmmoCnEcOHQKwKWH3olCdgkH9EIyxu2MgpY3rBlxWX8wMuKy5pcpyAsP/Ky4LLMp2JZcJkgxkiCywQ5RhJclullY5pqlAqOpizI/IQ4yIKYVYkDQc+kxAHPsajEAc+xqMQBz7EouKzwHIuCywrPsSi4rJjcByBslG9cEFa+emRY+VqfYYs6fWPYKrdDCNvkayeE7fK1LsEq+g7BZVWWFTKsqZpURBXKRYGqCtYZVUgxgVpERS2CVm28y6BNG0YxqCicQlCu7RBClYs7lLQS5B2CqwR9h+ArLvBQdlcu8FCOAi7wUM4tLvBQDllB4KF4i0s8BG9xkYdSa3X6pcHotjPFZeLMUorNjjNLqYw7ziyljOdSD6Xn4FIPpUHq8ItXKfKGlgs9lA5REHrwCDBB6ZEEKj6zhNsH41IP4arEuNRDuNcxrvTIirfguGzSZaEvOXOVR1YiAJ9YWYkAnFlZiQBeCwoREOAc+jAxBjuLHYk80BTnRI5i81McOxJ8fD5meZ3fvPuirBtnguRj2sAj0L1YkMZmy9c5SyNzMwuZqsCbuBzatCxUEV//aqgF4e3vRpWQ3sUCKgIxmx3JQoDNr2HCbDb1wEOxfSQQIUO+T7PdHfIZ14pMmz9ba3z4FSHThbdTRH+Rs4stMtaItVVsWKKRlW1sO7KX7aITTYtxnYj5HnM3zwiPwLSXpsfovz0FNmmT7iiC11lZhEr8Gj61LKpjEPIyJBPee3HAJvLMWWzMI3kNDX8BhvnZ40dOVSdBMZGVxRqrKSIrWQH4rf9Jt3XKdItH/ooM8yPAXVVB0nHANmKsqTMgho3qDIhh5a9iMmxWZ0AMK2vwGVb+hgvDNnUGxLBdnAEhqqDoEByW1XcyMaqJMyBGFV9MxqDi6zYYNGszIAYt2gyIQas2A2LQJs6AGLWLMyBE5SIOZcPiGg5ldy0mlZYJvCPLSpRKywRe5WVcvDG1aYlUQ0W7TUykGCpFuvVKpBjiqo2pnUzviqGvi/0bis+PXmi8GH6t7u73PX2ru9Yq9LHa4+P/fTkIkg== 单线铁路的十字互通双线铁路的环状互通这个蓝图是一个简单的双向铁路交汇环状互通的设计图。在建造的时候需要注意环岛入口的信号灯需要往后放一放，防止车头阻挡到环岛的部分交通。出口的信号灯更要往后放放，否则列车可能由于有车辆在环岛处没出来导致车尾卡在环岛里面阻塞交通。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 双线铁路的十字互通信号灯与信号网络的协调工作可以通过红绿灯和信号网络来模拟连锁灯。如下图所示，我们将前后的红绿灯用红线缆连成网络，我们需要将前面红绿灯的信号复制到后面的红绿灯上。根据上面的思路，我们将前面（右边）的红绿灯的信号连接设为读取信号灯，这个模式将红绿灯的值输出到信号网络中。例如，当红绿灯的值为红色时，那么信号网络中就会获得一个红色的信号。我们将后面的信号灯的模式设置为切换信号灯，设置当红色信号大于1时，则切换红绿灯为红色。 相关蓝图单线的相关终端设施一个无车站的掉头终端10eNqV1m1vgjAQB/Dvcq9rwh2Up6+ymEWxcU20GqhmhPDdV2Az091C7xUB7Y+j/V/TAfanm7m21nmoB7DNxXVQvw3Q2aPbnaZnvr8aqMF6cwYFbnee7tqdPcGowLqD+YQax60C47z11izj55v+3d3Oe9OGPzxGNrf2bg6bGVBwvXRhzMVNLwrORivowwV1sA+2Nc3yYz6qPyTFkSkvpoyYPsTOB+z44f8rs/xG6RktGDSLRXPeRMbUkbOJuJjVOpnHkdUPyBCFsCp8ripjyDJ6RZAWNOMqq0Qf91KXZkBMxIURVxii1ElYhqQMX420AShipjJR5+v1hkItafwXkDgwl7Uore8kWEgXhM0tivOfs0wlWoMiYu8V57/kCiMUBg6T9XwQyfYhTNd3R0ql34tso1ImdthOJS122IBRLnbYhJE47xgCEc4M86mi/nUIUXA3bbcEryyISqySIszBF1ec1uY= 双线的相关终端设施配合环状互通的无车站的掉头终端10eNqV0+GKwyAMAOB3yW8H1a619VXGGF0bdkJri9qxUnz3s5YbN85j7pdEzWeCZIVrP+OkpbIgVpDtqAyI0wpG3lTTb3t2mRAESIsDEFDNsEW6kT04AlJ1+ABB3ZkAKiutxD0/BMtFzcMVNYj8mdnO+o7dIQAEptH4nFFtD3nnUBBY/MI93UmN7X5WOPJHPKaJPAoeI2CRWGK9i/RVpBGxTBMp/REjBv+oqoQ2q4+KSviI+gka663bl/2vxjKQNHtv0iyx7Xwn81eSx0iaRhZRkcVEltp5FW0834YmjJX4NYUE7qhNuFBWnLGK1hlnzn0DcVg0XQ== 带车站版的10eNqV1s1ugzAMAOBXmXwOEnHD77GvsOM0TbTNukhtQBCqVRXvPkKkbu3czTm1QPLhGBtygc1h1F1vrIP6Ambb2gHqlwsMZm+bgz/nzp2GGozTRxBgm6M/6htzgEmAsTv9CbWcXgVo64wzOsxfDs5vdjxudD8PuM4c3Dx3/+GShRDQtcM8q7X+VrOU5ALO848sp0n8YpDLqL+UVXQwOcWo2GBIJYsORlFMHhsMqRRXZTv2J717FEoRkGqugJ3p9TZcywix5IkZCSoCrNj5kmlA1S1aEKgfGqnmt+qKUtlVX5ImlU+Jkebd6iVl8hvC396ryMipilYVI6fsfnnw+Mmk5rEoMrLKbSYZil8ySGY3+Qe6iJRRxYXFaElMo8JivDVQxtaORIaKzKVXgcz+L3Jc8ciCFJESVWQt3q+c6hrkf2XC90HmjEjZXZMgHy24aMo3S64ZEed3G3nSJoNru8crL+9EMUfShP/w7PR7Y5/WfTNa8BupZatV/9iZCTjpflhG52WBWMoqLXCavgCTjzMW 八瓶科研下图是一个不轮换位置的八瓶科研中心蓝图10eNqdnOtOIzkQhd+lfwfJ9wuvshqNwtDLRoIOSjqrRSjvvs2S1SDhTs7nX4jb8XG5ynXKLud9eHg+ja+H3TQP9+/D7td+Og73f7wPx93TtH3++Nn89joO98NuHl+GzTBtXz6+mw/b6fi6P8x3D+PzPJw3w256HP8Z7u35x2YYp3k378ZPpP++efs5nV4exsPyB2sYm+F1f1z+bT99jLpA3dXN8LZ8SQv64+4w/vr8XThvvoE6DJpvg3odtMhMgw6am6CpARox03wbNGGmAmjWQZM8/aKDRhm0YqbC9K3BVBVUEFNBNoAFQeV1VI+5KhYImKuCCuLK6RYAgWV11Iy5KhYomKuCqseWkQ3g9NDSreosZSpM3znKVAHV40p3VaeHlb4DuEiZKtNPlKkCqseUvq26QkEVpnpE6WnFGwoqTN/rEaWnVa9HlC5VvKdMlekHyjSdWzARC94gCN6EUaOA+juKTkuNcHg67Jevq1nENOkuzC51yP40v54+Ko7vA5WegWLHQBXrbcH6wWBUwfrBEqPkG8bfTSsmCa5jmMiH8ViVx9tBGQJGDQJqxFpf4ZowqsI1Y1WucC0YNbR2u1CxChXiLRqMKsRbxIpRMGTEilEB9ZSpYtRAmQreGbFiVECxYlRAM2WqLFShTBXQSmWoMP1kKKjANJEMFruTenJ8mA6RkjwVgLG1JSasI5s7a4pU47bZJArTZqNHT9V9slBQxScrcJbSq3ay4aNw6ZZtj2x23PWz6xnIdwzkcR3jbqe2HDCqF1Bjh3B2fJFTxzCeD5NxDaNYvmBUxfIkhv/X/R1uX0zHOB1eXyyuDHxrFy4O47gmDj/pb/MJGKfNB0Wa7420kjqG4ZFWMq5ehJgo/LxfiN+CIs11R1o1HeN0RFrFNZ5gpOooqLCe1QOL2F6Xr4GPwj2+RloGeeGWN9GCTQHNlKkTQAtlqoBWXvR0BKY1ho/je8axtAD1yqW9o6hOQcWVYDM9WoNLQdfGwbXgCh9cDK7wwdWgZHVcDkoe0lEP8n3W2o6C0HcMg3u0zO1UZC1v0rIKLG7TksgGXHJIZPmdgG0Gh8XXAKaNww/+Vwjhs/4VQvisX1lOx8/6leX80h7y5/Y43+2m43iYl1+tqB6jdF1RHSjNH5/1S9P/HSTP++np7q/tsik9XrGCv+ZBX/pCnrcPa/+88r9JXYirTgwaPvJVnAJx2rEAujrSNTqgkSNdoeNxWhDKHutxWlBc0+OsIHHFWUHiipPCyjLjnNAWXh7nhBU+OCWs8MEpQVnLgFOCspZf2i20LbEJ3W5xpYlBsgJNDJIRgrobxxZR18SM0LCxRbcNneBu3Xb3QJNH29tB00S6xobmjjabaDrubDquRW3EyUXoRrARJxevoHp+mcLv5WzE2UYyCX4sIpkk8UuOLjfJNMe1DykifjMS2jiV5rg2H9A5ccFp80HNEpfbhw7XTI4mT8U1QW/EBVVxzRT4rUCPa4JeCqObJEFQySIZn9f3+EhRVYDTmdeuilOBzgYe2gflUY6Fh/YSKO9U6vFn0EURdO70sLq9XeYIYdq7ZaZH1StsMoRZYUOPpiWD85PpjlgvPTKxo0nPkiaHyzDK47mCdaKEivuQhAZjWwJXn7FjSbFOTAr5RFElk2SuPru8D6vGZrukLZXiNF8B2YpVY5tPxQ+IV/g4rj47XLN6+tpXidYa6AtaCTVSTSuh4jfEShjVzJVyTxiBVgYj7yyVPioWLOJQ34Lt9GcHuhbaMdMEdVB6SqBUE0qgAevZDq9zhmrG5h7nDD0tjG0YqhlXYOhp4cqkKpSeyrqCD7so6s7nQG9C1UEdFskdYW6xHFRefpNOhYsilmCx/JNQ8RVVbvorb1uQ2BWqKyTUSnWF9BkS+PpKQqWdrRKog3tUe80d7ZeTuAW4R0mgEe5R30B/bD4/b+v+y8dzbYa/x8Px8w9Kdq4s8j+78/lfmSokZQ== 下图是一个轮换位置的八瓶科研中心蓝图，空间相对较小。10eNqdm9tu2zAQRP9FzzLAOyn/ShEUdqymAmzJkOSiQeB/r1w7dVCvrBk+Bbn4cLjiclbk5qPY7k/1sW/asVh/FM1r1w7F+ttHMTRv7WZ/+dn4fqyLddGM9aEoi3ZzuHw39pt2OHb9uNrW+7E4l0XT7urfxVqfX8qibsdmbOor6e8379/b02Fb99Mf/GMc6l1zOqzqff069s3r6tjt62mEYzdMH+7ay9gTcGXK4n36ks7n8gFmSNgzlp2b3KOkcMWEadq7pp9G/Ps7J0AdDY3LUI9DPaw04FAnQoMAjbTSuAxNtFIAWuFQC09fK5xqcKqmtQIB0IbWilCJrNJ4BPC0UjjU01KRAARWKgLF84oIamKhiFI8r/BFZRQLBaZv8KzCk8rgSYVvVcaySpHpO1ZpEA3Z04bnAXGBpjqAyrsTQk001S+7s6lo03PLVKtoKqDV8v4ErAHL+xNCtbRWJK6O1gqsLMsbFEKlDQqBRloq8rASKxWBVqztAfN3ioUCSt09r07Ty1b/1nfT1+fG9z+2/Hyd607j8XR5cXscxvDDuIxhLGs4XjIcR/uWEzGe9VRZTWAxsho8fXC7c4mFImuyIhaLX1iTTTuzVrziR3H8KJquMsxyhLyhqRagWtq5LXCw4GiqAaieeHqfNZHhdxQfMsaxGeNEumZAopRoKvJEmfz8rEUMnTpBZQxj+WE0WwAAqRQMXasgVMtKBfaS4GipCNXzhp+RniHww2RkZ6DPRpCnSZ+NIHGv2NLFSsVCVCzGiBj6/ENWY1iMrMayxQoQ8OhYKLA0oudrE36DjYEfhd9fY2QvZ25DafEZ0gf1atnQIn8QopepSWXeSokTT/dU+rEZxlXTDnU/Tr+Zwyjg0sOw5QEQzMSffiDBvKfZvmvfVj8304rdPYmCehbLe3rtN9u5z8ofDXm3gzIsos9UP6Mkdq+WMaxzKIlSKXarFsVUrHHIYtir3Gc7T0W/HQEFekW/HAG5UnkyV247hgZuNAOb3EgQ6HcfJAgJzS0j6TQSsiLjKobViHe6bL0lLlGtNIkxMoatt2bUsHdKM2rofgeH3KL7vLLEyhozjgkyzje1iux+AdwsaEUXVRahVnn1jxxhpu3BwjPn2x6QmWvDn1zwR4v6Sx/EUkmoce15hRaE9uTxBZLHRC/ELQoQNWaVeTNLN9GHFDl7g2YvnZBAGNaY5BAY1picjGGNaUYNa0wzalxWeTmjyZPnCNDT49/wM/Yhpufhqt0j2hNLRfqRTMUbdcZ9p2a6IDysnumCcDjVsFSgYUN/6YKg7F9sAdJM94OVZi5r9CwVmnng7Z+/v9REP4SCs45oh7jZKUStsuxUXgp0HwSiMKMPImdbcGzv3kwI2D4HL2Mc6YMzGLbPYWZSgXRA6LniSYJvw3TXAwTlux4yNg2vWFdFGnKZLgePU2lfgqj0+TREZVMpijngPZnYkLZA5gAEZduJHqAv5fX/f9Zf/l2oLH7V/XD9gxSNSbpS0ZzPfwCZZmJ4 斜线铁轨交汇模板10eNqVl+9u6jAMxd/Fn4vUJG4a+irTNDGItkhQUFvQEOLdb//d3bvNoz4fC82viY9PbN/odX+OpybVHVU3Sttj3VL1dKM2vdWb/fBbdz1Fqih18UAZ1ZvD8NRs0p7uGaV6Fz+oMvfnjGLdpS7Faf34cH2pz4fX2PQvfK5su37t23u3GhEZnY5tv+pYD58aSDajK1UrY3v6LjVxO/1Z3rMfUAtD+SvUCVCnha7C504FDKsx/AhTaDH5I4rXUh7upVSH++9m8mUNAwy1yxquYQ1z6cDDJ0ERZY5BVZQxFpVRxqgzfA5OWFbRMMj8nhqSiqZAZQzieT2qooz5l/7bc3OJu18gbmIUX89XSMQApoW8L3Wy+4niFRdrDjLDsprWoGp66bjWomrKGAfGXqYw6EhWxL4AmV4Re4/GnsXjlmjsZUzQOWll5rti2UpWbYK5E1B0Fy4HmZrmAjaBWIkdbAIZA5pAUc4dg75SVHOH1gGx7DmvzLpiZLjlpHN6O0wZokm6ADIVddSh7ZDc0KLNkOKuYwMyFdnCVqnzeiSWyzqzfiSYyqGiwjKDTMXlwqhPFI0do5VDUY1Y75u56dcMEhxQqqJpYb115hlTM7cWOUz9YfN+3h4n8uq/AT6jS2za8QUfSmuDWedlb+Y/EyQ69Q== 大规模铁路设计技巧 单线段用链式信号，因为单线段是不能容忍相向到来的火车的，所以要用链式 复线段与单线段的衔接处的入口用普通信号，这是因为车可以在复线段里面等对向过去，所以能够解决链式的粗粒度锁的问题，出口要用链式信号，这样车可以在复线段里面等对向过去。在复线段的每一股中要添加前进方向侧的链式信号以保证火车提前停止 单线单方向汇合端要加上此方向的信号灯（普通即可） 使用沙盒模式调试铁路在沙盒模式下推荐使用creative-mode这个mod，可以方便地获得电力等资源进行调试。 常用的Cheat code设置本地变量1/c local X = 10000 加入200个太空科技包1/c game.player.insert&#123;name='space-science-pack', count=200&#125; 强制解锁科技1/c game.player.force.technologies['electric-energy-distribution-1'].researched=true 长手12game.player.force.character_build_distance_bonus = 10000game.player.force.character_reach_distance_bonus = 10000 传送科技12/c game.player.print(game.player.position.x .. ", " .. game.player.position.y)/c game.player.teleport(&#123;X, Y&#125;) 烧铁（前期）10eNqdmutO4zAQhd/Fv1Pk+6WvskKrAlk2UkmrJF0tQn33TUEs3WWCz8kvxKUfY3t8ztjjF3W3P7XHoesntX1R3f2hH9X224sau8d+t7/8bHo+tmqruql9Uo3qd0+X76Zh14/HwzBt7tr9pM6N6vqH9rfamnNT/fA4Hfp28+M09Lv79uqz9nzbqLafuqlr36J4/eb5e396umuHGb70/xt1PIzzxw795Z/OqE1s1PP8xZjzJaD/OBbm6L+YRj10Q3v/9jsvQB0enMGpHqaGr0Yc6JkrEibyC6AlTqYXQNenqrDQUmcaTa8qQjV8rgATYCydLOLqGMdyxGQxns6WJHL45M0i5yN7u35sh2n+4WdCeI/kn+m2Ei8vKNpnqLt5x94EMbSP3N0f+sfNz92siA+bL8K07wOthmk1MmwLD9sadp/leupaWpITAOUlGaF6mopMQCAzQA44Smgk7+VIRVxC095Wst4WIDAPj9NpVrZEmXCGxYiq5SytWuIkOUdzosjx7A6LQM0TWGgAoJHeYAg10VRkAgqbLOLieDp1xVzxfIHsRA6fu17kOMJxXd16vOcd18na48NKx/VAmJFwXGTYid1lHjhY0DW4A6CF3mQANfBFODABwaxzXF93omBxx3UAztGOu5D1IeCOiwQWWdkSZSIkFiOqVsj86VTkFJpjxcMyXdPaetZGRx+dAShf0iLUQFORCchsssiLQxu3mCtJs7kiY2jjFg/uifBbU/edxNutlnUnrXRbJEjCbDWAY70WuJdJrNUCmyvRTgtAM220wOjzOp/VdfvJuM0agEa77EKyZ9xkkbBYj5UvXFmLFWUq0w4rGnWmDVaU8KJpeVooi4pdJ09A7V5YvwYssLBHeaDGLrRZI1D6JI+MPq3SE6CcLYVVgIV8Mpo9z1sZw15FORlDH+cXRkVfRXmZ4/EyBThuG02UABCPrQE80khii4CAQOkqAKHyTS9kAoyD3Ro4YhvDdkblXCSaS+GLrWHozqjc6jKJ5USZk/EthrS6TKG9Ni5o41U/ijLbCIR51Zuq8pBh022piHRp2ZIgIVD6CA9R6aoAmoC4ysEjoApXzakaLiG4zFYEi1mP97qQcdK9Llkm6F6XrFp8r0t+MMD3uuRG/1VbClWrsrBuLq5TqwKoi2PrDKCPbBxbZyDvVRxdZyBUT9cZyAT4dfcNBdh1eP/JVtLK43cEUGDsJYG8bzx7S7Dw7oe+Jlh4h+QLcZ8JXO6ZQLyFwYDsYxjoHVew9OUehMUrcANcv5nAluCXZb5t3l6Dbq9enjbqVzuMr3+dnDYx+LmAnTfOHzSFF+g= 太阳能10eNqd1ttqhDAUBdB/Oc8Kxvv4K6UUxwkloFG8lA6D/95oH1robsieJ1HiMon7hPOQa7/paTZ2leYhphvtIs3LQxbzbtv+eLbeJy2NmFUPEolth+NuGft2jqfW6l72SIy96U9p1P4aibarWY3+Zs6b+5vdhque3QAIRDKNi3tntMf3nBMrN/DuruW+R3+QNBCpPUYWaBQeIw80Uo9RhBm+7SjDiNxDVGFE5SHqwIUkHuNCpiNFyPEFJh4Y+QnqoG9mG2Ld626dTRdPY6//13KopVza8JQyLm4Yyam8YaMg90b5toZLL54QF19s1OSivP/7whUDnFGacNWgIKKoYsAGl15scOHFBpVdTBRM2jBRMmHDREXFAxv1cwdUBrHLUxUNrSx5qpCwRbYLBUS4dgEbXLuADa5dwAbVLmCCOnAxQZ23mODaBWe4xvLsQJtfDWskH3peztFVlqiyyJWq3dgvJDmPdA==]]></content>
      <tags>
        <tag>游戏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu上配置饥荒联机版服务器指南]]></title>
    <url>%2F2019%2F03%2F30%2Fdst-ubuntu%2F</url>
    <content type="text"><![CDATA[本文将介绍如何在Ubuntu云主机（阿里云ECS）上配置饥荒联机版服务器。主要过程在steamcommunity已经讲得很详细了。我提供了一个傻瓜脚本。但有一些细节操作方面需要进一步明确。 创建服务器游戏的名字和密码分别在/home/dst/.klei/DoNotStarveTogether/MyDediServer/cluster.ini这个文件下面的cluster_name和cluster_password字段上面。出现./dontstarve_dedicated_server_nullrenderer: error while loading shared libraries: libcurl-gnutls.so.4: cannot open shared object file: No such file or directory错误，需要安装32位的libcurl，apt-get install libcurl3-gnutls:i386。 有关ClusterToken网上有资料说可以在游戏主界面的个人资料里面找到自己的Token，但经过测试发现并没有。这时候需要在游戏里面输入一下的命令行，应该得到下图的结果，然后可以在自己的.klei文件夹里面找到一个cluster_token.txt的文件。如果显示Attempt to call a nil value这样的错误，可以尝试在Steam的库里面的工具里面下载Don’t Starve Together Dedicated Server。1TheNet:GenerateClusterToken() 有关不能在DST上面显示这个可能是由于版本不对的缘故。应当及时更新。 有关ECS的额外须知注意我们要在阿里云的安全组里面加入10999端口的UDP规则。 创建洞穴出现Unhandled exception during server startup: RakNet UDP startup failed: SOCKET_PORT_ALREADY_IN_USE (5)错误，注意Master世界和Caves世界的端口是不能冲突的。 有时候会出现洞穴地图被生成为地上的情况，这是因为原因是没有配置worldgenoverride.lua，或者照抄了Master里面的worldgenoverride.lua。 在另一台服务器上创建洞穴我们需要在cluster.ini文件里面指定主服务器的ip。有时候我们在主世界看到洞穴入口被藤蔓封住，然后查看洞穴服务器的server_log.ini发现以下log。注意设置阿里云的安全组和主服务器的cluster.ini文件中的bind_ip为0.0.0.0。12345678[00:05:35]: [Shard] Connection to master failed. Waiting to reconnect...[00:05:40]: About to start a shard with these settings:[00:05:40]: ShardName: Caves[00:05:40]: ShardID: 4048981408[00:05:40]: ShardRole: SLAVE[00:05:40]: MasterHost: 47.101.137.181[00:05:40]: MasterBind: (null)[00:05:40]: MasterPort: 11001 Dedicated Server主要文件解析 ~/.klei/DoNotStarveTogether/MyDediServer/cluster.ini 用于配置整个服务器的信息，包括在Steam平台上显示的游戏房间名字和密码等。 ~/.klei/DoNotStarveTogether/MyDediServer/cluster_token.txt 服务器主人的Token。在上面的ClusterToken章节讲过怎么设置了。 ~/.klei/DoNotStarveTogether/MyDediServer/下的Master和Caves文件夹 分别是主世界和洞穴的世界。 ~/server_dst/bin文件夹 存放有start.sh、restart.sh等文件，负责启动和重启服务器，关闭服务器则可以使用htop -u dst，然后SIGTERM掉进程。 ~/server_dst/mods/dedicated_server_mods_setup.lua和~/.klei/DoNotStarveTogether/MyDediServer/Master/modoverrides.lua 前者用来配置需要装的mod，后者用来给这个mod指定参数。一般mod配置是很麻烦的，首先需要验证这些mod不互相冲突，不会对服务器的性能造成较大负担。然后我们需要将这些mod的id注册到dedicated_server_mods_setup.lua里面。我们可以在steam上面创建一个ModCollection，然后直接添加这个ModCollection，从而避免手动输入每个mod的id。这里推荐我自己使用的Collection：1698005633。在设置完dedicated_server_mods_setup.lua之后可能启动后并没有加载mod，这是因为我们还需要设置modoverrides.lua。这里推荐我的配置。如果需要引入其他的模组，建议首先在自己电脑上配置后，然后可以白嫖本地的modoverrides.lua文件上的配置。 ~/.klei/DoNotStarveTogether/MyDediServer/Master/save文件夹 保存游戏存档 ~/.klei/DoNotStarveTogether/MyDediServer/Master/worldgenoverride.lua 该文件用来配置DST的世界设置。 需要注意leveldataoverride.lua会覆盖worldgenoverride.lua，所以在新创建的Master世界的时候需要删除这个文件，不然怎么改worldgenoverride.lua都没有用。 ~/home/dst/.klei/DoNotStarveTogether/MyDediServer/adminlist.txt 用来加入管理员。 我们可以在server_log.txt里面查找Read save字段，找到一个KU_开头的字段，加入这个文件里面即可。 备份恢复一般来说备份MyDediServer文件夹即可在存档被意外删除后进行简单替换的恢复。在替换后应当chown或者chmod一下，不然会出现权限引起的core。 额外说明出现问题可以查看server_log.txt，或运行start.sh看log。特别注意要su到dst之后再sudo sh restart.sh，不能在root下面搞，否则会到/root里面搞事。 RELATED WORK https://blog.chaos.run/dreams/dst-server/ https://forums.kleientertainment.com/forums/topic/100518-attempt-to-call-a-nil-value/ https://xueli.li/2017/09/22/build-dst-server-on-ubuntu/]]></content>
      <tags>
        <tag>游戏</tag>
        <tag>饥荒</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2PC和3PC]]></title>
    <url>%2F2019%2F03%2F12%2F2pc-3pc%2F</url>
    <content type="text"><![CDATA[本文来自我的文章分布式一致性和分布式共识协议太长，因此将其中的2PC和3PC部分单独列出来作为一篇文章。 缓存数据库双写问题见分布式一致性和分布式共识协议 两阶段提交协议Two-Phase commit(2PC)协议内容 第一阶段（投票阶段） 首先协调者向所有的参与者发出提交请求VOTE_REQUEST，参与者按照事务的标准流程写UNDO和REDO等日志，并在本地执行事务。如果事务执行顺利，则不提交（尽管事务中的全部操作已经正确完成），返回一个VOTE_COMMIT给协调者，表示自己成功执行了事务。如果事务执行出现错误，则返回一个VOTE_ABORT。 第二阶段（执行提交阶段） 假设协调者没有宕机，相应会出现两种状态： 成功，发生在所有的参与者节点都返回VOTE_COMMIT 此时协调者向所有参与者发送GLOBAL_COMMIT，参与者收到之后正式提交事务并释放资源，然后返回ACK确认。 失败，发生在任意参与者节点返回VOTE_ABORT，或者有的参与者timeout 此时协调者向所有参与者发送GLOBAL_ROLLBACK，参与者收到之后UNDO回前像状态，然后返回ACK确认。 协调者宕机/分区情况对一致性的影响OK，刚才协调者没有宕机，看起来很美好，可是如果协调者宕机了呢？ 我们考虑协调者将commit信息传递给了一部分参与者的情况，由于2PC是阻塞的，这意味着所有没有收到commit消息的节点都会阻塞在等到GLOBAL_COMMIT消息这里。如果协调者又重启或者从分区中恢复，那么参与者仍然有机会提交。但是如果协调者永久地宕机了，那么剩下来的节点就永远处在一个FLP里面的所谓b-valent了。此时整个事务就不在Safe了，因为并非所有的节点都能一致提交或者回滚。但仍然可以认为2PC是Safe的协议，因为它实际上是不假设永久宕机的情况的。 不过我们脑洞大开，如果在永久宕机之后是否可以通过一些选举的协议来选出新的协调者呢？ 假设参与者全部宕机 这时候整个集群“死绝了”，变成平凡情况，由于没人（有能力）commit，所以不一致性不会受到破坏。 假设参与者部分宕机 这时候不一致性是一定遭到破坏的了。虽然未宕机的参与者中可能存在有收到来自协调者消息的，可以选一个新协调者出来，但是宕机的参与者究竟是否提交成功是个量子力学问题了，所以新协调者即使知道原协调者发出了commit指令，也不能断然决定去commit。 二阶段提交协议的不足总而言之，2PC存在两个显著问题，阻塞和不能处理网络分区。 阻塞 2PC协议中，参与者一直是事务阻塞的，因此在事务进行的过程中，系统不能响应第三方节点的访问。这是偏于保守的，牺牲了一部分的可用性。阻塞带来的另一个问题来自于协调者可能的故障。由于协调者对于参与者有timeout机制，但是参与者对协调者没有timeout机制，如果协调者宕机，那么所有的参与者会跟着阻塞下去。特别地，即使做一个脚本定期扫描各数据库上被悬挂的事务，也不能确定是按照回滚还是提交进行处理。 网络分区 我们知道2PC协议通过分出投票阶段能够根据所有节点上事务的执行情况判断执行提交或者回滚。但它在第二阶段依然会出现不一致问题。 第二阶段出现网络分区 假设协调者发出了GLOBAL_COMMIT请求时发生了网络分区，此时有一部分节点收到消息正常commit，但另一部分节点未收到，还处于阻塞状态。 此时协调者仍可以通过最终返回的ACK进行补救。 第二阶段协调者宕机 假设协调者宕机了，那么整个集群就不可用了，这个在前面已经讨论过了。 三阶段提交协议三阶段提交协议致力于解决2PC的阻塞问题。为此它引入了参与者超时机制和一个额外的PreCommit阶段。 协议内容 CanCommit阶段 这个类似于2PC的投票阶段，协调者发出询问是否可以提交，Yes为可以提交，No相反。 PreCommit阶段 需要分为三种情况讨论： 如果上阶段全部为Yes 协调者发送PreCommit请求并进入Prepared状态 参与者接受到PreCommit后确保事务操作全部执行并记录UNDO与REDO，返回ACK 如果上阶段有No 协调者发送abort请求 参与者接受到abort后，REDO，中断事务，发送ACK 例外情况：参与者未收到协调者的消息 这可以认为是协调者的timeout，此时中断事务 注意到这里参与者是可以处理协调者的timeout的 DoCommit阶段 这是真正的事务提交阶段，同样分为三种情况 协调者收全上阶段ACK 协调者发送DoCommit请求 参与者接受到DoCommit后提交事务，返回ACK 协调者未收到上阶段ACK 这发生在协调者没有收到一些参与者的ACK（网络分区或该参与者abort） 协调者发送abort请求 参与者接受到abort，使用同上阶段的方式中断事务 例外情况：参与者未收到协调者的消息 这又是一个协调者的timeout，此时提交事务 为什么选择提交事务而不是中断事务？因为此时提交事务成功的可能性非常非常大了，但仍有例外，例如： 进入PreCommit后，协调者发出的是abort请求，如果只有一个Cohort收到并进行了abort操作，而其他对于系统状态未知的Cohort会根据3PC选择继续Commit，这仍然会导致不一致，不过这个概率就显然非常小了 三阶段提交协议的不足相对于2PC，3PC避免了协调者宕机之后可能出现的参与者们阻塞的情况。但仍然有较小的概率会导致不一致。 Reference NJU教学PPT A brief history of Consensus, 2PC and Transaction https://en.wikipedia.org/wiki/Two-phase_commit_protocol]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>2PC</tag>
        <tag>3PC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raft共识算法]]></title>
    <url>%2F2019%2F03%2F12%2Fraft-algorithm%2F</url>
    <content type="text"><![CDATA[本文来自我的文章分布式一致性和分布式共识协议太长，因此将其中的Raft部分单独列出来作为一篇文章。 Raft协议的设计者们认为Paxos协议非常难于理解，并且需要作出很多修改才能够应用到工程中，因此设计了偏重于实现的Raft协议，这甚至体现在他们的论文标题《In Search of an Understandable Consensus Algorithm(Extended Version)》上，此外作者也提供了一个C++版本的实现liblogcabin。Raft协议主要分为三个模块，Leader election、Log replication和Safety。Raft将服务器节点分为Leader、Candidate和Follower三种，协调者被称为领袖/主(Leader)，参与者被称为群众(Follower)。相对于其他的协议，Raft中的Leader更强，这体现在： Leader是唯一的。 Log entries只能从Leader发送给其他服务器，事实上Follower不主动发送，而只响应来自Leader和Candidate的请求。 客户端只能和Leader交互，如果客户端首先连上了Follower，那么会被Follower转发给Leader。 Raft的独特之处还在于其在Leader election的过程中Raft使用了随机计时器进行超时。此外，Raft还提供了一个joint consensus的算法处理Membership changes的问题。 Raft基础概念状态Raft协议要求在每个节点上维护以下的状态： 共有状态注意currentTerm、votedFor、log[]这三个状态是持久化的，其他的则是volatile的。 currentTerm 这个在后面的讨论中非常常用，表示了当前服务器已知的最新任期。 votedFor 顾名思义。 log[] 这个是日志，是我们需要维护一致性的对象。 commitIndex 已知的最大的已经被提交(Commit)的日志条目的index。对Follower来说，这个是根据来自Leader的AppendEntriesRPC中的leaderCommit字段来更新。 lastApplied 一旦commitIndex &gt; lastApplied，那么就将[lastApplied + 1, commitIndex]区间里的日志条目依次apply到复制状态机上。我们这里仍然要特别注意提交(commit)与应用(apply)区别。一个是针对日志，一个是针对RSM。 Leader专用状态 nextIndex[]：对于每一个服务器，Leader下一个需要发送给它的日志条目的索引值。初始值（当某个节点成为Leader后进行这项初始化）为Leader的logs.size()。在一些实现中会使用commitIndex + 1。 matchIndex[]：对于每一个服务器，已经复制给他的日志的最大索引值。初始值为-1，这个值是非常保守的。这两个值是Leader用来同步各Follower的日志的，但是当一个节点成为Leader时，它实际上并不知道其他节点上的日志情况，所以它给出的值都是需要调整的。这个调整的过程非常巧妙，它是和日志复制一同进行的。我们将在Log replication部分详细说明。 任期Raft中的Leader具有任期term机制，每个term只会对应一个Leader，所以可以通过term唯一标识这个Leader。每个节点维护有自己已知最新的currentTerm，出于网络分区等原因，它不一定是全局最新的。服务器之间通信时会交换各自的任期号，根据论文5.1节，如果一个节点检查到自己的currentTerm小于对方在RPC（包括Request和Response）中附带的term，则更新到较大的任期值；相对应地，如果检测到自己的大于对方的，则忽略对方的请求。当一个Leader发现自己具有过期的任期时，它会立刻切换成Follower。注意，一个有较大任期号的RequestVote请求并不意味着发送该请求的节点是Leader。但是一个较大任期号的AppendEntries请求一定是来自Leader的，因为只有Leader会发送AppendEntries。 一个有趣的问题（一个离题的讨论）在Raft编程实践中，当节点收到一个Candidate的RequestVote请求时更新term的做法，在我们判断选举结束时会有一些麻烦。一般地，假如我们观测Candidate节点，当它收到足够的票数时我们能够知道新Leader被决议出来，并且就是自己。但假如我们观测Follower节点，那么当它第一次收到新Leader合法的AppendEntries心跳时我们知道新Leader被决议出来，并且是发送方。但我们发现第一次和第二次并不是那么好区分，因为无论是第几次，我们观测的节点始终是Follower，而term也始终没有变（不然说明Leader又换了）。所以我们会使用另外的状态leader_name来维护Leader的名字，并在第一次收到心跳时设置其值为发送方，在丢失Leader或发现选举开始时将其值清空。这样我们就可以通过值是否为空来判断是否是第一次收到心跳了，于是我们能够准确找出选举结束的时刻。 日志与日志约束来自客户端的请求被表示成一系列将被应用到复制状态机上的指令，这些指令在Raft集群的所有节点上被记录为日志条目(Log Entries)。在每个日志条目中记录了对应的term以及是否该条目已经被提交。Raft协议下要求日志满足以下的约束（论文图3），这些约束贯穿Raft整个算法，并且是相互密不可分的。 领导人只附加原则(Leader Append-Only)（论文节5.3详细论述） Leader绝对不会删除或者覆盖自己的日志，只会增加。从上文中我们已经知道在Log replication部分会介绍一个Leader优雅的逐步同步Follower的日志，以求达到和自己一致的方法。而这换句话说也就意味着当Leader和Follower不一致时，永远是Follower顺应Leader，此时Follower的日志可能会被Leader覆盖。 日志匹配原则(Log Matching)（论文节5.3详细论述） 这个原则包含以下两个小点： 如果不同节点上的日志中的两个条目具有相同的index和term，那么这两个条目的内容是一致的。 这个特性为下面的领导人完全性提供了必要保证。 我们知道一个日志条目必然是由某个Leader在某个index创建的，根据领导人只附加原则，每个领导人在index创建的日志条目必然是unique的，因为日志的删除和覆盖不被允许。而在论述任期机制时我们又知道term是能唯一标识Leader的。综上，我们可以仅根据index和term唯一标识一个日志条目。 如果不同节点上的日志中的两个条目具有相同的index和term，那么这两个日志index前的部分也相同。 这是由AppendEntriesRPC这个RPC中prevLogIndex和prevLogTerm两个字段保证的。当一个AppendEntriesRPC命令到达时，Follower会比较自己是否具有prevLogIndex和prevLogTerm所标记的条目，如果没有（这意味着诸如Leader宕机等情况导致的诸如没有能够全部复制到所有节点的情况）则拒绝这次添加（此时AppendEntriesRPC失败了），并且会削减掉自己已知的不符合Leader日志的部分（可以查看后文有关AppendEntriesRPC的部分）。因此每一次的AppendEntriesRPC都会附带一次check，从而保证了这条性质，有点类似于归纳法(induction)。 根据日志匹配原则，我们在实现时可断言logs.size() == logs.back().index() + 1 == last_log_index() + 1。除非出现了Log compact的情况，这也是我们在实现时应当小心使用log.size()和logs[]的原因。 领导人完全性(Leader Completeness) 这个特性是Raft的一个核心特性。如果某个日志条目在某个term中已经被提交，那么这个条目必然出现在所有具有更大的term的Leader中，在这里已提交是必须的，我们将在Log replication中进行详细说明。这个规定实际上保证了选出的Leader拥有所有已经提交的日志条目，容易看出，我们先前的领导人只附加原则实际上为这个特性提供了条件。 根据这篇文章的介绍，我们发现领导人完全性是Raft容易实现的一个重要原因。通过领导人完全性原则，Raft协议不再允许日志空洞，也就是说Leader必须含有全部已提交记录，一个日志落后的节点不可能被选为Leader。而在Paxos协议族中的一些协议是允许具有日志空洞的节点成为Leader，再在后面异步地填自己的日志空洞的。而在Raft中，只有Leader通过AppendEntriesRPC单向向全部Follower复制日志。 状态机安全特性(State Machine Safety) 如果一个Leader已经apply了位于index的日志条目，那么没有任何服务器可以在这个index上apply一个不同的日志条目。 状态机安全特性实际上保证了所有的服务器都会按照相同的顺序提交相同的日志给RSM（论文5.4.3节旁注）。事实上根据领导人完全性可以证明状态机安全性，首先一个被apply的日志必须是已提交并与Leader相同的。如果某个较早term上的日志条目被apply的话，日志匹配原则能够保证所有之后term对应的Leader都拥有相同的日志条目，因此他们稍后也会apply相同的日志条目。 Raft协议保证一旦条目被提交，那么它是持久化的(durable)（不会被丢失或更改），并且一定会被所有可用的复制状态机执行（论文5.3节）。 选举限制(论文5.4.1节)再次总结一下，上面四点日志约束实际上保证了在Raft中的日志是连续的，中间不会出现空洞。Raft的论文提到除了Leader-based的共识算法，其他的共识算法并不保证这个特性，例如Viewstamped Replication（此外，还有基于zxid的Zookeeper协议）中，日志是可以拥有空洞的。对于这些协议，需要有一个额外的机制来方便性Leader找回空洞处日志。 要求日志连续，实际上方便了Follower和Leader之间的同步过程，所有的日志复制是单向从Leader到Follower的，Leader只需要关注Follower上一次的同步位置即可。而在选举过程中，我们也只需要比较最后一个log的index和term即可，不需要去比较其他的日志条目了。这也是Raft协议在实现上方便性的来源之一，但也可能会导致一些性能问题。 在上文中可以看到，实际上通过选举来保证领导人完全性原则，也就是只有拥有全部已提交日志的Candidate才有可能胜选，注意，未提交的日志无所谓。因为Candidate至少需要majority票，所以一旦它当选了，说明每一条被提交的日志，会出现在其中至少一台Server上。如果说这个Candidate的日志不比majority中任何其他节点的旧，那么他必然持有了所有的已提交日志。 【注】这里如何日志的新旧，查看“【如何比较日志新旧】”说明。 RPCRaft中定义了两种主要的RPC包，AppendEntriesRPC和RequestVoteRPC。 AppendEntriesRPCAppendEntriesRPC具有心跳包和推送日志的作用。此外，通过AppendEntriesRPC我们还可以发现选举产生的新Leader，可以参考先前讨论任期时提到的有趣的问题。这个RPC包含以下部分 term 表示Leader的当前任期号。为了表示区别，下面写作rpc_term_id。 leaderId 表示当前领导人的id，这样来自客户端的请求能被Follower转发给Leader。 prevLogIndex和prevLogTerm 表示新日志条目之前的index和其对应的term，这个是为了保障先前提到的日志匹配原则。Leader在构造这两个字段时实际上是根据自己维护的nextIndex[]和matchIndex[]来计算的。 entries entries就是我们要维护的日志条目。 leaderCommit 表示Leader已经提交的日志的序号，这样其他的服务器才能知道Leader当前的提交位置，并跟随提交。 注意Leader可能已经Commit了我还没有的日志，即我们不能assert(request.leader_commit() &lt;= last_log_index())(可以参考我的代码)。 AppendEntriesRPC ResponseFollower在接受到该RPC后会发送回执： term表示当前的任期号 success 表示这次添加是否成功，它的判定规则如下： 当rpc_term_id &lt; term时返回false，显然我们不接受一个较老的Leader。 当我们不存在满足prevLogIndex的条目时返回false。这个暗示Leader要发靠前一点的Log。 即使存在prevLogIndex的条目，但这个条目的term不同于prevLogTerm时，删除从prevLogIndex开始的所有项目。 这里的“不同于”是非常重要的，如果Follower拥有Leader发来的所有的Entries（也就是Leader的更短），他也是不能删除自己后面的Entry的。当Follower收到RPC时，prevLogIndex肯定是可能大于等于Follower的log大小的，例如Leader收到了Client的新Log。但prevLogIndex也是可能小于Follower的，最普遍的一种情况是Leader刚选举出来，还在试探Log。还有一种情况是Follower拥有了先前某个Leader复制的一些Log，而当前的Leader没有。还有一些情况是我们收到了经历了时延的RPC，这曾经导致我希望对RPC编号来解决这个问题，但实际上没必要。在我的代码中，会列举这些情况，以及相关日志。 添加所有我们log中没有的条目。 同步leaderCommit。 特别地，对于心跳包，我们同样应当进行这样的检测。 RequestVoteRPC term 表示Candidate的任期号 candidateId 表示Candidate的id lastLogIndex和lastLogTerm 表示Candidate的最后日志条目的index和term，每个投票者会比较对方是否新于自己的，从而进行投票。 RequestVoteRPC Response投票者在接受到该RPC后会基于term和投票规则进行判定，并发送回执 term voteGranted表明是否同意 Leader election投票过程在2PC中我们看到，参与者必须对协调者有timeout机制，否则整个系统会阻塞，Raft同样有这样的功能，并且Raft的election timeout是在150ms-300ms之间随机的，且每个节点不同。Leader存活时会不停的往所有的节点发送RPC心跳包，考虑一个节点在election timeout时间中没有接到心跳包的情况。站在全局的角度来看，这可能是老Leader挂了，所以得选举出一个新的Leader出来；这也可能是网络延迟/分区的原因，因此可能在选举途中或者结束后老Leader又回来了。但站在这个节点的角度来看，它只能认为Leader已经挂了，因此成为Candidates参加Leader选举。此时它执行下面两个操作： 递增自己的currentTerm 发送RequestVoteRPC消息给所有节点，这时候节点们根据一定规则进行投票 【Q】对于一个合法的RequestVote请求，我们需要更新自己的term么？根据Raft论文中的“Rules for Servers”条目，我们看到，只要我们在RPC中发现了一个更新的term，就需要更新自己的term。 成为Leader需要获得整个集群共$N$个节点中过半数（$\ge N/2+1$，例如3个节点则需要两个，4个节点则需要3个）的票，才能成为新的Leader，这是为了保证最多只会有一个Candidate赢得选举。投票可能产生三种结果： 自己成为Leader 获得过半数票的节点自动成为Leader，并开始发送心跳包，也就是entries字段为空的AppendEntriesRPC。如果其余的节点发现rpc_term_id大于等于自己的currentTerm时就可以知道已经选出一个新主了，此时选举结束，Candidate重新变为Follower，并同步自己的currentTerm与新主一致。 假设先前是老Leader发生网络分区从而导致选举的产生，在新Leader产生后网络又恢复了。此时他收到了来自新Leader的心跳包。显然这个心跳包中的rpc_term_id比老Leader自己的currentTerm要大，根据任期的约束，老Leader知道了新Leader的存在，切回Follower状态并更新任期。如果老Leader在发现新Leader依然履行了一次职责，发送了一个AppendEntriesRPC。首先它会被Candidate和已经发现新Leader的节点拒绝，因为它们的任期号肯定比老Leader的要大。 别人成为Leader 对应于第一种情况，此时自己发现了大于等于自己的Leader传来的心跳，于是自己退出选举。 没有Leader产生 这发生在没有节点获得过半数的票的情境下，例如有很多Follower的timeout时间比较接近，在选举开始时都timeout变成了Candidate，这时候每个Candidate都会投给自己，所以没有Candidate能获得大多数。此时认为currentTerm + 1届的任期以没有Leader告终，节点们开始下一轮的election timeout。由于每个节点election timeout时间都是随机的，所以下一次出现timeout时间接近的可能性并不高。 投票原则在上一节中我们提到收到RequestVoteRPC请求的节点会根据一定规则进行投票，事实上这是非常重要的，因为我们需要维护领导人完全性的原则。在Raft原论文中，这一部分是放到Safety章节来说明的，因此有必要在阅读此部分时首先查看Log replication章节。首先，我们已经知道在投票的时候一个Candidate必须得到过半数的节点的支持，这是因为每一个已经提交的日志条目必然存在在至少一个这样的节点上。我们上面断言的正确性来自在下面Log replication部分的一个规则：当Leader创建的某日志条目被成功复制到过半数的服务器上时，Leader可以提交该条目。【如何比较日志新旧】下面我们进行另一个断言：如果两份日志最后的条目的term不同，那么term大的日志新。如果两份日志最后的条目term相同，那么日志长的那个就新。如果一个Candidate的日志和大多数的节点一样新，那么它一定持有了所有已经提交的日志条目。具体原因我们在稍后讨论，我们现在要看的是这个断言描述了给VoteFor某个RequestVoteRPC的条件： 远端的term（也就是在RequestVoteRPC传递的）不能小于自己的term 远端的lastLogTerm不能小于自己的lastLogTerm 注意这个条件不能省略，因为脑裂的节点可以无限增加自己的currentTerm，所以实际上仍然需要通过比较日志来决定谁是最新的。 如果远端和自己的lastLogTerm相等，那么远端的lastLogIndex不能小于自己的lastLogIndex 注意，有时候一个刚竞选成功的Leader会收到同term的Candidate的Vote请求，而它会给一个Candidate投票。参考下面的log。这应该是一个错误的实现导致的，当Leader竞选成功时，我们不需要重置其vote_for。 Log replication一旦由当前Leader创建的某日志条目被成功复制到过半数的服务器上时，这个Leader可以Commit该条目及自己日志中该条目之前的所有条目（论文5.4.2节会提到一些细节证明）。这里要求至少过半数实际上为前面的选举投票顺利进行提供了保障，剩余的节点（可能因为宕机或者脑裂没收到）可以在后面慢慢AppendEntries。不需要全部成功复制的原因会在Safety中进行论证。有意思的是即使先前的条目可能是由其他Leader创建的，但这也不影响提交，事实上在下面可以看到，这种方式实际上是唯一的可以提交较旧的term的日志条目的方法。在AppendEntriesRPC中，Leader还通过leaderCommit字段来告知所有的Follower自己当前的提交位置，每个服务器会试图在本地提交直到commitIndex的日志。注意到有的服务器可能在本地并没有这个commitIndex的日志，因此它只能提交到自己最新日志条目的index位置。在更新完后，每个节点会更新lastApplied，从而将新的commitIndex后面的日志条目应用到复制状态机上。在apply之后，Leader便可以向客户返回结果。 leader在commit了一条日志后，立刻宕机会怎么样呢？，我认为领导人完全性(Leader Completeness)要求如果某个日志条目在某个term中已经被提交，那么这个条目必然出现在所有具有更大的term的Leader中。因此不具备该entry的节点不可能被选举为新leader。但是注意新Leader，不能提交来自较旧任期的日志条目。另外，我们还需要注意commitIndex是volatile的。在紧随其后的一节中，我们将看到个已经被存储到大多数节点中的较旧的日志条目也可能被未来的Leader所覆盖掉。但这并不影响本章的论述，因为在这个情形中，并不允许Commit。所以集群中确实可能出现有被超过半数节点拥有的log被新Leader覆盖掉的情况（Figure8），但在这种情况下，c阶段是不能Commit的，因此自然也不会出现Commit的日志被覆盖的情况了。 不能提交来自较旧任期的日志条目(论文5.4.2节)我们将论文中的5.4.2节放到这里来讨论。 首先我们来思考一个问题，如果一个LogEntry已经出现在多数节点上，那么可以认为它已经被Commit了么？答案不是的，因为已经被persist到majority节点中的较旧term的LogEntry也可能被未来的Leader所覆盖掉。因此，我们不能告诉客户端我们已经成功Commit了。我们来看这个经典的对Figure8的讨论。 下面的一张图（也就是原论文的Figure8）展示了当前Leader对具有较旧的term的日志条目进行提交时的一种情况，其中一个已经被存储到大多数节点中的较旧的日志条目（c阶段中的term 2 index 2）也会被未来的Leader（d term 3 index 2）覆盖掉。这也是在提到领导人完全性原则时我们强调了已提交三个字的原因。 (a) 我们首先查看a阶段，此时S1是Leader（被粗黑框框中），生成一个黄色块的条目并复制给S2，此时由于未超过半数，所以S1不能进行提交。 (b) S1未能继续复制黄色条目而崩溃了，此时S5透过S3、S4和S5的选票成为Leader（此时S1已挂，而S2的lastLogIndex和lastLogTerm会让它反对S5）。S5紧接着创建了一个蓝色块条目放到了索引2处，此时如果S5继续复制它的蓝色方块，那么S1和S2的黄色方块肯定会被覆盖掉，不过在这个例子中S5都没来得及复制就挂掉了。 (c) 这时候S1恢复了，这时候它的term最大（是4），并且lastLogTerm能得到S2（相等，但是lastLogIndex不小于，所以可以）、S4的票，因此成功竞选。 现在到了c阶段，这时候S1继续它复制黄色log的未竞伟业，同时创建了一个红色块。S1将黄色log继续复制给S3，这时候按照我们错误的可以提交较旧的条目的假设，S1已经可以提交黄色块了。 可以深入看到这个不一致性，Index为2处的日志被覆盖式地提交了两次，分别是蓝色和黄色。 (d) 如果S1又挂了，因此没能成功提交，这就对应d阶段。S5恢复了，此时它的term最大，因此通过S2、S3、S4当选。这时候它稳定了，于是覆盖了所有的黄色和红色LogEntry。 (e) 如果S1成功复制了日志到S2和S3，这就对应了e阶段。此时红色的LogEntry就能提交了。 如何解决这个问题呢？Raft禁止提交一个较旧的term的条目，即使它已被复制到大部分节点。我们来看看： (c) c阶段中，S1的term是4，但是它不能提交term 2 index 2这个日志。当然，它还是可以继续复制这条日志的。 只有当term 4 index 3这条红色的Entry被复制到大多数之后，才可以提交。 (d) d阶段中，蓝色Log，即term 3 index 2已经被复制到所有机器上了，但是S5仍然不能哪怕是提交自己之前Append的日志。 我们可以参考课后习题的第2题来进一步了解被Commit和被复制到大多数节点之间的关系。我是这样理解的，Raft协议中，并没有把commitIndex作为一个需要persist的内容，这是因为commitIndex作为一个易失字段并不影响Raft的正确性： 如果一个新Leader“接盘”了，如何确定哪些log已经被提交了呢？ 很简单，添加一个no-op操作就行。 其他节点可以读取leaderCommit来确定commit到的log位置 注意某些Follower可能没有到leaderCommit的所有日志。 再次强调，commitIndex是不可能倒退的。 当然，在一些issue中可以看到，保存commitIndex可以实现快速的恢复。 对日志不一致问题的处理下面我们关注Leader的复制请求的结果。其实通过前文已经知道，在正常情况下，Leader的日志始终是和Follower的一致的，所以来自Leader的AppendEntriesRPC始终会是成功的。但一旦Leader或者Follower出现崩溃或者网络发生脑裂，日志就会处于不一致状态。例如有些Follower会比Leader少条目或多条目，这时候就违背了日志匹配原则，导致失败，我们稍后看到这个失败实际上会被用来进行恢复一致性的工作。多条目看起来不可思议，但如下图所示，f就是一种情况，多出来的三个term为2的条目，这是可能是由于它是term为2时的Leader，并且添加了一些日志，但是在提交前崩溃了。 对于这种不一致的状态，Raft有简单粗暴的方法来处理，就是强制Follower直接复制自己的日志，这同时也是领导人只附加原则的要求。而这么做的保证则来自于根据领导人完全性原则，我们的Leader能选举出来就意味着是具有完全的日志的。因此现在的思路就是把Follower一直删到满足日志匹配原则的点为止在这个同步过程中，nextIndex[]和matchIndex[]就派上了用场。nextIndex[]维护了Leader下一个需要发送给Follower的日志序号，当Leader刚选举成功时，它是不知道各个Follower的日志相对于自己的情况的，因此默认nextIndex[]都为自己最后一条日志加一。但这样发出去的日志可能不会被接受，原因是根据之前提到过的日志匹配原则，如果Follower没有Leader的最后一条日志，那么它必然不能匹配Leader发送的AppendEntriesRPC中的prevLogIndex和prevLogTerm所标记，因此它会返回给Leader一个拒绝，此时Leader就会减小对应的nextIndex并重试。我们需要特别注意的是在这个过程中Follower的日志是有可能被Leader覆盖的。Raft论文指出这里其实是可以进行优化的（论文5.3节旁注），但这个优化并不是很必要的，因为现实中失败很少发生，而且也不大可能会造成很多的日志不一致的问题。容易看出，这种算法是非常优雅的，因为它把恢复一致性的过程和正常增加日志的过程统一起来了，我们不需要对恢复一致性过程额外进行设计，可想而知这个额外设计是相当麻烦的，因为我们还要考虑在回复一致性过程中出现失败的情况。 有关强制复制日志的细节由于实现细节的问题，可能会导致MIT 6.824 Lab2的TestFigure8Unreliable2C过不了，可以查看代码的on_append_entries_request函数的847-881行(node.h)，对比下一个commit。 Safety这一部分的论述对应了原论文安全性论证部分，证明了上面的Leader election和Log replication的算法是可靠的。 有关领导人完全性的论述(论文5.4.3节)现在我们利用反证法证明领导人完全性。首先我们提出反命题，即存在一个term为T的Leader提交的日志条目没有被其后的term为U的Leader所拥有。因此我们进行下面的推导 根据领导人只附加原则，这个记录在U竞选时就就不存在。 考虑到这个日志条目已经被提交，所以Leader T一定已经把它复制到过半数的集群上了；同时考虑到Leader U当选，所以它也收到了过半数的票。因此至少有一个节点它既拥有Leader T的日志条目又投票给了Leader U。我们考虑这个投票者。 这个投票者必然在投票给Leader U前接受了来自这个Leader T的日志。如果它在投票后才接受到来自Leader T的AppendEntriesRPC，那么它肯定会拒绝这条RPC，因为当收到来自Leader U的RequestVoteRPC时，这个投票者就已经更新自己的currentTerm了，因此现在它的currentTerm肯定大于RPC中的rpc_term_id。 这个投票者在投票时也保留了这个来自Leader T的日志。这是由于经过所有中间term的Leader都保有这个日志条目（我们假设中U是第一个没有这个日志条目的任期）。而Follower只有在日志和Leader冲突时才会丢日志。 既然这个投票者给Leader U投票，那么Leader U的日志必然不会比投票者的日志要旧。我们接下来从index更大和term更新两种情况来讨论。 首先假如投票者和Leader U当前的term是相同的，那么Leader U就会拥有更大的index，也就是日志更长。既然如此Leader U应当具有投票者当前所有的日志。 其次，另一种情况下，Leader U的最后一条日志的term要比投票者的最后一条日志大，并且要大于T。这是因为投票者的最后一条日志的term至少是T，毕竟投票者拥有一条在Leader T任期内提交的日志。而根据我们的假设，Leader U之前的Leader也拥有这样的一条日志。那么根据日志匹配原则的要求，Leader U也应当包含这个日志条目。 有关非Leader节点故障的讨论(论文5.5节)Follower和Candidate节点的故障是相对简单的： 如果还未完成RPC就宕机 在重启后，可以继续完成。 如果完成了，但还没有回复 在重启后，仍然会收到相同的RPC。因为这个是幂等的。 有关可用性的讨论（论文5.6节）有关脑裂（网络分区）的讨论由于某些节点的失效，部分节点的网络连接会断开，并形成一个与原集群一样名字的集群，这种情况称为集群脑裂(split-brain)现象。这个问题非常危险，因为两个新形成的集群会同时索引和修改集群的数据。Raft协议能够解决由于网络分区导致的脑裂，我们从脑裂过程中和脑裂恢复后两个阶段来讨论。 在脑裂过程中，Raft仍然保证了至少$N/2+1$的共识。特别地，当网络分区多于两块的时候，会不会存在有两个分区中都选出了新的term相同的Leader呢？我认为应该是不可能的，因为成为Leader必须达到全局的多数$N/2+1$张票，最多只能有一个。所以当分区较多的时候，很可能无法选出新Leader。另外某节点也不容易去“获得当前分区的多数票”，因为它也无法界定当前分区的范围。 Membership changes相比整体下线集群在重新启动的方法，Raft提供另一个方案。为了保障安全性，我们需要在新旧配置的过渡期间确保四个基本原则的基石之一，Leader与term一一对应不会被打破。论文指出直接做切换时不现实的，如下图所示，当集群规模从3变为5时，存在时间点使得集群分划为两个部分，其中绿色部分使用旧配置$C_{old}$进行选举，蓝色部分使用新配置$C_{new}$进行选举。因此Raft使用两个阶段实现配置转换。两阶段的转换有很多种方法，例如可以在第一阶段禁用旧配置，然后在新阶段启用新配置，这样在两个阶段之间系统不能响应客户请求。Raft的解决方案是第一阶段切换到一个过渡的称为joint consensus的配置上，当joint consensus被提交之后，系统再转换到新配置上，这样就不会存在新老配置共存的问题。joint consensus阶段要求如下： 日志条目应当被复制到对应到新旧两种配置的所有机器上。 两种配置中的任意服务器都可以作为Leader。 选举和提交日志的共识必须同时经由两种配置的多数同意。也就是说要得到两种配置下各自的过半票数。 在下图中，虚线部分表示已创建未提交的日志配置条目，实现部分表示被提交的配置条目。可以看到配置转换过程被分为三个阶段： 从Leader收到配置变更请求到在$C_{old, new}$被提交前 此时单独根据$C_{old}$决议。 首先，Leader在收到配置变更请求后，生成一个表示$C_{old, new}$这个配置的日志条目，并按照通常的方式AppendEntry。一旦这个日志提交成功，集群进入joint consensus状态。特别地，节点只要收到新配置的AppendEntry就会切换到新配置，无论这个AppendEntry有没有被提交。因此提交成功只是说明进入了joint consensus状态，此时很多节点已经切换到了配置$C_{old, new}$。 当Leader提交了配置$C_{old, new}$对应的日志条目时，它一定是使用的这个配置进行的决议。当Leader在这一阶段崩溃时，新选举的Leader可能是$C_{old, new}$，也可能是$C_{old}$。 在$C_{new}$被提交后到配置变更完成 此时单独根据$C_{new}$决议。 特别地，如果Leader使用$C_{new}$配置的话，这个时间节点可以提前到$C_{new}$被创建。 在1和2的中间阶段，即joint consensus状态 在这一阶段配置$C_{old, new}$已被提交，此时$C_{old}$退出舞台。由于Leader已被提交，所以领导人完全性原则保证了没有$C_{old, new}$的Candidate注定选举失败。此时Leader节点可以安全地去AppendEntry配置$C_{new}$的条目了。 三个Issue 刚加入的新节点没有日志 这里指的是我们计算多数的时候不考虑他们的投票权。此时他们仅接受日志的复制，不参与包括commit、vote之类的投票，这一阶段的结束。 Leader不在新配置里面 此时，当Leader提交完$C_{new}$后，就要Step Down回到Follower状态。这也说明了有一段时间Leader会去管理一个不包含自己的集群。 删除节点 被删除的节点不会收到来自Leader的RPC了，因此可能会超时，继而发送RequestVoteRPC来竞选，从而影响可用性。为了解决这个问题，所有节点可以忽略这些投票请求，知道他们认为现在存在一个Leader。 实现liblogcabin的实现方案是列出一个Configuration类，这个类包含以下几个关键信息 Configuration::State state 这是个enum类型，包含四种可能值BLANK、STABLE、STAGING、TRANSITIONAL。分别对应于集群初始化、正常运行、Issue1的解决方案和joint consensus状态。 quorumAll() 是否获得当前配置下的多数票，这里需要根据TRANSITIONAL分类讨论。 Log compactionRaft采用了Snapshot的方法来实现日志持久化，这种方法是独立于Raft的Strong Leader的原则的，这是由于每个节点的Snapshot的状态对Leader来说是透明的。论文中指出这样做是合乎情理的，这是由于我们Snapshot的东西都是经过一致性检验的，所以不会存在冲突，Snapshot只是Follower去reorganize自己数据的行为。此外，由Leader创建日志而非Follower创建日志有以下的弊端： 网络开销 这是因为Leader要将Snapshot复制到每个Follower，而这是冗余的，因为Follower实际上有全部信息。 实现复杂 InstallSnapshot当Leader发现Follower[i]的next_index已经严重落后，落到了自己的snapshot里面（next_index[i] &lt;= get_base_index()），就应当发送InstallSnapshot RPC催促其补上。这个RPC应当包含Leader自己持久化的log，这部分应该是已经提交了的。当Follower收到这个RPC时首先进行例行判断，例如term是否大于等于自己的current_term并更新，否则拒绝。如果自己是Candidate要切换回Follower，重新超时等等。接着直接dump下来Leader的snapshot。一个Snapshot表示state machine到last_included_index为止的状态，因此last_included_index必须位于已apply（而不是commit）的日志。在创建snapshot之后，我们可以将直到last_included_index的所有日志压缩成一个日志。 持久化我们需要区分持久化persist和快照snapshot技术。persist指持久化论文Figure2列出的vote_for、current_term和logs三个状态。特别注意诸如commit_index是volatile的。 关于持久化的问题为什么必须要持久化voteFor见习题6 为什么必须要持久化term显然，恢复后简单设置term为0肯定是不行的。那么如果我们设置term为log里面最新的term，是否可以呢？答案肯定也是不可以。在这里修改了知乎上一个例子。假设有机器S1、S2和S3，其中S1和S2是分区的（注意S1/S3，S2/S3这两个是连通的）。 S1成为Leader 显然，是通过S3的票上位的。S2因为分区，并没有收到请求，因此保持term为0。 S1添加了&lt;1,1,a&gt;，即index为1，term为1，内容为a S1没有进行任何复制就宕机了，但没有恢复 S3也宕机并重启了 因为S3没有缓存之前的term即1，所以读取log，发现为空，即term为0 在新一轮选举中S3成为Leader 可以发现，是S2投票的。S1这个时候还在宕机呢。 S3添加了&lt;1,1,b&gt;，并且提交了 S3宕机了 S1和S3从宕机中恢复了 此时，S1的日志是&lt;1,1,a&gt;，S2和S3的日志是&lt;1,1,b&gt;。那么原则上S1和S3都有可能成为Leader。那么&lt;1,1&gt;处的日志到底是a还是b呢？ 为什么必须要持久化logs见习题6 为什么不需要持久化commitIndex见“有关领导人完全性的论述(论文5.4.3节)” 为什么不需要持久化lastApplied我认为这个取决于我们状态机的实现。如果我们的状态机做不到幂等，那我觉得重启之后lastApplied是0，再搞一遍，肯定就有问题。 Raft的优化PrevotePrevote是Follower在超时进入Candidate状态前的行为。此时Follower进入PreCandidate状态，进行一轮Prevote。只有当Prevote获得大多数节点的赞同时，Follower才会正式超时。Prevote的引入减少了由于网络抖动等因素导致的主节点切换现象。 异步Apply使用一个新线程去Apply已经Commit的log。这么做的好处是，前面的Append Log Entry部分和Apply分离了，能提高吞吐量。我们注意，因为Raft不允许日志空洞，以及顺序Commit的特性，导致我们可以认为已经Commit的日志就可以Apply，但对于诸如MultiPaxos这样允许日志空洞的协议是不行的。 异步Append这里的异步指的是可以先并行发送log给所有的Follower，然后在Append给自己。 Follower Snapshot由Follower节点而非Leader节点发送Snapshot。这种做法能够降低Leader的负担。 Pipeline在有关复制状态机的介绍中已经介绍了有关Pipeline的机制。 当Leader向Follower发送了一个AppendEntries请求之后，它需要等待返回才能更新next_index从而继续后面的流程。Pipeline允许Leader在发送一个请求之后立即更新next_index，从而不等待返回以发送后面的请求。我们这么做的原因是我们认为网络在大多数情况下是正常的。但如果不幸在过程中出了问题，就可能需要重新发送log。 在这样的实现中可以在RPC消息的回复中附带上last_log_index和last_log_term。 BatchBatch策略指将多个来自客户端的请求打包到一个Raft Log中。这有点类似于我们在LevelDB中看到的WriteBatch。 成员变更的一阶段办法Raft习题讲解MIT6.824见MIT 6.824做题笔记。 官方习题本习题来自于作者的博客，知乎提供了中文版。 1下面四幅图中，哪些Server Configuation在Raft中是合法的呢？a是不合法的，这是因为term应该是递增的。创建index=4的Leader一定是从一个term大于等于3的Leader中获得index=3的条目的，我认为，AppendEntriesRPC附有当前Leader的term，当index=4的Leader在添加index=3的条目时候，它的term必然不会小于当前Leader的term，即3。d是不合法的，Raft日志不允许空洞，但Paxos允许。 2下面哪些日志是可能被安全地apply的？我们把机器从上到小编号为S1到S5。 首先，我们现在的term是4。在这个任期中，Leader创建了一个&lt;7,4&gt;，没有达到quorum，这个肯定是提交不了的。用类似的办法，通过比较quorum，我们可以排除到只剩下面5个条目，用&lt;Index,Term&gt;表示如下。1&lt;1,1&gt;, &lt;2,1&gt;, &lt;3,2&gt;, &lt;4,2&gt;, &lt;5,2&gt; 我们知道，“当Leader创建的某日志条目被成功复制到过半数的服务器上时，Leader可以提交该条目”，但我们不能忽略Figure8的情况，即“不能提交来自较旧任期的日志条目”，所以要等到&lt;7,4&gt;被提交之后，才能安全提交S1的1到5的日志。后来看答案发现，题目不是这个意思，比如说commitIndex是volatile的，没啥讨论的意义。所以题目的意思是，从一个全局的视野，根据Log判断哪些Entry是可以被安全地commit的。实际上，虽然我们有了Leader for term 4，但由于这个Leader可能没来得及提交&lt;7,4&gt;就Fail，导致重新选举，到时候新Leader可能就不是它了。所以这个问题等价于从日志判断讨论Leader可能是谁，然后我们假设这些节点分别成为了Leader，可能移除掉哪些Entry。S1：LastLogTerm为4，秒杀所有，足够quorum。S2：LastLogTerm秒杀除S1外所有，足够quorum。S3：它的LastLogTerm比S4要大，有1票；它的LastLogTerm和S5一样，此时需要比较LastLogIndex，这个比不过S5，因此总共2票，不够quorum。S4：它的LastLogTerm比S1/S2/S3/S4要小，只有1票，不够quorum。S5：它的LastLogTerm比S4要大，有1票；它的LastLogTerm和S3一样，但是LastLogIndex比S3大，因此总共3票，足够quorum。 下面，我们就要在S1、S2和S5中间取一个交集。特别地，如果S2当选，可能会移除掉S1现有的从index=3开始的所有条目。这也对应了我们“已经被存储到大多数节点中的较旧的日志条目也可能被未来的Leader所覆盖掉”的论述。综上，只有1和2是可以safely applied的。 3下图显示了一个6台服务器集群中的日志，此时刚刚选出term为7的新Leader。对于图中每一个Follower，给定的日志是否可能在一个正常运行的Raft系统中存在？首先，我们确定一点，就是index=1和2的日志条目是已经被提交了的。a是不合法的，因为违背了日志匹配原则。事实上因为a的&lt;5,3&gt;和选出的Leader是Match的，因此它前面index=3和4的term也应该和Leader是Match的，即都是3。b是不合法的，原因类似于a。我认为c是不合法的，因为此时Leader的term才是5，怎么可能会出现一个term为6的条目呢？但是我这里做错了，c是合法的，而且我看错了，现在Leader的term是7。例如，当大家都只具有日志&lt;1,1&gt;, &lt;2,1&gt;的时候（但不一定就是这个条件），其实c可能自己是term为6的Server，它在还没有来得及复制自己任期内的日志的情况下就挂掉了。d是不合法的，因为term没有单调递增，可以参考第一条。e是合法的，原因类似于c，其实它可以看做是最一开始的Leader，然后被分区了。 4假设硬件或软件错误破坏了 Leader 为某个特定 Follower 存储的nextIndex值。这是否会影响系统的安全？我认为是不会的，因为nextIndex的设计就是volatile的。事实上，如果nextIndex太小，相当于Leader发送了多余的日志，AppendEntriesRPC会返回一个成功，此时Leader就会增加nextIndex，这样通过有限次AppendEntriesRPC，nextIndex就会重新收敛到准确值。如果nextIndex太大，AppendEntriesRPC会返回一个失败，此时Leader会减小nextIndex。事实上，当一个Leader新被选举出时，他就是通过这种机制得知每个Follower的nextIndex的。当然，我们也没必要每次逐一递增或者递减，我们在正文部分提到过一些优化点。 5假设你实现了Raft，并将它部署在同一个数据中心的所有服务器上。现在假设你要将系统部署到分布在世界各地的不同数据中心的每台服务器，与单数据中心版本相比，多数据中心的Raft需要做哪些更改？为什么？这个题目我还真不知道怎么回答，贴一下标准答案。We’d need to set the election timeouts higher: my expected broadcast time is higher, and the election timeout should be much higher than the broadcast time so that candidates have a chance to complete an election before timing out again. The rest of the algorithm does not require any changes, since it does not depend on timing. 6【这一条主要考察Raft三个持久化项目的原因】 每个Follower都在其磁盘上存储了3个信息：当前任期（currentTerm）、最近的投票（votedFor）、以及所有接受的日志记录（log[]）。 a. 假设Follower崩溃了，并且当它重启时，它最近的投票信息已丢失。该Follower重新加入集群是否安全（假设未对算法做任何修改）？ 这个是不安全的，事实上我也犯过类似的错误，即Leader election/投票原则 这个章节列出的问题。7104成了Leader，但是重置了voteFor，导致后面投票给了7103，从而出现了两个Leader。其实还有一个节点S2会既投票给S1又投票给S3的场景，假设一个容量为3的集群，即S1和S2票了S1成为Leader，但是S2迅速重启，并且忘了投票给S1，此时S2收到了S3的投票请求，并投票给了S3，此时S3也会称为Leader。 b. 现在，假设崩溃期间Follower的日志被截断（truncated）了，日志丢失了最后的一些记录。该Follower重新加入集群是否安全（假设未对算法做任何修改）？ 这个是不安全的。容易发现，丢失最后一些记录的影响是有可能成为Majority的日志条目达不到Majority了。而又因为根据题目2的思路，我们可以（也只能）单纯通过日志判断哪些日志条目是可以被安全提交的，所以这些达不到Majority的日志可能在丢失前已经被提交，但在丢失后被认为没有提交。 在答案中，还举例解释了可能的后果，即这会导致这些被提交的entry被覆盖。同样地，对于一个3节点的集群：S1作为term2的Leader，添加了index=1的条目&lt;1,2,X&gt;，X是这个条目的内容。稍后，由于这个记录已经被复制到了S1和S2，所以它被成功提交。此后，S2重启，并丢失了所有记录。后面由于一些网络抖动的因素，S1被分区，S3变成了term3的Leader（通过S2和S3的票，因为他们的LogEntries都是空），然后它添加了index=1的条目&lt;1,3,Y&gt;，这个条目同样可以被提交。那么此时index=1处的值既被提交为了X又被提交为了Y，不一致性发生了。 7即使其它服务器认为Leader 崩溃并选出了新Leader后，老Leader依然可能继续运行。新的 Leader 将与集群中的多数派联系并更新它们的term，因此，老的Leader将在与多数派中的任何一台服务器通信后立即下台。然而在此期间，它也可以继续充当Leader，并向尚未被新Leader联系到的Follower发出请求；此外，客户端可以继续向老的Leader发送请求。我们知道，在选举结束后，老的Leader不能commit任何新的Log Entry，因为这样做获得多数派中的至少一台服务器的认可。但是，老的Leader是否有可能执行一个成功AppendEntries RPC，从而完成对选举开始前收到的旧日志记录的提交？如果可以，这是否会给Raft协议带来问题？ 这个题目描述的场景我没有真实遇到过，所以只能分析。首先老Leader的RPC只能发给少数派Follower，这些Follower也并未知晓新Leader的产生。但是如果新选出的Leader有包含老Leader的旧日志的话，那么其实这些旧日志是能够达到Majority的要求的。但对于是否会被覆盖这一点，我并没有什么结论。 看答案，实际上是可能存在这种情况的，这也发生在新Leader包含了老Leader这一部分的日志。在答案中给了一个具体的例子，涉及到一个5个节点的集群。S1，日志为空，通过S1、S2和S3的票成为了term2的Leader。稍后，它添加日志&lt;1,2,X&gt;，并且复制到S2。此后，这个S2通过S2、S4、S5的票成为了Leader。这里按照投票原则，S3也应该会投票的啊？其实S3和S1被分区了。在这之后，S1完成发送&lt;1,2,X&gt;到S3，在此时，S1完成了&lt;1,2,X&gt;的提交，即使它不再是这个term的Leader了。这个论述其实和我上面的论述是一致的，而下面给出了为啥不会被覆盖的论证。 这个是安全的，因为新Leader也具有老Leader提交的Entry，这会导致这个Entry被持久化，这是因为：这Entry肯定也在一些给新Leader L投票的机器S上存在，并且必须在S投票之前就存在。log completeness check要求在投票时检查对端的lastLogTerm和lastLogIndex必须至少都大于等于自己的。下面我们分类讨论：如果L是S之后的第一个Leader，那么必然有L.lastLogTerm == S.lastLogTerm &amp;&amp; L.lastLogIndex &gt;= S.lastLogIndex，即L拥有S拥有的所有Entry，包括我们担心的那一条。如果L是S之后的第二个Leader，那么如果他从前一个Leader M中收到了Entry，那么必然有L.lastLogTerm &gt; S.lastLogTerm，但是M肯定在复制自己的Entry之前，就已经将我们担心的那一条日志复制给了L，因此这也是安全的。由此扩展，我们可以推论到任何其他的Leader。 8在配置变更过程中，如果当前Leader不在C-new中，一旦C-new的日志记录被提交，它就会下台。然而，这意味着有一段时间，Leader不属于它所领导的集群（Leader上存储的当前配置条目是C-new，C-new不包括 Leader）。假设修改协议，如果C-new不包含Leader，则使Leader在其日志存储了C-new时就立即下台。这种方法可能发生的最坏情况是什么？ 首先，下台意味着什么呢？在C-new之前，C-old已经结束使命，配置C-joint已被提交，任何决议的提交都需要经过new和old的过半数的同意才行。那么下台意味着只要C-new日志被Leader存储，它就立即变成Follower，那么这个集群不再具有Leader，从而会发生选举，选举也是按照C-joint来选举的。考虑如果选出一个在C-old中的Leader，那么它会重复之前的流程，增加一个C-new，然后下台。这个流程会一直重复到C-old中的Majority都得到了C-new日志，这样剩余没有C-new日志的C-old机器也不能被选举为Leader了。这里注意，我们在讨论一个最坏的情况，就是每一次选举都是C-old中被选中，并且也不进行任何复制，因此所有C-new中的所有机器都没有收到C-new的日志。所以产生的结果就是最坏会有|C-old/2|次冗余选举。 Reference https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&amp;mid=2247494453&amp;idx=1&amp;sn=17b8a97fe9490d94e14b6a0583222837&amp;scene=21#wechat_redirect 有关幽灵日志的相关内容 https://github.com/ongardie/raft.tla/blob/master/raft.tla 关于Raft的TLA的内容 https://www.zhihu.com/question/382888510 讲解了为什么currentTerm需要持久化 https://zhuanlan.zhihu.com/p/47025699 有关幽灵日志的讨论 http://oceanbase.org.cn/ 郁白在OB的实践 http://oceanbase.org.cn/?p=160 成员变更]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jepsen使用]]></title>
    <url>%2F2019%2F02%2F20%2Fjepsen%2F</url>
    <content type="text"><![CDATA[Jepsen是一款用来验证分布式系统安全性的工具。 安装Jepsen是使用Clojure编写，Clojure基于JVM上的一款Lisp方言，本文假设对Lisp和函数式编程是有基础知识。特别地，我们关注以下几点语法 函数 函数使用defn定义，使用一个中括号接受参数。在参数列表中可以使用[&amp; args]，表示&amp;之后的args是一个可变参数列表。函数可以拥有多个重载，如下面代码所示 12345(defn hello3 ([] "Hello World") ([name] (str "Hello " name)))(hello3 "Jake") ; =&gt; "Hello Jake"(hello3) ; =&gt; "Hello World" 函数调用 使用/调用静态函数，例如c/cd调用类c里面的cd方法。 使用.调用成员函数，例如. (Date.) getTime调用了一个Date类型的对象Date.的成员方法getTime 映射数据结构 我们使用如下所示的方式定义一个Map 1234(def popsicle-map (hash-map :red :cherry, :green :apple, :purple :grape))(def popsicle-map &#123;:red :cherry, :green :apple, :purple :grape&#125;) ; same as previous 然后使用这样的方式访问其中的元素 123(get popsicle-map :green)(popsicle-map :green)(:green popsicle-map) doto 类似vb里面的With reify 创建一个继承某个特定interface/protocol或者java.lang.Object的匿名类。 Leiningen是Clojure项目的自动化配置工具，可以通过其官网的自安装脚本使用。 在Docker上配置JepsenJepsen官方推荐的Jepsen使用方式是借助于Docker或者虚拟机。特别地，试图用同一个IP上的多个端口来处理是很麻烦的。因此使用Docker是单机上运行Jespen的做法。以etcd测试为例，Jespen喜欢从官网上下载项目的release并安装，这对于国内用户是相当不友好的。对此，我们可以进入Jespen项目中的docker/control文件夹，将我们需要的binary放进去。这样在up.sh中，Jepsen会统一将control目录中的文件进行打包拷贝到容器中。接着我们修改Dockerfile，用来将我们传入容器中的release安装到指定位置。以etcd为例，我们编写如下所示的代码1234# /docker/control/DockerfileRUN mkdir -p /opt/etcd/ADD ./etcd /opt/etcd/etcdADD ./etcdctl /opt/etcd/etcdctl 并且注释掉etcd/src/jepsen/etcd.clj里面的从googleapis下载etcd的命令。 接着我们清除旧的容器，并启动新的1234docker stop $(docker ps -aq)docker rm $(docker ps -aq)bash ./up.shdocker exec -it jepsen-control bash 常见错误ssh配置问题我在使用百度的jepsen时出现这个错误。通常原因是没有配置好ssh12345lein test :only jepsen.atomic-test/create-partitionERROR in (create-partition) (Session.java:512)Uncaught exception, not in assertion.expected: nil docker配置问题下面这个错误的第一个原因是jepsen-control上没有sudo12ERROR [2019-02-21 14:04:00,576] main - jepsen.cli Oh jeez, I'm sorry, Jepsen broke. Here's why:java.util.concurrent.ExecutionException: java.lang.RuntimeException: sudo -S -u root bash -c "cd /; echo \`date +'%Y-%m-%d %H:%M:%S'\` \"Jepsen starting\" etcd \":--name n1 :--listen-peer-urls http://n1:2380 :--listen-client-urls http://n1:2379 :--advertise-client-urls http://n1:2379 :--initial-cluster-state :new :--initial-advertise-peer-urls http://n1:2380 :--initial-cluster n1=http://n1:2380,n2=http://n2:2380,n3=http://n3:2380,n4=http://n4:2380,n5=http://n5:2380 :--log-output :stdout\" &gt;&gt; /opt/etcd/etcd.log" returned non-zero exit status 1 on n1. STDOUT: 第二个原因是jepsen-n1等节点上没有etcd，我们需要改以下的细节 在up.sh中加上 123456INFO "Copying .. to node/jepsen"( rm -rf ./node/jepsen mkdir ./node/jepsen (cd ..; tar --exclude=./docker --exclude=./.git -cf - .) | tar Cxf ./node/jepsen -) 参照control/Dockerfile修改node/Dockerfile 将etcd也复制到node文件夹里面 修改etcd.clj里面的代码，注释掉下载etcd和删除etcd文件夹的语句。 etcd问题在control节点中运行lein run test --concurrency 10时出现这个问题123456789101112INFO [2019-02-22 07:37:52,339] jepsen worker 5 - jepsen.util 35 :invoke :write [0 1]INFO [2019-02-22 07:37:52,347] jepsen worker 1 - jepsen.util 31 :info :cas [0 [1 4]] indeterminate: Connection refused (Connection refused)INFO [2019-02-22 07:37:52,348] jepsen worker 8 - jepsen.util 38 :invoke :cas [0 [3 0]]INFO [2019-02-22 07:37:52,352] jepsen worker 3 - jepsen.util 33 :info :cas [0 [0 0]] indeterminate: Connection refused (Connection refused)INFO [2019-02-22 07:37:52,355] jepsen worker 9 - jepsen.util 39 :invoke :read [0 nil]INFO [2019-02-22 07:37:52,360] jepsen worker 0 - jepsen.util 30 :invoke :read [0 nil]INFO [2019-02-22 07:37:52,396] jepsen worker 7 - jepsen.util 37 :invoke :cas [0 [3 0]]INFO [2019-02-22 07:37:52,407] jepsen worker 1 - jepsen.util 41 :invoke :cas [0 [1 2]]INFO [2019-02-22 07:37:52,411] jepsen worker 3 - jepsen.util 43 :invoke :read [0 nil]WARN [2019-02-22 07:37:52,422] jepsen worker 0 - jepsen.core Process 30 crashedjava.net.ConnectException: Connection refused (Connection refused) at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_191] 查看n1节点的etcd日志发现以下错误122019-02-22 07:37:45 Jepsen starting etcd :--name n1 :--listen-peer-urls http://n1:2380 :--listen-client-urls http://n1:2379 :--advertise-client-urls http://n1:2379 :--initial-cluster-state :new :--initial-advertise-peer-urls http://n1:2380 :--initial-cluster n1=http://n1:2380,n2=http://n2:2380,n3=http://n3:2380,n4=http://n4:2380,n5=http://n5:2380 :--log-output :stdout2019-02-22 07:37:46.021492 E | etcdmain: error verifying flags, expected IP in URL for binding (http://n1:2380). See 'etcd --help'. 这是因为我们在url里面使用了n1、n2这样的名字。修改etcd.clj里面的代码，将所有的name改成jepsen.control.net/ip即可解决问题。特别地，这个问题在jepsen的一个PR中出现过]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>Clojure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通用生产力软件工具指南]]></title>
    <url>%2F2019%2F01%2F22%2Fcommon-software%2F</url>
    <content type="text"><![CDATA[最近换了新电脑，进行配置的时候遇到很多坑，这里记录一下常用的软件的一些注意事项。 mobaXTermmobaXTerm应该是Windows下最漂亮的SSH软件了。但其SSH-Browser经常断开连接。这里注意将其选为SCP而不是SFTP。 VMWare在新电脑下，主屏幕的缩放比是150%，外接显示屏是100%。在使用VMWare并且安装了VMWare Tools之后，虚拟机显示仍然不正常。最影响使用的是由于分辨率出现问题，导致鼠标不能正常点按。这里推荐使用以下配置。如果下面的配置还没有用，就改成应用程序。 虚拟机上不了网也是问题常客，一般我们ifconfig一下会发现eth0网卡没了。这里推荐在VMWare的虚拟网络编辑器中还原默认配置，并且查看VMware NAT Service这个Windows服务是否在正常工作。 此外在迁移虚拟机的时候建议先关机，这样可以减少复制开销。此外，有的时候由于硬件的差别，虚拟机到新机器可能打不开，这时候至少也要重置（相当于重启了），因此不如在老机器就直接关闭了。 “驱动程序vmci.sys版本不正确”这种错误就是上面说的，迁移计算机常见的问题。 如果“安装VMTools”的菜单是灰的，需要先关机，然后将CD/DVD、软盘等项目改为自动探测。 注册码/激活码 VSCode远程开发首先安装Remote SSH插件，在配置处勾上Reveal Login Terminal。通过编辑配置脚本的方式新建一个连接1234Host name HostName hhh User uuu Port ppp 在本地执行1ssh-keygen -t rsa 添加id_rsa.pub到远程的.ssh/authorized_keys 安装clang format通过clang format可以将代码自动格式化为不同的代码风格。首先，在VS Code上安装Clang-Format插件，这个插件实际上是安装到远程的。然后在Clang-format: Style的配置项上面选择Google值。注意，还要在远程机器上面安装Clang format1pip install clang-format 注意，有的人说yum install clang，这是错误的]]></content>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haskell中的多态]]></title>
    <url>%2F2019%2F01%2F16%2FHaskell-polymorphism%2F</url>
    <content type="text"><![CDATA[一般地来说，一个值（这里的值也包括普通函数）是多态的，当它可以是多种类型的。Haskell原始支持的多态分为参数多态和ad-hoc多态。在文章haskell学习笔记中提到了Parametric polymorphism、higher kinded polymorphism和higher rank polymorphism三个概念，我们将在本文中详细探讨。 参数多态和Ad-hoc多态参数多态参数多态(Parametric polymorphism)类似于其他语言中的泛型（模板），此时一个值的类型中包含多个(unconstrained) type variable。12id :: a -&gt; aid x = x 1234template &lt;typename T&gt;auto id(T x)&#123; return x;&#125; 在上面的代码中，a称为(unconstrained) type variable，它可以是任意的，这体现在没有=&gt;这样typeclass的约束。因此这也隐含了对于不同的类型，多态值的行为都是一致的，这是因为parametrically polymorphic value本身对自己的type variable类型一无所知。 Ad-hoc多态相对应地，Ad-hoc显得更随机应变。此时，这个多态值可以采用若干类型其中的一个，对于每一种不同类型，他们的行为都是不同的。例如对于(+)，它对浮点数的处理和对整数的处理显然是不一样的。特别地，typeclass中定义的函数也可以是类型多态或Ad-hoc多态的，这在文章haskell学习笔记的Ch3有详细探讨。 Rank N多态Haskell中的Rank N Types模块实现了higher rank polymorphism的概念。首先我们研究什么是Rank 1，123&#123;-# LANGUAGE RankNTypes #-&#125;id :: forall a. a -&gt; a 引入的forall显式说明id能够作用在任意的(universally quantified)类型上。 接下来是Rank 2，123type IdFunc = forall a. a -&gt; aid :: IdFuncid x = x 在上面的代码中，我们为forall a. a -&gt; a这样类型的函数创建了一个alias，称为IdFunc，然后我们定义了一个IdFunc类型的函数id。在这一步中，type variable a消失了。紧接着我们又定义someInt这个函数，这个函数是monomorphic的，虽然它接受一个polymorphic的参数。12someInt :: IdFunc -&gt; IntegersomeInt id' = id' 3 进一步看函数someInt，它要求我们去传入一个多态函数，但自己却是单态的。这样的函数在原始Haskell中是不允许的，支持它们会给类型推导带来困难。 从另一个角度查看这个问题，1a -&gt; b -&gt; a 上面的type signature隐含了a和b这两个type variable是universally quantified的，因此可以被写作1forall a b. a -&gt; b -&gt; a forall关键字可以被提到(-&gt;)的右边，或者(-&gt;)右边的forall可以提到前面（正如(-&gt;)是右结合的）。即下面的形式也是Rank-1的，并且与上面的写法都等价1forall a. a -&gt; (forall b. b -&gt; a) 但是在某一个(-&gt;)左边的forall不可以被提出。下面的语句中，后面的forall可以被提到最前面，因为它在(-&gt;)的右边；而前面的forall则不能提到最前面。1(forall a. a -&gt; a) -&gt; (forall b. b -&gt; b) 我们发现在上面的语句中出现了两个层面的universal quantification，forall b能够被提到最前面，适用范围更广一点。这样的类型就是Rank-2的。123456Prelude&gt; f :: (forall a. a -&gt; a) -&gt; (forall b. b -&gt; b)&lt;interactive&gt;:3:15: Illegal symbol '.' in type Perhaps you intended to use RankNTypes or a similar language extension to enable explicit-forall syntax: forall &lt;tvs&gt;. &lt;type&gt; 类型多态在先前，我们讲到的“函数”都是关乎值的，而类型多态，也就是higher kinded polymorphic，可以看做类型和类型之间的函数。 子类多态Haskell并没有提供子类多态的性质。子类多态实际上是雷子Protocol、Interface、Inherit这样的东西。 Reference https://ocharles.org.uk/blog/guest-posts/2014-12-18-rank-n-types.html https://www.stephanboyer.com/post/115/higher-rank-and-higher-kinded-types https://wiki.haskell.org/Rank-N_types https://wiki.haskell.org/Polymorphism]]></content>
      <tags>
        <tag>Haskell</tag>
        <tag>lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[曼谷/芭提雅游记]]></title>
    <url>%2F2019%2F01%2F15%2Ftravel-bangkok%2F</url>
    <content type="text"><![CDATA[今年去泰国跨年（避寒）了，30号到4号，一共玩了五天。 有关交通往返都是泰国狮子航空（禄口-廊曼），这是一家廉航。在坐前还是蛮紧张的，因为今年印尼狮航刚掉过飞机，KO了几百号人。实际做下来的话安全倒还不错，起飞的时候飞机都在上下震动有点感觉要散架，虽然要是真散架了那大家材料力学都白学了。这家航空公司对行李托运并不严格，朋友的29寸都能上，并且值机人员以及空乘都非常nice。座位前后空间确实很小，而且基本是满客的。机上提供收费食品，那个冬阴功泡面卖60泰铢，如果你想泡自己的泡面也可以，不过要收热水费。关于接送机，接机是房东安排的，我们用grab从central world打到廊曼是360泰铢。到了机场的时候还差点出事，因为我们现金不够，而司机点了只能现金支付的选项。最后我们找到路边的新人请求帮换泰铢，那人很nice，表示非常想收集RMB，于是我们就用2张20的换了200的泰铢，那人还额外给了司机20小费。曼谷市内是个大堵城，我们住的地方是水门市场，算是曼谷新城区的市中心了。但是到像大皇宫之类的老城的地方就很麻烦，出租车要给到300泰铢左右。这里推荐坐船过去，水门市场正好是第一站，坐到老城区是第七站近帕苏曼堡，穿过法政大学就到了。每人200泰铢一天随便坐。讲到市内出行，曼谷的出租车很多是不愿意打表的，芭提雅完全拒绝打表，我们从沙滩旁的麦当劳打到避孕套餐厅花了200，回去居然要300，而且还是摩托车，结果走了一路找了个女司机花了200块分别打到希尔顿和人妖秀。在芭提雅比较推荐的就是包双条车，如果熟悉路线的话也可以直接上去，等到了自己想要去的地方再下来。在水上市场我们三人和临时认识的一对情侣了双条车，分别送到Discovery Beach Hotel和汽车站Bus Terminal，总共才300。当然这里面费了好多口舌。至于曼谷到芭提雅的交通，打的是完全不推荐的，我们打车过去花了2000泰铢，后来发现其实可以谈到1500左右。那个司机发了一笔横财，开心死了，路上给我们放了一路中文歌。坐出租车是比较不舒服的，虽然我们走的是高速，但仍然很颠簸。本来我们还约了他晚上九点送我们回去，不过他似乎只会打电话，不会收发短信，连英文也讲不好。我们给他手机发了条短信他也一直没回，当然最后我们也没回去就是了。比较好的是淘宝拼车，但一定要提前一天预订。回程的话我们是坐的大巴，非常舒服，每人108泰铢，大概两小时就到了，终点是艾卡麦。 有关住宿泰国的住宿真的便宜。我们在曼谷的住宿是在AIRBNB上订的公寓Ideo Q Chidlom - Phetchaburi，人均1300+的人民币，30入住4号退房。到了之后发现人家在门口写了NO AIRBNB，还说这是违法的，我们也不知道啊，难怪一进门房东就说不要说你们是来租的，要说是朋友。不过那公寓是超级豪华，40楼是图书馆和娱乐室，里面有台球和桌上足球。42楼是一圈无边泳池，再往上走还有一个小健身房，再往上就是一个天台，可以见到超级美的日出和日落。临走的那天晚上我们意外发现了41楼有个泡澡的地方和桑拿房。 有关吃喝玩乐在曼谷的时候就是成天围绕central world逛，这个商场超级大，里面琳琅满目的各种东西。吃的里面感觉冬阴功、热带水果包括菠萝饭、咖喱都是非常好吃的。31号晚上在central world外面有盛大的跨年演唱会。下午我们从central world吃过饭出来时，路就已经被封起来了，中间已经有DJ在彩排了。晚上做过马杀鸡之后便去到水门市场那个路口的时候发现路已经被封起来了，需要排好长的队才能进场。曼谷遍地都是的711是不容错过的好去处，里面的各种饮料都很好喝而且便宜，冬阴功泡面和卡乐比蘸酱薯条很好吃。我们在芭提雅的Tiffany人妖秀观赏了人妖秀。这个人妖秀还是值得一看的，因为它非常有设计感。印象深刻的是一个人同时扮演一对恋人。此外，人妖秀里面还融入了一些中国文化的元素，例如有改编版的菊花台歌舞和阿里郎歌舞。 有关购物我们一号晚上本来准备继续central world觅食的，然后觉得这样也没啥意思，于是我提议去了火车头夜市逛了逛顺便吃饭。顺路走到ChidLom轻轨站体验一下轻轨的，但是买票超级麻烦，排了半天的自动售票机鼠标各种漂移，扫码支付微信根本扫不出。而且线路图给我的感觉是每条线各自为政，没有办卡的我们就到轻轨站下面准备打车。拒绝了多辆TUTU车（觉得不安全）之后我们花了250的泰铢去到了夜市。夜市非常的热闹，里面各种东西都有，泰国丝绸和做的围巾可以用来送人，一般都是100泰铢，但是丝绸买十送一，围巾的话讲了半天价就是不肯，那我先买了6条，看看品质还不错可以送人，吃过饭又多买了两条。手工香皂也还不错，基本就是100铢3个是比较划算了。]]></content>
      <tags>
        <tag>游记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stateful constexpr]]></title>
    <url>%2F2019%2F01%2F12%2Fstateful_constexpr%2F</url>
    <content type="text"><![CDATA[通过stateful constexpr，我们希望实现以下功能123456int main () &#123; constexpr int a = f (); constexpr int b = f (); static_assert (a != b, "fail");&#125; 通过在编译器实现副作用，我们可以在编译期实现容器、查看某个类是否已经被实例化、查看一个函数在决议后的地址，甚至实现反射。 实现f我们f的实现如下1234567template&lt; bool B = noexcept (flag (0)), int = sizeof (dependent_writer&lt;B&gt;)&gt;constexpr int f () &#123; return B;&#125; 其中noexcept (X)用来检测里面的X是否是常量表达式。特别地，在这里，如果函数flag没有被定义，那么noexcept会返回false。容易想到，下面对dependent_writer&lt;B&gt;求sizeof应该是为了去定义flag函数。下面我们来看这个类模板的实现。123456789constexpr int flag (int); // 1，flag只声明而未定义template&lt;class Tag&gt;struct writer &#123; friend constexpr int flag (Tag) &#123; // 2，定义了flag return 0; &#125;&#125;;template&lt;bool B, class Tag = int&gt;struct dependent_writer : writer&lt;Tag&gt; &#123; &#125;; 这段代码的核心点是，我们延迟了函数flag到我们实例化writer&lt;Tag&gt;的时候。其方式是声明函数flag是writer的友元，那么其定义应当随writer&lt;Tag&gt;的模板实例化进行。现在，一个最直接的疑问点是为什么不直接使用writer&lt;Tag&gt;，这个涉及到在附注中列举的C++模板实例化的一些规则。其原因是使用裸的writer&lt;int&gt;会直接实例化，为了避免这个问题，我们需要延迟这个实例化到f的实现上，因此我们引入dependent_writer，它要依赖一个bool B才能实例化。 附注C++ 模板实例化的规则 模板实例化与模板特化 模板实例化(instantiation)指通过指定的模板参数实例化一个模板。此时(point of instantiation)，编译器会为对应的模板特化生成real code。 12345template &lt;typename T&gt;struct test&#123; T m; &#125;;template test&lt;int&gt;; // explicit instantiationtest&lt;int&gt; a; // implicit instantiation 模板特化(specialization)依然是一个模板，它仍然需要进行实例化来得到real code。 123template &lt;typename T&gt;struct test&#123; T m; &#125;;template &lt;&gt; struct test&lt;int&gt;&#123; int newM; &#125; // specialization 类比到函数上，实例化类似于调用，特化类似于重载（虽然特化还可以分为全特化和偏特化） point of instantiation 一旦在一个需要实例化的上下文中refer了一个template specialization，就会产生一个point of instantiation，此时编译器就会为这个template specialization生成代码。 下面作者的话有点难于理解，于是我直接参考标准temp.point理解，并且问了问题。对于(member) function template specialization X，如果他被另一个template specialization Y所refer，且这个Y依赖于某个模板参数，那么他的point of instantiation等同于Y。在同样的情况下，如果X是class template specialization，那么它应该在Y紧前面初始化。 对于其他的情况，设X处在的名字空间的声明/定义位于D，如果X是一个函数，在D紧后面初始化；如果X是一个类，那么在D紧前面初始化。 function template specialization可以有任意多次的实例化，但我们必须保证它们的结果是相同的，否则ill-formed。可以联想到inline函数也是这样的。 如果class template specialization含有友元声明，那么它的所有友元将被对待为仿佛一个explicit specialization在point of instantiation处已经被声明。class template specialization只能有一次的实例化。 隐式实例化function template specialization的条件 没有被显式特化或显式实例化。 上下文需要它的定义。 隐式实例化class template specialization的条件 没有被显式特化或显式实例化。 上下文需要completely-defined的type。 特别地，隐式实例化class template specialization只会实例化成员的声明而非定义，除非： 成员是static data member，此时不需要实例化。这是因为禁止在声明时同时初始化非const的static类成员。 成员是unscoped enumeration or an anonymous union，此时声明+定义 一个class template specialization的成员的定义是在它被需要时才被隐式实例化。 Q：是否可以认为当我们没有refer到writer时，它所有的成员的声明都没有被实例化？ Q：是否可以认为当我们没有refer到writer的友元成员函数f时，f没有被实例化？ Reference http://b.atch.se/posts/non-constant-constant-expressions]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MIT6.824做题笔记]]></title>
    <url>%2F2018%2F12%2F29%2FMIT6.824note%2F</url>
    <content type="text"><![CDATA[MIT 6.824 2018的Lab。 Lab1 MapreduceLab2 Raft这个主要是把自己写的C++版本的Nuft精简而成的，在转换到Golang的过程中借鉴了一些较好的实现。单独运行测试可以使用 go test -run XXX 这里简要介绍一下这个Lab的设计吧，因为它比较考验调试能力。 在Lab中使用config.logs来保存被apply的entry，所以我们必须要apply才能够通过nCommitted检测，仅仅commit是没有用的。然后在处理AppendEntriesArgs的时候删日志也要注意，我之前的写法过不了Figure8(Unreliable)。后来参照了上面提到的实现进行了修改，但这个实现同样是有问题的（参见Nuft注释），我们必须立即删除不正确的日志。 死锁是容易遇到的大问题，但我主要是在Nuft中遇到的，基本上死锁中的一部分来自在一个函数调用链中（一般是node.h）两次请求了锁，这个是一个弱智错误。另外的死锁情形包括在Test里面注册的回调函数中调用了node.h的带锁API。或者一个线程持有锁并被主线程join。例如我花费了很长时间在节点销毁时正确处理gRPC的client和server上。 在Nuft中，由于是多个TestCase连续跑的，所以要处理节点销毁后到达的RPC消息，我在消息上附带时间戳来处理的，这个在长远看有时间的同步间隔。 虽然6.824已经提供了一个labrpc，但是在实际选择rpc的时候，我们并不需要选择流式RPC。这是由于在实现Nuft时我发现流式RPC创建信道的开销很大，并且非优雅地关闭连接很麻烦。流式RPC提供的有序的传输并不是性价比很高的，毕竟Raft本身就能处理乱序到达的RPC（详见Nuft注释）。并且如果单纯为了解决乱序到达的包带来的额外的处理开销，可以通过设置seq号的方式来直接丢弃掉。 Lab3 KVRaft写了一下，发现在Test1就过不去，阻塞在Commit=102处。发现这是因为没有及时更新ch所致。123get wrong value, key 0, wanted:x 0 0 y, got 这里的key，实际上就是客户的序号。这是因为我在server里面打日志的时候忘掉加上Value了。 get wrong value/missing element问题如下所示，缺失倒数第一或者倒数第二个项目。missing element12--- FAIL: TestSnapshotRecover3B (13.47s) test_test.go:85: 0 missing element x 0 50 y in Append result x 0 0 yx 0 1 yx 0 2 yx 0 3 yx 0 4 yx 0 5 yx 0 6 yx 0 7 yx 0 8 yx 0 9 yx 0 10 yx 0 11 yx 0 12 yx 0 13 yx 0 14 yx 0 15 yx 0 16 yx 0 17 yx 0 18 yx 0 19 yx 0 20 yx 0 21 yx 0 22 yx 0 23 yx 0 24 yx 0 25 yx 0 26 yx 0 27 yx 0 28 yx 0 29 yx 0 30 yx 0 31 yx 0 32 yx 0 33 yx 0 34 yx 0 35 yx 0 36 yx 0 37 yx 0 38 yx 0 39 yx 0 40 yx 0 41 yx 0 42 yx 0 43 yx 0 44 yx 0 45 yx 0 46 yx 0 47 yx 0 48 yx 0 49 yx 0 51 y get wrong value 1234get wrong value, key 0, wanted:x 0 0 yx 0 1 yx 0 2 yx 0 3 yx 0 4 yx 0 5 yx 0 6 yx 0 7 yx 0 8 yx 0 9 yx 0 10 yx 0 11 yx 0 12 yx 0 13 yx 0 14 yx 0 15 yx 0 16 yx 0 17 yx 0 18 yx 0 19 yx 0 20 yx 0 21 yx 0 22 yx 0 23 yx 0 24 yx 0 25 yx 0 26 yx 0 27 yx 0 28 yx 0 29 yx 0 30 yx 0 31 yx 0 32 yx 0 33 yx 0 34 yx 0 35 yx 0 36 yx 0 37 yx 0 38 yx 0 39 yx 0 40 yx 0 41 yx 0 42 yx 0 43 yx 0 44 yx 0 45 yx 0 46 yx 0 47 yx 0 48 yx 0 49 yx 0 50 yx 0 51 y, gotx 0 0 yx 0 1 yx 0 2 yx 0 3 yx 0 4 yx 0 5 yx 0 6 yx 0 7 yx 0 8 yx 0 9 yx 0 10 yx 0 11 yx 0 12 yx 0 13 yx 0 14 yx 0 15 yx 0 16 yx 0 17 yx 0 18 yx 0 19 yx 0 20 yx 0 21 yx 0 22 yx 0 23 yx 0 24 yx 0 25 yx 0 26 yx 0 27 yx 0 28 yx 0 29 yx 0 30 yx 0 31 yx 0 32 yx 0 33 yx 0 34 yx 0 35 yx 0 36 yx 0 37 yx 0 38 yx 0 39 yx 0 40 yx 0 41 yx 0 42 yx 0 43 yx 0 44 yx 0 45 yx 0 46 yx 0 47 yx 0 48 yx 0 49 yx 0 50 y 这是有关Snapshot的问题，在安装Snapshot的时候我们需要更新commit_index和last_applied为last_included_index，尽管它们的值可能比last_included_index要大。我们考虑从Snapshot恢复，此时我们的全部Log等于Snapshot+last_included_index+1开始的所有日志，由于commit_index等式volatile的（Figure 2），所以我们并不知道目前commit_index如何变化，唯一的标杆是last_included_index，我们知道它一定是applied的。实际上我们仍然需要回滚last_included_index到commit_index的一段。此外，需要特别注意，在加载Snapshot时要判断它是否为空。在修改之后发现还是有这个问题，进一步检查发现在崩溃前第85号日志是{Append 0 x 0 48 y 4062585092109805200 84}，到了恢复之后莫名其妙变成了{Append 0 x 0 49 y 4062585092109805200 85}。12345678910111213141516Leader Commit to 85Apply base 74 commit_index 85 last index 85 log len 12 i 85 cmd &#123;Append 0 x 0 48 y 4062585092109805200 84&#125;Apply base 74 commit_index 84 last index 85 log len 12 i 84 cmd &#123;Append 0 x 0 47 y 4062585092109805200 83&#125;Apply base 74 commit_index 84 last index 85 log len 12 i 84 cmd &#123;Append 0 x 0 47 y 4062585092109805200 83&#125;Apply base 74 commit_index 84 last index 85 log len 12 i 84 cmd &#123;Append 0 x 0 47 y 4062585092109805200 83&#125;ALoad Snapshot LastIncludedIndex 74 LastIncludedTerm 1 rf.commit_index 74 rf.last_applied 74 base 74truncate until (index 74, term 1), i 0, len 11, new len 11ALoad Snapshot LastIncludedIndex 74 LastIncludedTerm 1 rf.commit_index 74 rf.last_applied 74 base 74truncate until (index 74, term 1), i 0, len 11, new len 11ALoad Snapshot LastIncludedIndex 74 LastIncludedTerm 1 rf.commit_index 74 rf.last_applied 74 base 74truncate until (index 74, term 1), i 0, len 11, new len 11ALoad Snapshot LastIncludedIndex 74 LastIncludedTerm 1 rf.commit_index 74 rf.last_applied 74 base 74truncate until (index 74, term 1), i 0, len 13, new len 13ALoad Snapshot LastIncludedIndex 74 LastIncludedTerm 1 rf.commit_index 74 rf.last_applied 74 base 74truncate until (index 74, term 1), i 0, len 11, new len 11Leader Commit to 85 经检查（可以在Load处打印出所有日志比较）发现只有len为13的节点persist了最新Apply的85和86号日志。这是不正确的行为，因为Applied的日志必须要在持久化中有体现。于是核对了一下persist的时机，发现sendAppendEntries有一处笔误，但是并没有发现其他错误。后来发现，好像必须要rf.persist()才行，我之前裸写了rf.persister.SaveRaftState(rf.encode_raft_state())就不行。经过比较发现可能是defer rf.persister.SaveRaftState(rf.encode_raft_state())的时候里面的rf.encode_raft_state()就已经被求值了。 注意在AppendEntries函数中加上判断args.Prev_log_index &gt; rf.get_base_index()。此外broadcastAppendEntries函数中的rf.next_index[j] &lt;= rf.get_base_index()必须取到等号，不然会越界。 有关提交和应用的问题对于客户机而言，它会提交一个日志项，并等待其apply成功。这个过程可能是false negative的，即明明已经被提交了，但由于Leader切换的缘故Apply超时了。这时候客户机一般会选择重试，因此必须保证重试的日志和前面的日志是幂等的，比较好的做法是对每个日志项维护一个id号，重试时不增加id。由于KV的V可能比较大，所以我们可以将V放到某个外部存储中，raft中只记录序号和校验码。]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>6.824</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过C++预处理实现if]]></title>
    <url>%2F2018%2F12%2F07%2Fimplement-if-through-preprocessing%2F</url>
    <content type="text"><![CDATA[C++的预处理机制令人诟病的一点是在不同的编译器中的表现是不同的，在boost/preprocessor/config/config.hpp列举出了非常多的case，所以在本篇文章中我们只考虑g++-7的编译结果。此外，出于便于阅读的考虑，对名字进行了简化，去掉了诸如BOOST_PP等前缀。 一个最简单的原型我们首先将问题转化为只判断一个bit，0和1。这是trivial的，在boost实现中是著名的IIF宏。123#define IF_BOOL(test, t, f) IF_BOOL_##test(t, f)#define IF_BOOL_1(t, f) t#define IF_BOOL_0(t, f) f 接下来我们研究将其他的常量转换为bit。首当其冲的是整数和布尔型，我们可以尽情地复制粘贴。1234567#define BOOL(x) BOOL_##x#define BOOL_true(x) 1#define BOOL_false(x) 0#define BOOL_0(x) 0#define BOOL_1(x) 1#define BOOL_2(x) 1... 然后就是defined和空的判断。对于defined，我们有#if defined这样的语句，不过我们没有一个相应的函数，对于空我们进行了以下的尝试：1#define BOOL_(x) EMPTY 经过预处理展开发现结果是BOOL_，因此并不如人意。但是根据SoF，defined问题似乎也可以归结到是否为空上，所以我们来研究如何判空。 判断是否为空我们需要设计一个IS_EMPTY来判断是否是空12#define M // return 0#define N 0 // return 1 boost在boost/preprocessor/facilities/is_empty.hpp中给出一个巧妙的方案123456789#define STR(x) #x#define CAT(x, y) x ## y#define EMPTY()#define EAT_BRACE(x) x EMPTY#define IS_EMPTY(x) IS_EMPTY_I(x IS_EMPTY_HELPER)#define IS_EMPTY_I(contents) BOOST_PP_TUPLE_ELEM(2, 1, (IS_EMPTY_DEF_ ## contents()))#define IS_EMPTY_DEF_IS_EMPTY_HELPER _, EAT_BRACE(1)#define IS_EMPTY_HELPER() , 0 这个方案的基本原理是如果我们将IS_EMPTY_DEF_和x和IS_EMPTY_HELPER三者连接，对于一个平凡情况，如果x为空，那么我们最终会得到一个IS_EMPTY_DEF_IS_EMPTY_HELPER（过程稍后），我们将它展开为_, EAT_BRACE(1)。这是一个奇妙的构造，我们希望的结果1就构造在EAT_BRACE(1)里面，我们将在稍后谋划如何将其取出。为了能够理解代码的精妙之处，我们首先考虑一个不平凡的情况，如果我们做简单的连接，那么可能不能形成一个valid preprocessing token，那么我们就得想办法在早期将它搞掉。现在我们假定x的值就是x，那么我们第一步展开为IS_EMPTY_I(x IS_EMPTY_HELPER)。在第二步，我们不看BOOST_PP_TUPLE_ELEM，它里面的东西是IS_EMPTY_DEF_ ## x IS_EMPTY_HELPER ()。再展开IS_EMPTY_HELPER ()，发现它是, 0，于是我们得到了一个IS_EMPTY_DEF_, 0，容易看出我们要的结果同样在第1个（从0开始），我们可以通过BOOST_PP_TUPLE_ELEM将它取出来，其实现将在后面讨论。于是现在我们有了疑问，第一，为什么IS_EMPTY_HELPER后面要加上括号，这样一来怎么合成IS_EMPTY_DEF_IS_EMPTY_HELPER呢？第二，为啥0是裸着的，1要包着一个EAT_BRACE？首先我们推演IS_EMPTY_DEF_ ## IS_EMPTY_HELPER ()得到了这个结果，这时候##可以合成IS_EMPTY_DEF_IS_EMPTY_HELPER这个token，于是IS_EMPTY_HELPER ()就没有被展开。而我们又没有定义IS_EMPTY_DEF_IS_EMPTY_HELPER ()，所以最后只能挂着一个_, EAT_BRACE(1) ()，而EAT_BRACE的作用当然就是把后面挂着的这个括号去掉啦。 可变参数模板部分下面我们研究BOOST_PP_TUPLE_ELEM的实现，它位于boost/preprocessor/tuple/elem.hpp。这个宏接受两个或三个参数，当接受三个参数是，前两个分别是size和index，后面的__VA_ARGS__被括号包起来。1234#define ADD_SIZE_TO_SURFIX(prefix, ...) CAT(prefix, SIZE(__VA_ARGS__))#define TUPLE_ELEM(...) ADD_SIZE_TO_SURFIX(TUPLE_ELEM_O_, __VA_ARGS__)(__VA_ARGS__)#define TUPLE_ELEM_O_2(n, tuple) VARIADIC_ELEM(n, BOOST_PP_REM tuple)#define TUPLE_ELEM_O_3(size, n, tuple) TUPLE_ELEM_O_2(n, tuple) 其中ADD_SIZE_TO_SURFIX对应boost中的BOOST_PP_OVERLOAD方法，其作用是使用SIZE获得__VA_ARGS_的大小，并将这个值放到prefix之后形成新的token。我们看到TUPLE_ELEM视参数个数调用TUPLE_ELEM_O_2或TUPLE_ELEM_O_3，而最后都归结为VARIADIC_ELEM。也就是说TUPLE模块的实现借助了VARIADIC模块，TUPLE宏由于有个“重载”，所以它的__VA__ARGS__被用括号括起来，所以要把这一层括号去掉才能调用VARIADIC宏。BOOST_PP_REM定义在boost/preprocessor/tuple/rem.hpp里面，它的实现似乎是用来处理...部分的__VA_ARGS__是空的情况，或者是single element的情况。 获取一个序列的长度这段构思巧妙地代码来自于boost/preprocessor/variadic/size.hpp：12#define SIZE(...) SIZE_I(__VA_ARGS__, 4, 3, 2, 1,)#define SIZE_I(e0, e1, e2, e3, e4, size, ...) size SIZE在调用SIZE_I时，__VA_ARGS__能够填补从e0开始的形参，那么用来标记大小的4, 3, ...的序列就会被往后挤。美中不足的是这个宏不能处理size为0的情况，这是因为空参数表也占一个位置。虽然我们知道对于某些编译期，我们可以使用##__VA_ARGS__去掉前面的逗号，以避免func(non_va_arg1, non_va_arg2, )的情况，但它并不能去掉后面的逗号。事实上我们只能通过编译期来处理。如果熟悉C++模板，我们可以注意到这种做法很容易对应到std::make_index_sequence之类的做法。 实现ELEMBOOST_PP_VARIADIC_ELEM定义在boost/preprocessor/variadic/elem.hpp，同样也是运用了和size一样的思路1234#define VARIADIC_ELEM(n, ...) CAT(VARIADIC_ELEM_, n)(__VA_ARGS__,)#define VARIADIC_ELEM_0(e0, ...) e0#define VARIADIC_ELEM_1(e0, e1, ...) e1#define VARIADIC_ELEM_2(e0, e1, e2, ...) e2 其他的if实现方法我们在宏里面使用到的if实现方法非常典型，在C中我们可以通过函数数组的方式来实现，类似于我们在宏里面生成了两个函数*_0和*_1。在Python中，我们使用and的短路原则来替代三目运算符（虽然我更喜欢T if C then F这样写）。这里引用知乎上另外一个有趣的方法。1234// 来自知乎 https://www.zhihu.com/question/308901598true = λ a. λ b. afalse = λ a. λ b. bif = λ a. λ b. λ c. a(b)(c) 把true和false分别带到if函数里面即可了解思路。]]></content>
      <tags>
        <tag>C++</tag>
        <tag>boost</tag>
        <tag>预处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中join不能响应信号的问题]]></title>
    <url>%2F2018%2F08%2F01%2Fpython-join-no-signal%2F</url>
    <content type="text"><![CDATA[在文章subprocess模块用法中介绍了Python中的threading.Thread.join()时不能响应信号的问题。这个问题被Python官方标记为Bug。Python官方的Issue指出这个Bug与Python的signal、基础线程库thread（C实现）和高级线程库threading（Python封装）都有关，下面首先概览这三个模块的实现，接着通过编译调试的方式来观赏这个Bug的具体过程。 一个简单的测试程序这里提供一个可以在Ubuntu 16.04上的Python2.7上重现的代码片段。主程序调用threading_timeout_test时能够正常响应SIGINT等信号，调用threading_test时不能正常响应信号。12345678910111213141516171819202122232425262728import sys, os, signal, subprocess, multiprocessing, timeimport threading, threaddef on_shutdown(i, j): print "Bye" os._exit(0)signal.signal(signal.SIGINT, on_shutdown)signal.signal(signal.SIGTERM, on_shutdown)signal.signal(signal.SIGHUP, on_shutdown)def inner(): while 1: time.sleep(1)def threading_test(): ths = threading.Thread(target=inner) ths.daemon = True ths.start() ths.join()def threading_timeout_test(): ths = threading.Thread(target=inner) ths.daemon = True ths.start() ths.join(100)threading_test() ps一下发现此时进程处于Sl状态。 Python中的signal机制在signalmodule的开头注释中我们看到Python的信号只能为主线程所设置和捕获，这和POSIX原生signal不同了。在POSIX中，信号是传递给整个进程中的随机线程的。我们偏向于通过设置信号屏蔽字的方式，或者借助sigwait，让一个线程专门等待信号，这样将一个单线程完全异步的逻辑变为了同步的逻辑。12345678910111213141516171819// signalmodule.c// 翻译版/* Python线程语义: - 只有主线程可以设置signal handler - 任何线程可以获得signal handler - 信号只传送给主线程 我们不支持像SIGFPE之类的同步信号，也不支持使用信号做线程间通讯。 这是因为并不是所有的线程库都支持。 在一些实现中由键盘产生的信号如SIGINT会被分发到所有线程(SGI)， 或者按照随机概率(POSIX有中等概率会被发送到主线程)任意线程(Solaris)。 目前的机制需要兼容这三种特性，因此signal handler会忽略掉所有getpid()不等于主线程中的结果的信号。 // 注：我认为CPython以pthread为底层的线程实现不会出现不同线程getpid()不等的情况， // 可能作者的意思是在其他系统中可能会出现这种情况*/ 我个人理解上面这一段话的意思是Python为了简化在不同OS上的处理，选择为信号处理增加了限制。Python在signal_signal中负责注册信号。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687// thread_pthread.h// 这个函数用来获得当前线程的threadidlongPyThread_get_thread_ident(void)&#123; // pthread_t的大小不定，为4或者8 // 注意这个函数对线程切换是敏感的，宜加上volatile volatile pthread_t threadid; if (!initialized) // 我们将在稍后介绍这个函数的作用 PyThread_init_thread(); /* Jump through some hoops for Alpha OSF/1 */ threadid = pthread_self();#if SIZEOF_PTHREAD_T &lt;= SIZEOF_LONG return (long) threadid;#else return (long) *(long *) &amp;threadid;#endif&#125;// signalmodule.cstatic PyObject *signal_signal(PyObject *self, PyObject *args)&#123; PyObject *obj; int sig_num; PyObject *old_handler; void (*func)(int); // 传进来的tuple有两项，第一项是sig_num，第二项是一个ob_type-&gt;tp_name是function，也就是处理函数 if (!PyArg_ParseTuple(args, "iO:signal", &amp;sig_num, &amp;obj)) return NULL;#ifdef MS_WINDOWS /* Validate that sig_num is one of the allowable signals */ switch (sig_num) &#123; case SIGABRT: break;#ifdef SIGBREAK /* Issue #10003: SIGBREAK is not documented as permitted, but works and corresponds to CTRL_BREAK_EVENT. */ case SIGBREAK: break;#endif case SIGFPE: break; case SIGILL: break; case SIGINT: break; case SIGSEGV: break; case SIGTERM: break; default: PyErr_SetString(PyExc_ValueError, "invalid signal value"); return NULL; &#125;#endif#ifdef WITH_THREAD // 不能子线程中设置信号 if (PyThread_get_thread_ident() != main_thread) &#123; PyErr_SetString(PyExc_ValueError, "signal only works in main thread"); return NULL; &#125;#endif if (sig_num &lt; 1 || sig_num &gt;= NSIG) &#123; PyErr_SetString(PyExc_ValueError, "signal number out of range"); return NULL; &#125; if (obj == IgnoreHandler) func = SIG_IGN; else if (obj == DefaultHandler) func = SIG_DFL; else if (!PyCallable_Check(obj)) &#123; PyErr_SetString(PyExc_TypeError,"signal handler must be signal.SIG_IGN, signal.SIG_DFL, or a callable object"); return NULL; &#125; else func = signal_handler; if (PyOS_setsig(sig_num, func) == SIG_ERR) &#123; PyErr_SetFromErrno(PyExc_RuntimeError); return NULL; &#125; old_handler = Handlers[sig_num].func; // 清空触发位 // 当信号发生时，在`trip_signal`中会将tripped设为1 Handlers[sig_num].tripped = 0; Py_INCREF(obj); // 设置信号处理函数 Handlers[sig_num].func = obj; if (old_handler != NULL) return old_handler; else Py_RETURN_NONE;&#125; Python在signal_handler中负责处理信号。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// signalmodule.c// 这个函数将在稍后详细讨论static voidtrip_signal(int sig_num)&#123; Handlers[sig_num].tripped = 1; ... Py_AddPendingCall(checksignals_witharg, NULL); if (wakeup_fd != -1) write(wakeup_fd, "\0", 1);&#125;static voidsignal_handler(int sig_num)&#123; int save_errno = errno;#if defined(WITH_THREAD) &amp;&amp; defined(WITH_PTH) if (PyThread_get_thread_ident() != main_thread) &#123; pth_raise(*(pth_t *) main_thread, sig_num); &#125; else#endif &#123;#ifdef WITH_THREAD /* See NOTES section above */ if (getpid() == main_pid)#endif &#123; printf("Received POSIX signal in thread %x\n", PyThread_get_thread_ident()); trip_signal(sig_num); &#125;#ifndef HAVE_SIGACTION#ifdef SIGCHLD /* To avoid infinite recursion, this signal remains reset until explicit re-instated. Don't clear the 'func' field as it is our pointer to the Python handler... */ if (sig_num != SIGCHLD)#endif /* If the handler was not set up with sigaction, reinstall it. See * Python/pythonrun.c for the implementation of PyOS_setsig which * makes this true. See also issue8354. */ PyOS_setsig(sig_num, signal_handler);#endif &#125; /* Issue #10311: asynchronously executing signal handlers should not mutate errno under the feet of unsuspecting C code. */ errno = save_errno;&#125; 出于方便说明的考虑，我们将在后面查看Py_AddPendingCall的定义。 Python的threading模块threading.Thread.join()方法Python的低级线程模块thread并没有提供join的原语，threading.Thread.join()在Python层面进行了封装实现。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// threading.pydef Condition(*args, **kwargs): return _Condition(*args, **kwargs) class Thread(_Verbose): def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, verbose=None): ... # 意料之中的CV，稍后我们来看看具体实现 # 注意threading中还提供了一个递归锁RLock，我们这里用不到 self.__block = Condition(Lock()) def join(self, timeout=None): """Wait until the thread terminates. 翻译版 join函数会阻塞直到被join的线程正常终结，因未处理的异常终结，或者`timeout`超时退出 可选参数`timeout`可以是一个浮点数，用来表示超时时间。因为`join()`方法一直返回None， 所以需要在join返回后调用`isALive`来判断究竟是发生了超时(此时线程还活着)，还是线程已经终结 同一个线程可以被join很多次 join自己会抛出RuntimeError，否则导致死锁 在线程初始化或者启动前join会抛出RuntimeError """ if not self.__initialized: raise RuntimeError("Thread.__init__() not called") if not self.__started.is_set(): raise RuntimeError("cannot join thread before it is started") // join自己会导致死锁 if self is current_thread(): raise RuntimeError("cannot join current thread") if __debug__: if not self.__stopped: self._note("%s.join(): waiting until thread stops", self) # 锁住CV对应的锁，后面看到实际是个Lock = _allocate_lock self.__block.acquire() try: if timeout is None: # 和POSIX编程一样，这里同样要放在while循环里面 while not self.__stopped: # 等待条件变量 self.__block.wait() if __debug__: self._note("%s.join(): thread stopped", self) else: deadline = _time() + timeout while not self.__stopped: delay = deadline - _time() if delay &lt;= 0: if __debug__: self._note("%s.join(): timed out", self) break self.__block.wait(delay) else: if __debug__: self._note("%s.join(): thread stopped", self) finally: self.__block.release() 我们注意if timeout is None:这个条件，两个分支的代码相差无几，但在我的Ubuntu 16.04上的Python2.7.12中分别使用或不使用timeout进行join，却一个不能响应SIG，一个可以。显而易见，原因在self.__block.wait()这个方法中。而self.__block.wait()实际上在一个条件变量上进行等待。 Condition条件变量从上面的代码我们能看到self.__block实际上是个条件变量_Condition，这个_Condition实现地比较简陋，它并不会像C++中的std::condition_variable一样隔段时间解锁看看条件是否满足，事实上它根本就不接受一个condition参数，共享同一个_Condition的线程通过wait这个_Condition上的事件，或者notify系列向这个_Condition通告这个事件。此外，_Condition将互斥锁也整合了进去，我们不要在外面挂一个mutex之类的东西了。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145# threading.py_allocate_lock = thread.allocate_lock# 互斥锁Lock = _allocate_lock# 递归锁（略）def RLock(*args, **kwargs): """Factory function that returns a new reentrant lock. A reentrant lock must be released by the thread that acquired it. Once a thread has acquired a reentrant lock, the same thread may acquire it again without blocking; the thread must release it once for each time it has acquired it. """ return _RLock(*args, **kwargs) class _Condition(_Verbose): def __init__(self, lock=None, verbose=None): _Verbose.__init__(self, verbose) if lock is None: lock = RLock() self.__lock = lock # Export the lock's acquire() and release() methods self.acquire = lock.acquire self.release = lock.release # If the lock defines _release_save() and/or _acquire_restore(), # these override the default implementations (which just call # release() and acquire() on the lock). Ditto for _is_owned(). try: self._release_save = lock._release_save except AttributeError: pass try: self._acquire_restore = lock._acquire_restore except AttributeError: pass try: self._is_owned = lock._is_owned except AttributeError: pass self.__waiters = [] def _release_save(self): self.__lock.release() # No state to save def _acquire_restore(self, x): self.__lock.acquire() # Ignore saved state def _is_owned(self): # Return True if lock is owned by current_thread. # This method is called only if __lock doesn't have _is_owned(). if self.__lock.acquire(0): self.__lock.release() return False else: return True def wait(self, timeout=None): """Wait until notified or until a timeout occurs. 如果调用的线程没有取得锁将抛出`RuntimeError`错误。 这个方法释放锁`__lock`，然后阻塞直到同一个CV被另一个线程中的`notify()`或`notifyAll()`通知， 或者发生超时。一旦发生以上情况，它会重新获得锁并返回。 `timeout`参数是一个表示秒数的浮点。 当锁是递归锁`RLock`，release方法并不会直接解锁它，相应地一个内部的接口被使用， 从而保证它需要调用和acquire相同的重数才能被解锁。 """ # 必须持有锁才能操作共享变量 if not self._is_owned(): raise RuntimeError("cannot wait on un-acquired lock") # 实际调用thread模块对应实现中的`thread_PyThread_allocate_lock`函数，将在稍后看到 waiter = _allocate_lock() # 实际调用thread模块对应实现中的`lock_PyThread_acquire_lock`函数 # 先acquire一下waiter waiter.acquire() # 将代表自己的锁`waiter`加入`self.__waiters`队列中， self.__waiters.append(waiter) # 释放掉持有的lock saved_state = self._release_save() # 暂时不明白为啥要有个返回值 try: # restore state no matter what (e.g., KeyboardInterrupt) if timeout is None: # 再acquire一下waiter，这下阻塞了，原来把它当信号量用 # 等signal释放掉一个锁 waiter.acquire() if __debug__: self._note("%s.wait(): got it", self) else: # 翻译 # 这里使用一个busy loop轮询是划不来的，所以我们得sleep， # 不过如果睡一个较长的时间，程序的响应性会变差。 # 这个机制sleep interval的区间在[0.0005, 0.05]之间，每次按照2的幂增长。 endtime = _time() + timeout delay = 0.0005 # 500 us -&gt; initial delay of 1 ms while True: # 这里的0是一个waitflag，表示我们需不需要等待直到获得锁， # 因为我们现在有timeout，所以不能直接阻塞，而是不停地睡觉直到条件达成或者超时 gotit = waiter.acquire(0) if gotit: break remaining = endtime - _time() if remaining &lt;= 0: break delay = min(delay * 2, remaining, .05) _sleep(delay) if not gotit: if __debug__: self._note("%s.wait(%s): timed out", self, timeout) try: self.__waiters.remove(waiter) except ValueError: pass else: if __debug__: self._note("%s.wait(%s): got it", self, timeout) finally: self._acquire_restore(saved_state) def notify(self, n=1): """Wake up one or more threads waiting on this condition, if any. 如果调用的线程没有取得锁将抛出`RuntimeError`错误。 这个方法唤醒CV上的至多n个线程，当没有线程在等待时它相当于nop函数 """ # 必须持有锁才能操作共享变量 if not self._is_owned(): raise RuntimeError("cannot notify on un-acquired lock") __waiters = self.__waiters # 我们取出前n个进行通知 waiters = __waiters[:n] if not waiters: if __debug__: self._note("%s.notify(): no waiters", self) return self._note("%s.notify(): notifying %d waiter%s", self, n, n!=1 and "s" or "") for waiter in waiters: waiter.release() try: __waiters.remove(waiter) except ValueError: pass 从上面的代码我们可以看到一旦调用waiter.acquire()，程序就不能响应信号了，我们接下来到thread模块中看这个函数的实现。 thread模块Pythread锁承接上文，我们看到thread._allocate_lock实际调用了thread_PyThread_allocate_lock()创建了一个lockobject对象。lockobject对象中包含了一个lock_lock，这个实际上是一个PyThread_type_lock对象，由PyThread_allocate_lock()创建，也就是锁基于操作系统API的具体实现，我们将在稍后看到。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// pythread.h// 注意PyThread_type_lock中的实际对象根据具体实现而不同typedef void *PyThread_type_lock;typedef void *PyThread_type_sema;PyAPI_FUNC(PyThread_type_lock) PyThread_allocate_lock(void);PyAPI_FUNC(void) PyThread_free_lock(PyThread_type_lock);PyAPI_FUNC(int) PyThread_acquire_lock(PyThread_type_lock, int);#define WAIT_LOCK 1#define NOWAIT_LOCK 0PyAPI_FUNC(void) PyThread_release_lock(PyThread_type_lock);// threadmodule.cstatic PyMethodDef thread_methods[] = &#123; &#123;"start_new_thread", (PyCFunction)thread_PyThread_start_new_thread, METH_VARARGS, start_new_doc&#125;, &#123;"start_new", (PyCFunction)thread_PyThread_start_new_thread, METH_VARARGS, start_new_doc&#125;, &#123;"allocate_lock", (PyCFunction)thread_PyThread_allocate_lock, METH_NOARGS, allocate_doc&#125;, ... &#123;NULL, NULL&#125; /* sentinel */&#125;;static PyObject *thread_PyThread_allocate_lock(PyObject *self)&#123; return (PyObject *) newlockobject();&#125;typedef struct &#123; // Python对象的通用头，包含了引用计数等信息 PyObject_HEAD PyThread_type_lock lock_lock; PyObject *in_weakreflist;&#125; lockobject;static lockobject *newlockobject(void)&#123; lockobject *self; self = PyObject_New(lockobject, &amp;Locktype); if (self == NULL) return NULL; self-&gt;lock_lock = PyThread_allocate_lock(); self-&gt;in_weakreflist = NULL; if (self-&gt;lock_lock == NULL) &#123; Py_DECREF(self); PyErr_SetString(ThreadError, "can't allocate lock"); return NULL; &#125; return self;&#125; PyThread_allocate_lock系列函数的实现因系统而异。以Linux为例有两种方式，分别基于sem_t和基于pthread_mutex/pthread_cond的。我们首先查看基于信号量的机制12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788// thread_pthread.hPyThread_type_lockPyThread_allocate_lock(void)&#123; sem_t *lock; int status, error = 0; dprintf(("PyThread_allocate_lock called\n")); if (!initialized) PyThread_init_thread(); lock = (sem_t *)malloc(sizeof(sem_t)); if (lock) &#123; // 信号量只在线程间共享 status = sem_init(lock, 0, 1); CHECK_STATUS("sem_init"); if (error) &#123; free((void *)lock); lock = NULL; &#125; &#125; dprintf(("PyThread_allocate_lock() -&gt; %p\n", lock)); return (PyThread_type_lock)lock;&#125;voidPyThread_free_lock(PyThread_type_lock lock)&#123; sem_t *thelock = (sem_t *)lock; int status, error = 0; // 这种用法第一是禁止WARNING，第二是用来做跳转，如`(void *)0;` (void) error; dprintf(("PyThread_free_lock(%p) called\n", lock)); if (!thelock) return; status = sem_destroy(thelock); CHECK_STATUS("sem_destroy"); free((void *)thelock);&#125;intPyThread_acquire_lock(PyThread_type_lock lock, int waitflag)&#123; int success; sem_t *thelock = (sem_t *)lock; int status, error = 0; (void) error; /* silence unused-but-set-variable warning */ dprintf(("PyThread_acquire_lock(%p, %d) called\n", lock, waitflag)); do &#123; if (waitflag) status = fix_status(sem_wait(thelock)); else status = fix_status(sem_trywait(thelock)); &#125; while (status == EINTR); /* Retry if interrupted by a signal */ if (waitflag) &#123; CHECK_STATUS("sem_wait"); &#125; else if (status != EAGAIN) &#123; CHECK_STATUS("sem_trywait"); &#125; success = (status == 0) ? 1 : 0; dprintf(("PyThread_acquire_lock(%p, %d) -&gt; %d\n", lock, waitflag, success)); return success;&#125;voidPyThread_release_lock(PyThread_type_lock lock)&#123; sem_t *thelock = (sem_t *)lock; int status, error = 0; (void) error; /* silence unused-but-set-variable warning */ dprintf(("PyThread_release_lock(%p) called\n", lock)); status = sem_post(thelock); CHECK_STATUS("sem_post");&#125; 另一种方式是使用mutex和CV的经典实现，由于实际上没有用到，所以单独讨论。 观赏Bug形成过程在先前的讨论中我们已经确定了问题的所在是waiter.acquire()这个方法，对应到CPython内部就是PyThread_allocate_lock这个函数。PyThread_allocate_lock函数根据宏的不同选项有两种实现方式，在我的Ubuntu上提供了sem_t，所以默认使用sem_t的实现。我们跟踪这个PyThread_allocate_lock，发现这个函数能够正常加解锁，但是发送SIGINT信号却不能打断程序。 那么究竟是Python直接屏蔽了Native POSIX signal，还是出于其他的原因？为此重新编译了Python 2.7.6并进行按照下图打了Log进行调试。 得到结果如下图。 注意其中的^CSIG 2，这是我在signalmodule中的signal_handler函数的开头设置打印语句，此时Ctrl+C能够输出SIG 2，并且通过了if (getpid() == main_pid)的检测，到达了trip_signal。我们在这个函数中输出了Add pending 2 callback，和我们之前注册的时候相同。接着trip_signal调用了Py_AddPendingCall。 我们接下来查看Py_AddPendingCall的代码，他在ceval.c里面，这个文件也是Python的main loop的所在地。经过调试，Py_AddPendingCall中记录了这个信号已经被成功加到了pendingcalls[0]。截止目前已发现Python在POSIX层面是收到了SIG 2，并且挂载下半部程序。因此可以初步断定异常原因是信号处理下半部并没有能够被运行。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122// ceval.c// 这就是CPython臭名昭著的全局解释器锁GIL，// GIL保证了同时只有一个线程在解释器中运行static PyThread_type_lock interpreter_lock = 0; /* This is the GIL */static PyThread_type_lock pending_lock = 0; /* for pending calls */#define NPENDINGCALLS 32static struct &#123; int (*func)(void *); void *arg;&#125; pendingcalls[NPENDINGCALLS];static int pendingfirst = 0;static int pendinglast = 0;static volatile int pendingcalls_to_do = 1; /* trigger initialization of lock */static char pendingbusy = 0;intPy_AddPendingCall(int (*func)(void *), void *arg)&#123; int i, j, result=0; PyThread_type_lock lock = pending_lock; /* try a few times for the lock. Since this mechanism is used * for signal handling (on the main thread), there is a (slim) * chance that a signal is delivered on the same thread while we * hold the lock during the Py_MakePendingCalls() function. * This avoids a deadlock in that case. * Note that signals can be delivered on any thread. In particular, * on Windows, a SIGINT is delivered on a system-created worker * thread. * We also check for lock being NULL, in the unlikely case that * this function is called before any bytecode evaluation takes place. */ /* 翻译 * 自旋100次尝试请求锁。因为这个机制被用来做信号处理(限于主线程)， * 因此有较小的几率一个信号在同一个线程在`Py_MakePendingCalls()`函数中持有锁时被通告。 * 这种情况下使用多次尝试能够在以极大概率获取锁时避免死锁。 * 注意信号(这里应该是原生的信号)可以被通告到任意线程。 * 特别地，Windows上的SIGINT会被通告到system-created worker thread上。 * 我们同时检查`lock`是否是NULL，因为可能有较小的概率这个函数在（初始化）之前被调用 */ if (lock != NULL) &#123; for (i = 0; i&lt;100; i++) &#123; if (PyThread_acquire_lock(lock, NOWAIT_LOCK)) break; &#125; if (i == 100) return -1; &#125; // 将当前请求入队 i = pendinglast; j = (i + 1) % NPENDINGCALLS; printf("Insert into pendingcalls[] at %d\n", i); if (j == pendingfirst) &#123; result = -1; /* Queue full */ &#125; else &#123; pendingcalls[i].func = func; pendingcalls[i].arg = arg; pendinglast = j; &#125; /* signal main loop */ _Py_Ticker = 0; pendingcalls_to_do = 1; if (lock != NULL) PyThread_release_lock(lock); return result;&#125;intPy_MakePendingCalls(void)&#123; int i; int r = 0; if (!pending_lock) &#123; /* initial allocation of the lock */ pending_lock = PyThread_allocate_lock(); if (pending_lock == NULL) return -1; &#125; printf("Py_MakePendingCalls: before checking main thread\n"); /* only service pending calls on main thread */ if (main_thread &amp;&amp; PyThread_get_thread_ident() != main_thread) return 0; /* don't perform recursive pending calls */ if (pendingbusy) return 0; printf("Py_MakePendingCalls: before loop pendingcalls[]\n"); pendingbusy = 1; /* perform a bounded number of calls, in case of recursion */ for (i=0; i&lt;NPENDINGCALLS; i++) &#123; int j; int (*func)(void *); void *arg = NULL; /* pop one item off the queue while holding the lock */ PyThread_acquire_lock(pending_lock, WAIT_LOCK); j = pendingfirst; if (j == pendinglast) &#123; func = NULL; /* Queue empty */ &#125; else &#123; func = pendingcalls[j].func; arg = pendingcalls[j].arg; pendingfirst = (j + 1) % NPENDINGCALLS; &#125; pendingcalls_to_do = pendingfirst != pendinglast; PyThread_release_lock(pending_lock); /* having released the lock, perform the callback */ if (func == NULL) break; // 这里的func实际上就是`checksignals_witharg`这个函数 printf("Py_MakePendingCalls: before call pendingcalls[%d] = %d\n", j, (int)pendingcalls[j].func); r = func(arg); printf("Py_MakePendingCalls: after call pendingcalls[%d] = %d\n", j, (int)pendingcalls[j].func); if (r) break; &#125; pendingbusy = 0; return r;&#125; 使用Py_AddPendingCall加入队列pendingcalls中的信号将会在Py_MakePendingCalls中被真正处理，这有点类似Linux中断下半部的机制。这里的func实际上是trip_signal调用Py_AddPendingCall的第一个参数checksignals_witharg，也是一个函数。checksignals_witharg这个函数很短，只调用了PyErr_CheckSignals这个函数。我们下面查看具体代码，需要注意Handlers[i].func和pendingcalls[j].func不一样。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// signalmodule.cstatic voidtrip_signal(int sig_num)&#123; Handlers[sig_num].tripped = 1; if (is_tripped) return; /* Set is_tripped after setting .tripped, as it gets cleared in PyErr_CheckSignals() before .tripped. */ is_tripped = 1; Py_AddPendingCall(checksignals_witharg, NULL); if (wakeup_fd != -1) write(wakeup_fd, "\0", 1);&#125;intPyErr_CheckSignals(void)&#123; int i; PyObject *f; if (!is_tripped) return 0;#ifdef WITH_THREAD if (PyThread_get_thread_ident() != main_thread) return 0;#endif /* * The is_tripped variable is meant to speed up the calls to * PyErr_CheckSignals (both directly or via pending calls) when no * signal has arrived. This variable is set to 1 when a signal arrives * and it is set to 0 here, when we know some signals arrived. This way * we can run the registered handlers with no signals blocked. * * NOTE: with this approach we can have a situation where is_tripped is * 1 but we have no more signals to handle (Handlers[i].tripped * is 0 for every signal i). This won't do us any harm (except * we're gonna spent some cycles for nothing). This happens when * we receive a signal i after we zero is_tripped and before we * check Handlers[i].tripped. */ /* 翻译 * `is_tripped`被在没有信号到达时用来加速`PyErr_CheckSignals`的处理。 * 当信号到达时`is_tripped`会被设为1，然后在这里被清零。 * 注意，这个策略有一个特殊情况，当`is_tripped`时1但我们实际没有信号可以处理， * 也就是所有的`Handlers[i].tripped`都是0。这个最多只会浪费几次check而已。 * 这种特殊情况发生在我们清零完`is_tripped`之后，检查`Handlers[i].tripped`之前。 */ is_tripped = 0; if (!(f = (PyObject *)PyEval_GetFrame())) f = Py_None; for (i = 1; i &lt; NSIG; i++) &#123; if (Handlers[i].tripped) &#123; PyObject *result = NULL; PyObject *arglist = Py_BuildValue("(iO)", i, f); Handlers[i].tripped = 0; if (arglist) &#123; // 可以发现实际调用了`PyEval_CallObject`来执行`Handlers[i].func`。 printf("PyErr_CheckSignals called %d\n", (int)Handlers[i].func); result = PyEval_CallObject(Handlers[i].func, arglist); Py_DECREF(arglist); &#125; if (!result) return -1; Py_DECREF(result); &#125; &#125; return 0;&#125; 刚才我们已经知道Python使用Py_MakePendingCalls往下的调用链Py_MakePendingCalls -&gt; checksignals_witharg(即pendingcalls[j].func) -&gt; PyErr_CheckSignals -&gt; Handlers[i].func，而Py_MakePendingCalls这个函数在当前栈帧的主循环PyEval_EvalFrameEx中被以一定的Tick的时间间隔被调用。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/* for manipulating the thread switch and periodic "stuff" - used to be per thread, now just a pair o' globals */int _Py_CheckInterval = 100;volatile int _Py_Ticker = 0; PyObject *PyEval_EvalFrameEx(PyFrameObject *f, int throwflag)&#123; ... for (;;) &#123; // 这个循环里面不停地根据取指而执行 ... // 这里`_Py_Ticker`实际上就是一个倒计时器，从初始值`_Py_CheckInterval`往下递减， // 当归零时进入下面的分支，进行一次check if (--_Py_Ticker &lt; 0) &#123; if (*next_instr == SETUP_FINALLY) &#123; /* Make the last opcode before a try: finally: block uninterruptible. */ goto fast_next_opcode; &#125; // 还原计数器 _Py_Ticker = _Py_CheckInterval; tstate-&gt;tick_counter++;#ifdef WITH_TSC ticked = 1;#endif // 如果有待处理的signal if (pendingcalls_to_do) &#123; // 调用`Py_MakePendingCalls`执行下半部 if (Py_MakePendingCalls() &lt; 0) &#123; why = WHY_EXCEPTION; goto on_error; &#125; if (pendingcalls_to_do) // 翻译 // 这个说明`Py_MakePendingCalls`执行没有成功， // 将_Py_Ticker设为0，这样可以进行线程切换， // 从而让其他线程可以重新尝试一次， // 然后就可能成功 printf("Py_MakePendingCalls Failed, current thread %x main thread %x \n", PyThread_get_thread_ident(), main_thread); _Py_Ticker = 0; &#125;#ifdef WITH_THREAD // 下面的过程实现了线程切换。 if (interpreter_lock) &#123; if (PyThreadState_Swap(NULL) != tstate) Py_FatalError("ceval: tstate mix-up"); printf("Thread %x yield \n", PyThread_get_thread_ident()); // 假如当前线程持有GIL，就释放 PyThread_release_lock(interpreter_lock); // 此时其他线程可以竞争这个GIL // 本线程重新获取GIL PyThread_acquire_lock(interpreter_lock, 1); printf("Thread %x resume \n", PyThread_get_thread_ident()); if (PyThreadState_Swap(tstate) != NULL) Py_FatalError("ceval: orphan tstate"); /* Check for thread interrupts */ if (tstate-&gt;async_exc != NULL) &#123; x = tstate-&gt;async_exc; tstate-&gt;async_exc = NULL; PyErr_SetNone(x); Py_DECREF(x); why = WHY_EXCEPTION; goto on_error; &#125; &#125;#endif &#125; fast_next_opcode: ... 下面的图来自dabeaz，形象地展示了上面源码所描述的Python线程切换的过程。 现在我们发现一个问题，在上面的代码中Py_MakePendingCalls Failed输出了，这意味着我们的信号处理函数没有成功。为什么没有成功呢？我们回看Py_MakePendingCalls的Log输出在Py_MakePendingCalls: before checking main thread戛然而止，说明此时的线程并不是主线程！我们进一步查看线程调度情况，发现在主线程调用join()之后就一直睡眠了，其中唯一一次唤醒就是收到了SIGINT，主线程将这个信号放到pendingcalls之后又回去睡觉了，之后虽然子线程屡次调用Py_MakePendingCalls检查到了有待处理的信号，但由于自己不是主线程所以也是爱莫能助。下面我们着手解决这个问题，一个简单的方法就是让子线程也可以处理由主线程添加到pendingcalls中的信号，于是我们对代码中进行两处修改： 注释掉PyErr_CheckSignals中的if (PyThread_get_thread_ident() != main_thread) 注释掉Py_MakePendingCalls中的if (main_thread &amp;&amp; PyThread_get_thread_ident() != main_thread) 再次编译调试，发现可以正常退出了 杂项函数的实现线程创建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990// thread.cvoidPyThread_init_thread(void)&#123;#ifdef Py_DEBUG char *p = Py_GETENV("PYTHONTHREADDEBUG"); if (p) &#123; if (*p) thread_debug = atoi(p); else thread_debug = 1; &#125;#endif /* Py_DEBUG */ if (initialized) return; initialized = 1; dprintf(("PyThread_init_thread called\n")); PyThread__init_thread();&#125;static voidPyThread__init_thread(void)&#123; /* DO AN INIT BY STARTING THE THREAD */ static int dummy = 0; pthread_t thread1; pthread_create(&amp;thread1, NULL, (void *) _noop, &amp;dummy); pthread_join(thread1, NULL);&#125;// 这是创建线程的主入口longPyThread_start_new_thread(void (*func)(void *), void *arg)&#123; pthread_t th; int status;#if defined(THREAD_STACK_SIZE) || defined(PTHREAD_SYSTEM_SCHED_SUPPORTED) pthread_attr_t attrs;#endif#if defined(THREAD_STACK_SIZE) size_t tss;#endif dprintf(("PyThread_start_new_thread called\n")); if (!initialized) PyThread_init_thread();#if defined(THREAD_STACK_SIZE) || defined(PTHREAD_SYSTEM_SCHED_SUPPORTED) if (pthread_attr_init(&amp;attrs) != 0) return -1;#endif#if defined(THREAD_STACK_SIZE) tss = (_pythread_stacksize != 0) ? _pythread_stacksize : THREAD_STACK_SIZE; if (tss != 0) &#123; if (pthread_attr_setstacksize(&amp;attrs, tss) != 0) &#123; pthread_attr_destroy(&amp;attrs); return -1; &#125; &#125;#endif#if defined(PTHREAD_SYSTEM_SCHED_SUPPORTED) pthread_attr_setscope(&amp;attrs, PTHREAD_SCOPE_SYSTEM);#endif status = pthread_create(&amp;th,#if defined(THREAD_STACK_SIZE) || defined(PTHREAD_SYSTEM_SCHED_SUPPORTED) &amp;attrs,#else (pthread_attr_t*)NULL,#endif (void* (*)(void *))func, (void *)arg );#if defined(THREAD_STACK_SIZE) || defined(PTHREAD_SYSTEM_SCHED_SUPPORTED) pthread_attr_destroy(&amp;attrs);#endif if (status != 0) return -1; // 这里直接detach了，join是Python自己实现的wait pthread_detach(th);#if SIZEOF_PTHREAD_T &lt;= SIZEOF_LONG return (long) th;#else return (long) *(long *) &amp;th;#endif&#125; 线程状态转移12345678910111213141516171819202122232425// pystate.cPyThreadState *PyThreadState_Swap(PyThreadState *newts)&#123; PyThreadState *oldts = _PyThreadState_Current; _PyThreadState_Current = newts; /* It should not be possible for more than one thread state to be used for a thread. Check this the best we can in debug builds. */#if defined(Py_DEBUG) &amp;&amp; defined(WITH_THREAD) if (newts) &#123; /* This can be called from PyEval_RestoreThread(). Similar to it, we need to ensure errno doesn't change. */ int err = errno; PyThreadState *check = PyGILState_GetThisThreadState(); if (check &amp;&amp; check-&gt;interp == newts-&gt;interp &amp;&amp; check != newts) Py_FatalError("Invalid thread state for this thread"); errno = err; &#125;#endif return oldts;&#125; CV+Mutex实现锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// thread_pthread.htypedef struct &#123; char locked; /* 0=unlocked, 1=locked */ /* a &lt;cond, mutex&gt; pair to handle an acquire of a locked lock */ pthread_cond_t lock_released; pthread_mutex_t mut;&#125; pthread_lock;intPyThread_acquire_lock(PyThread_type_lock lock, int waitflag)&#123; int success; pthread_lock *thelock = (pthread_lock *)lock; int status, error = 0; dprintf(("PyThread_acquire_lock(%p, %d) called\n", lock, waitflag)); status = pthread_mutex_lock( &amp;thelock-&gt;mut ); CHECK_STATUS("pthread_mutex_lock[1]"); success = thelock-&gt;locked == 0; if ( !success &amp;&amp; waitflag ) &#123; /* continue trying until we get the lock */ /* mut must be locked by me -- part of the condition protocol */ while ( thelock-&gt;locked ) &#123; status = pthread_cond_wait(&amp;thelock-&gt;lock_released, &amp;thelock-&gt;mut); CHECK_STATUS("pthread_cond_wait"); &#125; success = 1; &#125; if (success) thelock-&gt;locked = 1; status = pthread_mutex_unlock( &amp;thelock-&gt;mut ); CHECK_STATUS("pthread_mutex_unlock[1]"); if (error) success = 0; dprintf(("PyThread_acquire_lock(%p, %d) -&gt; %d\n", lock, waitflag, success)); return success;&#125;voidPyThread_release_lock(PyThread_type_lock lock)&#123; pthread_lock *thelock = (pthread_lock *)lock; int status, error = 0; (void) error; /* silence unused-but-set-variable warning */ dprintf(("PyThread_release_lock(%p) called\n", lock)); status = pthread_mutex_lock( &amp;thelock-&gt;mut ); CHECK_STATUS("pthread_mutex_lock[3]"); thelock-&gt;locked = 0; status = pthread_mutex_unlock( &amp;thelock-&gt;mut ); CHECK_STATUS("pthread_mutex_unlock[3]"); /* wake up someone (anyone, if any) waiting on the lock */ // 在退出临界区时signal status = pthread_cond_signal( &amp;thelock-&gt;lock_released ); CHECK_STATUS("pthread_cond_signal");&#125;]]></content>
      <tags>
        <tag>python</tag>
        <tag>多线程</tag>
        <tag>Linux</tag>
        <tag>并行计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis底层对象实现原理分析]]></title>
    <url>%2F2018%2F07%2F23%2Fredis_learn_object%2F</url>
    <content type="text"><![CDATA[我将直接根据github上的unstable分支代码分析。主要是2018年7月版本（dict实现的大部分）的和2020年8月版本（其他部分）的，所以可能会有细微差别。因为Redis的代码比较好读，并且质量很高。这里还推荐《Redis设计与实现》一书，它介绍了Redis中部分比较有趣的设计思路，可惜还有些没有覆盖到，本文中对这些有趣的设计也进行了论述。Redis中主要包含了字符串STRING、列表LIST（双向链表）、集合SET、哈希表HASH、有序集合ZSET五种最常见的类型。在后续的版本中，还提供了bitmap、geohash、hyperloglog、stream这四种类型。这些对象依赖于一些内部结构，包括字符串(SDS)、哈希表(dict)、链表(list)、跳表(zskiplist)、压缩双向表(ziplist)、快表等。注意出于性能原因，一个对象的实现往往根据具体的内容而选择不同的实现。列举如下： STRING 使用int、sds(raw)或者embstr。 下面的类型也是使用STRING的存储的： hyperloglog bitmap HASH 使用dict或者ziplist方案。 LIST 3.0是使用list或者ziplist的方案。 目前使用快表。 SET 使用dict或者intset的方案。 ZSET 视数据规模选用ziplist和skiplist+dict的方案。 下面的类型也是使用ZSET的存储的： GEOHASH 此外，为了解释很多数据结构的实现，在这篇文章之中，还会介绍Redis服务器的相关实现，包括： redisDb，以及在这上面的增删改查 Redis的expire和evict机制 Redis的事件机制 Redis的主从复制（一部分） 注意，很多实现在引入主从复制之后都变得非常复杂，有很多边边角角要考虑，这也导致Redis的代码相比3.0版本要难看很多。本文对主从复制的涉及，局限于帮助理解实现。 本文介绍的部分比如propagate机制。 本文中不介绍的是： Redis Sentinel Redis Cluster Redis AOF/RDB 最后，本文的主体部分已经完成，但后续仍然会进行修订，或者补充。 Redis源码结构在3.0版本中，redis的主要结构都定义在redis.h中，在新版本中，它们被放到了server.h中。 Redis Server这个章节中介绍Redis数据库顶层键的架构和增删改查的实现，主要包括： 一些常用的类 redisServer redisDb redisObject 包含添加对象的逻辑 删除逻辑 包含对同步删除和异步删除的讨论。 查找逻辑 expire evict propagate 事件机制 内存管理 redisDb类1234567891011typedef struct redisDb &#123; dict *dict; /* 数据库键空间 */ dict *expires; /* 键的过期时间，字典的键为键，字典的值为过期时间 */ dict *blocking_keys; /* 用来服务诸如BLPOP的命令，记录目前被阻塞的键 */ dict *ready_keys; /* Blocked keys that received a PUSH */ dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ int id; /* Database ID */ long long avg_ttl; /* 数据库键的平均TTL，统计信息 */ unsigned long expires_cursor; /* Cursor of the active expire cycle. */ list *defrag_later; /* List of key names to attempt to defrag one by one, gradually. */&#125; redisDb; 可以发现，redisDb本身就依赖dict和list等Redis底层结构的实现，说明Redis的复用性还是很好的。 增删改查涉及的系统梳理 DB部分 更新dirty Cluster部分 事件部分 signalModifiedKey：包含通知WATCH列表、通知客户端更新缓存 notifyKeyspaceEvent：通过PUBLUSH发送消息 主从复制/持久化部分 propagate对应命令（在call中处理） Module部分 Redis Object诸如dict、sds之类的对象，在db层面实际上是用redisObject封装的，需要的时候通过robj-&gt;ptr获取实际需要的指针。 123456789101112typedef struct redisObject &#123; unsigned type:4; // 由OBJ_的值指定 unsigned encoding:4; // 由OBJ_ENCODING_的值指定 unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ int refcount; void *ptr;&#125; robj;// server.h#define LRU_BITS 24 Redis对象的类型是用OBJ_宏来列出的123456789101112131415161718192021// server.h/* The actual Redis Object */#define OBJ_STRING 0 /* String object. */#define OBJ_LIST 1 /* List object. */#define OBJ_SET 2 /* Set object. */#define OBJ_ZSET 3 /* Sorted set object. */#define OBJ_HASH 4 /* Hash object. *//* The "module" object type is a special one that signals that the object * is one directly managed by a Redis module. In this case the value points * to a moduleValue struct, which contains the object value (which is only * handled by the module itself) and the RedisModuleType struct which lists * function pointers in order to serialize, deserialize, AOF-rewrite and * free the object. * * Inside the RDB file, module types are encoded as OBJ_MODULE followed * by a 64 bit module type ID, which has a 54 bits module-specific signature * in order to dispatch the loading to the right module, plus a 10 bits * encoding version. */#define OBJ_MODULE 5 /* Module object. */#define OBJ_STREAM 6 /* Stream object. */ Redis对象实际使用的内部结构是用OBJ_ENCODING_宏来表示的，如前文所列举的，同一个对象可能有不同的实现。 1234567891011121314// server.h// OBJ_ENCODING_RAW是普通的SDS#define OBJ_ENCODING_RAW 0 /* Raw representation */#define OBJ_ENCODING_INT 1 /* Encoded as integer */#define OBJ_ENCODING_HT 2 /* Encoded as hash table */#define OBJ_ENCODING_ZIPMAP 3 /* Encoded as zipmap */#define OBJ_ENCODING_LINKEDLIST 4 /* No longer used: old list encoding. */#define OBJ_ENCODING_ZIPLIST 5 /* Encoded as ziplist */#define OBJ_ENCODING_INTSET 6 /* Encoded as intset */#define OBJ_ENCODING_SKIPLIST 7 /* Encoded as skiplist */// embstr是对短字符串的一种优化编码#define OBJ_ENCODING_EMBSTR 8 /* Embedded sds string encoding */#define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list of ziplists */#define OBJ_ENCODING_STREAM 10 /* Encoded as a radix tree of listpacks */ 引用计数有两种特殊的引用计数值： OBJ_SHARED_REFCOUNT 由makeObjectShared函数生成，在这种情况下这个对象是immutable的，因此可以不加锁地进行访问。这种对象也不受incrRefCount/decrRefCount控制。 注意，这种对象设为immutable是合理的，它的一个通常作用是共享小整数对象，例如Redis会共享0到9999。 OBJ_STATIC_REFCOUNT 一般由initStaticStringObject宏生成。看上去这个一般用在在栈上面分配的临时对象的refcount，我对此也不是很确定。1234#define OBJ_SHARED_REFCOUNT INT_MAX /* Global object never destroyed. */#define OBJ_STATIC_REFCOUNT (INT_MAX-1) /* Object allocated in the stack. */// 第一个有特殊含义的refcount值#define OBJ_FIRST_SPECIAL_REFCOUNT OBJ_STATIC_REFCOUNT 一般来说，使用引用计数可能存在循环引用的问题。Redis巧妙地避免了这个问题，首先在Redis的所有redisObject里面，只有String会被嵌入到其他类型中，也就是说ZSET等其他的数据类型不会互相引用（在Geo等新数据结构里面也是这样的么？）。而Redis对String类型引入对象共享机制，保证了不会产生互相引用。1234567891011void incrRefCount(robj *o) &#123; if (o-&gt;refcount &lt; OBJ_FIRST_SPECIAL_REFCOUNT) &#123; o-&gt;refcount++; &#125; else &#123; if (o-&gt;refcount == OBJ_SHARED_REFCOUNT) &#123; /* Nothing to do: this refcount is immutable. */ &#125; else if (o-&gt;refcount == OBJ_STATIC_REFCOUNT) &#123; serverPanic("You tried to retain an object allocated in the stack"); &#125; &#125;&#125; decrRefCount还负责销毁对象，步骤是freeXXXObject，然后在zfree。前者用来释放o-&gt;ptr指向的对象的内存，后者用来释放o的内存。123456789101112131415161718void decrRefCount(robj *o) &#123; if (o-&gt;refcount == 1) &#123; switch(o-&gt;type) &#123; case OBJ_STRING: freeStringObject(o); break; case OBJ_LIST: freeListObject(o); break; case OBJ_SET: freeSetObject(o); break; case OBJ_ZSET: freeZsetObject(o); break; case OBJ_HASH: freeHashObject(o); break; case OBJ_MODULE: freeModuleObject(o); break; case OBJ_STREAM: freeStreamObject(o); break; default: serverPanic("Unknown object type"); break; &#125; zfree(o); &#125; else &#123; if (o-&gt;refcount &lt;= 0) serverPanic("decrRefCount against refcount &lt;= 0"); if (o-&gt;refcount != OBJ_SHARED_REFCOUNT) o-&gt;refcount--; &#125;&#125; 我们可以这样理解incr/decrRefCount，如果我们创建或者复制一个对象，就要incr，如果我们要删除一个对象就要decr。 创建对象通过createObject创建对象，refcount设为1。encoding设为OBJ_ENCODING_RAW，也就是普通SDS字符串。传入的type是OBJ_宏的某个特定值。12345678910111213141516robj *createObject(int type, void *ptr) &#123; robj *o = zmalloc(sizeof(*o)); o-&gt;type = type; o-&gt;encoding = OBJ_ENCODING_RAW; o-&gt;ptr = ptr; o-&gt;refcount = 1; /* Set the LRU to the current lruclock (minutes resolution), or * alternatively the LFU counter. */ if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) &#123; o-&gt;lru = (LFUGetTimeInMinutes()&lt;&lt;8) | LFU_INIT_VAL; &#125; else &#123; o-&gt;lru = LRU_CLOCK(); &#125; return o;&#125; 一般在创建完对象后，还需要通过dbAdd将它插入到数据库里面。123456789101112/* Add the key to the DB. It's up to the caller to increment the reference * counter of the value if needed. * * The program is aborted if the key already exists. */void dbAdd(redisDb *db, robj *key, robj *val) &#123; sds copy = sdsdup(key-&gt;ptr); int retval = dictAdd(db-&gt;dict, copy, val); serverAssertWithInfo(NULL,key,retval == DICT_OK); signalKeyAsReady(db, key, val-&gt;type); if (server.cluster_enabled) slotToKeyAdd(key-&gt;ptr);&#125; 对象装箱拆箱这个都是返回一个“新”对象，这里“新”的意思是在使用完这个对象都应该decrRefCount。如果是原生encoding储存的，就直接返回。123456789#define sdsEncodedObject(objptr) (objptr-&gt;encoding == OBJ_ENCODING_RAW || objptr-&gt;encoding == OBJ_ENCODING_EMBSTR)robj *getDecodedObject(robj *o) &#123; robj *dec; if (sdsEncodedObject(o)) &#123; incrRefCount(o); return o; &#125; 如果使用SDS保存的整数，实际上里面是个long long，那么就需要先ll2string把这个转换成字符串。12345678910 if (o-&gt;type == OBJ_STRING &amp;&amp; o-&gt;encoding == OBJ_ENCODING_INT) &#123; char buf[32]; ll2string(buf,32,(long)o-&gt;ptr); dec = createStringObject(buf,strlen(buf)); return dec; &#125; else &#123; serverPanic("Unknown encoding type"); &#125;&#125; Redis CommandredisCommand对象redisCommand对象有新旧很多种版本，新旧版本中存在一些区别，例如sflag的内容，我们以新版本为主。123456789101112131415// server.hstruct redisCommand &#123; char *name; redisCommandProc *proc; int arity; char *sflags; /* Flags as string representation, one char per flag. */ uint64_t flags; /* The actual flags, obtained from the 'sflags' field. */ /* Use a function to determine keys arguments in a command line. * 通常用在Redis Cluster转发过程中 */ redisGetKeysProc *getkeys_proc; /* What keys should be loaded in background when calling this command? */ int firstkey; /* The first argument that's a key (0 = no keys) */ int lastkey; /* The last argument that's a key */ int keystep; /* The step between first and last key */ long long microseconds, calls; command id，是从0开始递增的，作用是检查ACL。一个connection在执行命令前，服务器先要检查第id位有没有设置，如果设置了，说明这个connection有对应的权限。12 int id;&#125;; 解释如下： sflags表示这个命令的一些特性 是字符串格式的。 详见https://segmentfault.com/a/1190000017104165 flags是通过populateCommandTableParseFlags从sflags生成的二进制表示。详见server.h中的CMD_定义，我们在下面会讲解。 下面是key三元组：firstkey表示第一个key参数的位置，lastkey表示最后一个key参数的位置，keystep表示key参数步长。通过上面三个参数，可以拿到所有的key。通常发生在getKeysFromCommand到getKeysUsingCommandTable函数调用链中。引入这个三元组的目的是有一些指令（如mset和msetnx的keystep取2）是支持在一个命令中对多个key/value对进行赋值的。我们需要注意的是诸如ZADD的指令虽然可以同时添加很多个(score, member)对，但是实际上他们是对一个key添加的，所以它们的三元组都是1。 getkeys_proc表示从命令中判断命令的key，实际上就是当firstkey、lastkey和keystep不能描述的时候，就会用到这个，返回一个int*表示所有key。例如后面举的eval的例子。 microseconds表示该命令的调用总时间 calls表示该命令的调用总次数 id是在运行时给每个指令分配的id flags枚举 CMD_WRITE (1ULL&lt;&lt;0) CMD_READONLY (1ULL&lt;&lt;1) 对应read-only，一般包括所有的非特殊的命令，例如返回keys的值，或者返回一些其他信息，例如TIME等。诸如admin、transaction相关的信息，也不会被标记为readonly，因为他们会影响服务器状态。 只读命令和非只读命令在主从复制时，是不一样的。 CMD_DENYOOM (1ULL&lt;&lt;2) 对应use-memory，表示这个命令可能导致内存增加。需要在发生OOM的时候拒绝掉。 CMD_MODULE (1ULL&lt;&lt;3) CMD_ADMIN (1ULL&lt;&lt;4) 对应admin，诸如SAVE或者SHUTDOWN的命令。 CMD_PUBSUB (1ULL&lt;&lt;5) CMD_NOSCRIPT (1ULL&lt;&lt;6) CMD_RANDOM (1ULL&lt;&lt;7) 对应random，有的命令即使在相同的情况下的运行结果也是不确定的，诸如SPOP、RANDOMKEY。 CMD_SORT_FOR_SCRIPT (1ULL&lt;&lt;8) 对应to-sort，需要对输出序列进行排序。 CMD_LOADING (1ULL&lt;&lt;9) CMD_STALE (1ULL&lt;&lt;10) CMD_SKIP_MONITOR (1ULL&lt;&lt;11) no-monitor，不自动将这个命令propagate到MONITOR。 CMD_SKIP_SLOWLOG (1ULL&lt;&lt;12) no-slowlog，不自动将这个命令propagate到slowlog。比如EXEC、AUTH之类的命。 CMD_ASKING (1ULL&lt;&lt;13) CMD_FAST (1ULL&lt;&lt;14) 这个命令是O(1)或者O(log(N))复杂度的，他们不会延误执行。注意所有可能导致DEL操作的并不是FAST命令，例如SET。 CMD_NO_AUTH (1ULL&lt;&lt;15) Demo我们结合一个具体的定义来了解这个结构：123456789101112131415161718192021222324252627282930313233343536373839// server.cstruct redisCommand redisCommandTable[] = &#123; &#123;"module",moduleCommand,-2, // -2表示大于等于2个参数 "admin no-script", 0,NULL,0,0,0,0,0,0&#125;, &#123;"get",getCommand,2, // 这个叫get的指令对应到void getCommand(client *c)，有2个参数 "read-only fast @string", // 是只读的，fast表示命令执行时间超过阈值时，会记录延迟事件。 0, // flags NULL, // getkeys_proc 1, // firstkey 1, // lastkey 1, // keystep 0, // microseconds 0, // calls 0 // id &#125;, /* Note that we can't flag set as fast, since it may perform an * implicit DEL of a large key. */ &#123;"set",setCommand,-3, "write use-memory @string", 0,NULL,1,1,1,0,0,0&#125;, &#123;"setnx",setnxCommand,3, "write use-memory fast @string", 0,NULL,1,1,1,0,0,0&#125;, &#123;"eval",evalCommand,-3, "no-script @scripting", 0, evalGetKeys, // eval无法通过key三元组描述，所以这里指定一个特殊的getkeys_proc 0,0,0, 0,0,0&#125;, &#123;"zadd",zaddCommand,-4, "write use-memory fast @sortedset", 0,NULL,1,1,1,0,0,0&#125;, ... 命令的处理顺序 call processCommand processCommandAndResetClient processInputBuffer readQueryFromClient handleClientsWithPendingReadsUsingThreads handleClientsWithPendingReadsUsingThreads stopThreadedIO beforeSleep processCommand这个函数很复杂： 通过call执行命令 准备从客户端进行一次读取 返回C_OK表示这个客户端还存在，否则表示这个客户端没了。 首先需要特别处理quit命令。123456789101112int processCommand(client *c) &#123; moduleCallCommandFilters(c); /* The QUIT command is handled separately. Normal command procs will * go through checking for replication and QUIT will cause trouble * when FORCE_REPLICATION is enabled and would be implemented in * a regular command proc. */ if (!strcasecmp(c-&gt;argv[0]-&gt;ptr,"quit")) &#123; addReply(c,shared.ok); c-&gt;flags |= CLIENT_CLOSE_AFTER_REPLY; return C_ERR; &#125; 下面通过lookupCommand查找对应的命令结构，并处理找不到或者命令格式错误的情况。123456789101112131415161718/* Now lookup the command and check ASAP about trivial error conditions * such as wrong arity, bad command name and so forth. */c-&gt;cmd = c-&gt;lastcmd = lookupCommand(c-&gt;argv[0]-&gt;ptr);if (!c-&gt;cmd) &#123; sds args = sdsempty(); int i; for (i=1; i &lt; c-&gt;argc &amp;&amp; sdslen(args) &lt; 128; i++) args = sdscatprintf(args, "`%.*s`, ", 128-(int)sdslen(args), (char*)c-&gt;argv[i]-&gt;ptr); rejectCommandFormat(c,"unknown command `%s`, with args beginning with: %s", (char*)c-&gt;argv[0]-&gt;ptr, args); sdsfree(args); return C_OK;&#125; else if ((c-&gt;cmd-&gt;arity &gt; 0 &amp;&amp; c-&gt;cmd-&gt;arity != c-&gt;argc) || (c-&gt;argc &lt; -c-&gt;cmd-&gt;arity)) &#123; rejectCommandFormat(c,"wrong number of arguments for '%s' command", c-&gt;cmd-&gt;name); return C_OK;&#125; 判断命令的性质，是只读的，还是可写的等性质。12345678int is_write_command = (c-&gt;cmd-&gt;flags &amp; CMD_WRITE) || (c-&gt;cmd-&gt;proc == execCommand &amp;&amp; (c-&gt;mstate.cmd_flags &amp; CMD_WRITE));int is_denyoom_command = (c-&gt;cmd-&gt;flags &amp; CMD_DENYOOM) || (c-&gt;cmd-&gt;proc == execCommand &amp;&amp; (c-&gt;mstate.cmd_flags &amp; CMD_DENYOOM));int is_denystale_command = !(c-&gt;cmd-&gt;flags &amp; CMD_STALE) || (c-&gt;cmd-&gt;proc == execCommand &amp;&amp; (c-&gt;mstate.cmd_inv_flags &amp; CMD_STALE));int is_denyloading_command = !(c-&gt;cmd-&gt;flags &amp; CMD_LOADING) || (c-&gt;cmd-&gt;proc == execCommand &amp;&amp; (c-&gt;mstate.cmd_inv_flags &amp; CMD_LOADING)); 进行权限检查12345678910111213141516171819202122232425262728293031/* Check if the user is authenticated. This check is skipped in case * the default user is flagged as "nopass" and is active. */int auth_required = (!(DefaultUser-&gt;flags &amp; USER_FLAG_NOPASS) || (DefaultUser-&gt;flags &amp; USER_FLAG_DISABLED)) &amp;&amp; !c-&gt;authenticated;if (auth_required) &#123; /* AUTH and HELLO and no auth modules are valid even in * non-authenticated state. */ if (!(c-&gt;cmd-&gt;flags &amp; CMD_NO_AUTH)) &#123; rejectCommand(c,shared.noautherr); return C_OK; &#125;&#125;/* Check if the user can run this command according to the current * ACLs. */int acl_keypos;int acl_retval = ACLCheckCommandPerm(c,&amp;acl_keypos);if (acl_retval != ACL_OK) &#123; addACLLogEntry(c,acl_retval,acl_keypos,NULL); if (acl_retval == ACL_DENIED_CMD) rejectCommandFormat(c, "-NOPERM this user has no permissions to run " "the '%s' command or its subcommand", c-&gt;cmd-&gt;name); else rejectCommandFormat(c, "-NOPERM this user has no permissions to access " "one of the keys used as arguments"); return C_OK;&#125; 如果启用了Redis Cluster，就要进行转发。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178 /* If cluster is enabled perform the cluster redirection here. * However we don't perform the redirection if: * 1) The sender of this command is our master. * 2) The command has no key arguments. */ if (server.cluster_enabled &amp;&amp; !(c-&gt;flags &amp; CLIENT_MASTER) &amp;&amp; !(c-&gt;flags &amp; CLIENT_LUA &amp;&amp; server.lua_caller-&gt;flags &amp; CLIENT_MASTER) &amp;&amp; !(!cmdHasMovableKeys(c-&gt;cmd) &amp;&amp; c-&gt;cmd-&gt;firstkey == 0 &amp;&amp; c-&gt;cmd-&gt;proc != execCommand)) &#123; int hashslot; int error_code; clusterNode *n = getNodeByQuery(c,c-&gt;cmd,c-&gt;argv,c-&gt;argc, &amp;hashslot,&amp;error_code); if (n == NULL || n != server.cluster-&gt;myself) &#123; if (c-&gt;cmd-&gt;proc == execCommand) &#123; discardTransaction(c); &#125; else &#123; flagTransaction(c); &#125; clusterRedirectClient(c,n,hashslot,error_code); return C_OK; &#125; &#125; /* Handle the maxmemory directive. * * Note that we do not want to reclaim memory if we are here re-entering * the event loop since there is a busy Lua script running in timeout * condition, to avoid mixing the propagation of scripts with the * propagation of DELs due to eviction. */ if (server.maxmemory &amp;&amp; !server.lua_timedout) &#123; int out_of_memory = freeMemoryIfNeededAndSafe() == C_ERR; /* freeMemoryIfNeeded may flush slave output buffers. This may result * into a slave, that may be the active client, to be freed. */ if (server.current_client == NULL) return C_ERR; int reject_cmd_on_oom = is_denyoom_command; /* If client is in MULTI/EXEC context, queuing may consume an unlimited * amount of memory, so we want to stop that. * However, we never want to reject DISCARD, or even EXEC (unless it * contains denied commands, in which case is_denyoom_command is already * set. */ if (c-&gt;flags &amp; CLIENT_MULTI &amp;&amp; c-&gt;cmd-&gt;proc != execCommand &amp;&amp; c-&gt;cmd-&gt;proc != discardCommand) &#123; reject_cmd_on_oom = 1; &#125; if (out_of_memory &amp;&amp; reject_cmd_on_oom) &#123; rejectCommand(c, shared.oomerr); return C_OK; &#125; /* Save out_of_memory result at script start, otherwise if we check OOM * untill first write within script, memory used by lua stack and * arguments might interfere. */ if (c-&gt;cmd-&gt;proc == evalCommand || c-&gt;cmd-&gt;proc == evalShaCommand) &#123; server.lua_oom = out_of_memory; &#125; &#125; /* Make sure to use a reasonable amount of memory for client side * caching metadata. */ if (server.tracking_clients) trackingLimitUsedSlots(); /* Don't accept write commands if there are problems persisting on disk * and if this is a master instance. */ int deny_write_type = writeCommandsDeniedByDiskError(); if (deny_write_type != DISK_ERROR_TYPE_NONE &amp;&amp; server.masterhost == NULL &amp;&amp; (is_write_command ||c-&gt;cmd-&gt;proc == pingCommand)) &#123; if (deny_write_type == DISK_ERROR_TYPE_RDB) rejectCommand(c, shared.bgsaveerr); else rejectCommandFormat(c, "-MISCONF Errors writing to the AOF file: %s", strerror(server.aof_last_write_errno)); return C_OK; &#125; /* Don't accept write commands if there are not enough good slaves and * user configured the min-slaves-to-write option. */ if (server.masterhost == NULL &amp;&amp; server.repl_min_slaves_to_write &amp;&amp; server.repl_min_slaves_max_lag &amp;&amp; is_write_command &amp;&amp; server.repl_good_slaves_count &lt; server.repl_min_slaves_to_write) &#123; rejectCommand(c, shared.noreplicaserr); return C_OK; &#125; /* Don't accept write commands if this is a read only slave. But * accept write commands if this is our master. */ if (server.masterhost &amp;&amp; server.repl_slave_ro &amp;&amp; !(c-&gt;flags &amp; CLIENT_MASTER) &amp;&amp; is_write_command) &#123; rejectCommand(c, shared.roslaveerr); return C_OK; &#125; /* Only allow a subset of commands in the context of Pub/Sub if the * connection is in RESP2 mode. With RESP3 there are no limits. */ if ((c-&gt;flags &amp; CLIENT_PUBSUB &amp;&amp; c-&gt;resp == 2) &amp;&amp; c-&gt;cmd-&gt;proc != pingCommand &amp;&amp; c-&gt;cmd-&gt;proc != subscribeCommand &amp;&amp; c-&gt;cmd-&gt;proc != unsubscribeCommand &amp;&amp; c-&gt;cmd-&gt;proc != psubscribeCommand &amp;&amp; c-&gt;cmd-&gt;proc != punsubscribeCommand) &#123; rejectCommandFormat(c, "Can't execute '%s': only (P)SUBSCRIBE / " "(P)UNSUBSCRIBE / PING / QUIT are allowed in this context", c-&gt;cmd-&gt;name); return C_OK; &#125; /* Only allow commands with flag "t", such as INFO, SLAVEOF and so on, * when slave-serve-stale-data is no and we are a slave with a broken * link with master. */ if (server.masterhost &amp;&amp; server.repl_state != REPL_STATE_CONNECTED &amp;&amp; server.repl_serve_stale_data == 0 &amp;&amp; is_denystale_command) &#123; rejectCommand(c, shared.masterdownerr); return C_OK; &#125; /* Loading DB? Return an error if the command has not the * CMD_LOADING flag. */ if (server.loading &amp;&amp; is_denyloading_command) &#123; rejectCommand(c, shared.loadingerr); return C_OK; &#125; /* Lua script too slow? Only allow a limited number of commands. * Note that we need to allow the transactions commands, otherwise clients * sending a transaction with pipelining without error checking, may have * the MULTI plus a few initial commands refused, then the timeout * condition resolves, and the bottom-half of the transaction gets * executed, see Github PR #7022. */ if (server.lua_timedout &amp;&amp; c-&gt;cmd-&gt;proc != authCommand &amp;&amp; c-&gt;cmd-&gt;proc != helloCommand &amp;&amp; c-&gt;cmd-&gt;proc != replconfCommand &amp;&amp; c-&gt;cmd-&gt;proc != multiCommand &amp;&amp; c-&gt;cmd-&gt;proc != discardCommand &amp;&amp; c-&gt;cmd-&gt;proc != watchCommand &amp;&amp; c-&gt;cmd-&gt;proc != unwatchCommand &amp;&amp; !(c-&gt;cmd-&gt;proc == shutdownCommand &amp;&amp; c-&gt;argc == 2 &amp;&amp; tolower(((char*)c-&gt;argv[1]-&gt;ptr)[0]) == 'n') &amp;&amp; !(c-&gt;cmd-&gt;proc == scriptCommand &amp;&amp; c-&gt;argc == 2 &amp;&amp; tolower(((char*)c-&gt;argv[1]-&gt;ptr)[0]) == 'k')) &#123; rejectCommand(c, shared.slowscripterr); return C_OK; &#125; /* Exec the command */ if (c-&gt;flags &amp; CLIENT_MULTI &amp;&amp; c-&gt;cmd-&gt;proc != execCommand &amp;&amp; c-&gt;cmd-&gt;proc != discardCommand &amp;&amp; c-&gt;cmd-&gt;proc != multiCommand &amp;&amp; c-&gt;cmd-&gt;proc != watchCommand) &#123; queueMultiCommand(c); addReply(c,shared.queued); &#125; else &#123; call(c,CMD_CALL_FULL); c-&gt;woff = server.master_repl_offset; if (listLength(server.ready_keys)) handleClientsBlockedOnKeys(); &#125; return C_OK;&#125; callcall就是调用指令的函数，有一系列的flag： CMD_CALL_NONE CMD_CALL_SLOWLOG 检查指令执行的速度，是否记录到slow log中呢？ CMD_CALL_STATS Populate command stats. CMD_CALL_PROPAGATE_AOF 如果对数据有改动（可以通过server.dirty字段看出），或者client有一个强迫propagate的CLIENT_FORCE_AOF，就加到AOF上。 相应的，如果client设置了CLIENT_PREVENT_AOF_PROP，那么即使数据集变动了，也不会写AOF。 注意，无论client设置了什么，如果没有CMD_CALL_PROPAGATE_AOF，那么永远不会写AOF。 CMD_CALL_PROPAGATE_REPL 同理，但是对Slave。同样有CLIENT_FORCE_REPL/CLIENT_PREVENT_REPL_PROP。 CMD_CALL_PROPAGATE 相当于PROPAGATE_AOF|PROPAGATE_REPL CMD_CALL_FULL 相当于SLOWLOG|STATS|PROPAGATE call主要就是用c-&gt;cmd-&gt;proc(c)执行命令，后者实际上就是xxxCommand()这样的命令。12345void call(client *c, int flags) &#123; long long dirty; ustime_t start, duration; int client_old_flags = c-&gt;flags; struct redisCommand *real_cmd = c-&gt;cmd; fixed_time_expire在expire机制中见到过的，如果有命令在执行过程中，这个值就不是0。还会把除了ADMIN之外的命令发送给MONITOR，ADMIN命令展示出来太危险了。12345678910server.fixed_time_expire++;/* Send the command to clients in MONITOR mode if applicable. * Administrative commands are considered too dangerous to be shown. */if (listLength(server.monitors) &amp;&amp; !server.loading &amp;&amp; !(c-&gt;cmd-&gt;flags &amp; (CMD_SKIP_MONITOR|CMD_ADMIN)))&#123; replicationFeedMonitors(c,server.monitors,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc);&#125; 下面是一些初始化和执行工作。1234567891011/* Initialization: clear the flags that must be set by the command on * demand, and initialize the array for additional commands propagation. */c-&gt;flags &amp;= ~(CLIENT_FORCE_AOF|CLIENT_FORCE_REPL|CLIENT_PREVENT_PROP);redisOpArray prev_also_propagate = server.also_propagate;redisOpArrayInit(&amp;server.also_propagate);/* Call the command. */dirty = server.dirty;updateCachedTime(0);start = server.ustime;c-&gt;cmd-&gt;proc(c); 在执行后，统计数据库被修改的次数dirty。在第一篇文章中看到，比如我新加一个元素，或者修改一个元素，都会导致dirty增加。也就对应了数据的改变。123456789101112131415161718duration = ustime()-start;dirty = server.dirty-dirty;if (dirty &lt; 0) dirty = 0;/* When EVAL is called loading the AOF we don't want commands called * from Lua to go into the slowlog or to populate statistics. */if (server.loading &amp;&amp; c-&gt;flags &amp; CLIENT_LUA) flags &amp;= ~(CMD_CALL_SLOWLOG | CMD_CALL_STATS);/* If the caller is Lua, we want to force the EVAL caller to propagate * the script if the command flag or client flag are forcing the * propagation. */if (c-&gt;flags &amp; CLIENT_LUA &amp;&amp; server.lua_caller) &#123; if (c-&gt;flags &amp; CLIENT_FORCE_REPL) server.lua_caller-&gt;flags |= CLIENT_FORCE_REPL; if (c-&gt;flags &amp; CLIENT_FORCE_AOF) server.lua_caller-&gt;flags |= CLIENT_FORCE_AOF;&#125; 记录延迟信息，并记录slowlog。其中latencyAddSampleIfNeeded在适当的时候调用latencyAddSample。12345678910111213141516/* Log the command into the Slow log if needed, and populate the * per-command statistics that we show in INFO commandstats. */if (flags &amp; CMD_CALL_SLOWLOG &amp;&amp; !(c-&gt;cmd-&gt;flags &amp; CMD_SKIP_SLOWLOG)) &#123; char *latency_event = (c-&gt;cmd-&gt;flags &amp; CMD_FAST) ? "fast-command" : "command"; latencyAddSampleIfNeeded(latency_event,duration/1000); slowlogPushEntryIfNeeded(c,c-&gt;argv,c-&gt;argc,duration);&#125;if (flags &amp; CMD_CALL_STATS) &#123; /* use the real command that was executed (cmd and lastamc) may be * different, in case of MULTI-EXEC or re-written commands such as * EXPIRE, GEOADD, etc. */ real_cmd-&gt;microseconds += duration; real_cmd-&gt;calls++;&#125; 下面处理propagate的情况，这个对应了CALL_开头的一些规则，就不详解了。最终会计算得到一个propagate_flags传给propagate。12345678910111213141516171819202122232425262728293031/* Propagate the command into the AOF and replication link */if (flags &amp; CMD_CALL_PROPAGATE &amp;&amp; (c-&gt;flags &amp; CLIENT_PREVENT_PROP) != CLIENT_PREVENT_PROP)&#123; int propagate_flags = PROPAGATE_NONE; /* Check if the command operated changes in the data set. If so * set for replication / AOF propagation. */ if (dirty) propagate_flags |= (PROPAGATE_AOF|PROPAGATE_REPL); /* If the client forced AOF / replication of the command, set * the flags regardless of the command effects on the data set. */ if (c-&gt;flags &amp; CLIENT_FORCE_REPL) propagate_flags |= PROPAGATE_REPL; if (c-&gt;flags &amp; CLIENT_FORCE_AOF) propagate_flags |= PROPAGATE_AOF; /* However prevent AOF / replication propagation if the command * implementations called preventCommandPropagation() or similar, * or if we don't have the call() flags to do so. */ if (c-&gt;flags &amp; CLIENT_PREVENT_REPL_PROP || !(flags &amp; CMD_CALL_PROPAGATE_REPL)) propagate_flags &amp;= ~PROPAGATE_REPL; if (c-&gt;flags &amp; CLIENT_PREVENT_AOF_PROP || !(flags &amp; CMD_CALL_PROPAGATE_AOF)) propagate_flags &amp;= ~PROPAGATE_AOF; /* Call propagate() only if at least one of AOF / replication * propagation is needed. Note that modules commands handle replication * in an explicit way, so we never replicate them automatically. */ if (propagate_flags != PROPAGATE_NONE &amp;&amp; !(c-&gt;cmd-&gt;flags &amp; CMD_MODULE)) propagate(c-&gt;cmd,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc,propagate_flags);&#125; 在结束之后，我们需要还原一下有关propagate的相关flag，因为call可能被递归调用。【Q】我觉得这里一个典型的例子就是这里的multi、exec。12345/* Restore the old replication flags, since call() can be executed * recursively. */c-&gt;flags &amp;= ~(CLIENT_FORCE_AOF|CLIENT_FORCE_REPL|CLIENT_PREVENT_PROP);c-&gt;flags |= client_old_flags &amp; (CLIENT_FORCE_AOF|CLIENT_FORCE_REPL|CLIENT_PREVENT_PROP); alsoPropagate函数可以往server.also_propagate里面加一些其他的op。下面就处理alsoPropagate的逻辑，也就是当propagate完当前的命令之后，还可以再去propagate一些命令。并且这些命令不被CLIENT_PREVENT_PROP影响。123456if (server.also_propagate.numops) &#123; int j; redisOp *rop; if (flags &amp; CMD_CALL_PROPAGATE) &#123; int multi_emitted = 0; 如果说已经被包在了MULTI里面，就不在继续包在also_propagate里面propagate了。execCommandPropagateMulti实际上就是下面的propagate调用。这里的shared.multi或者shared.exec实际上是缓存的字符串对象EXEC和MULTI，减少频繁的内存分配的作用。123456789void execCommandPropagateMulti(client *c) &#123; propagate(server.multiCommand,c-&gt;db-&gt;id,&amp;shared.multi,1, PROPAGATE_AOF|PROPAGATE_REPL);&#125;void execCommandPropagateExec(client *c) &#123; propagate(server.execCommand,c-&gt;db-&gt;id,&amp;shared.exec,1, PROPAGATE_AOF|PROPAGATE_REPL);&#125; 接下来就是做propagate。1234567891011121314151617181920212223242526272829303132 /* Wrap the commands in server.also_propagate array, * but don't wrap it if we are already in MULTI context, * in case the nested MULTI/EXEC. * * And if the array contains only one command, no need to * wrap it, since the single command is atomic. */ if (server.also_propagate.numops &gt; 1 &amp;&amp; !(c-&gt;cmd-&gt;flags &amp; CMD_MODULE) &amp;&amp; !(c-&gt;flags &amp; CLIENT_MULTI) &amp;&amp; !(flags &amp; CMD_CALL_NOWRAP)) &#123; execCommandPropagateMulti(c); multi_emitted = 1; &#125; for (j = 0; j &lt; server.also_propagate.numops; j++) &#123; rop = &amp;server.also_propagate.ops[j]; int target = rop-&gt;target; /* Whatever the command wish is, we honor the call() flags. */ if (!(flags&amp;CMD_CALL_PROPAGATE_AOF)) target &amp;= ~PROPAGATE_AOF; if (!(flags&amp;CMD_CALL_PROPAGATE_REPL)) target &amp;= ~PROPAGATE_REPL; if (target) propagate(rop-&gt;cmd,rop-&gt;dbid,rop-&gt;argv,rop-&gt;argc,target); &#125; if (multi_emitted) &#123; execCommandPropagateExec(c); &#125; &#125; redisOpArrayFree(&amp;server.also_propagate);&#125;server.also_propagate = prev_also_propagate; 这个应该是和客户端缓存有关的，如果client提供了keys tracking功能，要通知。这个函数里面维护了一个tracking invalidation表，这样客户端会收到一个invalidation信息。123456789101112131415 /* If the client has keys tracking enabled for client side caching, * make sure to remember the keys it fetched via this command. */ if (c-&gt;cmd-&gt;flags &amp; CMD_READONLY) &#123; client *caller = (c-&gt;flags &amp; CLIENT_LUA &amp;&amp; server.lua_caller) ? server.lua_caller : c; if (caller-&gt;flags &amp; CLIENT_TRACKING &amp;&amp; !(caller-&gt;flags &amp; CLIENT_TRACKING_BCAST)) &#123; trackingRememberKeys(caller); &#125; &#125; server.fixed_time_expire--; server.stat_numcommands++;&#125; 删除逻辑实现为了理解下面论述中涉及到的expire相关实现，我们需要先介绍一些UNLINK和DEL的实现。这个Command的实现是比较Legacy的，从c-&gt;argv中读取所有需要被删除的key。 12345678910/* This command implements DEL and LAZYDEL. */void delGenericCommand(client *c, int lazy) &#123; int numdel = 0, j; for (j = 1; j &lt; c-&gt;argc; j++) &#123; expireIfNeeded(c-&gt;db,c-&gt;argv[j]); int deleted = lazy ? dbAsyncDelete(c-&gt;db,c-&gt;argv[j]) : dbSyncDelete(c-&gt;db,c-&gt;argv[j]); if (deleted) &#123;... 容易发现，删除有两种模式：异步(lazy)删除和同步删除。异步删除的情况包括： delete逻辑 delGenericCommand中传入lazy 如果是unlink命令，那么一定是异步删除。 如果是del命令，则取决于server.lazyfree_lazy_user_del。 dbDelete中设置了server.lazyfree_lazy_server_del expire逻辑 expireIfNeeded中设置了server.lazyfree_lazy_expire 对应了Redis的lazy过期策略。 activeExpireCycleTryExpire中设置了server.lazyfree_lazy_expire 对应着Redis的定期循环，主动过期策略。 expireGenericCommand中设置了server.lazyfree_lazy_expire 在expire命令会主动检查一下有没有过期。 evict逻辑 freeMemoryIfNeeded中设置了server.lazyfree_lazy_eviction 其他 RM_UnlinkKey 同步删除的情况类似，除了“其他”中发生了变化： 其他 rdbLoadRio 下面的代码会进行事件通知，我们将专门进行介绍1234567891011// 【续】delGenericCommand函数... signalModifiedKey(c,c-&gt;db,c-&gt;argv[j]); notifyKeyspaceEvent(NOTIFY_GENERIC, "del",c-&gt;argv[j],c-&gt;db-&gt;id); server.dirty++; numdel++; &#125; &#125; addReplyLongLong(c,numdel);&#125; del和unlink的区别是，unlink一定是lazy删除的，但是del取决于配置。1234567void delCommand(client *c) &#123; delGenericCommand(c,server.lazyfree_lazy_user_del);&#125;void unlinkCommand(client *c) &#123; delGenericCommand(c,1);&#125; 同步删除我们首先来看简单的同步实现。首先，如果db-&gt;expires非空，从db-&gt;expires里面删除key，实际上是删除的过期时间。这里有个注释，说从db-&gt;expires中删除一个entry不会释放key-&gt;ptr这个sds，因为它和db-&gt;dict是共享的。这个有点奇怪，不清楚是什么回事。dictDelete最终调用dictGenericDelete。12345/* Delete a key, value, and associated expiration entry if any, from the DB */int dbSyncDelete(redisDb *db, robj *key) &#123; /* Deleting an entry from the expires dict will not free the sds of * the key, because it is shared with the main dictionary. */ if (dictSize(db-&gt;expires) &gt; 0) dictDelete(db-&gt;expires,key-&gt;ptr); 不过查看dictDelete实际上是dictGenericDelete的实现（在“dict的其他相关方法”这个章节中介绍），发现新版本的代码肯定会调用dictFreeKey（Redis3.0里面有个dictFreeEntryKey，不要混淆了）。从下面的实现中可以看到，这个函数调用keyDestructor，实际上是dictSdsDestructor，它一定会导致对应sds的析构，看上去和上面的注释是矛盾的。1234// dict.h#define dictFreeKey(d, entry) \ if ((d)-&gt;type-&gt;keyDestructor) \ (d)-&gt;type-&gt;keyDestructor((d)-&gt;privdata, (entry)-&gt;key) 究竟是怎么回事呢，我们看expires是如何被创建的1234567891011121314151617181920212223// server.cserver.db[j].dict = dictCreate(&amp;dbDictType,NULL);server.db[j].expires = dictCreate(&amp;keyptrDictType,NULL);/* Db-&gt;expires */dictType keyptrDictType = &#123; dictSdsHash, /* hash function */ NULL, /* key dup */ NULL, /* val dup */ dictSdsKeyCompare, /* key compare */ NULL, /* key destructor */ NULL /* val destructor */&#125;;/* Db-&gt;dict, keys are sds strings, vals are Redis objects. */dictType dbDictType = &#123; dictSdsHash, /* hash function */ NULL, /* key dup */ NULL, /* val dup */ dictSdsKeyCompare, /* key compare */ dictSdsDestructor, /* key destructor */ dictObjectDestructor /* val destructor */&#125;; 可以说一下#define DICT_NOTUSED(V) ((void) V)这个用法，实际上作用是为了保证编译器不会出现这个XXX没有被使用的warning。1234567// server.cvoid dictSdsDestructor(void *privdata, void *val)&#123; DICT_NOTUSED(privdata); sdsfree(val);&#125; 下面接着看dbSyncDelete的逻辑，刚才是删除的db-&gt;expires，还需要删除db-&gt;dict。此外server.cluster_enabled的情况进行了额外的处理。123456789 // 再从db-&gt;dict里面删除key if (dictDelete(db-&gt;dict,key-&gt;ptr) == DICT_OK) &#123; // Redis Cluster相关函数 if (server.cluster_enabled) slotToKeyDel(key-&gt;ptr); return 1; &#125; else &#123; return 0; &#125;&#125; 异步删除异步删除的核心是调用dictUnlink而不是dictDelete。前面的是大差不差的，删除db-&gt;expires里面的字段，因为他们的dictType不一样，他们的析构行为(keyDestructor)也不一样。这就导致expire可以直接dictDelete。1234567891011// lazyfree.c/* Delete a key, value, and associated expiration entry if any, from the DB. * If there are enough allocations to free the value object may be put into * a lazy free list instead of being freed synchronously. The lazy free list * will be reclaimed in a different bio.c thread. */#define LAZYFREE_THRESHOLD 64int dbAsyncDelete(redisDb *db, robj *key) &#123; /* Deleting an entry from the expires dict will not free the sds of * the key, because it is shared with the main dictionary. */ if (dictSize(db-&gt;expires) &gt; 0) dictDelete(db-&gt;expires,key-&gt;ptr); 下面调用dictUnlink而不是dictDelete了12345// 续dbAsyncDelete /* If the value is composed of a few allocations, to free in a lazy way * is actually just slower... So under a certain limit we just free * the object synchronously. */ dictEntry *de = dictUnlink(db-&gt;dict,key-&gt;ptr); 查看dictUnlink的源码，发现是设置了nofree=1调用了dictGenericDelete。在这个参数的作用下，不会去析构key和value。关于这个函数的具体实现，在dict相关章节进行介绍了。123dictEntry *dictUnlink(dict *ht, const void *key) &#123; return dictGenericDelete(ht,key,1);&#125; 下面，我们要手动来进行析构。会首先使用lazyfreeGetFreeEffort来计算析构的代价，如果代价过高，就将这个对象放到lazy free list里面让它后台去析构。1234// 续dbAsyncDelete if (de) &#123; robj *val = dictGetVal(de); size_t free_effort = lazyfreeGetFreeEffort(val); 下面的这段代码，有点奇怪。根据注释，如果这个对象是被共享的，那么在这里reclaim它（我理解是重新获得所有权）是不太现实的。这个倒不经常发生，但有些时候Redis的一些实现代码会调动incrRefCount来保护对象，然后调用dbDelete（我理解这种情况下val-&gt;refcount就是一个大于1的值）。在这种“保护对象”情况下我们会直接到达下面dictFreeUnlinkedEntry的调用，它的作用相当于调用decrRefCount。 dictFreeUnlinkedEntry这一块就是给之前nofree没做的事情擦一下屁股，包含调用dictFreeKey啥的来释放key和value所占用的内存。slotToKeyDel这个是Redis Cluster的实现逻辑，用来算出来这个key在哪个slot上。12345678910111213141516171819202122232425// 续dbAsyncDelete if (free_effort &gt; LAZYFREE_THRESHOLD &amp;&amp; val-&gt;refcount == 1) &#123; atomicIncr(lazyfree_objects,1); bioCreateBackgroundJob(BIO_LAZY_FREE,val,NULL,NULL); dictSetVal(db-&gt;dict,de,NULL); &#125; &#125; /* Release the key-val pair, or just the key if we set the val * field to NULL in order to lazy free it later. */ if (de) &#123; dictFreeUnlinkedEntry(db-&gt;dict,de); if (server.cluster_enabled) slotToKeyDel(key-&gt;ptr); return 1; &#125; else &#123; return 0; &#125;&#125;// dict.cvoid dictFreeUnlinkedEntry(dict *d, dictEntry *he) &#123; if (he == NULL) return; dictFreeKey(d, he); dictFreeVal(d, he); zfree(he);&#125; 这里面涉及的几个函数来讲解一下： lazyfreeGetFreeEffort这个函数返回我们释放一个对象的代价。返回值不一定是这个对象对应的内存分配次数，但是和这个量成比例的。具体来说： 对于字符串，函数永远返回1 对于用诸如哈希表等数据结构表示的聚合对象，返回组成该对象元素的数量。 对于只需要一次内存分配就产生的对象，认为是独立的一个对象，即使实际上是由多个造成的。 对于列表对象，返回quicklist里面的元素数量。 1234567size_t lazyfreeGetFreeEffort(robj *obj) &#123; if (obj-&gt;type == OBJ_LIST) &#123; quicklist *ql = obj-&gt;ptr; return ql-&gt;len; &#125; else if (obj-&gt;type == OBJ_SET &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_HT) &#123; dict *ht = obj-&gt;ptr; return dictSize(ht); 对于ZSET，如果是跳表实现，就返回跳表的长度。如果是ziplist实现就返回1？12345678910111213141516171819202122232425262728293031323334 &#125; else if (obj-&gt;type == OBJ_ZSET &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_SKIPLIST)&#123; zset *zs = obj-&gt;ptr; return zs-&gt;zsl-&gt;length; &#125; else if (obj-&gt;type == OBJ_HASH &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_HT) &#123; dict *ht = obj-&gt;ptr; return dictSize(ht); &#125; else if (obj-&gt;type == OBJ_STREAM) &#123; size_t effort = 0; stream *s = obj-&gt;ptr; /* Make a best effort estimate to maintain constant runtime. Every macro * node in the Stream is one allocation. */ effort += s-&gt;rax-&gt;numnodes; /* Every consumer group is an allocation and so are the entries in its * PEL. We use size of the first group's PEL as an estimate for all * others. */ if (s-&gt;cgroups) &#123; raxIterator ri; streamCG *cg; raxStart(&amp;ri,s-&gt;cgroups); raxSeek(&amp;ri,"^",NULL,0); /* There must be at least one group so the following should always * work. */ serverAssert(raxNext(&amp;ri)); cg = ri.data; effort += raxSize(s-&gt;cgroups)*(1+raxSize(cg-&gt;pel)); raxStop(&amp;ri); &#125; return effort; &#125; else &#123; return 1; /* Everything else is a single allocation. */ &#125;&#125; atomicIncr是一个原子操作，更新lazyfree里面的一个static变量lazyfree_objects。根据不同的操作系统的支持，有三种实现：如果支持atomic语义1#define atomicIncr(var,count) __atomic_add_fetch(&amp;var,(count),__ATOMIC_RELAXED) 如果有sync语义，一般是gcc的一个内置宏1#define atomicIncr(var,count) __sync_add_and_fetch(&amp;var,(count)) 如果什么都没有，用mutex12345#define atomicIncr(var,count) do &#123; \ pthread_mutex_lock(&amp;var ## _mutex); \ var += (count); \ pthread_mutex_unlock(&amp;var ## _mutex); \&#125; while(0) bioCreateBackgroundJob所有的bio开头的函数表示Redis的Background IO服务。根据注释，将来也许会迁移到libeio。12345678910111213void bioCreateBackgroundJob(int type, void *arg1, void *arg2, void *arg3) &#123; struct bio_job *job = zmalloc(sizeof(*job)); job-&gt;time = time(NULL); job-&gt;arg1 = arg1; job-&gt;arg2 = arg2; job-&gt;arg3 = arg3; pthread_mutex_lock(&amp;bio_mutex[type]); listAddNodeTail(bio_jobs[type],job); bio_pending[type]++; pthread_cond_signal(&amp;bio_newjob_cond[type]); pthread_mutex_unlock(&amp;bio_mutex[type]);&#125; dictSetVal查找和expirelookUpKey相关方法根据查找目的是读或者写区分了lookupKeyRead、lookupKeyWrite两个方向的函数，此外还根据是否WithFlags或者OrReply派生出其他几种函数。其中WithFlags目前只包含了LOOKUP_NONE和LOOKUP_NOTOUCH两个选项。 对于lookupKeyWrite来讲，有一个副作用，就是会先检查一下要不要expire，如果需要就直接expire掉。对于lookupKeyRead来讲，也要处理expire的问题，但是因为涉及到主从复制的问题，所以要进行额外处理。【Q】为什么不需要对写处理呢？我想应该是因为只有Master处理写，处理完再发指令给Slave。 我们直接介绍带Flags的版本。1234567robj *lookupKeyRead(redisDb *db, robj *key) &#123; return lookupKeyReadWithFlags(db,key,LOOKUP_NONE);&#125;robj *lookupKeyWrite(redisDb *db, robj *key) &#123; return lookupKeyWriteWithFlags(db, key, LOOKUP_NONE);&#125; 注意，Flags包含： LOOKUP_NONE LOOKUP_NOTOUCH 表示这次访问不要更新LRU啥的，例如type这样的命令就带上这个参数。 lookupKeyWriteWithFlags首先查看lookupKeyWriteWithFlags的实现，直接先检查下expire，然后调用lookupKey。这里的expireIfNeeded也是Redis的lazy过期策略的实现，在每次查找的时候都会调用，检查这个键是不是已经过期了。12345678910// db.c/* Lookup a key for write operations, and as a side effect, if needed, expires * the key if its TTL is reached. * * Returns the linked value object if the key exists or NULL if the key * does not exist in the specified DB. */robj *lookupKeyWriteWithFlags(redisDb *db, robj *key, int flags) &#123; expireIfNeeded(db,key); return lookupKey(db,key,flags);&#125; lookupKeyReadWithFlags下面查看lookupKeyReadWithFlags的实现，相比于写要复杂点，因为要处理键过期的时候读的问题。1234robj *lookupKeyReadWithFlags(redisDb *db, robj *key, int flags) &#123; robj *val; if (expireIfNeeded(db,key) == 1) &#123; 首先，考虑Master的情况，如果key过期了，那么就直接返回NULL，并且触发一个keymiss事件。这里注释上说在Master情况下，expireIfNeeded返回0当且只当这个key不存在，因此如果这个Server是Master的话（Master的masterhost肯定是NULL，这是一个经典判定），就可以安全地返回NULL。这个看起来有点费解，实际上可以结合expireIfNeeded的实现来看。提前说一下，对Slave而言，expireIfNeeded并不会真的让key过期并删除，而只是返回key在逻辑上是过期的，而真正的过期是由Master来同步的，这样能保持Slave和Master的一致。1234/* Key expired. If we are in the context of a master, expireIfNeeded() * returns 0 only when the key does not exist at all, so it's safe * to return NULL ASAP. */if (server.masterhost == NULL) &#123; 更新统计信息，server.stat_keyspace_misses可以通过INFO keyspace_misses命令来查看。1234 server.stat_keyspace_misses++; notifyKeyspaceEvent(NOTIFY_KEY_MISS, "keymiss", key, db-&gt;id); return NULL;&#125; 上面是对Master情况的处理，下面是对Slave的情况。我们已经知道，Slave并不会真的删除过期key，而是等待Master的Del指令。根据注释，对Slave而言，作为一个额外的安全措施，相关指令是只读的，我们可以在这里安全地返回NULL。我们通过只读的方式，向client提供一个更加一致性的行为（这里accessign还是个错别字），表达这个key不存在。Notably this covers GETs when slaves are used to scale reads。【Q】什么时候是CMD_READONLY的指令呢？12345678910111213141516171819 if (server.current_client &amp;&amp; server.current_client != server.master &amp;&amp; server.current_client-&gt;cmd &amp;&amp; server.current_client-&gt;cmd-&gt;flags &amp; CMD_READONLY) &#123; server.stat_keyspace_misses++; notifyKeyspaceEvent(NOTIFY_KEY_MISS, "keymiss", key, db-&gt;id); return NULL; &#125; &#125; val = lookupKey(db,key,flags); if (val == NULL) &#123; server.stat_keyspace_misses++; notifyKeyspaceEvent(NOTIFY_KEY_MISS, "keymiss", key, db-&gt;id); &#125; else server.stat_keyspace_hits++; return val;&#125; lookUpKeylookUpKey的主要内容包括从db里面找到对应的key，并且维护LRU或LFU。12345678910111213// db.c/* Low level key lookup API, not actually called directly from commands * implementations that should instead rely on lookupKeyRead(), * lookupKeyWrite() and lookupKeyReadWithFlags(). */robj *lookupKey(redisDb *db, robj *key, int flags) &#123; // 从db中获得key对应的entry dictEntry *de = dictFind(db-&gt;dict,key-&gt;ptr); if (de) &#123; // 如果找到了，就取出val robj *val = dictGetVal(de); // // 如果没有设置 在没有设置LOOKUP_NOTOUCH的情况，如果有子进程正在进行保存，就不进行LFU操作，以免破坏COW。123456789101112 if (!hasActiveChildProcess() &amp;&amp; !(flags &amp; LOOKUP_NOTOUCH))&#123; if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) &#123; updateLFU(val); &#125; else &#123; val-&gt;lru = LRU_CLOCK(); &#125; &#125; return val; &#125; else &#123; return NULL; &#125;&#125; 被动expire实现expireIfNeeded用来删除过期的键。返回0表示键有效（键未过期，或永不过期），否则返回1表示已经过期并被删除。对于Master，如果找到的键是expire的，会被从数据库中evict掉。并且会导致想AOF和Slave流propagate一条DEL或者UNLINK指令。1234567// db.c/* This function is called when we are going to perform some operation * in a given key, but such key may be already logically expired even if * it still exists in the database. The main way this function is called * is via lookupKey*() family of functions. */int expireIfNeeded(redisDb *db, robj *key) &#123; 如果没有过期，就返回0123... if (!keyIsExpired(db,key)) return 0;... 首先，通过keyIsExpired检测是不是已经过期了，如果还没有过期，上面就直接返回0了，再往下就是处理过期的情况。根据注释，如果Redis运行在主从模式下，并且是在Slave上，expireIfNeeded直接返回，而不是继续删除键。这是因为Slave上的key过期是由Master控制的，Slave并不直接处理key的过期。Master会发送一个同步的DEL命令给Slave来删除某个键，Slave等到那时候再删除，这样做的目的是出于一致性的考量。但尽管如此，对Slave调用expireIfNeeded也应该返回一个正确的值，也就是这个时候键应不应该过期。因此，Slave上是先过期，然后再删除键的，这其中存在一个窗口时间，因为Slave还没有来得及收到并处理Master的DEL。下面肯定对应了已经过期的情况了。123... if (server.masterhost != NULL) return 1;... 下面负责通知删除事件，这里还出现了propagateExpire函数，我们也统一在后面讲解123456... server.stat_expiredkeys++; // 向AOF文件和Slave节点传播过期信息，实际会调用propagate函数 propagateExpire(db,key,server.lazyfree_lazy_expire); // 发送事件通知 notifyKeyspaceEvent(NOTIFY_EXPIRED,"expired",key,db-&gt;id); 下面是真正的过期删除的过程。这里根据server.lazyfree_lazy_expire的配置，可以选择异步删除或者同步删除，这类似于上面讨论过的UNLINK和DEL的实现。事实上在expireGenericCommand上就可以看到对应的映射关系。12345... int retval = server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) : dbSyncDelete(db,key); if (retval) signalModifiedKey(NULL,db,key); return retval;&#125; keyIsExpiredkeyIsExpired的作用是判断某个键有没有过期。主要功能就是比较现在的时间，和获得的key的过期时间。123456789/* Check if the key is expired. */int keyIsExpired(redisDb *db, robj *key) &#123; mstime_t when = getExpire(db,key); mstime_t now; if (when &lt; 0) return 0; /* No expire for this key */ /* Don't expire anything while loading. It will be done later. */ if (server.loading) return 0; 如果在执行lua脚本，将时间设置成脚本执行开始的时间。这样在脚本执行过程中就不会expire。这么做的原因是源自Github上面的Issue1525。作者发现这个脚本在Master和Slave上的执行是不一样的。原因是在Master上第一次执行可能key存在，第二次就不存在了，此时在Master上面会加一次。但是因为此时Master会合成一个DEL指令，让Slave也删除并过期这个Key。此时，如果相同的脚本运行在Slave上面，就会得到不一样的结果。123456789if redis.call("exists",KEYS[1]) == 1then redis.call("incr","mycounter")endif redis.call("exists",KEYS[1]) == 1then return redis.call("incr","mycounter")end 因此作出这样的修改保障了向Slave和AOF的propagate是一致的。12345678910111213141516171819202122 if (server.lua_caller) &#123; now = server.lua_time_start; &#125; /* If we are in the middle of a command execution, we still want to use * a reference time that does not change: in that case we just use the * cached time, that we update before each call in the call() function. * This way we avoid that commands such as RPOPLPUSH or similar, that * may re-open the same key multiple times, can invalidate an already * open object in a next call, if the next call will see the key expired, * while the first did not. */ else if (server.fixed_time_expire &gt; 0) &#123; now = server.mstime; &#125; /* For the other cases, we want to use the most fresh time we have. */ else &#123; now = mstime(); &#125; /* The key expired if the current (virtual or real) time is greater * than the expire time of the key. */ return now &gt; when;&#125; propagateExpire在前面的代码中，还看到propagateExpire的使用，这里也解释下。我们知道，在主从结构下，键实际的expire操作是在Master完成的。在expire之后，Master会发送DEL指令给Slave和AOF，这个函数就是完成这个的。在注释中还指出，因为AOF，以及Master到Slave的连接都是保证有序的，所以即使有操作去写已经失效的key，都能保证结果是一致的。12345678910111213void propagateExpire(redisDb *db, robj *key, int lazy) &#123; robj *argv[2]; argv[0] = lazy ? shared.unlink : shared.del; argv[1] = key; incrRefCount(argv[0]); incrRefCount(argv[1]); propagate(server.delCommand,db-&gt;id,argv,2,PROPAGATE_AOF|PROPAGATE_REPL); decrRefCount(argv[0]); decrRefCount(argv[1]);&#125; 主动expire实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206void activeExpireCycle(int type) &#123; /* Adjust the running parameters according to the configured expire * effort. The default effort is 1, and the maximum configurable effort * is 10. */ unsigned long effort = server.active_expire_effort-1, /* Rescale from 0 to 9. */ config_keys_per_loop = ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP + ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP/4*effort, config_cycle_fast_duration = ACTIVE_EXPIRE_CYCLE_FAST_DURATION + ACTIVE_EXPIRE_CYCLE_FAST_DURATION/4*effort, config_cycle_slow_time_perc = ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC + 2*effort, config_cycle_acceptable_stale = ACTIVE_EXPIRE_CYCLE_ACCEPTABLE_STALE- effort; /* This function has some global state in order to continue the work * incrementally across calls. */ static unsigned int current_db = 0; /* Last DB tested. */ static int timelimit_exit = 0; /* Time limit hit in previous call? */ static long long last_fast_cycle = 0; /* When last fast cycle ran. */ int j, iteration = 0; int dbs_per_call = CRON_DBS_PER_CALL; long long start = ustime(), timelimit, elapsed; /* When clients are paused the dataset should be static not just from the * POV of clients not being able to write, but also from the POV of * expires and evictions of keys not being performed. */ if (clientsArePaused()) return; if (type == ACTIVE_EXPIRE_CYCLE_FAST) &#123; /* Don't start a fast cycle if the previous cycle did not exit * for time limit, unless the percentage of estimated stale keys is * too high. Also never repeat a fast cycle for the same period * as the fast cycle total duration itself. */ if (!timelimit_exit &amp;&amp; server.stat_expired_stale_perc &lt; config_cycle_acceptable_stale) return; if (start &lt; last_fast_cycle + (long long)config_cycle_fast_duration*2) return; last_fast_cycle = start; &#125; /* We usually should test CRON_DBS_PER_CALL per iteration, with * two exceptions: * * 1) Don't test more DBs than we have. * 2) If last time we hit the time limit, we want to scan all DBs * in this iteration, as there is work to do in some DB and we don't want * expired keys to use memory for too much time. */ if (dbs_per_call &gt; server.dbnum || timelimit_exit) dbs_per_call = server.dbnum; /* We can use at max 'config_cycle_slow_time_perc' percentage of CPU * time per iteration. Since this function gets called with a frequency of * server.hz times per second, the following is the max amount of * microseconds we can spend in this function. */ timelimit = config_cycle_slow_time_perc*1000000/server.hz/100; timelimit_exit = 0; if (timelimit &lt;= 0) timelimit = 1; if (type == ACTIVE_EXPIRE_CYCLE_FAST) timelimit = config_cycle_fast_duration; /* in microseconds. */ /* Accumulate some global stats as we expire keys, to have some idea * about the number of keys that are already logically expired, but still * existing inside the database. */ long total_sampled = 0; long total_expired = 0; for (j = 0; j &lt; dbs_per_call &amp;&amp; timelimit_exit == 0; j++) &#123; /* Expired and checked in a single loop. */ unsigned long expired, sampled; redisDb *db = server.db+(current_db % server.dbnum); /* Increment the DB now so we are sure if we run out of time * in the current DB we'll restart from the next. This allows to * distribute the time evenly across DBs. */ current_db++; /* Continue to expire if at the end of the cycle there are still * a big percentage of keys to expire, compared to the number of keys * we scanned. The percentage, stored in config_cycle_acceptable_stale * is not fixed, but depends on the Redis configured "expire effort". */ do &#123; unsigned long num, slots; long long now, ttl_sum; int ttl_samples; iteration++; /* If there is nothing to expire try next DB ASAP. */ if ((num = dictSize(db-&gt;expires)) == 0) &#123; db-&gt;avg_ttl = 0; break; &#125; slots = dictSlots(db-&gt;expires); now = mstime(); /* When there are less than 1% filled slots, sampling the key * space is expensive, so stop here waiting for better times... * The dictionary will be resized asap. */ if (num &amp;&amp; slots &gt; DICT_HT_INITIAL_SIZE &amp;&amp; (num*100/slots &lt; 1)) break; /* The main collection cycle. Sample random keys among keys * with an expire set, checking for expired ones. */ expired = 0; sampled = 0; ttl_sum = 0; ttl_samples = 0; if (num &gt; config_keys_per_loop) num = config_keys_per_loop; /* Here we access the low level representation of the hash table * for speed concerns: this makes this code coupled with dict.c, * but it hardly changed in ten years. * * Note that certain places of the hash table may be empty, * so we want also a stop condition about the number of * buckets that we scanned. However scanning for free buckets * is very fast: we are in the cache line scanning a sequential * array of NULL pointers, so we can scan a lot more buckets * than keys in the same time. */ long max_buckets = num*20; long checked_buckets = 0; while (sampled &lt; num &amp;&amp; checked_buckets &lt; max_buckets) &#123; for (int table = 0; table &lt; 2; table++) &#123; if (table == 1 &amp;&amp; !dictIsRehashing(db-&gt;expires)) break; unsigned long idx = db-&gt;expires_cursor; idx &amp;= db-&gt;expires-&gt;ht[table].sizemask; dictEntry *de = db-&gt;expires-&gt;ht[table].table[idx]; long long ttl; /* Scan the current bucket of the current table. */ checked_buckets++; while(de) &#123; /* Get the next entry now since this entry may get * deleted. */ dictEntry *e = de; de = de-&gt;next; ttl = dictGetSignedIntegerVal(e)-now; if (activeExpireCycleTryExpire(db,e,now)) expired++; if (ttl &gt; 0) &#123; /* We want the average TTL of keys yet * not expired. */ ttl_sum += ttl; ttl_samples++; &#125; sampled++; &#125; &#125; db-&gt;expires_cursor++; &#125; total_expired += expired; total_sampled += sampled; /* Update the average TTL stats for this database. */ if (ttl_samples) &#123; long long avg_ttl = ttl_sum/ttl_samples; /* Do a simple running average with a few samples. * We just use the current estimate with a weight of 2% * and the previous estimate with a weight of 98%. */ if (db-&gt;avg_ttl == 0) db-&gt;avg_ttl = avg_ttl; db-&gt;avg_ttl = (db-&gt;avg_ttl/50)*49 + (avg_ttl/50); &#125; /* We can't block forever here even if there are many keys to * expire. So after a given amount of milliseconds return to the * caller waiting for the other active expire cycle. */ if ((iteration &amp; 0xf) == 0) &#123; /* check once every 16 iterations. */ elapsed = ustime()-start; if (elapsed &gt; timelimit) &#123; timelimit_exit = 1; server.stat_expired_time_cap_reached_count++; break; &#125; &#125; /* We don't repeat the cycle for the current database if there are * an acceptable amount of stale keys (logically expired but yet * not reclaimed). */ &#125; while (sampled == 0 || (expired*100/sampled) &gt; config_cycle_acceptable_stale); &#125; elapsed = ustime()-start; server.stat_expire_cycle_time_used += elapsed; latencyAddSampleIfNeeded("expire-cycle",elapsed/1000); /* Update our estimate of keys existing but yet to be expired. * Running average with this sample accounting for 5%. */ double current_perc; if (total_sampled) &#123; current_perc = (double)total_expired/total_sampled; &#125; else current_perc = 0; server.stat_expired_stale_perc = (current_perc*0.05)+ (server.stat_expired_stale_perc*0.95);&#125; propagate机制在expire中，提到了propagate函数，因此这里也顺便介绍一些propagate机制。propagate机制是Redis主从复制逻辑的一部分，通常来说，Redis主从复制包含两个机制： sync/psync机制 用来处理sync和psync指令，也就是刚开始同步的情况，将从服务器的数据库状态更新至主服务器当前所处的数据库状态。 propagate机制 将指令从Master同步到Slave或者AOF文件。 propagate机制将特定的指令传播给AOF或者Slave，这些指令有下面几种： PROPAGATE_NONE 压根就不传播。 PROPAGATE_AOF 如果开启了AOF，就传播给AOF。此时就会调用AOF的主入口函数feedAppendOnlyFile。关于RDB和AOF机制，我们在专门的文章介绍。 PROPAGATE_REPL 传播给Slave。同样调用replicationFeedSlaves函数。 根据注释，不能够在各个command的实现代码中使用这个函数，因为它不会wrap the resulting commands in MULTI/EXEC，如果需要，应该用alsoPropagate、preventCommandPropagation、forceCommandPropagation等。However for functions that need to (also) propagate out of the context of a command execution, for example when serving a blocked client, you want to use propagate().12345678void propagate(struct redisCommand *cmd, int dbid, robj **argv, int argc, int flags)&#123; if (server.aof_state != AOF_OFF &amp;&amp; flags &amp; PROPAGATE_AOF) feedAppendOnlyFile(cmd,dbid,argv,argc); if (flags &amp; PROPAGATE_REPL) replicationFeedSlaves(server.slaves,dbid,argv,argc);&#125; evict实现介绍Redis对当前执行环节的判断 server.masterhost == NULL 常常被用来判断是不是Master服务器 server.current_client != server.master 根据注释，这是指的服务器的当前客户端，仅用于崩溃报告。 sentinelRedisInstance-&gt;flags &amp; (SRI_MASTER|SRI_SLAVE) sentinelRedisInstance-&gt;slave_master_host 大家都知道，Redis里面有下面几种evict policy： noeviction 这是默认情况。 内存爆了，就直接报错。 allkeys-lru 对所有的键做LRU。 allkeys-lfu 对所有的键做LFU。 allkeys-random 对所有的key做随机删除。 volatile-lru/volatile-lfu/volatile-random 这是对有expire的键做对应的操作。 volatile-ttl 删除剩余生命最短的键。 而对应的实现，就在freeMemoryIfNeeded中。根据注释，这个函数被定时调用，当发现超出最大使用内存后，就会释放相关内存。如果释放内存成功，或者我们不需要释放内存，那么返回C_OK；如果我们没有能够释放足够的内存，那么返回C_ERR。总之一堆废话。。。其实我们想了解的是这几个问题： 如何计算现在已经使用了多少内存？ 如何实现LFU和LRU？ 释放内存会对其他模块产生什么影响？ LRU和LFU的一般实现这两个是老生常谈了。对于LRU，一个队列就行了，我们把最近用到的元素放到队列尾部，需要evict的时候就弹出头部，一般用双向队列就行。但这样查找一个Key就变成O(n)的了，但这也不难，我们只需要用一个map记录一下对应元素在队列中的位置就行。 对于LFU，我们需要记录对应的访问次数，在淘汰时，选择最少访问次数的键值对。此时，队列的性质就不够用了，当然我们可以选择用优先队列，把访问次数作为key，大不了手动实现一个二叉堆嘛。当然，我们还可以用一个双层链表，第一层是从0开始的访问次数，第二层是具有这个访问次数的所有键值对的开链表。 Redis的LRU和LFU实现本章介绍了Redis对LRU和LFU数据结构的维护，这是必要的前置知识。真正的淘汰机制，在对freeMemoryIfNeeded函数的讨论中。 Redis并没有采用hash+双向链表的办法来维护一个LRU，显然内存开销很大，这是值得的么？文章中提到，当maxmemory-samples数为10的时候，近似LRU算法的性能已经很好了。此外，Redis实际上是记录了最后一次访问某个key的时间戳的（倒不是因为复用LFU的空间了，毕竟LRU是先有的）。到了我们这个版本的代码，近似LRU又被优化了，出现了一个evictionPoolEntry。这个pool的容量是16，里面的key是按照lru有序排列的。 取而代之，Redis对每个robj对象去维护了一个lru:LRU_BITS字段。在3.0版本，这个字段被用来存储当前秒级别的时间戳，在往后的版本中支持了LFU模式，在这种方式下会调用updateLFU进行处理，这个函数会在高16位存一个分钟级别的时间戳，在低8位存访问计数。 LRU_CLOCK这里会选择是直接用server.lruclock（也是在serverCron里面调用getLRUClock设置的），或者直接自己调用一次getLRUClock。这个比较是怎么来的呢？有必要介绍一下，毕竟诸如run_with_period里面也有这样的比较。首先，在文章中已经介绍过，server.hz指的是表示一秒钟被触发多少次。那么1000/server.hz就表示触发1000次要多少秒。LRU_CLOCK_RESOLUTION的默认值是1000，所以server.hz只要是1，就可以直接复用server.lruclock，少一次开销。12345678910111213// server.h#define LRU_BITS 24// evict.cunsigned int LRU_CLOCK(void) &#123; unsigned int lruclock; if (1000/server.hz &lt;= LRU_CLOCK_RESOLUTION) &#123; lruclock = server.lruclock; &#125; else &#123; lruclock = getLRUClock(); &#125; return lruclock;&#125; 在访问一个对象的时候，用updateLFU更新lru字段。更新需要注意两点，lru的值要根据时间衰减，但也要根据访问次数增长。首先，通过LFUDecrAndReturn计算出新的counter，这通常是减少counter。然后通过LFULogIncr增加counter。最后，将新的counter和最新的ldt组装起来。12345678910// db.c/* * Firstly, decrement the counter if the decrement time is reached. * Then logarithmically increment the counter, and update the access time. */void updateLFU(robj *val) &#123; unsigned long counter = LFUDecrAndReturn(val); counter = LFULogIncr(counter); // 组装lru字段 val-&gt;lru = (LFUGetTimeInMinutes()&lt;&lt;8) | counter;&#125; 减少counter LFUTimeElapsed获得从ldt开始经过了多少分钟。 1234567// 获得从ldt开始经过了多少分钟unsigned long LFUTimeElapsed(unsigned long ldt) &#123; unsigned long now = LFUGetTimeInMinutes(); if (now &gt;= ldt) return now-ldt; // 如果now小了，就当成已经wrap了刚好一次，这个和estimateObjectIdleTime的实现是类似的 return 65535-ldt+now;&#125; LFUDecrAndReturn会取出旧的counter减去num_periods并返回，具体num_periods的值是由server.lfu_decay_time来定的。也就是计算一下从上次ldt开始现在过去了几个lfu_decay_time，那么counter就减少多少。默认情况下，server.lfu_decay_time是1分钟，这时候对counter的减少就是经过的分钟数。 12345678910111213// evict.cunsigned long LFUDecrAndReturn(robj *o) &#123; unsigned long ldt = o-&gt;lru &gt;&gt; 8; // 取出老的分钟时间戳 unsigned long counter = o-&gt;lru &amp; 255; // 取出老的计数 unsigned long num_periods = server.lfu_decay_time ? LFUTimeElapsed(ldt) / server.lfu_decay_time : 0; if (num_periods) counter = (num_periods &gt; counter) ? 0 : counter - num_periods; return counter;&#125;// config.ccreateIntConfig("lfu-decay-time", NULL, MODIFIABLE_CONFIG, 0, INT_MAX, server.lfu_decay_time, 1, INTEGER_CONFIG, NULL, NULL) 增加counter 上面介绍了对counter随时间的衰减，下面介绍counter随访问次数的增长。counter的增长并不是访问一次就+1，而是用一个[0,1]之间的数p来描绘。p的值是1.0/((counter-LFU_INIT_VAL)*server.lfu_log_factor+1)，然后他还要和一个随机数r比较，大于r的话才能导致counter自增。可以看到当前的counter和lfu_log_factor越大，counter的自增概率就越小。事实上counter的增长和访问次数是成对数关系的。 另一个值得注意的是LFU_INIT_VAL的值，取5，这是为了防止新生对象的counter值为0，从而被快速淘汰掉。 123456789101112131415// server.h#define LFU_INIT_VAL 5// evict.cuint8_t LFULogIncr(uint8_t counter) &#123; if (counter == 255) return 255; double r = (double)rand()/RAND_MAX; double baseval = counter - LFU_INIT_VAL; if (baseval &lt; 0) baseval = 0; double p = 1.0/(baseval*server.lfu_log_factor+1); if (r &lt; p) counter++; return counter;&#125;// config.ccreateIntConfig("lfu-log-factor", NULL, MODIFIABLE_CONFIG, 0, INT_MAX, server.lfu_log_factor, 10, INTEGER_CONFIG, NULL, NULL) freeMemoryIfNeededfreeMemoryIfNeeded函数是evict的主要逻辑。首先，如果是从服务器，并且配置了server.repl_slave_ignore_maxmemory就忽略。123456int freeMemoryIfNeeded(void) &#123; int keys_freed = 0; /* By default replicas should ignore maxmemory * and just be masters exact copies. */ if (server.masterhost &amp;&amp; server.repl_slave_ignore_maxmemory) return C_OK;... 下面就来计算占用了多少内存mem_reported，主要函数getMaxmemoryState我们放在后面单独讲解。mem_reported表示总共用了多少内存，mem_tofree表示应该释放多少内存（不算Slave和AOF的缓存）。clientsArePaused的检查，有点奇怪。根据注释，它的意思是，如果client都被pause了，那么数据就是静止的。不仅对于所有的client是这样，对于还没有做expire和evict的所有key也是这样。我觉得这应该是一个优化，防止在这种情况下再走下面的逻辑。12345678910111213... size_t mem_reported, mem_tofree, mem_freed; mstime_t latency, eviction_latency, lazyfree_latency; long long delta; int slaves = listLength(server.slaves); int result = C_ERR; if (clientsArePaused()) return C_OK; if (getMaxmemoryState(&amp;mem_reported,NULL,&amp;mem_tofree,NULL) == C_OK) return C_OK; mem_freed = 0;... latencyStartMonitor这个宏和stopwatch一样。123... latencyStartMonitor(latency);... 下面开始根据淘汰政策maxmemory_policy进行讨论，如果是noeviction，那就直接返回。1234... if (server.maxmemory_policy == MAXMEMORY_NO_EVICTION) goto cant_free; /* We need to free memory, but policy forbids. */... 整个内存释放过程是多次的，因此用一个循环来。12345678910... while (mem_freed &lt; mem_tofree) &#123; int j, k, i; static unsigned int next_db = 0; sds bestkey = NULL; int bestdbid; redisDb *db; dict *dict; dictEntry *de;... 处理要排序的情况第一个if，用来处理所有需要排序的情况。查看代码，要用while循环去找bestkey，原因是可能从pool里面找到的key不存在了，【Q】可是究竟什么情况下会发生这个情况呢？循环里面的过程就是我们去遍历整个数据库里面的所有db，如果它的dict或者expires不为空，则调用evictionPoolPopulate。这个函数会往pool里面加入一些key。1234567891011121314151617181920212223... if (server.maxmemory_policy &amp; (MAXMEMORY_FLAG_LRU|MAXMEMORY_FLAG_LFU) || server.maxmemory_policy == MAXMEMORY_VOLATILE_TTL) &#123; struct evictionPoolEntry *pool = EvictionPoolLRU; while(bestkey == NULL) &#123; unsigned long total_keys = 0, keys; /* We don't want to make local-db choices when expiring keys, * so to start populate the eviction pool sampling keys from * every DB. */ for (i = 0; i &lt; server.dbnum; i++) &#123; db = server.db+i; dict = (server.maxmemory_policy &amp; MAXMEMORY_FLAG_ALLKEYS) ? db-&gt;dict : db-&gt;expires; if ((keys = dictSize(dict)) != 0) &#123; evictionPoolPopulate(i, dict, db-&gt;dict, pool); total_keys += keys; &#125; &#125; if (!total_keys) break; /* No keys to evict. */... 下面，我们遍历整个pool，找到最合适的一个。解释几个问题： 为什么要从尾往头遍历？ 在对evictionPool的介绍中提到，它是有序的，最左边的idle time最小，最右边的最大，因此优先淘汰右边的。 为什么要有bestdbid？将key之间的比较转化为数据库之间的比较么？ server.db[pool[k].dbid]是什么鬼？ 实际上是要选择pool[k].dbid这个db。 123456789101112131415161718192021222324252627282930313233... /* Go backward from best to worst element to evict. */ for (k = EVPOOL_SIZE-1; k &gt;= 0; k--) &#123; if (pool[k].key == NULL) continue; bestdbid = pool[k].dbid; if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_ALLKEYS) &#123; de = dictFind(server.db[pool[k].dbid].dict, pool[k].key); &#125; else &#123; de = dictFind(server.db[pool[k].dbid].expires, pool[k].key); &#125; /* Remove the entry from the pool. */ if (pool[k].key != pool[k].cached) sdsfree(pool[k].key); pool[k].key = NULL; pool[k].idle = 0; /* If the key exists, is our pick. Otherwise it is * a ghost and we need to try the next element. */ if (de) &#123; bestkey = dictGetKey(de); break; &#125; else &#123; /* Ghost... Iterate again. */ // 这个很奇怪，什么时候会出现这种情况呢？ &#125; &#125; &#125; &#125;... 处理随机情况第二个if，用来处理随机的情况。这个很简单，直接调用dictGetRandomKey就行，和eviction pool也没啥关系了。12345678910111213141516171819202122... /* volatile-random and allkeys-random policy */ else if (server.maxmemory_policy == MAXMEMORY_ALLKEYS_RANDOM || server.maxmemory_policy == MAXMEMORY_VOLATILE_RANDOM) &#123; /* When evicting a random key, we try to evict a key for * each DB, so we use the static 'next_db' variable to * incrementally visit all DBs. */ for (i = 0; i &lt; server.dbnum; i++) &#123; j = (++next_db) % server.dbnum; db = server.db+j; dict = (server.maxmemory_policy == MAXMEMORY_ALLKEYS_RANDOM) ? db-&gt;dict : db-&gt;expires; if (dictSize(dict) != 0) &#123; de = dictGetRandomKey(dict); bestkey = dictGetKey(de); bestdbid = j; break; &#125; &#125; &#125;... 删除元素如果我们找到了要删除的元素bestkey，就执行删除元素过程。首先，调用老朋友propagateExpire，这个会发送一条删除指令给AOF/Slave。1234567... /* Finally remove the selected key. */ if (bestkey) &#123; db = server.db+bestdbid; robj *keyobj = createStringObject(bestkey,sdslen(bestkey)); propagateExpire(db,keyobj,server.lazyfree_lazy_eviction);... 接着，我们统计这次evict释放了多少内存，就是首尾两个zmalloc_used_memory相减。这个有点粗略了，就在刚才我们还将AOF/Slave缓存单独拿出来算的呢，现在直接总内存相减了。在注释中还提到，有可能用来propagateExpire的内存比我们释放的db内存还多呢，但我们是管不了的，否则mem_freed &lt; mem_tofree这个循环条件永远达不到了。并且，这些缓存终究会被释放的。这里还统计了一下调用dictSyncDelete等的时间，并且通过latencyAddSampleIfNeeded放到统计里面。12345678910111213... delta = (long long) zmalloc_used_memory(); latencyStartMonitor(eviction_latency); if (server.lazyfree_lazy_eviction) dbAsyncDelete(db,keyobj); else dbSyncDelete(db,keyobj); signalModifiedKey(NULL,db,keyobj); latencyEndMonitor(eviction_latency); latencyAddSampleIfNeeded("eviction-del",eviction_latency); delta -= (long long) zmalloc_used_memory(); mem_freed += delta;... 下面是一些统计性的工作。1234567... server.stat_evictedkeys++; notifyKeyspaceEvent(NOTIFY_EVICTED, "evicted", keyobj, db-&gt;id); decrRefCount(keyobj); keys_freed++;... 我们在循环中就强制往Slave发送数据，确保即使在要传的数据都很大的情况下，我们仍然能够快速传递。特别地，我们在while (mem_freed &lt; mem_tofree)这个循环的最后，还会有条件地检查一下内存是不是达标。这个主要是对异步删除来说的，在这种情况下，dbAsyncDelete流程中对内存的释放未必能和我们循环这边同步起来。所以我们每释放16个键，就检查一次。123456789101112131415... if (slaves) flushSlavesOutputBuffers(); if (server.lazyfree_lazy_eviction &amp;&amp; !(keys_freed % 16)) &#123; if (getMaxmemoryState(NULL,NULL,NULL,NULL) == C_OK) &#123; /* Let's satisfy our stop condition. */ mem_freed = mem_tofree; &#125; &#125; &#125; else &#123; goto cant_free; /* nothing to free... */ &#125; &#125; result = C_OK;... 异常情况123456789101112131415161718192021...cant_free: /* We are here if we are not able to reclaim memory. There is only one * last thing we can try: check if the lazyfree thread has jobs in queue * and wait... */ if (result != C_OK) &#123; latencyStartMonitor(lazyfree_latency); while(bioPendingJobsOfType(BIO_LAZY_FREE)) &#123; if (getMaxmemoryState(NULL,NULL,NULL,NULL) == C_OK) &#123; result = C_OK; break; &#125; usleep(1000); &#125; latencyEndMonitor(lazyfree_latency); latencyAddSampleIfNeeded("eviction-lazyfree",lazyfree_latency); &#125; latencyEndMonitor(latency); latencyAddSampleIfNeeded("eviction-cycle",latency); return result;&#125; getMaxmemoryState这个函数获得内存的使用情况，包括： total 总共使用的内存。 来自zmalloc_used_memory。 logical 即mem_used，表示出了Slave/AOF buffer之外的内存。 这个计算就是要减去overhead，也就是Slave/AOF buffer的内存，用freeMemoryGetNotCountedMemory计算得到的。 level 表示内存使用率 12345678int getMaxmemoryState(size_t *total, size_t *logical, size_t *tofree, float *level) &#123; size_t mem_reported, mem_used, mem_tofree; /* Check if we are over the memory usage limit. If we are not, no need * to subtract the slaves output buffers. We can just return ASAP. */ mem_reported = zmalloc_used_memory(); if (total) *total = mem_reported;... 上面获得了总内存量，如果没有设置最大内存，或者总内存量都没有操作，也不需要计算比例，那么就直接返回了12345... /* We may return ASAP if there is no need to compute the level. */ int return_ok_asap = !server.maxmemory || mem_reported &lt;= server.maxmemory; if (return_ok_asap &amp;&amp; !level) return C_OK;... 计算两个缓冲区占用的内存1234567891011121314151617181920212223242526272829... /* Remove the size of slaves output buffers and AOF buffer from the * count of used memory. */ mem_used = mem_reported; size_t overhead = freeMemoryGetNotCountedMemory(); mem_used = (mem_used &gt; overhead) ? mem_used-overhead : 0; /* Compute the ratio of memory usage. */ if (level) &#123; if (!server.maxmemory) &#123; *level = 0; &#125; else &#123; *level = (float)mem_used / (float)server.maxmemory; &#125; &#125; if (return_ok_asap) return C_OK; /* Check if we are still over the memory limit. */ if (mem_used &lt;= server.maxmemory) return C_OK; /* Compute how much memory we need to free. */ mem_tofree = mem_used - server.maxmemory; if (logical) *logical = mem_used; if (tofree) *tofree = mem_tofree; return C_ERR;&#125; evictionPoolEntry和evictionPoolPopulate12345678910#define EVPOOL_SIZE 16#define EVPOOL_CACHED_SDS_SIZE 255struct evictionPoolEntry &#123; unsigned long long idle; /* Object idle time (inverse frequency for LFU) */ sds key; /* Key name. */ sds cached; /* Cached SDS object for key name. */ int dbid; /* Key DB number. */&#125;;static struct evictionPoolEntry *EvictionPoolLRU; 来看evictionPoolPopulate这个函数，它作用是往evictionPool里面加一些条目。evictionPool由一系列evictionPoolEntry组成，后者表示某个数据库中的某个键。idle time表示每个对象的空闲时间，对于LFU来说，就是频率的倒数。pool里面只能加入具有更大idle time的键。如果还有空余空间，就始终加入。加入过程是有序的，左边的idle time最小。输入参数sampledict表示从那个dict里面进行采样，可能是dict或者expire。而输入参数keydict只能是对应的dict。123void evictionPoolPopulate(int dbid, dict *sampledict, dict *keydict, struct evictionPoolEntry *pool) &#123; int j, k, count; dictEntry *samples[server.maxmemory_samples]; server.maxmemory_samples默认被设置成5个。1234567891011... count = dictGetSomeKeys(sampledict,samples,server.maxmemory_samples); for (j = 0; j &lt; count; j++) &#123; unsigned long long idle; sds key; robj *o; dictEntry *de; de = samples[j]; key = dictGetKey(de);... 下面分两种策略进行讨论： 不是volatile-ttl策略 需要获取lru字段o-&gt;lru。这里要注意一点，如果传入的是expire的话，需要回dict表再查一次。 在获得lru字段之后，就需要估计idle时间： 如果采用LRU 调用estimateObjectIdleTime函数计算，实际上就是乘以一个LRU_CLOCK_RESOLUTION。这里实现上还处理了一下回绕wrap的情况。 123456789unsigned long long estimateObjectIdleTime(robj *o) &#123; unsigned long long lruclock = LRU_CLOCK(); if (lruclock &gt;= o-&gt;lru) &#123; return (lruclock - o-&gt;lru) * LRU_CLOCK_RESOLUTION; &#125; else &#123; return (lruclock + (LRU_CLOCK_MAX - o-&gt;lru)) * LRU_CLOCK_RESOLUTION; &#125;&#125; 如果采用LFU 这里要反向一下，就是用255减减一下。因为idle和访问频率是相反的。 如果是volatile-ttl策略 那么我们直接使用dictGetVal(de)的值。这个看起来很奇怪，但细想很简单。因为这个时候传入的dict肯定是db-&gt;expire，而它里面的值就是过期时间。 1234567891011121314151617181920... if (server.maxmemory_policy != MAXMEMORY_VOLATILE_TTL) &#123; if (sampledict != keydict) de = dictFind(keydict, key); o = dictGetVal(de); &#125; /* Calculate the idle time according to the policy. This is called * idle just because the code initially handled LRU, but is in fact * just a score where an higher score means better candidate. */ if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LRU) &#123; idle = estimateObjectIdleTime(o); &#125; else if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) &#123; idle = 255-LFUDecrAndReturn(o); &#125; else if (server.maxmemory_policy == MAXMEMORY_VOLATILE_TTL) &#123; /* In this case the sooner the expire the better. */ idle = ULLONG_MAX - (long)dictGetVal(de); &#125; else &#123; serverPanic("Unknown eviction policy in evictionPoolPopulate()"); &#125;... 在得到idle时间之后，就要将元素插入到池中。首先，找到第一个空bucket或者第一个idle不小于我们当前元素的idle。下面的循环能够跳过所有不满足以上条件的情况。123456789... /* Insert the element inside the pool. * First, find the first empty bucket or the first populated * bucket that has an idle time smaller than our idle time. */ k = 0; while (k &lt; EVPOOL_SIZE &amp;&amp; pool[k].key &amp;&amp; pool[k].idle &lt; idle) k++;... 下面处理两种特殊情况，第一种是bucket满了。第二种是桶是完全空的。123456789... if (k == 0 &amp;&amp; pool[EVPOOL_SIZE-1].key != NULL) &#123; /* Can't insert if the element is &lt; the worst element we have * and there are no empty buckets. */ continue; &#125; else if (k &lt; EVPOOL_SIZE &amp;&amp; pool[k].key == NULL) &#123; /* Inserting into empty position. No setup needed before insert. */ &#125; else &#123;... 下面就是一个类似插入排序的过程，我们要把我们的那个键插入到k的位置，然后把原来k以及之后的数字往右边移动。这里使用了memmove，它能自动检测src内存和dest内存重叠的情况并处理，所以是更安全的memcpy。还有一点需要说明的是cached的使用。12345678910111213141516171819202122... if (pool[EVPOOL_SIZE-1].key == NULL) &#123; /* Free space on the right? Insert at k shifting * all the elements from k to end to the right. */ /* Save SDS before overwriting. */ sds cached = pool[EVPOOL_SIZE-1].cached; memmove(pool+k+1,pool+k, sizeof(pool[0])*(EVPOOL_SIZE-k-1)); pool[k].cached = cached; &#125; else &#123; /* No free space on right? Insert at k-1 */ k--; /* Shift all elements on the left of k (included) to the * left, so we discard the element with smaller idle time. */ sds cached = pool[0].cached; /* Save SDS before overwriting. */ if (pool[0].key != pool[0].cached) sdsfree(pool[0].key); memmove(pool,pool+1,sizeof(pool[0])*k); pool[k].cached = cached; &#125; &#125;... 下面，更新刚插入的pool的相关数据。1234567891011121314151617... /* Try to reuse the cached SDS string allocated in the pool entry, * because allocating and deallocating this object is costly * (according to the profiler, not my fantasy. Remember: * premature optimizbla bla bla bla. */ int klen = sdslen(key); if (klen &gt; EVPOOL_CACHED_SDS_SIZE) &#123; pool[k].key = sdsdup(key); &#125; else &#123; memcpy(pool[k].cached,key,klen+1); sdssetlen(pool[k].cached,klen); pool[k].key = pool[k].cached; &#125; pool[k].idle = idle; pool[k].dbid = dbid; &#125;&#125; dictGetSomeKeysdictGetSomeKeys这个函数，是对一个dict来说的，而不是对db来说的。不保证一定返回正好count个，也不保证返回的元素都不重复。返回值被存到des里面，需要保证这个数组至少能容纳count个。12345678910111213141516/* This function samples the dictionary to return a few keys from random * locations. * * Note that this function is not suitable when you need a good distribution * of the returned items, but only when you need to "sample" a given number * of continuous elements to run some kind of algorithm or to produce * statistics. However the function is much faster than dictGetRandomKey() * at producing N elements. */unsigned int dictGetSomeKeys(dict *d, dictEntry **des, unsigned int count) &#123; unsigned long j; /* internal hash table id, 0 or 1. */ unsigned long tables; /* 1 or 2 tables? */ unsigned long stored = 0, maxsizemask; unsigned long maxsteps; if (dictSize(d) &lt; count) count = dictSize(d); maxsteps = count*10; 首先，我们执行一点渐进式rehash。然后我们将maxsizemask设置为所有ht（没有rehash是1个，有是2个）的最大容量。将i设置为随机一个位置。12345678910111213141516... /* Try to do a rehashing work proportional to 'count'. */ for (j = 0; j &lt; count; j++) &#123; if (dictIsRehashing(d)) _dictRehashStep(d); else break; &#125; tables = dictIsRehashing(d) ? 2 : 1; maxsizemask = d-&gt;ht[0].sizemask; if (tables &gt; 1 &amp;&amp; maxsizemask &lt; d-&gt;ht[1].sizemask) maxsizemask = d-&gt;ht[1].sizemask; /* Pick a random point inside the larger table. */ unsigned long i = random() &amp; maxsizemask;... 下面进入主循环，循环条件有两个，一个是取满count个，一个是执行最多maxsteps=count*10次。在每一次迭代中，对所有的ht（1或2个）进行处理。12345... unsigned long emptylen = 0; /* Continuous empty entries so far. */ while(stored &lt; count &amp;&amp; maxsteps--) &#123; for (j = 0; j &lt; tables; j++) &#123;... 涉及到rehashidx相关的逻辑，表示在每次进入dictRehash函数的时候，首先ht[0].table[rehashidx]这个桶。如果现在在rehash过程中，到d-&gt;rehashidx为止的所有index都已经被访问过了。实际上这些桶里面都空(not populated)了，因此我们可以跳过ht[0]里面$[0,idx-1]$这个区间的关卡，直接去看ht[1]里面的。这其实是一个优化，在dictRehash实现中，也有对空桶跳过的优化。特别地，如果i在ht[1]里面也已经超了，这就表示截止到rehashidx两个表里面都没有了。【Q】为什么可以认为ht[1]中的rehashidx之前的也不需要判定了呢？或者说，为啥两个ht可以共享一个i呢？1234567891011121314151617181920212223242526272829303132... if (tables == 2 &amp;&amp; j == 0 &amp;&amp; i &lt; (unsigned long) d-&gt;rehashidx) &#123; if (i &gt;= d-&gt;ht[1].size) i = d-&gt;rehashidx; else continue; &#125; if (i &gt;= d-&gt;ht[j].size) continue; /* Out of range for this table. */ dictEntry *he = d-&gt;ht[j].table[i]; /* Count contiguous empty buckets, and jump to other * locations if they reach 'count' (with a minimum of 5). */ if (he == NULL) &#123; // 我们会统计遇到连续空桶的数量，如果超过了5个，就重新随机一个位置。 emptylen++; if (emptylen &gt;= 5 &amp;&amp; emptylen &gt; count) &#123; i = random() &amp; maxsizemask; emptylen = 0; &#125; &#125; else &#123; // 否则，我们使用桶里面所有的元素 emptylen = 0; while (he) &#123; *des = he; des++; he = he-&gt;next; stored++; if (stored == count) return stored; &#125; &#125; &#125;... 在主循环结束后，会自增i的值。12345... i = (i+1) &amp; maxsizemask; &#125; return stored;&#125; client类client类对应了3.0版本中的redisClient类。因为Redis对IO是多路复用的，所以需要为每个客户端连接维护一个状态，所以client实际上类似于session一样，是在服务器端维护的一个状态。而真正的Redis客户端定义在redis-cli.c这个文件里面。1234567// server.htypedef struct client &#123; uint64_t id; /* Client incremental unique ID. */ connection *conn; int resp; /* RESP protocol version. Can be 2 or 3. */ redisDb *db; /* Pointer to currently SELECTed DB. */ redisServer类server是一个全局对象，它的类型是redisServer。12345// server.hextern struct redisServer server;// server.cstruct redisServer server; /* Server global state */ Redis事件在前面的代码中可以看到下面的语句，实际上是对主数据库c-&gt;db进行修改后，需要进行事件通知，我们将在下面介绍这几个语句的作用。1234signalModifiedKey(c,c-&gt;db,c-&gt;argv[j]);notifyKeyspaceEvent(NOTIFY_GENERIC, "del",c-&gt;argv[j],c-&gt;db-&gt;id);server.dirty++; signalModifiedKeysignalModifiedKey是key被修改的钩子函数，每当数据库c-&gt;db里面的key被改动时，会调用这个函数。这里的key发生改动也包括key对应的值发生改动，这是因为从genericSetKey的实现可以看到，SET指令也会导致signalModifiedKey被调用。此外，根据注释，每一次DB被flush时，signalFlushDb会被调用。123456// db.c void signalModifiedKey(client *c, redisDb *db, robj *key) &#123; touchWatchedKey(db,key); trackingInvalidateKey(c,key);&#125; touchWatchedKeytouchWatchedKey字如其名，它的作用是让WATCH这个键的事务失效。1234567/* "Touch" a key, so that if this key is being WATCHed by some client the * next EXEC will fail. */void touchWatchedKey(redisDb *db, robj *key) &#123; list *clients; listIter li; listNode *ln;... 这里先特判一下，如果db-&gt;watched_keys为空就直接返回，这个用法在redis中非常常见，我猜想可能是dictFind的开销还是比较大的。123... if (dictSize(db-&gt;watched_keys) == 0) return;... 下面从db-&gt;watched_keys上拿到WATCH这个key的所有的client，并且对这个链表上的每一个client设置CLIENT_DIRTY_CAS这个flag。1234567891011121314... // 这个函数是dictFind(只能得到dictEntry)和dictGetVal的简单封装 clients = dictFetchValue(db-&gt;watched_keys, key); if (!clients) return; /* Mark all the clients watching this key as CLIENT_DIRTY_CAS */ /* Check if we are already watching for this key */ listRewind(clients,&amp;li); while((ln = listNext(&amp;li))) &#123; client *c = listNodeValue(ln); c-&gt;flags |= CLIENT_DIRTY_CAS; &#125;&#125; trackingInvalidateKey下面看另一个函数trackingInvalidateKey。这个系列的函数是在Redis6.0左右被引入的，主要用途是维护客户端缓存。12345/* Wrapper (the one actually called across the core) to pass the key * as object. */void trackingInvalidateKey(client *c, robj *keyobj) &#123; trackingInvalidateKeyRaw(c,keyobj-&gt;ptr,sdslen(keyobj-&gt;ptr),1);&#125; 当key的值被改变后，在keys tracking的逻辑下，我们的任务是给每一个有可能缓存了当前keys的client发送通知。如果传入的c为空，表示这个不是一个client的场景，而是例如服务器内部做expire。bcast参数的作用是是否要将这个key通过BCAST模式广播给client们。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* * This is the case when the function is called from the Redis core once a key is modified, however * we also call the function in order to evict keys in the key table in case * of memory pressure: in that case the key didn't really change, so we want * just to notify the clients that are in the table for this key, that would * otherwise miss the fact we are no longer tracking the key for them. */void trackingInvalidateKeyRaw(client *c, char *key, size_t keylen, int bcast) &#123; if (TrackingTable == NULL) return; if (bcast &amp;&amp; raxSize(PrefixTable) &gt; 0) trackingRememberKeyToBroadcast(c,key,keylen); rax *ids = raxFind(TrackingTable,(unsigned char*)key,keylen); if (ids == raxNotFound) return; raxIterator ri; raxStart(&amp;ri,ids); raxSeek(&amp;ri,"^",NULL,0); while(raxNext(&amp;ri)) &#123; uint64_t id; memcpy(&amp;id,ri.key,sizeof(id)); client *target = lookupClientByID(id); /* Note that if the client is in BCAST mode, we don't want to * send invalidation messages that were pending in the case * previously the client was not in BCAST mode. This can happen if * TRACKING is enabled normally, and then the client switches to * BCAST mode. */ if (target == NULL || !(target-&gt;flags &amp; CLIENT_TRACKING)|| target-&gt;flags &amp; CLIENT_TRACKING_BCAST) &#123; continue; &#125; /* If the client enabled the NOLOOP mode, don't send notifications * about keys changed by the client itself. */ if (target-&gt;flags &amp; CLIENT_TRACKING_NOLOOP &amp;&amp; target == c) &#123; continue; &#125; sendTrackingMessage(target,key,keylen,0); &#125; raxStop(&amp;ri); /* Free the tracking table: we'll create the radix tree and populate it * again if more keys will be modified in this caching slot. */ TrackingTableTotalItems -= raxSize(ids); raxFree(ids); raxRemove(TrackingTable,(unsigned char*)key,keylen,NULL);&#125; notifyKeyspaceEvent函数notifyKeyspaceEvent用来触发数据库事件，这个对应了Redis中的叫“键空间通知”/“键事件通知”的特性。这个特性是通过PUBLISH机制实现的。简单来说，对0号数据库的键mykey执行DEL key [key ...]命令时，系统将分发两条消息，相当于执行以下两个PUBLISH channel message命令。其中__keyspace系列命令称为键空间通知(key-space notification)，__keyevent系列命令称为键事件通知(key-event notification)。订阅第一个PUBLISH命令，可以接收0号数据库中所有修改键mykey的事件。订阅第二个PUBLISH命令，可以接收0号数据库中所有执行del命令的键12PUBLISH __keyspace@0__:mykey delPUBLISH __keyevent@0__:del mykey 下面看看这个函数的具体实现。123456789101112131415161718192021222324252627282930313233343536373839404142void notifyKeyspaceEvent(int type, char *event, robj *key, int dbid) &#123; sds chan; robj *chanobj, *eventobj; int len = -1; char buf[24]; /* If any modules are interested in events, notify the module system now. * This bypasses the notifications configuration, but the module engine * will only call event subscribers if the event type matches the types * they are interested in. */ moduleNotifyKeyspaceEvent(type, event, key, dbid); /* If notifications for this class of events are off, return ASAP. */ if (!(server.notify_keyspace_events &amp; type)) return; eventobj = createStringObject(event,strlen(event)); /* __keyspace@&lt;db&gt;__:&lt;key&gt; &lt;event&gt; notifications. */ if (server.notify_keyspace_events &amp; NOTIFY_KEYSPACE) &#123; chan = sdsnewlen("__keyspace@",11); len = ll2string(buf,sizeof(buf),dbid); chan = sdscatlen(chan, buf, len); chan = sdscatlen(chan, "__:", 3); chan = sdscatsds(chan, key-&gt;ptr); chanobj = createObject(OBJ_STRING, chan); pubsubPublishMessage(chanobj, eventobj); decrRefCount(chanobj); &#125; /* __keyevent@&lt;db&gt;__:&lt;event&gt; &lt;key&gt; notifications. */ if (server.notify_keyspace_events &amp; NOTIFY_KEYEVENT) &#123; chan = sdsnewlen("__keyevent@",11); if (len == -1) len = ll2string(buf,sizeof(buf),dbid); chan = sdscatlen(chan, buf, len); chan = sdscatlen(chan, "__:", 3); chan = sdscatsds(chan, eventobj-&gt;ptr); chanobj = createObject(OBJ_STRING, chan); pubsubPublishMessage(chanobj, key); decrRefCount(chanobj); &#125; decrRefCount(eventobj);&#125; Redis内存管理zmallocRedis基于zmalloc系列函数进行内存分配。zmalloc是为了解决什么问题呢？主要是为了做到异常处理和内存统计的功能。下面首先来看zmalloc的实现。可以看到，它会额外分配一个PREFIX_SIZE，用来存储额外信息。zmalloc最终返回的是(char*)ptr+PREFIX_SIZE，这个有点类似于SDS的骚操作。PREFIX_SIZE的大小是由宏来定义的，并且可以通过HAVE_MALLOC_SIZE禁用内存统计的功能。123456789101112131415161718192021222324252627// zmalloc.c#ifdef HAVE_MALLOC_SIZE#define PREFIX_SIZE (0)#else#if defined(__sun) || defined(__sparc) || defined(__sparc__)#define PREFIX_SIZE (sizeof(long long))#else#define PREFIX_SIZE (sizeof(size_t))#endif#endifvoid *zmalloc(size_t size) &#123; void *ptr = malloc(size+PREFIX_SIZE); if (!ptr) zmalloc_oom_handler(size);#ifdef HAVE_MALLOC_SIZE // 如果不记录内存分配大小 update_zmalloc_stat_alloc(zmalloc_size(ptr)); return ptr;#else // 如果记录内存分配大小 *((size_t*)ptr) = size; update_zmalloc_stat_alloc(size+PREFIX_SIZE); return (char*)ptr+PREFIX_SIZE;#endif&#125; 下面，我们仔细查看一下update_zmalloc_stat_alloc函数的实现，不出所料的话，应该是通过一个原子操作来实现更新的。实际上也果不其然，atomicIncr的实现在后面会讲到。1234static size_t used_memory = 0;pthread_mutex_t used_memory_mutex = PTHREAD_MUTEX_INITIALIZER;#define update_zmalloc_stat_alloc(__n) atomicIncr(used_memory,(__n)) 我们还可以看到的是一个用来处理oom的函数zmalloc_oom_handler。对于C语言来说，malloc在内存分配失败后会返回一个0指针，然后我们在进行后续操作的时候要自行判断。基本上对于oom的处理就是打印一条日志然后abort了。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// zmalloc.cstatic void zmalloc_default_oom(size_t size) &#123; fprintf(stderr, "zmalloc: Out of memory trying to allocate %zu bytes\n", size); fflush(stderr); abort();&#125;static void (*zmalloc_oom_handler)(size_t) = zmalloc_default_oom;// server.cvoid redisOutOfMemoryHandler(size_t allocation_size) &#123; serverLog(LL_WARNING,"Out Of Memory allocating %zu bytes!", allocation_size); serverPanic("Redis aborting for OUT OF MEMORY. Allocating %zu bytes!", allocation_size);&#125;// server.h#define serverPanic(...) _serverPanic(__FILE__,__LINE__,__VA_ARGS__),_exit(1)// debug.cvoid _serverPanic(const char *file, int line, const char *msg, ...) &#123; va_list ap; va_start(ap,msg); char fmtmsg[256]; vsnprintf(fmtmsg,sizeof(fmtmsg),msg,ap); va_end(ap); bugReportStart(); serverLog(LL_WARNING,"------------------------------------------------"); serverLog(LL_WARNING,"!!! Software Failure. Press left mouse button to continue"); serverLog(LL_WARNING,"Guru Meditation: %s #%s:%d",fmtmsg,file,line); if (server.crashlog_enabled) &#123;#ifdef HAVE_BACKTRACE logStackTrace(NULL, 1);#endif printCrashReport(); &#125; bugReportEnd(0, 0);&#125;void bugReportStart(void) &#123; pthread_mutex_lock(&amp;bug_report_start_mutex); if (bug_report_start == 0) &#123; serverLogRaw(LL_WARNING|LL_RAW, "\n\n=== REDIS BUG REPORT START: Cut &amp; paste starting from here ===\n"); bug_report_start = 1; &#125; pthread_mutex_unlock(&amp;bug_report_start_mutex);&#125; SDSSDS(simple dynamic string)是Redis中的动态字符串实现，没错，Redis又重复了C/C++的传统，自己造了套轮子。我们考虑一下设计一个字符串的几个方面，复制/移动效率、空间效率、编码问题。例如在std::string中就会进行一些短串优化(SSO)（对每个字符串对象内部维护一段较短的buffer，当buffer不够用时再向堆请求空间）、写时拷贝(COW)的方法来进行优化，这会导致不同STL下c_str的不同行为。但在字符串设计时，常将其实现成immutable的，以Java为例，这是为了防止在外部对容器（如Hashset）中对象的更改破坏容器的特性（Hashset的唯一性）、并发、便于进行常量池优化考虑。但是SDS却是可变的，并且被用在实现键和值中。例如SET hello world中，键hello和值world的底层都是SDS。此外，由于其可变性，SDS还被用作缓冲区。查看sds的实现，发现是一个char*，难道直接就是一个char*的原生表示么？其实还真是这样，可以直接通过printf(&quot;%s&quot;, s)打印这个sds。12// sds.htypedef char *sds; 那么问题来了，Redis总不会用O(n)来算字符串长度吧，那么元信息报错在哪里呢？我们看到Redis提供了支持不同最大长度的sdshdr类型，和sds开头的C-style的字符串函数。所以说元信息是保存在sdshdr里面的。1234567891011struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;...struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;; 简单解释一下这几个参数： len len表示了字符串的长度，所以我们省去了strlen的开销，虽然我们还是可以直接对sds用。 buf 特别地，buf实际上是一个二进制数组，\0可以出现在中间，Redis只保证buf最终以\0结尾。而这个buf实际上就是sds所指向的东西，我们将在稍后解释这一点。 现在要讲解的重点是Redis是如何组织sdshdr和sds的，事实上它们的内存布局如图所示。容易看出，给定一个sds，可以直接当做char*来处理，但也可以往前推sizeof(sdshdr)大小，去获得sdshdr结构。而到底往前推多少字节，取决于1234 sds | vsdshdr | sdshdr.buf 创建1234sds sdsnew(const char *init) &#123; size_t initlen = (init == NULL) ? 0 : strlen(init); return sdsnewlen(init, initlen);&#125; 可以发现，主要是会调用sdsnewlen这个函数。1234sds sdsnewlen(const void *init, size_t initlen) &#123; void *sh; sds s; char type = sdsReqType(initlen); 首先，看一下这个type123456789101112131415static inline char sdsReqType(size_t string_size) &#123; if (string_size &lt; 1&lt;&lt;5) return SDS_TYPE_5; if (string_size &lt; 1&lt;&lt;8) return SDS_TYPE_8; if (string_size &lt; 1&lt;&lt;16) return SDS_TYPE_16;#if (LONG_MAX == LLONG_MAX) if (string_size &lt; 1ll&lt;&lt;32) return SDS_TYPE_32; return SDS_TYPE_64;#else return SDS_TYPE_32;#endif&#125; 可以看出，根据要分配的字符串的长度，会给到不同的SDS_TYPE_，实际上也就对应到不同长度的sdshdr对象，下面我们就要具体来分配一个sdshdr对象了。1234/* Empty strings are usually created in order to append. Use type 8 * since type 5 is not good at this. */if (type == SDS_TYPE_5 &amp;&amp; initlen == 0) type = SDS_TYPE_8;int hdrlen = sdsHdrSize(type); 看一下sdsHdrSize，不出所料，是根据type去sizeof算得需要使用的sdshdr对象的大小。12345678910static inline int sdsHdrSize(char type) &#123; switch(type&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: return sizeof(struct sdshdr5); // ... case SDS_TYPE_64: return sizeof(struct sdshdr64); &#125; return 0;&#125; 下面是分配了sdshdr对象和sds字符串的所有的内存，并加上一个结尾的\0。123456789... unsigned char *fp; /* flags pointer. */ sh = s_malloc(hdrlen+initlen+1); if (sh == NULL) return NULL; if (init==SDS_NOINIT) init = NULL; else if (!init) memset(sh, 0, hdrlen+initlen+1);... 下面一个有趣的是s，它实际上就是最后返回的sds了。12345678910111213141516171819202122... s = (char*)sh+hdrlen; fp = ((unsigned char*)s)-1; switch(type) &#123; case SDS_TYPE_5: &#123; *fp = type | (initlen &lt;&lt; SDS_TYPE_BITS); break; &#125; // ... case SDS_TYPE_64: &#123; SDS_HDR_VAR(64,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; &#125; if (initlen &amp;&amp; init) memcpy(s, init, initlen); s[initlen] = '\0'; return s;&#125; list在新版本下，Redis中的list(t_list)的实现借助于快表，但本章主要是讲解原始双向链表list的实现，它被定义在adlist文件中。1234567891011121314151617typedef struct listNode &#123; struct listNode *prev; struct listNode *next; void *value;&#125; listNode;typedef struct list &#123; listNode *head; listNode *tail; // 复制 void *(*dup)(void *ptr); // 释放 void (*free)(void *ptr); // 对比 int (*match)(void *ptr, void *key); unsigned long len;&#125; list; 可以看到，保存了head、tail和len的值，因此len操作是O(1)的。 dictdict是Redis中非常重要的结构，它不仅被用来实现HASH等数据结构，而且还被广泛地使用到Redis数据库服务器等基础设施中。在本章中，将介绍dict的实现，并使用HASH数据结构跟踪到dict的上层调用。我们首先看一下dict类的包含关系。其中，union v包含下面的几个类型123456union &#123; void *val; uint64_t u64; int64_t s64; double d;&#125; v; dict的基本实现与Rehash机制在这个章节中，我们主要介绍dict的主要实现和Hash以及Rehash机制。 dictEntry、dictType、dicthtdict的实现在dict.h中，注意在deps/hiredis中也有另一个实现，注意不要搞混。1234567891011typedef struct dictEntry &#123; void *key; union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; // next指针 struct dictEntry *next;&#125; dictEntry; dictEntry是一个KV对，可以看到Redis以链表的形式存储KV，并且使用union来优化空间存储。我们不能从dictEntry获得任何的类型信息，实际上它是作为下面dictht对象的一个组件来使用的。下面是dictType这个类，实际上决定了对应的行为。12345678typedef struct dictType &#123; uint64_t (*hashFunction)(const void *key); void *(*keyDup)(void *privdata, const void *key); void *(*valDup)(void *privdata, const void *obj); int (*keyCompare)(void *privdata, const void *key1, const void *key2); void (*keyDestructor)(void *privdata, void *key); void (*valDestructor)(void *privdata, void *obj);&#125; dictType; 在server.c中，分门别类定义了各种dictType。这些type都是在dictCreate作为参数传入的，会产生不同的复制、析构、hash、比较等特性。我们在先前也介绍过了db-&gt;expires是一个keyptrDictType，他在析构的时候不会删除对应的key，但是db-&gt;dict是dbDictType，这就不一样了。123456789101112131415161718192021/* Generic hash table type where keys are Redis Objects, Values * dummy pointers. */dictType objectKeyPointerValueDictType = &#123; dictEncObjHash, /* hash function */ NULL, /* key dup */ NULL, /* val dup */ dictEncObjKeyCompare, /* key compare */ dictObjectDestructor, /* key destructor */ NULL /* val destructor */&#125;;/* Like objectKeyPointerValueDictType(), but values can be destroyed, if * not NULL, calling zfree(). */dictType objectKeyHeapPointerValueDictType = &#123; dictEncObjHash, /* hash function */ NULL, /* key dup */ NULL, /* val dup */ dictEncObjKeyCompare, /* key compare */ dictObjectDestructor, /* key destructor */ dictVanillaFree /* val destructor */&#125;; dictht描述了一个哈希表，它将dictEntry组织起来，它维护了长度和节点数等信息，但并没有描述这个哈希表的行为、类型等信息，它将被进一步封装。123456typedef struct dictht &#123; dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used;&#125; dictht; 具体解释一下dictht的一些成员： table 乍一看，就很奇怪，为啥是个二维数组呢？ 外面一维是哈希的桶，里面一维是开链表。 这个在Rehash的时候有介绍，到时候要将这些桶拆开来，将每个dictEntry而不是每个桶进行Rehash。【Q】为什么要这样麻烦呢？这是因为到时候桶里面的元素不一定都属于新的桶里面了。 size 这里的size表示桶的数量，是2的指数。因此size的扩张只会在dictExpand中发生。而真正添加元素只是加到对应桶的开链表里面。 需要和dictSize函数区分一下，后者表示dict中两个ht中所有的元素数量而不是桶的数量。 sizemask 始终是size-1，这个是2质数增长的一个很经典的一个实现了。 used 表示哈希表中装载的元素数量，也就是每个桶中所有链表的长度之和。 因为开链表的存在，used是可能大于size的 Hash看到这里有个疑问，似乎这里的key是一个指针，而不是我想象中的一个SDS或者char*值，难道我们仅仅是根据key的指针值来进行哈希么？事实上并非如此，根据不同的dictType，实际上会有不同的Hash函数。可以看到对于大多数key为SDS的情况，会落到dictGenHashFunction的调用上。在3.0时代，这个函数是一个对MurmurHash2函数的调用，在当前版本下，这是一个对siphash函数的调用12345678910111213141516171819202122232425262728293031323334// server.c/* Set dictionary type. Keys are SDS strings, values are ot used. */dictType setDictType = &#123; dictSdsHash, /* hash function */ NULL, /* key dup */ NULL, /* val dup */ dictSdsKeyCompare, /* key compare */ dictSdsDestructor, /* key destructor */ NULL /* val destructor */&#125;;uint64_t dictSdsHash(const void *key) &#123; return dictGenHashFunction((unsigned char*)key, sdslen((char*)key));&#125;uint64_t dictGenHashFunction(const void *key, int len) &#123; return siphash(key,len,dict_hash_function_seed);&#125;uint64_t siphash(const uint8_t *in, const size_t inlen, const uint8_t *k) &#123;#ifndef UNALIGNED_LE_CPU uint64_t hash; uint8_t *out = (uint8_t*) &amp;hash;#endif uint64_t v0 = 0x736f6d6570736575ULL; uint64_t v1 = 0x646f72616e646f6dULL; uint64_t v2 = 0x6c7967656e657261ULL; uint64_t v3 = 0x7465646279746573ULL; uint64_t k0 = U8TO64_LE(k); uint64_t k1 = U8TO64_LE(k + 8); uint64_t m; const uint8_t *end = in + inlen - (inlen % sizeof(uint64_t)); const int left = inlen &amp; 7; ... dict和dictAdd我们接着来看上面的dictht结构。就和我在libutp里面看到的环状缓冲区一样，这里size和sizemask已经是老套路了，我们已经可以想象size一定是按照2的级数增长的，然后sizemask一定全是1给哈希函数算出来的值&amp;一下。下面我们来看一个dictAdd的调用过程，以验证我们的思路。这些宏用来封装调用dictType中定义的方法，从而实现对不同类型的不同哈希。12345#define dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key)#define dictCompareKeys(d, key1, key2) \ (((d)-&gt;type-&gt;keyCompare) ? \ (d)-&gt;type-&gt;keyCompare((d)-&gt;privdata, key1, key2) : \ (key1) == (key2)) 检查是否已经存在dictAdd会最终调用dictAddRaw，然后会调用一个_dictKeyIndex，这个函数给定key，返回哈希表中可以插入到的slot的index。如果key已经在哈希表中存在，返回-1，并通过existing取回。123// dictAddRaw &lt;- dictAddif ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL; 这个函数主要就是一个for循环，这个循环在dict中是非常常见的对所有dictEntry遍历的循环，我们列在“dict遍历抽象主干代码”这个章节里面。循环关键如下： 遍历所有的table，如果正在Rehash过程中，那么就会有两个table。 【Q】根据源码中的注释，如果在Rehash过程中_dictKeyIndex返回那个idx，一定是ht[1]对应的索引值？ 这在说啥呢？参考“会不会有两个键出现在两个table里面？”这个讨论，如果在Rehash过程中，我们插入要插入到新的表ht[1]中，所以插入的位置idx，也应该是新的表中的位置idx。下面的for循环从0到1的顺序保证了这一点。 1for (table = 0; table &lt;= 1; table++) 我们根据key的哈希值，找到对应的桶d-&gt;ht[table].table[idx]。 我们遍历这个桶的开链表。 123456789101112131415161718192021222324252627// _dictKeyIndex &lt;- dictAddRaw &lt;- dictAddstatic long _dictKeyIndex(dict *d, const void *key, uint64_t hash, dictEntry **existing)&#123; unsigned long idx, table; dictEntry *he; if (existing) *existing = NULL; /* Expand the hash table if needed */ if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; // 这个for循环在“dict遍历抽象主干代码”也列举了出来。 for (table = 0; table &lt;= 1; table++) &#123; idx = hash &amp; d-&gt;ht[table].sizemask; // 注意Redis使用开链法解决哈希冲突，所以要搜完`d-&gt;ht[table].table[idx]`这条链。 he = d-&gt;ht[table].table[idx]; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123; // 如果key和he-&gt;key相等（指针相等或者值相等），我们尝试赋值给*existing if (existing) *existing = he; return -1; &#125; he = he-&gt;next; &#125; // 如果不在Rehash过程中，我们不找ht[1]，这个机制在后面的`dictFind`等函数中也会出现 if (!dictIsRehashing(d)) break; &#125;... 函数的返回值选取idx即可，具体的dictEntry *，如果调用者有需要，我们才设置*existing用来返回。因为我们用这个函数不仅是看有没有，还要顺便获得在后面插入位置。返回并保存链表头，后面就可以直接从链表头插入，这样的好处是一方面我们只要记录一个链表头，另一方面是Redis假设最近被添加的字段会被频繁访问。这里可以总结出链表使用的经验，如果需要快速push，保存链表头。如果需要快速pop，保存链表尾。123... return idx;&#125; 在刚才的代码中出现了dict这个结构，它也就是我们真正提供的完备的哈希表。因此，到这里的“继承关系”是dict &lt;- dictht &lt;- dictEntry1234567typedef struct dict &#123; dictType *type; void *privdata; dictht ht[2]; long rehashidx; unsigned long iterators;&#125; dict; 同样简单介绍一下成员： type/privdata 用来实现类似继承的机制，这样我们可以自定义dict的行为。 ht 是两个dictht结构，每一个dictht就是上面提到的一个哈希表。这个用来实际保存数据。 可是为什么是长度为2的数组呢？这里的ht[1]在rehash的时候用，在rehash的时候会把ht[0]慢慢搬到ht[1]上。 rehashidx 用来表示此时Rehash的过程（具体机制查看后文）。 -1表示未在Rehash。 &gt;=0表示Rehash开始，将要移动ht[0].table[rehashidx]这个桶。 iterators 表示这个字典上的安全迭代器的个数。 哈希表的扩容当哈希表容量不够时就需要进行扩容，同时需要进行Rehash。下面我们正式来研究哈希表的扩容与Rehash部分根据_dictExpandIfNeeded，扩容需要满足几个条件： used &gt;= size 回忆一下，size是桶的数量，used是键的数量。used是会大于size的，因为开链表。 dict_can_resize 根据updateDictResizePolicy函数，在一些情况下dict_can_resize是false，这时候不会扩张。 根据《Redis设计与实现》，这种情况发生在BGSLAVE或者BGREWRITEAOF命令运行时针对COW机制的一个优化。这两个命令实际上是后台写RDB和AOF的实现。 但是当used/size大于一个比例，默认是5，会强制扩张（注意扩张还是按照2倍）。 1234567891011121314151617#define dictIsRehashing(d) ((d)-&gt;rehashidx != -1)static int _dictExpandIfNeeded(dict *d)&#123; // 此时正在进行Rehash（有没有很奇怪为啥会有个正在进行中的状态？请看下文） if (dictIsRehashing(d)) return DICT_OK; // 哈希表是空的 if (d-&gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE); // Hash表扩张条件： if (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp; (dict_can_resize || d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio)) &#123; return dictExpand(d, d-&gt;ht[0].used*2); &#125; return DICT_OK;&#125; 下面的dictExpand就是扩容函数12345678910111213141516171819/* Expand or create the hash table */int dictExpand(dict *d, unsigned long size)&#123; // size是要扩张到的大小，在计算时是按照used成比例放大的，所以肯定比used要大。 if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size) return DICT_ERR; dictht n; /* the new hash table */ unsigned long realsize = _dictNextPower(size); /* Rehashing to the same table size is not useful. */ if (realsize == d-&gt;ht[0].size) return DICT_ERR; /* Allocate the new hash table and initialize all pointers to NULL */ n.size = realsize; n.sizemask = realsize-1; n.table = zcalloc(realsize*sizeof(dictEntry*)); n.used = 0;... 假如ht[0]是空的，那这是一次初始化，直接将ht[0]指向新的hash表n。123456... if (d-&gt;ht[0].table == NULL) &#123; d-&gt;ht[0] = n; return DICT_OK; &#125;... 否则将ht[1]指向新的哈希表n。12345... d-&gt;ht[1] = n; d-&gt;rehashidx = 0; return DICT_OK;&#125; Rehash我们看到扩容操作只是创建了一个空的哈希表，并没有真正移动ht[0]的元素到ht[1]对应的位置上（这个过程被称作桶转移），难道这里又是COW了？答案是肯定的。通过优秀的英文能力，我们猜到了真正做Rehash的函数int dictRehash(dict *d, int n)，dictRehash在dictRehashMilliseconds和_dictRehashStep中被调用。 dictRehash对d做n步的Rehash，其中一步表示将ht[0]中的一个桶d-&gt;ht[0].table[d-&gt;rehashidx]移到ht[1]上。注意下面几点： 这里的d-&gt;ht[0].table[d-&gt;rehashidx]是一个开链表。 我们不能直接移动桶，因为到时候里面的元素可能Rehash到不同的桶里面。所以，我们只能遍历桶的开链表里面的所有key，然后逐个放到新的table里面。 容易看出ht[0].size &gt; rehashidx是始终成立的。 因为ht[0].size就是桶的最多数量，rehashidx表示现在哈希到第几个桶了。 这个n的计算不包括空桶，Redis每次哈希可以跳过empty_visits个空桶，这时候我们要做的仅仅是自增d-&gt;rehashidx。 dictRehashMilliseconds 定时Rehash函数incrementallyRehash在后台被databasesCron定时调用，起到定时Rehash每个db的dict和expire表的作用。 dictRehashMilliseconds是一个时间相关的函数，它会在在ms毫秒的时间里面rehash尽可能多的桶，也就是每rehash 100个桶之后检查一下有没有超时，没有就接着来。 12345678910111213141516171819202122232425262728293031323334// server.cvoid databasesCron(void) &#123; ... if (server.activerehashing) &#123; for (j = 0; j &lt; dbs_per_call; j++) &#123; int work_done = incrementallyRehash(rehash_db); ...&#125;int incrementallyRehash(int dbid) &#123; /* Keys dictionary */ if (dictIsRehashing(server.db[dbid].dict)) &#123; dictRehashMilliseconds(server.db[dbid].dict,1); return 1; /* already used our millisecond for this loop... */ &#125; /* Expires */ if (dictIsRehashing(server.db[dbid].expires)) &#123; dictRehashMilliseconds(server.db[dbid].expires,1); return 1; /* already used our millisecond for this loop... */ &#125; return 0;&#125; int dictRehashMilliseconds(dict *d, int ms) &#123; long long start = timeInMilliseconds(); int rehashes = 0; while(dictRehash(d,100)) &#123; rehashes += 100; if (timeInMilliseconds()-start &gt; ms) break; &#125; return rehashes;&#125; _dictRehashStep _dictRehashStep在诸如dictAddRaw、dictGenericDelete、dictFind、dictGetRandomKey等函数中被调用，作为dictRehashMilliseconds的补充。 1234static void _dictRehashStep(dict *d) &#123; // 只有当 if (d-&gt;iterators == 0) dictRehash(d,1);&#125; 下面我们来看一下Rehash的过程。最外面是一个大循环，表示移动最多n个桶。1234567int dictRehash(dict *d, int n) &#123; int empty_visits = n*10; if (!dictIsRehashing(d)) return 0; while(n-- &amp;&amp; d-&gt;ht[0].used != 0) &#123; dictEntry *de, *nextde;... 我们最多跳过empty_visits == n*10个空桶，此时只更新rehashidx，不计算n。123456789... /* Note that rehashidx can't overflow as we are sure there are more * elements because ht[0].used != 0 */ assert(d-&gt;ht[0].size &gt; (unsigned long)d-&gt;rehashidx); while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) &#123; d-&gt;rehashidx++; if (--empty_visits == 0) return 1; &#125;... 下面开始移动非空桶。注意我们不能直接将这个非空桶整个移植过去，因为里面的key在Rehash之后可能会去到其他的桶里面，所以我们用de来遍历这个开链表。1234567891011121314151617... de = d-&gt;ht[0].table[d-&gt;rehashidx]; while(de) &#123; uint64_t h; nextde = de-&gt;next; /* Get the index in the new hash table */ h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; d-&gt;ht[0].used--; d-&gt;ht[1].used++; de = nextde; &#125; d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; d-&gt;rehashidx++; &#125;... 在大循环移动完n个桶，或者遇到太多的空桶退出之后，检查ht[0]是不是已经结束了。1234567891011121314... // 当ht[0].used为0时过程终止，将d-&gt;rehashidx设为-1。 if (d-&gt;ht[0].used == 0) &#123; zfree(d-&gt;ht[0].table); // 将ht[1]按指针赋值给ht[0]。 d-&gt;ht[0] = d-&gt;ht[1]; _dictReset(&amp;d-&gt;ht[1]); d-&gt;rehashidx = -1; return 0; &#125; // 否则Rehash还没有结束。 return 1;&#125; 我们发现在Rehash的过程中，调用dictRehash都将ht[0]掏空一点给ht[1]，直到最后过程结束后将ht[1]指针赋值给ht[0]。 ht[0]和ht[1]的顺序【Q】如果在Rehash过程中，增删改查需要考虑下面几点（注意我们的语境是在Rehash下！！）： 对于插入操作，会不会在ht[0]中已经有了，我们又新插入到ht[1]，导致一个值在两个地方，或者反过来？ 这个是不可能的。首先，我们要规定插入只能在ht[1]；然后在每次插入前，我们都要在ht[0]和ht[1]中都检查一遍。 对于删除操作，会不会只删除ht中的数据？ 总结一下，在Rehash的过程中我们插入必须对ht[1]，而查找删除优先在ht[0]操作，然后再ht[1]。Rehash在对哈希表每一次的增删改查中渐进进行，我们查看相关代码。 首先看插入，我们首先调用_dictKeyIndex，如果不存在，则： 如果不在Rehash，那么返回ht[0]中待插入的idx 如果在Rehash，则返回ht[1]。关于这部分，在_dictKeyIndex讲过了。 1234567891011121314151617// dictAddRawdictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)&#123; long index; dictEntry *entry; dictht *ht; if (dictIsRehashing(d)) _dictRehashStep(d); /* Get the index of the new element, or -1 if * the element already exists. */ if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL; ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0];...&#125; 对查找来说，也是从ht[0]查，再查ht[1]12345678910111213141516// dictFindif (dictIsRehashing(d)) _dictRehashStep(d);// 调用对应的hash function获得哈希值hh = dictHashKey(d, key);for (table = 0; table &lt;= 1; table++) &#123; idx = h &amp; d-&gt;ht[table].sizemask; // 找到第table(0或者1)个ht的第idx的元素 he = d-&gt;ht[table].table[idx]; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) return he; he = he-&gt;next; &#125; // 如果不在Rehash过程中，我们找完ht[0]就不找了，因为只可能ht[0]有内容 if (!dictIsRehashing(d)) return NULL;&#125; 删除同理123456789// dictGenericDeleteif (dictIsRehashing(d)) _dictRehashStep(d);h = dictHashKey(d, key);for (table = 0; table &lt;= 1; table++) &#123; idx = h &amp; d-&gt;ht[table].sizemask; he = d-&gt;ht[table].table[idx];...// _dictKeyIndex// 见前面 遍历机制(dictScan)Redis中的遍历分为两块，第一个是dictScan函数，第二个是借助dictIterator这个迭代器。其中，前者用来对外提供SCAN，后者主要用来服务其他数据结构。我们首先介绍dictScan。由于Redis中哈希表的动态扩展和缩小中有渐进Rehash的过程，所以做到恰巧一遍的遍历是非常难的，函数dictScan的实现确保了每个元素都能遍历到，但可能存在元素被重复遍历。函数dictScan接受一个cursor即参数v，并移动这个cursor，返回其新值，初始情况下我们传入v为0。dictScanFunction表示需要对每一个dictEntry设置的函数。dictScanBucketFunction表示需要对每个桶设置的函数。12345678910111213141516171819202122232425262728293031#define dictSize(d) ((d)-&gt;ht[0].used+(d)-&gt;ht[1].used)unsigned long dictScan(dict *d, unsigned long v, dictScanFunction *fn, dictScanBucketFunction* bucketfn, void *privdata)&#123; dictht *t0, *t1; const dictEntry *de, *next; unsigned long m0, m1; // 如果没有元素，直接返回0，表示遍历完毕 if (dictSize(d) == 0) return 0; if (!dictIsRehashing(d)) &#123; // 假设不在Rehash过程中，此时只有ht[0]中有元素 t0 = &amp;(d-&gt;ht[0]); m0 = t0-&gt;sizemask; // 下面这一串表示对桶和桶中所有元素调用bucketfn和fn回调函数 if (bucketfn) bucketfn(privdata, &amp;t0-&gt;table[v &amp; m0]); de = t0-&gt;table[v &amp; m0]; while (de) &#123; next = de-&gt;next; fn(privdata, de); de = next; &#125; v |= ~m0; v = rev(v); v++; v = rev(v); &#125; else &#123; ... &#125; return v;&#125; 这里对v的更新十分奇妙，按照理想情况，我们完全可以去直接v++，然后遍历完所有的桶。但是那四行代码的行为却很奇特，这种遍历方法被称为reverse binary iteration： 首先第一行将v的会和~mask or一下 第二行调用rev将v按比特反转，这时候高位填充的1就到了最低位上。 接着后面两行进行自增，再倒回去。 这么做的结果是二进制的进位是反向的，我们首先对最高位自增，如果高位溢出了，就对低位进位。 我们首先介绍一下rev这个函数，它的作用是将一个二进制串前后倒置。123456789101112131415161718// 进行位反转static unsigned long rev(unsigned long v) &#123; unsigned long s = 8 * sizeof(v); // bit size; must be power of 2 unsigned long mask = ~0; while ((s &gt;&gt;= 1) &gt; 0) &#123; mask ^= (mask &lt;&lt; s); v = ((v &gt;&gt; s) &amp; mask) | ((v &lt;&lt; s) &amp; ~mask); &#125; return v;&#125;int main()&#123; using namespace std; unsigned long long x; x = 0b1011011101111; cout &lt;&lt; std::bitset&lt;64&gt;(x) &lt;&lt; endl; cout &lt;&lt; std::bitset&lt;64&gt;(rev(x)) &lt;&lt; endl;&#125; 打印下来是这样的1200000000000000000000000000000000000000000000000000010110111011111111011101101000000000000000000000000000000000000000000000000000 以mask = (uint8_t) 15(0x1111)、v = (uint8_t) 2为例查看一下这个过程。1234500000010(2)初始状态-&gt; 11110010 `15`是0x1111，`~15`是0x11110000。这么做的目的是将“没用到”的位全部置为1-&gt; 01001111 rev函数逆向原串 -&gt; 01010000 自增-&gt; 00001010(10) rev函数再逆向回来 我们从v=0开始迭代，发现值依次是120 8 4 12 2 10 6 14 1 9 5 13 3 11 7 15 00b0000 0b1000 0b0100 0b1100 0b0010 0b1010 0b0110 0b1110 0b0001 0b1001 0b0101 0b1101 0b0011 0b1011 0b0111 0b1111 【Q】为什么要做这样的设计呢？因为Rehash是以2为倍数扩展或者收缩的，这样遍历之下，能够保证Rehash之后，既不会漏掉，也不会重复遍历。 我们考虑将数字[0,7]哈希到2和4的不同情况，可以发现哈希到4时每个slot里数字的后2位都相同，而哈希到2时每个slot里数字的后1位相同。我们可以认为从$2^i$到$2^{i+1}$，我们将每个slot中的数按照第i位的值分成两个slot。12345670(00):0(000),4(100)1(01):1(001),5(101)2(10):2(010),6(110)3(11):3(011),7(111)===0:0(000),2(010),4(100),6(110)1:1(001),3(011),5(101),7(111) 在上面讨论了更通用的情形，特别用了slot而不是之前提到的桶的概念。在这篇文章中，一个桶指的是ht中哈希值相同的所有元素组成的链表，也就是dictht的dictEntry** table的第一维。现在讨论的dictScan是针对桶的扫描而不是元素的扫描。特别地，我们将哈希表中的N个桶合并成N/2个桶时，相当于做一次针对桶的哈希。考虑一个8个桶的哈希表，其桶的遍历顺序是0 4 2 6 1 5 3 7 0。假设遍历6(110)前我们将8个桶缩小到4个桶，那么桶6中的元素应当被映射到新桶2(10)中了，因此我们应当遍历2(10)这个桶，此时我们已经遍历过的桶如下示意12345新桶 原桶0(00):0(000),4(100)1(01):2(10):2(010)3(11): 容易发现此时我们重复遍历了原来桶2(010)中的元素。这个过程结束时新的mask为3，v会更新到1(01)，我们发现下面要遍历的1 5两个就桶被合并到了1(01)这个新桶里面。如果考虑遍历2(010)前发生了缩小，那么我们就不要重复遍历元素。 遍历机制(迭代器)迭代器的声明如下，容易看出通过d、index和table我们可以确定一个桶。safe表示这个迭代器是否是一个安全的迭代器。12345678910111213141516typedef struct dictIterator &#123; // 被迭代的字典 dict *d; // 迭代器当前所指向的dictEntry位置 long index; // 正在被迭代的dictht号码，值可以是 0 或 1 int table; // 标识这个迭代器是否安全 int safe; // 当前迭代到的节点的指针 dictEntry *entry; // 见下文说明 dictEntry *nextEntry; /* unsafe iterator fingerprint for misuse detection. */ long long fingerprint;&#125; dictIterator; 我们将在下面逐一介绍相关的字段用法 安全迭代器 安全的迭代器是什么意思呢？比如在Rehash机制中，存在safe迭代器的情况下是暂停Rehash的。只有当iterators数量为0时，才会进行Rehash。 123456789/* Rehash for an amount of time between ms milliseconds and ms+1 milliseconds */int dictRehashMilliseconds(dict *d, int ms) &#123; if (d-&gt;iterators &gt; 0) return 0; ...&#125;static void _dictRehashStep(dict *d) &#123; if (d-&gt;iterators == 0) dictRehash(d,1);&#125; 需要注意的是，在Redis的6.0版本上，dictScan也会增加iterators，从而导致rehash停止。而在5.0版本还没有这个限制。【Q】为什么会有这个限制呢？ fingerprint 用来将两个ht的指针、size和used进行哈希，在dictNext开始和结束之后比较哈希值，如果不一样的话，就assert。这主要是用来保证，当不安全迭代器被使用时，该迭代器的使用者不能对这个哈希表做出不合法的操作。 dict迭代器相关方法搜索dict这个迭代器主要作用是在redis内部，例如持久化相关的工作。dict迭代器的相关方法主要包括dictNext、dictGetIterator、dictGetSafeIterator、dictReleaseIterator。 dictNextdictNext的实现比较特别，它会缓存当前的iter-&gt;entry，以及下一个iter-&gt;nextEntry。主要流程如下： 初始化 指向0这个table。指向0这个dictEntry。 iter-&gt;index表示遍历的distEntry的位置，iter-&gt;entry表示被遍历的那个distEntry。 如果iter-&gt;entry是NULL 通常是因为初始化，或者遍历完了一张表 如果遍历完了所有的dictEntry，就换到table 1。当然没有Rehash的话就结束。 如果iter-&gt;entry不是NULL 这是大部分情况。 我们移动到iter-&gt;nextEntry，然后去更新iter-&gt;nextEntry。 这里要用nextEntry的原因是安全迭代器是能够对哈希表进行增删的，因此如果iter-&gt;entry在迭代时被删除了，那么就会导致iter-&gt;entry-&gt;next是无法访问的，因此这里要提前保存一下。 123456789101112131415161718192021222324252627282930313233343536373839404142dictEntry *dictNext(dictIterator *iter)&#123; while (1) &#123; if (iter-&gt;entry == NULL) &#123; // 如果没有指定dictEntry // iter-&gt;table初始值是0 dictht *ht = &amp;iter-&gt;d-&gt;ht[iter-&gt;table]; if (iter-&gt;index == -1 &amp;&amp; iter-&gt;table == 0) &#123; // 这边是初始化 if (iter-&gt;safe) iter-&gt;d-&gt;iterators++; else iter-&gt;fingerprint = dictFingerprint(iter-&gt;d); &#125; // 通常操作，找到下一个entry iter-&gt;index++; // 但如果这个dictht遍历完了 if (iter-&gt;index &gt;= (long) ht-&gt;size) &#123; // 如果同时有两个表(dictIsRehashing条件)，且表0遍历完了，就切换到表1 if (dictIsRehashing(iter-&gt;d) &amp;&amp; iter-&gt;table == 0) &#123; iter-&gt;table++; iter-&gt;index = 0; ht = &amp;iter-&gt;d-&gt;ht[1]; &#125; else &#123; break; &#125; &#125; // 再设置一下entry iter-&gt;entry = ht-&gt;table[iter-&gt;index]; &#125; else &#123; // 如果指定了dictEntry，说明是之前有遍历到某个dictht的一半，这是大部分情况，所以就直接到nextEntry iter-&gt;entry = iter-&gt;nextEntry; &#125; if (iter-&gt;entry) &#123; /* We need to save the 'next' here, the iterator user * may delete the entry we are returning. */ iter-&gt;nextEntry = iter-&gt;entry-&gt;next; return iter-&gt;entry; &#125; &#125; return NULL;&#125; dict的其他相关方法dict遍历抽象主干代码由于在dict中常出现遍历操作，为了方便阅读代码，我们将整个遍历操作先抽象出来，在下面相关代码的介绍中，只列出主干。关于这个循环的说明，可以参看_dictKeyIndex的讲解1234567891011121314151617181920// dict.h#define dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key)if (dictIsRehashing(d)) _dictRehashStep(d);h = dictHashKey(d, key);for (table = 0; table &lt;= 1; table++) &#123; idx = h &amp; d-&gt;ht[table].sizemask; he = d-&gt;ht[table].table[idx]; prevHe = NULL; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123; // 找到了 return; &#125; he = he-&gt;next; &#125; // 如果不在Rehash过程中，就不需要查找table=1的表了 if (!dictIsRehashing(d)) break;&#125;return NULL; /* not found */ dictFind这个函数用来根据给定的key找到对应的dictEntry，如果找不到，就返回NULL。其中涉及一些Rehash相关的机制，我们在先前已经讲过了，在这里就略过。123456789dictEntry *dictFind(dict *d, const void *key)&#123; dictEntry *he; uint64_t h, idx, table; if (dictSize(d) == 0) return NULL; /* dict is empty */ // 参考“dict遍历抽象主干代码” return NULL;&#125; dictGet系列函数这个系列的函数主要通过读取union v里面的不同类型的值。12345#define dictGetKey(he) ((he)-&gt;key)#define dictGetVal(he) ((he)-&gt;v.val)#define dictGetSignedIntegerVal(he) ((he)-&gt;v.s64)#define dictGetUnsignedIntegerVal(he) ((he)-&gt;v.u64)#define dictGetDoubleVal(he) ((he)-&gt;v.d) dictDelete和dictGenericDeletedictDelete实现，就是调用dictGenericDelete，并且指定是要free的。注意，我们不要和hiredis里面的dictDelete实现搞混起来12345/* Remove an element, returning DICT_OK on success or DICT_ERR if the * element was not found. */int dictDelete(dict *ht, const void *key) &#123; return dictGenericDelete(ht,key,0) ? DICT_OK : DICT_ERR;&#125; 现在我们介绍其依赖函数dictGenericDelete。这函数表示要从d中删除一个key。在前面已经看到，dictDelete系列函数相比其他操作会多一个场景，也就是会考虑是不是立即将key和value的对象free掉。12345678910static dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) &#123; uint64_t h, idx; dictEntry *he, *prevHe; int table; if (d-&gt;ht[0].used == 0 &amp;&amp; d-&gt;ht[1].used == 0) return NULL; if (dictIsRehashing(d)) _dictRehashStep(d); // 参考“dict遍历抽象主干代码”&#125; 但这里对dict遍历抽象主干代码的处理会有一些修改，首先用prevHe来记录待删除节点he的父节点，从而将链表接起来。然后是一个nofree选项，可以不去析构key和value。12345678910111213141516171819202122// dictGenericDelete中不连续的部分代码... prevHe = NULL; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123; /* Unlink the element from the list */ if (prevHe) prevHe-&gt;next = he-&gt;next; else d-&gt;ht[table].table[idx] = he-&gt;next; if (!nofree) &#123; dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); &#125; d-&gt;ht[table].used--; return he; &#125; prevHe = he; he = he-&gt;next; &#125;... HSET的相关数据结构HSET是对dict的封装。 hset实现我们还是从redisCommandTable里面查到hset的对应函数是hsetCommand。hashTypeLookupWriteOrCreate这个函数就是调用lookupKeyWrite，如果找不到，就通过createHashObject创建，这个函数是创建一个OBJ_HASH对象。12345678910111213141516171819202122232425262728void hsetCommand(client *c) &#123; int i, created = 0; robj *o; if ((c-&gt;argc % 2) == 1) &#123; addReplyErrorFormat(c,"wrong number of arguments for '%s' command",c-&gt;cmd-&gt;name); return; &#125; if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return; hashTypeTryConversion(o,c-&gt;argv,2,c-&gt;argc-1); for (i = 2; i &lt; c-&gt;argc; i += 2) created += !hashTypeSet(o,c-&gt;argv[i]-&gt;ptr,c-&gt;argv[i+1]-&gt;ptr,HASH_SET_COPY); /* HMSET (deprecated) and HSET return value is different. */ char *cmdname = c-&gt;argv[0]-&gt;ptr; if (cmdname[1] == 's' || cmdname[1] == 'S') &#123; /* HSET */ addReplyLongLong(c, created); &#125; else &#123; /* HMSET */ addReply(c, shared.ok); &#125; signalModifiedKey(c,c-&gt;db,c-&gt;argv[1]); notifyKeyspaceEvent(NOTIFY_HASH,"hset",c-&gt;argv[1],c-&gt;db-&gt;id); server.dirty++;&#125; ZSET在本章中，我们将会从ZSET切入，了解它是如何包装ziplist和zskiplist的。但是具体到ziplist和zskiplist的实现，是在单独的章节里面讲的。ZSET有两个实现，基于跳表的和基于ziplist的，具体来说： ziplist 是一个双向压缩链表的实现，这里的压缩链表指的是不会保存prev和next信息，而是采用类似线性表的方式将整个list存放在一整块内存中。对应于元素数量少于128，且每个元素的长度小于64字节。 zskiplist 是个跳表的实现。对应于1之外的情况。 ZSET和zadd从redisCommandTable找到绑定的函数zaddCommand，它会调用一个zaddGenericCommand1234// t_zset.cvoid zaddCommand(client *c) &#123; zaddGenericCommand(c,ZADD_NONE);&#125; 查看zaddGenericCommand，它接受一个flags参数，我们稍后介绍。123456789101112131415void zaddGenericCommand(client *c, int flags) &#123; static char *nanerr = "resulting score is not a number (NaN)"; robj *key = c-&gt;argv[1]; robj *zobj; sds ele; double score = 0, *scores = NULL; int j, elements; int scoreidx = 0; /* The following vars are used in order to track what the command actually * did during the execution, to reply to the client and to trigger the * notification of keyspace change. */ int added = 0; /* Number of new elements added. */ int updated = 0; /* Number of elements with updated score. */ int processed = 0; /* Number of elements processed, may remain zero with options like XX. */ 下面一部分代码是用来处理一些额外输入的flag参数，这里引入了scoreidx表示score/value对开始的位置，在3.0版本中写死了是2，但是由于后面版本允许了nx、xx等参数，所以这边改为动态计算的。12345678910111213141516171819... scoreidx = 2; while(scoreidx &lt; c-&gt;argc) &#123; char *opt = c-&gt;argv[scoreidx]-&gt;ptr; if (!strcasecmp(opt,"nx")) flags |= ZADD_NX; else if (!strcasecmp(opt,"xx")) flags |= ZADD_XX; else if (!strcasecmp(opt,"ch")) flags |= ZADD_CH; else if (!strcasecmp(opt,"incr")) flags |= ZADD_INCR; else break; scoreidx++; &#125; /* Turn options into simple to check vars. */ int incr = (flags &amp; ZADD_INCR) != 0; int nx = (flags &amp; ZADD_NX) != 0; int xx = (flags &amp; ZADD_XX) != 0; int ch = (flags &amp; ZADD_CH) != 0;... 下面的代码主要是校验参数的合法性12345678910111213141516171819202122... // 这里是一个通常的做法，类似于Spark里面的KV存储一样，把score和elements存得很整齐。 elements = c-&gt;argc-scoreidx; if (elements % 2 || !elements) &#123; addReply(c,shared.syntaxerr); return; &#125; elements /= 2; /* Now this holds the number of score-element pairs. */ /* Check for incompatible options. */ if (nx &amp;&amp; xx) &#123; addReplyError(c, "XX and NX options at the same time are not compatible"); return; &#125; if (incr &amp;&amp; elements &gt; 1) &#123; addReplyError(c, "INCR option supports a single increment-element pair"); return; &#125;... 下面，我们开始正式处理参数了123456789101112131415... // 取回输入的score，或者报错，注意这里是从用户的输入取的 // 可以看出，偶数位是分数，奇数位是字段值 scores = zmalloc(sizeof(double)*elements); for (j = 0; j &lt; elements; j++) &#123; if (getDoubleFromObjectOrReply(c,c-&gt;argv[scoreidx+j*2],&amp;scores[j],NULL) != C_OK) goto cleanup; &#125; // 从数据库中找到这个ZSET对象 zobj = lookupKeyWrite(c-&gt;db,key); // 检查是否是OBJ_ZSET类型 if (checkType(c,zobj,OBJ_ZSET)) goto cleanup; // 如果这个对象还没有被创建，就创建... 为了阅读接下来的代码，首先了解两个参数，可以看到，这两个参数就是规定了何时使用ziplist的阈值。上面两个指示了对zset而言，ziplist能用到什么时候，后面就是skiplist。下面两个指示对hash而言，ziplist能用到什么时候，后面就用dict。12345// config.ccreateSizeTConfig("zset-max-ziplist-value", NULL, MODIFIABLE_CONFIG, 0, LONG_MAX, server.zset_max_ziplist_value, 64, MEMORY_CONFIG, NULL, NULL),createSizeTConfig("zset-max-ziplist-entries", NULL, MODIFIABLE_CONFIG, 0, LONG_MAX, server.zset_max_ziplist_entries, 128, INTEGER_CONFIG, NULL, NULL)createSizeTConfig("hash-max-ziplist-entries", NULL, MODIFIABLE_CONFIG, 0, LONG_MAX, server.hash_max_ziplist_entries, 512, INTEGER_CONFIG, NULL, NULL)createSizeTConfig("hash-max-ziplist-value", NULL, MODIFIABLE_CONFIG, 0, LONG_MAX, server.hash_max_ziplist_value, 64, MEMORY_CONFIG, NULL, NULL) 然后我们来看一下两个对象的创建方法1234567891011121314151617robj *createZsetObject(void) &#123; zset *zs = zmalloc(sizeof(*zs)); robj *o; zs-&gt;dict = dictCreate(&amp;zsetDictType,NULL); zs-&gt;zsl = zslCreate(); o = createObject(OBJ_ZSET,zs); o-&gt;encoding = OBJ_ENCODING_SKIPLIST; return o;&#125;robj *createZsetZiplistObject(void) &#123; unsigned char *zl = ziplistNew(); robj *o = createObject(OBJ_ZSET,zl); o-&gt;encoding = OBJ_ENCODING_ZIPLIST; return o;&#125; 下面来看一下创建的逻辑，可以发现，在创建时默认是创建一个ziplist的，其实在后面zsetAdd添加的时候，当超出了ziplist的阈值的时候会调用zsetConvert来转成skiplist。1234567891011121314151617... if (zobj == NULL) &#123; if (xx) goto reply_to_client; /* No key + XX option: nothing to do. */ if (server.zset_max_ziplist_entries == 0 || server.zset_max_ziplist_value &lt; sdslen(c-&gt;argv[scoreidx+1]-&gt;ptr)) &#123; // 如果zset_max_ziplist_entries是0，也就是说不管怎么样都不会创建ziplist了， // 或者第一个要加入的元素就已经超长了 zobj = createZsetObject(); &#125; else &#123; // 否则还是先创建一个ziplist zobj = createZsetZiplistObject(); &#125; // 向db注册这个zobj dbAdd(c-&gt;db,key,zobj); &#125;... 下面，就是调用zsetAdd依次往ZSET里面添加元素了。123456789101112131415161718192021222324252627282930313233343536373839... for (j = 0; j &lt; elements; j++) &#123; double newscore; score = scores[j]; int retflags = flags; ele = c-&gt;argv[scoreidx+1+j*2]-&gt;ptr; int retval = zsetAdd(zobj, score, ele, &amp;retflags, &amp;newscore); if (retval == 0) &#123; addReplyError(c,nanerr); goto cleanup; &#125; // 这个应该是用来支持CH参数的 if (retflags &amp; ZADD_ADDED) added++; if (retflags &amp; ZADD_UPDATED) updated++; if (!(retflags &amp; ZADD_NOP)) processed++; score = newscore; &#125; server.dirty += (added+updated);reply_to_client: if (incr) &#123; /* ZINCRBY or INCR option. */ if (processed) addReplyDouble(c,score); else addReplyNull(c); &#125; else &#123; /* ZADD. */ // 如果指定了CH，就返回增加和修改的数量，否则只返回增加的数量 addReplyLongLong(c,ch ? added+updated : added); &#125;cleanup: zfree(scores); if (added || updated) &#123; signalModifiedKey(c,c-&gt;db,key); notifyKeyspaceEvent(NOTIFY_ZSET, incr ? "zincr" : "zadd", key, c-&gt;db-&gt;id); &#125;&#125; zsetAdd的实现zsetAdd在3.0版本里面，并没有这个函数，而是直接放到了zaddGenericCommand里面。但由于后续版本支持了各种flag（注意3.0是可以incr的），逻辑复杂了，所以单独做出了一个函数。1int zsetAdd(robj *zobj, double score, sds ele, int *flags, double *newscore) &#123; 首先来讨论一下参数，flags按照指针传递，是因为它同时用来保存输入信息和输出信息。1234567891011/* Input flags. */#define ZADD_NONE 0#define ZADD_INCR (1&lt;&lt;0) /* Increment the score instead of setting it. */#define ZADD_NX (1&lt;&lt;1) /* Don't touch elements not already existing. */#define ZADD_XX (1&lt;&lt;2) /* Only touch elements already existing. *//* Output flags. */#define ZADD_NOP (1&lt;&lt;3) /* Operation not performed because of conditionals.*/#define ZADD_NAN (1&lt;&lt;4) /* Only touch elements already existing. */#define ZADD_ADDED (1&lt;&lt;5) /* The element was new and was added. */#define ZADD_UPDATED (1&lt;&lt;6) /* The element already existed, score updated. */ newscore被用来存储返回的incr后的分数。下面我们来看函数的具体实现过程。1234567891011121314... /* Turn options into simple to check vars. */ int incr = (*flags &amp; ZADD_INCR) != 0; int nx = (*flags &amp; ZADD_NX) != 0; int xx = (*flags &amp; ZADD_XX) != 0; *flags = 0; /* We'll return our response flags. */ double curscore; /* NaN as input is an error regardless of all the other parameters. */ if (isnan(score)) &#123; *flags = ZADD_NAN; return 0; &#125;... ziplist存储的分支123456789101112131415161718192021222324252627282930313233343536373839404142434445464748... /* Update the sorted set according to its encoding. */ if (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123; unsigned char *eptr; if ((eptr = zzlFind(zobj-&gt;ptr,ele,&amp;curscore)) != NULL) &#123; // 如果已经找到了这个元素 /* NX? Return, same element already exists. */ if (nx) &#123; *flags |= ZADD_NOP; return 1; &#125; /* Prepare the score for the increment if needed. */ if (incr) &#123; score += curscore; if (isnan(score)) &#123; *flags |= ZADD_NAN; return 0; &#125; // 如果需要取回score的值，则newscore不为NULL，那么就顺便返回 if (newscore) *newscore = score; &#125; // 通过先删除再添加的方法来实现修改score if (score != curscore) &#123; zobj-&gt;ptr = zzlDelete(zobj-&gt;ptr,eptr); zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score); *flags |= ZADD_UPDATED; &#125; return 1; &#125; else if (!xx) &#123; // 如果没有找到，并且没有xx选项（xx选项表示只更新不添加），那么就进行添加 /* Optimize: check if the element is too large or the list * becomes too long *before* executing zzlInsert. */ zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score); // 如果超过阈值，就要转换成跳表 if (zzlLength(zobj-&gt;ptr) &gt; server.zset_max_ziplist_entries || sdslen(ele) &gt; server.zset_max_ziplist_value) zsetConvert(zobj,OBJ_ENCODING_SKIPLIST); if (newscore) *newscore = score; *flags |= ZADD_ADDED; return 1; &#125; else &#123; *flags |= ZADD_NOP; return 1; &#125;... 跳表存储的分支123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960... &#125; else if (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123; // 需要同时更新哈希表和跳表 zset *zs = zobj-&gt;ptr; zskiplistNode *znode; dictEntry *de; // 查看成员是否存在 de = dictFind(zs-&gt;dict,ele); if (de != NULL) &#123; // 如果成员存在 /* NX? Return, same element already exists. */ if (nx) &#123; *flags |= ZADD_NOP; return 1; &#125; // 取出成员的分值 // 其中de是dictEntry // #define dictGetKey(he) ((he)-&gt;key) // #define dictGetVal(he) ((he)-&gt;v.val) curscore = *(double*)dictGetVal(de); /* Prepare the score for the increment if needed. */ if (incr) &#123; score += curscore; if (isnan(score)) &#123; *flags |= ZADD_NAN; return 0; &#125; if (newscore) *newscore = score; &#125; /* Remove and re-insert when score changes. */ if (score != curscore) &#123; // 对于跳表来讲，就有一个单独的函数了，对于某些情况，能够原地更新，但对于特殊情况会先删除再加上 znode = zslUpdateScore(zs-&gt;zsl,curscore,ele,score); /* Note that we did not removed the original element from * the hash table representing the sorted set, so we just * update the score. */ dictGetVal(de) = &amp;znode-&gt;score; /* Update score ptr. */ *flags |= ZADD_UPDATED; &#125; return 1; &#125; else if (!xx) &#123; // 如果没有设置只更新不添加的机制 ele = sdsdup(ele); znode = zslInsert(zs-&gt;zsl,score,ele); serverAssert(dictAdd(zs-&gt;dict,ele,&amp;znode-&gt;score) == DICT_OK); *flags |= ZADD_ADDED; if (newscore) *newscore = score; return 1; &#125; else &#123; *flags |= ZADD_NOP; return 1; &#125; &#125; else &#123; serverPanic("Unknown sorted set encoding"); &#125; return 0; /* Never reached. */&#125; zsetConvert参数encoding表示要转换成什么格式。12345678void zsetConvert(robj *zobj, int encoding) &#123; zset *zs; zskiplistNode *node, *next; sds ele; double score; if (zobj-&gt;encoding == encoding) return;... 12345678910111213141516171819202122232425262728293031323334353637... if (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123; unsigned char *zl = zobj-&gt;ptr; unsigned char *eptr, *sptr; unsigned char *vstr; unsigned int vlen; long long vlong; if (encoding != OBJ_ENCODING_SKIPLIST) serverPanic("Unknown target encoding"); zs = zmalloc(sizeof(*zs)); zs-&gt;dict = dictCreate(&amp;zsetDictType,NULL); zs-&gt;zsl = zslCreate(); eptr = ziplistIndex(zl,0); serverAssertWithInfo(NULL,zobj,eptr != NULL); sptr = ziplistNext(zl,eptr); serverAssertWithInfo(NULL,zobj,sptr != NULL); while (eptr != NULL) &#123; score = zzlGetScore(sptr); serverAssertWithInfo(NULL,zobj,ziplistGet(eptr,&amp;vstr,&amp;vlen,&amp;vlong)); if (vstr == NULL) ele = sdsfromlonglong(vlong); else ele = sdsnewlen((char*)vstr,vlen); node = zslInsert(zs-&gt;zsl,score,ele); serverAssert(dictAdd(zs-&gt;dict,ele,&amp;node-&gt;score) == DICT_OK); zzlNext(zl,&amp;eptr,&amp;sptr); &#125; zfree(zobj-&gt;ptr); zobj-&gt;ptr = zs; zobj-&gt;encoding = OBJ_ENCODING_SKIPLIST;... 1234567891011121314151617181920212223242526272829... &#125; else if (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123; unsigned char *zl = ziplistNew(); if (encoding != OBJ_ENCODING_ZIPLIST) serverPanic("Unknown target encoding"); /* Approach similar to zslFree(), since we want to free the skiplist at * the same time as creating the ziplist. */ zs = zobj-&gt;ptr; dictRelease(zs-&gt;dict); node = zs-&gt;zsl-&gt;header-&gt;level[0].forward; zfree(zs-&gt;zsl-&gt;header); zfree(zs-&gt;zsl); while (node) &#123; zl = zzlInsertAt(zl,NULL,node-&gt;ele,node-&gt;score); next = node-&gt;level[0].forward; zslFreeNode(node); node = next; &#125; zfree(zs); zobj-&gt;ptr = zl; zobj-&gt;encoding = OBJ_ENCODING_ZIPLIST; &#125; else &#123; serverPanic("Unknown sorted set encoding"); &#125;&#125; zrangeGenericCommandzrangeGenericCommand主要处理ZRANGE命令。12345678910111213141516171819202122232425262728293031323334353637void zrangeGenericCommand(client *c, int reverse) &#123; robj *key = c-&gt;argv[1]; robj *zobj; int withscores = 0; long start; long end; long llen; long rangelen; if ((getLongFromObjectOrReply(c, c-&gt;argv[2], &amp;start, NULL) != C_OK) || (getLongFromObjectOrReply(c, c-&gt;argv[3], &amp;end, NULL) != C_OK)) return; if (c-&gt;argc == 5 &amp;&amp; !strcasecmp(c-&gt;argv[4]-&gt;ptr,"withscores")) &#123; withscores = 1; &#125; else if (c-&gt;argc &gt;= 5) &#123; addReply(c,shared.syntaxerr); return; &#125; if ((zobj = lookupKeyReadOrReply(c,key,shared.emptyarray)) == NULL || checkType(c,zobj,OBJ_ZSET)) return; /* Sanitize indexes. */ llen = zsetLength(zobj); if (start &lt; 0) start = llen+start; if (end &lt; 0) end = llen+end; if (start &lt; 0) start = 0; /* Invariant: start &gt;= 0, so this test will be true when end &lt; 0. * The range is empty when start &gt; end or start &gt;= length. */ if (start &gt; end || start &gt;= llen) &#123; addReply(c,shared.emptyarray); return; &#125; if (end &gt;= llen) end = llen-1; rangelen = (end-start)+1;... 通过start和end计算出需要取出的长度rangelen。123456789... /* Return the result in form of a multi-bulk reply. RESP3 clients * will receive sub arrays with score-&gt;element, while RESP2 returned * a flat array. */ if (withscores &amp;&amp; c-&gt;resp == 2) addReplyArrayLen(c, rangelen*2); else addReplyArrayLen(c, rangelen);... 对于ziplist的实现123456789101112131415161718192021222324252627282930313233... if (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123; unsigned char *zl = zobj-&gt;ptr; unsigned char *eptr, *sptr; unsigned char *vstr; unsigned int vlen; long long vlong; if (reverse) eptr = ziplistIndex(zl,-2-(2*start)); else eptr = ziplistIndex(zl,2*start); serverAssertWithInfo(c,zobj,eptr != NULL); sptr = ziplistNext(zl,eptr); while (rangelen--) &#123; serverAssertWithInfo(c,zobj,eptr != NULL &amp;&amp; sptr != NULL); serverAssertWithInfo(c,zobj,ziplistGet(eptr,&amp;vstr,&amp;vlen,&amp;vlong)); if (withscores &amp;&amp; c-&gt;resp &gt; 2) addReplyArrayLen(c,2); if (vstr == NULL) addReplyBulkLongLong(c,vlong); else addReplyBulkCBuffer(c,vstr,vlen); if (withscores) addReplyDouble(c,zzlGetScore(sptr)); if (reverse) zzlPrev(zl,&amp;eptr,&amp;sptr); else zzlNext(zl,&amp;eptr,&amp;sptr); &#125;... 对于跳表的实现，通过zslGetElementByRank获得我们要遍历的起点ln。在摘到之后，我们直接移动backward指针，或者最底层的forward指针，取出rangelen的元素。所以对于面试日经题目，跳表的zrange复杂度是多少？答案就是O(log(n)+rangelen)。123456789101112131415161718192021222324252627282930... &#125; else if (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123; zset *zs = zobj-&gt;ptr; zskiplist *zsl = zs-&gt;zsl; zskiplistNode *ln; sds ele; /* Check if starting point is trivial, before doing log(N) lookup. */ if (reverse) &#123; ln = zsl-&gt;tail; if (start &gt; 0) ln = zslGetElementByRank(zsl,llen-start); &#125; else &#123; ln = zsl-&gt;header-&gt;level[0].forward; if (start &gt; 0) ln = zslGetElementByRank(zsl,start+1); &#125; while(rangelen--) &#123; serverAssertWithInfo(c,zobj,ln != NULL); ele = ln-&gt;ele; if (withscores &amp;&amp; c-&gt;resp &gt; 2) addReplyArrayLen(c,2); addReplyBulkCBuffer(c,ele,sdslen(ele)); if (withscores) addReplyDouble(c,ln-&gt;score); ln = reverse ? ln-&gt;backward : ln-&gt;level[0].forward; &#125; &#125; else &#123; serverPanic("Unknown sorted set encoding"); &#125;&#125; zskiplistzskiplist是跳表，Redis用它来作为有序集合ZSET的一个实现。跳表的查找复杂度是平均$O(log n)$最坏$O(n)$，而插入/删除复杂度是$O(log n)$。 基本数据结构跳表的结构如下所示 结构定义如下所示。123456789typedef struct zskiplistNode &#123; sds ele; double score; struct zskiplistNode *backward; struct zskiplistLevel &#123; struct zskiplistNode *forward; unsigned long span; &#125; level[];&#125; zskiplistNode; 容易看到，这里的level是一个Flex Array，这是C99里面的特性，实际上是一个长度为0的数组。 跳表里面的一个元素，对应一个zskiplistNode。每个zskiplistNode可能有若干个zskiplistLevel，从而组成跳表的层次结构。 backward 这个指针是一个zskiplistNode一个的，指向最下面一层的前一个节点。 zskiplistLevel::forward 每一层都有一个，指向当前层的下一个节点。层数越往上，zskiplistLevel::span越大。 span span表示当前节点当前层的后向(forward)指针跨越了多少节点。对于最下面一层，它的span就是1。如果在某一层上，forward相对对下面一层跳过了一个节点，那么span就是2。 这个值对跳表实现不是必要的，增加它是为了方便计算rank[i]。 rank是为了实现zsetRank设置的。【Q】一个问题是为什么需要用rank[i]数组。这个我加日志打印了一下，发现这反映了插入新Node时，我们插入到的是update[i]的后面，而rank[i]就表示这个update[i]到链表头的距离。 考虑zslInsert，我们要插入下面两行 123zadd y 1.0 a 2.0 b 3.0 c 4.0 d 5.0 e 6.0 fzadd y 4.5 dezadd y 3.5 cd 检查插入cd前的行为。对于4/5层来说，d前面都没有该层节点了，所以rank都是0。同时可以注意到，因为最底层(第0层)永远表示待插入的节点前面有多少个。 1234567891011121314rank[0]=3rank[1]=3rank[2]=3rank[3]=3rank[4]=0rank[5]=0SUMMARY: tot level 6( )[S: 1] ( a)[S: 1] ( b)[S: 1] ( c)[S: 1] ( d)[S: 1] ( de)[S: 1] ( e)[S: 1] ( f)[S: 0] ( )[S: 2] .............( b)[S: 1] ( c)[S: 1] ( d)[S: 3] ..........................( f)[S: 0] ( )[S: 3] ..........................( c)[S: 1] ( d)[S: 3] ( )[S: 3] ..........................( c)[S: 1] ( d)[S: 3] ( )[S: 4] .......................................( d)[S: 3] ( )[S: 4] .......................................( d)[S: 3] node_len 13 zslCreateNode我们进一步查看zslCreateNode是如何被初始化的，容易看出，它的空间占用等于zskiplistNode的大小，加上level的长度乘以zskiplistLevel的大小。12345678// t_zset.czskiplistNode *zslCreateNode(int level, double score, sds ele) &#123; zskiplistNode *zn = zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel)); zn-&gt;score = score; zn-&gt;ele = ele; return zn;&#125; 跳表数据结构的展现下面的代码可以轻松地打印出zskiplist的结构。123456789101112131415161718192021222324252627282930313233343536373839404142void printZsl(zskiplist *zsl)&#123; int tot_level = zsl-&gt;level; int node_len = 0; int join_size = 2; char buf[1000]; printf("SUMMARY: tot level %d\n", tot_level); for(int level = 0; level &lt; tot_level; level++)&#123; zskiplistNode * prev = 0; zskiplistNode * x = zsl-&gt;header; while(1) &#123; int gap = 0; if(level &amp;&amp; prev)&#123; zskiplistNode * y = prev; while (1) &#123; if(y-&gt;ele != x-&gt;ele) &#123; gap ++; &#125;else&#123; break; &#125; if(y-&gt;level[0].forward) y = y-&gt;level[0].forward; else break; &#125; int length = (gap - 1) * node_len; int modified_length = length &lt;= 0 ? 0 : length; for(int kk = 0; kk &lt; modified_length; kk++) printf("."); &#125; sprintf(buf, "(%3.3s)[S:%2ld]%*s", x-&gt;ele, x-&gt;level[level].span, join_size, " "); if(node_len == 0) node_len = strlen(buf); printf(buf); prev = x; if(x-&gt;level[level].forward) x = x-&gt;level[level].forward; else break; &#125; printf("\n"); &#125; printf("node_len %d\n", node_len);&#125; 我们修改zslInsert代码，并输入下面的语句，为了便于得到更高的跳表，我们设置ZSKIPLIST_P到0.5（参考下文）。1zadd zs2 1 a 2 b 10 c 5 d 5 e 6 f1 6 f2 6 f3 6 f4 6 f5 6 f6 6 f7 6 f8 6 f9 6 f10 6 f11 得到打印的结果如下（这里输出是反的，第0层实际上是“最下面一层”，也就是最密集的那一层）123456789SUMMARY: tot level 7( )[S: 1] ( a)[S: 1] ( b)[S: 1] ( d)[S: 1] ( e)[S: 1] ( f1)[S: 1] (f10)[S: 1] ( f2)[S: 1] ( f3)[S: 1] ( f4)[S: 1] ( f5)[S: 1] ( f6)[S: 1] ( f7)[S: 1] ( f8)[S: 1] ( f9)[S: 1] ( c)[S: 0] ( )[S: 1] ( a)[S: 1] ( b)[S: 1] ( d)[S: 1] ( e)[S: 2] .............(f10)[S: 1] ( f2)[S: 5] ....................................................( f7)[S: 1] ( f8)[S: 2] ( )[S: 1] ( a)[S: 1] ( b)[S: 1] ( d)[S: 4] .......................................( f2)[S: 5] ....................................................( f7)[S: 1] ( f8)[S: 2] ( )[S: 2] .............( b)[S: 1] ( d)[S: 4] .......................................( f2)[S: 6] .................................................................( f8)[S: 2] ( )[S: 2] .............( b)[S: 1] ( d)[S: 4] .......................................( f2)[S: 8] ( )[S: 2] .............( b)[S: 1] ( d)[S:12] ( )[S: 2] .............( b)[S:13] node_len 13 可以比较容易得看出： header节点是空的 span表示当前层上相邻两个节点的实际距离。对于level 0来说，相邻两个节点的实际距离一定为1 zslInsert的实现跳表遍历抽象主干代码我们首先看到的是跳表遍历抽象的主干代码，它会在很多地方重复出现。这段代码的含义是计算update[i]和rank[i]。123456789101112131415161718192021222324252627282930313233zskiplistNode *zslInsert(zskiplist *zsl, double score, sds ele) &#123; // 表示我们在第i层的第update[i]节点后面，插入新节点 zskiplistNode *update[ZSKIPLIST_MAXLEVEL]; // 这是一个临时变量，前期做迭代用，后期表示新节点 zskiplistNode *x; unsigned int rank[ZSKIPLIST_MAXLEVEL]; int i, level; serverAssert(!isnan(score)); // x是表头节点 x = zsl-&gt;header; // 从最高层节点（跨度最大）逐层向下遍历，这样方便复用，稍后将看到我们新增节点的时候是从下往上构建的 for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* store rank that is crossed to reach the insert position */ // 最终rank[0]的值加一就是新节点的前置节点(update)的排位 rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1]; while (x-&gt;level[i].forward &amp;&amp; // 如果要插入的score，比前面节点的score还要大，就前进 (x-&gt;level[i].forward-&gt;score &lt; score || // 如果score相等，那么就比较ele (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) &#123; // x-&gt;level[i].span表示第i层上，当前节点到forward节点的中间有多少个节点，比如这是第t个节点，那么经过了a_&#123;t+1&#125; – a&#123;t&#125;个节点。 // rank[i]表示这个节点排第几 rank[i] += x-&gt;level[i].span; // 前进节点 x = x-&gt;level[i].forward; &#125; // 对于第i层，我们要修改这个节点，它是score最大的小于要插入的x的节点 update[i] = x; &#125;... 在以上的代码执行完之后，我们得到了计算好的update和rank数组。我们要在update[i]后面插入节点，并且用rank[i]来更新span。在这里，我们假设元素没有在跳表中，这是因为： 跳表是通过score排序的，而score是允许重复的，所以无法通过score来判断。 而在跳表中插入相同的元素是不可能的情况，因为zslInsert的调用者通过dict来维护是否有相同元素。 在插入新节点前，首先需要为这个节点生成一个随机层高，同时处理这个随机层高大于现有层高的情况。1234567891011121314151617// 续zslInsert... level = zslRandomLevel(); if (level &gt; zsl-&gt;level) &#123; // 如果新节点的level比这个跳表的最大层数zsl-&gt;level都大，即出现一个珠穆朗玛峰了， // 初始化一下zsl-&gt;level以上的所有的层 for (i = zsl-&gt;level; i &lt; level; i++) &#123; // 这里是初始化一下rank，方便后面往上加span rank[i] = 0; update[i] = zsl-&gt;header; update[i]-&gt;level[i].span = zsl-&gt;length; &#125; // 更新跳表的最大层数 zsl-&gt;level = level; &#125;...// 函数待续 zslRandomLevel生成待插入节点的随机高度。12345678910// t_zset.cint zslRandomLevel(void) &#123; int level = 1; while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125;// server.h#define ZSKIPLIST_P 0.25 /* Skiplist P = 1/4 */ 下面就是将新增的节点插入跳表中。新链表的前后顺序是update -&gt; x -&gt; update.forward 12345678910// 续zslInsert... // 主要就是分配一个zskiplistNode，并且设置score和ele。 x = zslCreateNode(level,score,ele); for (i = 0; i &lt; level; i++) &#123; // 更新x前向指针 x-&gt;level[i].forward = update[i]-&gt;level[i].forward; // 更新update前向指针 update[i]-&gt;level[i].forward = x;... 下面我们的目标是计算x-&gt;level[i].span。从前面介绍过了，span表示当前节点当前层的后向指针跨越了多少节点。由于x被插到了中间，所以需要更新x和update的span。对于x而言，它继承了update的span的后半部分，即+号覆盖的部分，这个后半部分的长度等于总span的长度减去从update到x的span。12插入前 update-------------update.forward插入后 update x++++++update.forward 下面这个公式，有点愣神了。为了方便理解，不如先看i=0的情况。1x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]); 计算x最下层的span，即x-&gt;level[0].span 结果是update[i]-&gt;level[i].span。这是因为x是紧插到update后面的，这样会导致x实际上继承了update的span。 计算update最下层的span，即update[0]-&gt;level[0].span 结果是rank[0]-rank[0]+1=1。这是因为update紧后面就是x了，所以这里的1就表示跨越到x节点的距离。 那么，往回看到i取任意值的情况： 计算x-&gt;level[i].span 计算update[i]-&gt;level[i].span 从前面的讨论中，我们可以知道rank[0]表示第0层中，待插入节点x前面有多少个节点。 同理rank[i]表示在第i层中，待插入节点x前面有多少个节点。 那么(rank[0] - rank[i]) + 1就是第i层上，update[i]和x中间有多少个节点。 1234567891011121314151617181920... // 计算对于新增节点而言，它第i层的span x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]); update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1; &#125; // 在level层及之上，新节点x是没有对应的节点的，所以span要自增。 for (i = level; i &lt; zsl-&gt;level; i++) &#123; update[i]-&gt;level[i].span++; &#125; // 新节点的前向节点始终是update[0]，也就是最底层的前驱 x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0]; if (x-&gt;level[0].forward) x-&gt;level[0].forward-&gt;backward = x; else zsl-&gt;tail = x; zsl-&gt;length++; return x;&#125; zslGetRank实现注意Rank是从1开始算的。这里实现还是一个经典的二层循环。1234567891011121314151617181920212223242526/* Find the rank for an element by both score and key. * Returns 0 when the element cannot be found, rank otherwise. * Note that the rank is 1-based due to the span of zsl-&gt;header to the * first element. */unsigned long zslGetRank(zskiplist *zsl, double score, sds ele) &#123; zskiplistNode *x; unsigned long rank = 0; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt;= 0))) &#123; rank += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; /* x might be equal to zsl-&gt;header, so test if obj is non-NULL */ if (x-&gt;ele &amp;&amp; sdscmp(x-&gt;ele,ele) == 0) &#123; return rank; &#125; &#125; return 0;&#125; zslUpdateScore的实现123456789101112131415161718192021222324zskiplistNode *zslUpdateScore(zskiplist *zsl, double curscore, sds ele, double newscore) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i; /* We need to seek to element to update to start: this is useful anyway, * we'll have to update or remove it. */ x = zsl-&gt;header; // 参考zslInsert，主要是为了取得update和x for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; curscore || (x-&gt;level[i].forward-&gt;score == curscore &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) &#123; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; /* Jump to our element: note that this function assumes that the * element with the matching score exists. */ x = x-&gt;level[0].forward; serverAssert(x &amp;&amp; curscore == x-&gt;score &amp;&amp; sdscmp(x-&gt;ele,ele) == 0);... 在下面几种情况下，可以不进行先删除再添加的操作，而只是更新score： 如果是第一个节点，或者前面的节点的分数比新分数要小。 或者是最后一个节点（必须最下层），或者后面的节点的分数比新分数要大。 12345678... if ((x-&gt;backward == NULL || x-&gt;backward-&gt;score &lt; newscore) &amp;&amp; (x-&gt;level[0].forward == NULL || x-&gt;level[0].forward-&gt;score &gt; newscore)) &#123; x-&gt;score = newscore; return x; &#125;... 在更通用的情况下，我们只能删除原节点x，并且重新插入新节点。12345678910... /* No way to reuse the old node: we need to remove and insert a new * one at a different place. */ zslDeleteNode(zsl, x, update); zskiplistNode *newnode = zslInsert(zsl,newscore,x-&gt;ele); // 这里复用原节点的ele字段，所以置为NULL，防止被delete x-&gt;ele = NULL; zslFreeNode(x); return newnode;&#125; zslGetElementByRank的实现这个函数作用是获得的元素，被用来处理跳表对zrange的实现。这里的rank是从1开始的。此外还有个zsetRank，用来获得元素从0开始的RANK。 这里的遍历，其实和经典的遍历类似。我们从最高层尝试往右移动指针，一旦我们发现移动过头了，我们就转而下沉一层。12345678910111213141516171819/* Finds an element by its rank. The rank argument needs to be 1-based. */zskiplistNode* zslGetElementByRank(zskiplist *zsl, unsigned long rank) &#123; zskiplistNode *x; unsigned long traversed = 0; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (traversed + x-&gt;level[i].span) &lt;= rank) &#123; traversed += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; if (traversed == rank) &#123; return x; &#125; &#125; return NULL;&#125; ziplistziplist是一个比较神奇的结构，通常被用在ZSET和HASH等结构上面。首先我们解释一下它的名字 zip 说明ziplist是压缩的，空间优化的。那么既然优化了空间，时间可能就会受损。 list 说明ziplist是一个双向链表，可以存储SDS和整数。 那么，ziplist优化在哪里呢？ ziplist整体是连续分配的 虽然作为一个链表存在，但它的内存是一次性连续分配的。 因为连续分配，所以ziplist省去了前向指针 可以根据这个entry的encoding，直接算出来下一个元素的offset。 ziplist节约了后向指针的大小 因为只是指定了后向指针的偏移。 格式与创建首先，分配了头部和尾部的空间12345// ziplist.c/* Create a new empty ziplist. */unsigned char *ziplistNew(void) &#123; unsigned int bytes = ZIPLIST_HEADER_SIZE+ZIPLIST_END_SIZE; unsigned char *zl = zmalloc(bytes); 那么头部和尾部究竟是什么呢？头部包含了32位的int，表示总长度；32位的int表示最后一个元素的offset。16位表示item的数量。在头部保存尾部指针的实现逻辑在链表中是非常常见的，这使得查找尾部的操作是$O(1)$的。1#define ZIPLIST_HEADER_SIZE (sizeof(uint32_t)*2+sizeof(uint16_t)) 尾部有一个”end of ziplist” entry，它是一个值为255的byte，表示结束。不过为什么需要这个ZIP_END来表示结束呢？也许是为了遍历的方便，那么在这里我们就能猜测到ziplist里面的元素肯定是经过特殊编码的，255这个编码表示结束，没有第二个编码长这样。12/* Size of the "end of ziplist" entry. Just one byte. */#define ZIPLIST_END_SIZE (sizeof(uint8_t)) 这两个宏可以取头和尾12345/* Return total bytes a ziplist is composed of. */#define ZIPLIST_BYTES(zl) (*((uint32_t*)(zl)))/* Return the offset of the last item inside the ziplist. */#define ZIPLIST_TAIL_OFFSET(zl) (*((uint32_t*)((zl)+sizeof(uint32_t)))) 下面继续看实现，我们可以看到，ziplist的大小是包括了头和尾的大小的1234567... ZIPLIST_BYTES(zl) = intrev32ifbe(bytes); ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(ZIPLIST_HEADER_SIZE); ZIPLIST_LENGTH(zl) = 0; zl[bytes-1] = ZIP_END; return zl;&#125; 格式下面我们来看看ziplist的编码格式 00xxxxxx xxxxxx表示字符串的位数，最大长度63。 01xxxxxx xxxxxxxx xxxxxx xxxxxxxx(14个x)表示字符串的长度。 10000000 aaaaaaaa bbbbbbbb cccccccc dddddddd 从a到d表示字符串的长度。 11000000 int16 11010000 int32 11100000 int64 11110000 int24 11111110 int8 11111111 ZIP_END是255表示结束。 1111xxxx xxxx的范围只能是(0001~1101), 也就是1~13。 因为int8和EOF占了14和15的情况。 HyperLogLogHyperLogLog算法主要用在基数统计中，也就是能用很小的内存占用统计出集合的大小。在Redis中，只需要大概12KB的内存就能够统计接近2**64个不同元素的基数。HyperLogLog算法是对LogLog算法的改进。包括LogLog Counting采用的算数/几何平均数对离群值（比如0）更敏感，而HyperLogLog采用了调和平均。这里的LogLog指的是算法复杂度是$O(log(log(N_{max})))$ HLL原理HLL通过一个哈希函数把输入x映射到一个bitset上，然后对这个bitset进行考察。考虑bitset长度为4，那么出现0001这样的结果的概率是1/16，也就是说平均要抛16次才能得到。在对数字的二进制表示进行采样的过程中，我们认为有一半的数字是以1开头的，另一半是以0开头的。同理，有1/4的数字是以01开头的，1/8以001开头的。那么在一个随机流中，我们恰恰发现一个001开头的，那么至少这个集合有8个元素。我们可以进行推广，考虑长度为L的bitset，那么前k-1项都为0，而第k项为1的概率，根据二项分布是$1/2^k$。因此我们就可以通过统计bitset中第一个1出现的位置来估算数量。具体来说，我们把一批元素通过哈希函数处理成一系列bitset并放入一个桶里面，然后我们统计这个桶里面1出现的位置的最大值。我们假设最左端是第1位，那么假如第一个1出现的位置的最大值是在第$m$位，那么集合中就有$2^m$个元素。为了提高精度，实际上可以使用多个桶而不是一个桶来进行统计，但在Redis中使用了一个分桶的技巧，也就是说给定一个序号$b$，将bitset中小于$b$的所有位数bitset[0..(b-1)]决定桶的序号。那么最终就能够得到这$2^b$个桶中的预估元素个数$2^{m_i}$。HLL使用调和平均数来计算每个桶元素的个数，令$B = 2^b$，表示总的桶数。那么计算$A$就是平均每个桶里面的元素个数。 $$A = \frac{B}{\sum_{i=1}^{B}{2^{-m_i}}} = \frac{B}{\sum_{i=1}^{B}{ \frac{1}{2^{m_i}} }}$$ 那总元素的个数就是$AB$。 在实际操作的时候，发现有一个问题，例如有的桶直接就是0，也就是说没有出现一个1，对这种情况我们如何处理呢？或者说，我们认为这表示这个集合的值是比001这样的小还是大呢？我觉得，其实应该认为这个集合是远远大于001的，事实上集合的大小至少应该等于10...0（共有len(bitset)个0）。形象一点，这里都是0的原因是因为真正的1其实还在更前面！所以在计算的时候，0...00和0...01表示的值之间就会存在一个很大的落差，不知道我理解是否正确。 最后，我们得到的$AB$其实不准确，还需要进行修正。 Redis的HLL的基本结构1234567struct hllhdr &#123; char magic[4]; /* "HYLL" */ uint8_t encoding; /* HLL_DENSE or HLL_SPARSE. */ uint8_t notused[3]; /* Reserved for future use, must be zero. */ uint8_t card[8]; /* Cached cardinality, little endian. */ uint8_t registers[]; /* Data bytes. */&#125;; 首先是encoding，它的取值是HLL_DENSE和HLL_SPARSE，分别对应Dense存储模式和Sparse存储模式，这两个存储模式是Redis的HLL实现的一个精妙的部分，用来节省存储空间。此外，在内部还会有一个HLL_RAW的模式，这个只在pfcount上用到，并且不对外暴露。Dense模式就是经典的HLL算法，其中registers大概占据了12KB的大小。容易看到，这个空间占用还是比较大的，考虑到这里面大多数都是0，所以Redis又使用了Sparse模式。Sparse模式是创建时默认的，实际上不会占用12KB的大小，主要用来表达连续多个桶的值为0的情况，也就是用CPU换存储。它使用下面三种编码方式： XZERO：格式为01xxxxxx yyyyyyyy 这个能表示最多的0形态。初始化之后，因为一个数都没有加入HLL中，就使用XZERO，占用两个字节。 前面的6个x叫Most Signigicent Bits(MSB)，后面8个y叫Least Significant Bits(LSB)。所以可以表示16384个0，这也对应了后面提到的HLL_SPARSE_XZERO_MAX_LEN这个宏的取值，刚好等于HLL_REGISTERS的值。 ZERO：格式为00xxxxxx ZERO能表示的0比XZERO要少，但只占用一个字节，所以能表示较少的0。 表示xxxxxx+1个0，所以实际上能够表示最多64个0。 VAL：格式为1vvvvvxx 当HLL开始进一步稠密时，就可能出现VAL这种情况。 5个v表示重复的计数值，2个x表示重复的桶的数量，也就是说有连续xx+1(&lt;4)个桶的值都是vvvvv+1(&lt;32)。 变换为Dense 注意，当VAL也无法描述时，例如某一段重复的桶的数量超过4了，那么就要变换为Dense。同理当出现超过32的值之后，就会切换为Dense模式。 createHLLObject实现1234567// hyperloglog.c#define HLL_P 14#define HLL_HDR_SIZE sizeof(struct hllhdr)#define HLL_SPARSE_XZERO_MAX_LEN 16384#define HLL_REGISTERS (1&lt;&lt;HLL_P) /* With P=14, 16384 registers. */#define HLL_P_MASK (HLL_REGISTERS-1) /* Mask to index register. */ 先说一下这几个常数，HLL_REGISTERS表示有多少个桶，默认HLL_P取14，实际上就是有16384个桶（对应到registers）。HLL_P_MASK可以通过&amp;来取出实际桶的序号。由于创建的HLL结构中每个桶的值都是0，所以默认肯定是Sparse存储省空间。现在需要手动构造一下。首先分配sparselen的空间，包括： HLL_HDR_SIZE也就是HLL头部的大小 register的空间 $$\frac{(HLL\_REGISTERS+(HLL\_SPARSE\_XZERO\_MAX\_LEN-1))}{HLL\_SPARSE\_XZERO\_MAX\_LEN} * 2$$这个公式看起来很奇怪，但是$\frac{X + (Y-1)}{Y}$实际上是向上取整的常规操作，所以说实际上要做的就是算出$$\lceil \frac{HLL\_REGISTERS}{HLL\_SPARSE\_XZERO\_MAX\_LEN} \rceil * 2$$ 所以这就好理解了，总共有多少个桶，然后除以每个XZERO opcode能放存多少个桶，最后乘以2，因为每个XZERO占用两个bytes。而一个HLL_SPARSE_XZERO_MAX_LEN能表示16384个桶，这在上文已经讲解过了，刚好等于HLL_REGISTERS的值，因此实际上一开始所有register用两个bytes就完全可以cover了。打印下来发现sparselen为18，HLL_HDR_SIZE是16，所以确实一开始register只用了两个字节。 1234567891011robj *createHLLObject(void) &#123; robj *o; struct hllhdr *hdr; sds s; uint8_t *p; int sparselen = HLL_HDR_SIZE + (((HLL_REGISTERS+(HLL_SPARSE_XZERO_MAX_LEN-1)) / HLL_SPARSE_XZERO_MAX_LEN)*2); printf("sparselen %d HLL_HDR_SIZE %d\n", sparselen, HLL_HDR_SIZE); int aux;... 分配完空间，下面就是要初始化，具体做法就是调用HLL_SPARSE_XZERO_SET每两个字节set一下。123456789101112131415... /* Populate the sparse representation with as many XZERO opcodes as * needed to represent all the registers. */ aux = HLL_REGISTERS; s = sdsnewlen(NULL,sparselen); p = (uint8_t*)s + HLL_HDR_SIZE; while(aux) &#123; int xzero = HLL_SPARSE_XZERO_MAX_LEN; if (xzero &gt; aux) xzero = aux; HLL_SPARSE_XZERO_SET(p,xzero); p += 2; aux -= xzero; &#125; serverAssert((p-(uint8_t*)s) == sparselen);... 可以看到，实际上HLL是一个String对象。Redis中的String是可以存储二进制序列的，而不局限于是字符串。12345678... /* Create the actual object. */ o = createObject(OBJ_STRING,s); hdr = o-&gt;ptr; memcpy(hdr-&gt;magic,"HYLL",4); hdr-&gt;encoding = HLL_SPARSE; return o;&#125; pfadd实现如果没有，就新创建一个HLL对象12345678910111213141516// server.c/* PFADD var ele ele ele ... ele =&gt; :0 or :1 */void pfaddCommand(client *c) &#123; robj *o = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]); struct hllhdr *hdr; int updated = 0, j; if (o == NULL) &#123; /* Create the key with a string value of the exact length to * hold our HLL data structure. sdsnewlen() when NULL is passed * is guaranteed to return bytes initialized to zero. */ o = createHLLObject(); dbAdd(c-&gt;db,c-&gt;argv[1],o); updated++;... 否则，调用dbUnshareStringValue确保对象o能够被原地进行修改。123456... &#125; else &#123; if (isHLLObjectOrReply(c,o) != C_OK) return; o = dbUnshareStringValue(c-&gt;db,c-&gt;argv[1],o); &#125;... 根据dbUnshareStringValue的注释，一个对象是可以被修改的，除非： 它是被shared的，即refcount &gt; 1 它的encoding不是RAW 如果有对象是满足上面两个条件的，那么会存入这个string对象的一个unshared/not-encoded的副本，否则直接返回这个对象o。我们可以查看下面的实现。12345678910robj *dbUnshareStringValue(redisDb *db, robj *key, robj *o) &#123; redisAssert(o-&gt;type == REDIS_STRING); if (o-&gt;refcount != 1 || o-&gt;encoding != REDIS_ENCODING_RAW) &#123; robj *decoded = getDecodedObject(o); o = createRawStringObject(decoded-&gt;ptr, sdslen(decoded-&gt;ptr)); decrRefCount(decoded); dbOverwrite(db,key,o); &#125; return o;&#125; 下面就是对于所有要添加的项目调用hllAdd，这和前面的zaddGenericCommand等命令很相似。12345678910111213141516... /* Perform the low level ADD operation for every element. */ for (j = 2; j &lt; c-&gt;argc; j++) &#123; int retval = hllAdd(o, (unsigned char*)c-&gt;argv[j]-&gt;ptr, sdslen(c-&gt;argv[j]-&gt;ptr)); switch(retval) &#123; case 1: updated++; break; case -1: addReplySds(c,sdsnew(invalid_hll_err)); return; &#125; &#125; hdr = o-&gt;ptr;... 下面的话同样会调用signalModifiedKey和notifyKeyspaceEvent进行通知，参考之前的讲解。有趣的是这个HLL_INVALIDATE_CACHE，它涉及了cache的机制，我们将在稍后讲解。123456789... if (updated) &#123; signalModifiedKey(c,c-&gt;db,c-&gt;argv[1]); notifyKeyspaceEvent(NOTIFY_STRING,"pfadd",c-&gt;argv[1],c-&gt;db-&gt;id); server.dirty++; HLL_INVALIDATE_CACHE(hdr); &#125; addReply(c, updated ? shared.cone : shared.czero);&#125; 下面的是主要的hddAdd实现，主要分为Dense和Sparse两种12345678int hllAdd(robj *o, unsigned char *ele, size_t elesize) &#123; struct hllhdr *hdr = o-&gt;ptr; switch(hdr-&gt;encoding) &#123; case HLL_DENSE: return hllDenseAdd(hdr-&gt;registers,ele,elesize); case HLL_SPARSE: return hllSparseAdd(o,ele,elesize); default: return -1; /* Invalid representation. */ &#125;&#125; pfadd的Dense实现hllDenseAdd函数主要在HLL结构中“插入”一个元素，事实上并没有什么元素被加上，只是说在需要的时候自增一下这个哈希值所属的max 0 pattern counter。 hllPatLen首先，通过hllPatLen计算ele的哈希，并从哈希值获得桶的序号index，并且把这个哈希值里面第一个1出现的位置count返回（具体含义见下面说明，这里难以理解的是到底从左边数还是从右边数。。。）。需要注意的是，我们并不需要实际的哈希值。123456int hllDenseAdd(uint8_t *registers, unsigned char *ele, size_t elesize) &#123; long index; uint8_t count = hllPatLen(ele,elesize,&amp;index); /* Update the register if this element produced a longer run of zeroes. */ return hllDenseSet(registers,index,count);&#125; 为了更方便进行调试，我们将createHLLObject中新对象的创建默认改为HLL_DENSE，并加上一系列调试语句，来观察行为。1234567891011121314151617void format_binary(uint64_t x, char *buf)&#123; int i = 0; while(x)&#123; char b = x % 2; buf[i] = b + '0'; x /= 2; i++; &#125; int m = i / 2; for(int j = 0; j &lt; m; j++)&#123; char tmp = buf[j]; buf[j] = buf[i - 1 - j]; buf[i - 1 - j] = tmp; &#125; buf[i] = '\0';&#125; 但是单纯这样改会有问题，当第二次调用pfadd时会报错WRONGTYPE Key is not a valid HyperLogLog string value，原因是下面的语句检查不通过。12345int isHLLObjectOrReply(client *c, robj *o) &#123;... if (hdr-&gt;encoding == HLL_DENSE &amp;&amp; stringObjectLen(o) != HLL_DENSE_SIZE) goto invalid;... 所以比较好的做法是在createHLLObject最后直接调用hllSparseToDense(o);。下面，我们就来查看hllPatLen的实现。首先，它基于MurmurHash64A算得哈希值hash，并且得到所在的桶(register)的编号index。容易知道，这个index的取值是在[0, 2**HLL_P=16384)之间的，这也对应了桶的数量。12345678910111213/* Given a string element to add to the HyperLogLog, returns the length * of the pattern 000..1 of the element hash. As a side effect 'regp' is * set to the register index this element hashes to. */int hllPatLen(unsigned char *ele, size_t elesize, long *regp) &#123; uint64_t hash, bit, index; int count; hash = MurmurHash64A(ele,elesize,0xadc83b19ULL); index = hash &amp; HLL_P_MASK; /* Register index. */ char s[100]; format_binary(hash, s); printf("Raw hash %s\n", s); 接着，将表示桶的P位移出，开始对剩下的64-HLL_P=50位进行原始的HLL算法。这里有一个优化点，就是将最高位设为1，防止死循环，这样的话返回值count最大为Q+1，也就是51。这样做的目的也是顺应了前面提到的全是0的情况。12345678... hash &gt;&gt;= HLL_P; /* Remove bits used to address the register. */ format_binary(hash, s); printf("P-shift hash %llx %s\n", hash, s); hash |= ((uint64_t)1&lt;&lt;HLL_Q); format_binary(hash, s); printf("Q-set hash %llx %s\n", hash, s);... 从第HLL_REGISTERS位开始计算0的数量，也就是从低位往高位找，最多运行64-P+1=Q+1位。所以可以看出这里和HLL的原算法还是有点不同的，原算法是找leftmost 1，而现在的实现是找right most 1。TODO 这里需要进一步确认下。根据注释，需要注意的是结尾的1也要被算在计数里面，例如”001”的count是3；count的最小值是1，此时没有前导0。这个循环看上去很没有效率，但在平均情况下在很少的迭代之后就能找到一个1。1234567891011121314... bit = 1; count = 1; /* Initialized to 1 since we count the "00000...1" pattern. */ while((hash &amp; bit) == 0) &#123; format_binary(bit, s); printf("while bit %s count %d\n", s, count); count++; bit &lt;&lt;= 1; &#125; format_binary(bit, s); printf("while end bit %s count %d\n", s, count); *regp = (int) index; return count;&#125; 下面打印了pfadd p1 a的执行结果12345Raw hash 101001111010010010001110000101010011011010000111011000110100111P-shift hash 14f491c2a6d0e 1010011110100100100011100001010100110110100001110Q-set hash 54f491c2a6d0e 101010011110100100100011100001010100110110100001110while bit 1 count 1while end bit 10 count 2 我们接着运行pfadd p1 b c d e f h i0 i1 i2，会看到这样一条记录12345678Raw hash 110100001100001000111001011000101111000000001000000001111010000P-shift hash 1a18472c5e010 1101000011000010001110010110001011110000000010000Q-set hash 5a18472c5e010 101101000011000010001110010110001011110000000010000while bit 1 count 1while bit 10 count 2while bit 100 count 3while bit 1000 count 4while end bit 10000 count 5 hllDenseSet下面，我们再来看hllDenseSet的实现，它应该就是根据hllPatLen计算的结果更新对应桶的值了。hllDenseSet是一个一个底层的函数，用来设置Dense HLL register。将index处的值设为count，如果count比当前值大。registers应该能够容纳HLL_REGISTERS+1的长度，这个是由sds的实现来保证的，因为sds字符串始终会在最后自动加上一个’\0’。这个函数始终会成功，返回1表示发生了修改，否则返回0。1234567891011int hllDenseSet(uint8_t *registers, long index, uint8_t count) &#123; uint8_t oldcount; HLL_DENSE_GET_REGISTER(oldcount,registers,index); if (count &gt; oldcount) &#123; HLL_DENSE_SET_REGISTER(registers,index,count); return 1; &#125; else &#123; return 0; &#125;&#125; 逻辑很简单，就是先把老的oldcount读出来，如果count比较大，那么就更新，比较麻烦的就是这两个宏。首先是HLL_BITS，它的取值是6，为什么这么奇怪呢？这是出于压缩空间的考虑。首先，我们知道每个桶里面存储的是这个桶最大的count，那么这个值最大是多少呢？首先，我们得到的是64位的哈希，然后其中有14位被用来分桶了，那剩下最多还能表示64-P+1=51位的count（参考上文实验），而这个是最少需要6个bit来表示的，所以这里用了6比特而不是8比特。不过这样会不会因为内存不对齐从而产生开销呢？12345678910111213141516/* Store the value of the register at position 'regnum' into variable 'target'. * 'p' is an array of unsigned bytes. */// do...while(0)是Linux中常见的保护宏的机制#define HLL_DENSE_GET_REGISTER(target,p,regnum) do &#123; \ uint8_t *_p = (uint8_t*) p; \ // 获得当前桶所在的起始byte unsigned long _byte = regnum*HLL_BITS/8; \ // 获得当前桶所在的起始byte的偏移 unsigned long _fb = regnum*HLL_BITS&amp;7; \ // 还有_fb8个bit在下一个byte上 unsigned long _fb8 = 8 - _fb; \ unsigned long b0 = _p[_byte]; \ unsigned long b1 = _p[_byte+1]; \ // 拼起来 target = ((b0 &gt;&gt; _fb) | (b1 &lt;&lt; _fb8)) &amp; HLL_REGISTER_MAX; \&#125; while(0) pfadd的Sparse实现首先介绍一下几个宏1234// xzero类型前缀 01xxxxxx#define HLL_SPARSE_XZERO_BIT 0x40// val类型前缀 1vvvvvxx#define HLL_SPARSE_VAL_BIT 0x80 下面的三个宏用来判断类型123456// 0xc0=0x11000000 判断是否是zero类型#define HLL_SPARSE_IS_ZERO(p) (((*(p)) &amp; 0xc0) == 0) // 判断是否是xzero类型#define HLL_SPARSE_IS_XZERO(p) (((*(p)) &amp; 0xc0) == HLL_SPARSE_XZERO_BIT)// 判断是否是val类型#define HLL_SPARSE_IS_VAL(p) ((*(p)) &amp; HLL_SPARSE_VAL_BIT) 下面的几个宏计算出是连续多少个数字，对于VAL，还需要获得VAL的值12345678// 00xxxxxx &amp; 0x00111111 获得后6位的值，即zero的长度#define HLL_SPARSE_ZERO_LEN(p) (((*(p)) &amp; 0x3f)+1)// 01xxxxxx yyyyyyy 计算xzero长度#define HLL_SPARSE_XZERO_LEN(p) (((((*(p)) &amp; 0x3f) &lt;&lt; 8) | (*((p)+1)))+1)// 001vvvvv &amp; 值0x00011111 获得中间5位的值，即val的值#define HLL_SPARSE_VAL_VALUE(p) ((((*(p)) &gt;&gt; 2) &amp; 0x1f)+1)// 获得后两位的值, 即长度#define HLL_SPARSE_VAL_LEN(p) (((*(p)) &amp; 0x3)+1) 下面的几个宏给出数值范围12345678// spase值5bit最大32#define HLL_SPARSE_VAL_MAX_VALUE 32// 长度2bit 最大4#define HLL_SPARSE_VAL_MAX_LEN 4// zero类型6位表示长度, 64#define HLL_SPARSE_ZERO_MAX_LEN 64// xzero类型14bit, 最大16384#define HLL_SPARSE_XZERO_MAX_LEN 16384 hllSparseAdd的实现还是需要先通过hllPatLen来获得count和index。123456int hllSparseAdd(robj *o, unsigned char *ele, size_t elesize) &#123; long index; uint8_t count = hllPatLen(ele,elesize,&amp;index); /* Update the register if this element produced a longer run of zeroes. */ return hllSparseSet(o,index,count);&#125; 下面来看hllSparseSet，这是一个贼复杂的函数，先翻译一下头部的说明。该函数接受输入参数对象o是用来存储HLL的String对象，这个函数需要这个对象的一个引用（指针），从而在需要的时候扩容。当集合的cardinality发生变化后，函数返回1；否则返回0，表示没有实际更新。返回-1表示错误。另外一个副作用是使得HLL从Sparse表示变为Dense表示，这个通常发生在某个值不能通过Sparse格式表示了（参考之前对VAL表示方法的论述），或者结果集的大小超过了server.hll_sparse_max_bytes（createHLLObject似乎不会检查当server.hll_sparse_max_bytes为0的时候就直接Dense，此外，还有个HLL_SPARSE_VAL_MAX_VALUE阈值）。123456789int hllSparseSet(robj *o, long index, uint8_t count) &#123; struct hllhdr *hdr; uint8_t oldcount, *sparse, *end, *p, *prev, *next; long first, span; long is_zero = 0, is_xzero = 0, is_val = 0, runlen = 0; // 如果count大于32，直接走promote流程到Dense if (count &gt; HLL_SPARSE_VAL_MAX_VALUE) goto promote;... 下面，我们需要为处理最差情况（XZERO变为XZERO-VAL-XZERO）额外分配三个字节（后面讲到）。这个必须要现在做，因为sdsMakeRoomFor可能realloc，也可能malloc，但这两种都不保证返回的ptr和原来是相同的。而我们希望以后的o-&gt;ptr能够是不变的。123... o-&gt;ptr = sdsMakeRoomFor(o-&gt;ptr,3);... 下面是第一步，先定位到sparse的头sparse，也就是registers数组，和尾end。这么做的目的是定位到需要修改的opcode，从而检查是否真的要修改。下面这个大循环，主要就是从头遍历，先通过HLL_SPARSE_IS_宏判断是具体哪种op类型，然后前进对应的oplen和span。其中oplen表示在物理表示上使用了多少字节，而span表示跨过了多少个（相同的）数字。12345678910111213141516171819202122232425262728293031... sparse = p = ((uint8_t*)o-&gt;ptr) + HLL_HDR_SIZE; end = p + sdslen(o-&gt;ptr) - HLL_HDR_SIZE; first = 0; prev = NULL; /* Points to previous opcode at the end of the loop. */ next = NULL; /* Points to the next opcode at the end of the loop. */ span = 0; while(p &lt; end) &#123; long oplen; /* Set span to the number of registers covered by this opcode. */ // 这个循环是最performance critical的。所以需要从最可能被处理的情况开始(ZERO)处理。 // 最少见的情况(XZERO)放到最后。 oplen = 1; if (HLL_SPARSE_IS_ZERO(p)) &#123; span = HLL_SPARSE_ZERO_LEN(p); &#125; else if (HLL_SPARSE_IS_VAL(p)) &#123; span = HLL_SPARSE_VAL_LEN(p); &#125; else &#123; /* XZERO. */ span = HLL_SPARSE_XZERO_LEN(p); oplen = 2; &#125; /* Break if this opcode covers the register as 'index'. */ if (index &lt;= first+span-1) break; prev = p; p += oplen; first += span; &#125; if (span == 0 || p &gt;= end) return -1; /* Invalid format. */... 在上面的while循环结束后，我们维护了下面几个性质： first储存了当前的opcode所覆盖的第一个register，注意这里的register对应了Dense里面桶的概念，而不是表示一个uint8_t next和prev分别存储了后一个和前一个opcode，如果不存在前驱后继，对应值是NULL span表示当前opcode覆盖了多少个register oplen表示这个op实际长度是多少个byte，根据前面对ZERO、XZERO和VAL的定义，其实取值只会在1和2 p指向了当前的opcode index表示要哈希到哪个桶里面 现在，我们找到了包含index的那个op了，我们判断这个op的类型到，并且计算runlen。那么这个runlen和span有啥区别呢？123456789101112131415161718... next = HLL_SPARSE_IS_XZERO(p) ? p+2 : p+1; if (next &gt;= end) next = NULL; /* Cache current opcode type to avoid using the macro again and * again for something that will not change. * Also cache the run-length of the opcode. */ if (HLL_SPARSE_IS_ZERO(p)) &#123; is_zero = 1; runlen = HLL_SPARSE_ZERO_LEN(p); &#125; else if (HLL_SPARSE_IS_XZERO(p)) &#123; is_xzero = 1; runlen = HLL_SPARSE_XZERO_LEN(p); &#125; else &#123; is_val = 1; runlen = HLL_SPARSE_VAL_LEN(p); &#125;... 在得到类型后，我们需要进行分类讨论。首先是两种VAL的平凡情况，我们尝试进行原地修改。 如果这个VAL opcode所表示的count大于现在这个哈希产生的count，那么实际上并不需要进行更新。在这种情况下PFADD会返回0，因为没有发生任何更新。 在要更新的情况中，还有个特例。如果这个VAL opcode仅仅就覆盖了一个register，那么就仅直接进行更新，因为这是一个平凡情况。我们稍后会去具体查看updated的具体实现。相对的不平凡的情况就是这个VAL opcode覆盖了多个register，也就是有相邻的多个桶都是这个count，可想而知，我们要把这个register分离出来单独做一个VAL opcode，我们将在稍后看分割VAL的实现。 12345678910111213... if (is_val) &#123; oldcount = HLL_SPARSE_VAL_VALUE(p); /* Case A. */ if (oldcount &gt;= count) return 0; /* Case B. */ if (runlen == 1) &#123; HLL_SPARSE_VAL_SET(p,count,1); goto updated; &#125; &#125;... 我们先来看看HLL_SPARSE_VAL_SET的实现，很简单，这是通过移位进行拼装。len-1的意味很明显，VAL的后两位为00的时候表示有1个val的值。那有0个是怎么表示的呢？很简单啊，用ZERO和XZERO啊。此外，可能还有一个抑或，就是为什么要HLL_SPARSE_VAL_SET(p,count,1)，因为从宏的定义上来看，count被传给了形参val，而不是语义上更接近的len。原因需要回顾VAL的定义，它表示在p处有连续1个桶，它的值为count。123#define HLL_SPARSE_VAL_SET(p,val,len) do &#123; \ *(p) = (((val)-1)&lt;&lt;2|((len)-1))|HLL_SPARSE_VAL_BIT; \&#125; while(0) 然后是数量为1的ZERO平凡情况，同样，如果是0，并且只覆盖了一个register，我们同样直接进行更新。12345678... /* C) Another trivial to handle case is a ZERO opcode with a len of 1. * We can just replace it with a VAL opcode with our value and len of 1. */ if (is_zero &amp;&amp; runlen == 1) &#123; HLL_SPARSE_VAL_SET(p,count,1); goto updated; &#125;... 下面是较为复杂的普通情况，在这种情况下，opcode要不是VAL或者ZERO（len大于1），要不就是XZERO。这些情况特殊在需要将原来的opcode拆分为多个opcode。其中最坏情况要把XZERO拆分成XZERO-VAL-XZERO的结构，也就是在原来的XZERO范围中有一个register被hit了。这样会占用5个字节，比原来多3个。下面的代码主要就是先将新序列写到n里面，然后将n原地插入到就数组中。首先处理ZERO和XZERO这块，这个处理主要就是将它分为Z-VAL-Z的序列，其中Z可能是ZERO可能是XZERO。具体查看代码中的注释。123456789101112131415161718192021222324252627282930313233343536... uint8_t seq[5], *n = seq; int last = first+span-1; /* Last register covered by the sequence. */ int len; if (is_zero || is_xzero) &#123; /* Handle splitting of ZERO / XZERO. */ if (index != first) &#123; // 在index前面有len个桶 len = index-first; // 如果这么多个桶不能不用ZERO放下， // 就用XZERO放 if (len &gt; HLL_SPARSE_ZERO_MAX_LEN) &#123; HLL_SPARSE_XZERO_SET(n,len); n += 2; &#125; else &#123; HLL_SPARSE_ZERO_SET(n,len); n++; &#125; &#125; // 设置count HLL_SPARSE_VAL_SET(n,count,1); n++; // 同样的办法处理尾部的count if (index != last) &#123; len = last-index; if (len &gt; HLL_SPARSE_ZERO_MAX_LEN) &#123; HLL_SPARSE_XZERO_SET(n,len); n += 2; &#125; else &#123; HLL_SPARSE_ZERO_SET(n,len); n++; &#125; &#125; &#125; else &#123;... 下面是分割VAL的情况。我们也是在n上面进行修改。把除自己之外的设为curval，自己设置为count。123456789101112131415161718... /* Handle splitting of VAL. */ int curval = HLL_SPARSE_VAL_VALUE(p); if (index != first) &#123; len = index-first; HLL_SPARSE_VAL_SET(n,curval,len); n++; &#125; HLL_SPARSE_VAL_SET(n,count,1); n++; if (index != last) &#123; len = last-index; HLL_SPARSE_VAL_SET(n,curval,len); n++; &#125; &#125;... 下面将n插入到老序列里面，其实就是一个memmove。12345678910111213141516... /* Step 3: substitute the new sequence with the old one. * * Note that we already allocated space on the sds string * calling sdsMakeRoomFor(). */ int seqlen = n-seq; int oldlen = is_xzero ? 2 : 1; int deltalen = seqlen-oldlen; if (deltalen &gt; 0 &amp;&amp; sdslen(o-&gt;ptr)+deltalen &gt; server.hll_sparse_max_bytes) goto promote; if (deltalen &amp;&amp; next) memmove(next+deltalen,next,end-next); sdsIncrLen(o-&gt;ptr,deltalen); memcpy(p,seq,seqlen); end += deltalen;... 下面，来看updated的实现，这一块代码，主要是从处理VAL和ZERO的两个goto过来，以及通常情况的顺序执行过来。123456789101112131415161718192021222324252627282930313233343536373839404142434445...updated: /* Step 4: Merge adjacent values if possible. * * The representation was updated, however the resulting representation * may not be optimal: adjacent VAL opcodes can sometimes be merged into * a single one. */ p = prev ? prev : sparse; int scanlen = 5; /* Scan up to 5 upcodes starting from prev. */ while (p &lt; end &amp;&amp; scanlen--) &#123; if (HLL_SPARSE_IS_XZERO(p)) &#123; p += 2; continue; &#125; else if (HLL_SPARSE_IS_ZERO(p)) &#123; p++; continue; &#125; /* We need two adjacent VAL opcodes to try a merge, having * the same value, and a len that fits the VAL opcode max len. */ if (p+1 &lt; end &amp;&amp; HLL_SPARSE_IS_VAL(p+1)) &#123; int v1 = HLL_SPARSE_VAL_VALUE(p); int v2 = HLL_SPARSE_VAL_VALUE(p+1); if (v1 == v2) &#123; int len = HLL_SPARSE_VAL_LEN(p)+HLL_SPARSE_VAL_LEN(p+1); if (len &lt;= HLL_SPARSE_VAL_MAX_LEN) &#123; HLL_SPARSE_VAL_SET(p+1,v1,len); memmove(p,p+1,end-p); sdsIncrLen(o-&gt;ptr,-1); end--; /* After a merge we reiterate without incrementing 'p' * in order to try to merge the just merged value with * a value on its right. */ continue; &#125; &#125; &#125; p++; &#125; /* Invalidate the cached cardinality. */ hdr = o-&gt;ptr; HLL_INVALIDATE_CACHE(hdr); return 1;... 下面是promote流程，是比较直截了当的，也就是先hllSparseToDense转换到Dense，然后调用hllDenseSet。注意这也反过来意味着PFADD命令需要保证被广播到slaves和AOF中，从而保证slaves中也进行这个转换。12345678910111213...promote: /* Promote to dense representation. */ if (hllSparseToDense(o) == C_ERR) return -1; /* Corrupted HLL. */ hdr = o-&gt;ptr; /* We need to call hllDenseAdd() to perform the operation after the * conversion. However the result must be 1, since if we need to * convert from sparse to dense a register requires to be updated. */ int dense_retval = hllDenseSet(hdr-&gt;registers,index,count); serverAssert(dense_retval == 1); return dense_retval;&#125; pfcount实现pfcountCommand函数首先照例是pfcountCommand作为入口。首先是处理PFCOUNT给出多个key的情况，此时会返回将这些HLL做union之后的近似cardinality。1234567891011121314151617181920212223242526272829303132333435363738/* PFCOUNT var -&gt; approximated cardinality of set. */void pfcountCommand(client *c) &#123; robj *o; struct hllhdr *hdr; uint64_t card; /* Case 1: multi-key keys, cardinality of the union. * * When multiple keys are specified, PFCOUNT actually computes * the cardinality of the merge of the N HLLs specified. */ if (c-&gt;argc &gt; 2) &#123; uint8_t max[HLL_HDR_SIZE+HLL_REGISTERS], *registers; int j; /* Compute an HLL with M[i] = MAX(M[i]_j). */ memset(max,0,sizeof(max)); hdr = (struct hllhdr*) max; hdr-&gt;encoding = HLL_RAW; /* Special internal-only encoding. */ registers = max + HLL_HDR_SIZE; for (j = 1; j &lt; c-&gt;argc; j++) &#123; /* Check type and size. */ robj *o = lookupKeyRead(c-&gt;db,c-&gt;argv[j]); if (o == NULL) continue; /* Assume empty HLL for non existing var.*/ if (isHLLObjectOrReply(c,o) != C_OK) return; /* Merge with this HLL with our 'max' HLL by setting max[i] * to MAX(max[i],hll[i]). */ if (hllMerge(registers,o) == C_ERR) &#123; addReplySds(c,sdsnew(invalid_hll_err)); return; &#125; &#125; /* Compute cardinality of the resulting set. */ addReplyLongLong(c,hllCount(hdr,NULL)); return; &#125;... 下面的情况是处理一个HLL的cardinality。1234567891011121314151617... /* Case 2: cardinality of the single HLL. * * The user specified a single key. Either return the cached value * or compute one and update the cache. */ o = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]); if (o == NULL) &#123; /* No key? Cardinality is zero since no element was added, otherwise * we would have a key as HLLADD creates it as a side effect. */ addReply(c,shared.czero); &#125; else &#123; if (isHLLObjectOrReply(c,o) != C_OK) return; o = dbUnshareStringValue(c-&gt;db,c-&gt;argv[1],o); /* Check if the cached cardinality is valid. */ hdr = o-&gt;ptr;... 假如可以使用cache，那么就直接使用cache去组装card。可以看出低字节在数组的低index中，所以是按照小端存储的。不过我还是比较好奇为啥不直接放一个uint64_t，而是要自己用uint8_t去维护一下？难道仅仅是为了在高位留一个字节表示是否是valid的？那其实可以用位域来实现啊？12345678910111213... if (HLL_VALID_CACHE(hdr)) &#123; /* Just return the cached value. */ card = (uint64_t)hdr-&gt;card[0]; card |= (uint64_t)hdr-&gt;card[1] &lt;&lt; 8; card |= (uint64_t)hdr-&gt;card[2] &lt;&lt; 16; card |= (uint64_t)hdr-&gt;card[3] &lt;&lt; 24; card |= (uint64_t)hdr-&gt;card[4] &lt;&lt; 32; card |= (uint64_t)hdr-&gt;card[5] &lt;&lt; 40; card |= (uint64_t)hdr-&gt;card[6] &lt;&lt; 48; card |= (uint64_t)hdr-&gt;card[7] &lt;&lt; 56; &#125; else &#123;... 假如cache是无效的，那么会实际调用hllCount。hllCount有个invalid参数，表示这个HLL的结构是有问题的。1234567891011121314151617... int invalid = 0; /* Recompute it and update the cached value. */ card = hllCount(hdr,&amp;invalid); if (invalid) &#123; addReplySds(c,sdsnew(invalid_hll_err)); return; &#125; hdr-&gt;card[0] = card &amp; 0xff; hdr-&gt;card[1] = (card &gt;&gt; 8) &amp; 0xff; hdr-&gt;card[2] = (card &gt;&gt; 16) &amp; 0xff; hdr-&gt;card[3] = (card &gt;&gt; 24) &amp; 0xff; hdr-&gt;card[4] = (card &gt;&gt; 32) &amp; 0xff; hdr-&gt;card[5] = (card &gt;&gt; 40) &amp; 0xff; hdr-&gt;card[6] = (card &gt;&gt; 48) &amp; 0xff; hdr-&gt;card[7] = (card &gt;&gt; 56) &amp; 0xff;... 在下面，同样需要调用signalModifiedKey。这是因为虽然PFCOUNT不会修改实际的存储，但是它可能会修改cache值。考虑到HLL实际上是作为String来存储的，所以我们需要广播这个变化。1234567... signalModifiedKey(c,c-&gt;db,c-&gt;argv[1]); server.dirty++; &#125; addReplyLongLong(c,card); &#125;&#125; cache实现在先前可以看到，HLL结构有个card[8]字段用来缓存cardinality。这个card会在PFCOUNT被访问到。此外，在PFADD和PFMERGE操作中，会调用HLL_INVALIDATE_CACHE使得缓存失效。12#define HLL_INVALIDATE_CACHE(hdr) (hdr)-&gt;card[7] |= (1&lt;&lt;7)#define HLL_VALID_CACHE(hdr) (((hdr)-&gt;card[7] &amp; (1&lt;&lt;7)) == 0) 一个naive的count函数下面我们根据自己的理解实现一个count函数。123456789101112131415161718192021double naiveHllCount(int * reghisto) &#123; double s = 0.0; double c = 0; double res = 0; bool useHarm = true; for(int v = 1; v &lt; 64; v++)&#123; double bucketCount = 1.0 / pow(2.0, -(v-1)); int countOfV = reghisto[v]; if(useHarm)&#123; double delta = countOfV * 1.0 / bucketCount; printf("v %d countofV %d bucketCount %f delta %f \n", v, countOfV, bucketCount, delta); s += delta; c += countOfV; &#125;else&#123; double delta = countOfV * bucketCount; printf("v %d countofV %d bucketCount %f delta %f \n", v, countOfV, bucketCount, delta); s += delta; c += countOfV; &#125; &#125;... 这个0.709的修正来自于论文中，知乎给出了解释。123456789... if(useHarm)&#123; res = c / s * c * 0.709; &#125;else&#123; res = s; &#125; printf("sum %f, c %f, res %f\n", s, c, res); return res;&#125; 参考12345678910switch (p) &#123; case 4: constant = 0.673 * m * m; case 5: constant = 0.697 * m * m; case 6: constant = 0.709 * m * m; default: constant = (0.7213 / (1 + 1.079 / m)) * m * m;&#125; hllCount函数返回估计的cardinality，基于register数组的调和平均数。hdr指向持有这个HLL的SDS的开始位置。如果HLL的稀疏表示形式是不合法的，则设置invalid为0，否则不设置这个值。hllCount支持一种特殊的内部编码HLL_RAW，也就是hdr-&gt;registers会指向一个长度HLL_REGISTERS的uint8_t数组。这个有助于加速对多个键调用PFCOUNT，因为我们不需要处理6-bit的整数了，所以实际上这是一个空间换时间的方案。12345uint64_t hllCount(struct hllhdr *hdr, int *invalid) &#123; double m = HLL_REGISTERS; double E; int j;... 下面计算每个register的直方图。注意到直方图数组reghisto的长度最多是HLL_Q+2，因为HLL_Q+1是哈希函数对&quot;000...1&quot;这样序列所能返回的最大的frequency。当然，很难检查输入的sanity，相反地，我们。。。这后面一堆注释，我理解就是说我们分配reghisto大一点。1234567... int reghisto[64] = &#123;0&#125;; /* Compute register histogram */ if (hdr-&gt;encoding == HLL_DENSE) &#123; hllDenseRegHisto(hdr-&gt;registers,reghisto);... hllDenseRegHisto会根据HLL_REGISTERS == 16384 &amp;&amp; HLL_BITS == 6的通用情况进行优化，我们对这个优化暂时按下不表，只关注实际在做什么。可以看到，它实际上去遍历了所有的register，然后通过HLL_DENSE_GET_REGISTER把这个HLL_BITS=6位的register取出来，并增加这个register的数量。12345678910111213void hllDenseRegHisto(uint8_t *registers, int* reghisto) &#123; int j; if (HLL_REGISTERS == 16384 &amp;&amp; HLL_BITS == 6) &#123; ... &#125; else &#123; for(j = 0; j &lt; HLL_REGISTERS; j++) &#123; unsigned long reg; HLL_DENSE_GET_REGISTER(reg,registers,j); reghisto[reg]++; &#125; &#125;&#125; 同理，hllSparseRegHisto对Sparse情况进行统计。这个实现其实也很简单，遍历每个opcode，对于ZERO和XZERO就增加reghisto[0]，对于VAL就增加reghisto[val]。12345... &#125; else if (hdr-&gt;encoding == HLL_SPARSE) &#123; hllSparseRegHisto(hdr-&gt;registers, sdslen((sds)hdr)-HLL_HDR_SIZE,invalid,reghisto);... 下面是HLL_RAW这个特殊的encoding。1234567... &#125; else if (hdr-&gt;encoding == HLL_RAW) &#123; hllRawRegHisto(hdr-&gt;registers,reghisto); &#125; else &#123; serverPanic("Unknown HyperLogLog encoding in hllCount()"); &#125;... 在这个操作之后，我们得到了直方图reghisto[reg]，表示在所有HLL_REGISTERS个桶中，count为reg的桶的数量，而这个count表示第一个1出现的位置。即之前的while end bit 10000 count 5这样的内容。下面就是根据直方图来计算估计的数量。在先前的论述中，我们设计了一个很naive的naiveHllCount。我们提到一个基于调和平均数的多桶的实现方案，而这里用了一篇很屌的论文里面的一个很屌的做法。下面来看看聪明做法123456789101112131415... /* Estimate cardinality form register histogram. See: * "New cardinality estimation algorithms for HyperLogLog sketches" * Otmar Ertl, arXiv:1702.01284 */ double z = m * hllTau((m-reghisto[HLL_Q+1])/(double)m); for (j = HLL_Q; j &gt;= 1; --j) &#123; z += reghisto[j]; z *= 0.5; &#125; z += m * hllSigma(reghisto[0]/(double)m); // #define HLL_ALPHA_INF 0.721347520444481703680 /* constant for 0.5/ln(2) */ E = llroundl(HLL_ALPHA_INF*m*m/z); return (uint64_t) E;&#125; 1234567891011121314151617181920212223242526272829// New cardinality estimation algorithms for HyperLogLog sketchesdouble hllTau(double x) &#123; if (x == 0. || x == 1.) return 0.; double zPrime; double y = 1.0; double z = 1 - x; do &#123; x = sqrt(x); zPrime = z; y *= 0.5; z -= pow(1 - x, 2)*y; &#125; while(zPrime != z); return z / 3;&#125;double hllSigma(double x) &#123; if (x == 1.) return INFINITY; double zPrime; double y = 1; double z = x; do &#123; x *= x; zPrime = z; z += x * y; y += y; &#125; while(zPrime != z); return z;&#125; intsetintset是存储int的集合。在底层存储上体现为一个有序的数组，这是它和ziplist的一个不同点。intset数组中的每个元素具有相同的长度，这个长度由encoding指定。length表示Intset里面元素的个数，所以柔性数组(Flex Array)contents的长度实际上就是encoding * length的值。123456// intset.htypedef struct intset &#123; uint32_t encoding; uint32_t length; int8_t contents[];&#125; intset; encoding类似于HLL的实现，intset也要考虑节省空间。出于节省空间考虑，支持三种encoding，当出现该encoding装不下的数时，会新创建一个更大的encoding，当然这样会伴随空间浪费。123#define INTSET_ENC_INT16 (sizeof(int16_t))#define INTSET_ENC_INT32 (sizeof(int32_t))#define INTSET_ENC_INT64 (sizeof(int64_t)) 给定v的值，得到能够承载它的最小encoding。需要注意的是，这里都是有符号整数。12345678static uint8_t _intsetValueEncoding(int64_t v) &#123; if (v &lt; INT32_MIN || v &gt; INT32_MAX) return INTSET_ENC_INT64; else if (v &lt; INT16_MIN || v &gt; INT16_MAX) return INTSET_ENC_INT32; else return INTSET_ENC_INT16;&#125; 编码因为支持不同的编码，所以intset索性用一个int8_t contents[]来存这些int。如果我们要把一个64位数字按照8位8位地存到char数组里面，那么就会涉及到选择大端或者小端两种存储方式。其实在Redis的很多数据结构的实现中，我们可以明显地看到Redis开发者，或者很多C开发者的一个特点，也就是喜欢把所有的数据结构都自己编码到char*上面。intrev32ifbe这个函数用来从小/大端序转为小端序。123456789101112131415#if (BYTE_ORDER == LITTLE_ENDIAN)#define memrev16ifbe(p) ((void)(0))#define memrev32ifbe(p) ((void)(0))#define memrev64ifbe(p) ((void)(0))#define intrev16ifbe(v) (v)#define intrev32ifbe(v) (v)#define intrev64ifbe(v) (v)#else#define memrev16ifbe(p) memrev16(p)#define memrev32ifbe(p) memrev32(p)#define memrev64ifbe(p) memrev64(p)#define intrev16ifbe(v) intrev16(v)#define intrev32ifbe(v) intrev32(v)#define intrev64ifbe(v) intrev64(v)#endif 查找intsetFind语句首先排除掉encoding过大的，比如在一串最大32767的数组里面肯定找不到99999。12345/* Determine whether a value belongs to this set */uint8_t intsetFind(intset *is, int64_t value) &#123; uint8_t valenc = _intsetValueEncoding(value); return valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,NULL);&#125; 下面就是intsetSearch，因为intset是有序的嘛，所以我想这个肯定是个二分的实现吧，果不其然。这个函数返回1表示找到，并用pos标记找到的位置/插入位置；否则返回0在二分前，需要先特判一下value过大或者过小的情况，从而能够快速失败，而不是进入下面的二分。123456789101112131415161718192021static uint8_t intsetSearch(intset *is, int64_t value, uint32_t *pos) &#123; // min和max表示intset的最左和最右的index int min = 0, max = intrev32ifbe(is-&gt;length)-1, mid = -1; int64_t cur = -1; /* The value can never be found when the set is empty */ if (intrev32ifbe(is-&gt;length) == 0) &#123; if (pos) *pos = 0; return 0; &#125; else &#123; /* Check for the case where we know we cannot find the value, * but do know the insert position. */ if (value &gt; _intsetGet(is,max)) &#123; if (pos) *pos = intrev32ifbe(is-&gt;length); return 0; &#125; else if (value &lt; _intsetGet(is,0)) &#123; if (pos) *pos = 0; return 0; &#125; &#125;... 这里的二分每次都会对mid进行+1或者-1，和我们通常的二分还不太一样。通常的二分因为要在一个F/T…TTT或者TTT…F/T型的序列中找到边界的T，所以在移动mid时，如果我们发现当前的mid是T，并且我们想移动l/r的话，我们不能移动到mid-1/mid+1，这是因为mid可能就是我们要找的值。但这个二分我们要找的是exact value，所以我们可以激进一点，直接-1或者+1。123456789101112131415161718192021... while(max &gt;= min) &#123; mid = ((unsigned int)min + (unsigned int)max) &gt;&gt; 1; cur = _intsetGet(is,mid); if (value &gt; cur) &#123; min = mid+1; &#125; else if (value &lt; cur) &#123; max = mid-1; &#125; else &#123; break; &#125; &#125; if (value == cur) &#123; if (pos) *pos = mid; return 1; &#125; else &#123; if (pos) *pos = min; return 0; &#125;&#125; 添加对于intsetAdd的情况，想想肯定是有一个$O(logn)$的查找和一个$O(n)$的移动的。1234567891011121314151617181920212223242526272829303132intset *intsetAdd(intset *is, int64_t value, uint8_t *success) &#123; uint8_t valenc = _intsetValueEncoding(value); uint32_t pos; if (success) *success = 1; /* Upgrade encoding if necessary. If we need to upgrade, we know that * this value should be either appended (if &gt; 0) or prepended (if &lt; 0), * because it lies outside the range of existing values. */ if (valenc &gt; intrev32ifbe(is-&gt;encoding)) &#123; // 如果encoding明显大了，那么需要直接升级intset /* This always succeeds, so we don't need to curry *success. */ return intsetUpgradeAndAdd(is,value); &#125; else &#123; /* Abort if the value is already present in the set. * This call will populate "pos" with the right position to insert * the value when it cannot be found. */ if (intsetSearch(is,value,&amp;pos)) &#123; // 如果已经存在，就直接返回 if (success) *success = 0; return is; &#125; // 为新插入的value分配长度为1的空间 is = intsetResize(is,intrev32ifbe(is-&gt;length)+1); // 把[pos, )移到[pos+1, )，即往后挪一位 if (pos &lt; intrev32ifbe(is-&gt;length)) intsetMoveTail(is,pos,pos+1); &#125; _intsetSet(is,pos,value); is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1); return is;&#125; Resize走的zrealloc，这个函数之前讲到过，并不保证不会重新分配内存，这也是为什么intsetResize会重新返回intset *指针的原因。 12345static intset *intsetResize(intset *is, uint32_t len) &#123; uint32_t size = len*intrev32ifbe(is-&gt;encoding); is = zrealloc(is,sizeof(intset)+size); return is;&#125; intsetMoveTail实际调用了memmove，直截了当的函数。1234567891011121314151617static void intsetMoveTail(intset *is, uint32_t from, uint32_t to) &#123; void *src, *dst; // bytes表示移动多少字节，目前的赋值是多少元素，后面还要乘上元素的长度 uint32_t bytes = intrev32ifbe(is-&gt;length)-from; uint32_t encoding = intrev32ifbe(is-&gt;encoding); if (encoding == INTSET_ENC_INT64) &#123; src = (int64_t*)is-&gt;contents+from; dst = (int64_t*)is-&gt;contents+to; bytes *= sizeof(int64_t); &#125; else if (encoding == INTSET_ENC_INT32) &#123; ... &#125; else &#123; ... &#125; memmove(dst,src,bytes);&#125; 这里就是先把64位的value放上去，如果机器上是大端(be)存储，那么再调用下面的宏倒成小端。1234567891011121314static void _intsetSet(intset *is, int pos, int64_t value) &#123; uint32_t encoding = intrev32ifbe(is-&gt;encoding); if (encoding == INTSET_ENC_INT64) &#123; ((int64_t*)is-&gt;contents)[pos] = value; memrev64ifbe(((int64_t*)is-&gt;contents)+pos); &#125; else if (encoding == INTSET_ENC_INT32) &#123; ((int32_t*)is-&gt;contents)[pos] = value; memrev32ifbe(((int32_t*)is-&gt;contents)+pos); &#125; else &#123; ((int16_t*)is-&gt;contents)[pos] = value; memrev16ifbe(((int16_t*)is-&gt;contents)+pos); &#125;&#125; 大端小端宏简单介绍一下memrev系列大小端转换的代码。16的简单，3次交换123456void memrev16(void *p) &#123; unsigned char *x = p, t; t = x[0]; x[0] = x[1]; x[1] = t;&#125; 32位的，6次交换，实际上是轴对称交换1230 1 2 33 1 2 03 2 1 0 代码如下12345678910void memrev32(void *p) &#123; unsigned char *x = p, t; t = x[0]; x[0] = x[3]; x[3] = t; t = x[1]; x[1] = x[2]; x[2] = t;&#125; 64位的，12次交换，同样也是轴对称交换，代码就不列了。 bitmapbitmap底层是一个SDS count实现这个命令可以统计得到从[start, end]区间内的1的数量，但是这个start和end是以byte为单位的，从0开始。我们可以参考下面的这个demo123setbit test1 10 1setbit test1 20 1setbit test1 30 1 下面两个命令返回值都是312bitcount test1 bitcount test1 1 9 其实bitmap底层是从左到右开始编号的。乍一看有点本末倒置，为啥最高位是0，但仔细想想，这种方式方便扩展啊。1234byte offset : 0 1 2 3setbit test1 10 1: 00000000 00100000setbit test1 20 1: 00000000 00000000 00001000setbit test1 30 1: 00000000 00000000 00000000 00000010 再举一个例子1setbit test2 15 1 计算15/8=1.875，所以是位于第1个byte的最后一位100000000 00000001(15) 因此getbit test2 0 0 返回0getbit test2 0 1 返回1，因为第一个byte被包含了getbit test2 2 3 返回0‘下面看bitcountCommand12345678910111213141516171819202122232425262728293031323334// bitops.cvoid bitcountCommand(client *c) &#123; robj *o; long start, end, strlen; unsigned char *p; char llbuf[LONG_STR_SIZE]; /* Lookup, check for type, and return 0 for non existing keys. */ if ((o = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.czero)) == NULL || checkType(c,o,OBJ_STRING)) return; p = getObjectReadOnlyString(o,&amp;strlen,llbuf); /* Parse start/end range if any. */ if (c-&gt;argc == 4) &#123; ... &#125; else if (c-&gt;argc == 2) &#123; /* The whole string. */ start = 0; end = strlen-1; &#125; else &#123; /* Syntax error. */ addReply(c,shared.syntaxerr); return; &#125; /* Precondition: end &gt;= 0 &amp;&amp; end &lt; strlen, so the only condition where * zero can be returned is: start &gt; end. */ if (start &gt; end) &#123; addReply(c,shared.czero); &#125; else &#123; long bytes = end-start+1; addReplyLongLong(c,redisPopcount(p+start,bytes)); &#125;&#125; 上面一堆废话结束，最关键的是redisPopcount这个函数，统计从s开始的bytes长度的slice里面的1的个数。一开始发现一个表bitsinbyte，这里面bitsinbyte[i]表示i这个数字的二进制表示里面有几个1。可以从中看出，bitcount统计bytes而不是统计bits的原因可能很大程度上就是对bytes可以查表处理，起到加速作用。12345678910/* Count number of bits set in the binary array pointed by 's' and long * 'count' bytes. The implementation of this function is required to * work with a input string length up to 512 MB. */size_t redisPopcount(void *s, long count) &#123; size_t bits = 0; unsigned char *p = s; uint32_t *p4; static const unsigned char bitsinbyte[256] = &#123;0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8&#125;;... 下面的代码中(unsigned long)p &amp; 3的目的是用一个while循环统计下前面没有对齐到32位的数量。其实如果我们愿意慢一点，直接这个while循环就能全部统计完了。1234567... /* Count initial bytes not aligned to 32 bit. */ while((unsigned long)p &amp; 3 &amp;&amp; count) &#123; bits += bitsinbyte[*p++]; count--; &#125;... 一次性计算28个bytes，这个算法经历过疯狂的升级，3.0的时候是同时计算16个，但总体来说还是一个SWAR算法，为了便于理解，先看3.0版本的16 bytes的算法，它其实有点类似于我们在GeoHash中看到的interleave64的算法。快速计算64位和32位整数二进制表示中1数量的算法是种群算法，我在csapp data lab这篇文章中有介绍。这篇文章 中的介绍也很详细。12345678910111213141516171819//for 64 bit numbersint NumberOfSetBits64(long long i)&#123; i = i - ((i &gt;&gt; 1) &amp; 0x5555555555555555); i = (i &amp; 0x3333333333333333) + ((i &gt;&gt; 2) &amp; 0x3333333333333333); i = ((i + (i &gt;&gt; 4)) &amp; 0x0F0F0F0F0F0F0F0F); return (i*(0x0101010101010101))&gt;&gt;56;&#125;//for 32 bit integersint NumberOfSetBits32(int i)&#123; // A i = i - ((i &gt;&gt; 1) &amp; 0x55555555); i = (i &amp; 0x33333333) + ((i &gt;&gt; 2) &amp; 0x33333333); // B i = ((i + (i &gt;&gt; 4)) &amp; 0x0F0F0F0F); return (i*(0x01010101))&gt;&gt;24;&#125; 我们以32位为例，复习一下该算法的原理。首先，我们回顾一下这几个常量的表示，F实际上是01的重复，T是0011的重复，O是00001111的重复123F = 0x55555555 = 01010101010101010101010101010101T = 0x33333333 = 00110011001100110011001100110011O = 0x0f0f0f0f = 00001111000011110000111100001111 这个算法的思路是首先把32位长度的数组按照奇偶组合成16组，然后在每组中统计1的个数，容易看到，这个结果只能是0b0/0b1/0b10，不会溢出。12‭数字 01 11 01 01 10 11 11 00 11 01 00 01 01 01‬(123456789)‬‬和 01 10 01 01 01 10 10 00 10 01 00 01 01 01 这个过程是可以用位运算解决的，即1i = (i &amp; 0x55555555) + ((i &gt;&gt; 1) &amp; 0x55555555); 然后我们发现，为啥函数里面不是这样写的？其实下面两种是等价算法12i = (i &amp; 0x55555555) + ((i &gt;&gt; 1) &amp; 0x55555555);i = i - ((i &gt;&gt; 1) &amp; 0x55555555); 一般来说，&amp;对+是不满足分配率的，但在对按4移位的情况下是可以的，即不会产生溢出。所以后面我们还可以提出0x0F0F0F0F公因式。注意对2移位是不能提公因式的，考虑1010b这种情况，移位相加会出现10b + 10b从而导致溢出。 下面我们来对照看看3.0版本的16 bytes的实现，在前面执行NumberOfSetBits32的A步骤，依次计算4个byte的数量到aux1/2/3/4里面。在最后执行B步骤，将最后结果加到bits里面。12345678910111213141516171819202122232425 p4 = (uint32_t*)p; while(count&gt;=16) &#123; uint32_t aux1, aux2, aux3, aux4; aux1 = *p4++; aux2 = *p4++; aux3 = *p4++; aux4 = *p4++; count -= 16; aux1 = aux1 - ((aux1 &gt;&gt; 1) &amp; 0x55555555); aux1 = (aux1 &amp; 0x33333333) + ((aux1 &gt;&gt; 2) &amp; 0x33333333); aux2 = aux2 - ((aux2 &gt;&gt; 1) &amp; 0x55555555); aux2 = (aux2 &amp; 0x33333333) + ((aux2 &gt;&gt; 2) &amp; 0x33333333); aux3 = aux3 - ((aux3 &gt;&gt; 1) &amp; 0x55555555); aux3 = (aux3 &amp; 0x33333333) + ((aux3 &gt;&gt; 2) &amp; 0x33333333); aux4 = aux4 - ((aux4 &gt;&gt; 1) &amp; 0x55555555); aux4 = (aux4 &amp; 0x33333333) + ((aux4 &gt;&gt; 2) &amp; 0x33333333); bits += ((((aux1 + (aux1 &gt;&gt; 4)) &amp; 0x0F0F0F0F) * 0x01010101) &gt;&gt; 24) + ((((aux2 + (aux2 &gt;&gt; 4)) &amp; 0x0F0F0F0F) * 0x01010101) &gt;&gt; 24) + ((((aux3 + (aux3 &gt;&gt; 4)) &amp; 0x0F0F0F0F) * 0x01010101) &gt;&gt; 24) + ((((aux4 + (aux4 &gt;&gt; 4)) &amp; 0x0F0F0F0F) * 0x01010101) &gt;&gt; 24); &#125;... 下面看28 bytes算法也是类似，不过为啥要选择28这个数呢，我不是很明白123456789101112131415161718192021... p4 = (uint32_t*)p; while(count&gt;=28) &#123; uint32_t aux1, aux2, aux3, aux4, aux5, aux6, aux7; // *p++等于*(p++) aux1 = *p4++; ... aux7 = *p4++; count -= 28; aux1 = aux1 - ((aux1 &gt;&gt; 1) &amp; 0x55555555); aux1 = (aux1 &amp; 0x33333333) + ((aux1 &gt;&gt; 2) &amp; 0x33333333); ... aux7 = aux7 - ((aux7 &gt;&gt; 1) &amp; 0x55555555); aux7 = (aux7 &amp; 0x33333333) + ((aux7 &gt;&gt; 2) &amp; 0x33333333); bits += ((((aux1 + (aux1 &gt;&gt; 4)) &amp; 0x0F0F0F0F) + ... ((aux7 + (aux7 &gt;&gt; 4)) &amp; 0x0F0F0F0F))* 0x01010101) &gt;&gt; 24;&#125; 这个循环和之前的(unsigned long)p &amp; 3循环是对应的，用来处理余下来和28个bytes不对齐的。12345 /* Count the remaining bytes. */p = (unsigned char*)p4; while(count--) bits += bitsinbyte[*p++]; return bits;&#125; set/get实现1234567891011121314151617181920212223/* SETBIT key offset bitvalue */void setbitCommand(client *c) &#123; robj *o; char *err = "bit is not an integer or out of range"; size_t bitoffset; ssize_t byte, bit; int byteval, bitval; long on; // 把bitoffset位置设置为on if (getBitOffsetFromArgument(c,c-&gt;argv[2],&amp;bitoffset,0,0) != C_OK) return; if (getLongFromObjectOrReply(c,c-&gt;argv[3],&amp;on,err) != C_OK) return; /* Bits can only be set or cleared... */ // 如果on不是0或者1，那么就返回错误 if (on &amp; ~1) &#123; addReplyError(c,err); return; &#125;... 下面这个命令，进行检查，该创建的创建，该扩容的扩容12345678910111213141516171819202122... if ((o = lookupStringForBitCommand(c,bitoffset)) == NULL) return; /* Get current values */ // bitoffset除以8，得到所在的byte byte = bitoffset &gt;&gt; 3; byteval = ((uint8_t*)o-&gt;ptr)[byte]; // 由于bitmap是从左往右数的，所以这边要用7减一下，得到这个byte中从右往左的偏移量 bit = 7 - (bitoffset &amp; 0x7); // 取出实际的bit值 bitval = byteval &amp; (1 &lt;&lt; bit); /* Update byte with new bit value and return original value */ // 更新并返回原先的值 byteval &amp;= ~(1 &lt;&lt; bit); byteval |= ((on &amp; 0x1) &lt;&lt; bit); ((uint8_t*)o-&gt;ptr)[byte] = byteval; signalModifiedKey(c,c-&gt;db,c-&gt;argv[1]); notifyKeyspaceEvent(NOTIFY_STRING,"setbit",c-&gt;argv[1],c-&gt;db-&gt;id); server.dirty++; addReply(c, bitval ? shared.cone : shared.czero);&#125; bitopbitop指令的格式如下面所示，结果存到dest里面。1bitop opname dest src1 src2 ... 123456789101112/* BITOP op_name target_key src_key1 src_key2 src_key3 ... src_keyN */void bitopCommand(client *c) &#123; char *opname = c-&gt;argv[1]-&gt;ptr; robj *o, *targetkey = c-&gt;argv[2]; unsigned long op, j, numkeys; robj **objects; /* Array of source objects. */ unsigned char **src; /* Array of source strings pointers. */ unsigned long *len, maxlen = 0; /* Array of length of src strings, and max len. */ unsigned long minlen = 0; /* Min len among the input keys. */ unsigned char *res = NULL; /* Resulting string. */... 在字符串判定的时候有个优化，因为strcasecmp的开销比较大，所以会先判断第一个字母合不合法，合法再调用这个函数。12345678910111213141516... /* Parse the operation name. */ if ((opname[0] == 'a' || opname[0] == 'A') &amp;&amp; !strcasecmp(opname,"and")) op = BITOP_AND; ... else &#123; addReply(c,shared.syntaxerr); return; &#125; /* Sanity check: NOT accepts only a single key argument. */ if (op == BITOP_NOT &amp;&amp; c-&gt;argc != 4) &#123; addReplyError(c,"BITOP NOT must be called with a single source key."); return; &#125;... 遍历所有要查找的key，统计一些信息： objects 调用getDecodedObject。因为这个是raw encoding，所以相当于就是自增了一下引用。 src 每一个src的指针 len 每一个src的对应长度，这个长度是按照字节算的 maxlen/minlen 所有src的最大长度和最小长度123456789101112131415161718192021222324252627282930313233343536... /* Lookup keys, and store pointers to the string objects into an array. */ numkeys = c-&gt;argc - 3; src = zmalloc(sizeof(unsigned char*) * numkeys); len = zmalloc(sizeof(long) * numkeys); objects = zmalloc(sizeof(robj*) * numkeys); for (j = 0; j &lt; numkeys; j++) &#123; o = lookupKeyRead(c-&gt;db,c-&gt;argv[j+3]); /* Handle non-existing keys as empty strings. */ if (o == NULL) &#123; objects[j] = NULL; src[j] = NULL; len[j] = 0; minlen = 0; continue; &#125; /* Return an error if one of the keys is not a string. */ // 如果有不是OBJ_STRING对象，就返回错误，并且释放 if (checkType(c,o,OBJ_STRING)) &#123; unsigned long i; for (i = 0; i &lt; j; i++) &#123; if (objects[i]) decrRefCount(objects[i]); &#125; zfree(src); zfree(len); zfree(objects); return; &#125; objects[j] = getDecodedObject(o); src[j] = objects[j]-&gt;ptr; len[j] = sdslen(objects[j]-&gt;ptr); if (len[j] &gt; maxlen) maxlen = len[j]; if (j == 0 || len[j] &lt; minlen) minlen = len[j]; &#125;... 比较有趣的是这里同样针对对齐数据有个优化。我们需要在ARM架构上跳过这个优化点，这是因为ARM不支持multiple-words load/store，即使在V6架构下。首先，解释一下几个临时变量： j 表示SDS里面的每一个字节 i 表示op作用的每一个key 出于从普通到特殊，可以先阅读后面的普通实现，再看这个优化实现。优化实现能够处理最短的bitmap至少有4个long（32位）的情况，但是要求key的总数小于等于16。也就是说我们能够一批4个地对所有的key做bitop。【Q】不过不需要什么特殊的指令，直接这样写CPU就可以优化了吗？1234567891011121314151617181920212223242526272829303132333435363738394041... /* Compute the bit operation, if at least one string is not empty. */ if (maxlen) &#123; res = (unsigned char*) sdsnewlen(NULL,maxlen); unsigned char output, byte; unsigned long i; j = 0; #ifndef USE_ALIGNED_ACCESS if (minlen &gt;= sizeof(unsigned long)*4 &amp;&amp; numkeys &lt;= 16) &#123; unsigned long *lp[16]; unsigned long *lres = (unsigned long*) res; /* Note: sds pointer is always aligned to 8 byte boundary. */ memcpy(lp,src,sizeof(unsigned long*)*numkeys); memcpy(res,src[0],minlen); /* Different branches per different operations for speed (sorry). */ if (op == BITOP_AND) &#123; while(minlen &gt;= sizeof(unsigned long)*4) &#123; for (i = 1; i &lt; numkeys; i++) &#123; lres[0] &amp;= lp[i][0]; lres[1] &amp;= lp[i][1]; lres[2] &amp;= lp[i][2]; lres[3] &amp;= lp[i][3]; lp[i]+=4; &#125; lres+=4; j += sizeof(unsigned long)*4; minlen -= sizeof(unsigned long)*4; &#125; &#125; else if (op == BITOP_OR) &#123;... &#125; else if (op == BITOP_XOR) &#123;... &#125; else if (op == BITOP_NOT) &#123;... &#125; &#125; #endif... 专门提取第一个出来作为左操作数，下面i从1开始循环123456... /* j is set to the next byte to process by the previous loop. */ for (; j &lt; maxlen; j++) &#123; output = (len[0] &lt;= j) ? 0 : src[0][j]; if (op == BITOP_NOT) output = ~output;... 这里我有个疑惑了，既然里面都不处理BITOP_NOT了，为啥不直接跳过这个for循环呢？12345678910111213... for (i = 1; i &lt; numkeys; i++) &#123; byte = (len[i] &lt;= j) ? 0 : src[i][j]; switch(op) &#123; case BITOP_AND: output &amp;= byte; break; case BITOP_OR: output |= byte; break; case BITOP_XOR: output ^= byte; break; &#125; &#125; res[j] = output; &#125; &#125;... 下面是清理工作了1234567891011121314151617181920212223... for (j = 0; j &lt; numkeys; j++) &#123; if (objects[j]) decrRefCount(objects[j]); &#125; zfree(src); zfree(len); zfree(objects); /* Store the computed value into the target key */ if (maxlen) &#123; o = createObject(OBJ_STRING,res); setKey(c,c-&gt;db,targetkey,o); notifyKeyspaceEvent(NOTIFY_STRING,"set",targetkey,c-&gt;db-&gt;id); decrRefCount(o); server.dirty++; &#125; else if (dbDelete(c-&gt;db,targetkey)) &#123; signalModifiedKey(c,c-&gt;db,targetkey); notifyKeyspaceEvent(NOTIFY_GENERIC,"del",targetkey,c-&gt;db-&gt;id); server.dirty++; &#125; addReplyLongLong(c,maxlen); /* Return the output string length in bytes. */&#125; quicklistGeo和GeoHashRedis在3.2版本之后提供GeoHash的实现，主要包含下面的命令： GEOADD key longitude latitude member [longitude latitude member ...] 将某个经纬度以及对应的名字(member)加入到指定的key里面 GEOPOS key member [member ...] 以member为输入，返回经纬度为输出 GEODIST key member1 member2 [unit] 返回两个位置之间的间隔，以unit为单位，默认为米 GEORADIUS key longitude latitude radius unit 返回给定经纬度为中心radius范围内的位置，默认返回未排序的元素 GEORADIUSBYMEMBER 同上，但是不是给出经纬度，而是直接给一个member名字 GEOHASH ley member [member ...] 返回member的GeoHash值 ZREM 用来删除一个GEOHASH对象 GEOADD对应GEOADD指令。可以看到，Geo的底层存储是一个ZSET。这也是可以理解的，因为通过GeoHash确实可以实现有序的地理坐标，所以我们是按照顺序存储的。1234567891011/* GEOADD key long lat name [long2 lat2 name2 ... longN latN nameN] */void geoaddCommand(client *c) &#123; /* Check arguments number for sanity. */ if ((c-&gt;argc - 2) % 3 != 0) &#123; /* Need an odd number of arguments if we got this far... */ addReplyError(c, "syntax error. Try GEOADD key [x1] [y1] [name1] " "[x2] [y2] [name2] ... "); return; &#125;... 在这里构建将来提供给zadd命令的argc和argv。elements表示坐标的数量，一个坐标需要有(long, lat, name)三元组来表示，所以这里要除以3。123456789... int elements = (c-&gt;argc - 2) / 3; int argc = 2+elements*2; /* ZADD key score ele ... */ robj **argv = zcalloc(argc*sizeof(robj*)); // 表示创建一个值是"zadd"的`OBJ_STRING`对象 argv[0] = createRawStringObject("zadd",4); argv[1] = c-&gt;argv[1]; /* key */ printf("Step 1: argv[1]-&gt;refcount %d, c-&gt;argv[1]-&gt;refcount %d\n", argv[1]-&gt;refcount, c-&gt;argv[1]-&gt;refcount);... 这里自增argv[1]的引用计数是因为直接把argv[1]指向c-&gt;argv[1]了，所以实际上也是自增c-&gt;argv[1]的引用计数。实际上这么做同时也保证了replaceClientCommandVector在释放掉c-&gt;argv后，c-&gt;argv[1]所指向的对象仍有一个引用。123... incrRefCount(argv[1]);... 在这个语句之后，我们得到Step 1: argv[1]-&gt;refcount 2, c-&gt;argv[1]-&gt;refcount 2。下面的循环依次解析每个坐标，并构建score和member字段。首先通过extractLongLatOrReply把经纬度读到xy里面，如果出现经纬度超出范围的问题函数会返回C_ERR，从而导致直接return。123456789101112131415... /* Create the argument vector to call ZADD in order to add all * the score,value pairs to the requested zset, where score is actually * an encoded version of lat,long. */ int i; for (i = 0; i &lt; elements; i++) &#123; double xy[2]; if (extractLongLatOrReply(c, (c-&gt;argv+2)+(i*3),xy) == C_ERR) &#123; for (i = 0; i &lt; argc; i++) if (argv[i]) decrRefCount(argv[i]); zfree(argv); return; &#125;... 下面的geohashEncodeWGS84函数根据我们取出来的xy算GeoHash，最后会调用到geohashEncodeType -&gt; geohashEncode，关于GeoHash部分会在后面讨论。12345678... /* Turn the coordinates into the score of the element. */ GeoHashBits hash; // geohashEncodeWGS84最终调用geohashEncode geohashEncodeWGS84(xy[0], xy[1], GEO_STEP_MAX, &amp;hash); GeoHashFix52Bits bits = geohashAlign52Bits(hash);// geoaddCommand未完结... geohashAlign52Bits函数能够将得到的哈希值GeoHashBits，其中hash.bits是哈希值，hash.step是精度。我们需要将它做成一个52位的整数。123456789// geohash_helper.htypedef uint64_t GeoHashFix52Bits;// geo.cGeoHashFix52Bits geohashAlign52Bits(const GeoHashBits hash) &#123; uint64_t bits = hash.bits; bits &lt;&lt;= (52 - hash.step * 2); return bits;&#125; 接着来看函数geoaddCommand，我们将得到的bits组装成SDS，并且安装到argv里面，接着调用replaceClientCommandVector得到一个以argc和argv为参数的新的redisCommand，放到c-&gt;cmd里面。123456789101112131415// 续geoaddCommand... robj *score = createObject(OBJ_STRING, sdsfromlonglong(bits)); robj *val = c-&gt;argv[2 + i * 3 + 2]; argv[2+i*2] = score; argv[3+i*2] = val; incrRefCount(val); &#125; /* Finally call ZADD that will do the work for us. */ printf("Step 2: argv[1]-&gt;refcount %d, c-&gt;argv[1]-&gt;refcount %d\n", argv[1]-&gt;refcount, c-&gt;argv[1]-&gt;refcount); replaceClientCommandVector(c,argc,argv); printf("Step 3: argv[1]-&gt;refcount %d, c-&gt;argv[1]-&gt;refcount %d\n", argv[1]-&gt;refcount, c-&gt;argv[1]-&gt;refcount); zaddCommand(c);&#125; 在这之后，输出是12Step 2: argv[1]-&gt;refcount 2, c-&gt;argv[1]-&gt;refcount 2Step 3: argv[1]-&gt;refcount 1, c-&gt;argv[1]-&gt;refcount 1 replaceClientCommandVectorreplaceClientCommandVector函数会释放c-&gt;argv和c-&gt;argc，并且使用传入的argc和argv替换。1234567891011// networking.c/* Completely replace the client command vector with the provided one. */void replaceClientCommandVector(client *c, int argc, robj **argv) &#123; freeClientArgv(c); zfree(c-&gt;argv); c-&gt;argv = argv; c-&gt;argc = argc; c-&gt;cmd = lookupCommandOrOriginal(c-&gt;argv[0]-&gt;ptr); serverAssertWithInfo(c,NULL,c-&gt;cmd != NULL);&#125; freeClientArgv查看freeClientArgv1234567static void freeClientArgv(client *c) &#123; int j; for (j = 0; j &lt; c-&gt;argc; j++) decrRefCount(c-&gt;argv[j]); c-&gt;argc = 0; c-&gt;cmd = NULL;&#125; lookupCommandOrOriginallookupCommandOrOriginal用来根据指令名name找到对应的redisCommand项目。首先会在server.commands里面找，如果没找到会在server.orig_commands里面找。orig_commands表示没有被redis.conf里面的rename命令修改过的原始的命令名字。看起来很奇怪，不过人家注释也说了lookupCommandOrOriginal一般只和lookupCommandOrOriginal配合使用。123456789/* This is used by functions rewriting the argument vector such as * rewriteClientCommandVector() in order to set client-&gt;cmd pointer * correctly even if the command was renamed. */struct redisCommand *lookupCommandOrOriginal(sds name) &#123; struct redisCommand *cmd = dictFetchValue(server.commands, name); if (!cmd) cmd = dictFetchValue(server.orig_commands,name); return cmd;&#125; GEOHASH算法介绍GEOHASH是将二进制的经纬度转换为字符串，每个字符串表示一块矩形的区域。这些字符串越长，那么表示的范围就越精确。 下面阐述如何计算GEOHASH： 如何编码精度或者纬度 例如纬度的范围是[-90,90]，那么我们不断二分就可以得到一个二进制的表示。例如00表示[-90,-45)，11表示[45,90]。 如何组合精度和纬度 通过interleave来组合。也就是偶数位放经度，奇数位放纬度。 如何生成字符串 我们组成的GeoHash有52位，通过Base32编码(一个char能表示5位)可以得到长度为11的字符串。 这种interleave的组合方式成为Peano空间填充曲线。如下所示，这个曲线可能存在编码相邻但是实际距离很远的情况，例如0111和1000。因此，在通过GEOHASH召回部分空间点后，还需要去判断一下实际距离。 GEOHASH实现GeoHashBits/geohashGetCoordRangeGeoHashBits是GEOHASH结构。bits表示hash值，是interleave64之后的结果。step表示进行二分的次数，Redis中默认是26，所以最终得到的hash是52位的。1234typedef struct &#123; uint64_t bits; // 表示哈希值 uint8_t step; // 表示精度&#125; GeoHashBits; 下面四个宏规定了经纬度的取值范围。在这里需要说明的是Redis的GeoHash的内部存储和标准有差异。标准规定纬度的取值范围是[-90, 90]，而Redis的实现是[-85, 85]。因此Redis实际上是不能索引位于南北极的一小块范围的。【Q】为什么这么做呢？我觉得可能有两个原因： 南北极的位置本来也不常用 南北极的经度变化比较敏感，所以其实有点浪费 12345/* Limits from EPSG:900913 / EPSG:3785 / OSGEO:41001 */#define GEO_LAT_MIN -85.05112878#define GEO_LAT_MAX 85.05112878#define GEO_LONG_MIN -180#define GEO_LONG_MAX 180 我们回顾之前看到的geohashEncodeWGS84的函数的调用链，它会通过geohashGetCoordRange来获得这次经纬度的范围，并作为参数传给geohashEncode。123456789101112131415161718192021// geohash.cint geohashEncodeType(double longitude, double latitude, uint8_t step, GeoHashBits *hash) &#123; GeoHashRange r[2] = &#123;&#123;0&#125;&#125;; geohashGetCoordRange(&amp;r[0], &amp;r[1]); return geohashEncode(&amp;r[0], &amp;r[1], longitude, latitude, step, hash);&#125;int geohashEncodeWGS84(double longitude, double latitude, uint8_t step, GeoHashBits *hash) &#123; return geohashEncodeType(longitude, latitude, step, hash);&#125;void geohashGetCoordRange(GeoHashRange *long_range, GeoHashRange *lat_range) &#123; /* These are constraints from EPSG:900913 / EPSG:3785 / OSGEO:41001 */ /* We can't geocode at the north/south pole. */ long_range-&gt;max = GEO_LONG_MAX; long_range-&gt;min = GEO_LONG_MIN; lat_range-&gt;max = GEO_LAT_MAX; lat_range-&gt;min = GEO_LAT_MIN;&#125; geohashCommand查看geohashCommand的实现，它主要是通过geohashEncode去得到一个GeoHashBits对象。1234567891011121314void geohashCommand(client *c) &#123; char *geoalphabet= "0123456789bcdefghjkmnpqrstuvwxyz"; int j; /* Look up the requested zset */ robj *zobj = lookupKeyRead(c-&gt;db, c-&gt;argv[1]); if (checkType(c, zobj, OBJ_ZSET)) return; /* Geohash elements one after the other, using a null bulk reply for * missing elements. */ addReplyArrayLen(c,c-&gt;argc-2); for (j = 2; j &lt; c-&gt;argc; j++) &#123; double score;... 首先通过zsetScore获得指定member即c-&gt;argv[j]-&gt;ptr的score。12345... if (!zobj || zsetScore(zobj, c-&gt;argv[j]-&gt;ptr, &amp;score) == C_ERR) &#123; addReplyNull(c); &#125; else &#123;... 在前面提到过，Redis的GeoHash的内部存储和标准的GEOHASH坐标有差异。Redis的是[-85,85]这个区间，但是普通的GEOHASH是[-90,90]区间。因为这个命令会返回标准的GEOHASH值，所以我们需要将它转换到标准GeoHash。因此需要用decodeGeohash将score解码到xy，并且再通过GeoHashRange编码，得到纬度取值范围为[-90, 90]的hash。1234567891011121314151617181920212223... /* The internal format we use for geocoding is a bit different * than the standard, since we use as initial latitude range * -85,85, while the normal geohashing algorithm uses -90,90. * So we have to decode our position and re-encode using the * standard ranges in order to output a valid geohash string. */ /* Decode... */ double xy[2]; if (!decodeGeohash(score,xy)) &#123; addReplyNull(c); continue; &#125; /* Re-encode */ GeoHashRange r[2]; GeoHashBits hash; r[0].min = -180; r[0].max = 180; r[1].min = -90; r[1].max = 90; geohashEncode(&amp;r[0],&amp;r[1],xy[0],xy[1],26,&amp;hash);... 下面我们得到了符合标准的hash，接下来我们将这个hash值根据geoalphabet编码到字符串buf上。1234567891011121314151617181920... char buf[12]; int i; for (i = 0; i &lt; 11; i++) &#123; int idx; if (i == 10) &#123; /* We have just 52 bits, but the API used to output * an 11 bytes geohash. For compatibility we assume * zero. */ idx = 0; &#125; else &#123; idx = (hash.bits &gt;&gt; (52-((i+1)*5))) &amp; 0x1f; &#125; buf[i] = geoalphabet[idx]; &#125; buf[11] = '\0'; addReplyBulkCBuffer(c,buf,11); &#125; &#125;&#125; geohashEncode下面我们来看最关键的geohashEncode的实现。首先是进行校验，包含两部分。首先检验经纬度Range是否合法，然后校验经纬度是否在GEO_宏规定的区间内，然后校验经纬度是否在经纬度Range给出的区间内。【Q】在这里有一个问题，从上面的代码实现可以看到，其实lat_range是可能比GEO_LAT_MAX/GEO_LAT_MIN范围大的，那么这是否影响GeoHash的结果呢？123456789101112// geohash.c#define RANGEISZERO(r) (!(r).max &amp;&amp; !(r).min)#define RANGEPISZERO(r) (r == NULL || RANGEISZERO(*r))int geohashEncode(const GeoHashRange *long_range, const GeoHashRange *lat_range, double longitude, double latitude, uint8_t step, GeoHashBits *hash) &#123; /* Check basic arguments sanity. */ if (hash == NULL || step &gt; 32 || step == 0 || RANGEPISZERO(lat_range) || RANGEPISZERO(long_range)) return 0;... longitude和latitude既要满足GEO_宏定义的区间限制，也要满足传入的long_range和lat_range区间限制。1234567891011121314... /* Return an error when trying to index outside the supported * constraints. */ if (longitude &gt; GEO_LONG_MAX || longitude &lt; GEO_LONG_MIN || latitude &gt; GEO_LAT_MAX || latitude &lt; GEO_LAT_MIN) return 0; hash-&gt;bits = 0; hash-&gt;step = step; if (latitude &lt; lat_range-&gt;min || latitude &gt; lat_range-&gt;max || longitude &lt; long_range-&gt;min || longitude &gt; long_range-&gt;max) &#123; return 0; &#125;... 下面计算的两个offset，实际上就是根据传入的long_range和lat_range做min-max归一化。123456... double lat_offset = (latitude - lat_range-&gt;min) / (lat_range-&gt;max - lat_range-&gt;min); double long_offset = (longitude - long_range-&gt;min) / (long_range-&gt;max - long_range-&gt;min);... 接着对归一化的结果，乘以$2^{step}$【Q】这是为什么呢？这里的两个offset是无量纲的比例。我们乘以(1ULL &lt;&lt; step)相当于就是先把地图分step次，然后找到对应的offset在的位置。所以在读取GeoHash的时候，实际上是需要知道对应的step的。我们参考geoaddCommand里面的调用是geohashEncodeWGS84(xy[0], xy[1], GEO_STEP_MAX, &amp;hash)。12345... /* convert to fixed point based on the step size */ lat_offset *= (1ULL &lt;&lt; step); long_offset *= (1ULL &lt;&lt; step);... 接下来就是GeoHash算法的一个核心，也就是将得到的两个offset，按照奇数为纬度，偶数为经度的方式组成一个二进制序列。1234... hash-&gt;bits = interleave64(lat_offset, long_offset); return 1;&#125; 下面我们来看这个interleave64的实现，他看起来就像一个拉链一样，交错。12345678910111213141516171819202122232425262728293031/* Interleave lower bits of x and y, so the bits of x * are in the even positions and bits from y in the odd; * x and y must initially be less than 2**32 (65536). * From: https://graphics.stanford.edu/~seander/bithacks.html#InterleaveBMN */static inline uint64_t interleave64(uint32_t xlo, uint32_t ylo) &#123; static const uint64_t B[] = &#123;0x5555555555555555ULL, 0x3333333333333333ULL, 0x0F0F0F0F0F0F0F0FULL, 0x00FF00FF00FF00FFULL, 0x0000FFFF0000FFFFULL&#125;; static const unsigned int S[] = &#123;1, 2, 4, 8, 16&#125;; uint64_t x = xlo; uint64_t y = ylo; x = (x | (x &lt;&lt; S[4])) &amp; B[4]; y = (y | (y &lt;&lt; S[4])) &amp; B[4]; x = (x | (x &lt;&lt; S[3])) &amp; B[3]; y = (y | (y &lt;&lt; S[3])) &amp; B[3]; x = (x | (x &lt;&lt; S[2])) &amp; B[2]; y = (y | (y &lt;&lt; S[2])) &amp; B[2]; x = (x | (x &lt;&lt; S[1])) &amp; B[1]; y = (y | (y &lt;&lt; S[1])) &amp; B[1]; x = (x | (x &lt;&lt; S[0])) &amp; B[0]; y = (y | (y &lt;&lt; S[0])) &amp; B[0]; return x | (y &lt;&lt; 1);&#125; 我们不妨以一个32位的0xffff进行调试。123456789101112x (ffffffff)11111111111111111111111111111111 y (0) S 4: x (ffff0000ffff) 111111111111111100000000000000001111111111111111S 4: y (0) S 3: x (ff00ff00ff00ff) 11111111000000001111111100000000111111110000000011111111S 3: y (0) S 2: x (f0f0f0f0f0f0f0f) 111100001111000011110000111100001111000011110000111100001111S 2: y (0) S 1: x (3333333333333333) 11001100110011001100110011001100110011001100110011001100110011S 1: y (0) S 0: x (5555555555555555)101010101010101010101010101010101010101010101010101010101010101S 0: y (0) GEORADIUS/GEORADIUSBYMEMBERGeoHashRadius类这个类是一个非常大的上下文，包含了一个GEOHASH位置本身，以及他解码后实际的经纬度，以及它的八个邻居的GeoHashBits。12345typedef struct &#123; GeoHashBits hash; GeoHashArea area; GeoHashNeighbors neighbors;&#125; GeoHashRadius; GeoHashBits之前介绍过，包含哈希位bits和精度step，也就是一个GEOHASH地址，表示一块区域。GeoHashArea的定义如下所示，它实际上就是对hash值的一个经纬度的表示，可以由geohashDecode算得。12345typedef struct &#123; GeoHashBits hash; GeoHashRange longitude; GeoHashRange latitude;&#125; GeoHashArea; GeoHashNeighbors表示周围八个区域。12345678910typedef struct &#123; GeoHashBits north; GeoHashBits east; GeoHashBits west; GeoHashBits south; GeoHashBits north_east; GeoHashBits south_east; GeoHashBits north_west; GeoHashBits south_west;&#125; GeoHashNeighbors; georadiusGeneric函数在很多应用中有查找附近的人这样的功能，这就可以通过GEORADIUSBYMEMBER命令来实现。【Q】在启用了GEOHASH之后，两个hash值越接近，说明两个点距离越近。所以说，这个函数是不是可以直接匹配前缀呢？答案是不行的，因为这样会漏掉跨边界的情况。如下图所示，如果我们采用前缀匹配的方式，则红点和蓝点的前缀更为接近，但实际上它和黄点的实际距离更近。所以在搜索时，我们要搜索周围的8个方块。 这个函数包含两部分： geohashGetAreasByRadius获得上下文GeoHashRadius membersOfAllNeighbors得到所有满足条件的点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/* GEORADIUS key x y radius unit [WITHDIST] [WITHHASH] [WITHCOORD] [ASC|DESC] * [COUNT count] [STORE key] [STOREDIST key] * GEORADIUSBYMEMBER key member radius unit ... options ... */void georadiusGeneric(client *c, int flags) &#123; robj *key = c-&gt;argv[1]; robj *storekey = NULL; int storedist = 0; /* 0 for STORE, 1 for STOREDIST. */ /* Look up the requested zset */ robj *zobj = NULL; if ((zobj = lookupKeyReadOrReply(c, key, shared.emptyarray)) == NULL || checkType(c, zobj, OBJ_ZSET)) &#123; return; &#125; /* Find long/lat to use for radius search based on inquiry type */ int base_args; double xy[2] = &#123; 0 &#125;; if (flags &amp; RADIUS_COORDS) &#123; base_args = 6; if (extractLongLatOrReply(c, c-&gt;argv + 2, xy) == C_ERR) return; &#125; else if (flags &amp; RADIUS_MEMBER) &#123; base_args = 5; robj *member = c-&gt;argv[2]; if (longLatFromMember(zobj, member, xy) == C_ERR) &#123; addReplyError(c, "could not decode requested zset member"); return; &#125; &#125; else &#123; addReplyError(c, "Unknown georadius search type"); return; &#125; /* Extract radius and units from arguments */ double radius_meters = 0, conversion = 1; if ((radius_meters = extractDistanceOrReply(c, c-&gt;argv + base_args - 2, &amp;conversion)) &lt; 0) &#123; return; &#125; /* Discover and populate all optional parameters. */ int withdist = 0, withhash = 0, withcoords = 0; int sort = SORT_NONE; long long count = 0; if (c-&gt;argc &gt; base_args) &#123; // 这里面一堆对命令参数的判断，就省略了 ... &#125; /* Trap options not compatible with STORE and STOREDIST. */ if (storekey &amp;&amp; (withdist || withhash || withcoords)) &#123; addReplyError(c, "STORE option in GEORADIUS is not compatible with " "WITHDIST, WITHHASH and WITHCOORDS options"); return; &#125; /* COUNT without ordering does not make much sense, force ASC * ordering if COUNT was specified but no sorting was requested. */ if (count != 0 &amp;&amp; sort == SORT_NONE) sort = SORT_ASC;... 函数geohashGetAreasByRadiusWGS84（实际上是geohashGetAreasByRadius）根据中心点位置xy和搜索范围距离radius_meters计算georadius，这个GeoHashRadius georadius可以理解为是一个上下文对象。12345... /* Get all neighbor geohash boxes for our radius search */ GeoHashRadius georadius = geohashGetAreasByRadiusWGS84(xy[0], xy[1], radius_meters);... 函数membersOfAllNeighbors对中心点以及它周边八个方向进行查找，找出所有范围内的元素，返回满足搜索距离范围的点。该函数中依次对中心点及周边8个区块调用membersOfGeoHashBox函数。这个函数比较厉害，我们后面单独讲。12345... /* Search the zset for all matching points */ geoArray *ga = geoArrayCreate(); membersOfAllNeighbors(zobj, georadius, xy[0], xy[1], radius_meters, ga);... 如果我们找不到对应的点，那么就返回一个空的Array。 12345678... /* If no matching results, the user gets an empty reply. */ if (ga-&gt;used == 0 &amp;&amp; storekey == NULL) &#123; addReply(c,shared.emptyarray); geoArrayFree(ga); return; &#125;... 否则我们就进行排序。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101... long result_length = ga-&gt;used; long returned_items = (count == 0 || result_length &lt; count) ? result_length : count; long option_length = 0; /* Process [optional] requested sorting */ if (sort == SORT_ASC) &#123; qsort(ga-&gt;array, result_length, sizeof(geoPoint), sort_gp_asc); &#125; else if (sort == SORT_DESC) &#123; qsort(ga-&gt;array, result_length, sizeof(geoPoint), sort_gp_desc); &#125; if (storekey == NULL) &#123; /* No target key, return results to user. */ /* Our options are self-contained nested multibulk replies, so we * only need to track how many of those nested replies we return. */ if (withdist) option_length++; if (withcoords) option_length++; if (withhash) option_length++; /* The array len we send is exactly result_length. The result is * either all strings of just zset members *or* a nested multi-bulk * reply containing the zset member string _and_ all the additional * options the user enabled for this request. */ addReplyArrayLen(c, returned_items); /* Finally send results back to the caller */ int i; for (i = 0; i &lt; returned_items; i++) &#123; geoPoint *gp = ga-&gt;array+i; gp-&gt;dist /= conversion; /* Fix according to unit. */ /* If we have options in option_length, return each sub-result * as a nested multi-bulk. Add 1 to account for result value * itself. */ if (option_length) addReplyArrayLen(c, option_length + 1); addReplyBulkSds(c,gp-&gt;member); gp-&gt;member = NULL; if (withdist) addReplyDoubleDistance(c, gp-&gt;dist); if (withhash) addReplyLongLong(c, gp-&gt;score); if (withcoords) &#123; addReplyArrayLen(c, 2); addReplyHumanLongDouble(c, gp-&gt;longitude); addReplyHumanLongDouble(c, gp-&gt;latitude); &#125; &#125; &#125; else &#123; /* Target key, create a sorted set with the results. */ robj *zobj; zset *zs; int i; size_t maxelelen = 0; if (returned_items) &#123; zobj = createZsetObject(); zs = zobj-&gt;ptr; &#125; for (i = 0; i &lt; returned_items; i++) &#123; zskiplistNode *znode; geoPoint *gp = ga-&gt;array+i; gp-&gt;dist /= conversion; /* Fix according to unit. */ double score = storedist ? gp-&gt;dist : gp-&gt;score; size_t elelen = sdslen(gp-&gt;member); if (maxelelen &lt; elelen) maxelelen = elelen; znode = zslInsert(zs-&gt;zsl,score,gp-&gt;member); serverAssert(dictAdd(zs-&gt;dict,gp-&gt;member,&amp;znode-&gt;score) == DICT_OK); gp-&gt;member = NULL; &#125; if (returned_items) &#123; zsetConvertToZiplistIfNeeded(zobj,maxelelen); setKey(c,c-&gt;db,storekey,zobj); decrRefCount(zobj); notifyKeyspaceEvent(NOTIFY_ZSET,"georadiusstore",storekey, c-&gt;db-&gt;id); server.dirty += returned_items; &#125; else if (dbDelete(c-&gt;db,storekey)) &#123; signalModifiedKey(c,c-&gt;db,storekey); notifyKeyspaceEvent(NOTIFY_GENERIC,"del",storekey,c-&gt;db-&gt;id); server.dirty++; &#125; addReplyLongLong(c, returned_items); &#125; geoArrayFree(ga);&#125; geohashGetAreasByRadius12345678910GeoHashRadius geohashGetAreasByRadius(double longitude, double latitude, double radius_meters) &#123; GeoHashRange long_range, lat_range; GeoHashRadius radius; GeoHashBits hash; GeoHashNeighbors neighbors; GeoHashArea area; double min_lon, max_lon, min_lat, max_lat; double bounds[4]; int steps;... 我们首先以(longitude, latitude, radius_meters)构造一个圆，我们通过geohashBoundingBox计算这个圆的外接矩形的经纬度范围。1234567... geohashBoundingBox(longitude, latitude, radius_meters, bounds); min_lon = bounds[0]; min_lat = bounds[1]; max_lon = bounds[2]; max_lat = bounds[3];... 接下来，我们要计算精度steps。123... steps = geohashEstimateStepsByRadius(radius_meters,latitude);... geohashGetCoordRange函数没鸟用，就是单纯用GEO_LONG_MAX/GEO_LONG_MIN设置一下range，得到的range被用来做Encode。1234... geohashGetCoordRange(&amp;long_range,&amp;lat_range); geohashEncode(&amp;long_range,&amp;lat_range,longitude,latitude,steps,&amp;hash);... 计算所有的邻居。这里的neighbors是GeoHashNeighbors结构的指针，这个结构里面保存了周围8个块的GeoHashBits。123... geohashNeighbors(&amp;hash,&amp;neighbors);... 把一个GEOHASH值，解码成经纬度的表示area。123... geohashDecode(long_range,lat_range,hash,&amp;area);... 我们需要检查自己算出来的step是否足够。下面的注释说有的时候，search area太靠近area的边缘了，step就还不够小，因为东南西北侧的正方形太靠近search area，以至于无法覆盖所有的东西。【Q】反正我是没懂search area和area的区别是啥？反正对于这种情况，我们需要再减小一下step。1234567891011121314151617181920212223242526272829303132... /* Check if the step is enough at the limits of the covered area. * Sometimes when the search area is near an edge of the * area, the estimated step is not small enough, since one of the * north / south / west / east square is too near to the search area * to cover everything. */ int decrease_step = 0; &#123; GeoHashArea north, south, east, west; geohashDecode(long_range, lat_range, neighbors.north, &amp;north); geohashDecode(long_range, lat_range, neighbors.south, &amp;south); geohashDecode(long_range, lat_range, neighbors.east, &amp;east); geohashDecode(long_range, lat_range, neighbors.west, &amp;west); if (geohashGetDistance(longitude,latitude,longitude,north.latitude.max) &lt; radius_meters) decrease_step = 1; if (geohashGetDistance(longitude,latitude,longitude,south.latitude.min) &lt; radius_meters) decrease_step = 1; if (geohashGetDistance(longitude,latitude,east.longitude.max,latitude) &lt; radius_meters) decrease_step = 1; if (geohashGetDistance(longitude,latitude,west.longitude.min,latitude) &lt; radius_meters) decrease_step = 1; &#125; if (steps &gt; 1 &amp;&amp; decrease_step) &#123; steps--; geohashEncode(&amp;long_range,&amp;lat_range,longitude,latitude,steps,&amp;hash); geohashNeighbors(&amp;hash,&amp;neighbors); geohashDecode(long_range,lat_range,hash,&amp;area); &#125;... 1234567891011121314151617181920212223242526272829... /* Exclude the search areas that are useless. */ if (steps &gt;= 2) &#123; if (area.latitude.min &lt; min_lat) &#123; GZERO(neighbors.south); GZERO(neighbors.south_west); GZERO(neighbors.south_east); &#125; if (area.latitude.max &gt; max_lat) &#123; GZERO(neighbors.north); GZERO(neighbors.north_east); GZERO(neighbors.north_west); &#125; if (area.longitude.min &lt; min_lon) &#123; GZERO(neighbors.west); GZERO(neighbors.south_west); GZERO(neighbors.north_west); &#125; if (area.longitude.max &gt; max_lon) &#123; GZERO(neighbors.east); GZERO(neighbors.south_east); GZERO(neighbors.north_east); &#125; &#125; radius.hash = hash; radius.neighbors = neighbors; radius.area = area; return radius;&#125; membersOfAllNeighbors这里讲解一下返回值geoArray，这是一个简单的数组，buckets和used让我们联想到了之前的dict等结构。实际上，它也就是保存了一些列的点。buckets表示数组的容量，used表示实际数组用了多少。12345678910111213typedef struct geoPoint &#123; double longitude; double latitude; double dist; double score; char *member;&#125; geoPoint;typedef struct geoArray &#123; struct geoPoint *array; size_t buckets; size_t used;&#125; geoArray; 下面看主体函数12345678910111213141516/* Search all eight neighbors + self geohash box */int membersOfAllNeighbors(robj *zobj, GeoHashRadius n, double lon, double lat, double radius, geoArray *ga) &#123; GeoHashBits neighbors[9]; unsigned int i, count = 0, last_processed = 0; int debugmsg = 0; neighbors[0] = n.hash; neighbors[1] = n.neighbors.north; neighbors[2] = n.neighbors.south; neighbors[3] = n.neighbors.east; neighbors[4] = n.neighbors.west; neighbors[5] = n.neighbors.north_east; neighbors[6] = n.neighbors.north_west; neighbors[7] = n.neighbors.south_east; neighbors[8] = n.neighbors.south_west;... 主要逻辑就是遍历所有的neighbors，并调用membersOfGeoHashBox。这里唯一值得一提的逻辑是，如果说我们的半径范围很大，例如超过5000km了，那么neighbour可能会重复，所以我们判断一下重复的neighbour。12345678910111213141516171819202122232425262728293031... /* For each neighbor (*and* our own hashbox), get all the matching * members and add them to the potential result list. */ for (i = 0; i &lt; sizeof(neighbors) / sizeof(*neighbors); i++) &#123; if (HASHISZERO(neighbors[i])) &#123; if (debugmsg) D("neighbors[%d] is zero",i); continue; &#125; /* Debugging info. */ if (debugmsg) &#123; ... &#125; /* When a huge Radius (in the 5000 km range or more) is used, * adjacent neighbors can be the same, leading to duplicated * elements. Skip every range which is the same as the one * processed previously. */ if (last_processed &amp;&amp; neighbors[i].bits == neighbors[last_processed].bits &amp;&amp; neighbors[i].step == neighbors[last_processed].step) &#123; if (debugmsg) D("Skipping processing of %d, same as previous\n",i); continue; &#125; count += membersOfGeoHashBox(zobj, neighbors[i], ga, lon, lat, radius); last_processed = i; &#125; return count;&#125; membersOfGeoHashBox首先，我们根据hash，通过scoresOfGeoHashBox算出这个里面的位置点对应在ZSET中的score的范围。这个函数的实现，我们稍后讲。123456789/* Obtain all members between the min/max of this geohash bounding box. * Populate a geoArray of GeoPoints by calling geoGetPointsInRange(). * Return the number of points added to the array. */int membersOfGeoHashBox(robj *zobj, GeoHashBits hash, geoArray *ga, double lon, double lat, double radius) &#123; GeoHashFix52Bits min, max; scoresOfGeoHashBox(hash,&amp;min,&amp;max); return geoGetPointsInRange(zobj, min, max, lon, lat, radius, ga);&#125; scoresOfGeoHashBox如果step是3，那么我们的hash就有step * 2 = 6个有效位。例如，二进制的hash值，即bits是101010。但是因为我们的分数是52位的，我们需要获取101010?????????????????????????????????????????????的范围，所以我们要在101010后面填充，让它对齐成52bit。因为我们补齐部分的?可以取0，也可以取1，所以我们可以直接自增二进制的hash值即bits。 1234567891011121314151617181920212223/* Compute the sorted set scores min (inclusive), max (exclusive) we should * query in order to retrieve all the elements inside the specified area * 'hash'. The two scores are returned by reference in *min and *max. */void scoresOfGeoHashBox(GeoHashBits hash, GeoHashFix52Bits *min, GeoHashFix52Bits *max) &#123; /* We want to compute the sorted set scores that will include all the * elements inside the specified Geohash 'hash', which has as many * bits as specified by hash.step * 2. * * To get the min score we just use the initial hash value left * shifted enough to get the 52 bit value. Later we increment the * 6 bit prefis (see the hash.bits++ statement), and get the new * prefix: 101011, which we align again to 52 bits to get the maximum * value (which is excluded from the search). So we get everything * between the two following scores (represented in binary): * * 1010100000000000000000000000000000000000000000000000 (included) * and * 1010110000000000000000000000000000000000000000000000 (excluded). */ *min = geohashAlign52Bits(hash); hash.bits++; *max = geohashAlign52Bits(hash);&#125; geoGetPointsInRange在membersOfAllNeighbors中，ga最后是通过geoGetPointsInRange设置的。geoGetPointsInRange在ZSET中查找score位于min和max之间的所有元素，然后再通过geoAppendIfWithinRadius用(log,lat,radius)条件过滤一遍，将符合要求的点通过geoArrayAppend加入到ga中。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/* * The ability of this function to append to an existing set of points is * important for good performances because querying by radius is performed * using multiple queries to the sorted set, that we later need to sort * via qsort. Similarly we need to be able to reject points outside the search * radius area ASAP in order to allocate and process more points than needed. */int geoGetPointsInRange(robj *zobj, double min, double max, double lon, double lat, double radius, geoArray *ga) &#123; /* minex 0 = include min in range; maxex 1 = exclude max in range */ /* That's: min &lt;= val &lt; max */ zrangespec range = &#123; .min = min, .max = max, .minex = 0, .maxex = 1 &#125;; size_t origincount = ga-&gt;used; sds member; if (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123; unsigned char *zl = zobj-&gt;ptr; unsigned char *eptr, *sptr; unsigned char *vstr = NULL; unsigned int vlen = 0; long long vlong = 0; double score = 0; if ((eptr = zzlFirstInRange(zl, &amp;range)) == NULL) &#123; /* Nothing exists starting at our min. No results. */ return 0; &#125; sptr = ziplistNext(zl, eptr); while (eptr) &#123; score = zzlGetScore(sptr); /* If we fell out of range, break. */ if (!zslValueLteMax(score, &amp;range)) break; /* We know the element exists. ziplistGet should always succeed */ ziplistGet(eptr, &amp;vstr, &amp;vlen, &amp;vlong); member = (vstr == NULL) ? sdsfromlonglong(vlong) : sdsnewlen(vstr,vlen); if (geoAppendIfWithinRadius(ga,lon,lat,radius,score,member) == C_ERR) sdsfree(member); zzlNext(zl, &amp;eptr, &amp;sptr); &#125; &#125; else if (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123; zset *zs = zobj-&gt;ptr; zskiplist *zsl = zs-&gt;zsl; zskiplistNode *ln; if ((ln = zslFirstInRange(zsl, &amp;range)) == NULL) &#123; /* Nothing exists starting at our min. No results. */ return 0; &#125; while (ln) &#123; sds ele = ln-&gt;ele; /* Abort when the node is no longer in range. */ if (!zslValueLteMax(ln-&gt;score, &amp;range)) break; ele = sdsdup(ele); if (geoAppendIfWithinRadius(ga,lon,lat,radius,ln-&gt;score,ele) == C_ERR) sdsfree(ele); ln = ln-&gt;level[0].forward; &#125; &#125; return ga-&gt;used - origincount;&#125; geoAppendIfWithinRadius123456789101112131415161718192021222324252627/* Helper function for geoGetPointsInRange(): given a sorted set score * representing a point, and another point (the center of our search) and * a radius, appends this entry as a geoPoint into the specified geoArray * only if the point is within the search area. * * returns C_OK if the point is included, or REIDS_ERR if it is outside. */int geoAppendIfWithinRadius(geoArray *ga, double lon, double lat, double radius, double score, sds member) &#123; double distance, xy[2]; if (!decodeGeohash(score,xy)) return C_ERR; /* Can't decode. */ /* Note that geohashGetDistanceIfInRadiusWGS84() takes arguments in * reverse order: longitude first, latitude later. */ if (!geohashGetDistanceIfInRadiusWGS84(lon,lat, xy[0], xy[1], radius, &amp;distance)) &#123; return C_ERR; &#125; /* Append the new element. */ geoPoint *gp = geoArrayAppend(ga); gp-&gt;longitude = xy[0]; gp-&gt;latitude = xy[1]; gp-&gt;dist = distance; gp-&gt;member = member; gp-&gt;score = score; return C_OK;&#125; RaxRedis还提供了一个基数树的实现。这个实现被用作Redis Cluster模式下面存储slot对应的所有key的信息。此外，在Stream、RDB、客户端缓存等模块中也用到了这个数据结构。 StreamzipmapReference https://xiking.win/2018/11/07/reverse-binary-iteration/ https://zhuanlan.zhihu.com/p/90125709]]></content>
      <tags>
        <tag>并行计算</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[subprocess模块用法]]></title>
    <url>%2F2018%2F07%2F17%2Fsubprocess_usage%2F</url>
    <content type="text"><![CDATA[在Python中我们可以通过os.system来以控制台的形式运行程序，但当涉及到需要进行进程间通信时，就需要用到subprocess模块。本文原来是和multiprocessing作为一个整体来介绍的，后来进行了拆分，但内容仍然会有所重叠，并且会涉及Python的线程和进程相关机制。 简单的调用subprocess提供了一下三个函数来实现简单的调用-检查结果的功能，下面列出了它们接受的常用参数。 call(args, *, stdin=None, stdout=None, stderr=None, shell=False) 返回错误码returncode。 check_call(args, *, stdin=None, stdout=None, stderr=None, shell=False) 在returncode为0时返回0，否则抛出subprocess.CalledProcessError异常。 check_output(args, *, stdin=None, stderr=None, shell=False, universal_newlines=False) 返回标准输出，在错误时抛出subprocess.CalledProcessError异常。注意在前面两个函数中实际上也可以通过设置stdout等参数来重定向标准输出和标准错误。 有关shell参数的说明容易发现shell参数为True时第一个参数推荐是一个字符串，而为False时我们需要传入一个原命令行.split(&quot; &quot;)的列表过去，而不能够直接将参数直接和程序名写到一个字符串里面，这么做的目的是为了防止shell注入的发生。12345&gt;&gt;&gt; subprocess.call(["ls", "-l"])0&gt;&gt;&gt; subprocess.call("ls -1", shell=True)1 我们查看一个shell注入的实例，下面的代码本意是想cat一个文件，但最终却运行了恶意的rm -tf /代码。12345&gt;&gt;&gt; from subprocess import call&gt;&gt;&gt; filename = input("What file would you like to display?\n")What file would you like to display?non_existent; rm -rf / #&gt;&gt;&gt; call("cat " + filename, shell=True) # Uh-oh. This will end badly... 此外，shell参数为True时还能运行一些命令，例如在windows中我们运行dir /B只能通过shell来做，这是因为dir并不是一个程序，而是cmd内置的一个命令。Subprocess文档指出这是我们唯一在Windows下需要指定shell = True来运行一个程序的情况，subprocess根据COMSPEC环境参数来运行shell。但在下面的讨论中我们看到shell的设置也影响了输入输出流重定向的细节。 Popen对于大多数的灵活需求，我们都需要Popen这个类来解决。Popen的定义如下所示：1Popen(args, bufsize=0, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=False, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0 部分参数说明以下说明来自Subprocess文档 bufsize 等同于open函数的buffering参数。设为0表示无缓存。设为1表示行缓存。大于1表示使用这个size的缓冲区。负数表示系统默认。 executable 有一些晦涩而不常使用的作用，比较有用的是shell = True时会用它来指定用的shell。 preexec_fn (POSIX) 这个在下面的强制终止进程的讨论中会用到，其作用是在子程序执行前在子程序上下文中需要执行的语句，实际上是一个Hook。 close_fds (POSIX) 对于Linux，子进程在执行前会先关闭除标准输入输出外的所有fd。我们使用以下的代码来测试这个特性 12345678910import os, sys, time, signalimport subprocess# Parentif __name__ == '__main__': fd = os.open("test.txt", os.O_RDWR | os.O_CREAT) os.write(fd, "line1 \n") proc = subprocess.Popen(["python", "ch.py"])# Childif __name__ == '__main__': os.write(3, "line2 \n") 运行发现test.txt中有两行的输出。特别地，这个特性是由Linux保证的，查看subprocess源码，发现它在内部采用了先fork再exec的策略。而exec也是保持file descriptor的。 1234567self.pid = _posixsubprocess.fork_exec( args, executable_list, close_fds, sorted(fds_to_keep), cwd, env_list, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, errpipe_read, errpipe_write, restore_signals, start_new_session, preexec_fn) 对于Windows事情就没有这么美妙了，close_fds = True意味着子进程不会继承任何从父进程过来的句柄，也就是说我们不能重定向标准输入输出了，一个可行的解决方案。 cwd 这个设置子线程的环境目录 env 这个设置子线程的环境变量 universal_newlines 这个用来统一所有的换行符模式为\n startupinfo (Windows) Windows的CreateProcess的对应参数 不同操作系统的不一致性首先，我们可以通过if &#39;posix&#39; in sys.builtin_module_names来判断操作系统是否为POSIX。 有关重定向标准流的问题Popen的stdin等参数用来重定向子程序的三个标准流，常见选项是subprocess.PIPE、None和一个打开的文件。使用None继承父进程的标准流，例如当shell = False时则所有父程序的输入会被转发给子程序，但当shell = True时会先启动一个shell再运行程序，这时候实际上是接受的shell的标准输入。使用subprocess.PIPE则和子程序之间建立管道。特别地，我们可以指定open(os.devnull, &#39;w&#39;)来忽略一个流。可以调用Popen.communicate(input)来通过管道向子进程传递信息，之后程序会阻塞在communicate上，直到从子程序传回信息。与communicate方法对应的是Popen.stdin.write()方法，这两个有一些区别。此外communicate会默认调用stdin.close()，这相当于向对方发送一个EOF。所以当需要多次向子程序写数据时，并且子程序侦测来自主程序的EOF作为结束提示时，应当使用stdin.write。在写ATP时我还遇到程序子程序无法获得stdin.write()写入的数据的情况，这是需要设置shell=True。在写Nuft的时候，有一次发现subprocess.Popen(&quot;./bin/node -f./settings.txt -i0&quot;, subprocess.PIPE, open(&quot;n0.out&quot;, &quot;w&quot;), open(&quot;n0.err&quot;, &quot;w&quot;)这样的是没有输出的，后来我索性在控制台里面执行了&gt; n1.out这样的操作，发现在Ctrl+C中断之后也是没有重定向的内容的。所以这个并不是subprocess的问题。根据SoF，这实际上是Linux的lazy write问题，我们需要在进程结束的时候手动fflush一下。我们可以注册一个SIGTERM和SIGINT等事件的钩子，这样就可以发送SIGTERM来终止进程了。注意我们可能在SIGTERM之后还要在收尾SIGKILL一下，如下所示123456if proc.poll() == None: # Give a chance to save work os.killpg(os.getpgid(proc.pid), signal.SIGTERM) time.sleep(0.2) # Note we can't add a `if` here, otherwise we can't eliminate all child procs. os.killpg(os.getpgid(proc.pid), signal.SIGKILL) 管道死锁subprocess中给我们提供了一个.communicate(input=None)方法，我们向子进程的stdin输入数据，然后接受来自stdout和stderr的输出，直到读到EOF或者子进程结束。Python官方鼓励使用communicate()替代.wait()方法，这是因为如果我们在wait时子进程还在往stdout/stderr中写数据，我们由阻塞在wait上不能读取，当管道的缓存被写满后子进程就会停止写等待我们读取缓冲区，而此时我们还在傻傻地wait子进程！这就造成了死锁。 强制终止进程subprocess提供了kill()函数来终止进程，但这常常不能如愿，这常发生在我们想要kill的进程启动了其他的子进程时。父进程终结并不意味着子进程终结。我们知道Linux中包含有进程组(process group)和会话(session)两个概念。进程组由fork或exec产生，按照父子关系传递，进程组的pgid由进程组leader的pid决定，但leader可以先挂，此时进程组仍然存在，并保有相同的pgid。我们可以通过以下的bash代码查看/枚举pgid/sid1234ps -p 进程ID -o pgrp=ps -A -o pgrp= ps -p 进程ID -o sid=ps -A -o sid= 在Python中，如果我们subprocess启动的进程启动了其他的子进程，那么在杀死该进程后子进程并不会被杀死，而是变为孤儿进程（注意区别僵尸进程），随后被同进程组的其他进程或者init接管。但是我们可以向整个进程组signal，也就是我们下面使用os.killpg来终止进程组。1234567# 从终止着手if 'posix' in sys.builtin_module_names: # 杀掉proc.pid所在的用户组 os.killpg(os.getpgid(proc.pid), signal.SIGKILL)else: # F表示强制终止，T表示终止该进程和所有以此启动的子进程 subprocess.call(['taskkill', '/F', '/T', '/PID', str(self.proc.pid)], stdout = open(os.devnull, 'w')) 我们容易发现这个方法存在一定缺陷，如果我们当前的程序不是该进程组的leader，那么我们简单粗暴的os.killpg会误伤该进程组中的其他进程。例如，假设我们的fa进程启动了ch进程，ch进程启动了grand_ch进程，这时候我们想终止fa，使用os.killpg是可以的，因为fa是当前进程组的leader，fa的家族ch和grand_ch都是我们想终止的对象。但当这个fa进程是由grand_fa进程启动时，当前进程组是以grand_fa为leader的家族，我们使用os.killpg(fa.pid, signal.SIGKILL)就会误杀grand_fa。会话则层级更高，由一个前台进程组和若干后台进程组组成（统称为作业job）建立，每个会话可以关联一个终端（称为控制终端）来实现与人的交互，例如键盘的输入Ctrl+C等都会交给此时前台的进程组。会话也有leader，同样是由第一个创建的进程（通常是bash）决定，当终端的链接断开时，会话leader就会收到SIGHUP信号，而这个信号的默认处理就是关闭所有子进程。因而我们常通过nohup cmd &amp;或者disown来在后台执行长期任务。123456# 启动时建立一个独立的进程组if 'posix' in sys.builtin_module_names: # 创建一个会话组，设置当前进程为会话组组长 return subprocess.Popen(exe, stdin = fin, stdout = fout, stderr = ferr, shell = in_shell, preexec_fn = os.setsid)else: return subprocess.Popen(exe, stdin = fin, stdout = fout, stderr = ferr, shell = in_shell) subprocess的惯用法与坑threading.Thread.join不能捕获SIGINT等信号根据Python官网的Bug，我们在主线程中等待子线程join，这个阻塞的过程不能被SIGINT(2)所唤醒，而SIGINT也不能执行其默认的退出处理，稍后尝试了SIGTERM等信号也同样不能响应，唯有SIGSTOP和SIGKILL可用。这是因为至少在POSIX系统中Lock.acquire()（PyThread_acquire_lock()）中无论是信号量还是CV的实现都会忽略信号。这个问题可以通过设置.join()的timeout参数来解决。注意如果daemon为False则timeout参数无效，这里的daemon表示守护线程。守护线程通常是一些不是那么重要的线程，Python会在所有非守护线程退出后结束。我们将在这篇文章中专门探讨这个机制。]]></content>
      <tags>
        <tag>python</tag>
        <tag>多线程</tag>
        <tag>Linux</tag>
        <tag>并行计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2字符编码]]></title>
    <url>%2F2018%2F06%2F25%2FPython2Encoding%2F</url>
    <content type="text"><![CDATA[字符编码我们通常见到的字符串编码主要是三种GB2312/GBK、Unicode、UTF-8。GB2312/GBK是多字节(multibytes)编码的一种，属于“ASCII的加强版”，与之平行的由Big5、ShiftJIS之类的编码各自为政，所有这些用两个字节表示汉字的多字节编码标准统称为ANSI编码，同样的汉字在不同的ASNI编码中的表示是不同的。为了避免这个问题，Unicode应运而生，将全世界所有的字符统一编码到一个定长的结构中。Unicode解决了统一编码的问题，但带来了新的问题。第一点，Unicode和ASCII不兼容了，这是因为ASCII只有一个字节，而这一个字节肯定装不下Unicode。第二点，用Unicode传输开销变大了，这是因为很多文档二十六个字母（1个字节）就能解决了，用Unicode多了很多冗余的字节。因此UTF-8应运而生。UTF-8对Unicode进行变长编码（我们可以想象下Huffman树），通常长度在1-4字节。目前Linux系统使用的是UTF-8编码，而Windows内部则是UTF-16LE/GBK编码。 Python2的字符串表示Python2中有表示字符串有str和Unicode两种。其中一个str字面量由&quot;&quot;表示，我们也可以用&#39;&#39;或者&quot;&quot;&quot;这类括号括起，一个Unicode字面量由u&quot;&quot;括起。12345678&gt;&gt;&gt; "你好"'\xc4\xe3\xba\xc3'&gt;&gt;&gt; u"你好"u'\u4f60\u597d'&gt;&gt;&gt; type("你好")&lt;type 'str'&gt;&gt;&gt;&gt; type(u"你好")&lt;type 'unicode'&gt; 其中Unicode得益于ucs2/ucs4标准，在不同系统上都是固定的表示的。其中ucs2即Unicode16，比较常见，用2个字节(65536)来索引，一般表示是u&quot;\uxxxx&quot;，ucs4即Unicode32，一般表示是u&quot;\Uxxxxyyyy&quot;在一些Python中也能见到。我们可以通过下面的代码来检测Python是哪一个123456789--enable-unicode=ucs4&gt;&gt;&gt; import sys&gt;&gt;&gt; print sys.maxunicode1114111--enable-unicode=ucs2&gt;&gt;&gt; import sys&gt;&gt;&gt; print sys.maxunicode65535 str的表示取决于所在的系统，例如Linux是默认UTF8，上面的“你好”就会变为&#39;/xe4/xbd/xa0/xe5/xa5/xbd&#39;，我们这里看到UTF8确实是一种字符的表示。1234567891011&gt;&gt;&gt; "hello".encode("utf-8")'hello'&gt;&gt;&gt; "hello".decode("gbk").encode("utf-8")'hello'&gt;&gt;&gt; "你好".encode("utf-8")Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;UnicodeDecodeError: 'ascii' codec can't decode byte 0xc4 in position 0: ordinal not in range(128)&gt;&gt;&gt; "你好".decode("gbk").encode("utf-8")'\xe4\xbd\xa0\xe5\xa5\xbd' Python2中字符串问题实录reload在Python2中出现编码问题时，很多人喜欢使用下面的语句来改变系统的默认编码123import sysreload(sys)sys.setdefaultencoding('utf-8') 这种策略通常用来解决下面这样的错误提示 UnicodeEncodeError: &apos;ascii&apos; codec can&apos;t encode byte 现在ASCII码不能encode是吧，那我默认都用utf-8来encode总行了吧？但这样可能存在问题，博文中就举出了一个实例。对于多字节字符串str，我们之前默认用ASCII解码，要是解不开，就RE了。现在我们默认用utf-8解，utf-8阈值广，基本都能解开，不RE了，可是就不WA了么？样例中举出一个例子，一个latin-1编码的字符串，用utf-8解码不会报错，但解出来的结果并不对。因此在多字节编码规则不统一这个客观问题存在的情况下，不存在银弹。我们需要的是用chardet.detect来猜测编码。当猜测不出时我们只能不停地try，直到找到一个解码不报错的编码，虽然可能解出来还是乱码，因为可能一段byte串同时用utf-8、gbk、Big5等都能解码而不报错。这里提供一个工具类，能够尽可能地猜测字节串所使用的编码1234567891011121314151617181920212223def ultimate_decode(doc): def try_decode(s, try_decoding): try: res = s.decode(try_decoding) return True, res except UnicodeDecodeError: return False, "" if isinstance(doc, str): predicted = chardet.detect(doc) print predicted if predicted['encoding'] and predicted['confidence'] &gt; 0.5: doc = doc.decode(predicted['encoding']) else: encodeing_list = ["utf-8", "gbk", "Big5", "EUC-JP"] for e in encodeing_list: state, res = try_decode(doc, e) if state: doc = res break if not isinstance(doc, unicode): return None return doc coding当我们在Python代码文件中需要加入中文时，我们需要在文件开头加上这两行中的一行，不然即使用上前面的reload大法都不行。12# -*- coding:utf-8 -*-# coding: utf8 这是用来指定Python代码文件所使用的编码方式。在Python2.1时，这个机制还没有引入，我们只能通过unicode-escape的方式输入。一个类似的做法是很多json库dump的结果中常出现\u打头的unicode-escape字符串，这是非常正常的现象。这样json库可以省事地避免编码问题，因为这样json文件现在都是ASCII码了。 伪装成Unicode的多字节有时候我们会看到这种东西u&#39;\xe3\x80\x8a\xe5&#39;，首先这外面套了个u，应该是Unicode，但是里面却是\x打头的multi-bytes的形式，这往往是由于错误调用unicode()函数所致的。对此，python提供了raw_unicode_escape来解决这个问题 正则匹配由于存在特殊符号的原因，使用正则匹配时宜使用Unicode而不是多字节匹配。但是以下的编码在Win10和某些Linux发行版上都跑不了，但在MacOS和Ubuntu上能够正常运行，去StackOverflow问了，他们认为这是一个Bug，所以暂时还是先用上面的方法。]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Kickstart 2018 Round B题解]]></title>
    <url>%2F2018%2F06%2F14%2FKickstart2018B%2F</url>
    <content type="text"><![CDATA[继续写第二轮 A. No Nine数位DP直接莽过了，也可以推公式吧，反正我懒。 AC代码 B. Sherlock and the Bit Strings小数据蛮简单的，因为它相当于限定了若干格子里面的到底是0还是1了（注意我脑抽直接认为$C_i = 1$了，WA得蛮惨的）。然后就是将$P - 1$填在长度为$N$的串从后往前还没有被固定的格子里面。大数据就有点难度了，因为$A_i$和$B_i$不相等了。 AC代码（小）]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>codejam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Kickstart 2018 Round A题解]]></title>
    <url>%2F2018%2F06%2F14%2FKickstart2018A%2F</url>
    <content type="text"><![CDATA[Kickstart，我又回来了，今年是校招年了，所以加油吧。 A. Even Digits这道题蛮简单的，就是要求离$N$最近的都是数位上都是偶数的数，所以可以向上或者向下找。简单的说就是最高位++或者--，然后剩下来通通改成8或者0。不过我们需要额外考虑一下借位和进位的情况，对于向下来说，不存在，因为1下面是0，不需要借位。对于向上来说9上面是10，要进一位，但是我们注意到进的1是奇数，所以我们还要将它变成2，这无疑是比向下的方法去多了，所以我们不需要考虑9的进位。 AC代码 B. Lucky Dip有物品$V_i$，假如最多有$K$次放回重抽的机会，问最后手上的物品期望最高是多少。首先由于是不放回的，所以每次的概率其实都是平均的。所以$K = 0$时就是平均数，下面我们思考最优策略是什么。其实很简单，我们枚举$i$，我们的策略就是在对$V_i$不满意的时候逆天改命。下面就是判断标准，是与平均数比吗，还是和中位数比呢？我们假设第$d$次的期望是$prev = dp[d]$，现在我们决定要不要抽第$d + 1$次，这取决于我们实际抽到的$V_i$是否高于期望$prev$。 AC代码]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>codejam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用语言的时间模块]]></title>
    <url>%2F2018%2F06%2F12%2FAllTimeModule%2F</url>
    <content type="text"><![CDATA[在相当长的时间里面，与时间相关的库我总是很不熟练，每次用到总要卡一下，慢慢Google，这次索性直接记下来，这样下次遇到我就可以查自己的博客而不是Google了（反正我是不会记在脑子里面的是吧~）。 PythonPython表示时间可以用float格式的时间戳、time.struct_time和字符串三种表示。 struct_time time.struct_time是一个构造struct_time time.struct_time(tm_year=2016, tm_mon=4, tm_mday=7, tm_hour=10, tm_min=3, tm_sec=27, tm_wday=3, tm_yday=98, tm_isdst=0) 时间戳 时间戳是以秒为单位的浮点 时间格式的转换struct_time是Python中最灵活的表现时间的方式，它是一个不包含时区信息的struct。 字符串和time.struct_time 注意，借助于time模块不能Parse秒后面跟着毫秒的情况 12ts = time.strptime("2020-12-12T11:11:11Z", "%Y-%m-%dT%H:%M:%SZ")time.strftime("%Y-%m-%dT%H:%M:%S.%fZ", ts) struct_time和时间戳 12time.mktime(ts)time.localtime(time.time()) 如果我们知道自己的localtime是东八区，那么想知道日本当前的时间，就是 1time.localtime(time.time()+60*60) 如果需要得到当前的utc时间，需要借助于datetime模块，同样返回一个struct_time 1datetime.datetime.utcfromtimestamp(time.time()) 也可以通过下面的方法实现 1time.gmtime(time.time()) 那么如果我们对localtime不信任，要得到一个东八区的struct_time就可以如下操作 1time.gmtime(time.time()+60*60*8) datetimedatetime模块是基于datetime.datetime类来实现的 时间戳和datetime 12tz = pytz.timezone('Asia/Shanghai')datetime.datetime.fromtimestamp(int(time.time()), tz) 转换回来没有对应函数，但可以算出来 12t = (dt - datetime(1970, 1, 1)) / timedelta(seconds=1)t = (dt - datetime(1970,1,1, tzinfo=timezone.utc)) / timedelta(seconds=1) datatime和struct_time 可以直接获取 1dt.timetuple() 也可以借助于时间戳中转 1dt = datetime.datetime.fromtimestamp(time.mktime(ts)) 还有一种骚的方法 12st = time.localtime()dt = datetime.datetime(*st[:6]) 常用需求 解析一个时间戳，并进行变换 由于有些场景用UTC时间戳来表示一个东八区时间，所以需要对时间计算偏移，例如回答X小时后的时间是多少的问题。 12datetime.datetime.now() + datetime.timedelta(days=-1)datetime.datetime.now() + datetime.timedelta(hours=8) 比较两个时间 获得两个时间差，其中seconds是时间差除开days之外的秒数，而total_seconds()是总秒数，如果需要知道两个时间之间差了多少秒，应该用后者 1234time_delta = (datetime.datetime(2020,1,1,0,0,0) - datetime.datetime(2020,1,1,1,0,0))time_delta.days # -1time_delta.seconds # 82800 # 可以看到seconds必须要和days拼起来看，不然就不准time_delta.total_seconds() # -3600]]></content>
      <tags>
        <tag>C++</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gRPC配置与用法]]></title>
    <url>%2F2018%2F03%2F28%2FgRPC-usage%2F</url>
    <content type="text"><![CDATA[本文中介绍了如何配置gRPC和brpc。gRPC的配置真的是蛋疼。主要原因是官方的推荐方式是从源码编译。于是我首先花了一个下午用小水管clone了下gRPC和它的十来个三方库。 安装和配置protobufgRPC依赖于protobuf，但我们不能盲目安装protobuf，例如Ubuntu默认的protobuf是2.6.1，而Google给的helloworld示例需要protobuf 3才能编译，所以不能用apt安装。此外即使从源码编译装，也没必要去protobuf的官方仓库。注意gRPC不会自动帮你make install protobuf，所以需要到gRPC的third_party目录下找到protobuf的源码编译安装。更新gRPC中的子模块的命令如下1git submodule update --init --recursive 进入protobuf目录123456./autogen./configuremakemake checksudo make installsudo ldconfig 注意点 ./autogen里面会下载gmock，可能会失败，这里可以直接进去注释掉相关语句。 需要安装libtool，否则会出现undefined macro: AC_PROG_LIBTOOL 需要安装autoconf，否则会出现autoreconf: command not found 由于protobuf的安装版本不带调试信息，有时候会出现Can&#39;t parse message of type的情况，不能assert然后调试dump，可参考https://github.com/protocolbuffers/protobuf/issues/1102编译调试版本。 gRPC项目的编译编译gRPC应当遵循BUILDING.md12345678apt-get install build-essential autoconf libtool pkg-configapt-get install libgflags-dev libgtest-devapt-get install clang libc++-devgit clone -b $(curl -L https://grpc.io/release) https://github.com/grpc/grpccd grpcgit submodule update --initmakemake install 在编译gRPC项目时，对于客户端会生成.pb.h和.pb.cc两个文件；但是服务端则需要.grpc.pb.h和.grpc.pb.cc两个文件。这四个文件是由protoc通过不同的指令生成的，如下所示，这里grpc_out即表示生成服务端需要使用的带.grpc.pb系文件，plugin字段需要我们指明grpc_cpp_plugin这个插件所在的位置。如果我们从源码编译安装的话，这个插件一般会在/usr/local/lib里面，我们一般需要将这个路径export出来1export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH 当然也可以运行这个脚本来一劳永逸地解决问题。 注意点 注意使用git clone -b $(curl -L https://grpc.io/release) https://github.com/grpc/grpc来下载grpc的release版本对应的repo。 unused-variable的错误，可见https://github.com/grpc/grpc/issues/16739，不过解决不了问题，我是替换掉所有-Werror`解决的 Makefile如果直接使用Makefile来编译，我们需要先按照下面的规则生成四个文件，此外我们还需要将程序链接到protobuf、grpc++、grpc这三个库上。gRPC的官方Git仓库中提供了Makefile的demo。12$ protoc -I ../../protos --grpc_out=. --plugin=protoc-gen-grpc=`which grpc_cpp_plugin` ../../protos/route_guide.proto$ protoc -I ../../protos --cpp_out=. ../../protos/route_guide.proto CMakegRPC的官方Git仓库也提供了CMakeLists的Demo，不过我并没有能够成功进行编译，它提示缺少gRPCConfig.cmake或grpc-config.cmake文件，于是我放弃了来自官方的CMakeLists。在我先前的protobuf试用中，我了解了cmake中的PROTOBUF_GENERATE_CPP宏可以编译出.pb.h和.pb.cc两个文件，现在我们需要依葫芦画瓢搞出一个PROTOBUF_GENERATE_GRPC_CPP宏就行了。在爆栈网的一篇回答中我找到了一个实用的实现，借助于它我实现了自己的CMakeLists。注意目前gRPC的编译需要C++11标准的支持，所以这里我使用了SET(CMAKE_CXX_COMPILER /usr/bin/g++-7 CACHE PATH &quot;&quot; FORCE)来强制设置了编译器。 可以在https://github.com/CalvinNeo/ARPC/blob/master/test/grpc/中找到我的一个完整的配置 gRPC使用的坑14 Connection RefusedLinux下的Connection Refused这是由于我们配置了http_proxy的缘故 Server::Shutdown根据https://github.com/grpc/grpc/issues/10324，这个函数也会阻塞 gRPC服务类型gRPC支持Unary RPC、Server streaming RPC、Client streaming RPC和Bidirectional streaming RPC。 常用类服务端一般服务器端的类包含ServiceImpl类（一般派生自Service类）、grpc::ServerBuilder类、Server类。我们一般可以用下面的类进行封装1234567891011121314151617181920struct Context&#123; ServiceImpl * service; std::unique_ptr&lt;Server&gt; server; ServerBuilder * builder; Context(/* 这里可以加上一点用来初始化ServiceImpl类的上下文 */)&#123; service = new ServiceImpl(/* 上下文 */); builder = new ServerBuilder(); builder-&gt;AddListeningPort(/* 地址和端口 */, grpc::InsecureServerCredentials()); builder-&gt;RegisterService(service); server = std::unique_ptr&lt;Server&gt;&#123;builder-&gt;BuildAndStart()&#125;; wait_thread = std::thread([&amp;]()&#123;server-&gt;Wait();&#125;); &#125;; ~Context()&#123; server-&gt;Shutdown(); wait_thread.join(); delete service; delete builder; &#125; std::thread wait_thread;&#125; Service::package_name::ServiceName::Service（简称为Service）类是由Protobuf根据我们proto文件自动生成的类，实际上是用C++描述了ServiceName这个service。我们一般会从Service中派生出一个类ServiceImpl: Service类来实现这些方法。1234struct ServiceImpl: public ::package_name::ServiceName::Service&#123; Status RPC1(grpc::ServerContext* context, const package_name::RPC1Request*, package_name::RPC1Response*); /* ... */&#125; Statusgrpc::Status类一般用来维护RPC调用的状态 ServerServer类 gRPC线程模型gRPC提供了异步和同步的API。https://github.com/grpc/grpc/pull/10919/files brpc的编译安装brpc依赖gflags、protobuf、openssl和leveldb。其中gflags按照以下方式安装12345git clone https://github.com/gflags/gflags.gitmkdir build &amp;&amp; cd buildcmake -DCMAKE_INSTALL_PREFIX=/usr/local -DBUILD_SHARED_LIBS=ON -DGFLAGS_NAMESPACE=google ../ make sudo make install openssl通过以下命令安装1apt install libssl-dev openssl 接下来make，注意一定要加上--with-glog不然例如braft里面的test的用到glog的都有问题12sh config_brpc.sh --headers="/usr/local/include /usr/include" --libs=/usr/local/lib --cxx=g++ --cc=gcc --nodebugsymbols --with-glogmake 在gRPC 3.7版本后，GoogleOnceInit被用std::call_once取代了，这时候编译brpc就会出现问题。这里推荐使用3.6的版本，特别注意，在换版本之后一定要先make clean掉已经生成的pd文件。 这里注意一下，我们可以同时从源码和从apt安装protobuf的，这时候我们就要指定我们要用哪个版本的protobuf。一般apt安装在不带local的文件夹下。 特别地，gflags可能和glog产生冲突，这时候可以先apt purge掉gflags再编译glog。或者可以采用./configure CPPFLAGS=&quot;-I/usr/local/include&quot; LDFLAGS=&quot;-L/usr/local/lib&quot;命令编译。]]></content>
      <tags>
        <tag>gRPC</tag>
        <tag>protobuf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++智能指针的使用与实现]]></title>
    <url>%2F2018%2F03%2F18%2FC%2B%2B-smart-pointer%2F</url>
    <content type="text"><![CDATA[在C++史前时代只有一种智能指针std::auto_ptr&lt;T&gt;，它的作用方式类似一个lock_guard&lt;T&gt;，或者经过封装的RAII。但在使用中发现，依托于RAII是不够的，为了方便地实现更复杂逻辑下的资源管理，我们需要从资源的所有权上对智能指针进行更加细致的分类。在C++11之后，标准库引入了std::shared_ptr&lt;T&gt;、std::unique_ptr&lt;T&gt;、std::weak_ptr&lt;T&gt;来替换之前的std::auto_ptr&lt;T&gt;。截至目前为止，我基本没怎么用过智能指针，一方面之前做的项目都比较局限，使用RAII或者对象池会更方便，另一方面智能指针和对C风格的兼容性也不是很好，例如很多C风格的代码要求bit-wise而不是member-wise的操作，而智能指针并不是trivial的，而且具有传染性，所以往往适用不了。【未完待续】 auto_ptrshared_ptr正确使用shared_ptr构造函数、删除器与分配器std::shared_ptr的构造函数有12种之多，这里只列举几种重要的123456789// 构造一个空的智能指针constexpr shared_ptr() noexcept;constexpr shared_ptr( std::nullptr_t ) noexcept;// 这是最常用的template&lt;class Y&gt; explicit shared_ptr( Y* ptr );// 这里在后面加了一个删除器的参数template&lt;class Y, class Delete &gt; shared_ptr( Y* ptr, Deleter d );// 这里又添加了一个分配器的函数template&lt;class Y, class Deleter, class Alloc&gt; shared_ptr( Y* ptr, Deleter d, Alloc alloc ); 删除器和分配器构成了智能指针的主要特性之一。我们知道智能指针的重要特点就是自动帮助我们管理资源，它们解决了何时销毁对象的难题WHEN，但同时也让我们可以自行定义如何创建和销毁对象的次要问题HOW。标准库为我们提供了两个标准的std::default_delete&lt;T&gt;的实现，其内容是非常的简单，即直接调用delete和delete []，在这里列出了后者的实现。12345678910111213141516template&lt;class _Ty&gt; struct default_delete&lt;_Ty[]&gt;&#123; // 一个默认的构造函数`shared_from_this()` // 一个默认的构造函数 constexpr default_delete() _NOEXCEPT = default; // 一个默认的复制构造函数 template&lt;class _Uty, class = typename enable_if&lt;is_convertible&lt;_Uty(*)[], _Ty(*)[]&gt;::value, void&gt;::type&gt; default_delete(const default_delete&lt;_Uty[]&gt;&amp;) _NOEXCEPT &#123;&#125; template&lt;class _Uty, class = typename enable_if&lt;is_convertible&lt;_Uty(*)[], _Ty(*)[]&gt;::value, void&gt;::type&gt; void operator()(_Uty *_Ptr) const _NOEXCEPT &#123; static_assert(0 &lt; sizeof (_Uty), "can't delete an incomplete type"); delete[] _Ptr; &#125;&#125;; 在这里需要注意，在C++17前后，std::shared_ptr创建数组的行为仍然是不同的。 在C++17前 创建数组的时候需要手动指定删除器 1std::shared_ptr&lt;int&gt; sp(new int[10], array_deleter&lt;int&gt;()); 从C++17开始 创建数组需要手动指定数组类型int[]，而不再可以使用int了。 1std::shared_ptr&lt;int[]&gt; sp(new int[10]); 循环引用与weak_ptr正确使用shared_ptr与裸指针我们知道智能指针是有传染性的，这意味着我们要避免同时使用raw pointer和智能指针，也要注意不能显式或者隐式地让多个智能指针同时管理同一个raw pointer。我们进一步地探讨这个问题，shared_ptr的主要创建方式有三种： make_shared函数 这个函数是Effective Modern C++所推荐的示例，它会创建一个控制块和一个对象。根据cppreference的介绍，这个函数有5个重载 123456789template&lt;class T, class... Args&gt; shared_ptr&lt;T&gt; make_shared( Args&amp;&amp;... args );// 从C++20开始，这里T是数组U[]template&lt;class T&gt; shared_ptr&lt;T&gt; make_shared(std::size_t N);// 从C++20开始，这里T是数组U[N]template&lt;class T&gt; shared_ptr&lt;T&gt; make_shared();// 从C++20开始，这里T是数组U[]template&lt;class T&gt; shared_ptr&lt;T&gt; make_shared(std::size_t N, const std::remove_extent_t&lt;T&gt;&amp; u);// 从C++20开始，这里T是数组U[N]template&lt;class T&gt; shared_ptr&lt;T&gt; make_shared(const std::remove_extent_t&lt;T&gt;&amp; u); 我们注意一下这里的初始化是小括号初始化而不是C++11新规定的uniform初始化，即花括号初始化，例如下面的语句会创建10个20，如果我们想放两个元素10和20进去就要显式创建一个初始化列表 1234567// 10个20auto upv = std::make_shared&lt;std::vector&lt;int&gt;&gt;(10, 20);// 10, 20// create std::initializer_listauto initList = &#123; 10, 20 &#125;;// create std::vector using std::initializer_list ctorauto spv = std::make_shared&lt;std::vector&lt;int&gt;&gt;(initList); shared_ptr构造函数 这种情况下我们将一个裸指针传给shared_ptr，这时就可能将裸指针泄露出去，从而导致可能的double free问题。因此在Effective Modern C++的条款19中强调best practice是我们写成将new语句写到参数列表里面 1std::shared_ptr&lt;Widget&gt; spw1(new Widget); 特别地，我们也可以从一个unique_ptr构造shard_ptr，这时候我们和上面的裸指针是类似的。 我们不能忽视this也是一个raw pointer，但我们又不能在内部直接定义一个std::shared_ptr&lt;T*&gt;(this)，这毫无疑问会导致循环引用。更严重的是在对象内部传出this是非常常见的，例如bind系列的函数，会使用this作为一个context。为了能够正确使用this，就得让我们的类继承一个enable_shared_from_this&lt;T&gt;，并传入一个shared_from_this()作为this的化身。书中甚至对这种继承一个以自己为模板参数的父类的方法介绍了一种专门的称呼，叫The Curiously Recurring Template Pattern(CRTP)。12345struct Widget: public std::enable_shared_from_this&lt;Widget&gt;&#123; void process()&#123; processedWidgets.emplace_back(shared_from_this()); &#125;&#125;; 在使用shared_from_this()时我们需要注意以下问题： 二次析构 在构造函数中不能使用shared_from_this()，否则会抛出std::bad_weak_ptr我们下面来探究一下这个类的实现原理。它首先寻找当前对象的控制块，然后创建一个新的std::shared_ptr来引用那个控制块。 使用make函数而不是使用智能指针的构造函数这个来自于Effective Modern C++的条款21。原因之一是make函数是异常安全的，下面的代码可能导致内存泄露1processWidget(std::shared_ptr&lt;Widget&gt;(new Widget), computePriority()); // potential resource leak! 原因是什么呢？我们考虑这个调用的过程可以分为下面三个阶段： 创建new Widget 构造std::shared_ptr&lt;Widget&gt; 计算computePriority() 根据C++标准，这三个的求值顺序是UB的。我们考虑编译器产生1/3/2这样的执行顺序，并且此时computePriority()产生了异常，此时步骤1中new出来的对象就泄露了。此外，对shared_ptr来说，使用make_shared函数还能提高效率。这是由于创建new Widget和控制块分配两次内存，而使用make_shared函数可以一次分配完。我们来看看标准库的实现，在这里我们看到只分配了一个_Ref_count_obj&lt;_Ty&gt;的对象，这个对象实际上继承了我们上面看到的_Ref_count_base的子类，它有一个typename aligned_union&lt;1, _Ty&gt;::type _Storage的字段管理了我们实际的对象。12345678910111213141516template&lt;class _Ty, class... _Types&gt; inlineshared_ptr&lt;_Ty&gt; make_shared(_Types&amp;&amp;... _Args)&#123; // make a shared_ptr _Ref_count_obj&lt;_Ty&gt; *_Rx = new _Ref_count_obj&lt;_Ty&gt;(_STD forward&lt;_Types&gt;(_Args)...); shared_ptr&lt;_Ty&gt; _Ret; _Ret._Resetp0(_Rx-&gt;_Getptr(), _Rx); return (_Ret);&#125;// In _Ref_count_obj's definitiontemplate&lt;class... _Types&gt; _Ref_count_obj(_Types&amp;&amp;... _Args) : _Ref_count_base()&#123; // construct from argument list ::new ((void *)&amp;_Storage) _Ty(_STD forward&lt;_Types&gt;(_Args)...);&#125; 此外从之前的讨论中我们看到make_shared杜绝了我们看到裸指针的一切可能性，因为它在函数内部创建了智能指针所指向类的实例，因此也更安全。 shared_ptr的结构与实现我们以PJ Plauger的STL实现为例来查看这个智能指针的实现 基类_Ptr_basestd::shared_ptr继承了_Ptr_base，里面持有了两个指针，第一个就是实际的裸指针_Ptr，另一个是控制块指针_Rep。所有的控制块包括_Ref_count&lt;T&gt;、_Ref_count_del&lt;T&gt;、_Ref_count_del_alloc&lt;T&gt;、_Ref_count_obj&lt;T&gt;、_Ref_count_obj_alloc&lt;T&gt;，都继承自_Ref_count_base。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// shared_ptr的基类template&lt;class _Ty&gt; class _Ptr_base &#123; // base class for shared_ptr and weak_ptr /* ... */ private: // 这是真实资源的指针 _Ty *_Ptr; // 这是shared_ptr外挂式的控制块 _Ref_count_base *_Rep; // 所有的实例化的_Ptr_base都互为友元 template&lt;class _Ty0&gt; friend class _Ptr_base; &#125;;&#125;;// 所有控制块对象的基类class _Ref_count_base &#123; // common code for reference countingprivate: // 删除裸指针 virtual void _Destroy() _NOEXCEPT = 0; // 删除自己 virtual void _Delete_this() _NOEXCEPT = 0;private: _Atomic_counter_t _Uses; _Atomic_counter_t _Weaks;protected: // 注意在涉及引用计数的部分，都要是原子的，这里默认使用了Windows的互锁函数，详情可参见我的[博文《并发编程重要概念及比较》](/2017/12/28/Concurrency-Programming-Compare/) // _Ref_count_base() &#123; // construct // 在构造时我们初始化引用计数都为**1** _Init_atomic_counter(_Uses, 1); _Init_atomic_counter(_Weaks, 1); &#125;public: // 虚析构函数 virtual ~_Ref_count_base() _NOEXCEPT &#123; // ensure that derived classes can be destroyed properly &#125; bool _Incref_nz() &#123; // increment use count if not zero, return true if successful ... &#125;; // 这里直接进行强转，以便调用互锁函数 #define _MT_INCR(x) _InterlockedIncrement(reinterpret_cast&lt;volatile long *&gt;(&amp;x)) #define _MT_DECR(x) _InterlockedDecrement(reinterpret_cast&lt;volatile long *&gt;(&amp;x)) void _Incref() &#123; // increment use count _MT_INCR(_Uses); &#125; void _Incwref() &#123; // increment weak reference count _MT_INCR(_Weaks); &#125; void _Decref() &#123; // decrement use count if (_MT_DECR(_Uses) == 0) &#123; // destroy managed resource, decrement weak reference count _Destroy(); _Decwref(); &#125; &#125; void _Decwref() &#123; // decrement weak reference count if (_MT_DECR(_Weaks) == 0) _Delete_this(); &#125; ... 初始化过程的实现进一步研究上面列出的构造函数中的实现，我们发现它们引用了下面三个函数之一，分别是适用于构造函数是否指定了Deleter和Allocator的情况。这里我们看到shared_ptr的某些构造函数是会抛出异常的，所以我们会看到书中的best practice建议使用make系函数而不是构造函数进行创建。下面我们首先查看三个_Resetp函数，这些函数用来接管一个裸指针_Px，根据上面的讨论，我们知道这时候控制块肯定是不存在的，因此创建一个全新的控制块，它们实际上对应通过裸指针创建shared_ptr的构造函数。我们稍后会看到一组_Reset函数，它们则处理较为复杂的情况12345678910111213141516171819202122232425262728293031323334353637383940private: template&lt;class _Ux&gt; void _Resetp(_Ux *_Px) &#123; // release, take ownership of _Px _TRY_BEGIN // allocate control block and reset // 注意_Ref_count在创建时两个引用计数都为1了，因为它继承了_Ref_count_base，详见_Ref_count_base相关代码 _Resetp0(_Px, new _Ref_count&lt;_Ux&gt;(_Px)); _CATCH_ALL // allocation failed, delete resource delete _Px; _RERAISE; _CATCH_END &#125; template&lt;class _Ux, class _Dx&gt; void _Resetp(_Ux *_Px, _Dx _Dt) &#123; // release, take ownership of _Px, deleter _Dt _TRY_BEGIN // allocate control block and reset _Resetp0(_Px, new _Ref_count_del&lt;_Ux, _Dx&gt;(_Px, _Dt)); _CATCH_ALL // allocation failed, delete resource _Dt(_Px); _RERAISE; _CATCH_END &#125; template&lt;class _Ux, class _Dx, class _Alloc&gt; void _Resetp(_Ux *_Px, _Dx _Dt, _Alloc _Ax) &#123; // release, take ownership of _Px, deleter _Dt, allocator _Ax typedef _Ref_count_del_alloc&lt;_Ux, _Dx, _Alloc&gt; _Refd; typedef _Wrap_alloc&lt;_Alloc&gt; _Alref0; typename _Alref0::template rebind&lt;_Refd&gt;::other _Alref(_Ax); _TRY_BEGIN // allocate control block and reset _Refd *_Pref = _Alref.allocate(1); _Alref.construct(_Pref, _Px, _Dt, _Ax); _Resetp0(_Px, _Pref); _CATCH_ALL // allocation failed, delete resource _Dt(_Px); _RERAISE; _CATCH_END &#125; _Resetp0是所有_Resetp的终点，包含了两个调用，我们将对此进行探讨1234567public: template&lt;class _Ux&gt; void _Resetp0(_Ux *_Px, _Ref_count_base *_Rx) &#123; // release resource and take ownership of _Px this-&gt;_Reset0(_Px, _Rx); _Enable_shared(_Px, _Rx); &#125; this-&gt;_Reset0 _Reset0基类_Ptr_base中有定义，并且派生类std::shared_ptr也没有进行覆盖，它的功能是切换智能指针管理另一个资源。可以看到，如果此时智能指针已经绑定了控制块，那么就调用_Decref自减一次（代码可查看上面_Ptr_base的实现），因为稍后我们的智能指针即将管理新的_Other_rep控制块和_Other_ptr对象指针了。容易看到，在被_Resetp0调用时_Rep是空指针，所以我们直接赋值。 12345678void _Reset0(_Ty *_Other_ptr, _Ref_count_base *_Other_rep)&#123; // release resource and take new resource // 这里的_Rep是_Ptr_base持有的_Ref_count_base * if (_Rep != 0) _Rep-&gt;_Decref(); _Rep = _Other_rep; _Ptr = _Other_ptr;&#125; 既然如此，为什么我们不增加下_Other_rep的调用数目呢？其实是会增加的，只是不在_Other_rep之中。首先根据上面的讨论，当_Other_rep是新被创建的对象时，它的两个引用计数就默认被设为0了。其次，当_Other_rep是由其它智能指针创建的，也就是说我们此时将智能指针是从另一个智能指针创建的时，我们会调用之前提到的_Reset函数，而这个函数在自增对方的控制块_Other_rep后才会调用_Reset0 123456789101112131415161718template&lt;class _Ty2, class = typename enable_if&lt;is_convertible&lt;_Ty2 *, _Ty *&gt;::value, void&gt;::type&gt;shared_ptr(const shared_ptr&lt;_Ty2&gt;&amp; _Other) _NOEXCEPT&#123; // construct shared_ptr object that owns same resource as _Other this-&gt;_Reset(_Other);&#125;template&lt;class _Ty2&gt;void _Reset(const _Ptr_base&lt;_Ty2&gt;&amp; _Other)&#123; // release resource and take ownership of _Other._Ptr _Reset(_Other._Ptr, _Other._Rep);&#125;void _Reset(_Ty *_Other_ptr, _Ref_count_base *_Other_rep)&#123; // release resource and take _Other_ptr through _Other_rep if (_Other_rep) _Other_rep-&gt;_Incref(); _Reset0(_Other_ptr, _Other_rep);&#125; _Enable_shared 这里的_Enable_shared用来处理继承了enable_shared_from_this&lt;T&gt;的情况，我们将在下面的讨论中详细了解有关这个函数和enable_shared_from_this的实现。 enable_shared_from_this上文讨论了当需要传出this时，我们应当让我们的类继承template&lt;class _Ty&gt; class enable_shared_from_this，现在来查看一下这个类模板的结构。12345678910111213141516171819202122232425262728template&lt;class _Ty&gt; class enable_shared_from_this&#123; // provide member functions that create shared_ptr to thispublic: // 稍后我们将看到，这个_EStype被用来做SFINAE typedef _Ty _EStype; shared_ptr&lt;_Ty&gt; shared_from_this() &#123; return (shared_ptr&lt;_Ty&gt;(_Wptr)); &#125; shared_ptr&lt;const _Ty&gt; shared_from_this() const &#123; return (shared_ptr&lt;const _Ty&gt;(_Wptr)); &#125;protected: constexpr enable_shared_from_this() _NOEXCEPT &#123;&#125; enable_shared_from_this(const enable_shared_from_this&amp;) _NOEXCEPT &#123;&#125; enable_shared_from_this &amp; operator=(const enable_shared_from_this&amp;) _NOEXCEPT &#123; return (*this); &#125; ~enable_shared_from_this() _NOEXCEPT &#123;&#125;private: // 这个函数是个自由函数，它接受三个参数，分别是托管对象的指针、enable_shared_from_this指针和控制块指针。 // 由于托管对象继承了enable_shared_from_this，所以这两个指针其实是一样的，我们将看到在_Enable_shared函数中直接进行了强转 template&lt;class _Ty1, class _Ty2&gt; friend void _Do_enable(_Ty1 *, enable_shared_from_this&lt;_Ty2&gt;*, _Ref_count_base *); weak_ptr&lt;_Ty&gt; _Wptr;&#125;; 下面我们可以继续查看上面提到的_Enable_shared函数，可以看到这里实际上是一个SFINAE，如果我们的类继承了enable_shared_from_this&lt;T&gt;，那么就会执行_Do_enable函数1234567891011template&lt;class _Ty&gt;inline void _Enable_shared(_Ty *_Ptr, _Ref_count_base *_Refptr, typename _Ty::_EStype * = 0)&#123; // reset internal weak pointer if (_Ptr) _Do_enable(_Ptr, (enable_shared_from_this&lt;typename _Ty::_EStype&gt;*)_Ptr, _Refptr); &#125;inline void _Enable_shared(const volatile void *, const volatile void *)&#123; // not derived from enable_shared_from_this; do nothing&#125; 下面我们来查看这个关键的_Do_enable函数12345template&lt;class _Ty1, class _Ty2&gt;inline void _Do_enable(_Ty1 *_Ptr, enable_shared_from_this&lt;_Ty2&gt; *_Es, _Ref_count_base *_Refptr)&#123; _Es-&gt;_Wptr._Resetw(_Ptr, _Refptr);&#125; 别名使用构造函数和owner_before在shared_ptr的定义中，我们能发现一个奇特的构造函数，即别名使用构造函数(aliasing constructor)。此时它管理一个指针r，但同时指向另外一个unrelated且 unmanaged指针ptr。这个用法看似奇怪，但当我们考虑到如果我们将一个智能指针指向另一个智能指针所拥有的对象的某个成员时，事情变得显然了起来。12template&lt;class Y&gt; shared_ptr( const shared_ptr&lt;Y&gt;&amp; r, element_type* ptr ) noexcept; 在下面的代码中，我们构造一个Father，它持有一个Son的实例，现在我们创建一个智能指针son，它持有father，但是却指向了&amp;father-&gt;son。它负责管理father的生命周期，但调用get会返回son的指针。1234567891011struct Son &#123; // some data that we want to point to&#125;;struct Father &#123; Son son;&#125;;shared_ptr&lt;Father&gt; father = make_shared&lt;Father&gt;(...);// aliasing constructor用法shared_ptr&lt;Son&gt; son(father, &amp;father-&gt;son); 下面我们尝试通过shared_ptr::reset方法来释放father指针对其管理的Father对象的引用。123456// 这时候Father对象的引用计数为2，我们不对Son来计算引用计数father.reset();// 这时候Father对象仍然存在，并且引用计数为1// 如果我们对Son对象计算引用计数的话，这个对象就会被销毁了func(son); 因此可以发现，当我们需要将智能指针p指向一个对象father的某个字段，并且这个字段是一个依赖于该对象的智能指针的时候，我们需要使用aliasing constructor，从而保证当p不销毁时，father也一直存在。此时如果使用operator&lt;比较shared_ptr的大小关系就会发现它们不等，因为指向的对象不同。但此时应当owner_before用来比较两个shared_ptr之间的“大小关系”。1234567std::shared_ptr&lt;Father&gt; father = std::make_shared&lt;Father&gt;(Son());std::shared_ptr&lt;Son&gt; son(father, &amp;father-&gt;son);printf("%d %d\n", father.owner_before(son), son.owner_before(father)); // 0 0std::shared_ptr&lt;Father&gt; father2 = std::make_shared&lt;Father&gt;(Son());std::shared_ptr&lt;Son&gt; son2 = std::make_shared&lt;Son&gt;();printf("%d %d\n", father2.owner_before(son2), son2.owner_before(father2)); // 1 0 unique_ptrunique_ptr实际上相当于一个安全性增强了的auto_ptr。unique_ptr的使用标志着控制权的转移，如果有熟悉Rust的朋友应该会对此感触比较深了。容易想到，unique_ptr并不能被复制，所以它没有复制构造函数和复制赋值运算符。同样，因为删除数组要用到delete []，所以对于数组有个偏特化版本。]]></content>
      <tags>
        <tag>C++</tag>
        <tag>智能指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++历史标准的发展及常见的Workaround和最佳实践]]></title>
    <url>%2F2018%2F03%2F10%2FC%2B%2B-hist-workaround-best%2F</url>
    <content type="text"><![CDATA[C++历史概述C++是一门历史悠久的语言，原来叫C with classes，自1979年以来已经出现了98/03/11/14/17五个标准，因此C++中的Workaround和Best practice是随着标准演化而推进的。因此这里首先概览一下C++从开始设计以来的特性的引入、废止与更新的过程，以及对C++11及以后引入的重要特性的一些论述。 史前时代1979年，这门语言基于C（cfront将C++编译到C）实现了对象机制（但还没有虚函数等运行时多态），inline函数（大快人心的大好事）等。1985年，cfront正式面世，现在虚函数、重载、引用、new/delete、const这些我们常见的概念都出现了，而标准库也有了雏形。1989年是另一个重要的年头，多继承、抽象类、static/const成员函数、类限定的指针（指向类成员）/new/delete应运而生，C++的OOP机制进一步增强。1998年，C++迎来第一个ISO标准。98标准列出了RTTI机制、virtual（cppreference上翻译成了协变返回类型）、各种cast以及自定义的operator T、mutable/bool关键字和模板的一些特性。2003年，C++03发布了，这是一个次要版本，之后C++0x标准的出台陷入了长久的等待。在这段时间中C++标准库引入了tr和tr1两个扩展包（主要来自Boost和C99的冷饭）。 C++112011年，C++11千呼万唤始出来。C++11带来的主要新特性如下，其中斜体表示标准库特性： auto/decltype、尾随返回类型(trailing) 1234template&lt;typename T, typename U&gt;auto add(T x, U y) -&gt; decltype(x + y)&#123; return x + y;&#125; decltype和完美转发能够非常方便地替换result_type、argument_type之类的手动实现，于是在C++17中，这些机制被去除了。与之同时被去除的还有result_of现在变为invoke_result 右值/移动语义/完美转发 详见我的文章C++右值 enum class =delete和=default final/override constexpr user defined literals 这里指可以支持operator&quot;&quot;了 列表初始化、委托/继承构造函数、花括号初始化器 详见我的文章C++初始化方式 nullptr/nullptr_t/long long/char16_t/char32_t等类型 类型别名（别名模板） 现在我们可以用using替代typedef了 12template &lt;typename T&gt; using V = vector&lt;T&gt;;using VI = vector&lt;int&gt;; 可变参数模板（参数包）详见我的文章C++模板编程 放松了union的限制 放松了POD的限制，现在分为trivial和standard_layout详见C++初始化方式和我的其他文章 Unicode字面量 用户自定义字面量和operator &quot;&quot;现在支持下面这些很骚的写法 1212_km0.5_Pa 属性属性用两个中括号括起来，如[[ noreturn ]]，用来标准化像__attribute__、__declspec这类的用法 lambda表达式 noexcept和新的异常处理机制 alignof和alignas详见我的文章C++内存对齐与多态 thread_local、原子库和线程库包括&lt;thread&gt;、&lt;conditional_variable&gt;、&lt;mutex&gt;、&lt;future&gt;、&lt;atomic&gt;等头文件。详见我的文章并发编程重要概念及比较 GC的API range for 1234int ran[3] = &#123;1,2,3&#125;;for(int &amp; x: ran)&#123; ...&#125; static assert emplace_backC++11的完美转发和参数包特性支持了emplace_back的实现，我们避免了构造并复制/移动临时对象的开销。 std::initializer_list std::forward_list chrono库 ratio库 algorithm库引入了新的算法，如all_of系列、is_permutation系列、copy_系列、move系列（注意不是右值引用的那个move）、shuffle、is_partioned系列、is_sorted系列、is_heap系列。 新的allocator：std::scoped_allocator_adaptor 合并tr1tr1主要包含了reference_wrapper、智能指针、mem_fn（之前从来没用过）、result_of、std::function和std::bind、各种trait函数、随机数模块、新的数学函数、tuple、array、regex、unordered_系列容器。 在exception库中合并Boost的部分异常处理机制exception_ptr、error_code、error_condition 合并Boost的迭代器std::begin、std::end、 std::next、std::prev 标准库新增容器unordered_map、unordered_set、tuple、array（从tr1中引入） string库增加了std::to_string等函数 C++14 lambda C++14放松了lambda的要求，现在lambda的参数可以使用auto声明了 1234// C++11auto l = [](int x)&#123;return x;&#125;;// C++14auto l = [](auto x)&#123;return x;&#125;; 此外，在C++11中lambda表达式是无法捕获右值得到，于是有了诸如Lambda如何捕获转换自临时变量的右值这样的问题。 现在lambda允许捕获右值了，这是典型的给C++11擦屁股 12345Value v = ...;// C++14auto l = [value = std::move(v)] &#123;return *value;&#125;;// C++11auto l = std::bind([] (const Value &amp; value)&#123;return *value;&#125;, std::move(v)); 增强了类型推导（函数返回值） 对于普通函数，我们现在可以进行如下声明而免去尾随返回类型(trailing)了。但是我们要注意对于有多个return的情形，我们要保证所有的返回值推导到一致的类型，对于函数中出现递归调用的情况，需要在当前行前看到至少一个return定义。如下面的例子中语句2涉及递归调用，那么在它前面必须要出现一个能够推导的return（语句1），如果我们颠倒语句1和2的出现次序，编译将报错。 123456789auto fac(int i)&#123; if(i == 0)&#123; // 1 return 1; &#125;else&#123; // 2 return fac(i - 1) * i; &#125;&#125; 增强了类型推导（decltype(auto)） C++11引入了两种类型推导方式auto和decltype。其中auto始终推导出一个非引用的类型，如同std::decay所做的那样，而auto &amp;&amp;始终推导出一个引用类型。decltype的推导结果则和具体表达式密切相关，例如decltype(*ptr)是带引用的。WIKI上列出了一些demo，我们可以看到decltype区分值和表达式，对于表达式始终是返回引用的。 12345678int i;int&amp;&amp; f();auto x3a = i; // x3a的类型是intdecltype(i) x3d = i; // x3d的类型是intauto x4a = (i); // x4a的类型是intdecltype((i)) x4d = (i); // x4d的类型是int&amp;auto x5a = f(); // x5a的类型是intdecltype(f()) x5d = f(); // x5d的类型是int&amp;&amp; C++14通过decltype(auto)为auto声明提供了decltype的行为。 放松了constexpr 根据文章，这一些列变化主要体现在放松了对constexpr函数体中的限制 模板变量 放松了聚合初始化的要求 C++11允许使用default member initializer初始化构造函数没有初始化的成员。C++14允许在聚合初始化中使用这个特性，下面的代码现在成为可能 12345struct CXX14_aggregate &#123; int x; int y = 42;&#125;;CXX14_aggregate a = &#123;1&#125;; // C++14允许。a.y被初始化为42 0b引导的2进制数字常量、数字分位符（便于阅读） 线程库和原子库 引入&lt;shared_mutex&gt;读写锁的相关实现shared_timed_mutex、shared_lock（注意shared_mutex从C++17开始提供） 标准库提供了一系列_t函数用来简化提取traits书写 标准库提供了一系列自定义literal来简化书写这个特性能够实现例如chrono库中的“时间单位”，如s、h、ms、us等。这个是通过String Literal Operator，即operator””实现的。特别需要注意的是，由于这项特性的引入，连接字符串字面量和变量的时候必须要在中间空一格空格。例如 1234// Not OK"%"PRId64// OK"%" PRId64 关联容器支持异构查找 标准库的其他更新 tuple允许通过类型索引（但必须类型在tuple中是唯一的），看起来并没有什么用 引入了std::make_unique给C++11擦屁股 整数序列std::integer_sequence 增强了traits（擦屁股） std::integral_constant的const的operator() std::is_final std::exchange函数 增加了全局的std::cbegin/std::cend（又是擦屁股） std::quoted函数用来处理IO C++17 static_assert现在可以省略第二个参数了（这居然也算特性） template template现在允许typename了，之前只能用class 他这个typename啦class啦啥的总是有很多人搞不清，上次用那个RapidXML，多加了几个typename 类型推导 现在auto可以从braced-init-list推导了，即我们可以按照下面的写法 12345auto x1 = &#123; 1, 2 &#125;; // decltype(x1) is std::initializer_list&lt;int&gt;auto x2 = &#123; 1, 2.0 &#125;; // error: cannot deduce element typeauto x3&#123; 1, 2 &#125;; // error: not a single elementauto x4 = &#123; 3 &#125;; // decltype(x4) is std::initializer_list&lt;int&gt;auto x5&#123; 3 &#125;; // decltype(x5) is int namespace可以用::连接了 Allowing attributes for namespaces and enumerators 新的attributes，包括[[fallthrough]]等 提供了u8来表示UTF-8编码的char，这是出于兼容性和擦屁股考虑的，因为仍然只有一个字节，所以只能放ASCII 二进制的浮点表示。。。 允许所有非类型模板参数的常量计算（？） Fold expr折叠表达式。。。让你的C++代码越发令人望而生畏 常量表达式if constexpr 结构绑定(structured binding)这个是非常有用的特性了，可以用来做pattern matching。可以用它实现聚合类的反射。 if和switch里面也可以定义变量了，这个特性也不错 copy-initialization and direct-initialization of objects of type T from prvalue expressions of type T (ignoring top-level cv-qualifiers) shall result in no copy or move constructors from the prvalue expression. 这一段话总而言之就是guaranteed copy elision的一些规则，可参考我的问题。 Some extensions on over-aligned memory allocation 构造函数可以模板推导了下面的代码在C++17是可行的。这个之前在VS2015上写CFortranTranslator的时候就想有，上SoF查了一下发现原来真有，可惜是C++17，所以只能函数模板封装一层，做成make_系函数，估计C++20之后标准库里面这些make_函数都要deprecate吧。 1234// C++17std::pair(5.0, false);// C++14std::pair&lt;double,bool&gt;(5.0, false); Inline variable在我的博文中指出了这个特性的作用，以及没有这个特性之前的丑陋的Workaround __has_include 标准库新增一些库包括std::string_view、std::optional、std::any、std::variant（涉及到合并了一些TS的特性）这四个库是很有用的 std::byte int std::uncaught_exceptions() noexcept替换了bool std::uncaught_exception() noexcept，所以我们不只学会了英语的复数 容器map系容器添加了两个方法增加了统一的std::size、std::empty、std::data访问容器 Definition of “contiguous iterators” 基于Boost的一个文件系统库 STL算法的并行版本 新的数学函数现在有椭圆积分和贝塞尔曲线了 逻辑运算std::conjunction、std::disjunction、std::negation 限制类型特性concepts前在concepts前，C++限制类型特性常可以通过static_assert对应traits或直接上SFINAE解决，这里还列出一些特殊的情形。 创建只能在栈上的对象 在对象内重载void * operator new (size_t) 创建只能在堆上的对象 禁用析构函数 在栈上new对象 使用placement new 不借助final关键字创建final对象 实际上就是让我们不能定义出一个派生对象，我们知道将构造函数设为私有之后这个这个类就不能实例化了，不过这个就像化疗一样，虽然派生类不能实例化了，但是自己也不能实例化。 将函数的返回值加入重载决议 注意返回值不是函数签名的一部分（所以函数重载决议也是不包括返回值的），不被推导。如果希望实现将返回值也加入重载决议类似的效果，可以借助于类型转换操作符operator T::U()实现。 concepts后concepts后的C++发生了翻天覆地的变化，翻身码农把歌唱，过去的地主富农们装逼的套路又少了很多。可惜码农们南望王师又一年，这concepts是迟迟不来啊。 反射我一直认为C++、反射和优雅之间只能同时存在两个。在C++17标准前，C++实现反射主要有以下的几种思路： 手动注册 rttr是一个较为成熟的库，它并不丑，但是免不了需要在程序运行之前手动执行RTTR_REGISTRATION一下。 基于编译中间结果 内存管理C++在内存管理方面常出现的问题包括如下的方面： 缓冲区溢出 由于现行冯洛伊曼架构，这个是老生常谈的话题了，由此还派生出专门的栈/堆溢出攻击。在C++层面，我们需要审慎使用sprintf或者strcpy等函数，或者使用能显式指定长度的_s系函数。在系统层面，有一些常见的方法，例如金丝雀值。 内存泄露 假设我们的程序是一个批处理程序，那么内存泄露其实影响有限，如果我们能够确保我们的代码逻辑是没有问题的话。 double free double free一个悬空指针产生的问题相对内存泄露的后果要严重多，因为它会导致SegmentFault或者Double free or corruption。但一般来说这样的RE甚至是好事情，double free问题通常意味着代码存在严重的逻辑错误，这时候RE至少能dump，总比WA之后穷查log要好吧。 非法访问 非法访问包括访问越界地址和访问未初始化（完毕）或者被销毁的的变量。例如我们删除了某个指针，但没有置指针值为nullptr，那么现在这个指针就称为悬空指针，对它进行访问会造成Access Violation等错误。 C++中对此还有一些更为隐晦的规则，例如C++中在构造函数和析构函数中不能访问虚函数。或者有时候大家会情不自禁用一个被删除的对象来进行复制构造，抑或返回一个自动变量的指针等。 new/delete不配对 有关new/delete的问题可以查看我的文章C++初始化方式 内存碎片 这个是一个复杂的问题。 右值有关右值可以查看我的文章C++右值]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp data lab]]></title>
    <url>%2F2018%2F01%2F18%2Fcsapp-data-lab%2F</url>
    <content type="text"><![CDATA[csapp中的lab非常出名，在这篇文章中我主要记载第一部分，也就是data lab的解法。所有lab的源码在我的Github上。在知乎的一篇文章中记录了一些和二进制处理相关的内容，我觉得也是非常好的学习材料 abs使用位运算求绝对值。这里用到一些位运算的基础概念。相反数的求法是~x + 1。符号位的判断方法是x &gt;&gt; 31，如果是负数得到的是0xffffffff（注意是算数右移），如果是正数得到的是0x0。于是可以得到下面的方法12int sgn_bit = x &gt;&gt; 31; int abs_val = (x ^ sgn_bit) - sgn_bit; 这里x ^ y是个有趣的用法，根据异或的性质，当y全为0时，返回x；而当y全为1时，返回~x。所以x ^ sgn_bit会对负数的所有位取反，而不修改正数的任何位。不过有意思的是我这份对拍代码在Dev-C++ 5.5.3、Window10 1709版上会报Trojan:Win32/Fuerboos.C!cl。点此查看图片 logicalShift借助右移可以在右边添加若干0，借助算数左移0x80000000可以在左边添加若干1。12int mask1 = ((1 &lt;&lt; 31) &gt;&gt; n) &lt;&lt; 1;int mask = ~mask1; 在上面的代码中mask1这样写是为了在没有-的情况下实现1 &lt;&lt; (32 - n)，不过这样写是不太靠谱的，在下面的fitsBits中类似的写法会导致n == 32时溢出。 bit count这道题要求仅使用位运算! ~ &amp; ^ | + &lt;&lt; &gt;&gt;和小于0xff的数在40步之内来统计一个int32_t里面的1的数量，这题标准实现就是种群计数。种群计数实际上是按bit的分治法，核心思想是一个$n$位数中1的数量等于高$\frac{n}{2}$位和低$\frac{n}{2}$位的1的数量的和。考虑递归的最下层需要计算一个2位数$x$，即(x &amp; 0b01) + ((x &gt;&gt; 1) &amp; 0b01)，扩展到16个2位数就成了(x &amp; 0x55555555) + ((x&gt;&gt;1) &amp; 0x55555555)，这个结果的每两位上的值表示这两位中1的数量。下面考虑把相邻的两个2位数拼成一个四位数，方法是(x &amp; 0b11) + ((x &gt;&gt; 2) &amp; 0b11)，理解也非常简单，把每个2位数当成四进制数就好。123456789int bitCount(int x)&#123; x = (x &amp; 0x55555555) + ((x&gt;&gt;1) &amp; 0x55555555); x = (x &amp; 0x33333333) + ((x&gt;&gt;2) &amp; 0x33333333); x = (x &amp; 0x0f0f0f0f) + ((x&gt;&gt;4) &amp; 0x0f0f0f0f); x = (x &amp; 0x00ff00ff) + ((x&gt;&gt;8) &amp; 0x00ff00ff); x = (x &amp; 0x0000ffff) + ((x&gt;&gt;16) &amp; 0x0000ffff); return x;&#125; bang这道题当时让我感到困难的地方是怎么将所有的非零值映射到一个数上。后来在网上看到解法是(~x + 1) | x，这样可以确保符号位肯定是1。 fitsBits直观地看，一个$n$位数的前32 - n位要么全是0，要么全是1。所以可以得到下面的代码12345678int mask = (1 &lt;&lt; 31) &gt;&gt; (32 + ~n + 1);if (x &lt; 0)&#123; return (x | ~mask) == 0xffffffff; // return (~x &amp; mask) == 0; // de morgan&#125;else&#123; return (x &amp; mask) == 0;&#125; 下面应用下德摩根律，就可以把这个if结构缩成!((x ^ p) &amp; mask)。 divpwr2这道题一开始的思路是1return (x &lt; 0) ? -((-x) &gt;&gt; n) : x &gt;&gt; n; 但是这样的方法是不对的，考虑当x取0x80000000时，-x就溢出了。正确方法可以借助于前面abs的求法123int mask = x &gt;&gt; 31;int offset = ((1 &lt;&lt; n) - 1) &amp; mask;return (x + offset) &gt;&gt; n; 注意这个offset来自于CSAPP上的公式$\lfloor x / y \rfloor = \lceil x / y + (y - 1) / y \rceil$ isPositive这道题很简单，借此总结一下一些常用的操作。 构造0xffffffff：~0 映射0到0，非0到1：!!x 映射0到0，1到0xffffffff：~(x - 1) isLessOrEqual首先熟记此图然后发现，两数同号时比较除符号位剩下的31位，否则比较符号位。因此可以得到这样的代码123456789101112int isLessOrEqual(int x, int y) &#123; int sgn_x = x &gt;&gt; 31; int sgn_y = y &gt;&gt; 31; int do_cmp = ~(sgn_x ^ sgn_y); // 判断是否同号 int cmp_res = y - 1; int sgn_res = cmp_res &gt;&gt; 31; if(do_cmp)&#123; return sgn_res == 0; &#125;else&#123; return !!sgn_x; &#125;&#125; 可以按照下面的方法去掉if块123// do_cmp is either 0x0 or 0xffffffffreturn do_cmp ? x : y;return (do_cmp &amp; x) | (~do_cmp &amp; y); ilog2 这个就是二分法，在字长小于等于4后，可以直接暴力算。注意最后结果要减1。 float_neg从这里开始的三条是浮点数的题目。本题很简单，特判下NaN即可。注意符号位连上阶码为9位而不是8位，这真的很丑啊。 float_i2f 考虑x的绝对值ux。规格化的浮点数尾数共有24位有效数字，其中整数部分恒为1，但不显式表示出来，小数部分为23位。如果ux的有效数字不够24，那么需要左移使得其最高的1对其到24，如果有效数字超过24就需要右移，这时候发生舍入造成精度损失。阶码E是可以根据ux的有效数字算出来的，与ux需要左移/右移多少没有关系，我们应当参照小数部分的最高位，即$2^{-1}$而不是最低位$2^{-24}$，简单地来理解，由于最高位已经对齐到了整数位的个位，所以要将最高位1后面的部分也移到最高位1的后面，也就是要去掉最高位1前面的前导0。不过我很快遇到一个巨大的困难，对于0x80000001来说计算的值是0xcf000000，等于0x80000000，容易发现这里出现了一个舍入。CSAPP中说明了向偶数舍入的规则，但我不是很懂，这里看了CSDN的一篇文章终于搞明白了。其实这个说的是一个特殊情况。一般当多余数字严格小于或大于最低有效位的一半时，我们按照传统的四舍五入的规则。考虑对下面的数字舍入到小数点后3位，1.0011001 -&gt; 1.010，这里由于1001 &gt; 1000因此进位，同理，1.0010111 -&gt; 1.001就直接抹掉后面四位。当多余数字刚好等于1000时，这里就应当使用向偶数舍入的原则。最后未压缩的代码是这样的 float_twice这个主意分情况讨论，首先NaN/无穷大还是NaN/无穷大。接着是非规格化的情况，如果尾数最高位不为1，直接&lt;&lt;=尾数部分，否则阶码加1切回规格化。对于规格化情况，首先增加阶码，如果阶码满了，就&lt;&lt;=尾数部分，并牺牲精度，容易发现随着移动自然而然能够达到无穷大（尾数为0）的情况，这体现了浮点数设计的巧妙之处。]]></content>
      <tags>
        <tag>C++</tag>
        <tag>csapp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[B树]]></title>
    <url>%2F2018%2F01%2F17%2FB-tree%2F</url>
    <content type="text"><![CDATA[B树的设计目的是减少磁盘存取，而不是诸如BST、RBT、AVL一样试图减少比较次数。根据局部性原理，当一个数据被访问时，那么它附近的数据很大概率会马上被访问，因此我们可以一同将其加载。这个原理常常被用在存取速度不同的两个设备间，如寄存器与主存（多级缓存）以及数据库系统中出现的磁盘与内存的情况。B树相对于一般的平衡BST的特点是高度低、出度大、节点大。一个高度低的树能有效减少检索磁盘的次数。一个具有较大的分支因子的树可以减少$k*log(n)$的常数$k$，其中$n$是总关键字数，也能减少磁盘存取。特别地，B树的节点设计不仅要考虑到容纳尽可能多的节点，也要同时考虑到从磁盘加载的便利性。 B树B树具有一个最小度数$t$，表示一个节点的最小出度，我们要求最小出度必须$t \ge 2$，容易发现当$t = 1$时这个B树实际上就退化为二叉树了。B树主要构造如下： 对节点$x$ 每个节点$x$应当具有$x.n$个按照非降序排列的关键字$x.key_i$。对于叶子节点$s$，它们具有相同的层高$h$。对于内部节点$x$，还具有$n + 1$个指向子节点的指针$x.c_i$。B树递归的有序性表现在对于任意一个子树$x.c_i$记录的关键字$k_i$，它满足$k_1 \le x.key_1 \le k_2 \le x.key_2 \le … \le x.key_{x.n} \le k_{x.n+1}$。如下图所示 对关键字个数$x.n$ B树要求每个节点的出度在$[t, 2t]$之间，因此$x.n$的的上下界为$[t - 1, 2 t - 1]$。当一个节点中存在$2 t - 1$个关键字后，这个节点就是满的。 搜索节点B树分裂节点的CPU复杂度是$O(t)$，磁盘复杂度是$O(1)$。向B树插入新关键字是从树根开始的，磁盘复杂度为$O(t log_t n)$ B+树相比B树，B+树有两点不同 B+树里面的节点存索引，通过索引指向真正的数据。这是因为叶子节点上的空间就算放数据也放不了多少数据，还不如放索引。 B+树的叶子节点用链表串联，方便查找。这一点使得在遍历的时候不需要再反复查询索引了。 我们需要区分一下聚集索引的概念，聚集索引下，表中相邻行存储的物理顺序和逻辑顺序是一致的，但这些数据并不一定要放在B+树的一个节点上。]]></content>
      <tags>
        <tag>ACM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程重要概念及比较]]></title>
    <url>%2F2017%2F12%2F28%2FConcurrency-Programming-Compare%2F</url>
    <content type="text"><![CDATA[在本篇中比较了各种并发、并行技术。并发(concurrency)强调的是逻辑上的同时发生，是语义上的模型(semantic model)，在实际上并发程序可能是由一个处理器同时(simultaneously)处理多个任务，因此并发过程中常出现一个线程等待其他资源的情况。此时常伴随着线程的阻塞和调度。并发过程通常可划分为多个级别：Blocking、Obstruction-Free、Lock-Free、Wait-Free，其中后三种统称为Non-blocking的。并行(parallelism)属于并发，是运行期的行为(runtime behavior)，并行强调这两个并发事件实际上也是同时发生的，例如在多个处理器上运行的多个任务。但我们不能讲这两个概念绝对化，例如在处理器层面，流水线绝对是并发的，但在操作系统之上提供的机制来说，却体现出顺序的特性。【未完待续】 处理器层面的并发处理器在硬件架构上可以被分为对称多处理器(Symmetric Multiprocessing, SMP)、非均匀访问存储模型(Non-Uniform Memory Access, NUMA)、Massive Parallel Processing(MPP)等。其中SMP被广泛用于PC中，架构简单，但扩展性较差。这里简单地论述处理器层面的并发相关，例如流水线、分支预测、多级缓存等技术。 流水线(pipeline)流水线和吞吐量我们通常使用GOPS（每秒千兆次操作）来定义吞吐量，表示每秒内执行操作的次数。CPU流水线的目的是为了提高吞吐量(throughput)，但会增加每条指令的延迟(latency)，这是因为执行一条指令需要经过更多的流水线寄存器。CSAPP使用一个称为SEQ的架构来描述流水线的通用模型，一条指令在CPU中被执行会经过取指(fetch)、译码(decode)、执行(execute)、访存(memory)、写回(write back)、更新PC（在SEQ+中和取指进行了合并）等阶段。取指从PC处取得指令。指令包含icode和ifun。还包含译码阶段需要读取的寄存器rA和rB（可选的），一个常数valC。译码指的是从寄存器读取。读到的数令为valA和valB。访存指的是读写内存。如果读内存，读到的值令为valM。写回指的是写回到寄存器。特别注意，处理器可以读写寄存器和内存，读写寄存器和读写内存是不同的阶段。容易想到在某一时钟周期内，每一个阶段都可以独立运行。例如当指令PC在执行阶段时，我们可以对指令PC+1进行译码，这样译码器就不会闲置，这就是流水线化的一个简单思路。这种流水线设计很常见，以486为例，其拥有两条5级流水线取指F-&gt;译码D1-&gt;转址D2-&gt;执行EX-&gt;写回WB。出于两点的考虑，流水线技术会制约了吞吐量能提高的上限： 流水线不同阶段的延迟是不同 如下图所示，流水线的吞吐量会受到其中最长操作的局限。 一个较深的流水线可能带来很大的流水线寄存器延迟 这是来自于增加的流水线寄存器所带来的额外开销。 流水线和冒险控制相关和顺序（数据）相关是使用流水线并发执行一些指令需要面临的问题。其中顺序相关指后一条指令的执行依赖于前一条指令的值，控制相关指的是指令流的路径依赖于前一条指令（通常是条件测试）的结果。为了解决这样的问题，CSAPP首先升级了原先的SEQ到SEQ+，现在我们将更新PC移到最前面，并且和取指进行了合并，这样做的目的是使得我们在程序开始时通过上面一条指令结束时的状态来确定地址。CSAPP基于SEQ+引入了PIPE-这个流水线，并希望PIPE-能够实现每个时钟周期发射(issue)一条指令，因此我们需要在取出一条指令后马上确定下一条指令的位置。这对于ret和条件转移来说是较为麻烦的，因为我们要进行分支预测。分支预测有一些策略，包括总是选择（分支），从不选择(NT)。一种正向不选择(BTFNT)策略只接受跳往地址更低的分支（也就是往前跳，后向分支），因为它可能标志着一个循环的右大括号。现在的分支预测器通常分为静态规则和动态规则的，动态规则会基于一些运行期的历史进行类似“强化学习”，例如如果一段分支历史上不进行跳转的成功率大，那么就这一次预测的时候就不进行跳转，知乎专栏上给出了一个详细的例子来验证这个特性，这个实验中验证了对一个有序数组遍历时其耗时约为无序数组的1/3。分支预测失败，也就是所谓的控制冒险(hazard)，它的代价是就会导致流水线刷新(flush)。此外当一条指令写后面指令会读到的那些程序状态时就会带来数据冒险，特别地我们可以发现控制冒险可以看做是对程序计数器PC而言的数据冒险。我们考虑整个流水线中可能出现的部件，其中通用寄存器和PC已经被证明是存在冒险的，以通用寄存器为例，其写和读发生在流水线上不同的阶段（写回和解码）。剩下来的是EFLAGS以及存储器则是不存在冒险的，以存储器为例，其读写都发生在流水线的访存阶段，那么前一条指令对存储器的写对后一条指令对存储器的读总是可见的。CPU流水线中通过暂停(stalling)和转发(forward)/旁路(bypassing)的机制解决数据冒险的问题。此外在汇编层面，我们可以使用条件传送而不是条件控制转移来避免分支预测出错的问题。 暂停暂停的思路很简单，就是阻塞流水线中的一些指令直到冒险条件不满足。对通用寄存器而言，在解码阶段时流水线会检查前方执行、访存和写回阶段中是否有指令会更新该通用寄存器。如果存在那么就会阻塞处于解码阶段的指令（包括后面即将执行的下一条指令的取指阶段，也就是保持PC的值）。在阻塞时，流水线的一部分会进入空转状态，此时我们成为插入一个气泡(bubble)。如下图所示，在时刻5，原本应该执行的0x00d处的D被阻塞了，因为0x006处的W尚未完成。因此在等待其完成的时间中插入了三个气泡（分别对应EMW阶段）。 转发上面的暂停机制非常直白和简单，但考虑到前后连续两条指令对同一个寄存器先写后读是很通常的情况，此时三个气泡是很划不来的。此时可以借助转发来避免暂停。转发机制指将结果从流水线的较晚阶段发送到流水线的较早阶段的过程，通常是从写回阶段W转发到译码D阶段作为操作数之一。【写回–译码】我们查看下面的图，在第6周期上，0x00e的解码逻辑发现0x006上所在的写回阶段有对%eax的写，而自己恰恰要访问这个寄存器，所以与其这样不如直接拿过来用了。这样相当于只插入了两个气泡。【访存–译码】更厉害的是我们甚至可以在访存阶段就转发到解码阶段。我们查看下面的图，在第5周期上位于解码阶段的0x00d发现0x006和0x000分别处于访存和写回阶段，这里写回阶段如上所示，而访存阶段我们发现我们正在读入数据到%eax。因此我们可以直接将这个对%eax的写也转发过去。现在我们相当于只插入了一个气泡。【执行–译码】能不能一个都不插入呢？也是可以的，我们从执行阶段就转发到解码阶段。我们查看下面的图，在第4周期上位于解码阶段的0x00c发现0x006和0x000分别处于执行和访存阶段，这里访存阶段如上所示，而在执行阶段我们发现我们正在计算一个立即数，这个立即数将在稍后写入%eax。问题来了，有没有【访存–译码】呢？ 加载互锁转发能够解决相当多的数据冒险，但有一类加载/使用冒险难以被解决，这是因为加载（从存储器读）存在于访存阶段，而如果下一条指令就要使用的话，那么就会“赶不上趟”。 现代处理器在现代的处理器中，流水线被拆分地更加细，出现了所谓的12级、31级乃至更深的流水线。但是这么深的流水线阻塞的代价是非常巨大的。为此Intel使用了乱序执行组件(Out-of-Order core)。 流水线机制对程序优化的启示流水线机制对我们程序性能优化的启示主要有下面几点： 减少连续指令的相关性 这一点是针对数据冒险而言的。 进行循环展开 这一点是针对控制冒险而言的。循环处必然出现分支，这就带来了可能的分支预测失败的成本。因此我们展开循环能够减少这样的跳转次数。 CPU的缓存和缓存一致性x86往往都有高速缓存Cache，而且有多级。高速缓存基于静态RAM(SRAM)技术，区别于主存的动态RAM(DRAM)技术。现代CPU中寄存器与内存之间没有直接的渠道，而必须通过多级的高速缓存才能到内存。高速缓存的作用依然是为了弥补CPU和内存在速度上的差异，高速缓存提高效率的原理是基于时间局部性(Temporal Locality)和空间局部性(Spatial Locality)，我们稍后将详细讨论这个概念。虽然高速缓存对用户来说是透明的，我们的代码要不直接操作寄存器，要不直接操作内存，但它并不是不存在，如果深究下去会发现如何保障内存和对应CPU缓存的同步是个问题。但是我们不要担心诸如此类的“一个核心写另一个核心脏读”的情况，缓存一致性协议能够解决内存和多核CPU缓存之间以及缓存与缓存之间的同步性问题。但我们仍然要关注缓存这个概念以写出高质量的程序。 局部性原理时间局部性和空间局部性原理表示被引用过一次的存储器位置很可能在不远的将来再次被引用，而存储器中的某一个地址被引用过，那么它附近的地址很可能也会被使用。我们考虑对一个向量求和12345int s = 0;for(int i = 0; i &lt; N; i++)&#123; s += v[i];&#125;return s; 首先对于标量s，它并没有空间局部性一说，但是它在每次循环中都被访问，因此具有较好的时间局部性。而向量v是被逐一访问的，即具有步长为1的引用模式，因此空间局部性很好，不过用一次就不用了，所以时间局部性不好。一般来说步长越小，空间局部性越好。这样的空间局部性在对二维数组的访问上会更加明显，例如对于行存储的模型，如果以列为单位遍历，那么就会破坏空间局部性，这个在我CFortranTranslator工程的设计上曾有所考虑。 多级缓存和缓存不命中往下深究局部性原理，我们能够想到缓存不命中的问题。我们始终希望能够在当前缓存找到我们需要的对象，这样最快，但缓存的容量总是有限的。当缓存不能命中时，我们就需要从下一级缓存中找。当系统开始运行时缓存是空的，这时候的命中称为冷不命中或者强制不命中，没有什么道理可讲。下面我们考虑如何从缓存中找呢？我们总不能说也有个现成的哈希表甚至红黑树来维护吧？实际上，我们是快速根据地址m来定位和映射Cache，由于一般高层k缓存的容量要小，所以缓存在设计的时候会分成几个桶（高速缓存组），这样可以Hash到桶里面。事实上高速缓存一般将地址分为三段，即组索引位s、行标记位t和偏移位b。这样的Hash可能存在问题，例如我们mod 4一下到四个桶里面。那么假如说我们从k+1层交替访问0号和8号块，那么我们发现其实缓存会一直不命中，即使其他的块还是空的，这被称为冲突不命中(conflict miss)。当然有的时候缓存就是太小了，这个就是容量不命中(capacity miss)。在组织时，我们按照桶的数量和桶中元素数量的区别将高速缓存分为了直接映射高速缓存、组相联高速缓存和全相联高速缓存。直接映射(direct-mapped)高速缓存每一个桶里面只有一行，缓存根据是否命中会选择直接返回或者向下层请求对应块。整个匹配过程分为三步： 第一步是组选择，我们在地址的中间部分抽出s个位作为组索引位s，s的大小取决于组数S，我们有关系$S = log_2^S$。我们选择中间部分是出于对空间局部性的利用，如果我们使用高位做索引，那么我们空间局部性好的连续的块就会被映射到一个桶里面，这样的话就会导致缓存的频繁刷新。 第二步是行匹配，我们根据标记位t去寻找一个有效位被设置了的缓存，这是因为缓存可能会失效，这个对于只有一行的直接映射缓存来说的trivial的。t是由s和b决定的，假设地址长度为m，块偏移位数为b，那么我们的t = m - s - b，这样做的话，一旦我们找到匹配的t，我们就可以认为这个地址在缓存行中。由于s占了中间位，所以t实际上就占了高位 于是第三步是字选择，因为缓存行是一个包含了$2^b$字节的块，我们整体读出来是没用的，所以我们要读到指定的字需要一个offset，这时候就可以借助于缓存行中的偏移位b了。对于下面的代码，如果x和y都被映射到一个高速缓存组中，就会造成thrash。CSAPP中指出，即使一个局部空间性看上去很好的程序也可能造成缓存抖动(thrash)。123for(int i = 0; i &lt; 8; i++)&#123; s += x[i] * y[i];&#125; 此外，对于异常控制流，例如中断和上下文切换，缓存工作会受影响。此时主程序的缓存和中断处理的程序缓存会相互影响导致互相变cold。这种情况下当中断返回或者上下文切换回来时缓存需要较长时间来warm up，这种情况称为缓存污染(cache pollution)。 常见的缓存替换算法在组相联高速缓存中，每个组中存在多个缓存行。如果我们当前的缓存满了的话，就需要去确定一个最合适的牺牲块(victim block)进行替换，我们有常见的LRU和LFU算法来达成这个目的。LFU替换过去引用次数最少的行，LRU替换最后一次访问时间最久远的一行。但是当出现偶发性的批量操作时LRU容易将Hot块（访问频率高的块）移出缓存，造成缓存污染。这时候我们引入了LFU算法，LFU需要额外的一些计算，但是在性能上好于LRU，但当数据访问模式改变后LFU需要较长的时间重新进行适应（统计频率）。因此我们引入了LRU-K算法，这个算法比较距当前第K次的访问时间和当前时间的距离来移出缓存。 一般来讲，LFU可以通过优先队列或者双层链表来实现。 缓存一致性协议一致性协议嘛，肯定是用来协调多个对象的，在这里，对象指的是不同的核心。MESI是实现缓存一致性的一个基础协议，MESI分别表示缓存行可能处于的四个状态Modified、Exclusive、Shared、Invalid。其中Intel使用了扩展的MESIF，增加了状态Forward，而AMD使用了MOESI，增加了状态Owned。MESI协议需要正确处理local read(LR)、local write(LW)、remote read(RR)、remote write(RW)四个场景，其中local表示本core对本地缓存读写，而remote则表示非本地core对非本地缓存的读写。一个缓存行Cache0初始状态为I，因为它并不缓存任何数据。当本地core向该缓存行请求时，CPU会向其他缓存行询问，如果存在缓存行Cache1拥有该缓存，则将对应缓存行设为S状态，表示目前有多个缓存行缓存有该数据，并且缓存行中数据和内存中一样；否则从内存中加载到Cache0，并设为E状态，表示目前只有一个缓存行缓存有该数据。当本地处理器写入时，缓存行状态变为M，此时缓存与主存之间的数据不一致，CPU通知所有对应的其他的缓存行失效。这时候相当于该core独有这个缓存行，而其他core缓存行的状态变为I。在这个模型有点像读写锁的模式，读是Shared，写会作废所有的缓存行。下面的图描述了四种读写下的状态变化。容易理解的是所有的RW都会导致I，所有的RR都会导致S，所有的LW都会导致M，下面考虑LR。对于状态E，由于是独占的，所以怎么读都是E，因此是自环。同理状态M也是独占的。对于S状态，虽然不是独占，但缓存行中数据和主存一致，因而是有效的，所以也是自环。下面对于I状态，缓存行失效意味着有其他core的写导致了缓存行的刷新，所以进行LR之后实际上就和这些core进行了数据的同步，也就是回到了S状态。 伪共享伪共享(False Sharing)是在MESI模型下多个线程对同一缓存行竞争写所导致的性能降低。我们考虑这篇博文中的一个场景一个数组int32_t arr[]被同时加载到CPU0和CPU1的L1缓存Cache0和Cache1上。现在两个线程A和B试图分别修改arr[0]和arr[1]。这种情况下是不存在race condition的，但是可能导致伪共享。我们考虑初始情况下Cache0和Cache1都处于S状态，现在CPU0收到线程A的请求，写arr[0]，Cache0状态变为M，而Cache1收到通知后也作废了自己的缓存行。接下来CPU1发起了写操作，根据MESI模型，CPU0会先将arr[0]写回内存，此时Cache0变为I，之后CPU1才能从内存重新读取，Cache1变成E，然后CPU1才能修改arr[1]。为了解决伪共享存在的问题，我们通常的做法是尽量避免将需要访问的数据放到同一个缓存行中，而这就是在一些指令中需要内存对齐的原因，还有的原因是原子操作上的考虑。 测试缓存大小缓存一致性和volatile既然我们CPU总是能读到内存里面最新的值，那为啥还需要volatile呢？原因有二 CPU不一定会读缓存，可能直接读寄存器 这时候要注意区分CPU缓存一致性和volatile之间的关系。例如出于优化的角度，编译器可能把一个在内存的值放到到寄存器里面，以避免访问内存，既然不访问内存那和缓存一致也没啥关系了。但这样就会出现问题，如果某个线程修改了这个值对应的内存，那么寄存器是不知道的，所以这时候volatile强制说不要在寄存器里面读啦，直接从内存里面读，这时候缓存就能发挥应该有的作用了。所以CPU缓存一致性解决的是CPU的Lx缓存和内存之间之间的问题，而不是CPU寄存器和内存之间的问题。 有的缓存一致性也不保证是任意时刻的 经过简单的了解，CPU缓存行的写操作也分为直写(write though)和回写(write back)两种策略。直写就是同时写缓存和内存，因此对于直写来说，确实可以做到任意时刻各缓存中的内容等于内存中内容；但回写就不一定是任意时刻了，因为它并不是立即更新缓存，而是只修改本级缓存，而将对应缓存标记为脏段，只有当所有脏段被回写后我们才能达到一致性。具体还可以参看缓存一致性。当然，直写和回写实际上是广泛意义上的概念，同样也出现在Linux、Innodb等系统中。 CPU提供的并发处理机制栅栏以x86为例，提供了lfence、sfence和mfence。其中mfence可以看做是两者合一，但是有的资料指出lfence+sfence弱于mfence，因为它不能禁止Store-Load的乱序。 总线锁在较为古老的CPU上LOCK指令通常是锁总线的，后面有使用Ringbus+MESI协议的，这个协议我们后面会讲到。 内核层面的同步与并发中断x86上的中断在一些经典的x86系统中使用的是Intel 8259 PIC处理中断，在这种形式下CPU通过两个8259处理16个IRQ，这两个8259以Master/Slave形式存在。在现在的多核CPU特别是SMP架构背景下，中断的机制和单核有所区别，此时主要借助于高级可编程中断控制器(APIC)。APIC由本地APIC和IO APIC组成，其中本地APIC与每个处理器核心对应，IO APIC负责采集和转发来自IO设备的中断信号。根据Intel的规定，广义上的中断可分为同步中断和异步中断。 同步中断又称异常，实际上是由CPU产生的，因此显然不能被屏蔽。异常分为故障(fault)、陷阱(trap)和终止(abort)，对应到中断号的0-15。 异步中断又称中断，分为外部非屏蔽中断(NMI)和外部可屏蔽中断(INTR)，分别对应中断号IRQ的16-31和32-47。Intel将非屏蔽中断也归入异常，所以异常一般为来自外设或CPU中的非法或故障状态，例如常见的除零错误、缺页（故障）、单步调试（陷阱）等情况。 在中断的语境中，我们主要讨论异步中断中的可屏蔽中断，它通常是来自外部设备的中断。这是因为除了一些硬件故障，来自外部IO设备的中断常是可以等待的，所以属于可屏蔽中断，当IF标志为1时，CPU可以不响应可屏蔽中断，而是将它缓存起来，在开中断后会传给CPU。当CPU在响应一个异常时，所有的可屏蔽中断都将被屏蔽，而如果此时再出现一个异常，即产生了double fault故障，一般来说系统就会宕机。 Linux的中断Linux上每一个CPU都拥有一个中断栈，这个始于Linux2.6的版本，在此之前，中断共享其所在的内核栈，后来Linux认为对每个进程提供两页不可换出的内核栈太奢侈的，所以就将其缩小为1页，并且将中断栈独立了出来。中断处理的原则是快，否则很容易被覆盖。因此，中断上下文又被称为原子上下文（《Linux内核设计与实现》），该上下文中的代码不允许阻塞，这是因为中断上下文完全不具备进程的结构，因此在睡眠之后无法被重新调度。在操作系统如Linux中，中断还可以被分为软件中断（内部中断）和硬中断，硬中断是来自硬件的中断，它可以是可屏蔽的，也可以是不可屏蔽的。软件中断一般是由int指令产生的，由操作系统提供，在Linux中软中断对应于中断号48-255。软件中断是不可屏蔽的（不然干嘛调用int呢），但在操作系统中软件中断也可能是由一个硬中断产生的，例如一个来自打印机的硬中断可能产生一个软件中断给内核中的相关处理程序。我们需要区分软件中断和软中断，前者指的是INT指令，后者特指Linux的一种中断推后处理机制（在Windows和Linux的分别被称为中断延时处理和中断下半部）。 x86中断向量/中断描述符在实模式中使用中断向量表，在保护模式中使用中断描述符表IDT。从上文中我们得到不可屏蔽中断占用了IDT的0-31，其中前半是异常，后半是外部中断。Intel使用了三种中断描述符：中断门、任务门、陷阱门。而Linux中则分为五种，即中断门、系统门、系统中断门、陷阱门、任务门。 中断程序的注册和处理需要使用中断的驱动程序会调用request_irq()向内核注册一个中断号irq和中断处理函数irq_handler_t handler，并激活对应的中断线。request_irq()会接受一个flag，flag中的一个选项IRQF_DISABLED表示禁用所有中断，如果不设置这个值，那么该中断处理程序可以被非同种中断打断，这也就是说Linux中硬中断是可以嵌套的。不过Linux禁止来自同种类中断的打断，它会挂起后来的中断，这主要是为了防止重入现象的发生，从而简化系统实现。Linux通过巧妙的机制来防止同种类中断重入。1234567891011121314151617181920// 当中断来临时，IRQ_PENDING被设置，表示正在排队// action为当前的中断处理函数指针action = NULL;// 如果IRQ_INPROGRESS不为0，说明有正在处理的同种中断，所以拜拜if (likely(!(status &amp; (IRQ_DISABLED | IRQ_INPROGRESS)))) &#123; action = desc-&gt;action; // 如果当前没有中断等待处理，我们清除IRQ_PENDING，设置IRQ_INPROGRESS status &amp;= ~IRQ_PENDING; /* we commit to handling */ status |= IRQ_INPROGRESS; /* we are handling it */&#125;desc-&gt;status = status; /* * If there is no IRQ handler or it was disabled, exit early. * Since we set PENDING, if another processor is handling * a different instance of this same irq, the other processor * will take care of it. */if (unlikely(!action)) goto out; 需要特别注意的是“只要非同种中断发生就可以抢占内核”这句话也是不准确的，因为开中断发生在中断处理函数handle_IRQ_event中，此时如果没有设置IRQF_DISABLED，Linux就会立马开中断。12345irqreturn_t handle_IRQ_event(unsigned int irq, struct irqaction *action)&#123; ... if (!(action-&gt;flags &amp; IRQF_DISABLED)) local_irq_enable_in_hardirq(); 但是在这个函数前的一条调用链中都是关中断的，这是CPU的一个特性，即中断发生时触发中断门会自动关中断，也就是置IF为0，可参考这篇文章。关中断的好处在于可以防止中断嵌套，防止内核抢占，但不能禁止来自SMP架构下其他处理器的并发访问，为了解决这种并发访问，通常的做法是借助于例如自旋锁的机制。此外在关中断时要注意关中断会导致异步IO、调度等一系列依赖中断的功能失效，所以屏蔽中断后一定要尽快执行完临界区内代码。此外，flag中还有一些其他的选项，例如IRQF_SAMPLE_RANDOM，这个被Linux用来实现随机数，会将每次的中断间隔填入内存熵池。与之对应的是IRQF_TIMER，这个表示系统时钟中断，显然系统时钟具有固定间隔，是不适合用来实现随机数的。 中断的开启与关闭我们使用local_irq_disable和local_irq_enable来控制当前处理器的中断，他们对应到x86架构上就是常见的cli和sti命令。不过Linux更推荐使用local_irq_save来禁止中断、local_irq_restore来恢复到原来的状态（因为可能一直就是禁止中断的）。123456789static inline void native_irq_disable(void)&#123; asm volatile("cli": : :"memory");&#125;static inline void native_irq_enable(void)&#123; asm volatile("sti": : :"memory");&#125; 《Linux内核设计与实现》指出在2.5版本前存在一个禁止所有处理器中断的内核函数cli()，这个函数非常暴力，乃至它实际上提供了对其他所有中断处理程序的互斥访问机制，在这一把全局大锁下我们实际上就可以保证共享数据的互斥了，也就不要像后面版本中那样关闭本地中断后还需要用自旋锁来维护。取消这个全局大锁的好处是使用细粒度的锁能提高性能。相对于local_系更轻量级的方案是只禁用一种中断，也就是disable_irq、disable_irq_nosync系列，他们禁止中断控制器上的指定中断线irq，其中_nosync系列立即返回，而前面的需要等待已有的中断处理完毕，其实就是在调用_nosync之后调用synchronize_irq去等待，借助于raw_spin_lock_irqsave。《Linux内核设计与实现》指出disable_irq和enable_irq不是幂等的，因此要成对调用才能确保正确回到原始状态。此外还指出这个是保证不会sleep的，但是我在4.17的内核中看到现在的实现是wait_event一个事件，里面涉及一个might_sleep宏的调用。 共享中断Linux的中断是可以共享的，也就是说同一个中断可以有多个处理程序响应。一个共享中断，例如定时器中断，必须通过request_irq设置IRQF_SHARED标志。 中断下半部Linux中，中断下半部可以被硬中断打断，所以可以认为硬中断具有更高的“优先级”（不过Linux中并没有中断优先级的概念，虽然也有个中断线程化的东西）。这道理是显然的，因为我们又要快速地响应设备，又不能在中断上下文停留过久，所以才发明了中断下半部这个东西。Linux中的中断下半部的实现有三种机制：Orignial Bottom Half机制、Task Queue机制、软中断Softirq机制、tasklet和工作队列，其中前两种已被替代。 Orignial Bottom Half(BH)使用32个链表串联，全局中只有一个BH能够运行。 Task Queue软中断从2.3开始，软中断和tasklet被引入，其中tasklet是基于软中断实现的。软中断和软中断之间是不会抢占的，事实上它们被抢占也就是如之前提到的只能被硬中断抢占，但包括相同类型的软中断都可以在SMP的不同CPU上并行执行。注意软中断处理函数属于中断上下文，从而在处理软中断时也不允许休眠，所以其实软中断的优先级还是很高的。Linux中使用softirq_action结构表示软中断，Linux中设置了一个长度为32的softirq_action数组来存放这些中断。123struct softirq_action &#123; void (*action) (struct softirq_action *); /* 软中断的处理函数 */ &#125;; 可以看出，软中断实际上很像一个回调函数。那么软中断和回调函数之间有什么区别呢： 软中断能够实现不同优先级代码的跳转 软中断的重入性和回调函数不同 软中断的检查与执行一般出现在以下几种情况： 从硬中断返回时。这是一个很常见的情况，因为从硬中断返回之后往往会立即开启软中断，但是在软中断时可以自由地抢占了。 ksoftirqd内核线程。 这个内核线程是为了处理可能存在的大量的软中断。对于如网络子系统之类的使用软中断的系统，他们可能会频繁的触发软中断，并且在软中断处理函数中可能还会重复触发软中断。这样就会存在大量的软中断抢占其他任务执行时间的问题。对于这个问题，单纯地选择执行完所有当前的软中断或者所有重复触发的软中断都放到下一跳执行都是不合适的。 来自网络子系统等显式要求检查软中断的部分。 软中断的执行非常有意思，通过移位操作来实现按顺序check并执行32个软中断的行为，具体可以查看《Linux内核与实现》 虽然不如硬中断处理函数那么严苛，但由上可见软中断的使用还是有很大限制的，目前使用软中断的主要有网络IO、SCSI、内核定时器、tasklet等、RCU等。但注意工作队列由内核线程eventX执行，允许被调度甚至睡眠。Linux的外部中断处理过程可以参考文章。 tasklet相对于softirq，相同类型的tasklet在一个时刻只有一个在执行。tasklet通过TASKLET_SOFTIRQ和HI_SOFTIRQ两个软中断触发，实际上也是出于中断上下文之中的，所以不能睡眠。 进程与线程设施进程模型五状态进程模型包括新建、就绪（等待CPU）、阻塞（等待事件）、运行和退出。在五状态模型之外，还有挂起操作。挂起操作指的是将进程交换到外存，这常常是由于内存紧张或者该进程被阻塞的缘故。挂起不同于阻塞或者就绪，被挂起的进程犹如进入一个平行世界，当等待的事件到达时，它能够从挂起阻塞直接切换成挂起就绪。一个挂起的进程必须脱去挂起这层壳之后才能重新进入五状态模型，如一个挂起就绪态进程必须换回到内存切换成就绪态才能被调度。在Linux中，进程的状态主要有TASK_RUNNING、TASK_INTERRUPTIBLE、TASK_UNINTERRUPTIBLE、_TASK_TRACED、_TASK_STOPPED。其中TASK_RUNNING表示进程处于执行或者排队等待执行的状态，此时进程可能位于用户态，也可能位于内核态。TASK_INTERRUPTIBLE表示进程正在被阻塞，等待条件达成或者信号。TASK_UNINTERRUPTIBLE是不可中断的睡眠状态，这是指这个进程不响应SIGKILL等外部信号，因此必须是十分短暂的，在ps -aux命令中显示为D。顺带一提另一令不能响应外部信号的僵尸进程Z（区别于失去父进程的孤儿进程），僵尸进程的资源已经被全部释放，只留下包括task_struct在内的一点信息用来给父进程提供返回码等信息，如果此时父进程被阻塞而不能回收子进程，那么子进程就会进入僵尸状态。fork出的子进程默认会拷贝父进程的一系列资源，包括内存（包括堆栈）、文件描述符（特别地exec也会保留文件描述符，可以参考我有关subprocess的文章）、信号设定、Nice优先级值、工作目录等。 线程模型Linux根据调度者在内核内还是内核外将线程分为用户线程和核心线程，前者一般更利于并发使用多核处理器资源，后者则需要较多地考虑上下文切换的开销。为此在设计时往往会引入一对多或者一对一多对多等线程模型，例如使用一个核心线程去调度多个用户线程。pthread(POSIX threads)是POSIX下的一套线程模型，而Linux对这套模型或者接口的实现跟随时间先后有LinuxThreads和NPTL等几种方式。 LinuxThreads 容易想到的简单办法就是直接复用进程，也就是LinuxThread轻量级线程。无论是fork()还是pthread_create()，最后都是调用do_fork()，普通进程和轻量级进程（线程）的区别在于调用参数不同。线程的创建一般会使用CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND等clone_flags参数选项，表示共享地址空间、文件系统、描述符和信号处理，而fork只有CLONE_CHLD。 在Linux内核2.6出现之前进程是(最小)可调度的对象，当时的Linux不真正支持线程。LinuxThreads计划使用系统调用clone()来提供一个内核级的线程支持。但是这个解决方法与真正的POSIX标准有一些不兼容的地方，尤其是在信号处理、进程调度和进程间同步原语方面。 NPTL Native POSIX Thread Library(NPTL)是Linux内核中实践POSIX Threads标准的库，是POSIX线程模型的新实现。我们可以在glibc库源码的nptl目录下可以看到它被用来实现了pthread系列函数接口。这里的POSIX Threads标准也就是一系列pthread_开头的函数。 信号Linux中信号是一个实现异步的机制。信号分为同步信号(synchronous signal)和异步信号(asynchronous signal)。同步信号类似于SIGFPE、SIGSEGV，通常标记着一个无法恢复的错误，来自当前执行上下文中，通常由一个trap陷入内核，并由一个trap handler触发。异步信号则来自当前的执行上下文之外 系统调用在稍后的论述中，我们将看到进程在用户态和内核态之间切换时常伴随有很多奇妙的工作，不过首先来先行讨论一下系统调用。进程从用户态进入内核态可以通过系统调用、异常（如缺页异常）和来自外部设备的硬中断，而系统调用是最常见的一种，也是应用程序唯一主动进入内核的机制。Linux的系统调用以asmlinkage long sys_打头，据说asmlinkage保证从栈中提取函数的参数，其实就是CPP_ASMLINKAGE __attribure__((syscall_linkage))，其中CPP_ASMLINKAGE就是在C++上用extern &quot;C&quot;导出符号。system_call系统调用负责系统调用并陷入内核，从前它是一个int 0x80指令，现在它是sysenter指令，它精简了int的流程。这是因为保护模式中CPU首先从中断描述符表(IDT)中取出对应的门描述符，比较中断描述符级别DPL和int调用者级别CPL，我们禁止CPL&gt;DPL的调用，但是对于系统调用来说比较描述符的这一步是能省掉的，因为我们可以确定这个CPL和DPL。system_call从eax中获得系统调用号，并定位到对应的NR_调用位置。我们需要特别注意的是由于内核抢占和SMP的关系，我的系统调用一定要是可重入的。因此系统调用时完全可以被信号打断的，当然我们也可以在调用前通过SIG_IGN、sigprocmask()、pthread_sigmask()的方法去屏蔽掉信号以防止系统调用被打断。 调度多任务系统常使用非抢占式(cooperative)或者抢占式(preemptive)的调度策略，Linux支持抢占式的任务调度。和处理器的流水线设计类似，一个好的调度策略需要balance延迟和吞吐量，也就是说它应该能在一定程度上识别和预测出IO型和计算型的程序，并且分别给予它们更短的响应时间或者吞吐量。此外，调度的时间间隔，或者说每个进程所拥有的时间片的大小也对应着处理器流水线深度的情况，太频繁的调度会导致系统在调度器上浪费太多的资源，所以我们也要控制调度的切换代价。Linux的调度算法从简单粗暴，变为了O(1)，并在最后使用了RSDL也就是目前的CFS算法。 CFS调度算法CFS根据NICE给每个进程分配一个处理器使用比，一个实际消耗使用比小于当前进程的进程将抢占当前进程。注意到这种策略相对于传统的，按照NICE值给高优先级进程分配更长时间片要更为贴近现实，因为NICE值较高（也就是优先级较低）的进程通常是计算密集型的，而如果按照NICE值，这些进程将获得较短的时间片，反而是优先级高的获得较多的时间片，旱的旱死，涝的涝死。此外，直接用NICE去标定时间片还会涉及定时器节拍改变导致时间片改变、优化NICE到时间片映射的问题，最终的结论是进程之间的切换频率如果非固定的，效果会更好。CFS理论上希望一个进程能运行多久取决于处理器使用比，因此指定目标延迟（如20ms）的情况下，每个进程实际能得到的运行时间就和它占到的比例以及总的可运行进程数有关了。当然，我们的分配也是要有最小粒度的，例如最小的时间片长度不能小于1ms。Linux使用task_struct中的sched_entity结构来描述。在具体实现的时候我们并不会望文生义地来做，而是在结构sched_entity中使用vruntime表示加权的虚拟运行时间，这里的加权指的是默认进程的权重比上当前进程的权重。在update_urr中，Linux使用now - curr-&gt;exec_start计算出delta_exec时间并使用__update_curr，将未加权的加入到sum_exec_runtime，加权的加入到vruntime中。根据CFS的原则，我们现在应当从CFS队列cfs_rq（这里rq表示run queue的意思，在Linux源码中有很多这样的简写）中调用__pick_next_entity()选取vruntime最小的进程，Linux在这里使用了红黑树来实现。 Linux的调度器schedule()函数负责选中最高优先级的调度类中最高优先级的进程，整个过程最后会到idle类，对应到Linux中的0号(idle)进程。有多个调度类的原因是由于Linux中不但存在普通进程（对应于CFS），还存在实时进程。在选中之后，schedule()会调用context_switch()来进行上下文切换。一般来说，schedule()函数是由进程调用的，当进程死亡（调用do_exit）、阻塞等需要放弃当前时间片时就会调用schedule()。我们现在考虑最主要的等待某个条件而陷入阻塞的情况，这时候线程会将自己放入等待队列，等待一个condition。这个过程涉及到多个函数，其中DEFINE_WAIT宏用来创建一个wait_queue_entry结构，add_wait_queue负责将一个进程增加到等待队列，prepare_to_wait负责等待队列上的一个进程置入睡眠，finish_wait负责将一个进程移出等待队列。这些函数中都使用了内部结构spin_lock来维护等待队列。《Linux内核设计与实现》书中举了下面的典型的用例，我们看到整个过程用while所维护，期间会发生若干次schedule()。此外我们发现进程可能会被信号所唤醒，也就是所谓的虚假唤醒/伪唤醒，这时候我们同样退出循环，而不是继续循环等待，这也就是为什么我们在后面看到使用条件变量要while-wait的原因。唤醒操作由wake_up()函数负责，它会负责调用try_to_wake_up，该函数会唤醒等待队列上的所有进程，注意系统中有很多个这样的等待队列，每个等待队列上的所有进程等待同一个事件。一般来说，wake_up的调用者就是使得条件达成的那一方，这个和条件变量的逻辑是相同的。刚才说到有虚假唤醒，其实还有无效唤醒，也就是进程带着condition进入睡眠。12345678910111213141516171819202122232425// 3.11.10// inotify_readDEFINE_WAIT(wait);start = buf;group = file-&gt;private_data;while (1) &#123; prepare_to_wait(&amp;group-&gt;notification_waitq, &amp;wait, TASK_INTERRUPTIBLE); mutex_lock(&amp;group-&gt;notification_mutex); kevent = get_one_event(group, count); mutex_unlock(&amp;group-&gt;notification_mutex); if (kevent) &#123; ... ret = copy_event_to_user(group, kevent, buf); fsnotify_put_event(kevent); ... continue; &#125; ... if (signal_pending(current)) break; ... schedule();&#125;finish_wait(&amp;group-&gt;notification_waitq, &amp;wait);... Linux的抢占被动式的调度指的是使用一个调度器决定哪一个任务会在下一刻运行，而不是由进程主动放弃处理器。由调度器决定暂时停止一个任务并让另一个任务开始执行的行为就是抢占式(preempt)调度。抢占式调度分为用户抢占和内核抢占两种。先前提到，进程可以通过主动调用schedule()来放弃剩余时间片，但对于时间片耗尽的情况，内核中的scheduler_tick()函数（此时关中断，需要在2.6版本左右查看）会通过set_tsk_need_resched(p)函数设置一个need_resched标志，这个标志从逻辑上讲应该是全局性的，但为了方便从高速缓存中读取，它自2.2版本后被放到了每一个进程的task_struct中，自2.6内核后放到thread_info中。此外在刚才的try_to_wake_up()唤醒过程中，如果被唤醒的进程的优先级更高，这个标志也会被设置。从系统调用/中断处理程序中返回的情况也包括在内，这也对应着用户抢占。 用户抢占Linux的用户抢占并不是在用户态下，而是发生在进程即将从内核态返回用户态时，这对应两种情况，从系统调用返回和从中断处理程序返回。如果不开启内核抢占，抢占式调度会给每一个进程的运行分配一个固定或者动态计算的时间片(timeslice)，进程在内核态的运行会直至结束（主动放弃(yield)/时间片耗尽/阻塞）。这样的假设方便了内核的编写，特别是在单处理器(UP)下，因为我们考虑到在内核态中不存在对进程上下文的切换，所以内核并不需要考虑对临界资源的竞争访问问题，因此用户程序也可以假设在一次系统调用过程中不需要保护内核临界资源。但需要注意的是中断仍然存在，所以在进入临界区前还需要关中断。 内核抢占通过内核抢占，系统允许高优先级的进程抢占低优先级的进程的内核态，这将能提高系统的实时性能。内核抢占可能发生在中断处理程序返回到内核空间前、内核代码具有抢占性、内核代码显式调用调度器schedule、内核中的任务被阻塞时。此外，内核抢占是可以被关闭的，即所谓的关抢占的几种情况： 当内核调度器scheduler正在运行时 这个是显然的，我们可以直接在schedule()函数中看到相应实现 1234567891011121314// 2.6.11// /include/linux/preempt.#define preempt_disable() \do &#123; \ inc_preempt_count(); \ barrier(); \&#125; while (0)// /kernel/sched.cneed_resched: preempt_disable(); prev = current; release_kernel_lock(prev);need_resched_nonpreemptible: rq = this_rq(); 另及，Linux通过内核抢占锁preempt_count来跟踪一个进程的可抢占性，当内核代码具有抢占性时（此时preempt_count为0，且need_resched被设置），则调用preempt_schedule_irq -&gt; schedule进行内核抢占，这过程的发生场景之一就是从时间中断返回。我们看到这里关中断实际上是自增了preempt_count使它不等于0。这里的do{}while(0)是出于宏的考虑，防止和其他语法结构（如没有括号的if）混用导致错误。 中断的bottom half 通常有上文所述的三种方式，当内核执行软中断和tasklet禁止内核抢占，但注意此时可以被硬中断打断。 当进程持有自旋锁读写锁 这实际上是为了保护临界资源，在有关自旋锁的讨论中会详细说明。事实上当进程持有锁时preempt_count会自增，释放锁时preempt_count会自减，这也就是使用preempt_count的缘由，进程持有锁的数量直接影响到它的可抢占性。 内核正在处理中断 这时候也就是所谓的中断上半部，中断在操作系统中拥有最高的优先级，我们也在前文中论述了中断上下文中不能睡眠的原因，这里不能抢占的原因也是类似的。 内核操作Per-CPU data structures 在SMP架构中，不同的CPU仍然会维护一些私有数据，此时抢占可能造成一个进程被调度到另一个CPU上去，此时Per-CPU变量就会发生改变。我们可以查看相关代码 1234// 2.6.39.4// /include/linux/smp.h#define get_cpu() (&#123; preempt_disable(); smp_processor_id(); &#125;)#define put_cpu() preempt_enable() 而get_cpu就是获得当前的CPU，我们看到首先这一步骤就关了抢占，其中smp_processor_id会调用raw_smp_processor_id这个宏，然后根据不同的CPU来讨论。例如对x86来说，这个宏是#define raw_smp_processor_id() (percpu_read(cpu_number))，然后是#define percpu_read(var) percpu_from_op(&quot;mov&quot;, var, &quot;m&quot; (var))。然后我们就可以根据获得的CPU号操作unsigned long my_percpu[NR_CPUS]这样的每个CPU独有的数据了。注意所有这样的操作是不需要加锁的，因为这是当前CPU独有的数据，而内核抢占又被关闭了，所以不存在并发访问问题。 《Linux内核设计与实现》中指出了对每个CPU维护私有数据的好处： 减少了竞态条件和锁的使用，这个在上面已经提到 减少了缓存失效的可能 根据MESI，同一数据可能存在于多个CPU的缓存中，这样一个CPU造成的修改会导致缓存失效。而一些性能不佳的代码会造成缓存抖动，也就是缓存的不停刷新，这样极大地降低了效率。Linux2.6内核提供了per_cpu接口能够缓存对齐(cache-align)所有数据，这样可以保证不会讲其他处理器的数据带到同一缓存上。 关中断 这是一种特殊情况，关中断后抢占机制自然无法实现了，Linux关中断通常借助于local_irq_disable或者local_irq_save。 可重入、异步信号安全、线程安全与中断安全可重入函数考虑单线程模型，一般来说执行流程是不会被外部打断的，但考虑可重入(reentrant)性仍然是有必要的。一个典型的场景是signal机制（借助于软中断实现）。例如，我们在函数func涉及读写全局变量errno，在这个过程中被signal中断，而中断处理程序也会访问这个errno，那么当继续进行func时就可能读到无效的errno。很多的系统调用是可重入的，一般来说不可重入函数具有以下几个特征： 在未保护的情况下访问全局或者局部静态变量 我们希望可重入函数只访问自己栈上的变量。 这里注意，严格意义上errno这个全局变量是怎么都避免不了的，但幸好这个变量有着明确的修改时间，所以我们推荐在信号处理函数一开始保存errno，退出时恢复errno的做法，从而保护了调用前后的现场。 调用malloc/free函数 因此我们在信号处理函数里面应当避免使用malloc，这是因为如果我们在主逻辑里面malloc时被signal了，这时候信号处理对malloc的调用就有可能破坏内核数据结构。 调用标准IO等对硬件有副作用的函数 调用longjmp之类的函数 POSIX中还描述了异步信号安全(async-signal-safe)的概念，并列举了一系列信号安全的系统调用。从本质上讲一个异步信号安全的函数要不是可重入的，要不对信号处理函数来说是原子的，即不能被打断。 线程安全异步可重入和线程安全是两个不同的概念，线程安全指一个函数能够同时被多个线程安全地调用。一般来说线程安全的函数不一定是可重入的，如malloc，而反之则一般是成立的。所以我们可以体会到Linux提供的signal机制虽然能够实现异步，但是却添加了许多需要考虑的成分。 中断安全内核和运行时向外提供的并发与同步设施多进程与多线程进程是UNIX设计模型中的一个重要部分，UNIX推崇以多进程+IPC的方式组成应用系统，充分贯彻了KISS的方针。在UNIX产生的年代，这种方式无疑是很健壮的。从定义上看，进程是资源分配的最小单位，那么线程是程序执行的最小单位。线程通常和同一程序下的其他线程共享一套地址空间，其中包含应用程序拥有的程序代码与资源，每个线程自己维护一套运行上下文。 同步与异步在进程IPC中同步和异步是两种编程模型，描述了IPC中被调用者的行为。在同步模型中一个调用只有在等到结果（也就是被调用者完成计算）时才返回，被调用者并不会进行通知。而异步模型中调用会立即返回，而由被调用者选择在结果达到后通过回调函数或者信号等机制进行通知。UNP书中还强调异步过程中用户不需要手动将数据从内核复制到用户（即不需要在被通知后调用read等函数），但我觉得这是异步过程所必须具备的特性，而不是其根本的区分点。需要和同步异步进行区分的是阻塞和非阻塞的概念，这两个描述了调用结果未到达时调用者的状态。阻塞调用会直接睡眠线程，而非阻塞调用不会阻塞线程。在非阻塞同步调用中，当调用者还没有收到来自调用者的返回时，调用者可以原地进行轮询等待，此时虽然逻辑无法持续，但线程并没有进入睡眠。此外，非阻塞模型还可以是异步的，此时线程可以继续执行下面无关返回值的逻辑，消息到达时线程收到一个异步信号或者回调，或者采用类似协程的方法。IO多路复用是一种特殊的同步模型，并且它们在消息到来前必须在一个循环中轮询，而不是立即返回并跳出循环。不过IO多路复用并不属于同步阻塞模型，因为当一个fd在等待结果时，线程可能在处理来自其它fd的IO，因此并不一定会进入睡眠。IO多路复用也不属于同步非阻塞模型，因为当没有任何一个fd产生IO事件时，线程还是会被阻塞的。此外UNP还特别指出poll函数中仍然需要手动将数据从内核复制回来，并把它作为多路复用和异步之间的一个区别。以UNIX套接口为例，SS_NBIO和SS_ASYNC标志分别表示非阻塞和异步的选项，其中非阻塞套接口在请求资源不满足时会返回EWOULDBLOCK，而异步套接口则会通过SIGIO信号来通知进程。 协程协程(Coroutine)是具有多个入口点的函数，协程内部可通过yield进行中断，此时处理器可能被调度到执行其他的函数。虽然线程也可以睡眠，但睡眠本身涉及用户态与内核态的上下文切换，开销较大。对于套接字等IO密集型的应用，协程在提高CPU使用率上比线程轻很多。协程根据其底层实现可以分为stackful和stackless两种。stackless实现不保存调用栈和寄存器等上下文，因此效率比较高。stackless的协程实现例如C++中的setjmp、Python中的生成器等。stackful即栈式构造，这时候协程拥有自己的堆栈等上下文。stackful的协程类似于C++中的ucontext、libco等。协程根据控制传递方式可以分为对称(symmetric)协程和非对称协程(asymmetric)。我们知道协程实际上是一种对CPU控制权的转移，对称协程在转移时可以转移到其指定的任一对称协程，而非对称协程只能转移到其“调用者”。理论上已经证明了这两种协程是等价的，但显然非对称协程在使用上更友好。 C++下协程的实现方式基于ucontextucontext是POSIX上的一套用于保存上下文的库，这里上下文包括寄存器（通用和浮点）、信号等。 黑科技1Protothreads基于C的是围绕switch展开的一系列黑科技实现的协程。我们首先看它定义的一些原语，原来这就是一个简易的，关于行号的状态机。我在这里模仿Protothreads实现了一个简易版的协程12345#define PT_BEGIN() bool ptYielded = true; (void) ptYielded; switch (_ptLine) &#123; case 0:#define PT_YIELD() \ do &#123; ptYielded = false; _ptLine = __LINE__; case __LINE__: \ if (!ptYielded) return true; &#125; while (0)#define PT_END() default: ; &#125; Stop(); return false; 为了理解这段代码，我们回想C++实现协程需要实现的一个核心问题，并不是调度，而是实现从多个入口点进入。这就意味着我们需要在退出协程函数时记录下已经到了哪里，然后在下一次进入函数时回到这个地方。对于第一个需求，我们可以借助于__LINE__这个宏表示执行到的行号，每次将这个行号赋值给一个int。对于第二个需求，我们可以借助于switch实现跳转。这里用switch而不用goto的原因是switch能够根据int变量来实现goto的功能，而goto需要依赖静态的label。这种巧妙的机制不禁让我想起了称为Duff’s device的优化方案。不过这种机制有一个语法缺陷就是在里面嵌套的switch语句会产生干扰。 基于setjmp和longjmpsetjmp和longjmp类似跨栈帧的带上下文的goto。int setjmp(jmp_buf env)负责将函数当前的上下文保存在jmp_buf中。 约束线程间并发行为线程间实现互斥与同步的任务常具有下面两种形式： 多个线程同时访问一个共享资源，需要维护该共享资源的完整性。这就是Race condition问题，将在本节讨论。 一个线程向另一个线程通告自己的结果/等待另一个线程的结果，这将在章节数据共享中讨论。 总的来说，为了实现同步，等待资源的一方可以处于用户态（忙等）或者内核态（睡眠），而获得资源的一方可以选择锁进行同步，或者使用原子操作保证自己访问不被打断。这分别下面的基于锁和原子操作的工具。Linux、Windows和C++11的标准库中都对这些工具提供了不同程度的支持，具体可参考文档。 Race condition竞态条件常出现在逻辑电路这样的硬件环境中，对于软件环境而言，当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件(race condition)，导致竞态条件发生的代码区称作临界区。 volatile在有关CPU缓存一致性的章节中，我们讨论的volatile、寄存器、主存和CPU缓存之间的关系。这里我们讨论语言（C/C++）层面的volatile的有关特性。C++中的volatile并不以任何形式保证线程安全，它仅用来告知编译器期修饰的变量是易变的，要避免对其进行优化，这里所谓的优化常常是将变量缓存到寄存器中而不是每次都从内存读取。volatile并不蕴含禁止编译器或者处理器进行重排或乱序，我们需要通过编译器屏障或者内存屏障来实现这一点。volatile关键字有时是有用的，例如可以在自旋锁中防止多次循环中始终读取寄存器中的值。但滥用volatile不仅不会提高程序的安全性，而且会导致程序变慢。对于以为可以加“volatile”就可以解决的问题，一般可以使用std::atomic来避免使用内核锁的开销。 内核锁内核锁一般基于内核对象互斥量/信号量，它们通常是阻塞锁，会导致线程进入睡眠。锁的存在通常限制了并发范围，变并行访问为串行访问。在使用锁维护临界资源时应当争取让序列化访问最小化，真实并发最大化。 互斥量在C++中一般不直接使用std::mutex，而使用lock_guard和unique_lock。lock_guard和unique_lock利用了RAII来自动管理加锁解锁操作，它们能够应用到包括互斥量的所有Lockable的对象上。unique_lock相比于lock_guard更灵活，用户能够手动地加/解锁，例如在条件变量中就需要unique_lock以便解锁，而在取得对临界资源后进行处理时也可以暂时解锁。unique_lock还是可移动的，以下面的代码为例，这里1处是一个直接返回lk，编译器可能进行NRVO，当然即使不这么做，2作为一个直接初始化操作，也可以接受get_lock返回的将亡值，从而完成移动构造std::unique_lock&lt;std::mutex&gt;。因此这里锁的控制权从get_lock转移到了process_data。123456789101112std::unique_lock&lt;std::mutex&gt; get_lock()&#123; extern std::mutex some_mutex; std::unique_lock&lt;std::mutex&gt; lk(some_mutex); prepare_data(); return lk; // 1&#125;void process_data()&#123; std::unique_lock&lt;std::mutex&gt; lk(get_lock()); // 2 do_something();&#125; 一般会将mutex和临界资源一起放到一个类中进行管理，此时宜保证该临界资源是非public的，并且不会以引用或者指针的形式传出。这些场景例如成员函数直接返回指针或者引用，友元函数，或者一个接受函数指针P作为参数的函数，且P接受了临界成员的指针或引用，并将其泄露到类外（C++ Concurrency in Action），因此我们还要避免在持有锁时调用用户提供的代码。虽然我们的愿景是希望最大化真实并发，因此要追求较小粒度的锁(small granularity)，一个较小的粒度表现在锁所保护的临界数据较少，并且持有锁的时间较短，但粒度不可能无限小。例如考虑删除双向链表中的一个节点，需要修改三个节点的数据，如果对这三个修改单独加锁，其实等于没有加锁。因此一个直截了当的解决方案是在删除过程中锁住整个链表。如果是仍然希望为每个节点维护一把锁，那么对于删除操作必须获得被删除节点和其相邻的共三把锁，当重新连接节点时，必须在获得当前节点锁的前提下尝试获取下一节点的锁（但一旦持有了下一节点的锁就可以释放当前节点的锁了），以防后继节点产生变化，这有点类似于数据库上的蟹行协议，称为lock coupling。与此同时，在遍历时同样需要按照和删除相同的上锁步骤。我有个朋友当时就对这一点很疑惑，他说我添加删除都上锁了，那为啥访问还需要加锁？锁这玩意，防君子不防小人，那我访问的时候完全可以不去获取锁的嘛，那你那边的线程加不加锁管我什么事，除非加锁、解锁和改指针的操作是原子的。那么在遍历的时候是只锁一个节点就行了，还是要蟹行呢？我们可以举一个很夸张的例子，例如我们从头遍历链表[a,b,c]并试图删除b，其过程是获取a的锁，然后获取b=a.next，然后锁住b，然后移除从a到b的指针。那么我们同时有一个遍历线程，它是龟兔赛跑里面属兔子的，乌龟还没出发，他就遍历到a了，这时候a没有被锁住，然后这位兔子线程释放了a的锁（蛮良心的，睡觉前懂得释放锁），然后拿着a的后继也就是b去睡觉去了。这时候乌龟线程才开始锁住a和b，并删除掉了b。乌龟线程释放完锁继续往后面遍历了，这时候a的后继已经是c了，兔子线程醒来了， 此时他还以为b是真的后继呢！下面我们再考虑一个线程安全的栈，其中实现了empty()、top()、size()、push()、pop()等常见方法。在多线程下，下面的代码中pop()可能使得top()的结果无效，这是因为在1和2两个方法间可能有另一个线程执行了pop()。容易看出无论这些方法内部怎么加锁都无法避免这种情况，因为这里的竞态发生在这些方法之间，C++ Concurrency in Action特别指出这属于接口设计的问题。在后面内存模型的部分，我们能看到类似的问题，原子操作虽然避免了竞态，但原子操作之间可能存在的乱序必须要被考虑。书中还指出了另一个更严重的2和3之间竞争的错误，假设有两个线程并行执行该段代码，我们期望的顺序是top[1] -&gt; pop[1] -&gt; top[2] -&gt; pop[2]，中括号表示执行该方法的线程。然而实际执行顺序可能是top[1] -&gt; top[2] -&gt; pop[1] -&gt; pop[2]。这就导致了从栈顶开始的两个元素有一个被处理了两次，另一个完全没有被处理。一个简单的解决方案是将这两个调用合并成一个带返回值的pop，使用一个mutex来管理，但Tom Cargill指出这处理方式是有问题的。这涉及到为什么标准库在设计时选择将top()和pop()两个方法，原因是可能发生在成功将元素pop后而拷贝函数失败，这个元素就被丢失，所以先取top()再pop()保证了top()失败情况下可以选择不执行pop()。123456stack&lt;int&gt; s;if (! s.empty())&#123; // 1 int const value = s.top(); // 2 s.pop(); // 3 do_something(value);&#125; 死锁使用互斥量的另一个问题是死锁，这时候锁机制避免了竞态，却可能产生线程对锁的竞争，即线程间互相等待对方的锁。死锁的产生满足四个条件：互斥、占有且请求、不可抢占和循环等待。其中等待且请求条件很关键，当完成一个操作需要获得两个及以上的锁时，死锁往往就会发生。为了解决死锁就要想办法破坏它的四个条件之一。从占有且求的角度来解决，我们可以借助于Dijkstra的银行家算法。在C++11中，我们可以使用标准库函数std::lock来同时上锁，不过现实情境下我们往往难以在申请锁时就确定自己需要哪些锁。因此在诸如数据库的系统中，会引入两段加锁协议。从破坏循环等待条件的解读来设计的一个解决方案是永远按照一个顺序来获得锁，以哲学家就餐问题为例，我们将筷子进行编号，并约定哲学家们总是先尝试获得编号较低的筷子，用完后总是先释放编号较高的筷子，这样就能避免死锁问题，在加锁阶段只加锁 不解锁，在解锁阶段只解锁不加锁。注意到约定哲学家们总是先拿起左手边的筷子，再拿起右手边的筷子恰恰会导致死锁问题，因为在这里我们并不是对每一个哲学家的操作指定一个相对的规则，而是为所有的资源（锁）的获取直接指定一个绝对的顺序。于是我们发现有时候去确定一个顺序并不是很容易。对于swap函数来说，我们可以按照参数的顺序来加锁，例如先获得第一个参数的锁，再获得第二个参数的锁。可惜这个是相对的，例如考虑如下面代码所示的两个规则，容易发现这两个线程并行执行时死锁就会发生了。1234// thread 1swap(a, b);// thread 2swap(b, a); 为了解决这个问题，一个方法是对每个对象求Hash，从而进行排序，另一种是借助于std::lock函数。这个函数的作用是将多个互斥量同时上锁（失败时则抛出异常并释放已经获得的锁），下面代码展示了一个线程安全的swap。12345678910111213141516171819202122232425class some_big_object;void swap(some_big_object&amp; lhs,some_big_object&amp; rhs);class X&#123;private: some_big_object some_detail; std::mutex m;public: X(some_big_object const&amp; sd):some_detail(sd)&#123;&#125; friend void swap(X&amp; lhs, X&amp; rhs) &#123; if(&amp;lhs==&amp;rhs) return; std::lock(lhs.m, rhs.m); // 1 // std::adopt_lock告知这个lock_guard已获得锁 std::lock_guard&lt;std::mutex&gt; lock_a(lhs.m, std::adopt_lock); // 2 std::lock_guard&lt;std::mutex&gt; lock_b(rhs.m, std::adopt_lock); // 3 swap(lhs.some_detail, rhs.some_detail); &#125;&#125;;// 注意1/2/3也可以换为以下代码 std::unique_lock&lt;std::mutex&gt; lock_a(lhs.m, std::defer_lock); std::unique_lock&lt;std::mutex&gt; lock_b(rhs.m, std::defer_lock); // unique_lock 不对互斥量上锁 std::lock(lock_a, lock_b); // 互斥量在这里上锁 std::lock的实现借助了try_lock即_Try_lock。1234567891011121314151617181920212223242526272829303132333435363738template&lt;class _Lock0, class _Lock1, class... _LockN&gt; inlinevoid lock(_Lock0&amp; _Lk0, _Lock1&amp; _Lk1, _LockN&amp;... _LkN)&#123; // lock N mutexes int _Res = 0; while (_Res != -1) _Res = _Try_lock(_Lk0, _Lk1, _LkN...);&#125; template&lt;class _Lock0&gt; inlineint _Try_lock(_Lock0&amp; _Lk0)&#123; // try to lock one mutex if (!_Lk0.try_lock()) return (0); else return (-1);&#125;template&lt;class _Lock0, class _Lock1, class... _LockN&gt; inlineint _Try_lock(_Lock0&amp; _Lk0, _Lock1&amp; _Lk1, _LockN&amp;... _LkN)&#123; // try to lock n-1 mutexes int _Res; // 如果第一个锁_Lk0直接失败，则返回失败0 if (!_Lk0.try_lock()) return (0); try&#123; // 否则递归地尝试获取第二个锁_Lk1，如果失败则解开第一个锁并修改_Res为失败0 if ((_Res = std:: try_lock(_Lk1, _LkN...)) != -1) &#123; // tail lock failed _Lk0.unlock(); ++_Res; &#125; &#125;catch(...)&#123; // 如果出现异常同样解开第一个锁并返回失败0 _Lk0.unlock(); throw; &#125; return (_Res);&#125; 值得注意的是引起死锁的并不一定是锁，而可以扩展到造成互相等待的其他情况，例如一组线程互相join等待对方，相互阻塞，这导致整个程序无法往下运行，或者线程在持有锁时同时等待其他线程。此外即使在一个线程中，也会出现如同死锁的现象，例如下面的代码中，我们希望subroutine1和routine都在mut的保护下，但这样一来程序就会死锁。1234567891011void subroutine1()&#123; mut.lock(); mut.unlock();&#125;void routine()&#123; mut.lock(); subroutine1(); ... subroutine2(); mut.unlock();&#125; 另一种解决死锁的办法从锁的角度，为锁提供层级。一个已持有低层级锁的线程是不能试图获得高层级的锁的，试图违反这一约定的行为将导致抛出异常或终止程序。注意到不能同时持有相同层级上的锁，所以这些互斥量往往形成一条链。一个层次互斥量hierarchical_mutex的实现可以对每个线程使用一个thread_local全局变量进行维护当前线程所持有的锁的层级，默认取UINT_MAX，这样线程可以获得任何层级的互斥量。但即使可以避免死锁也要注意锁的粒度（保护数据规模与持有时间）对性能的影响，一个总的原则是一个锁应当被持有尽可能少的时间，并且在持有过程中只应该去完成必要的工作。特别地，持有一个锁的同时等待另一个锁，即使不造成死锁，也要考虑其性能问题。以判定两个int是否相等为例，在先前我们看到了一个swap函数的实现方案，同时对两个互斥量进行加锁。但这里考虑到实际上int非常小，所以比较好的是分别对两个int加锁，复制副本，并比较两个副本，从而避免同时持有两个锁。注意和前面top()和pop()所遇到的问题一样，在对intA和intB的读操作(LOAD)间可能发生另一个线程对intA的写操作，导致先前读取到的是旧值。 自旋锁自旋锁是一种忙等锁(busy waiting)，它适用于短时间锁定某个资源，这样可以避免内核锁所需要的线程睡眠（两次线程上下文切换）等一系列的开销，但持有过长的自旋锁会导致浪费大量CPU资源。特别是在单核CPU上，自旋锁的使用需要审慎考虑，因为在单核CPU上同一时间只能运行一个线程，这时候如果等待锁的线程先运行，那么它势必进入空等直到时间片用完，因为获得锁的线程势必不能运行以释放锁。因此在单核CPU上使用内核锁进入睡眠是一个好的选择。自旋锁常被用在对称多处理器(SMP)系统中，在多CPU的情况下保护临界区。 自旋锁与中断处理处理中断时不能使用互斥量、信号量等让线程进入睡眠的锁，因此自旋锁常用于内核中有关中断处理的部分。内核锁必须在进程上下文（对应于中断上下文）中才能使用，这里的关闭中断的目的是为了关闭调度，因为关闭了时钟中断（时钟中断是可以被关闭的），调度器就无法运转了。这样就产生了睡死的现象。 持有自旋锁时不能进入睡眠自旋锁适用于不能睡眠的场景，但双向地来说，持有自旋锁时也不能进入睡眠，否则会引起死锁。为了理解原因，首先要了解为什么自旋锁常伴随关中断和关抢占。Linux中提供了各个品种的自旋锁操作函数。其中spin_lock系列的关闭了抢占而不关中断，而spin_lock_irqsave、spin_lock_irq、spin_lock_bh会一道把中断也关了。关抢占的原因是如果一个低优先级的线程A获得自旋锁而紧接着被一个高优先级的进程B抢占，那么会造成这两个线程死锁，直到时间片用尽，也就是所谓的优先级反转（优先级倒置）现象，会严重影响性能。关中断的原因是如果一个进程A获得自旋锁然后被一个中断打断，如果这个中断处理器也试图获得同一个自旋锁，那么就会造成在中断内部的死锁（自旋锁不能嵌套上锁，否则会造成自死锁现象），并且中断处理无法被抢占（但可以被其他中断打断）。可以参考文章和知乎。既然使用自旋锁应当关闭中断或者调度，那么原因就很明显了，如果进程A获得了自旋锁并且阻塞在内核态，此时内核调度了进程B（阻塞可导致调度），而B也试图获得自旋锁，那么B将永远自旋，A将永远睡眠，这类似于开中断时在中断内的死锁情况，不过在这种情况下仍有可能B时间片用完从而再次重新调度。此外另一种解释认为对于不关中断的自旋锁在睡眠后可能会被重新调度，从而造成自死锁的现象。这种思想同样值得用在处理异常、信号等会破坏程序执行顺序的地方。 临界区相对于互锁访问函数这种“有限的”原子操作，临界区允许对一段代码进行“原子操作”，临界区相对于互斥量比较轻便，这是由于互斥量能够跨进程，并且支持等待多个内核对象。同时线程在进入一个被占用的临界区时会首先尝试自旋锁，在自旋锁循环一定次数失败后再让线程进入睡眠。 临界资源的初始化我们考虑临界资源的初始化问题，一个重要的情景就是实现单例模式。在C++11后，可以方便地使用局部静态变量（Meyers Singleton满足初始化和定义完全在一个线程中发生，并且发生在所有其他线程访问之前）或者std::call_once（在C++11前我们只能使用Linux系统中的替代品pthread_once）实现线程安全的单例模式。不过首先先看看一个使用锁的朴素的，也是开销巨大的方案。查看下面的代码，我们可以发现这里用一把大锁保证了不会有两个线程竞争创建/访问p_singleton的实例。但同时需要意识到当实例被唯一地创建好后，这个函数就不需要要锁来保护了，因为在这种情况下它简单到可以作为原子操作，然而事与愿违的是每次调用这个函数都需要获得锁。因此我们需要一种仅保护临界资源初始化过程的机制。12345678Singleton * p_singleton = nullptr;Singleton * get_singleton() &#123; std::lock_guard&lt;std::mutex&gt; lock(mtx); if (p_singleton == nullptr) &#123; p_singleton = new Singleton(); &#125; return p_singleton;&#125; 双重检查锁定模式(Double-checked locking pattern, DCLP)指的是在加锁前先进行一次验证是否可以加锁。下面使用双重检查锁定模式来减少加锁的开销，具体的做法是先检查一遍p_singleton是否为nullptr。12345678910Singleton * p_singleton = nullptr;Singleton * get_singleton() &#123; if (p_singleton == nullptr) &#123; // a std::lock_guard&lt;std::mutex&gt; lock(mtx); if (p_singleton == nullptr) &#123; // b p_singleton = new Singleton(); &#125; &#125; return p_singleton;&#125; 但其实这种加锁方式也是有理论上的风险的，例如我们的p_singleton不是原子的，甚至都不是volatile的，基于我们与编译器的约定，编译器完全可以认为p_singleton的值不会发生变化，因此直接将两层if削掉一层。但是即使我们将p_singleton套上std::atomic、加上volatile，这个代码仍然是错误的。原因在于p_singleton = new Singleton()这条语句不是原子的。我们可以把该语句分为三步 分配内存 构造对象 指针指向对象 编译器在理论上（但实践中编译器没有理由去进行这样的重排）会在2构造对象前执行1内存分配和3指针指向操作。假设线程在1/3步骤完毕之后被挂起而来不及执行2步骤，而另一个线程开始访问a处的代码，注意到此时p_singleton已经不是nullptr了，于是函数会返回一个未初始化的内存。继续思考我们发现，这里的问题是由于第一个线程此时已经在初始化p_singleton，这第二个线程就不应该有机会执行到a处的代码，试想即使第二个线程知道初始化再被另一个线程执行，那它也做不了任何事情，因为代码中写了要么初始化并返回指针，要么直接返回指针。选择前者会破坏第一个线程的初始化过程，选择后一个会造成上面说的结果。因此在a处对p_singleton进行保护是非常有必要的。在稍后的章节中，我们将对双重检查锁定模式进行进一步的讨论。 因此实际上使用上面提到的std::call_once是一个更好的解决方案。在下面的代码中，只会输出一行Called once。12345678910111213std::once_flag flag; void do_once() &#123; std::call_once(flag, []()&#123; std::cout &lt;&lt; "Called once" &lt;&lt; std::endl; &#125;); &#125;int main() &#123; std::thread t1(do_once); std::thread t2(do_once); t1.join(); t2.join();&#125; 这里的std::once_flag不能被拷贝和移动，其实相当于一个锁，call_once实现如下1234567891011121314151617181920212223242526272829303132333435363738template&lt;class _Fn, class... _Args&gt; inline void (call_once)(once_flag&amp; _Flag, _Fn&amp;&amp; _Fx, _Args&amp;&amp;... _Ax) &#123; // call _Fx(_Ax...) once // 定义一个_Tuple类型 typedef tuple&lt;_Fn&amp;&amp;, _Args&amp;&amp;..., _XSTD exception_ptr&amp;&gt; _Tuple; // _Seq的值索引上面的_Tuple typedef make_integer_sequence&lt;size_t, 1 + sizeof...(_Args)&gt; _Seq; _XSTD exception_ptr _Exc; // 将回调函数参数打包到_Tuple类型里面，最后一个是exception_ptr _Tuple _Tup(_STD forward&lt;_Fn&gt;(_Fx), _STD forward&lt;_Args&gt;(_Ax)..., _Exc); // 使用_Tup里面的上下文特化_Callback_once函数模板 _Lambda_fp_t _Fp = &amp;_Callback_once&lt;_Tuple, _Seq, 1 + sizeof...(_Args)&gt;; // 在xonce.cpp中实际调用了__crtInitOnceExecuteOnce的WINAPI if (_Execute_once(_Flag, _Fp, _STD addressof(_Tup)) != 0) return; if (_Exc) _XSTD rethrow_exception(_Exc); _XGetLastError(); &#125; // xonce.cpp_STD_BEGIN_CRTIMP2_PURE int __CLRCALL_PURE_OR_CDECL _Execute_once( once_flag&amp; _Flag, _Lambda_fp_t _Lambda_fp, void *_Pv) _NOEXCEPT &#123; // wrap Win32 InitOnceExecuteOnce() static_assert(sizeof(_Flag._Opaque) == sizeof(INIT_ONCE), "invalid size"); return (__crtInitOnceExecuteOnce( reinterpret_cast&lt;PINIT_ONCE&gt;(&amp;_Flag._Opaque), reinterpret_cast&lt;PINIT_ONCE_FN&gt;(_Lambda_fp), _Pv, 0)); &#125; 虽然我们可以通过Meyer’s Singleton来做线程安全的单例，但如果我们想带参数地初始化，这个就是困难的。我们可以借鉴下面的代码1234567891011121314template &lt;typename T, typename F&gt;struct Singleton &#123; static T* get() &#123; static T* p&#123;nullptr&#125;; std::call_once(flag, F()); return p; &#125; private: static std::once_flag flag;&#125;;template &lt;typename T&gt;std::once_flag Singleton&lt;T&gt;::flag; 读写锁相对于临界区，读写锁能提供更精细的控制，它适用于写操作远少于读操作的数据结构。读写锁允许一个写线程独占访问，而多个读线程并行访问。当写线程需要独占访问时，它需要获得一个排它锁，如果此时有另外的线程持有排它锁或者共享锁，那么本线程就会被阻塞。当读线程需要共享访问时，只要没有线程持有排它锁，那么他就可以立即获得共享锁。读写锁的过程可以参照来自博文的论述12345678910111213Read object begin P(object.lock) AtomicAdd(object.activeReader, 1) V(object.lock) Do Actual Read AtomicAdd(object.activeReaders, −1)endWrite object begin P(object.lock) while object.activeReaders != 0 do delay Do Actual Write V(object.lock)end 对读写锁Windows API提供了所谓的SRW系列函数，Linux提供了rwlock系列函数。在C++14中终于提供了std::shared_timed_mutex来实现读写锁，C++17中提供了std::shared_mutex来实现一个没有定时的读写锁，从设计上看来这是有点本末倒置的，为什么要在C++17实现一个功能更少的类呢？SoF指出这是出于性能原因，在C++14制定时，原本的std::shared_mutex拥有定时功能，但稍后一些人指出去掉定时功能能够提高效率，例如在Windows上的SRWLOCK机制提供了高效简便地实现一个没有定时的读写锁的方案，因此后来C++14版本的std::shared_mutex被重命名到std::shared_timed_mutex，而一个没有定时的std::shared_mutex在C++17提供。在C++17中我们的读锁可以声明为std::shared_lock&lt;std::shared_mutex&gt;(shared_lock来自C++14)，写锁可以声明为std::unique_lock&lt;std::shared_mutex&gt;(unique_lock来自C++11)，如此跨越三个版本的标准才最终完成的实现，你只有在C++中才能看到。从实现上来看，无论是关键段、互斥量、信号量，甚至是条件变量都可以实现读写锁。 关键段的实现方式 这里摘录了CSDN上的一个实现。其思想如下 互斥量的实现方式 使用互斥量时我们需要注意在进行读操作时我们要获取写锁以免脏读，但可能出现多个读线程竞争写锁的情况，所以我们需要一个读锁。只有竞争到读锁的线程才能去锁定写锁。其过程如下 1234567891011121314151617// 写lock(mutex_write);write();unlock(mutex_write);// 读lock(mutex_read);if(readers == 0) lock(mutex_write);readers++;unlock(mutex_read);read();lock(mutex_read);readers--;if(readers == 0) unlock(mutex_write);unlock(mutex_read); 信号量的实现方式 这里的Swait(sem, t, d)表示信号量sem的P操作需要t个资源，并且会消耗d个资源，Ssignal(sem, d)表示信号量sem的V操作产生d个资源。这里Swait类似std::lock，可以同时对若干个信号量上锁，从而避免死锁。 1234567891011121314// 初始化max_reader = n; // 最多允许n个读者读Sinit(sem_read, max_reader);Sinit(sem_write, 1);// 写Swait(sem_write, 1, 1; sem_read, max_reader, 0);write();Ssignal(sem_write, 1);// 读Swait(sem_write, 1, 0; sem_read, 1, 1);write();Ssignal(sem_read, 1); 条件变量的实现方式 不变量与恶性条件竞争不变量(invariant)是某个特定数据结构始终保持的特性。例如通过链表的前向指针始终能到达前驱结点。不变量对应的特性常常在更新过程中被破坏，特别是当更新涉及到修改多个值，或者需要多个过程时。这就类似于在最终一致性系统的窗口内强一致性被破坏。当不变量遭到破坏时，才会产生竞态条件（C++ Concurrency in Action: Ch3）。为了解决竞态条件，一种方法是确保只有当前进行修改的线程才能看到不变量被修改的中间状态，也就是将临界资源保护起来，前面看到的互斥量等属于这种机制。另一种方法是借助于锁无关编程技术，这种技术将对数据结构的修改分解为若干个不破坏不变量的原子操作。还有一种办法是借助于事务的STM技术，将所需要的操作存储于日志中，再合并提交。 锁无关锁无关(Lock-Free)是一种比无干扰(Obstruction-Free)高层次的并发模型，它是一个容易混淆的概念。锁无关与其他模型的本质区别并不是不用锁(Lockless)，而是确保各个线程在访问共享资源时之间不会互相阻塞，从而使得整个程序整体上能够始终向后执行。也就是说，如果线程T1被阻塞在某个操作上，那么一定有个线程T2在某个操作上成功了，通常我们也会这样证明一个算法是锁无关的。相对应地，如果使用内核锁，如果一个获得内核锁的线程被挂起或者挂掉，这容易导致其他拥有锁的线程陷入永久等待。但即使借助于原子操作，也会产生死锁、竞态的问题，例如自旋锁的死锁问题和使用CAS时可能出现的ABA问题。加锁操作通常存在着一些问题，锁无关的编程虽然复杂，但相对于使用锁，锁无关的可伸缩性和性能方面会强于锁相关的算法，并且如果我们能够有序地组织各个线程“各行其道”，就能减少锁的使用。通常来说一个基于锁的算法在高竞争的系统中有较好的效率，因为当发生竞态时线程进行睡眠而不是立即重试，但在一般的情境中，不使用锁往往能避免上下文切换的开销。相应的还有一个无阻塞(Non-blocking)的概念，无阻塞的限制条件要弱于锁无关。属于无阻塞算法而不属于无锁算法的常见例子包括自旋锁。在自旋锁中，所有的线程都不会进入睡眠，因此是非阻塞算法；而考虑当获得锁的线程因为一些原因被暂停时，所有的其他线程仍然需要在原地自旋忙等，因而自旋锁不是无锁算法。由此可见，锁无关编程中定义了如原子操作、CAS之类的范式，它们本身都是不涉及到锁的，但为了确保我们的读写成功，往往需要尝试若干次，但这个多次尝试造成的等待本身不属于锁无关的范畴。其实锁机制本身也是和等待没有关系的，因为有些操作中的等待是客观的，我们不能看到锁，就想到阻塞，就想到等待，这是不正确的，即使我们不停while去轮询，没有锁，但还是存在等待。 原子操作原子操作是常见的实现锁无关编程的方式，常见的原子操作有CAS、FAA、TAS、TTAS等。原子操作指的是不可被中断的一系列操作，在原子操作保证当前操作中不发生线程切换，因此保证了其他的线程不可能访问这个资源。原子操作一般有两种实现方式，第一个是使用锁或者CPU的特殊指令等机制来维持原子性，第二个是当出现并发写等破坏原子性的情况时让操作失败，因此对于第二种情况需要使用一个循环不断尝试。这里需要注意的是，原子操作并不一定就能够提高效率，也就是所谓的scalability，这是由于涉及对共享对象操作的原子指令都可能造成cache invalidation，也就是需要重新刷新缓存行。另外，原子操作本身也是很慢的，如下图所示我们知道x86汇编要求对任意位置的1字节，以及对2/4/8对齐的2/4/8长度的整型读取都是原子的，但是C++11前我们却不能假设甚至是对一个int赋值的操作是原子的，而在C++11后我们需要使用std::atomic来显式声明一个原子的变量。这一方面是由于C++无法保证通过一条指令从内存的存取（考虑一些违反strict aliasing的胡乱cast破坏了对齐）。另一方面也是C++11前根本没有考虑对多线程提供语言级别的支持（这点Java就做得比较好），C++标准规定data race，即并发地去修改一个对象是UB的，所以编译器可以不考虑多线程的情况而进行优化，产生错误。因此通常的方式是直接使用操作系统提供的API，一般来说如果能够有一个原子的CAS，那么就能够借助它实现其他的原子操作。为了展示问题的复杂性，下面展示了一个早期GCC编译器的问题1234567891011121314151617extern int v;void f(int set_v)&#123; if (set_v) v = 1;&#125;// GCC 3.3.4--4.3.0 O1f: pushl %ebp movl %esp, %ebp cmpl $0, 8(%ebp) movl $1, %eax cmove v, %eax ; load (maybe) movl %eax, v ; store (always) popl %ebp ret 在这个问题中考虑调用f(0)，理想情况下v的值无论如何都不会变动的，但是在gcc生成的代码中，我们看到一个始终执行的存储movl %eax, v。显然编译器认为f并不会被修改，而且这对仅面向单线程优化的编译器是完全有理由说得通的。但如果在load和store之间发生了切换，并导致竞态。除了上面的例子，一些常见的优化，例如循环展开都会造成严重后果。 如何判断是不是原子操作举个例子，i++是原子操作么？答案并不是有人说，我i++不就是一条INC指令么，不是原子的么？别忘了执行只是流水线的一部分，还有访存、解码、写回啥的呢。所以我们需要考虑三个维度： 内存 CPU缓存 寄存器和指令 在这些维度中，还需要考虑是否对齐。12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include &lt;sys/syscall.h&gt;#define gettid() syscall(SYS_gettid)int acc = 0;void *start_routine(void* arg) &#123; for(int i = 0; i &lt; 100000; i++)&#123; acc++; &#125;&#125;int main() &#123; acc = 0; pthread_t tid1; pthread_create(&amp;tid1, NULL, start_routine, 0); pthread_t tid2; pthread_create(&amp;tid2, NULL, start_routine, 0); pthread_t tid3; pthread_create(&amp;tid3, NULL, start_routine, 0); pthread_t tid4; pthread_create(&amp;tid4, NULL, start_routine, 0); int a1, a2; pthread_join(tid1, 0); pthread_join(tid2, 0); pthread_join(tid3, 0); pthread_join(tid4, 0); printf("res %d\n", acc); return 0;&#125; 互锁访问函数和CAS操作操作系统提供的原子API常借助于某些CPU（比如Intel处理器）提供的指令，能够对某些类型实现某些原子操作。注意到对SMP架构而言，会出现多个核心并发写的情况，这个涉及到后面的内存模型，并且在这里我们可以暂时忽略这个问题。Windows API提供了一系列Interlocked开头的互锁访问函数，这些函数在处理器层面被保证独占访问。其中一个很关键的便是InterlockedCompareExchange(PLONG dest, LONG value, LONG old)函数，这个函数提供了对LONG类型的原子的CAS操作。InterlockedCompareExchange将*dest和old进行比较，如果相等就将*dest设为value。显然，通过内核锁能够方便地实现原子语义，但原子操作通常会借助于这样的CAS操作，因为这样能避免线程进入睡眠。借助于CAS可以实现其他的原子操作，例如下面的对LONG进行原子赋值的InterlockedExchange函数。在C++11的std::atomic类型中，我们会看到更多的CAS的应用。1234567LONG InterlockedExchange(LONG volatile * target, LONG value)&#123; LONG old; do&#123; old = *target; &#125;while(! InterlockedCompareExchange(target, value, old)); return old;&#125; 这里的do-while循环保证了在InterlockedCompareExchange失败之后再来一遍能够再来一遍直到成功，但是不能将这个循环和自旋锁中的忙等混淆，从而认为CAS不是锁无关的。这是因为CAS实际上并没有“持有”临界资源，它只需要一个指令就能结束战斗。因此任意一个线程的暂停并不会使得其他线程进入忙等，甚至能够使得CAS的成功率更高。因此可以看出CAS在这里对竞争访问实际上是“消极防御”的态度，也就是所谓的乐观锁(Optimistic Locking)，乐观锁是一种非独占锁，它并不是向内核锁一样直接让竞争者们睡眠，而是返回一个失败的状态。相对应的，之前的内核锁和自旋锁等机制属于悲观锁、独占锁。相比乐观锁，悲观锁有以下的弱点（也可以理解为基于锁算法的弱点） 上下文切换造成的性能开销 可能造成的死锁问题 优先级倒置 使用CAS操作实现的无锁链表常见的用CAS实现的Lockfree算法例如并发缓冲队列，我们可以抽象成维护一个链表。 有锁链表——使用一把大锁有锁链表——每个节点一把锁第一版首先对于一读一写的模型我们可以仅通过约束读指针和写指针的行为即可实现，并不需要接触并发模型。下面我们考虑多对多的模型，以Valois的论文Implementing Lock-Free Queues中的论述为例。1234567891011121314151617Initialize()&#123; head = new record(); head-&gt;next = NULL; tail = head;&#125;Enqueue(x) &#123; q = new record(); q-&gt;value = x; q-&gt;next = NULL; do &#123; p = tail; // 使用tail维护链表尾指针的位置 &#125; while( CAS(p-&gt;next, NULL, q) != true); // 1 CAS(tail, p, q); // 2&#125; 【Q】这里有一个疑问，就是为什么2这句不使用循环保护起来，以确保成功呢？这是因为这个语句是始终能够成功的。我们考虑： 线程T1成功进行了1处的CAS，它就会使得tail-&gt;next不为NULL 线程T2执行到1，那么它的CAS一定是失败的 这是因为tail还是老的值，但是tail-&gt;next已经被线程T1更新过，不是0了。这个过程一直到语句2之后tail被成功更新成q，因此实际上可以把tail-&gt;next看成一个锁一样的东西。 不过，这样我们就发现了一个违背锁无关性质的问题，也就是当线程T1在执行语句2时挂掉了，那就会阻塞所有其他在循环中的线程。 深入思考一下，原因在于两个CAS操作1和2并不是原子的，所以可能出现某个线程执行了1，但没有执行2的中间状态。换句话说，这个版本中语句p = tail中的tail并不一定是结尾。这也导致了为了维护离开循环时p必须指向结尾这个特性，线程需要在循环内自旋，从而导致上述的死锁现象的产生。于是我们想到，tail和next真的都是必要的么？事实上，即使我不记录tail，那么这个链表也是正确的啊。 为了解决问题，在这一版本中我们索性放宽假设，认为tail只是“接近”结尾，因此现在我们需要使用一个内层的while循环（指3处的while）来从tail开始尝试更新结尾，此时tail存在的目的是为了减少我们next的数量。因此我们提出下面的改良版，不过在此之前，需要再研究下Dequeue的实现。 下面是Dequeue的实现，我们需要额外考虑两种情况下和Enqueue会不会产生冲突： 链表中只有一个元素 那么head和tail指向的就会是同一个节点。为了解决这个问题，我们增加一个dummy节点作为head，并且每次弹出head-&gt;next而不是head。 这样，Enqueue的时候不需要访问head，Dequeue的时候，不需要访问tail。 链表为空 此时，head和tail应当指向同一个节点。但这种实现有可能会破坏这个性质。考虑下面的图，我们假设T1在做Dequeue，正准备执行位于1处的判断。此时T2正在执行Enqueue插入节点A，并且刚执行完1处的CAS，此时p-&gt;next不为NULL了。回归到T1，此时1处的判断不成立，Dequeue就会把Enqueue新生成的节点取走。而等线程切换回来，T1还在傻傻地设置tail。Scott等人的论文中提到，这种方案会阻碍对Dequeued节点的释放。 12345678910DeQueue() &#123; do&#123; p = head; // 判断是不是空节点 if (p-&gt;next == NULL)&#123; // 1 return ERR_EMPTY_QUEUE; &#125; &#125; while( CAS(head, p, p-&gt;next) != TRUE ); return p-&gt;next-&gt;value;&#125; 改良版1123456789101112131415EnQueue(x)&#123; q = new record(); q-&gt;value = x; q-&gt;next = NULL; p = tail; oldp = tail; do &#123; while (p-&gt;next != NULL) // 3 p = p-&gt;next; &#125; while( CAS(p-&gt;next, NULL, q) != TRUE); // 1 CAS(tail, oldp, q); // 2&#125; 观察改良版代码，即使T1线程挂在语句2，没能更新完tail指针，线程T2也可以自动跟踪到T1在1处的修改。此时我们也不要担心语句2的失败问题，因为有的时候它应该失败。考虑下面的执行顺序： 原先链表中只有一个元素1 此时线程T1添加了一个元素2，并且成功执行语句1，将p指向了元素2的位置 此时发生了调度，线程T2获得处理器，它需要在队列中加一个元素3 T2在刚进入循环时它发现自己的tail是指向1的，这是因为此时T1还没有更新tail指针。 但T2在内层的while循环中根据p的next指针走到了刚被T1添加进去的元素2处。因此T2在元素2的末尾增加了元素3，并且更新自己的p指向元素3。 T2继续执行语句2，此时tail == oldp指向元素1，所以CAS成功，tail指向了元素3。 现在，T1重新获得了处理器，此时tail已经被T2修改到指向元素3了，于是不能匹配oldp，这个CAS就会失败，因为它试图更新一个较旧的值。 容易看到这个失败不会影响tail指向精确的队列结尾。但是如果我们稍稍修改下上面的运行顺序，按照T1添加元素2 =&gt; T2添加元素3 =&gt; T1修改tail =&gt; T2修改tail(失败)来执行，那么我们就会发现tail被更新到指向元素2而不是元素3。所以我们看到先前我们放宽的假设是非常有必要的，在论文中作者指出这种情况下tail指针距离列表的准确结束位置最多相差2 * p - 1个节点。其实这个“最多”还是有点多的，所以在实践中我们常常结合两种方案来使用。 改良版2Michael和Scott在1996年提出了另一种无锁队列的实现方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546initialize(Q: pointer to queue t)node = new node() # Allocate a free nodenode–&gt;next.ptr = NULL # Make it the only node in the linked listQ–&gt;Head = Q–&gt;Tail = node # Both Head and Tail point to itenqueue(Q: pointer to queue t, value: data type)E1: node = new node() # Allocate a new node from the free listE2: node–&gt;value = value # Copy enqueued value into nodeE3: node–&gt;next.ptr = NULL # Set next pointer of node to NULLE4: loop # Keep trying until Enqueue is doneE5: tail = Q–&gt;Tail # Read Tail.ptr and Tail.count togetherE6: next = tail.ptr–&gt;next # Read next ptr and count fields togetherE7: if tail == Q–&gt;Tail # Are tail and next consistent? 如果此时Tail还是最新的。E8: if next.ptr == NULL # Was Tail pointing to the last node? 如果此时next还是最后一个节点E9: if CAS(&amp;tail.ptr–&gt;next, next, &lt;node, next.count+1&gt;) # Try to link node at the end of the linked listE10: break # Enqueue is done. Exit loopE11: endifE12: else # Tail was not pointing to the last node。此时Tail不再是最后一个节点了，我们需要重新更新一下TailE13: CAS(&amp;Q–&gt;Tail, tail, &lt;next.ptr, tail.count+1&gt;) # Try to swing Tail to the next nodeE14: endifE15: endifE16: endloopE17: CAS(&amp;Q–&gt;Tail, tail, &lt;node, tail.count+1&gt;) # Enqueue is done. Try to swing Tail to the inserted nodedequeue(Q: pointer to queue t, pvalue: pointer to data type): booleanD1: loop # Keep trying until Dequeue is doneD2: head = Q–&gt;Head # Read HeadD3: tail = Q–&gt;Tail # Read TailD4: next = head–&gt;next # Read Head.ptr–&gt;nextD5: if head == Q–&gt;Head # Are head, tail, and next consistent?如果Head不是最新的，说明有人Dequeue了D6: if head.ptr == tail.ptr # Is queue empty or Tail falling behind?检查是不是空，或者是Tail落后了(Valois算法的一个问题)D7: if next.ptr == NULL # Is queue empty?D8: return FALSE # Queue is empty, couldn’t dequeueD9: endifD10: CAS(&amp;Q–&gt;Tail, tail, &lt;next.ptr, tail.count+1&gt;) # Tail is falling behind. Try to advance it。如果落后了，就用next.ptr更新Q-&gt;TailD11: else # No need to deal with Tail # Read value before CAS, otherwise another dequeue might free the next nodeD12: *pvalue = next.ptr–&gt;valueD13: if CAS(&amp;Q–&gt;Head, head, &lt;next.ptr, head.count+1&gt;) # Try to swing Head to the next nodeD14: break # Dequeue is done. Exit loopD15: endifD16: endifD17: endifD18: endloopD19: free(head.ptr) # It is safe now to free the old dummy nodeD20: return TRUE # Queue was not empty, dequeue succeeded 需要注意根据爆栈网上的某个问题，这里的free不能是通常意义上的Free。事实上，无锁算法中释放内存的难点在于当线程释放了一块内存后，是无法获知是否有别的线程也同时持有该块内存的指针并需要访问。 我们将证明上面这个算法是Non-Blocking的，主要思路是证明如果循环判断条件触发了超过一次，那么必然有另外一个进程完成了操作，那么整体来说，整个算法就是一直在往前运行的。首先我们考虑Enqueue情况： E7 如果E7不满足，说明Tail被另一个进程修改了。因为Tail永远指向最后一个，或者倒数第二个节点，所以如果E7失败超过1次，那么另一个进程一定成功完成了一次Enqueue。 E8 如果E8失败，说明Tail此时正指向倒数第二个节点。那么在E13的交换后，Tail就会指向链表中最后一个节点，除非另一个进程又Enqueue了一个。因此，如果E8又失败了一次，说明另一个进程一定成功完成了一次Enqueue。 E9 下面是Dequeue情况： D5 如果D5不满足，说明Head被修改过了，而Head只有在被成功Dequeue（E13）的时候才会被修改。 D6 如果D6满足，并且此时链表是不空的，说明此时Tail正指向倒数第二个节点，也就是正数第一个节点。那么在D10之后，Tail一定指向最后一个节点了，除非此时又有一个进程完成一次Enqueue操作(并且同一个或者另一个进程又Dequeue了一个item)。 CPU提供的原子操作如果细究上面WINAPI的InterlockedCompareExchange，容易猜到它的实现方式来自于CPU的硬件支持，因为它只能为特定数据类型提供服务。事实上，这里用了x86中的cmpxchg命令。CPU原子操作的实现借助于总线锁、缓存锁等机制。 C++的原子操作库在上面的章节中，我们概览了锁无关编程的一些思想。从现在开始，我们将讨论C++11标准库提供的原子操作支持。 std::atomic_flagstd::atomic_flag是C++11原子库的一个基础设施，它被广泛地运用到下面的std::atomic类模板的实现中。std::atomic_flag基于TAS(test-and-set)操作维护了一个布尔量flag，提供了test_and_set和clear两个方法，可以保证对flag的写不会冲突，读不会脏读。test_and_set尝试将flag从false设为true，该函数返回的是flag先前的值。由于std::atomic_flag原子地维护了一个flag，它常被用来实现自旋锁。下面的代码来自MSVC的atomic库，它在std::atomic的_Atomic_copy方法中被调用。123456789101112inline void _Lock_spin_lock( volatile _Atomic_flag_t *_Flag) &#123; while (_ATOMIC_FLAG_TEST_AND_SET(_Flag, memory_order_acquire)) _YIELD_PROCESSOR; &#125;inline void _Unlock_spin_lock( volatile _Atomic_flag_t *_Flag) &#123; _ATOMIC_FLAG_CLEAR(_Flag, memory_order_release); &#125; 此外，容易发现TAS操作也可以通过CAS实现，其代码很简单1return InterlockedCompareExchange(&amp;flag, true, false); 在MSVC的标准库实现中test_and_set借助了Interlock互锁访问函数，保证了访问的原子性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 #if defined(_M_ARM) || defined(_M_ARM64) #define _INTRIN_RELAXED(x) _CONCAT(x, _nf) #define _INTRIN_ACQUIRE(x) _CONCAT(x, _acq) #define _INTRIN_RELEASE(x) _CONCAT(x, _rel) #define _INTRIN_SEQ_CST(x) x #else /* defined(_M_ARM) || defined(_M_ARM64) */ #define _INTRIN_RELAXED(x) x #define _INTRIN_ACQUIRE(x) x #define _INTRIN_RELEASE(x) x #define _INTRIN_SEQ_CST(x) x #endif /* defined(_M_ARM) || defined(_M_ARM64) */inline int _Atomic_flag_test_and_set(volatile _Atomic_flag_t *_Flag, memory_order _Order) &#123; /* atomically test flag and set to true */ switch (_Order) &#123; case memory_order_relaxed: return (_INTRIN_RELAXED(_interlockedbittestandset)(_Flag, 0)); case memory_order_consume: case memory_order_acquire: return (_INTRIN_ACQUIRE(_interlockedbittestandset)(_Flag, 0)); case memory_order_release: return (_INTRIN_RELEASE(_interlockedbittestandset)(_Flag, 0)); case memory_order_acq_rel: case memory_order_seq_cst: return (_INTRIN_SEQ_CST(_interlockedbittestandset)(_Flag, 0)); default: _INVALID_MEMORY_ORDER; return (0); &#125; &#125;inline void _Atomic_flag_clear(volatile _Atomic_flag_t *_Flag, memory_order _Order) &#123; /* atomically clear flag */ static_assert(sizeof(_Atomic_flag_t) == sizeof(_Uint4_t), "Unexpected _Atomic_flag_t size"); switch (_Order) &#123; case memory_order_relaxed: case memory_order_release: case memory_order_seq_cst: _Atomic_store_4((volatile _Uint4_t *)_Flag, 0, _Order); break; default: _INVALID_MEMORY_ORDER; break; &#125; &#125; std::atomic在前面的讨论中我们已经明白C++中的基本类型并不保证是原子的，所以std::atomic&lt;T&gt;定义了一系列具有原子行为的类型。std::atomic禁用了复制构造函数和复制赋值运算符，相当于不允许复制语义。同时，atomic也是不允许移动的。这是由于这两个操作发生在两个对象间，势必要破坏原子性，而一个std::atomic的所有操作都是原子的。对于用户自定义类型(UDT)typename T，std::atomic的主模板要求T满足standard layout、trivial default constructor和trivial destructor，即编译器可以使用memcpy等进行bitwise的复制并使用memcmp进行bitwise的比较。在CAS操作的实现中调用了memcpy和memcmp。这看起来限制很大，我们希望有用户自定义的复制构造函数，这样我们就可以进行member-wise的操作了，对此想法，C++ Concurrency in Action一书中指出，如果有自定义的复制构造函数，那么就势必要将锁定区域（下文中会交待其实std::atomic的主模板实现中可能会有自旋锁）内的数据交给这些用户代码，如果在用户代码中再使用了锁，就可能产生死锁的现象。容易发现这样一来，std::atomic&lt;T&gt;里面能放的东西，有很多限制。例如，我们常用的智能指针std::shared_ptr并不能被放到std::atomic里面，但是我们又确实有这个需要，因此标准库通过重载std::atomic_系列函数为std::shared_ptr提供了原子操作的支持。而对于std::atomic类型，我们既可以通过std::atomic_系列函数，也可以通过std::atomic模板中提供了compare_exchange_weak、compare_exchange_strong、load、store等操作。一般标准库会对一些大小满足能够直接使用某些处理器的原子指令的类型进行特化，例如指针类型、integral类型和一些用户定义类型。对于指针类型，std::atomic会进行偏特化。原子的指针运算可以通过fetch_开头的函数和相应的operator运算符来实现。对integeral类型std::atomic类模板也会进行特化，其实现类似指针类型，并且添加了对位运算的支持。对于“复杂”的整型计算如乘法，虽然atomic未提供，但可以通过compare_exchange_weak等函数间接实现。从C++20开始，std::atomic类模板提供对浮点类型的特化。注意在这之前，compare_exchange_strong等CAS方法对浮点数可能出现问题，原因显而易见是memcmp的锅，C++浮点数之间比较时甚至都不能使用==，遑论memcmp。在上文中提到，除了std::atomic_flag，std::atomic&lt;typename T&gt;类模板都是不保证不使用锁的（情况特定于处理器和标准库实现），用户可通过bool is_lock_free()函数判断是否Lockfree的。以PJ Plauger的实现为例，主模板的load()内部就使用了上文提到的用std::atomic_flag实现的自旋锁。1234567inline void _Atomic_copy(volatile _Atomic_flag_t *_Flag, size_t _Size, volatile void *_Tgt, volatile const void *_Src, memory_order _Order)&#123; _Lock_spin_lock(_Flag); _CSTD memcpy((void *)_Tgt, (void *)_Src, _Size); _Unlock_spin_lock(_Flag);&#125; 这里要提一句，主模板的template&lt;class _Ty&gt; struct atomic的实现继承了_Atomic_base&lt;_Ty, sizeof (_Ty)&gt;。这个_Atomic_base&lt;_Ty, sizeof (_Ty)&gt;模板又继承了_Atomic_impl&lt;_Bytes&gt;模板，其作用相当于把_Atomic_impl&lt;_Bytes&gt;中全void *的东西封装回了_Ty。我们查看最核心的_Atomic_impl&lt;_Bytes&gt;模板，它是和数据字节数相关的，分别对1/2/4/8字节的进行了偏特化。模板里面定义了最重要的_Is_lock_free、_Store、_Load、_Exchange、_Compare_exchange_weak、_Compare_exchange_strong等操作，全部是void*的。我们刚才看到的_Atomic_copy来自于主模板。我们下面看看_Atomic_impl&lt;_Bytes&gt;的偏特化版本，如对于一个uint2_t是如何实现的1234567891011121314151617181920212223242526272829303132333435363738394041424344 #define _Compiler_barrier() _ReadWriteBarrier() #if defined(_M_ARM) #define _Memory_barrier() __dmb(_ARM_BARRIER_ISH) #endif /* defined(_M_ARM) */ #if defined(_M_ARM64) #define _Memory_barrier() __dmb(_ARM64_BARRIER_ISH) #endif /* defined(_M_ARM64) * /* _Atomic_load_2 */inline _Uint2_t _Load_seq_cst_2(volatile _Uint2_t *_Tgt) &#123; _Uint2_t _Value; #if defined(_M_ARM) || defined(_M_ARM64) _Value = __iso_volatile_load16((volatile short *)_Tgt); _Memory_barrier(); #else _Value = *_Tgt; _Compiler_barrier(); #endif return (_Value); &#125;inline _Uint2_t _Load_relaxed_2(volatile _Uint2_t *_Tgt) &#123; _Uint2_t _Value; #if defined(_M_ARM) || defined(_M_ARM64) _Value = __iso_volatile_load16((volatile short *)_Tgt); #else _Value = *_Tgt; #endif return (_Value); &#125;inline _Uint2_t _Load_acquire_2(volatile _Uint2_t *_Tgt) &#123; return (_Load_seq_cst_2(_Tgt)); &#125; 可以发现在这个偏特化版本的实现中直接借助了处理器提供的设施，而避免了自旋锁的使用。 weak和strong版本的CAS类似与Windows API的互锁访问函数，atomic库通过bool atomic::compare_exchange_weak(old, value)和bool atomic::compare_exchange_strong(old, value)提供了对CAS操作的支持。这两个函数监测该std::atomic中维护的std::atomic_flag _My_flag（在_Atomic_impl模板中定义）的值，如果等于old就改为value，函数返回一个表示修改是否成功的bool量。因此容易发现这两个函数不总是成功的，因为CPU可能仅对某些类型提供了相应的CAS原子指令，对于其他的类型则必须通过使用自旋锁甚至内核锁来实现。12345678910111213inline int _Atomic_compare_exchange_weak(volatile _Atomic_flag_t *_Flag, size_t _Size, volatile void *_Tgt, volatile void *_Exp, const volatile void *_Src, memory_order _Order1, memory_order _Order2)&#123; /* atomically compare and exchange with memory ordering */ int _Result; _Lock_spin_lock(_Flag); _Result = _CSTD memcmp((const void *)_Tgt, (const void *)_Exp, _Size) == 0; if (_Result != 0) _CSTD memcpy((void *)_Tgt, (void *)_Src, _Size); else _CSTD memcpy((void *)_Exp, (void *)_Tgt, _Size); _Unlock_spin_lock(_Flag); return (_Result);&#125; 这两个函数有一些细致的区别，compare_exchange_weak在可能会False Negative，这是由于weak允许spurious failure。在某些平台（不错ARM、PowerPC又被点名了）上的CAS是通过LL/SC实现的，而不像x86上那样只通过一条指令，所以可能存在问题。因此使用compare_exchange_weak的时候需要一个循环。注意到这个!expected不是必要的。123bool expected=false;extern atomic&lt;bool&gt; b; // set somewhere elsewhile(!b.compare_exchange_weak(expected,true) &amp;&amp; !expected); 在Stackoverflow上相关问题的整理中提到了这两者之间的性能比较，由于weak会忽视检查，所以一般weak比strong快。但是如果使用strong能避免weak+loop，那么选择strong是适合的。注意到即使使用strong，loop也不是就一定可以避免的，因为原子操作本来就存在使用乐观锁的情况。 ABA问题伴随着CAS的是可能存在的ABA问题。ABA问题的根源是从内存中取出值和CAS这两个操作不是原子的，因此可能在这两个过程中发生切换。ABA问题的根源是我们使用CAS操作时，希望是和某个时刻的状态来Compare的，但是在实现上，我们却只比较两个状态的值是否相等，而忽略了时刻。初看ABA问题，会觉得这也是个问题？我最终一致就行了，管它中途发生什么呢。但实际上ABA描述的是一个“浅层的”的比较，例如以栈A -&gt; B -&gt; C为例，很可能一个线程在试图pop栈顶A的时候被调度走，新的线程先弹出A再弹出B再压入A。这时候老线程被调度回来，发现栈顶还是A，就会认为栈没有发生变化，还是A -&gt; B -&gt; C，但实际上栈已经变成了A -&gt; C了。123456789def pop(): cur = top next = cur.next old = cur # 此时第一个线程被调度了 while (old != CAS(top, cur, next)): old = cur next = cur.next return cur 刚才的例子是对一个栈来说的，A/B/C是不同的数据对象，有的人可以说，我们比较栈里面的全部元素不就行了？在下面的一个例子中可以看到，即使对于相同的对象，也是会产生问题的。12345X is $100.Thread 1. If X is $100, A will sub $50 from XThread 2. If X is $100, B will sub $50 from XThread 3. If X is $50, C add $50 to X 我们考虑下面的执行顺序，Thread 2会Fail掉，最后X还是100。121 - 2 - 32 will fail, and X will end up with $100 但是对于下面的执行顺序，121 - 3 - 2X will end up with $50 可以看出，这其实还是一个逻辑上的问题：对于前者来说，Thread 1和Thread 2可以理解为发送了重复的请求；对于后者来说，可以理解为Thread 2是一个新的请求，只是恰巧和Thread 1的判断条件相等。一般来说，我们认为三个线程的任务是在同一个时间戳下面开始执行的，并且我们认为是原子的。 ABA问题的解决可以通过引入序列号或者HazardPointer来解决。 基于序列号解决ABA问题基于HazardPointer解决ABA问题原子操作与锁的关系在上面的讨论中，我们能够直观地发现原子操作和锁的关系。原子操作看起来是“独善其身”的只能管住自己，原子操作之间、原子操作和非原子操作之间可能发生乱序或重排；而锁像大哥，能护住一段代码。由此我们思考如何通过原子操作来组织其他的那些非原子操作呢？这就要引入下面讨论的内存模型的问题。 其他的同步原语在上面的几个章节中，我们论述了基于锁和基于原子操作的同步原语。还有一些其他的同步原语，例如RCU、MCS Lock等。 Hazard PointerHazard Pointer类似于面向多线程的智能指针，它能够无等待地进行线程安全的垃圾回收。我们维护一个全局数组HP hp[N]，其中N表示线程的数量，因此HP看上去是ThreadLocal的。但实际上HP也不是ThreadLocal的，因为虽然每个线程只能写自己的HP，但是却可以读所有其他线程的HP。当我们需要访问某个指针时，我们就将这个指针赋值给自己的HP，也就是通知别人不要释放这个指针。【Q】如果我们同时访问多个指针呢？其实也是可以扩展的，因为HazardPointer的思维通常是在无锁队列中出现，而在处理无锁队列时，最多也就操作一个节点的指针。每个线程维护一个私有链表，当该线程准备释放一个指针时，把该指针放入自己的链表中，当链表数目达到一个设定数目R后，释放这个链表里面的全部指针。当一个线程要释放某个指时，它需要检查全局的HP数组，确定如果没有任何一个线程的HP值与当前指针相同，则释放之，否则不释放，仍旧把该指针放回自己的链表中。 RCURCU(Read Copy Update)是Linux2.6引入的一种替代读写锁的方法，在Linux内核中被广泛使用。其思想是在多个读者能和一个写者并行，写者在访问值时首先拷贝一个副本，对副本进行修改，再在适当的时候将新的数据一次性写回，这个时机就是所有读者完成读取之后。由此看出这种方法能够很好地适应读多写少的情况，因为现在读者端不需要任何锁来保证同步，也不会被写者阻塞。但是写者端的任务加重了，一方面它仍然要处理和其他写者的竞争问题，另一方面它具有复制开销，还需要监听所有读者的信号以确定数据的修改时间。下面描述了写操作的流程： 对旧数据建立一块副本，对副本进行修改 等待前面所有的读者完成读取 这时候RCU实际上向专门的垃圾回收器注册一个callback并等待器通知，这段时间称为grace period。 写者将原来的数据替换为新的数据 写者删除旧的数据 MCS LockMCS Lock是一种高性能的自旋锁，通过保存执行线程申请锁的顺序信息解决了传统自旋锁的“不公平”问题。MCS Lock具有Owner和Next两个域，初始值都为0。当内核线程申请锁时，会return Next++值作为自己的Ticket Number。如果返回的Ticket Number等于申请时的Owner，则直接获得锁，否则该线程就进行忙等。 普通的MCS Lock要求线程自旋在同一个共享变量上，因此涉及对该共享变量的频繁修改，这给诸如NUMA架构的系统会导致缓存失效的问题。因此有了MCS Spinlock这个基于链表的数据结构。MCS Spinlock维护多个被组织为链表的自旋变量waiting，其初始值为1。每个节点的申请者都自旋在waiting上等待其prev释放锁，当waiting变为0时结束自旋。 通过内存模型约束线程对变量的读写顺序锁无关编程的难点之一就是需要从编译器与CPU两个层面考虑行为对线程间的同步造成的的影响，也就是考虑编译器重排和CPU缓存与乱序对读写逻辑可能造成的影响。当我们试图使用原子操作去解决非原子操作间的竞态问题时，那么我们需要谨慎选择使用恰当的内存模型，这样能够在提升效率的同时保证安全性。当线程释放锁后，会从忙等中退出。 原子操作的线程间顺序我们知道从C++语言到运行程序得到结果之间需要经历编译器优化和处理器优化两道坎，处理器优化包括高速缓存和指令乱序，编译器优化可能进行重排。编译器和处理器达成的协议是不能改变单线程程序的行为。以编译器优化为例，下面展示的代码在O0下，g++7按照1-2的原始顺序来编译，但开启O1后，g++7就会进行Store-Store重排，将2提到1前面，先对b赋值，再对a赋值；并且还去除了一部分没用的代码。对单线程来说，这样的优化并没有任何问题。但对于多线程来说则可能出现问题。一方面，由于去除部分代码的原因，汇编O1事实上不能在a处观察到a == 1 &amp;&amp; b == 1的情况，而假设O0汇编在进行到b处被抢占，那么其他的线程有机会看到以上的情况。另一方面，在O1中先对b赋值再对a赋值，仍然会出现问题。假如说在3和4间线程被强占，那么另外一个线程观察a和b，得到b为123，而a为不确定值（或者1，如果前面赋初值语句没有被删去的话），而如果编译器不进行重排，我们理想中的原始结果是a为43，b为不确定值。12345678910111213141516171819202122int main()&#123; int a = 1, b = 1; // 0 // a a = b + 42; // 1 // c b = 123; // 2 printf("%d %d", a, b); return 0;&#125;// compile with -O0 movl $1, -8(%rbp) movl $1, -4(%rbp) // b movl -4(%rbp), %eax addl $42, %eax movl %eax, -8(%rbp) movl $123, -4(%rbp) movl -4(%rbp), %edx movl -8(%rbp), %eax// compile with -O1 movl $123, %ecx // 3 movl $43, %edx // 4 出于性能方面的考虑，对多线程的程序而言并不存在和单线程一样的硬性要求。在使用原子操作等锁无关技术时，不能假设所有环境下程序最后行为一如我们希望代码所“暗示”一样。事实上编译器或处理器可以在不同线程间对不同变量间进行读写乱序，而这在多线程中会造成问题。例如在单线程中将对B的写提到对A的读前面是没有问题的，但是对多线程来说，这往往就会出现问题。虽然大部分时候我们不需要操心这个问题，这是因为一方面在使用mutex等内核锁时，内核帮我们做了相关工作，另一方面部分处理器（如x86）也提供了（近似，实际上是TSO）acquire/release的保障，并也可以通过一些指令命令编译器在某些地方减少优化，但这依然是一个客观存在的问题。 可见性和有序性可见性指一个线程对变量的写操作对其它线程后续的读操作可见，这里见的是结果。可见性要求CPU在对缓存行写操作后能够保证至少在某个时间点前必须写回内存，从而保证其他线程能读到最新的值。有序性指的是数据不相关变量在并发的情况下，实际执行的结果和单线程的执行结果和单线程的执行结果是一样的，不会因为重排/乱序的问题导致结果不可预知。 根据以上的定义，我们引入下面的两个概念：如果操作A先行发生(happen-before)于操作B，那么A造成的修改能够被B观察到。我们以知乎上举出的一个例子来理解，根据上面有关原子操作的线程间顺序的讨论，我们知道下面的代码在单线程条件下断言是始终成立的，即使语句1和2之间发生了重排。容易看出happen-before强调的是一个现象，C++保证在单线程中happen-before现象是始终成立的，不管后面编译器和CPU如何进行重排。123456int a, b;void foo() &#123; a = 42; // 1 b = a; // 2 assert(b == 42);&#125; 如果A同步发生(synchronizes-with)于B，那么某个线程中A的修改能够被另一个线程中的B观察到。它实际上是建立一种方法，使得一个时间点前内存的变化能够被其他线程看到。我们引用同样的来源的一个例子，由于重排的问题，在下面的代码中语句4的断言不一定成立（我们不考虑x86 CPU的TSO模型）。这就说明在Relax等无约束或者少约束的内存模型下，在多线程中试图通过某原子量来同步非原子量并不是可靠的。1234567891011121314int data;std::atomic_bool flag &#123; false &#125;;// Execute in thread Avoid producer() &#123; data = 42; // (1) flag.store(true, memory_order_relaxed); // (2)&#125;// Execute in thread Bvoid consume() &#123; while (!flag.load(memory_order_relaxed)); // (3) assert(data == 42); // (4)&#125; 内存一致性模型广义上的一致性模型包括Strict Consistency、Sequential Consistency、Causal Consistency、Processor Consistency、FIFO consistency、Cache Consistency、Slow Consistency、Release consistency、Entry Consistency、General Consistency、Local Consistency等。在std::atomic中提供了六种内存模型(memory order)来描述不同线程之间相同/不同数据的读写的顺序。 Sequential顺序一致性(sequential consistency, SC)是最强的模型，要求程序中的行为从任意角度来看，序列顺序都是一致的(have single total order)；这是在说这段多线程程序的行为和一段单线程程序的行为是一致的，类似于不是并行的并发。这个模型禁止了任何四种类型的读写重排，因此我们可以认为SC下每次读到的都是最新值。在C++ Concurrency in Action中举了一个例子，使用四个线程运行下面四个函数，断言无论如何z永远不可能为0。这说明了在read_x_then_y和read_y_then_x两个函数至少有一个能看到x和y同时被设为true。容易看出将1/2/3/4任意排序，那么上面的断言是显然的（注意到即使read_x_then_y在write_x前被调用也有while循环兜底）。但是如果(1 -&gt; 3)和(2 -&gt; 4)这两个步骤并行发生的话，上面断言就不成立了。12345678910111213141516171819202122std::atomic&lt;bool&gt; x = false, y = false;std::atomic&lt;int&gt; z = 0;void write_x()&#123; x.store(true,std::memory_order_seq_cst); // 1&#125;void write_y()&#123; y.store(true,std::memory_order_seq_cst); // 2&#125;void read_x_then_y()&#123; while(!x.load(std::memory_order_seq_cst)); // a if(y.load(std::memory_order_seq_cst)) // 3 ++z;&#125;void read_y_then_x()&#123; while(!y.load(std::memory_order_seq_cst)); // b if(x.load(std::memory_order_seq_cst)) // 4 ++z;&#125; Relaxed自由模型(Relaxed ordering)是最弱的模型，它对线程间的执行顺序不做任何synchronizes-with的假设，但同线程的变量仍然遵循happens-before假设，即它除了禁止重排单线程上对单个变量的访问顺序（关于是否是单个变量，后面还有讨论），并不作任何额外的事情。下面展示的一个C++11对应的自由模型std::memory_order_relaxed的例子，注意在后面的详述中可以看到，由于特定平台的一致性模型要强于自由模型，所以std::memory_order_relaxed只是保证强于等于自由模型。注意到这时候仍然保证了1先于2、3先于4，且3读到true，但是z就可能为0了。这是由于x和y是两个不同变量，自由模型不关注它们之间的关系。关注一下图5.4，我们发现这张图非常反直觉，例如4步骤还会返回false，这是出于什么机理呢？但是在这之前，先在x86下的MSVC2015上测试一下，发现z始终不为0，这是为什么呢？我在StackOverflow上提了个问题。回答首先指出std::memory_order_relaxed的副作用实际上是禁止编译器（注意区分编译器的重排行为和处理器的乱序行为）重排x和y的Store-Store，但是断言失败还可能由于CPU决定颠倒写x和写y的顺序（虽然一般不会进行这种乱序），或者CPU的缓存导致了x延迟写入内存。回答接着解释了为什么x86上不会assertion fail，这是因为x84提供了acquire/release语义，保证了当3是true时，在2前的对3后的可见。注意到这个并不违反x86对Store-Load可能的乱序，它实际上利用了Store-Store不会乱序的特性。回顾之前的最严格的顺序一致模型的要求是对于每个共享变量，Load-Load、Load-Store、Store-Load、Store-Store都不乱序。12345678910111213std::atomic&lt;bool&gt; x = false, y = false;std::atomic&lt;int&gt; z = 0;void write_x_then_y()&#123; x.store(true,std::memory_order_relaxed); // 1 y.store(true,std::memory_order_relaxed); // 2&#125;void read_y_then_x()&#123; while(!y.load(std::memory_order_relaxed)); // 3 if(x.load(std::memory_order_relaxed)) // 4 ++z;&#125; 但在cppreference上列出一个例子。指出在下面的代码中，A is sequenced-before B within thread 1 and C is sequenced before D within thread 2, nothing prevents D from appearing before A in the modification order of y, and B from appearing before C in the modification order of x。这个似乎和上面说的relaxed不会限制不同变量的访问顺序有冲突了。123456// Thread 1:r1 = y.load(std::memory_order_relaxed); // Ax.store(r1, std::memory_order_relaxed); // B// Thread 2:r2 = x.load(std::memory_order_relaxed); // C y.store(42, std::memory_order_relaxed); // D 对此，在SoF上也有相关提问。解释是sequenced before只适用于单线程中，但编译器和CPU都可能进行重排。另一个问题进一步做了阐释。 acquire/releaseacquire/release模型相对灵活一点，也是x86实现的语义。release可以理解为写操作，acquire可以理解为读操作。acquire fence要求其后面的RW不能与其前面的R重排，也就是RW不能重排到（原本在自己前面的）R前，例如R1 W2不能变成W2 R1，否则R1读到的就是脏值的。release fence要求其前面的RW不能和其后面的W重排，也就是RW不能重排到（原本在自己后面的）W后，例如R1 W2不能重排为W2 R1，否则R1又脏读。但是这两个模型即使组合起来也不能禁止其前面的W和后面的R重排。C++11使用剩下四个内存模型常数来实现这一机制，memory_order_release和memory_order_acquire表示B线程在使用memory_order_acquire读时，线程A在memory_order_release前的所有写操作都是可见的。而稍弱一点的memory_order_release和memory_order_consume只用来保证当前操作涉及到的对象的可见性。 Store-Load乱序问题在前面的讨论中提到了x86的Store-Load乱序问题，对于x86，Loads May Be Reordered with Earlier Stores to Different Locations，但对于相同地址则不会乱序。在这篇博文中记录了一个有关Store-Load乱序的实验。在实验中，X的写操作可能被延迟到Y的读操作之后，尽管我们插入了compiler barrier。这时候我们需要一个full/general memory barrier，也就是实现让它前面所有的Load/Store操作对它后面的Load/Store操作都是可见的，包括了止Store-Load类型的乱序。在同一篇博文中指出可以使用插入一个mfence，以实现full/general memory barrier。12345// gccasm volatile("mfence" ::: "memory")// c++11// https://stackoverflow.com/questions/25478029/does-atomic-thread-fencememory-order-seq-cst-have-the-semantics-of-a-full-memostd::atomic_thread_fence(std::memory_order_seq_cst) SoF上指出虽然atomic(seq_cst)和atomic(seq_cst)始终不会重排，但是在atomic(seq_cst)附近的non-atomic甚至是atomic(non-seq_cst)形式的STORE-LOAD都会被重排。例如在下面的代码中1和3的STORE-LOAD肯定不会被重排，但2和3的STORE-LOAD就可能被重排，所以一定要注意。1234std::atomic&lt;int&gt; a, b, c;a.store(2, std::memory_order_seq_cst); // 1: movl 2,[a]; mfence;c.store(4, std::memory_order_release); // 2: movl 4,[c];int tmp = b.load(std::memory_order_seq_cst); // 3: movl [b],[tmp]; 因此在x86上至少要对LOAD/STORE其中的一个加上MFENCE，或者用一个LOCK指令，而这也实现了类似memory_order_seq_cst的效果。在章节内存模型的实现中还有更多说明。下面的代码不一定是等价的12345678910atomic&lt;int&gt; x, yy.store(1, memory_order_relaxed); //(1)atomic_thread_fence(memory_order_seq_cst); //(2)x.load(memory_order_relaxed); //(3)atomic&lt;int&gt; x, y;y.store(1, memory_order_seq_cst); //(1)// Nothingx.load(memory_order_seq_cst); //(3) 语言和系统级别的fence及其实现常见的fence包括thread fence(memory/CPU barrier)和signal fence(compiler barrier)。 signal fencesignal fence类似下面的东西，参考Wikipedia。123456// gccasm volatile("" ::: "memory");// msvc__MACHINE(void _ReadWriteBarrier(void))// c++11std::atomic_signal_fence(memory_order_acq_rel) 对于gcc版本，asm、volatile、memory三个关键字的作用可以参考SoF上的回答，这里简单解释一下，实际上是用asm声明了一个空指令，但是后面的memoryclobber会告诉编译器这个空指令可能访问任意内存，因此编译器会防止这条指令前后的访存操作跨过这条指令进行重排。并且这条指令还会使得缓存失效，因此还有下面的方式来进行精细化的管理，例如下面的语句表示可能会读x写y。123WRITE(x)asm volatile(&quot;&quot;: &quot;=m&quot;(y) : &quot;m&quot;(x):) // memory fenceREAD(y) 对于MSVC版本，根据MSDN，_ReadWriteBarrier限制了编译器可能的重排。C++11标准库中的std::atomic_signal_fence在MSVC上也是利用Compiler Barrier实现的。一个signal fence的作用是 强制单线程和该线程上的异步中断之间的顺序性 强制单核上运行的多线程之间的顺序性 注意到在SMP架构下这一点难以保证，所以对于多线程程序往往需要更强的thread fence。 thread fencethread fence也就是所谓的内存屏障，我们可以使用下面的语句进行声明，此外，我们还可以声明一个单独的Store/Load Barrier。这里补充一下Store Barrier强制所有屏障前的store指令，都在屏障指令执行之前被执行，并把store缓冲区的数据都刷到主存。Load Barrier强制所有屏障后的load指令，都在屏障指令执行之后被执行，并且一直等到load缓冲区被该CPU读完才能执行之后的load指令。而一个full barrier兼而有之。12345678910// x86asm volatile("mfence":::"memory")// gcc__sync_synchronize// msvcMemoryBarrier()// c++11std::atomic_thread_fence(memory_order_seq_cst)// other methods_mm_mfence 我们需要注意的是内存屏障是相当耗时的操作，甚至还要超过原子操作，内存屏障还会干扰CPU的流水线，导致性能的降低。下面我们查看一下标准库atomic_thread_fence函数的实现12345678910111213141516171819202122// MSVCinline void _Atomic_thread_fence(memory_order _Order) &#123; /* force memory visibility and inhibit compiler reordering */ #if defined(_M_ARM) || defined(_M_ARM64) if (_Order != memory_order_relaxed) &#123; _Memory_barrier(); &#125; #else _Compiler_barrier(); if (_Order == memory_order_seq_cst) &#123; /* force visibility */ static _Uint4_t _Guard; _Atomic_exchange_4(&amp;_Guard, 0, memory_order_seq_cst); _Compiler_barrier(); &#125; #endif &#125;// GCCinline voidatomic_thread_fence(memory_order __m) noexcept&#123; __atomic_thread_fence(__m); &#125; 可以发现由于x86自带的acquire/release语义，除非是最强的memory_order_seq_cst，否则atomic_thread_fence等价于atomic_signal_fence。而memory_order_seq_cst下的thread fence的full barrier实现则比较奇特，仔细查看这个full barrier的实现这里为啥不直接插入一个MemoryBarrier()，而是利用了一个原子操作呢？我在爆栈网上问了这个问题。结论是_Atomic_exchange_4这个函数会自动生成一个XCHG，而这个指令是默认带LOCK的，是一个full memory barrier，类似于mfence。当然，后面老哥还提到了这个实现很傻逼，不如直接用mfence。32位的CPU上不支持mfence，但是老哥自己在godbolt验证了在64架构下的GCC9已经能编译出mfence了。进一步的，在这片文章中，答主列出了四种实现Seq的方法，并且指出GCC用了第一种，MSVC用了第二种，虽然有bug(2012版本)，所以MSVC在这块的实现确实是不需要借鉴的。 LOAD (without fence) and STORE + MFENCE LOAD (without fence) and LOCK XCHG MFENCE + LOAD and STORE (without fence) LOCK XADD ( 0 ) and STORE (without fence) 在Linux中，可以通过smp_mb这个宏代替mfence，它实际上是lock add指令，它的性能更好，当然mfence可能更强一点，例如它可以fence a subsequent non-temporal load from a WC-type memory region在Linux中，smp_store_mb实际上就是”xchg”指令。 内存模型的实现六种内存模型通过加入Compiler Barrier和Memory Barrier来实现。在SoF中指出acquire/release相当于在relax后面加一道栅栏，即下面的代码是等价的。但如果不显式加入fence的话，编译器可以视情况生成等价的更好的代码。而在x86等强内存模型架构cpu上，也不一定生成fence，例如单独的atomic_thread_fence(memory_order_acquire)就可以简化为nop。12345// 1a.load(memory_order_acquire)// 2a.load(memory_order_relaxed)atomic_thread_fence(memory_order_acquire) 而memory_order_seq_cst则需要额外的MFENCE或者LOCK，可参考上节所述。下面的代码是等价的12345678910if (var.load(std::memory_order_acquire) == 0)&#123; assert(a==123);&#125;if (var.load(std::memory_order_relaxed) == 0)&#123; std::atomic_thread_fence(std::memory_order_acquire); assert(a==123);&#125; 使用内存模型解决双重检查锁定模式(DCLP)存在的问题在之前的章节中，我们曾经提到过双重检查锁定模式中存在的问题，对此文章Double-Checked Locking is Fixed In C++11指出我们可以通过适当的内存屏障或者atomic store/load语义来解决。1234567891011121314151617std::atomic&lt;Singleton*&gt; Singleton::m_instance;std::mutex Singleton::m_mutex;Singleton* Singleton::getInstance() &#123; Singleton* tmp = m_instance.load(std::memory_order_relaxed); std::atomic_thread_fence(std::memory_order_acquire); if (tmp == nullptr) &#123; std::lock_guard&lt;std::mutex&gt; lock(m_mutex); tmp = m_instance.load(std::memory_order_relaxed); if (tmp == nullptr) &#123; tmp = new Singleton; std::atomic_thread_fence(std::memory_order_release); m_instance.store(tmp, std::memory_order_relaxed); &#125; &#125; return tmp;&#125; 123456789101112131415std::atomic&lt;Singleton*&gt; Singleton::m_instance;std::mutex Singleton::m_mutex;Singleton* Singleton::getInstance() &#123; Singleton* tmp = m_instance.load(); if (tmp == nullptr) &#123; std::lock_guard&lt;std::mutex&gt; lock(m_mutex); tmp = m_instance.load(); if (tmp == nullptr) &#123; tmp = new Singleton; m_instance.store(tmp); &#125; &#125; return tmp;&#125; 无等待无等待(Wait-Free)是比锁无关更高层面的并发。无等待指的是程序中的每个线程都可以一直运行下去而不阻塞。 实战读写共享对象来自yubai大佬的共享对象的并发读写。多个线程对下面这个对象进行读写。显然，这个超过了128bit，没法一次原子操作来搞定。123456struct GConf&#123; int64_t a; int64_t b; int64_t c;&#125;; 读写锁 容易读者和锁者互相阻塞。 COW 第一版 这个也介绍过，在更新的时候原子地swap指针。 一个要点是，旧的Version不能立刻被析构，而应该维护一个引用计数。 但我们很快想到，类似于实现单例的过程，取对象指针，以及根据指针读取该对象的引用计数并判断要不要swap这两个操作并不是原子的。 COW 第二版 一个简单的办法是将上面两个阶段用锁保护起来。这个锁是全局的。 COW 第三版 现在需要设计一个无锁的办法。 HazardPointer多线程并发模型在本章节中将讨论多线程编程中变量共享与消息传递机制。 条件变量Condition VariableCV和mutex锁lock_guard和unique_lock能够保证线程之间的互斥访问临界资源，但是不能控制这些访问的先后顺序。自然而然地可以想到可以用锁维护一个共享变量记录状态，以实现线程间同步的措施，例如在生产者/消费者模型中用它来描述产品数量。一个比较naive的方式是轮询(poll)，注意在实现时仍然是需要锁的，否则可能两个互相竞争的线程同时获得flag。1234567891011121314bool flag;std::mutex m;void wait_for_flag()&#123; std::unique_lock&lt;std::mutex&gt; lk(m); while(!flag) &#123; lk.unlock(); // 1 解锁互斥量 std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 2 休眠100ms lk.lock(); // 3 再锁互斥量 &#125; flag = false;&#125; 另一种更好的方法是利用条件变量，条件变量(condition variable)是利用共享的变量进行线程之间同步的一种机制。条件变量维护一个等待列表，相对于前面的轮询，条件变量应用了推的机制，当某一个线程所需要的条件不满足时，它会被阻塞。拥有锁的线程在退出临界区时使用notify_one/notify_all发出信号通知条件变量，条件变量会唤醒一个/所有正在等待的线程。使用条件变量等待事件通常是类似下面的形式，容易发现期间需要解锁，所以这里只能用unique_lock而不能用lock_guard。12345678910111213141516171819202122232425262728void wait_for_event()&#123; std::unique_lock&lt;std::mutex&gt; uni_lock(mtx); while (!condition) &#123; // 调用wait后发生的操作: // 1. 将线程挂到等待队列上 // 2. 释放锁(前面说过带着锁睡觉会死锁) // 3. 进入睡眠阻塞线程 cv.wait(uni_lock, []()&#123;return condition;&#125;); // wait until condition // wait返回时会重新获得锁 &#125;&#125;void signal_event()&#123; std::unique_lock&lt;std::mutex&gt; uni_lock(mtx); condition = true; cv.notify_one();&#125;void broadcast_event()&#123; std::unique_lock&lt;std::mutex&gt; uni_lock(mtx); // 在notify前需要在锁保护下修改condition condition = true; // 理论上notify的时候不一定要拥有锁，但是性能上可能差一点 // 原因是 https://stackoverflow.com/questions/4544234/calling-pthread-cond-signal-without-locking-mutex cv.notify_all();&#125; 下面我们回答两个问题： 为什么使用mutex的时候要CV 我认为这是因为从逻辑上来讲，CV提供了一种新的同步原语。如果我们使用mutex来进行同步，其实也是可以的。如下面代码所示，我们两个线程竞争一个mut，以类似轮询的方式来获得同步，不仅很耗资源，而且从逻辑上不够整齐。而CV把consumer的轮询变成了阻塞wait，以provider的通知notify来唤醒，节省了资源，从逻辑上也有了一个完整过程的抽象。 1234567891011def provider(mut): while 1: lock(mut) count++ unlock(mut)def consumer(mut): while 1: lock(mut) if count: count-- unlock(mut) 为什么使用CV的时候要mutex 首先我们看signal的源码，我们修改了维护的condition，然后notify。我们知道condition是一个临界变量，所以必须要用锁来保护。 另一个原因是cv.wait对应的一系列步骤必须要是原子的，否则会造成丢失signal的问题。例如当条件满足!condition时程序应当释放锁并阻塞在CV上进入睡眠，这个过程必须是原子的。我们考虑在释放锁之后另一个线程上的一个signal获得了锁，并发送了signal，但此时本线程上还没有来得及阻塞在CV上，这个信号就不能被本线程收到了。这一现象广泛出现在使用边缘触发(Edge triggered)机制的程序中，例如Linux的信号（Linux的信号属于一种边缘触发），pthread_cond_系列也是边缘触发。相对于水平触发，边缘触发只会唤醒已经等待在wait上的线程（可以参考Python的Condition条件变量的实现），因此可能出现丢失信号的问题。例如当notify操作早于wait操作时，这个notify就会丢失了。注意到上面的实现中，cv.notify_one和cv.notify_all函数始终是出现在修改condition之后的，这也是为了保证当睡眠线程在收到信号后能够及时观察到条件满足了。 CV是全局一份，还是是生产者和消费者各自创建，通过mutex关联 应该是全局一份，我们可以看Python的Condition条件变量的实现来了解这一点。 具体原因是wait和notify需要作用在条件变量，而不是mutex上。并且这个条件变量需要在内部维护所有的waiter。 关于使用CV时使用锁的错误用法在陈硕大牛的博客中还指出了更多的例子，其优化点很多也是为了解决可能的丢失信号的问题。例如不为signal部分上锁是错误的，因为可能在wait部分在检测到condition不满足准备pthread_cond_wait睡眠前，另一个线程修改condition和pthread_cond_signal，这样进入pthread_cond_wait的wait部分代码就会丢失这次的signal，如下代码所示。所以我们在signal部分加锁的目的是为了确保自己现在可以signal。 Process A Process B pthread_mutex_lock(&amp;mutex); while (condition == FALSE) condition = TRUE; pthread_cond_signal(&amp;cond); pthread_cond_wait(&amp;cond, &amp;mutex); 不过即使为signal部分上锁还可能丢失信号。原因是生产者和消费者竞争同一把锁虽然能够保证wait和signal是串行的顺序，但可能整个signal过程都在wait过程前面。 虚假唤醒使用条件变量时可能发生虚假唤醒/伪唤醒(spurious wakeup)的问题，虚假唤醒指的是被wait中阻塞的线程在没有notify的情况下被唤醒，或者一次notify_one唤醒多个线程（惊群效应）。虚假唤醒可能发生在多处理器系统和接收Linux信号时，条件变量设计者出于性能因素容忍了虚假唤醒的存在。APUE指出pthread_cond_signal函数可能唤起多个线程。SoF中指出，当等待队列中的Linux线程收到一个系统信号时，会得到虚假唤醒。在另一个回答中，Jon Skeet大神指出其深层次原因是没有任何的保障是一个被唤醒(awakened)的线程一定会被调度(scheduled)，很可能当一个等待队列中的线程被唤醒后准备获得锁时，另一个线程已经捷足先登了获得了锁，并且重置了条件condition的值。但注意，即使是虚假唤醒的情况，cv.wait也是在获得锁之后再返回，但这时候条件condition可能已经不满足了，这时候就出现了虚假唤醒。解决虚假唤醒的方案很简单，如上文wait_for_event所示，可以将wait包裹在一个while循环里面。在SF上记录了一番实验，强行产生虚假唤醒。12345con_var.notify_one();// trigger the spurious wakeuplock.unlock();std::this_thread::sleep_for(std::chrono::seconds(2));condition = true; 可以发现在notify和unlock两个过程之后的两秒内消费者线程已经被唤醒了，但在拿到锁和条件变量后它发现其实condition值并不为true，这就产生了一次虚假唤醒。在使用notify_all()唤醒时需要注意惊群问题，如果我们只需要唤醒任意一个线程，那么notify_one()就行了，但是如果我们希望唤起特定的几个，或者我们不清楚需要唤醒几个，就得使用notify_all()唤醒全部。前者的情况类似于accept，当多个线程的套接口listen同一个fd时，内核只notify等待队列最顶部的套接口。后者的情况类似epoll，内核不知道究竟有多少个线程需要被唤醒。 惊群效应惊群效应是指多进程在wait的时候，如果notify all，那么会唤醒所有进程，但是最终却只有一个进程能够真的获得锁。惊群效应的影响是造成性能浪费，例如线程调度造成的上下文切换开销。一些解决惊群的方案包括： epoll Linux网络内核对accept的优化 信号量的实现在POSIX和Linux中分别提供了两种信号量的实现方式。其实我们也可以方便地通过mutex+cv+counter来实现信号量。 事件Windows内核编程中出现了事件，可以用来替代条件变量的使用。相比使用条件变量显式等待，事件机制将这个wait前置，将处理函数直接register给一个代理，当需要notify时，代理会直接调用这个处理函数。实际上事件机制更类似于对回调的一种封装，能够更好地实现模块化和组件化。事件机制减少了阻塞，因此能更好地服务于异步编程。事件和回调有什么区别？回调不一定是异步的。 基于线程的异步调用std::thread是实现并行最简单的方式了，不过在使用时我们要注意一下几点： 分清std::thread对象和实际线程 一个实际的例子是detach之后的std::thread对象销毁后线程并不会结束，反而是*this不在指向任何线程。 区分std::thread对象和线程实体 线程实体是由操作系统管理的，它不等同于std::thread对象。特别地，std::thread的生命周期是不同于线程实体的。当主线程退出时所有的子线程释放，或者当子线程执行完毕时子线程释放。而std::thread对象遵循所有C++对象的生命周期。 std::thread是由程序员管理生命周期的，程序员应当在join()或者detach()后释放std::thread。如果我们强行析构一个joinable的std::thread会导致异常terminate。 程序员可以通过std::thread控制线程实体，直到调用detach之后。一个简单的场景是std::thread::detach()之后，线程就和std::thread无关了，此时std::thread对象即使析构也无碍于线程实体。 试图从主线程fire掉子线程一个坏主意。如果我们希望某个线程的生命周期等同于某个对象，那么我们可以在该线程的loop里面去跟踪一个flag，这个flag可以是全局变量，也可以作为参数传入或者直接捕获。当对象需要析构时，我们设置这个flag使得线程内部的loop检测并最终退出，此时只要在析构函数中join这个线程即可。 注意线程带来的开销 因此我们需要线程池。 线程池线程池的产生是为了解决维护线程生命周期所带来的开销的问题，同时节约操作系统资源。一个线程池维护多个线程，当任务到来时在池中取出一个线程来执行这个任务。线程池可以动态地进行扩展。一般对于IO型的任务，我们维护线程池在2x或者2x+2的规模，而对于计算型的任务，盲目加线程是不正确的。甚至对于一些HT超线程的架构线程还要少一点会更好。具体是多少，我们需要profile来看。 std::thread实现是否应当实现poolingSoF上有相关的讨论 工作队列/任务队列注意这里并不是特指Linux中的特定数据结构，而是指一种通用的编程概念。工作队列(work queue)/任务队列(task queue)维护一组工作线程，调用者将异步任务注册到工作队列中，工作线程竞争运行这些异步任务。由此看到工作队列的实现依赖一个线程安全的队列，我们可以通过使用CV做一个简单的生产者消费者的模式来实现。使用工作队列需要注意的方面： 死锁/优先级反转 例如所有正在执行的任务都阻塞等待锁A，但持有锁A的任务却因为没有空余的线程而在队列中空等。 线程泄露 例如在异步任务中触发了异常，那么控制流就可能跳出loop循环，导致该线程无法参与到后面的计算任务中。 过载 概念比较 与线程池相比 线程池存在一些显著缺点，例如当主线程希望取得一个空闲进程执行异步任务，线程池中可用线程为空的时候，此时无论是扩展线程池加入新线程或者等待某一个线程执行完任务重新变为空闲，都会导致主线程的阻塞。而工作队列能够避免这样的问题。 与future相比 工作队列解决一系列的异步计算问题，相比future，工作队列需要额外考虑任务的调度、负载均衡等问题。在一定程度上它可以被视作future.then的迭代版。 基于future和shared_future的异步调用条件变量Condition Variable的一个重要的应用就是生产者/消费者模型，但对于一些平凡的情况，消费者只等待一次(one-off)来自生产者的结果。一个最简单的做法是启动一个计算线程（或者从线程池中取出一个线程）并异步获取它的结果，不过std::thread不能直接提供获取返回值的方法，此时可以考虑使用全局变量、传入指针、回调函数这些做法。容易发现这种方案是完全异步的。另一个较为方便的做法是使用future来获取异步任务中的结果。future是异步编程中一个非常通用的概念，在C++中被实现为std::future，在Python3中被实现为concurrent.future。std::future通常是下面提到的async、promise等异步机制返回给主线程的一个句柄。在启动这个异步任务后，当我们需要用到结果时，可以通过future::get()来获取。此时如果异步任务已经完成，则该函数立即返回，否则主线程会阻塞在future::get()上。这可以理解为主线程在等待异步线程的join。特别地，std::future也可以调用wait()、wait_for(const chrono::duration&lt;Rep,Period&gt;&amp; rel_time)等函数进行主动等待，这些函数会返回三种状态，future_status::ready表就绪，future_status::timeout表超时，future_status::deferred表示这个future对应一个deferred function，此时我们还没有执行这个异步任务，我们将在下节进行详细说明。需要注意的是，当多个线程访问std::future时，要锁来保护线程安全。不过我们应当尽量避免这种用法，因为C++中还提供了std::shared_future，相比std::future，它是可以复制的。这也意味着它的结果可以被多次get，而多个线程可以通过一个std::shared_future来跟踪异步任务的结果。需要注意的是，为了保证线程安全，我们需要对每个线程维护一份std::shared_future，而每个线程仅仅可以操作自己的一份。 async如下面代码所示，std::future常和std::async一并使用。容易看到，它类似于Python中的subprocess.call，是个高层面的封装。123456int main()&#123; std::future&lt;int&gt; the_answer = std::async(get_integer()); do_other_stuff(); std::cout&lt;&lt; the_answer.get() &lt;&lt; std::endl;&#125; 这里面的std::async用来实现一次异步调用。std::async是一个模板函数，它可以接受一个std::launch类型的参数，其中使用std::launch::defered表示异步调用是个deferred function，它将延迟到.wait()或.get()再执行。而std::launch::async表示在一个独立线程中运行。默认是std::launch::defered | std::launch::async表示这两个二选一。std::async能够接受函数指针、函数对象（的左值、右值。引用和std::ref），也能够通过类似std::bind一样的机制以引用、std::ref等方式传入对象的上下文。需要注意的是std::async不能被简单地当做std::thread来使用。例如我们可能不关注其返回值，但此时这个std::future的析构仍然会阻塞到异步操作结束。因此我们希望它将返回值通过回调的方式传出去的理想并不能实现（实际上这个可以通过future.then实现）。如下面代码所示：123// https://zh.cppreference.com/w/cpp/thread/asyncstd::async(std::launch::async, []&#123; f(); &#125;); // 临时量的析构函数等待 f()std::async(std::launch::async, []&#123; g(); &#125;); // f() 完成前不开始 SoF中也提到这是一个争议问题，但至少在C++11中，future的析构函数可能会阻塞线程。 优先使用async等机制替代裸线程相比裸线程，async隐藏了底层的细节，从而我们可以更关注于异步逻辑。例如它可以帮我们视情况使用线程池进行优化(pooling)等。此外，裸线程还存在回调地狱(callback hell)的缺点，使用async或者后面提到的future.then甚至co_wait等机制能够让代码更加平展。 packaged_task不同于std::async，std::packaged_task是个函数对象，这个函数对象有点类似std::function（但std::function还能够复制构造），因此std::packaged_task需要手动调用以运行。1234567std::packaged_task&lt;int()&gt; task(sleep);auto f = task.get_future();// 在主线程中运行task();// 启动另一个线程运行，注意只能移动packaged_taskstd::thread myThread(std::move(task));f.get(); 由于std::packaged_task能移动到某个std::thread中，因此适合用来实现线程池，负责打包待计算的任务。std::packaged_task还可以被用来向另一个线程派发任务。 promise在上面的两种派发任务-等待获取结果的模型中，我们的主线程是作为等待任务结果的一方，而将执行任务的异步线程则是产生结果的一方。std::future对象由调用者（一般是主线程）持有，调用者会调用std::async或者std::packaged_task等启动一个任务，并且在需要结果时调用f.get()获得异步线程的结果。对于异步线程来说，调用者对自己是透明的，只能通过执行完任务正常返回完成向调用者同步。但是这在promise中就不一样了，在使用std::promise时，异步线程需要显式向调用者设置值std::promise::set_value()或传递异常std::promise::set_exception()。因此promise实际上为被调用者提供一个显式向调用者同步的方法。被调用者显得更加主动，而且它现在可以返回一个异常。 future.then在先前介绍future时，我们认为其有一个美中不足就是最后总有一个同步的过程，也就是调用get时候的等待，而使用裸线程（池）有优势的一点就是我们可以通过回调更为灵活地控制我们的逻辑，但裸线程也有之前提到的回调地狱之类的缺点。能不能两相结合呢？SoF上也有类似的提问。实际上有一个提案称为future.then就是用来解决这个问题的。其风格类似于CPS和Haskell中的Monad，相比先前介绍的future/promise/packaged_task机制，future.then利用了回调链的机制避免了调用future::get()形成阻塞。相比std::future，future.then是完全的异步。future.then目前还没有进入C++标准，因此C++中目前还需要借助于线程池、事件或者IOCP的方式来实现异步。 co_await、co_yield、co_returnfuture.then机制降低了流程操控的复杂度，不过写起来仍然很繁琐，而且存在回调地狱的问题。在链式调用的过程中，整个流程难以在中间直接abort，为此Rust先后提出了try!和?.这样的机制。截至目前这三个函数尚未进入C++标准，但这种由C Sharp流行开来的异步编程范式其实十分优雅，我们将在一个单独的专题进行讨论。 多进程并发模型常见的并发模型有共享变量（内存）、Communicating Sequential Process(CSP)、Actor等模型。共享变量的模型中，多个线程通过锁或者原子操作对变量进行有序访问，在先前我们讨论了future等基于线程的共享内存的模型，它们在多线程环境中非常实用。共享变量模型强调利用共享内存进行通信，我们明显发现在future等模式中信息的交互是一次性的，即调用者在启动异步任务后很难再去操作异步任务，而异步任务更是看不到调用者。另一种思路是通过通信来共享内存，CSP和Actor模型选择后者，因此在多进程情况下会更得心应手。CSP模型可以参照Go语言中的Channel，Actor模型可以参照Mapreduce模型，他们都是通过消息来进行同步的。 Actor模型Actor模型围绕具名节点（称为Actor）展开，消息从一个Actor直接发送到另一个Actor，而并不需要通过诸如Channel的桥梁。特别地，Actor是与线程无关的，一个线程上可以存在多个Actor。更进一步地，Actor的消息传递也是异步的，消息的发送和接受可以在任意时间发生。Actor之间进行严格地隔离，实现所谓“Share nothing”的机制，每一个Actor只能同时处理一个消息，多余的消息会存放在Mailox里面。这样实际上消息的处理过程是独占的。 CSP模型相比Actor，CSP模型围绕一个中间桥梁（在这里使用Go语言中的具象也就是Channel来表示），不同的节点向对应的Channel获取或者发送消息，因此在耦合性上要比Actor模型松一点。相比Actor模型，CSP模型要求发送方在接收方准备好接受消息时才能发送消息，所以同步性要更强一点。以Go为例，Channel一般具有4个基本操作： 创建 c = make(chan int, buffer_size) 发送 c &lt;- 接受 &lt;- c 关闭 close(c) Channel的C++实现这篇文章中讲述了使用C++模拟Go中的Channel的一个方案。首先Channel一个最基础的功能就是收发消息，这个可以通过一个队列来实现。 并发编程中的基础架构在设计高性能的并发代码时，我们需要注意以下几点： 充分利用局部性假设，是同一线程中的数据紧密联系 减少线程上所需的数据量 让不同线程访问不同位置，避免伪共享，这里也是将内存分配对齐到缓存行大小的一个重要原因。 响应式(reactive)架构Reference https://coolshell.cn/articles/8239.html]]></content>
      <tags>
        <tag>C++</tag>
        <tag>多线程</tag>
        <tag>Linux</tag>
        <tag>并行计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[libutp源码简析]]></title>
    <url>%2F2017%2F12%2F05%2Flibutp%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[libutp是uTorrent使用的类似TCP的传输层实现。它基于UDP提供可信的、有序的点对点的传输，并具有最少的时延。需要注意的是utp和另一个基于UDP的传输协议QUIC的实现思路和优势并不一样，例如QUIC更强调连接建立的快速性，建立连接时只需要1至2次握手，又如QUIC将TLS整合到协议中，实现了0RTT，而基于HTTP2的协议需要2/3RTT。QUIC还允许在用户层面配置各种拥塞控制算法。网上有关libutp实现的介绍几乎没有，因此我打算就其源码做一个简单的分析。这里要注意UTP是基于包的而不像TCP是基于流的，虽然它提供的API还是基于流的。这样有一些影响，例如黏包问题的处理、缓冲区的管理（例如可以去掉PUSH标记）、窗口管理、重新分组等方面。 uTP源码简介utp.h以C89的形式提供接口。例如utp_write是以proactive的方式实现的。utp相关的实现大多在utp_internal.cpp文件中。utp_packedsockaddr.cpp中封装了sockaddr_in结构。ucat.c基于uTP框架构建了一个基础的应用。uTP的设计主要是异步的，应用代码不会阻塞在异步IO操作上，而是指定回调函数并立即返回。utp_callbacks.cpp中注册了各种回调函数，utp向外界传输消息都是以这里回调的形式开展的。例如当收到数据包时，ctx-&gt;callbacks[UTP_ON_READ]这个回调函数就会被调用。 使用回调函数也体现了libutp总体的设计思路： 回调函数能够屏蔽掉套接字API的细节 一个可靠通信协议的主要任务是在不可靠的设施上建立可靠的传输通道，至于使用哪一种不可靠的传输方式并不是核心问题。uTP协议的内部实现能够与UDP套接字等做到隔离，utp不是继承或者封装了UDP套接字描述符，然后提供一个TCP的鸭子类型。而是完全工作在UDP上层，打包了一些对UDP的操作，方便用户调用。 例如uTP就可以选择不实现sendto等方法，而用户选择使用send还是write还是sendmsg，然后写成回调，uTP只需要在它需要通过UDP发送它构造的数据报时调用这个回调就好了。又例如系统从UDP套接口收到一个消息时，它并不是直接处理，而是调用utp_process_udp函数。对于一个已连接的套接字，这个函数会找到对应的UTPSocket结构，并调用utp_process_incoming函数，该函数是个非常大的函数，里面uTP协议根据自己的报头处理了相关消息之后，调用用户设置的回调函数通知收到了消息。对于连接请求，我们将在下面的被动连接上详细讨论。 回调函数方便实现proactive和reactive风格的API常见的反射式(reactive)异步IO模型包括select、poll、kqueue、Java NIO等，只会通知到某IO设备上产生了IO事件，然后由用户来发起IO请求，例如调用read、recv等。前摄式(proactive)包括IOCP、Boost Asio等，用户主动发送IO请求（即使现在IO设备还没有准备好）并提前向系统注册一个回调函数，当实际的IO事件发生时由系统处理该IO操作，并在完成后触发指定的回调函数，因此前摄式能够避免用户将数据从内核取回来的开销。因此前摄式强调的是对未来读取事件的预期，抽象程度要高一点，用户可以利用Proactor的回调构造一条执行顺序链，而Reactor必须手动维护接受的状态。 回调函数能减少处理并发问题的难度 鉴于以上的这几点，在分析uTP协议时必须要将ucat.c纳入考虑范围，不然很难搞懂原理。 ucat简介ucat使用了poll来维护了两个fd，stdin和套接口，并且设置了500ms的超时时间。 uTP重要数据结构utp_context12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// utp.htypedef struct struct_utp_context utp_context;// utp_internal.hstruct struct_utp_context &#123; void *userdata; utp_callback_t* callbacks[UTP_ARRAY_SIZE]; uint64 current_ms; utp_context_stats context_stats; UTPSocket *last_utp_socket; Array&lt;UTPSocket*&gt; ack_sockets; Array&lt;RST_Info&gt; rst_info; UTPSocketHT *utp_sockets; size_t target_delay; size_t opt_sndbuf; size_t opt_rcvbuf; uint64 last_check; // utp_api.cpp struct_utp_context::struct_utp_context() : userdata(NULL), current_ms(0), last_utp_socket(NULL), log_normal(false), log_mtu(false), log_debug(false) &#123; memset(&amp;context_stats, 0, sizeof(context_stats)); memset(callbacks, 0, sizeof(callbacks)); target_delay = CCONTROL_TARGET; utp_sockets = new UTPSocketHT; callbacks[UTP_GET_UDP_MTU] = &amp;utp_default_get_udp_mtu; callbacks[UTP_GET_UDP_OVERHEAD] = &amp;utp_default_get_udp_overhead; callbacks[UTP_GET_MILLISECONDS] = &amp;utp_default_get_milliseconds; callbacks[UTP_GET_MICROSECONDS] = &amp;utp_default_get_microseconds; callbacks[UTP_GET_RANDOM] = &amp;utp_default_get_random; // 1 MB of receive buffer (i.e. max bandwidth delay product) // means that from a peer with 200 ms RTT, we cannot receive // faster than 5 MB/s // from a peer with 10 ms RTT, we cannot receive faster than // 100 MB/s. This is assumed to be good enough, since bandwidth // often is proportional to RTT anyway // when setting a download rate limit, all sockets should have // their receive buffer set much lower, to say 60 kiB or so opt_rcvbuf = opt_sndbuf = 1024 * 1024; last_check = 0; &#125; ~struct_utp_context()&#123; delete this-&gt;utp_sockets; &#125; void log(int level, utp_socket *socket, char const *fmt, ...); void log_unchecked(utp_socket *socket, char const *fmt, ...); bool would_log(int level); bool log_normal:1; // log normal events? bool log_mtu:1; // log MTU related events? bool log_debug:1; // log debugging events? (Must also compile with UTP_DEBUG_LOGGING defined)&#125;; utp_context的成员 utp_sockets utp_sockets指向一个UTPSocketHT : utpHashTable&lt;UTPSocketKey, UTPSocketKeyData&gt;哈希表。这个哈希表维护了所有的套接字： 在utp_sockets析构时调用UTP_FreeAll释放所有的套接字。 当UDP包被接受时，会调用utp_process_udp这个处理程序。此时我们仅能获得对应的套接字地址const struct sockaddr *，因此需要能够通过这个指针找到对应的套接字。 UTPSocketHT中的键UTPSocketKey和值UTPSocketKeyData的构造如下： 键UTPSocketKey中存放了对应UTPSocket中的PackedSockAddr addr以及recv_id字段。 PackedSockAddr addr字段是在utp_initialize_socket设置的，表示指向的目标地址。 recv_id对应着套接字里面的conn_id_recv字段，是在utp_initialize_socket中随机生成的。这里的recv_id的主要功能是作为ATP协议中“host端的端口号”来使用。查看相关代码我们可以发现conn_id_send始终比conn_id_recv要大1。 123456// utp_process_udputp_initialize_socket(conn, to, tolen, false, id, id+1, id);// void utp_initialize_socket(utp_socket *conn, const struct sockaddr *addr, socklen_t addrlen, bool need_seed_gen, uint32 conn_seed, uint32 conn_id_recv, uint32 conn_id_send)&#123;// ...conn_id_recv += conn_seed;conn_id_send += conn_seed; 下面讨论了几个重要的问题 为什么我们要使用id而不直接使用四元组呢？ 使用id能够方便地实现以下的机制（虽然libutp并不一定实现了） 使用三次握手和四次挥手的很高创建成本很高，使用ID能够复用已经创建好的连接。当然这样的复用可能带来队头阻塞问题，需要小心处理。 将连接概念独立于四元组概念，方便隔离底层，从而实现连接迁移。QUIC实现了这个特性。 为什么要有两个id呢？ 这是因为在同一个UDP port上会存在多个uTP连接，因此我们需要增设一个ID字段来区分这些连接。对于每一个套接口，uTP选择它的发送和接受都设置一个ID。当utp_process_udp接受到UDP包的时候，他获得的是一个sockaddr地址，所以需要找到对应的UTPSocket套接字，当套接字不存在时，需要发送RST包。当套接字关闭时，需要它来维护2MSL的等待时间，实际上由于UDP的UTPSocketKey包含了recv_id，所以2MSL是不必要的，在UTPSocket::check_timeouts代码中看到只等到rto_timeout就行。 为什么选择conn_id_recv而不是conn_id_send来作为哈希值呢？ 这是因为当数据报到达时，要通过里面的recv_id找到具有特定conn_id_recv的套接字。 值UTPSocketKeyData中主要持有了对应的UTPSocket *的指针。 opt_sndbuf和opt_rcvbuf 这两个size_t表示发送缓冲区和接收缓冲区的默认大小。缓冲区的大小与窗口大小形成协同。在创建套接字时，套接字的opt_sndbuf和opt_rcvbuf会“继承自”对应的context。 target_delay单位为微秒，初始值为CCONTROL_TARGET = 100 * 1000。 current_ms的作用是用来保存当前时间，这样可以避免多次调用获取时间函数的开销。 context_stats是一个utp_context_stats类型的结构，用来统计不同大小的uTP包的数量。 ack_sockets与schedule_ack机制有关，详见超时重传部分。 rst_info维护了RST_INFO_LIMIT个reset信息，详见连接重置部分。 utp_context的用途 方便集中管理的UTP套接口UTPSocket 从上面的结构中看到所有的UTPSocket被放到一个哈希表里面。当UTPSocket销毁时，要将哈希表中对应的&lt;UTPSocketKey, UTPSocketKeyData&gt;键值对删掉，在utp_initialize_socket函数中要往context里面注册自己，这些操作实际上都是为了方便集中管理套接字。 以utp_check_timeouts函数为例，这个函数作为每次“时钟中断”的入口，接受的是一个utp_context而不是一个UTPSocket，context里面对所有的UTPSocket调用了check_timeouts，这样避免了为每一个套接字维护一个时钟信号的开销。 方便实现UTP服务 libutp是工作在用户态的，所以并不能向外提供系统调用，因此每一个进程会维护一个utp_context。 utp_socket123456// utp.htypedef struct UTPSocket utp_socket;// utp_internal.cppstruct UTPSocket &#123; // ...&#125;; UTPSocket类型用来维护一个套接字的上下文，里面东西比较多，将在下面展开讨论。 OutgoingPacket对于一个（将要）被发出去的包，有一个OutgoingPacket与其对应。12345678struct OutgoingPacket&#123; size_t length; // 总长 size_t payload; // 有效载荷 uint64_t time_sent; // microseconds uint32_t transmissions; // 总传输次数 bool need_resend; char data[1];&#125;; 这里的data是个VLA（这里勘误一下，VLA是另外一个C99特性，实际上这里是一个Flex Array），实际上是包头+数据包的全部内容。注意到最好不要将包头和数据包分开存放，不然又要多一次复制的开销。 PacketFormatV1/PacketFormatAckV1首先查看基础的PacketFormatV1，这是一个uTP常规数据报的报头。1234567891011121314151617181920212223// utp_internal.cppstruct PACKED_ATTRIBUTE PacketFormatV1 &#123; // packet_type (4 high bits) // protocol version (4 low bits) byte ver_type; byte version() const &#123; return ver_type &amp; 0xf; &#125; byte type() const &#123; return ver_type &gt;&gt; 4; &#125; void set_version(byte v) &#123; ver_type = (ver_type &amp; 0xf0) | (v &amp; 0xf); &#125; void set_type(byte t) &#123; ver_type = (ver_type &amp; 0xf) | (t &lt;&lt; 4); &#125; // Type of the first extension header byte ext; // connection ID uint16_big connid; uint32_big tv_usec; uint32_big reply_micro; // receive window size in bytes uint32_big windowsize; // Sequence number uint16_big seq_nr; // Acknowledgment number uint16_big ack_nr;&#125;; ver_type ver_type标志了数据报的类型，这个类似于压缩了后的TCP报头中的flags字段，节约了一些空间，并且更加直观。包含下面的5种。 12345678enum &#123; ST_DATA = 0, // Data packet. ST_FIN = 1, // Finalize the connection. This is the last packet. ST_STATE = 2, // State packet. Used to transmit an ACK with no data. ST_RESET = 3, // Terminate connection forcefully. ST_SYN = 4, // Connect SYN ST_NUM_STATES, // used for bounds checking&#125;; 这里ST_STATE即一个不带数据的探查包，因此并不会增加seq_nr。 ext 这个表示扩展号，默认是0，设为1时表示使用了EACK的扩展，对应着扩展后的PacketFormatAckV1类型的数据包。 connid connid的用途已在前面的utp_context进行了论述。 tv_usec tv_usec是一个时间戳，表示数据包的发送时间，在send_data中被设置。我们看到相比TCP则保守地用了TCP Timestamps Option这个选项，UTP中强制将其整合了进来。其实时间戳的作用是非常大的，例如借助于时间戳可以更精确地计算出RTT。否则我们只能对非重传的数据包进行采样。时间戳还能方便我们对高带宽下序号迅速耗尽进行PAWS(Protect Againest Wrapped Sequence numbers)防范，不过我检查下代码发现UTP里面并没有PAWS的机制（详见后面收包的部分）。 reply_micro reply_micro在utp_process_incoming中被设置，当A发送数据包给B时，B提取收到数据包中的tv_usec字段并和自己的本地时间作差，得到更新的reply_micro。这个值会随着下一个数据包被传送给对端（send_data函数）。 这里再提一下PACKED_ATTRIBUTE这个属性，在utp_internal.cpp中已经使用了#pragma pack，这里是为了双重保险。12345678910111213141516// utp_internal.cpp#if (defined(__SVR4) &amp;&amp; defined(__sun)) #pragma pack(1)#else #pragma pack(push,1)#endif// utp_types.h// Allow libutp consumers or prerequisites to override PACKED_ATTRIBUTE#ifndef PACKED_ATTRIBUTE#if defined BROKEN_GCC_STRUCTURE_PACKING &amp;&amp; defined __GNUC__ // Used for gcc tool chains accepting but not supporting pragma pack // See http://gcc.gnu.org/onlinedocs/gcc/Type-Attributes.html #define PACKED_ATTRIBUTE __attribute__((__packed__))#else #define PACKED_ATTRIBUTE#endif // defined BROKEN_GCC_STRUCTURE_PACKING &amp;&amp; defined __GNUC__ PacketFormatAckV1这个包表示当这个包是EACK包时的附加数据，EACK包是类似于SACK的一种机制，用于选择性确认。在UTPSocket::send_ack函数中能看到EACK将acr_nr前最多32个报文的接受情况按位放到长度为4的字节数组里面，这是一个非常巧妙的方法。123456struct PACKED_ATTRIBUTE PacketFormatAckV1 &#123; PacketFormatV1 pf; byte ext_next; byte ext_len; byte acks[4];&#125;; SizableCircularBuffer这是一个环形缓冲区，值得注意的是这个缓冲区并不是线程安全的，不过libutp的接口不是线程安全的。12345678910111213141516171819202122232425struct SizableCircularBuffer &#123; // This is the mask. Since it's always a power of 2, adding 1 to this value will return the size. size_t mask; // This is the elements that the circular buffer points to void **elements; void *get(size_t i) const &#123; assert(elements); return elements ? elements[i &amp; mask] : NULL; &#125; void put(size_t i, void *data) &#123; assert(elements); elements[i&amp;mask] = data; &#125; void grow(size_t item, size_t index)&#123; // Figure out the new size. size_t size = mask + 1; do size *= 2; while (index &gt;= size); // Allocate the new buffer void **buf = (void**)calloc(size, sizeof(void*)); size--; // Copy elements from the old buffer to the new buffer for (size_t i = 0; i &lt;= mask; i++) &#123; buf[(item - index + i) &amp; size] = get(item - index + i); &#125; // Swap to the newly allocated buffer mask = size; free(elements); elements = buf; &#125; void ensure_size(size_t item, size_t index) &#123; if (index &gt; mask) grow(item, index); &#125; size_t size() &#123; return mask + 1; &#125;&#125;; 环形缓冲区的大小size始终是2的整数幂，这里的mask等于size - 1，因此全部为1。mask起到类似取模的作用。这里的ensure_size和grow的参数有点奇怪，其实查看调用情况可以发现item表示要插入的元素的编号，如seq_nr；而index表示当前队列中元素的个数，如cur_window_packets，这样队列就不会出现假溢出的现象。如果说队列中元素比容量size = mask + 1要多了，那么就要扩展队列。由于扩展队列变了模数，不同余了，所以要按照模前的数(item - index + i)进行复制。 环形缓冲区的增长grow需要提供item和index，两个变量可以分别理解为缓冲区中最旧的序号和最新的序号，其中item - index表示最老的未确认的ATPPacket的序号。对于缓冲区中的序号$seq$，有$seq \, mod \, m1 = x$，当mask从$m1$增长到$m2$时，需要求出在$seq$未知的情况下求出$seq \, mod \, m2 = y$。其实有个简单的开销较大的办法，就是用一个std::pair把原始的序号计算出来。 套接字的连接关闭与读写操作创建套接字utp_create_socket用来创建一个套接字，在创建套接字时并不向context进行注册，这也是因为目前已有信息无法计算出哈希值的缘故。state = CS_UNINITIALIZED 定位套接字在uTP中，当我们收到一个UDP数据包时会调用utp_process_udp函数通告context，context会根据端口和报头来定位到具体套接字。 主动连接实现在函数utp_connect内。 首先调用utp_initialize_socket utp_initialize_socket的作用初始化套接字，这里的操作包括设置dest端的地址/端口，初始化conn_id_recv和conn_id_send，初始化套接字的部分字段。向context注册自己。 在初始化之后，套接字具有状态state = CS_IDLE 然后调用UTPSocket::send_packet 这个函数详见下面 被动连接uTP对被动连接的处理在utp_process_udp函数中。首先context会判断是否接受连接，条件如下： 是否设置了UTP_ON_ACCEPT回调 是否已存在该连接 context中保持的连接数是否已超过3000 可以看出，uTP对连接的限制还是比较放松的，在TCP协议中还会对在连接队列中（三次握手尚未完成）的套接口有限制，即listen的backlog参数。事实上协议实现会分别维护连接中的队列so_q0和已连接的队列so_q，并保持一个so_head指向accept套接字指针。 来自防火墙回调utp_call_on_firewall的反馈 发包操作UTPSocket::send_packet是主要的发包函数 UTPSocket::send_packet、UTPSocket::send_ack、send_rst send_packet函数用来发送构造好的OutgoingPacket::data。 send_ack会就地构造一个ACK包，然后调用send_data发送。 send_rst直接调用更基础的send_to_addr发送RST包。 UTPSocket::send_data 这个函数的存在主要是处理一些UTPSocket::send_packet和UTPSocket::send_ack的共同部分 send_to_addr 这个函数位于调用链的最下端，调用了注册的callback函数来发送数据包，同时调用utp_register_sent_packet像utp_context::context_stats报告了发送长度用来统计。这个统计信息可以被API函数utp_get_context_stats取得，以供用户分析。 写操作utp_writeutp_write被作为utp_writev的一个特例来处理。 utp_writev同UNIX套接口函数writev一样，utp_writev接受一个指向iovec数组的指针iovec_input：1234struct iovec&#123; void *iov_base; size_t iov_len;&#125;; utp_writev按照iovec_input[0 .. num_iovecs-1]的顺序从缓冲区发送数据，并返回成功发送的总字节数。utp_writev主要做一些检查，如num_iovecs是否超过了UTP_IOV_MAX。然后将iovec_input复制到自己的一块缓存iovec里面（为啥呢），计算所有iovec的大小的总和到bytes。我们实际发送的数据量num_to_send为bytes和连接最多允许的数据包大小packet_size（由MTU决定）两者的最小值。当bytes过大时，就需要分批发送，如下面的代码所示。123456size_t packet_size = conn-&gt;get_packet_size();size_t num_to_send = min&lt;size_t&gt;(bytes, packet_size);while (!conn-&gt;is_full(num_to_send)) &#123; bytes -= num_to_send; sent += num_to_send; conn-&gt;write_outgoing_packet(num_to_send, ST_DATA, iovec, num_iovecs); 这里的is_full由窗口决定。utp_writev下面会调用write_outgoing_packet(size_t payload, uint flags, struct utp_iovec *iovec, size_t num_iovecs)。我们知道OutgoingPacket用来描述一个数据包的上下文，在第一次握手时由于没有数据需要传输，所以直接调用的utp_send_packet，相当于只发送了一个包头。而对于utp_writev来说，需要在包头后面加上数据。下面的代码将每个iov[i]中的iov_base复制到。12345678910111213for (size_t i = 0; i &lt; num_iovecs &amp;&amp; needed; i++) &#123; if (iovec[i].iov_len == 0) continue; size_t num = min&lt;size_t&gt;(needed, iovec[i].iov_len); memcpy(p, iovec[i].iov_base, num); p += num; iovec[i].iov_len -= num; iovec[i].iov_base = (byte*)iovec[i].iov_base + num; // iovec[i].iov_base += num, but without void* pointers needed -= num;&#125; write_outgoing_packetwrite_outgoing_packet接受一个utp_iovec数组，然后组织数据包结构，并将其放入发送缓存。注意write_outgoing_packet函数并不会直接调用send_packet发送数据包。write_outgoing_packet主要是一个大循环12345do &#123; // ... payload -= added;&#125; while (payload);flush_packets(); 首先write_outgoing_packet在发送缓冲区中取出前一个seq_nr - 1序号的pkt，试图重用它。注意到如果窗口小于等于0，那么实际的pkt就是NULL，这是为了保证当窗口小于等于0时，不会再往当前的pkt里面放东西了，否则pkt的容量超过窗口导致被缓存。相反的，我们重新开一个包放超出窗口的数据，这样只有这个新开的包会被缓存。123if (cur_window_packets &gt; 0) &#123; pkt = (OutgoingPacket*)outbuf.get(seq_nr - 1);&#125; 下面的代码的上半部分，当数据包pkt尚未满载，并且尚未发送时，在本次循环中会重新使用它，在它的后面续上added长度的空间，供添加数据使用。sizeof(OutgoingPacket) - 1是减去VLA的一个字节。1234567891011121314151617// if there's any room left in the last packet in the window// and it hasn't been sent yet, fill that frame firstif (payload &amp;&amp; pkt &amp;&amp; !pkt-&gt;transmissions &amp;&amp; pkt-&gt;payload &lt; packet_size) &#123; // Use the previous unsent packet added = min(payload + pkt-&gt;payload, max&lt;size_t&gt;(packet_size, pkt-&gt;payload)) - pkt-&gt;payload; pkt = (OutgoingPacket*)realloc(pkt, (sizeof(OutgoingPacket) - 1) + header_size + pkt-&gt;payload + added); outbuf.put(seq_nr - 1, pkt); append = false; assert(!pkt-&gt;need_resend);&#125; else &#123; // Create the packet to send. added = payload; pkt = (OutgoingPacket*)malloc((sizeof(OutgoingPacket) - 1) + header_size + added); pkt-&gt;payload = 0; pkt-&gt;transmissions = 0; pkt-&gt;need_resend = false;&#125; 下面的代码紧接着上面，为pkt添加added长度的数据1234567891011121314151617181920212223if (added) &#123; assert(flags == ST_DATA); // Fill it with data from the upper layer. unsigned char *p = pkt-&gt;data + header_size + pkt-&gt;payload; size_t needed = added; for (size_t i = 0; i &lt; num_iovecs &amp;&amp; needed; i++) &#123; if (iovec[i].iov_len == 0) continue; size_t num = min&lt;size_t&gt;(needed, iovec[i].iov_len); memcpy(p, iovec[i].iov_base, num); p += num; iovec[i].iov_len -= num; iovec[i].iov_base = (byte*)iovec[i].iov_base + num; // iovec[i].iov_base += num, but without void* pointers needed -= num; &#125; assert(needed == 0);&#125; append表示是否是一个需要被加入缓冲区的新数据包，在上面的if块中被设置12345678if (append) &#123; // Remember the message in the outgoing queue. outbuf.ensure_size(seq_nr, cur_window_packets); outbuf.put(seq_nr, pkt); p1-&gt;seq_nr = seq_nr; seq_nr++; cur_window_packets++;&#125; 接下来write_outgoing_packet调用flush_packets来刷新缓冲区 flush_packetsflush_packets函数在发包时和重传计时器超时时被调用。123456789101112131415161718192021222324bool UTPSocket::flush_packets()&#123; size_t packet_size = get_packet_size(); // send packets that are waiting on the pacer to be sent // i has to be an unsigned 16 bit counter to wrap correctly // signed types are not guaranteed to wrap the way you expect for (uint16 i = seq_nr - cur_window_packets; i != seq_nr; ++i) &#123; OutgoingPacket *pkt = (OutgoingPacket*)outbuf.get(i); if (pkt == 0 || (pkt-&gt;transmissions &gt; 0 &amp;&amp; pkt-&gt;need_resend == false)) continue; // have we run out of quota? if (is_full()) return true; // Nagle check // don't send the last packet if we have one packet in-flight // and the current packet is still smaller than packet_size. if (i != ((seq_nr - 1) &amp; ACK_NR_MASK) || cur_window_packets == 1 || pkt-&gt;payload &gt;= packet_size) &#123; send_packet(pkt); &#125; &#125; return false;&#125; 读操作在ucat.c中，当context收到UDP包之后会交给对应socket的udp_process_incoming函数进行处理，这个函数中涉及和uTP实现可靠传输有关的很多内容，因此与之相关的内容将放在下面的章节中进行讨论，本节主要讨论uTP处理出数据并返回上层的相关内容。首先我们看到udp_process_incoming调用了utp_register_recv_packet，这是一个统计用的函数，我们可以不做考虑。 主动关闭12345678910111213141516171819202122void utp_close(UTPSocket *conn)&#123; switch(conn-&gt;state) &#123; case CS_CONNECTED: case CS_CONNECTED_FULL: conn-&gt;state = CS_FIN_SENT; conn-&gt;write_outgoing_packet(0, ST_FIN, NULL, 0); break; case CS_SYN_SENT: conn-&gt;rto_timeout = utp_call_get_milliseconds(conn-&gt;ctx, conn) + min&lt;uint&gt;(conn-&gt;rto * 2, 60); // fall through case CS_GOT_FIN: conn-&gt;state = CS_DESTROY_DELAY; break; case CS_SYN_RECV: // fall through default: conn-&gt;state = CS_DESTROY; break; &#125;&#125; 超时重传与可靠传输引起发送方超时重传的原因有大致三种： 分组丢失。这里指报文并没有顺利到达接收方，因此需要发送发进行重传。 确认丢失。这里报文顺利传送到接收方，但接收方返回的ACK报文丢失了。这种情况下发送方很可能会在超时之后重新发送该分组，而接收方应该选择丢弃并重新确认。 经受延迟。这里报文和ACK都顺利传送，但整个过程耗时超过了Timeout，这时发送方也会进行重传。 对于发送出去的每个数据包设置一个定时器，等定时器超时之后触发回调进行重传是开销很大的。实际上可以维护一个超时重传计时器，当对方有数据包过来时就重置这个计时器，否则当计时器超时时，就重传发送队列中的所有数据包。 发送ACK当对方封包过来时，需要根据其序号更新自己的确认号，并进行相关处理，如发送ACK、处理乱序包等。这是一个复杂的流程，本部分介绍如何向对方发送一个ACK。而在此之前的例如接受封包，更新自己的ack_nr则在下面的数据包接收（确认部分）进行介绍。 延迟确认uTP使用了schedule_ack的机制来实现Delayed ACK特性。首先使用UTPSocket::schedule_ack向context注册socket自己，表示请不要立即发送一个空的ACK包，而是尝试将ACK放到带用户数据的包里面。当计时器超时时，utp_issue_deferred_acks函数会被调用（在ucat.c里面）。这个函数调用ack_sockets里面所有注册了的socket的send_ack()方法，发送ACK包。12345for (size_t i = 0; i &lt; ctx-&gt;ack_sockets.GetCount(); i++) &#123; UTPSocket *conn = ctx-&gt;ack_sockets[i]; conn-&gt;send_ack(); i--;&#125; 当新的ACK能够随着带用户数据的包一同发送时，就能免于发送一个空ACK包的开销。这时候会调用removeSocketFromAckList函数将这个socket从ack_sockets列表中删除。12345678910111213141516void removeSocketFromAckList(UTPSocket *conn)&#123; if (conn-&gt;ida &gt;= 0) &#123; UTPSocket *last = conn-&gt;ctx-&gt;ack_sockets[conn-&gt;ctx-&gt;ack_sockets.GetCount() - 1]; assert(last-&gt;ida &lt; (int)(conn-&gt;ctx-&gt;ack_sockets.GetCount())); assert(conn-&gt;ctx-&gt;ack_sockets[last-&gt;ida] == last); last-&gt;ida = conn-&gt;ida; conn-&gt;ctx-&gt;ack_sockets[conn-&gt;ida] = last; conn-&gt;ida = -1; // Decrease the count conn-&gt;ctx-&gt;ack_sockets.SetCount(conn-&gt;ctx-&gt;ack_sockets.GetCount() - 1); &#125;&#125; 这个函数会将需要移除的指针和队尾指针互换，并弹出队尾。需要注意的是延迟确认存在很多特殊情况： 保活心跳包立即发送 SYN和FIN等关键包立即发送 当窗口变为0立即发送，因为窗口为0表示一段时间内不能向对方发送数据了 具体实现从具体实现上看，libutp在void UTPSocket::ack_packet(uint16 seq)函数里面处理对方发过来的ACK，在void UTPSocket::send_ack(bool synack)里面向对方发送自己对对方的ACK。ack_packet函数有3个返回值，返回0表示正常ACK，返回1表示这个包已经被ACK过了，返回2表示这个包还没有被发送。 数据包接收（确认部分）TCP协议中使用的是后退N重传(Go-Back-N)协议，即从第一个未确认的包开始全部传送。TCP用ACK号表示小于ACK号的所有字节都已经被接受到。例如A发送了1/2/3/4四个数据包，如果截止到A的RTO超时，B只接受到了1/3，那么它只能ACK到1。这时候A就必须重传2/3/4三个数据包，但其实3是可以不重传的。此时在传输过程中发生了乱序，这里数据包3号早于数据包2号到达了。uTP使用reorder_count记录数据包乱序抵达的情况。我们查看在utp_process_incoming中有关处理对方序号的部分12// seqnr is the number of packets past the expected packet this is. ack_nr is the last acked, seq_nr is the current. Subtracring 1 makes 0 mean "this is the next expected packet".const uint seqnr = (pk_seq_nr - conn-&gt;ack_nr - 1) &amp; SEQ_NR_MASK; 这里的pk_seq_nr指的是数据包包头中的seq_nr字段，而conn-&gt;ack_nr表示我们最后确认的序号，因此seqnr为0时表示这个包是序号紧接着的数据包。注意这个是能够正确处理溢出的情况的。接下来跳过若干行，在utp_process_incoming函数的最后，对当前的数据包进行确认工作，并调用utp_call_on_read回调。查看代码，这里对seqnr是否为0，也就是是否为乱序包展开了讨论，首先查看不是乱序包的情况，我们直接在代码中进行注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748if (seqnr == 0) &#123; size_t count = packet_end - data; if (count &gt; 0 &amp;&amp; conn-&gt;state != CS_FIN_SENT) &#123; // Post bytes to the upper layer utp_call_on_read(conn-&gt;ctx, conn, data, count); &#125; conn-&gt;ack_nr++; // Check if the next packet has been received too, but waiting in the reorder buffer. // 这里检查是否可以释放缓存着的乱序包，例如seqnr==1的包可能已经到达，但由于当前seqnr==0的包还未到达，所以无法确认，只能缓存着 for (;;) &#123; if (conn-&gt;got_fin &amp;&amp; conn-&gt;eof_pkt == conn-&gt;ack_nr) &#123; if (conn-&gt;state != CS_FIN_SENT) &#123; conn-&gt;state = CS_GOT_FIN; conn-&gt;rto_timeout = conn-&gt;ctx-&gt;current_ms + min&lt;uint&gt;(conn-&gt;rto * 3, 60); utp_call_on_state_change(conn-&gt;ctx, conn, UTP_STATE_EOF); &#125; // if the other end wants to close, ack conn-&gt;send_ack(); // reorder_count is not necessarily 0 at this point. even though it is most of the time, the other end may have sent packets with higher sequence numbers than what later end up being eof_pkt since we have received all packets up to eof_pkt just ignore the ones after it. conn-&gt;reorder_count = 0; &#125; // 当已经没有乱序包了，就直接退出循环。这里和后面的assert联动 // Quick get-out in case there is nothing to reorder if (conn-&gt;reorder_count == 0) break; // Check if there are additional buffers in the reorder buffers // that need delivery. byte *p = (byte*)conn-&gt;inbuf.get(conn-&gt;ack_nr+1); if (p == NULL) break; conn-&gt;inbuf.put(conn-&gt;ack_nr+1, NULL); count = *(uint*)p; if (count &gt; 0 &amp;&amp; conn-&gt;state != CS_FIN_SENT) &#123; // Pass the bytes to the upper layer utp_call_on_read(conn-&gt;ctx, conn, p + sizeof(uint), count); &#125; conn-&gt;ack_nr++; // Free the element from the reorder buffer free(p); assert(conn-&gt;reorder_count &gt; 0); conn-&gt;reorder_count--; &#125; // 向context注册一个延迟确认 conn-&gt;schedule_ack();&#125; 下面查看是乱序包的情况1234567891011121314151617181920212223242526272829303132333435363738// if we have received a FIN packet, and the EOF-sequence number is lower than the sequence number of the packet we just received something is wrong.if (conn-&gt;got_fin &amp;&amp; pk_seq_nr &gt; conn-&gt;eof_pkt) &#123; return 0;&#125;// 如果这里接受到一个序号距离ack_nr偏移非常严重的包，选择直接丢弃。注意到这里实际上也处理了一个序号在pk_seq_nr前的包的情况// if the sequence number is entirely off the expected one, just drop it. We can't allocate buffer space in the inbuf entirely based on untrusted inputif (seqnr &gt; 0x3ff) &#123; return 0;&#125;// we need to grow the circle buffer before we check if the packet is already in here, so that we don't end up looking at an older packet (since the indices wraps around).conn-&gt;inbuf.ensure_size(pk_seq_nr + 1, seqnr + 1);// 一个提前抵达的包同样可能已经被处理过// Has this packet already been received? (i.e. a duplicate) If that is the case, just discard it.if (conn-&gt;inbuf.get(pk_seq_nr) != NULL) &#123; return 0;&#125;// Allocate memory to fit the packet that needs to re-orderedbyte *mem = (byte*)malloc((packet_end - data) + sizeof(uint));*(uint*)mem = (uint)(packet_end - data);memcpy(mem + sizeof(uint), data, packet_end - data);// Insert into reorder buffer and increment the count of # of packets to be reordered. we add one to seqnr in order to leave the last entry empty, that way the assert in send_ack is valid. we have to add one to seqnr too, in order to make the circular buffer grow around the correct point (which is conn-&gt;ack_nr + 1).assert(conn-&gt;inbuf.get(pk_seq_nr) == NULL);assert((pk_seq_nr &amp; conn-&gt;inbuf.mask) != ((conn-&gt;ack_nr+1) &amp; conn-&gt;inbuf.mask));conn-&gt;inbuf.put(pk_seq_nr, mem);conn-&gt;reorder_count++;#if UTP_DEBUG_LOGGINGconn-&gt;log(UTP_LOG_DEBUG, "0x%08x: Got out of order data reorder_count:%u len:%u (rb:%u)", conn-&gt;reorder_count, (uint)(packet_end - data), (uint)utp_call_get_read_buffer_size(conn-&gt;ctx, conn));#endif// 向context注册一个延迟确认conn-&gt;schedule_ack(); RTT与RTO的计算RTT(Round-Trip Time)即往返时间。受到链路的传播时间、终端系统的处理时间、路由器缓存与处理时间的影响。如果我们使用发送时间戳TS和收到ACK的时间戳TR来计算$RTT = TR - TS$，那么这个值是偏大的，因为它包含了链路中的来回时间，但是也包含了对端在收到数据包之后到发送ACK包之间的包括缓存、处理的时间（称为ack delay）。因此一个较好的RTT计算方式应该是$RTT = TR - TS - ACKDELAY$RTO(Retransmission TimeOut)，超时重传时间，与RTT有关。RFC793中使用低通过滤器对RTT进行平滑，然后再乘上一个因子$\beta$得到初次重传RTO。此外在往返时间变化起伏较大是，还要根据均值和方差计算RTO。RTO随着重传次数是按照指数增长的，即第二次超时则重传时间变为2倍的RTO。在新的RFC2988/6298中又更新了相关的算法，在此不详述。 uTP中RTT和初始RTO的计算实现在ack_packet函数里面。ack_packet是作用在发送队列上的，当数据包没有被重传的时候，使用当前时间减去它的发送时间来计算出ertt，然后计算出rtt和rto。而rto_timeout指的是超时的时刻，初始化时有rto_timeout = ctx-&gt;current_ms + retransmit_timeout。当ctx-&gt;current_ms - rto_timeout时则超时条件触发。下面是ack_packet中具体的代码。注意我们只对没有重传的包计算RTT，这是因为如果数据包经历了重传，并且我们收到了来自对端的ACK，我们无法知道这个ACK是对原始包还是被重传包的响应。1234567891011121314151617181920212223// 我们只对没有重传的包计算RTTif (pkt-&gt;transmissions == 1) &#123; // Estimate the round trip time. const uint32 ertt = (uint32)((utp_call_get_microseconds(this-&gt;ctx, this) - pkt-&gt;time_sent) / 1000); if (rtt == 0) &#123; // First round trip time sample rtt = ertt; rtt_var = ertt / 2; // sanity check. rtt should never be more than 6 seconds// assert(rtt &lt; 6000); &#125; else &#123; // Compute new round trip times const int delta = (int)rtt - ertt; rtt_var = rtt_var + (int)(abs(delta) - rtt_var) / 4; rtt = rtt - rtt/8 + ertt/8; // sanity check. rtt should never be more than 6 seconds// assert(rtt &lt; 6000); rtt_hist.add_sample(ertt, ctx-&gt;current_ms); &#125; rto = max&lt;uint&gt;(rtt + rtt_var * 4, 1000);&#125;retransmit_timeout = rto;rto_timeout = ctx-&gt;current_ms + rto; QUIC的解决方案QUIC协议的一个非常不同的地方在于它虽然也是按照Packet编号的，称为Packet Number。但是它的编号是严格递增的。这么做也是为了解决TCP中存在的重传歧义问题，但显而易见我们无法维护有序性了，因此对于承载的流数据，QUIC提供了stream offset来维护其顺序和可靠性。 超时重传TCP的实现超时重传一般是设置一个超时重传定时器icsk-&gt;icsk_retransmit_timer，通过inet_csk_init_xmit_timers来注册。常用的超时方式有使用alarm信号、使用select、设置SO_RCVTIMEO和SO_SNDTIMEO字段、使用Linux提供的定时器（setitimer等）。但是在uTP的实现里面我并没有发现使用上面定时器的痕迹，这个定时器在哪里呢？我们首先找到uTP的超时重传实现，在void UTPSocket::check_timeouts函数里，而这个函数只被utp_check_timeouts调用。utp_check_timeouts是作为uTP的API函数，在应用程序ucat.c中，每次network_loop中的poll函数超时时，utp_check_timeouts就被调用。其实libutp框架更类似于一个个中断处理程序，而不是一个服务，它需要来自外部的信号才能驱动。下面我们来查看UTPSocket::check_timeouts这个方法。这个方法中出发了对坚持定时器zerowindow_time、重传定时器rto_timeout、保活定时器last_sent_packet和时间等待定时器rto_timeout（这里复用了）。首先查看最基本的重传定时器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283case CS_SYN_SENT:case CS_SYN_RECV:case CS_CONNECTED_FULL:case CS_CONNECTED:case CS_FIN_SENT: &#123; if ((int)(ctx-&gt;current_ms - rto_timeout) &gt;= 0 &amp;&amp; rto_timeout &gt; 0) &#123; // 这里删去了处理mtu探测的部分内容，移到专门的章节 // 这里删除了一段被注释了的重传次数大于4就重新计算rtt的策略 // Increase RTO const uint new_timeout = ignore_loss ? retransmit_timeout : retransmit_timeout * 2; // 这里防范恶意连接的情况，当第三次握手超时时就直接关闭连接 if (state == CS_SYN_RECV) &#123; state = CS_DESTROY; utp_call_on_error(ctx, this, UTP_ETIMEDOUT); return; &#125; // 这里删去了处理连接超时的部分内容，移到专门章节 retransmit_timeout = new_timeout; rto_timeout = ctx-&gt;current_ms + new_timeout; if (!ignore_loss) &#123; // 此时连接超时，ignore_loss只有当执行mtu探测任务时才为true duplicate_ack = 0; int packet_size = get_packet_size(); if ((cur_window_packets == 0) &amp;&amp; ((int)max_window &gt; packet_size)) &#123; // 这时连接处于闲置状态，并不急切需要重置拥塞窗口 max_window = max(max_window * 2 / 3, size_t(packet_size)); &#125; else &#123; // 此时延迟非常大，因此将拥塞窗口缩小到1个数据包，并开始慢启动算法 max_window = packet_size; slow_start = true; &#125; &#125; // 这个时候使用后退N协议全部重传 for (int i = 0; i &lt; cur_window_packets; ++i) &#123; OutgoingPacket *pkt = (OutgoingPacket*)outbuf.get(seq_nr - i - 1); if (pkt == 0 || pkt-&gt;transmissions == 0 || pkt-&gt;need_resend) continue; // uTP使用`need_resend`来描述一个包是否需要被重传。 pkt-&gt;need_resend = true; assert(cur_window &gt;= pkt-&gt;payload); cur_window -= pkt-&gt;payload; &#125; if (cur_window_packets &gt; 0) &#123; retransmit_count++; fast_timeout = true; timeout_seq_nr = seq_nr; OutgoingPacket *pkt = (OutgoingPacket*)outbuf.get(seq_nr - cur_window_packets); assert(pkt); // Re-send the packet. send_packet(pkt); &#125; &#125; // Mark the socket as writable. If the cwnd has grown, or if the number of // bytes in-flight is lower than cwnd, we need to make the socket writable again // in case it isn't if (state == CS_CONNECTED_FULL &amp;&amp; !is_full()) &#123; state = CS_CONNECTED; #if UTP_DEBUG_LOGGING log(UTP_LOG_DEBUG, "Socket writable. max_window:%u cur_window:%u packet_size:%u", (uint)max_window, (uint)cur_window, (uint)get_packet_size()); #endif utp_call_on_state_change(this-&gt;ctx, this, UTP_STATE_WRITABLE); &#125; if (state &gt;= CS_CONNECTED &amp;&amp; state &lt; CS_GOT_FIN) &#123; if ((int)(ctx-&gt;current_ms - last_sent_packet) &gt;= KEEPALIVE_INTERVAL) &#123; send_keep_alive(); &#125; &#125; break; 注意这里对于一个socket而不是一个数据包维护一个retransmit_count。下面查看时间等待定时器，这里并不需要等2MSL的时间，而是3*RTO和60之间的较小值。1234567891011121314151617// check_timeoutscase CS_GOT_FIN:case CS_DESTROY_DELAY: if ((int)(ctx-&gt;current_ms - rto_timeout) &gt;= 0) &#123; state = (state == CS_DESTROY_DELAY) ? CS_DESTROY : CS_RESET; if (cur_window_packets &gt; 0) &#123; utp_call_on_error(ctx, this, UTP_ECONNRESET); &#125; &#125; break; // utp_process_incomingif (conn-&gt;state != CS_FIN_SENT) &#123; conn-&gt;state = CS_GOT_FIN; conn-&gt;rto_timeout = conn-&gt;ctx-&gt;current_ms + min&lt;uint&gt;(conn-&gt;rto * 3, 60); utp_call_on_state_change(conn-&gt;ctx, conn, UTP_STATE_EOF);&#125; Fast retransmitFast retransmit虽然也是超时重传行为，但实际上是拥塞避免算法中的一部分。因此将在拥塞控制部分论述。 Selective Acknowledgment在TCP协议中使用SACK选项进行选择确认，使用若干组[start, end)来表示已经接受到数据的区间。SACK能够有效减少重传数据包的数量，对于带宽紧张的网络十分有用。不过需要注意恶意使用SACK对CPU资源造成的损害。在先前的数据包头构造部分已经提到了UTP的EACK机制，这是一个非常巧妙的方案，即用一个32位的比特串来表示从ack_nr + 2开始的32个未确认的包中有哪些是已经收到了在缓存里的，这里不从ack_nr + 1开始是因为我们可以默认这个包丢了，不然的话ack_nr就至少会到ack_nr + 1的值了。有关SACK的代码在UTPSocket::send_ack方法里面。1234567891011121314151617181920212223if (reorder_count != 0 &amp;&amp; state &lt; CS_GOT_FIN) &#123; // if reorder count &gt; 0, send an EACK. reorder count should always be 0 for synacks, so this should not be as synack assert(!synack); pfa.pf.ext = 1; pfa.ext_next = 0; pfa.ext_len = 4; uint m = 0; // reorder count should only be non-zero if the packet ack_nr + 1 has not yet been received assert(inbuf.get(ack_nr + 1) == NULL); size_t window = min&lt;size_t&gt;(14+16, inbuf.size()); // Generate bit mask of segments received. for (size_t i = 0; i &lt; window; i++) &#123; if (inbuf.get(ack_nr + i + 2) != NULL) &#123; m |= 1 &lt;&lt; i; &#125; &#125; pfa.acks[0] = (byte)m; pfa.acks[1] = (byte)(m &gt;&gt; 8); pfa.acks[2] = (byte)(m &gt;&gt; 16); pfa.acks[3] = (byte)(m &gt;&gt; 24); len += 4 + 2;&#125; 首先我们看到条件是reorder_count != 0 &amp;&amp; state &lt; CS_GOT_FIN，这表明在非连接建立/关闭时，当出现数据包乱序抵达时，启动EACK机制。ESAK是不允许Reneging的， 连接的异常终止重传失败在Linux中使用tcp_retries1 = 3和tcp_retries2 = 15（计算得到的一个时间戳）来限定普通包的重传次数。特别地，在握手时设有专门的tcp_syn_retries，这是由于对于连接建立时的重传需要精心设计以防止可能的SYN Flood攻击。在UTP中的重传失败机制比较简单。1234567891011if (retransmit_count &gt;= 4 || (state == CS_SYN_SENT &amp;&amp; retransmit_count &gt;= 2)) &#123; // 4 consecutive transmissions have timed out. Kill it. If we // haven't even connected yet, give up after only 2 consecutive // failed transmissions. if (state == CS_FIN_SENT) state = CS_DESTROY; else state = CS_RESET; utp_call_on_error(ctx, this, UTP_ETIMEDOUT); return;&#125; 连接重置保活定时器从TCP对长连接的管理上来讲，服务器通常会对其的对端启用保活定时器，以避免在对端意外崩溃下连接的浪费。我们看到TCP是非常珍惜服务器端的连接资源的，这还体现在TCP往往鼓励客户端主动关闭，从而让客户端而不是服务端等待2MSL。TCP规定当给定的连接在两个小时之内无任何动作，则服务器向对端发送探测包。根据客户端的状态会分为四种情况：1. 当客户端和网络都正常时，那么服务器能够得到正常响应，于是复位保活定时器。2. 当客户主机崩溃（关闭或重启中）时，客户端没有响应，服务器会等待10次75秒的超时，直到关闭连接。3. 当客户主机从崩溃中恢复后，服务器将受到来自客户端的RESET。4. 当客户端正常运行，但网络异常，类似网络分区状况，这种情况类似2。在libutp中设定了一个KEEPALIVE_INTERVAL 29000的阈值，表示29秒后会启动保活探测，它同时指出这个阈值来自对很多家庭NAT设备的计量。保活探测很简单，就是发送一个重复的ACK。1234567891011void UTPSocket::send_keep_alive()&#123; ack_nr--; #if UTP_DEBUG_LOGGING log(UTP_LOG_DEBUG, "Sending KeepAlive ACK %u [%u]", ack_nr, conn_id_send); #endif send_ack(); ack_nr++;&#125; 流量控制和拥塞控制TCP的流量控制以及拥塞控制算法被迁移到这一篇文章中 uTP拥塞控制概述uTP拥塞控制选择了丢包率和单向缓冲时延(one way buffer delay)进行度量。我们注意到在链路中存在一些设备能够缓存几秒钟内通过的数据，但uTP希望实现0字节的发送缓存。在实践中uTP的目标延迟在100ms，即当套接字侦测到自己发送数据包经受了100ms以上的延迟时，它就会调整拥塞窗口。下面我们查看相关逻辑的实现。在uTP报文头部我们可以看到tv_usec和reply_micro，通过这两个值uTP可以维护一个两分钟内的最小延迟值delay_base，我们将它作为两个服务器之间的延迟的基线，如果我们的实际延迟超过基线100ms，那么就认为网络发生了拥塞。delay_base在DelayHist::add_sample中更新，DelayHist使用数组cur_delay_hist维护所有delay值相对于delay_base的偏移。我们将在下面的时间测量部分继续讨论DelayHist的相关实现。在UTPSocket::apply_ccontrol中，首先取our_delay用DelayHist::get_value()获得的所有cur_delay_hist的最小值，注意由于没有样本时返回UINT_MAX，所以此时our_delay取RTT。12345678910// DelayHist::get_value()uint32 get_value()&#123; uint32 value = UINT_MAX; for (size_t i = 0; i &lt; CUR_DELAY_SIZE; i++) &#123; value = min&lt;uint32&gt;(cur_delay_hist[i], value); &#125; // value could be UINT_MAX if we have no samples yet... return value;&#125; 我们在套接字中定义一个target_delay默认为100000微秒即100毫秒，我们希望每个套接字发送端的延时不超过100ms。 uTP的窗口libutp定义了一些有关窗口的变量123456789101112131415// the number of packets in the send queue. Packets that haven't// yet been sent count as well as packets marked as needing resend// the oldest un-acked packet in the send queue is seq_nr - cur_window_packetsuint16 cur_window_packets;// how much of the window is used, number of bytes in-flight// packets that have not yet been sent do not count, packets// that are marked as needing to be re-sent (due to a timeout)// don't count eithersize_t cur_window;// maximum window size, in bytessize_t max_window;// max receive window for other end, in bytessize_t max_window_user; 其中cur_window_packets表示数据包的窗口，包含所有在发送队列的数据包，无论是否已经被发送，或者是否需要重传。因此最旧的未被对方确认的序号是seq_nr - cur_window_packets。UTP对cur_window_packets的限制是一定要小于OUTGOING_BUFFER_MAX_SIZEcur_window就是按字节算的通常意义上的窗口，在计算时不包含需要重传的包。max_window表示最大的窗口，它和max_window_user不同的是max_window还包含了拥塞窗口，而max_window_user来自对方，表示对方缓冲区的大小。下面的is_full判断从cur_window_packets和cur_window角度窗口是否饱和。123456789101112131415161718bool UTPSocket::is_full(int bytes)&#123; size_t packet_size = get_packet_size(); if (bytes &lt; 0) bytes = packet_size; else if (bytes &gt; (int)packet_size) bytes = (int)packet_size; size_t max_send = min(max_window, opt_sndbuf, max_window_user); // subtract one to save space for the FIN packet if (cur_window_packets &gt;= OUTGOING_BUFFER_MAX_SIZE - 1) &#123; last_maxed_out_window = ctx-&gt;current_ms; return true; &#125; if (cur_window + bytes &gt; max_send) &#123; last_maxed_out_window = ctx-&gt;current_ms; return true; &#125; return false;&#125; Fast retransmit当发送方连续收到3次相同的ACK，那么就重传可能被丢了的包。这里为什么是至少收到3次而不是2次是因为丢包情况下发送方至少会收到三次重复的ACK。从实现上看，有的快速重传选择只重传最初被丢的包，有的选择重传所有被丢的包。uTP使用duplicate_ack来记录收到重复ACK的次数。在utp_process_incoming函数中对duplicate_ack进行更新123456789101112131415161718192021if (conn-&gt;cur_window_packets &gt; 0) &#123; // 当ack_nr等于最后被对方确认的序号时，这里`conn-&gt;seq_nr - conn-&gt;cur_window_packets`等于第一个没被对方确认的包 if (pk_ack_nr == ((conn-&gt;seq_nr - conn-&gt;cur_window_packets - 1) &amp; ACK_NR_MASK) // 这里作者强调了当数据包带上了用户数据后，就不应该算入重复ACK中，这和BSD4.4 TCP实现是一致的 &amp;&amp; pk_flags == ST_STATE) &#123; ++conn-&gt;duplicate_ack; if (conn-&gt;duplicate_ack == DUPLICATE_ACKS_BEFORE_RESEND &amp;&amp; conn-&gt;mtu_probe_seq) &#123; // It's likely that the probe was rejected due to its size, but we haven't got an ICMP report back yet if (pk_ack_nr == ((conn-&gt;mtu_probe_seq - 1) &amp; ACK_NR_MASK)) &#123; conn-&gt;mtu_ceiling = conn-&gt;mtu_probe_size - 1; conn-&gt;mtu_search_update(); &#125; else &#123; // A non-probe was blocked before our probe. Can't conclude much, send a new probe conn-&gt;mtu_probe_seq = conn-&gt;mtu_probe_size = 0; &#125; &#125; &#125; else &#123; conn-&gt;duplicate_ack = 0; &#125; // TODO: if duplicate_ack == DUPLICATE_ACK_BEFORE_RESEND and fast_resend_seq_nr &lt;= ack_nr + 1, resend ack_nr + 1 also call maybe_decay_win()&#125; 报文分段MTU(Maximum Transmission Unit)，最大传输单元。通常地，以太网的MTU是1500，而IP是65535（包括头部），Internet的标准MTU是576。所以对于较大的IP包，如果在以太网上传输就需要进行分片。而TCP协议提供了MSS选项用来在建立连接时写上MSS大小，也就是TCP的最大的分段大小，超过这个MSS的数据就需要进行分段传输。MSS的协商在前两次的SYN握手时处理。而UDP是不带有分片功能的，所以对于较大的数据包是采用IP进行分片的。这其中带来一些问题，IP分片后只有第一个分片带有UDP头部，因此只要有一个IP数据报传输失败，那么整个UDP报文就无法交付（校验和和长度都通不过）。而IP协议本身并没有重传功能，且分片可能发生在链路上的任一路由器上，实际上根本无法知道原数据包是怎么被分片的。因此如果在UDP上层的实现要求重传（UDP本身不带重传），必须整个UDP数据报全部重传。所以说我们重新考虑UDP协议就会发现它头部的2字节的长度显得很不必要，因为根本不会发这么长的数据报。事实上按照TCP的按字节编码省掉一个长度字段也是方便的。因此我们基于UDP实现的传输层协议首先要做的就是避免IP层为我们分片，这样就能保证每个IP数据报中都要带有UDP头和我们的协议头，是个完整的传输层协议包。这就意味着我们需要让我们的基于UDP的协议的MSS + HEAD + UDP_HEAD + IP_HEAD小于可能的链路层的MTU。 MTU探测UTP通过截取ICMP Type3 Code4(fragmentation needed)来获得分片情况，即在IP首部设置了不可分片标志，但如果UDP报文达到MTU上限则会丢弃该IP报，返回ICMP不可达差错。UTP通过这个机制使用二分法来找到一个合适的MTU。在UTPSocket::mtu_reset函数中，预置了MTU搜寻空间为[576, udp_mtu]，也就是default IP maximum datagem size。不过由于以太网的流行，所以将576作为下限，此时对应于TCP的MSS为536。123456void UTPSocket::mtu_reset()&#123; mtu_ceiling = get_udp_mtu(); mtu_floor = 576; mtu_discover_time = utp_call_get_milliseconds(this-&gt;ctx, this) + 30 * 60 * 1000;&#125; 时间测量本章将详细讨论在前面拥塞控制等章节遇到的各类延迟的计算。 延迟测量在数据报报头的tv_usec和reply_micro两个字段用来测量延迟。发送端S设置tv_usec表示发送时间S1123// send_datauint64 time = utp_call_get_microseconds(ctx, this);b1-&gt;tv_usec = (uint32)time; 接收端R计算reply_micro表示接受时间R1与发送时间S1的差，粗略地估计了从S到R的经历的时间。注意由于两个主机的时钟不一定一致，所以这个值不精确。1234567// utp_process_incominguint64 p = pf1-&gt;tv_usec;// get delay in both directions// record the delay to report backconst uint32 their_delay = (uint32)(p == 0 ? 0 : time - p);conn-&gt;reply_micro = their_delay; 为了消除误差，UTP借助了NTP授时协议的机制。这里需要假设S与R之间的网络状况是对等的（这是一个很强的假设），即从S到R的速度不至于显著慢或快于从R到S的速度。这时候从R往S端发送一个回复的数据包，记录下这次的发送时间R2和接收时间S2。可以计算得到仅由网络原因造成的延时为$(S2 - S1) - (R2 - R1)$，还能得到S和R两个主机之间的时间差是$\frac{(R1 - S1) + (R2 - S2)}{2}$。12// send_datab1-&gt;reply_micro = reply_micro; DelayHist类型DelayHist记录了时间的延迟，具有以下的方法 shift 用来将所有的delay_base_hist向右偏移一段时间长度 clock drift问题由于UTP被用来实现一些BT下载软件，这个机制是UTP用来防止用户故意调慢时钟从而霸占带宽设计的，并且不会产生误报(False positive)。 uTP数据包统计在utp_context_stats和utp_context_stats中进行context和socket级别的统计。1234567891011121314151617// Returned by utp_get_context_stats()typedef struct &#123; uint32 _nraw_recv[5]; // total packets recieved less than 300/600/1200/MTU bytes fpr all connections (context-wide) uint32 _nraw_send[5]; // total packets sent less than 300/600/1200/MTU bytes for all connections (context-wide)&#125; utp_context_stats;// Returned by utp_get_stats()typedef struct &#123; uint64 nbytes_recv; // total bytes received uint64 nbytes_xmit; // total bytes transmitted uint32 rexmit; // retransmit counter uint32 fastrexmit; // fast retransmit counter uint32 nxmit; // transmit counter uint32 nrecv; // receive counter (total) uint32 nduprecv; // duplicate receive counter uint32 mtu_guess; // Best guess at MTU&#125; utp_socket_stats; 此外在utp_context中也维护了rst_info等信息。 序号溢出问题TCP中使用了32位的序号，并且具有PAWS机制防止在大带宽的情况下序号被迅速耗尽后产生回绕。如前文所展示的，在uTP的实现中利用了无符号整数的溢出来避免回绕时序号变为0的问题。12345678910111213141516// compare if lhs is less than rhs, taking wrapping// into account. if lhs is close to UINT_MAX and rhs// is close to 0, lhs is assumed to have wrapped and// considered smallerbool wrapping_compare_less(uint32 lhs, uint32 rhs, uint32 mask)&#123; // distance walking from lhs to rhs, downwards const uint32 dist_down = (lhs - rhs) &amp; mask; // distance walking from lhs to rhs, upwards const uint32 dist_up = (rhs - lhs) &amp; mask; // if the distance walking up is shorter, lhs // is less than rhs. If the distance walking down // is shorter, then rhs is less than lhs return dist_up &lt; dist_down;&#125;]]></content>
      <tags>
        <tag>网络</tag>
        <tag>UDP</tag>
        <tag>libutp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP的流量控制和拥塞控制]]></title>
    <url>%2F2017%2F12%2F05%2Ftcp-window%2F</url>
    <content type="text"><![CDATA[本文作为一个专题来讨论TCP的流量控制和拥塞控制，其中部分论述迁移自libutp源码简析 流量控制着眼于接收端，保证发送端的发送速率能够匹配接收端的接受速率和缓存大小。流量控制包含滑动窗口rwnd、Nagle算法等。拥塞控制着眼于整个网络的性能，是当前发送端的速率匹配当前链路能承载的的限额。拥塞控制包含拥塞窗口rwnd、慢启动、拥塞避免、Fast retransmit和Fast recovery等。 序号ACK序号表示下一次期待收到的序号，是最末尾的字节数+1。需要注意的是SYN和FIN报文，即使没有payload，也会占用一个序号，这就有点类似于sizeof空struct一样。 连接的建立Listen和AcceptListen的(本地ip, 本地port, 远程ip, 远程port)四元组一般是(*, 本地port, *, *)。我们可以通过netstat查看到出于Listen状态的端点。 当连接建立后，四元组就确定了，通过netstat可以看到一个Established的条目。 Accept在三次握手完成之后才会返回。 Backlog 三次握手完成的连接，会进入一个队列，这个队列有一个backlog用来维护它的长度 当新的SYN到来时，也要根据这个队列的长度判断是否接受这个SYN，如果不接受，那么也不返回RST，因为我们可能只是暂时不能接收 同时打开和同时关闭同时打开的情况下，其实还是产生一个连接。 流量控制Nagle算法Nagle是一个发送方的算法，它要求一个TCP连接上最多只能有一个未被确认的（未完成的）小分组，在该分组的确认到达之前不能发送其他的小分组。既然一次只能发送一个分组，那么Nagle算法的策略昭然若揭，也就是我们会合并小分组，直到到达一定规模后，或者接收方的ACK后再发出。这个规模是当窗口大小大于MSS且payload大于MSS/2。MSS大是TCP的最大的分段大小，超过这个MSS的数据就需要进行分段传输，MSS的协商在前两次的SYN握手时处理，这个处理过程是通过TCP协议的一个选项来实现。1234567891011if there is new data to send then if the window size ≥ MSS and available data is ≥ MSS then send complete MSS segment now else if there is unconfirmed data still in the pipe then enqueue data in the buffer until an acknowledge is received else send data immediately end if end ifend if 通过Nagle算法能够从发送端减少链路上的小分组数量，但显然，实时性会受影响。我们可以使用TCP_NODELAY关闭这个算法 Nagle算法和Delayed ACK的冲突Delayed ACK是一个接收方的算法。在启用时，允许服务器延迟ACK发送至多500ms(TCPIP详解说大部分实现是200ms)，且最多间隔一个数据包。DACK有如下的好处： ACK等一等，让payload搭一下顺风车，减少发送空ACK的概率 给接收端读取缓存，更新窗口的时间，减少用来窗口更新报文 容易想到，当发送方启用Nagle而接收方启用DACK的时候，可能会导致进一步的延迟。考虑发送端进行两次连续的小段写再跟着读的情况。在发送方一侧，第一个写能够被顺利发出，但此时接收端在DACK，所以不能回包。此时由于发送端没有收到回ACK，所以Nagle算法不满足只有一个inflight包的条件；而发送缓存也没有达到MSS，此时就要等到DACK超时才会回包。可以通过TCP_QUICKACK禁用DACK。 TCP_CORK选项滑动窗口相比于Nagle算法，滑动窗口允许有多个inflight的报文。 虽然TCP必须支持左移窗口右边界，但是TCP协议非常不鼓励这一点。 PUSH命令用于告知接收端将缓冲区数据全部提交给进程。 窗口扩大系数窗口扩大系数，是一个TCP选项。通告窗口大小，等于TCP头部的窗口值，再左移扩大系数位。通常用来解决长肥管道的问题。 时间戳时间戳，也是一个TCP选项，通常可以用它来计算RTT。 不合理的通告窗口滑动窗口的精髓是不是有多少缓冲区空间就把窗口大小设成多少的。不然这个协议一句话就能讲明白了，下面我们看看有一些不合理的窗口可能产生的问题。 坚持定时器在滑动窗口协议中，如果接收方通告窗口为0，意味着接收方暂时不希望我们继续发送数据。当接收方能够继续接收时，它可以在发回的ACK报文中重新设置自己的通告窗口。但这其中存在一个问题，ACK报文会发几遍呢？如果接收方启用了保活定时器，也许能发送一些探测包？但我们需要寄希望于接收方来处理这个事情么？可以看出，如果ACK报文被意外丢弃后，发送方就不能接受到接收方的新通告窗口大小，因此继续不发送报文。接受方没有办法区分出自己没有接受到报文是因为没报文可发，还是窗口问题，还是丢包等问题，因此死锁形成了。此时需要在收到0窗口通告后，启动坚持定时器。坚持定时器会指数退避(exponential back-off)地增加，发送窗口探查(window probe)报文，直到监视到对方的窗口变化为止。坚持定时器会不停地发送payload为一个字节的报文，当然这个报文肯定不被对方ACK，因为对方缓冲区不够了。但是坚持定时器会一直坚持重传，并且不像重传定时器一样，坚持定时器没有放弃时间。 糊涂窗口综合征维基百科对糊涂窗口综合征(SWS)是这样解释的：当发送程序缓慢地生产数据，接收程序缓慢地消耗数据，或者两者同时存在时，滑动窗口运作会出现严重问题。如果一个服务器无法处理所有传入的数据而存在此问题，它会要求客户端减少一次发送的数据量，如果这个过程循环往复，数据量会越来越少，导致连接上交换的数据段是小数据段而不是全尺寸的数据段。简单地来说，SWS的不利影响是它的payload相比TCP Header很小，从而导致信道的利用率很差。 对于这种情况的正确做法是： 接收方应该等到可以发较大窗口通告再发窗口通告 根据David D Clark算法，这个阈值是min(MSS，cache_size/2)，不满足这个阈值要通知窗口为0。 但这里有一个注意点，因为TCP协议是非常不鼓励左移窗口右界的，所以在Demo中，出现了一个509的窗口。 发送方应该等到数据够多的时候一次性发送一个较大的段 对于这个想法，我们有个现成的Nagle算法 接收方里面数据+可用的始终为4096。 拥塞控制标准TCP中的拥塞控制首先简单地讨论下TCP进行拥塞控制的原理。拥塞的发生一般有两个预兆，一个是超时，另一个是收到重复的ACK。这里重复的ACK来自于一个超出可靠传输协议的额外约定，也就是当我们收到一个失序的报文段时，我们仍然需要立即回复一个ACK给对方的，而这个ACK在对方看来肯定是重复的了。必须要说明的是，这两者的还可能是由分组损坏导致的对端的丢包，但是这种情况很少，所以我们并不考虑。在TCP协议中我们考虑发送方和接收方之间存在较多路由器以及较慢链路的情况。在滑动窗口协议的控制下，我们知道只要窗口未被填满，缓冲区有数据，我们就可以往对端发包。但当链路较为复杂时，我们就必须要考虑当流量过大时，中途某个路由器可能无法负担而直接丢包，诸如此类的情况实际上限制了TCP的吞吐量。 我们可以理解，滑动窗口是接收方的流量控制，而拥塞窗口是发送方主动的流量控制。 慢启动为了解决这个问题，TCP首先提出了慢启动的算法。慢启动要求我们增加一个拥塞窗口cwnd，当连接刚建立时，我们设置cwnd为1个MSS的大小，并随着对方的每次的ACK而线性增大。注意在没有约束的情况下这实际上导致了指数增大的过程，例如一开始cwnd是1（个MSS），发送1个包，收到对方的ACK之后cwnd增加1到2，我们现在可以最多发送两个包，接着我们真的发送2个包，收到对方的确认后cwnd增长2，到达4。此外，我们能看到称为TCP自计时(self-clocking)的行为，也就是接收方返回的ACK的间隔和发送发送间隔趋于一致，我们可以从TCPIP详解（卷一）中看到一个详细的图示。即12和13这两个返回到发送方的ACK之间的间隔与报文段之间的间隔一致，这个原因是我们假设网络是对称的，并且也不考虑链路上出现的排队。接着来看，当这个过程收敛后（出现拥塞或者达到慢启动阈值ssthresh），也就是发送方和接收方之间的管道被填满，此时连接饱和，无论拥塞窗口和通告窗口是多少都不能再容纳更多数据，此时只有一个包被确认，发送方才能再发送另一个包。我们看到“慢启动”其实一点都不慢。 拥塞避免上面的慢启动过程以拥塞和达到阈值ssthresh（默认为65535）为结束，特别地，当cwnd超过ssthresh后需要执行拥塞避免算法。拥塞避免算法实际上将cwnd从慢启动的指数增长变为线性增长，也就是在一个RTT内只增大cwnd一次，对应到每个确认，我们只增加1/cwnd；而在慢启动中，该RTT中收到几个ACK就增加几次（注意cwnd是按字节计算的，由于成块数据流往往以MSS为单位发送，所以我们按照ACK来简化讨论，但合并的ACK并不影响）。一旦拥塞发生，拥塞避免会减少慢启动阈值ssthresh（实际上是减去cwnd/2），然后拥塞窗口cwnd立刻变为1，重新开始慢启动算法。容易看到这个第二次开始的慢启动算法在达到原先阈值的一半就会停止并进入拥塞避免，这类似于用一种二分法的思路寻找稳定的承载量，即ssthresh。 快速重传和快速恢复下面我们看到一个称为快速重传和快速恢复算法的改进，这个算法要求对于由重复的ACK（至少3次）报告的拥塞，我们在减半慢启动阈值ssthresh后不进行慢启动，而是只将拥塞窗口cwnd下降到新的ssthresh处，并继续执行拥塞避免算法。 长肥管道还有一类被称为长肥管道的连接，它的带宽(bandwidth)乘以RTT的积很大，在这种管道上传输时由于时延高，往往出现窗口耗尽而报文还没送达对端的问题，对此可以使用扩大窗口选项解决。但丢包问题仍可能造成发送窗口收敛到很小，因此网络通信速度急剧下降。上面的快速重传与快速恢复能够部分地解决问题，但不管怎么样，吞吐率还是受到了影响。这时候使用SACK可以避免再重传对方已经收到的包，减少了冗余的ACK包。 TCP的其他拥塞控制算法上面一节讨论了标准TCP对于拥塞控制的一种“加性增、乘性减”的控制算法，该算法以最大化利用网络上瓶颈链路的带宽为目的，不断尝试更大的窗口直到丢包发生（从超时或者重复的ACK来监测）。该算法在应对长肥管道类型的连接时有一些注意点。此外，我们还需要注意到一个称为bufferfloat的问题。 BBR在前面的讨论中我们能够发现探测丢包是比较困难的一件事情，我们不仅需要间接地探测丢包事件，还要判断出丢包是来源于拥塞还是无效包（虽然无效包是一个较小的概率）。因此BBR算法放弃了从丢包角度的考虑，而是从带宽和RTT的角度进行考虑。]]></content>
      <tags>
        <tag>网络</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UDP套接字编程]]></title>
    <url>%2F2017%2F12%2F02%2FUDP-Socket-Programming%2F</url>
    <content type="text"><![CDATA[UDP协议是相对于TCP协议不是面向连接的，也是不可靠的，因此UDP套接字编程在思路上和TCP套接字编程很不一样。 普通的UDP套接字sentto函数和recvfrom函数sentto函数和recvfrom函数比面向连接（稍后并不仅指TCP）的send和recv函数多了flag和表示送达和接收地址的SA。容易看到这两个函数是适合UDP这样的无连接协议的。对于客户端来说，相当于将connect函数功能去掉，然后每次都显式传地址。对于服务端来说，它也不需要accept函数，每次recvfrom过来，它都可以取到这是从谁发过来的。甚至recvfrom的SA参数可以设为nullptr，这样表示我接受所有信息，不管是谁发的。注意recvfrom传入的最后一个长度参数必须是已经初始化后的。否则UDP函数返回的地址和端口都会是0。 普通的UDP套接字存在的问题异步错误上面这样的设计看起来似乎很好，但考虑当服务端进程未开启，那从客户端过来的UDP包是送不到的，这时候recvfrom阻塞了。UNP书中给出了echo服务的例子，需要注意的是在Ubuntu的终端中我们可以仍可以输入，但实际上线程是阻塞的。但是对客户端来说并不是这样，因为sendto函数是立即返回的（不返回也没有意义啊，毕竟无连接的，并不能指望对方一定会回复）。但对系统来说，这个包并不是就这么杳无音信的，因为服务端会发一个端口不可达的ICMP过来，可惜这个不会被客户端的进程接受（原因稍后论述）。并且这个ICMP是具有时延，所以它也不能被立即返回的sendto接受。这样的错误称为异步错误。BTW，注意ICMP本身也是不可靠的，可能会被丢掉。所以客户端存在收不到ICMP的情况，这可能是因为数据报根本没发过去，也可能是对方主机回复的ICMP丢了。TCP甚至有个专门的Duplicate ACK机制来解决“是发过去的包丢了还是返回的ACK丢了”的问题。 为什么对应进程收不到端口不可达的ICMP考虑刚才的recvfrom函数，假如说给recvfrom函数设置一个超时（Ch14.2），那么它就不会在端口不可达时永远陷入阻塞，此时我们考虑它的行为。假设一个多宿的UDP套接口（它可向多个IP发送数据包）向另外3个服务器发送了数据包，然后阻塞在reccfrom上等待回应。这三台服务器中前两台开启了相应的端口并给出了回应，但是第三台服务器是端口不可达的，因而对端回复了ICMP报文。按照直截了当的思路，内核应当把源IP和端口等信息写到recvfrom的SA * from参数里面，然后设置errno = -1，这样recvfrom就可以超时返回了，客户端对应进程也就能知道刚才的的一个sendto失败了。作者指出从逻辑上就是不现实的，这是因为在recvfrom函数的返回值里面不能知晓是自己发送的3个UDP包中发向哪个服务器的包出现了问题，导致自己收不到回应，因为返回的errno无法承载IP地址信息。不过讲得并不清楚。这是由于sendto函数调用后，它是立即返回的，此时内核已经释放了和对端套接字相关的数据结构，当端口不可达的ICMP过来时，内核无法追踪出对应的套接字了，所以它无法通知上层的应用。基于上面的两点原因，最好不要重复利用UDP套接口，也就是说将它连接到一个对端。因此对UDP也有了connect函数。重新考虑上面的问题，在connect的情况下，内核中记录了这个五元组(源IP, 源port, 宿IP, 宿port, 协议)的状态。如果对端传来了ICMP消息，内核可以取出ICMP中的端口号，然后根据记录的五元组找到相应的进程。因此进程就能收到这个错误，虽然还是异步的。 “连接的”套接字一个不面向连接的UDP套接字不能收到它引发的异步错误，除非它已经被connect。但这里的connect和TCP中的并不一样，它没有TCP中三次握手的过程，事实上它仅仅在内核中注册了一下，并未和对端服务器进行交互。此时应当使用write、send来代替sendto（硬要用sendto需要将第5个参数即宿地址设为nullptr），用read、recv、recvmsg来代替recvfrom，这是因为connect声明了我们的套接口只和某个ip:port进行交互了。已连接的套接字会忽略其他IP或端口传来的数据报。同理，断开UDP的“连接”也不需要进行四次挥手，而是直接用AF_UNSPEC参数再次调用connect函数即可。对于不同的POSIX系统，还有其他各不相同的方法。]]></content>
      <tags>
        <tag>网络</tag>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘简易复习]]></title>
    <url>%2F2017%2F11%2F21%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%80%E6%98%93%E5%A4%8D%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[《数据挖掘》课程简易复习提纲，主要根据PPT整理。时间仓促，不排除存在部分内容爆炸。 IntroData Mining: process of semi-automaticlly analyzing large databases to find patterns that are: Valid: hold on new data with certainty Novel: non-obvious to the system Useful: should be possible to act on the item Understandable: humans should be able to interpret the pattern Data Exploration数据具有属性(attribute/feature)，属性可以分为Norminal、Binary、Ordinal或者Numeric的，也可以分为连续的或离散的。 度量数据度量中心度量中心的方式包括Mean平均数，Medium中位数和众数Mode。根据这三种数的位置关系可以分为symmetric和asymmetric(Positively skew和Negatively skew)两种 度量离散程度Quantile，常用的有四分位数，把Q3-Q1定义为IQR(Interquartile range)。在作业中还提到了absolute deviation，表示到中心点（median、mean、mode）的度量，等于$$\frac{1}{n} \sum^{n}_{i = 1}{|x_i - m(X)|}$$ 数据可视化包括直方图、Box Plots、散点图、康托图、Parallel Coordinates、Star Plots、Chernoff Faces Box Plots包含Upper/Lower Extreme、Upper/Lower Quartile、Median、Outlier和Whicker。Outlier离群点在后面会有专门一章讨论 Parallel Coordinates平行坐标将高维数据映射到一个N个纵坐标轴的折线，用于高维数据。类似的有Star Plots。 Dissimilarity matrix相异度矩阵 对Nominal而言$$d(i, j) = \frac{total - match}{total}$$ 对Binary而言令$q = (1, 1), r = (1, 0), s = (0, 1), t = (0, 0)$，分别表示对象$A$、$B$中属性值出现的四种对应情况的计数。 $$dissimilarity = \frac{r + s}{total} \\asymmetricBinaryDissimilarity = \frac{r + s}{q + r + s} \\Jaccard = 1 - asymmetricBinaryDissimilarity$$原因是$(1, 1)$和$(0, 0)$有时不能同等看待，例如有时$(1, 1)$非常罕见。 对Numeric而言曼哈顿距离（L1范数）和欧几里得距离（L2范数）分别是k为1和2的闵可夫斯基距离。$k \to \infty$是切比雪夫距离。 对Ordinal而言首先进行排序，得到$x_{i, feature}$对应的排行$rank_{i, feature}$（从1开始），然后把排行归一化。$$z_{i, feature} = \frac{rank_{i, feature} - 1}{total_{feature} - 1}$$ 混合属性$$d(i, j) = \frac{\sum_{feature}{exsit_{i, j} d_{i, j}}}{\sum_{feature}{exsit_{i, j}}}$$其中$d_{i, j}$：对Numeric是，相当于做个归一化$$\frac{|x_{i, feature} - x_{j, feature}|}{max_h(h, feature) - min_h(h, feature)}$$对Nominal是根据$x_{i, feature}$和$x_{j, feature}$是否相等取0或者1对于Ordinal是先根据排名进行标准化，再按照Numeric的方法计算 Data Preprocessingdata cleaning、data integration、data reduction和data transformation是数据预处理的基本任务。数据清洗包括缺失值、噪声、离群点和不一致问题的处理。数据集成包括对多种来源数据进行合并（实体识别），并处理其中的非一致和冗余数据。数据归约包含对维数和数量的归约。数据变换包括归一化、离散化和Concept Hierarchy Generation。 数据清洗处理缺失值忽略、人工填充、常数、填入全体中位数或均值、填入同类的中位数或均值、使用最可能的值填充（回归、贝叶斯算法等）。 处理噪声根据分箱(binning)、回归、聚类（检测离群点）分箱要求首先对数据排序，再划分为等频的箱，然后选择使用均值光滑（用均值替换箱中所有点）、边界光滑（用离自己最近的边界值替换）、中位数光滑等。这些光滑噪声的手段常也被用作离散化和数据归约。 数据集成可以通过相关性分析来检查数据冗余，例如对Nominal数据有$\chi^2$检验，对于Numeric数据有协方差和相关系数 $\chi^2$检验卡方检验可以描述两个向量$A[1..m]$和$B[1..n]$的相似程度。卡方检验的第一步是有一个数据集矩阵$M$，$M$中的元素$M_{ij}$，表示同时满足$A_i$和$B_i$性质的样本个数将矩阵填入一张表中，在表的最右端和最下端扩充一列/行，用来记录对应行/列的总和 首先计算$e_{ij}$，也就是对应的列和乘以行和除以总数$$e_{ij} = \frac{sum(B = b_i) * sum(A = a_j)}{sum(all)}$$ 将它填在括号里面，再对于矩阵中所有的单元格计算 $$\chi^2 = \sum_{m}{ \sum_{n}{ \frac{(x_{ij} - e_{ij})^2}{e_{ij}} } }$$ 皮尔逊相关系数协方差可以衡量两个变量的总体误差，方差可以看做两个变量相同时协方差的特例对于实数$X$、$Y$，定义协方差为$$Cov(X, Y) = E((X - \mathbb{E}(X))(Y -\mathbb{E}(Y)))$$对于向量$A$、$B$，定义协方差为 $$Cov(A, B) = E((A - \bar{A})(B - \bar{B})) = \frac{\sum_{i = 1}^{n}{(A_i - \bar{A})(B_i - \bar{B})}}{n} = E(A * B) - \bar{A} \bar{B}$$ 皮尔逊相关系数为 $$r_{A, B} = \frac{Cov(A, B)}{\sigma_A \sigma_B}$$ 注意这里分母标准差和分子期望中的$n$被约掉了，取值范围为$[-1, 1]$，等于0时变量独立，大于0时正相关，小于0负相关。注意相关性不暗示因果性。 数据归约小波分析主成分分析选取的主成分对应的坐标轴应当追求方差尽可能大 规范化数据 计算$k$个正交向量，即主成分。该过程可以对协方差矩阵求特征值和特征矩阵。 取出对应特征值最大的k个向量 标准化方法 min-max： $$ v’_i = \frac{v_i - min_A}{max_A - min_A} (newMax_A - newMin_A) + newMin_A $$ Z-score： 这里$\bar{A}$也可以替换成medoid或者mode等中心度量值，$\sigma_A$也可替换成absolute deviation$s$等离散程度度量值 $$ v’_i = \frac{v_i - \bar{A}}{\sigma_A} $$ demical scaling： $$ v’_i = \frac{v_i}{10^j} \quad where \\ \underset{j}{\mathrm{argmin}}(max(|v’_i|) &lt; 1) $$ Frequent ItemsetsFrequent Pattterns are patterns that appear frequently in a datasetsupport：$A$和$B$同时出现的概率$p(A \cap B)$，可以是绝对的即出现次数，可以是相对的，再除以事务数confidence：$p(B|A)$ = $c(A \cap B) / c(A)$频繁项集指的是支持度满足最小支持度阈值$min_{sup}$的项集闭频繁项集：$X$的任意超集$Y$的支持度不等于（小于）$X$的支持度极大频繁项集：$X$是频繁的，并且没有任何$X$的超集$Y$是频繁的 下面使用Apriori算法和FP-Growth算法来发现频繁$k$项集，注意我们不关注频繁$k+1$项集，尽管在过程中我们可以作为一个子问题得到它。 Apriori算法Apriori算法基于Apriori性质：频繁项集的子集一定是频繁的 使用Apriori生成频繁项集使用频繁项集生成关联项集 对于所有的频繁项集$l$，生成$l$所有的非空子集 对于$l$的每个非空子集$s$，输出规则$s \rightarrow (l - s)$，如果满足$p(l|s) \ge min\_conf$ Apriori优化方法 Hash-based itemset counting：hash到多个桶里进行初步删选 Transaction reduction：删去不包含任何$k$项集的事务 Partitioning：任何在DB中可能频繁的项集，至少在一个DB分区中是频繁的 这个性质很有意思，假设将数据集$D$分成了$n$个不重叠的部分$D_1, .. D_n$，下面证明任何在$D$中频繁（相对最小支持度为$s$）的项至少在$D$的一个部分$D_i$中频繁。 使用反证法证明。设有一个项集$x$在$D$中频繁。则有 $$ support\_count(x \in D) / |D| \ge s $$ 而$x$在$D_1, .. D_n$都不频繁，则有 $$ \frac{ support\_count(x \in D_i) }{ |D_i| } \lt s $$ 有 $$ \sum_{i = 1}^{n}{ support\_count(x \in D_i) } \lt s \, \sum_{i = 1}^{n}{ |D_i| } $$ 即 $$ \sum_{ i = 1 }^{ n } { \frac{ support\_count(x \in D_i) }{ |D| } } \lt s $$ 上面的式子就是 $$ n * support\_count(x \in D) / |D| &lt; n * s $$ 与假设矛盾 Sampling：在给定数据集的子集中挖掘，降低支持度要求，并采用一些方法确定其完整性 Dynamic itemset couting： FP-Growth利用FP-Tree生成频繁项集在建成FP-Tree后，从后往前生成频繁项集。以《数据挖掘：概念与技术(第3版)》为例，考虑最后的节点$I5$： 构造$I5$的条件模式基(prefix path sub-tree ending in $e$) 首先从$I5$的所有节点（可以是叶子节点也可以是内部节点，这里$I5$就都是叶子节点，而$I1$就有一个内部节点）往树根找到一条树链，将树链上的所有节点的支持度改为等于叶子节点$I5$的支持度 12&lt;I2, I1, I5 : 1&gt;&lt;I2, I1, I3, I5 : 1&gt; 接着提取出前缀路径，即条件模式基 12&lt;I2, I1: 1&gt;&lt;I2, I1, I3 : 1&gt; 使用条件模式基构造条件FP树 $I5$的条件FP树可以看做是原事务集中含有$I5$的所有项组成的集合，然后把里面的$I5$全部去掉 因此可以使用和构造FP树相同的办法 1&lt;I2, I1: 1&gt; 注意此时$I3$被去掉了，因为它在条件FP树上的的支持度为1，不满足2的最小支持度。实际上指的是$(I2, I3, I5)$这个项集的支持度不足。 查看$I5$是否是频繁项集（可以由简单计数得到） 如果$I5$是频繁的，找到所有以$I5$结尾的频繁项集 Basic Classification基本概念训练集、测试集 决策树决策树分为树枝，表示对特征测试的结果，由此产生子节点。子节点分为内部节点和叶子节点，叶子节点展示所属类的标签，内部节点展示被测试的特征决策树不需要领域知识和数值参数，能够处理多维数据，学习结果直观在设计决策树算法时需要考虑：如何确定特征测试条件（二类划分还是多类划分等）从而获得最佳切分（考量homogeneous/purity），什么时候可以终止切分（同类、早停）如果决策树的一个节点下只有一个类，这个节点就是pure的 节点的信息熵假设数据集$D$可被分为类$[1..n]$，定义节点$t$下的数据属于类$j$的条件概率是$p(j|t)$，即$$P(X = j) = p(j|t)$$由此可以定义信息熵为$$info(t) = entropy(t) = H(t) = -\sum_{j = 1}^{n}{p{(j|t)}\,log\,p(j|t)}$$ 信息熵能够描述节点的homogeneity，当熵最大（$=log\,n$）时意味着随机性越大，信息也就越少；当熵最小（=0）则相反。所有数据从根节点可以通过所属的类分为$n$部分，这种关于类别的信息熵称为数据集的经验熵，如果不利用特征建立决策树，我们只能根据经验熵得到一个数据所属类别的概率。 $$H_{j}(D) = - p(j)\,log\,p(j) \\H(D) = \sum_{j = 1}^{n}{ H_{j}(D) }$$ 也可以定义关于特征$A$的信息熵，其中特征$A$取值为$[1..n_A]$ $$H_{A}(D) = \sum_{j = 1}^{n_A}{ H_{j}(D) }$$ 信息增益、信息增益比和基尼指数决策树生成是一个递归的过程，通过测试父节点$t$的特征$A$，将其划分为$k$个子节点，其得到的经验条件熵要小于等于父节点集合的经验熵，产生的差值为信息增益。这是符合直觉的，特征$A$的信息应当能够减少分类的不确定程度。其中$n_i$表示特征$A$取值为第$i$种时对应的数据集大小，也可写作$|D_i|$，显然$D_1 + D_2 + .. + D_n$ $$Gain_{split} = H(t) - \sum_{i = 1}^{k}{\frac{n_i}{n} H(i)}$$ 不过信息增益容易将结果分为很多个小类，因此提出了信息增益比的概念 $$GainRatio_{split} = \frac{Gain_{split}}{ H_{A}(D) }$$ 基尼指数是用来度量impurity的，例如在节点$t$上。基尼系数熵之半的函数图像差别不大，但是计算要简单很多，所以很常用 $$Gini = 1 - \sum_{j = 1}^k{p(j|t)^2}$$ 使用基尼系数分类具有相似的规则，同样是为了使得“增益最大”，所以可以求下面式子的argmax $$Gini_{split} = Gini(t) - \sum_{i = 1}^{k}{\frac{n_i}{n} Gini(i)}$$但通常而言是直接求argmin $$Gini_{split} = \sum_{i = 1}^{k}{\frac{n_i}{n} Gini(i)}$$ 当数据是均匀分布在所有类上时，基尼系数取最大值$1-1/n$，当数据值集中在一个类上时（更为有趣的信息），基尼系数取最小值0。 决策树训练由周志华教授的《机器学习》P77，当信息增益出现平票时可以任意选择。此外还有一种情况，当最后没有其他属性，只能进行多数表决时，出现平票也是随便选。 欠拟合与过拟合欠拟合表现为模型太简单，训练集误差(Re-substitution errors)和泛化误差(Generalization errors)都很大。过拟合表现为模型对新数据的泛化能力较弱，模型过于复杂。为了估算泛化误差，可以使用Reduced error pruning方法，即使用验证集来估算。奥卡姆剃刀法则，复杂的模型有更大的几率是拟合了数据里面的误差，因此在选择模型时应当考虑模型复杂度。常用的解决过拟合的办法有早停策略，对于决策树来说可以在决策树彻底生成前停止算法，即预剪枝；还可以在决策树生成后进行处理，例如后剪枝。 缺失值处理贝叶斯分类器朴素贝叶斯算法相对决策树和部分神经网络算法要快，对于大数据更准确，基于贝叶斯定理$$P(H|X) = \frac{P(X, H)}{P(X)} = \frac{P(X|H) P(H)}{P(X)}$$ 其中$X = (x_1, …, x_n)$是数据集中的一个向量，$H$是有关分类的假设，例如$P(C_i|X), i \in [1, m]$表示$X$为类$C_i$的概率。$P(H|X)$是后验概率，$P(H)$是先验概率。对于未知向量$X$，朴素贝叶斯算法要求找到最大化$P(C_i|X)$的类$C_i$$$P(C_i|X) = \frac{P(X|C_i) P(C_i)}{P(X)} \quad for \, i \in [1, m]$$其中$P(C_i)$来自先验假设或根据数量统计得到，$P(X)$也是先验的，是个常数，所以有的时候并不考虑这个分母。在Class conditional independence假设下，$P(X|C_i)$计算变得简单很多，只需要对$X$中的每个属性$x_k$分别计算即可$$P(X|C_i) = \prod_{k = 1}^{n}{P(x_k | C_i)}$$例如计算$P([rain, hot, high] | Yes)$，就可以计算$$P(rain | Yes) \, P(hot | Yes) \, P(high | Yes)$$然后可以得到$$P(Yes | [rain, hot, high]) \propto (P(rain | Yes) \, P(hot | Yes) \, P(high | Yes)) P(Yes)$$ 分类评估我们定义$TP$、$TN$、$FP$、$FN$分别为真正例、真反例、假正例、假反例。这里$T$、$F$表示预测和真实值是否相同，$P$、$N$表示我们的预测结果是正例还是反例。令$U = TP + TN + FP + FN$为样例总数由此可以派生出一系列评价指标：accuracy/recognition rate是所有的$T$比上总数$U$；error rate是所有的$F$比上总数$U$。衡量了整个分类器在正反例上的准确度。查准率precision是$TP$比上预测结果中所有的$P$($ = TP + FP$)，也就是所有预测的正例中正确的比率。查全率、敏感度recall为$TP$比上真实情况下所有的$P$($ = TP + FN$)，也就是所有正例中被预测出的比率specificity是$TN$比上真实情况下所有的$N$，也就是所有反例中被预测出的比率$F_1$值为precision和recall的调和平均 Holdout方法包括交叉验证和留一法 Alternative Classification支持向量机神经网络Lazy Learning集成学习Basic Clustering聚类分析包含Partitioning、Hierarchical、Density-based和Grid-based方法。 k-meansk-means的目的是最小化簇内方差$$E = \sum_{i = 1}^{k}{ \sum_{p \in C_i}{EuclideanDistance(p, c_i)^2} }$$这个问题是NP难的，k-means使用的贪心的方法不保证最优解，其步骤是： 选择$k$个簇的中心 将数据点分配到距离最近的中心对应的簇 使用每个簇中点的均值更新中心 重复2-3直到收敛 初始值确定一般可以取$k = \sqrt{n/2}$，或者使用Elbow method$k$值确定后可以使用Sampling或Pick “dispersed” set of points（选择到已选点最小距离最大的点）方法来取出$k$个中心点 由此可以看出k-means方法对初始化很敏感。并且有的数据是没有定义均值的，这时候可以选择使用k-modes。此外k-means对离群点和噪音和敏感。 对于大数据集，可以采用采样、micro-clusters、additional data structure来实现scalability k-medoids和PAM方法由于k-means对噪声很敏感，所以引入了k-medoids，它并不是用均值，而是用数据集中的一个代表点来表示集群的中心 $$E = \sum_{i = 1}^{k}{ \sum_{p \in C_i}{EuclideanDistance(p, o_i)^2} }$$如上式，$o_i$是簇$C_i$的代表点。该算法流程如下： 选取$k$个代表点 尝试使用非代表对象$o_{random}$替换代表点$o_1 .. o_k$，假设正在替换某代表点$o_j$，则更新其代价函数 对于所有的对象重新进行分配，并计算交换总代价。如果总代价小于0，则接受这次替换，否则维持$o_j$不变 对于大数据可使用CLARA、CLARANS等方法 agglomerative clusteringdendrogram图，类似一个从底部构建的二叉树。Hierarchical Clustering的优点是不需要预测簇的数量，并且往往能和一些分类学的知识建立联系。agglomerative方法是自底而上地不断merge，divisive方法是自定而上的不断split基础的算法应用一个proximity matrix描述两个簇之间的相似度 agglomerative的方法也有缺陷，例如簇之间merge的结果不能取消，没有像kmeans一样针对目标函数优化，三种簇间距离的度量方法各有缺陷 度量两个簇之间的距离 两簇间最相近的两个元素的距离：对噪声和离群点敏感 两簇间最相异的两个元素的距离：减少了集群半径的增加，容易打破大的集群 每个点对间距离的平均：对噪声和离群点不那么敏感，Biased towards globular clusters divisive clustering和最小生成树DBSCANDBSCAN是基于密度的方法，将所有的点分为三类 Core 在集群中，且neighborhood是dense的（Eps-MinPts条件） Border 在集群中，但neighborhood不dense Outlier 不在集群中 可以做出下面的讨论 从$q$直接密度可达$p$ 当$p$在$q$的Eps-neighborhood内，并且$q$是一个Core 从$q$密度可达$p$ 存在对象链$p_1, .. , p_{n-1}, p$，其中$p_{i+1}$直接密度可达$p_i$ $p$和$q$密度连接 存在一点$o$从$p$和$q$都密度可达 因此算法流程如下： 标记所有节点为未读 选取随机未读节点$p$并标记 如果$p$是一个Core，则包含所有密度可达$p$点的点$p’$建立一个新的簇 如果$p’$未访问，把$p’$加入簇，并递归。 如果$p’$已访问，但不属于任何簇（之前被标记为噪音了），把$p’$加入簇。 通过以上的两点可以保证点$p’$如果在Eps-neighborhood内有一个Core点$q$，那么即使$p’$本身不是Core，在一开始被划为Noise，最后也能正确地被分到对应的簇中。 否则标记$p$为噪声 DBSCAN对参数取值敏感 OPTICS聚类评估Clustering Tendency数据集是否根据一个均匀分布产生的Hopkin Statistics Cluster Quality外在方法外在方法通过把聚类(cluster, $C$)和基本事实(catagory, $L$)比较 Cluster Homogeneity：簇的纯度 Cluster Completeness：如果在基于基本事实，两个对象属于同一catagory，那么他们应当属于同一个簇 Rag bag：翻译叫碎布袋，即一个异类的对象最好放入碎布袋中，而不是放入纯的簇中 Small cluster preservation：将小catagory再分成碎片是非常有害的，因为它使得这些小簇可能成为噪声 BCubed precision： Correctness：等于1如果$L(o_i) = L(O_j) \Leftrightarrow C(o_i) = C(O_j)$ BCubed recall BCubed precision 内在方法内在方法通过比较簇之间分离的优劣轮廓系数Silhouette coefficient，定义$a(o)$为对象$o$到所属簇中其他对象之间的平均距离，定义$b(o)$为$o$到$o$不属于的所有簇的最小平均距离。则$$s(o) = \frac{b(o) - a(o)}{max(a(o), b(o))}$$ Alternative Clustering高斯混合模型在Fuzzy clusters和Probabilitic-model based clustering中，一个对象可以属于多个簇，按照对应的概率。高斯混合分布属于生成模型，它可以描述数据是如何从模型中产生的。 EM算法：E步骤EM算法：M步骤Biclustering对于高维数据，传统的基于距离的方法，例如基于欧几里得距离的方法是不可信的，容易被多个维度的噪音所掩盖。因此高维数据的聚类常常是用一小组属性来定义的。常见有两种高维聚类的方式，第一类是Subspace clustering methods，在高维数据的一个子空间里面搜索聚类，常见的有Biclustering；第二类是Dimensionality reduction approaches，构造一个更低维数的空间，并且在那个空间里面搜索聚类，例如Spectral Clustering Clustering with constraintsOutlier Analysis离群点，相对于normal/expected data，是指距离其他对象显著远的对象。离群点不是噪音，噪音是没有研究价值的，类似于random error或者variance离群点分为全局离群点（相对于其余数据）、情景离群点（相对于某些特定context的数据）和集体离群点。对集体离群点来说，里面的点单个考虑可能就不是离群点了。 统计学方法参数法之Univariate Outlier DetectionUnivariate Outlier Detection假设数据仅对一个指标服从正态分布。然后就可以使用3$\sigma$原则来检测一维离群点了（不过为啥要用极大似然估计呢）。还可以使用之前学过的box plot来进行可视化估计，认为在$Q1 - 1.5 \, IQR$以下和$Q3 + 1.5 \, IQR$要上的点都是离群点还可以使用Grubb’s检验（最大标准残差检验），与z-score有关 参数法之Multivariate Outlier DetectionMahalanobis距离方法$\chi^2$统计量 参数法之混合参数分布非参数法之直方图非参数法之Kernel Density Estimation(KDE)基于邻近性的方法距离方法网格方法密度方法MapReduceCluster Computing架构：backbone between racks和rack between nodesMapReduce是一种批处理算法，核心思想是Bring computation to data和Store files multiple times for reliability。 Mining Streaming data流处理查询主要有两种类型：Ad-hoc查询和Stading查询 流数据取样Bloom Filter我记得之前柳晗就和我讨论过这个算法。布隆过滤器用来检测一个数是否在集合中，对于确定性的方法而言，这通常意味着对$log(n)$的时间复杂度进行常数优化，或者对哈希函数和哈希方法进行优化。但无论如何，空间开销是免不了的。布隆过滤器牺牲了准确性，他可能造成FP假阳性，即可能认为没出现过的数出现过，但换来了空间性能的提高。算法思想很简单，将$n$个输入送给$k$个哈希函数$h_1, .., h_k$，哈希函数的计算结果将依次按位或到一个长度为$n$的bitset中，因此这个bitset中的某一位只能从0变成1。例如，假设此时bitset为$b_i$，现对于新输入$x$，判断是否出现过。然后把$x$依次送入$k$个哈希函数，如果$h_j(x) = a$，则将第$a$位设为1。注意到如果此时第$a$位为0，则说明$x$肯定没出现过，但反之不一定成立。 例如，假设此时bitset为$b_i$，现对于新输入$x$，判断是否出现过。创建一个新的bitset为$b_{i+1}$，并memset为0，然后把$x$依次送入$k$个哈希函数，将哈希的结果按位或到$b_{i+1}$上。接着比较$b_i \&amp; b_{i+1}$。如果不等于$b_{i+1}$，那么肯定没有出现过。但是如果相等，并不一定就真的出现，可能两个数对$k$个哈希函数的输出都一样。 Bloom Filter算法分析Bloom Filter时间空间复杂度相对于数据规模是常数，因此主要分析出现FP的概率。FP的概率与1的密度有关，显然1越多，越容易出现碰撞，因此可以表示为$a^k$，其中$a$表示此时1占的比例，不过碰撞概率是要略低于这个值的。我们还可以这样理解，把FP的概率近似看做对元素$x_i$哈希后输出的$k$个位置上都是1的概率$p_1$（当然有可能是重复了）。为了方便计算，我们实际考虑截至$x_i$，某一位仍然是0的概率$p_0 = 1 - p_1$。将任意一位从0变为1的概率相当于将$d$和飞镖随机扔向$t$个目标，这里的$d$相当于所有的$n$个输入通过$k$个哈希函数得到的$nk$个结果，$t$相当于bitset。目标$T_i$被指定飞镖集中的概率是$1/t$，因此所有的$d$个飞镖都没有击中目标$T_i$的概率就是$(1 - 1/t)^d$，由于$t$通常很大，可以将其改写为$e^{-d/t}$（重要极限）。 Bit Counting和DGIM算法对一个01串，在线回答问题最近的$k &lt;= N$位中有多少个1。朴素的方法需要$O(N)$的空间，每次查询需要花费$O(k)$的时间。DGIM算法能够只储存$O(log^2N)$位，在$O(log N)$的时间复杂度内给出一个大概的值，误差在50%以内，并可以进一步缩小到任意eps。算法思路是维护一个容量为$N$的线性队列，从队尾到队头按照1的个数将其划分为$m \approx O(log_2N)$个桶，每个桶中分别有$2^0, 2^1, .., 2^m$个1（0的数量不考虑）。为了方便讨论，定义桶的大小是桶里面1的数目。因此我们容易看出这个线性队列具有下面的性质： 每个桶的最右（靠近队尾）端总是1 所有的1都在某个桶中；但是0不一定，可能在桶间 每种大小的桶最多容忍有两个 下面使用该线性队列回答开始的问题：通过比较每个桶两端的位置与$k$的大小，找到$k$值所在的桶$b$，累加$b$右边所有桶的大小及桶$b$的一半大小，即为估计值。下面考虑如何维护该线性队列，考虑接受一个新比特时 首先弹出队头，并更新队头所属的桶（如果属于某个桶的话），如果此时桶里已经没有1了，就删除这个桶 如果新比特是0，则不做任何处理 如果新比特是1，则从右至左检查是否破坏性质每种大小的桶最多容忍有两个，并进行合并处理 DGIM算法分析首先可以看到我们实际上不要将整个线性表存下来，我们只需要记录每个桶两端的坐标即可，这样的坐标有$O(log_2N)$个。对于每个坐标，他的值域是$[0, n)$，因此我们需要$O(log_2N)$比特来表示它。注意由于$N$很大，所以不能理解成一个坐标用一个$O(1)$的常数空间（例如int）就好。下面分析DGIM误差的上下界 流数据聚类和BDMO算法Recommendation SystemContent Based方法注意物品的属性，协同过滤方法注意物品与用户的关系 TF.IDF考虑从文档中选择关键词来最好地概括文档，一个简单的想法是希望这个词出现的频率越来越高，这也就是TF。但其实这是不够的，因为很多助词，例如“也”、“是”这些词出现的频率很高，但却不能用来概括文档。这时候我们需要IDF来描述，也就是说一个词如果出现的文档数越多，它就越common，权重就越底。$f_{ij}$为term$t_i$在文档$d_j$中出现的频率定义$TF_{ij} = f_{ij} / max_k(f_{kj})$$n_i$为出现term$t_i$的文档数定义$IDF_i = log \frac{N}{n_i}$由此可以计算得到$TF.IDF = TF_{if} * IDF_i$ Content FilteringContent Filtering首先对每一个item建立profile，这里的profile指的是一组属性。使用余弦相似度衡量user profile$c$和item profile$s$。$$u(c, s) = cos(c, s) = \frac{c.s}{|c||s|}$$这种方法的缺点是过于专门化，它从来不推荐在user’s content profile外面的item，并且人们可能具有多个兴趣爱好。此外需要有效的办法去查找high utility的items，也就是相似度高的profile，这时候可以借助于Locality Sensitive Hashing。 Collaborative Filtering协同过滤算法的基本思路是对于用户$c$，找到其他用户组$D$和$c$的对所有item的交集给出的评分相近，然后对于新的item，基于$D$的评分估计$c$的评分。设$x$的评分向量为$r_x$，那么$x$，$y$的相似度可以用余弦相似度衡量$cos(r_x, r_y)$，也可以计算$sim$的的皮尔逊相关系数（仅对$x$、$y$都评分项计算）下面使用协同过滤算法进行预测$c$给item$s$的打分。在给item$s$打分的用户里面找出$k$个最接近用户$c$的用户，令为$D$。则$$r_{cs} = \frac{1}{k \sum_{d \, in \, D}{r_{ds}}} \\r_{cs} = \frac{ \sum_{d \, in \, D}{sim(c, d) \, r_{ds}} }{ \sum_{d \, in \, D}{sim(c, d)} }$$协同过滤算法的计算$D$是比较昂贵的，对于每个用户，需要线性的时间。此时我们可以同样借助Locality Sensitive Hashing。此外可以使用MapReduce来计算协方差矩阵，我记得当时参加第一节云计算大赛的时候的技能题就有一条是这个。刚才的算法是基于用户的，user-user协同过滤，也有item-item协同过滤，对于item$s$，找到相似的items，当然这里还是使用对相似item的rating而不是对用户的rating，因此可以使用相同的矩阵和预测函数。在实践上item-item的常优于user-user的。 Locality Sensitive Hashing在之前提到的两种算法中提到了Locality Sensitive Hashing这个算法可以用来快速的找到高相似度的向量对（例如各种profile）Locality Sensitive Hashing属于一种Approximate Nearest Neighbor Search方法Locality-sensitive family是一组可以组合起来将向量按相似度区分开的函数。这些函数在统计上是彼此独立的。他们的速度要比遍历所有向量对来得快，并且能够被组合起来解决FP和FN问题。 $(d_1, d_2, p_1, p_2)$敏感表示： 如果$d(x, y) \le d1$，则$h(x) = h(y)$的概率至少为$p1$ 如果$d(x, y) \ge d2$，则$h(x) = h(y)$的概率至多为$p2$ AND、OR of Hash functions给定family$H$，从$H$中选择$r$个函数构造family$H’$。对于$H’$中的$h = [h_1, .., h_r]$： $h(x) = h(y)$当且仅当对于任意的$i$都存在$h_i(x) = h_i(y)$ 这是AND构造，指的是这$k$个哈希值里面要全部相同，才会被投影到相同的桶内 AND操作能够使得保持$p1$较大时$p2$更小，即降低FN 相应的定理是如果$(d_1, d_2, p_1, p_2)$敏感的，那么$H’$是$(d_1, d_2, p_1^r, p_2^r)$敏感的 $h(x) = h(y)$当且仅当对于存在一个以上$i$使得$h_i(x) = h_i(y)$ 这是OR构造，指的是这$k$个哈希值里面有一对以上相同，就会被投影到相同的桶内 OR操作能够使得$p1$较小时$p2$更大，即降低FP 相应的定理是如果$(d_1, d_2, p_1, p_2)$敏感的，那么$H’$是$(d_1, d_2, 1-(1-p_1)^r, 1-(1-p_2)^r)$敏感的 Amplify LS family考试内容2017 列出数据的种类（Nominal等）。解释Mean、Medoid等。 简述缺失值处理方法。简介PCA。 简述支持度等概念。证明Apriori性质。 比较Apriori和FP-Growth的性能。使用Apriori计算频繁项集。 为什么Naive Bayes是Naive的。如何基于Gini系数构建决策树。 使用BP计算神经网络 k-means有哪些缺点。DBScan。什么是dendrogram，如何度量两个簇的距离 协同过滤和内容过滤的区别是什么。什么是$(d_1, d_2, p_1, p_2)$敏感。证明（类似Excecise 2）。]]></content>
      <tags>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++仿函数的作用实现]]></title>
    <url>%2F2017%2F11%2F17%2FC%2B%2B-functor%2F</url>
    <content type="text"><![CDATA[仿函数(functor)，实际上是一个定义了运算符operator()的类。123456struct Foo&#123; void operator()(const int &amp; x) &#123; &#125;&#125;; 仿函数不是函数，std::is_function返回false_type。 Functor Adaptorstd::function的实现《STL源码解析》一书首先介绍了诸如binary_function、unary_function之类的，注意到里面诸如argument_type、result_type的成员都在C++17中被deprecated了，原因是现在C++中的完美转发和decltype已经能够很好地解决这个问题了，所以我们不要计较这个细节。&lt;functional&gt;中还定义了诸如plus、minus、multiplies、divides、modulus、negate等数学函数和诸如equal_to、less等比较函数，我们常见是用法是作为一个predicate，也就是sort(v.begin(), v.end(), greater&lt;int&gt;());，此外还实现了一些函数式的函数，例如identity、select（类似car或者head）、project等。 类型擦除说到std::function的实现，必须要提一下类型擦除的机制。我们以std::any这样的机制为例，它可以储存任何形式的对象，在C++17之后由于有了构造函数的模板推导，事情不太一样了，我们可以直接用个模板，然后加一些乱七八糟的casting。1234567template &lt;typename T&gt;struct my_any &#123; typedef T value_type; my_any(const T &amp; raw)&#123; ... &#125;&#125; 不过我们不考虑这些，因为我们假设std::any是一个非模板类，那么我们现在就面临如何存储的问题，一种方法是用void *，不过这样会丢失类型信息。1234567struct my_any &#123; void * ptr = nullptr; template &lt;typename T&gt; my_any(const T &amp; raw)&#123; ... &#125;&#125; 于是我们引入一层间接，也就是将实际盛放T的模板类holder&lt;T&gt;继承一个placeholder，于是我们就可以通过操作placeholder来操作holder&lt;T&gt;了。与此对应的机制还有智能指针实现中著名的T: public enable_shared_from_this&lt;T&gt;，具体可以查看我的博文1234567891011121314151617181920class placeholder &#123; virtual ~placeholder()&#123;&#125; virtual const std::type_info &amp; type() const = 0; virtual placeholder * clone() const = 0; &#125;; template&lt;typename T&gt; class holder : public placeholder &#123; holder(const T &amp; value): held(value) &#123;&#125; virtual const std::type_info &amp; type() const &#123; return typeid(T); &#125; virtual placeholder * clone() const &#123; return new holder(held); &#125; public: T held; &#125;; std::function中的类型擦除为什么std::function中会需要类型擦除呢？首先我们知道C++中的Callable或者说Invokable的对象主要有函数指针、函数对象和lambda几类，而这三个的类型不尽相同，lambda更是每一个lambda都具有一个类型。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Kickstart 2017 Round C题解]]></title>
    <url>%2F2017%2F11%2F14%2FKickstart2017C%2F</url>
    <content type="text"><![CDATA[C轮感觉比校招笔试轮次的DE要简单点了，这次有四道题都很有意思。 A. Ambiguous Cipher题目就是要解一个模意义下的线性方程。由于加减乘对模运算是封闭的，所以可以直接解。注意解下来的结果还要模一下26。用numpy搞了一波，特判下奇异矩阵，对应无穷多解的情况。AC代码 B. X Squared一开始找规律觉得只要除了允许其中一行和一列拥有一个叉，其他的每个行列必须有且只有两个叉。结果果断WA了，对拍下看看 5 .X..X ...XX XX... ..X.. X..X. 上面的这个样例输出POSSIBLE，但实际上却是IMPOSSIBLE的，看来我的条件只是必要条件。还能加上啥条件呢？初等变换得到的矩阵都是等价的，不过看来这性质用不上。然后发现之前的性质挖掘不彻底，事实上矩阵在任意行列互换后位于同行/列的元素依然位于同行/列，于是矩阵中一定存在两行中的两个X的距离是相等的。果断又WA了，后来发现不仅距离要相等，而且是要平行的。AC代码 C. Magical Thinking小数据$N=1$，感觉是送分啊。直接看大数据，$N \le 2$。想了一会儿方程，发现是DP。其实思路很简单，$dp[i][r1][r2]$表示到第$i$个题目前同学1对了$r1$条且同学2对了$r2$条时自己可能获得的最多分数。根据$N$取值可以分别分4、2种。而得分$s[0..1]$的作用就是当$r1 \ge s[0]$时他这条就不能再对了。但是代码在小数据上都卡了很久。最后发现原因是出现了dp[2][6]这样的值，为什么进行到2的时候能对6个呢？将里面r1的循环改成了r1 &lt;= min(s[0], i)，就AC了。AC代码 D. The 4M Corporation]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>codejam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++内存对齐与多态]]></title>
    <url>%2F2017%2F11%2F08%2FC%2B%2B-align%2F</url>
    <content type="text"><![CDATA[最近在看Inside the C++ Object Model，一种日经面试题，求sizeof(A)12345678910struct A&#123; char c; int i; long long ll; int j; virtual void f()&#123;&#125;;&#125;;struct B&#123;&#125;; 这种题目其实考的知识点很多，包含了虚函数虚继承、内存对齐等一系列C++的语言特性。 普通情况和继承条件下的align和padding首先，int长度是不固定的，与编译器和平台有关，所以首先可以回答“不知道”。但假设是按“通常情况来计算”，于是埋头苦算。恩，出现了虚（包括构造、析构）函数就要创建虚表，在对象中会储存一个虚指针vptr，根据指令集字长定。这里可以考虑为4。但下面不能简单相加了，在实际输出下，答案是32。究其原因是C++的内存对齐机制，对齐要求来自于一些CPU的架构、编译器或者系统设计上的考虑，在对齐的存储下，有些存储操作是原子的，所以可以很快。根据标准，对齐应该遵守下面的规则： 每个成员应该对其到它的大小，即开始位置应当能够被其size整除 因此如果一个struct中一个成员不能对齐到对应的size，那么就需要在前面一个成员后面加padding。因此我们发现struct中所有字段的顺序不一样，其大小也会不一样。 整个struct按最大成员大小进行对齐在对齐的情况下，对象的大小也会改变。根据Inside the C++ Object Model Ch1.3中的注解，一个class object的大小包括其non-static data members的总大小，加上保持alignment时需要padding上去的空间（在members之间以及在objects之间），以及维持虚函数等的开销。因此上面的结构等价于12345678void * vftable; // 4char c; // 5char gap[3]; // 8int i; // 12char gap[4]; // 16long long ll; // 24int j; // 28char gap[4]; // 32 根据Inside the C++ Object Model Ch3.1，一个空的struct仍有1字节，这是为了保证其实例化得到的所有对象能在内存上拥有自己独有的地址，我们发现这里没有为这个空的struct加上padding。但正如下面即将看到的一样，这个1字节在使用虚继承时可以被去掉。 虚继承下的align和padding下面我们看看复杂一点的虚继承。为了避免在菱形继承中A出现两份的X拷贝，进而出现二义性的问题，可以使用虚继承。虚继承中对于给定的虚基类，无论该类在继承体系中作为虚基类出现了多少次，只继承一个共享的基类子对象，这样菱形继承中的二义性问题也能够解决了（但普通多继承并没有解决）。下面看看Inside the C++ Object Model上的这段菱形继承代码，它的大小如何？1234class X&#123;&#125;;class Y: public virtual X&#123;&#125;;class Z: public virtual X&#123;&#125;;class A: public Y, public Z&#123;&#125;; 作者指出应当为1 8 8 12，但也同时指出有些编译器（译者指出例如MSVC）会产生1 4 4 8。首先X有1的开销这是毫无疑问的。下面的Y大小为8。首先Y虚继承了X，所以还需要一个4字节的指针，指向虚基类的X大小为1字节的子对象。这是类似于vftable指针的机制，称为vbtable指针。然后X的1字节的占位符也被继承下来到了Y对象中，这里译者的图应该错了，不然没有办法解释后面A也能算空类，为啥不给A加上1字节。最后，我们为已有的5字节加上3字节的padding，总共有8字节。考虑A，它拥有12字节，这包括Y和Z的子对象中除X以外的部分，各4字节（注意不是8字节，由于X被共享了，这也是虚继承的核心思想）。现在在加上被共享的X的1字节，共9字节，加上padding共12字节。Inside the C++ Object Model指出此时A自己的大小是0字节。MSVC优化掉了空类X占用的1字节开销，这样Y最后的3字节的padding也不需要了，因此只保留了一个指针。 虚函数+虚继承虚函数和虚继承可能同时出现。 控制对象对齐方式对齐要求源自CPU的一些指令需要传入的地址满足能整除某个值。 C语言中的规定有的时候我们需要禁用对齐功能，例如我们需要将某个struct按照二进制格式进行传输或者存储，这时候我们需要严格的、紧缩的大小，而不是加上一个和具体对齐方式有关的padding占用空间。在g++中可以通过__attribute__((__packed__))来禁止编译器进行优化对齐。packed属性可能是不安全的，因为它会导致非对齐访问。注意这里要区分packed和aligned，aligned(x)强调的是我对象所在的地址应当至少以x字节对齐，为了对齐会导致padding的加入，从而改变内存布局。packed会禁用padding。因此会产生__attribute__((packed, aligned(4)))这样的奇怪用法。 C++11标准中的规定C++11提供了一系列控制对齐的功能，其中alignof能够求出对应类型的对齐，std::alignment_of是标准库对alignof的封装，具有size_t类型12345template&lt;class _Ty&gt; struct alignment_of : integral_constant&lt;size_t, alignof(_Ty)&gt; &#123; // determine alignment of _Ty &#125;; 指针与对齐考虑一个多继承的情况12345678910111213141516171819202122struct BA&#123; int a;&#125;;struct BB&#123; double b;&#125;;struct D : public BA, public BB&#123;&#125;;int main()&#123; D d; D d2; D * pd = &amp;d; B1 * pb1 = &amp;d; B2 * pb2 = &amp;d; int * pi = reinterpret_cast&lt;int*&gt;(&amp;d); pd == pb1; // true，指向同一对象 pb1 == pb2; // CE，虽然指向同一对象，但两个指针类型都不等于对象类型（即使有继承关系） pi == pd; // CE，虽然指向同一对象，但两个指针类型都不等于对象类型&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Kickstart 2017 Round E题解]]></title>
    <url>%2F2017%2F11%2F06%2FKickstart2017E%2F</url>
    <content type="text"><![CDATA[E轮是Google的校招笔试轮次了。 A. Copy &amp; Paste求通过三种操作构造一个字符串S的最少操作次数 在生成串尾部添加一个字符 将生成串的一个子串拷贝到剪贴板 将剪贴板中的内容添加到生成串尾部 可以贪心么？考虑$abcabcabab$，复制$ab$其实和复制$abc$再复制$ab$一样好（之前算错了），所以尽可能地多复制即可。即在位置$i$处时，尝试在$[0, i)$中找到最长的$[j, j+len)$等于$[i, i+len)$。然而这个思路是错的，考虑下面的$’a’*11$字符串，最好的方法是等到3个再复制，比上面的按2的幂复制要少1次。正确的解法是DP，表示字符串完成状态需要一维数组，如何表示剪贴板的状态呢？再加两维数组。$dp[i][ps][pl]$表示完成第$i$个字符时，剪贴板的内容为$[ps, ps + pl]$时至少需要多少操作。Naive的方法是根据不使用剪贴板、使用当前剪贴板、更新剪贴板并使用三种情况进行讨论。由于更新剪贴板需要一个二重循环，所以在认为字符串判等是常数时间下，复杂度为$O(n^5)$。为了降低复杂度，可以使用另开一个数组，或者使用$dp[i][0][0]$来表示所有$dp[i][ps][pl]$的最小值。因为我们肯定是使用最小值来更新的。这样复杂度就变成了$O(n^3)$了。AC代码 B. Trapezoid Counting梯形(trapezoid)是有且仅有一条平行边的凸(convex)四边形(quadrilateral)，等腰(isosceles)梯形是两非平行边长相等的梯形。有一堆木条，要求从中选4个拼成一个等腰梯形，问有多少组方案。注意长度相等的两根木条仍然被认为是不同的木条。很straightforward的题目了，首先梯形成立条件是短三边和大于最长边。然后讨论三种情况$2i+1j1k$、$2i+2j$（不可行由于是矩形）、$3i+j$。小数据挂了一发，因为$3i+j$没有判断梯形成立条件。AC代码后来看别人的题解发现其实$O(n^3)$是可以被卡掉的（Google还是比较仁慈的，毕竟不是ACM）。 C. Blackhole用三个半径相等的球如何将三个点覆盖。the total set of points covered by at least one sphere must form a single connected area这句话是啥意思？小数据由于只在一条线上，直接除以6就可以了。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>codejam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Kickstart 2017 Round G题解]]></title>
    <url>%2F2017%2F11%2F05%2FKickstart2017G%2F</url>
    <content type="text"><![CDATA[Google Kickstart 2017 Round G，当时参加了Google招聘的云中讲堂，建议我们刷一刷Round G。然后就被虐了，只过了A和BC的小数据，55分Rk338滚粗。今天重新做了下，发现其实并不是很难，关键还是手速和脑子要快。 A. Huge Numbers首先快速幂算阶乘的时候用了&lt; n，完美地WA了两发，快速幂过了小数据，用祖传的公式过了大数据。$$A^x = A^{x mod \phi(c) + \phi(c)} (mod c) \\x \ge \phi(c)$$后来看题解发现可以将$A^{N!}$展开成$$A^{1^{2^{3…}}}$$的形式，然后递归地来做。AC代码 这边额外说一下这个$\phi$函数，也就是欧拉函数，表示小于n的与n互质的数的数量。欧拉函数的计算有如下公式$$\phi(n) = p^k - p^{k - 1}$$其中$p$表示$n$的所有质因子。为了理解这个公式，我们首先假设$n$可以表示为一个p的k次幂。那么与$n = p ^ k$不互质的数就是所有的p的倍数，这样的数有$p ^ k / p$个。下面我们可以通过中国剩余定理得到欧拉函数是积性的，也就是说$\phi(i*j) = \phi(i) \, \phi(j)$。不过在日常编码中，我们常使用递推来求欧拉函数。 B. Cards Game有N个卡片，正反各有一个正整数。玩家初始分数0分，每次选两张卡片，分别将其中一张的正面和另一张的反面异或，并将结果加到总分上。结束后将一张卡片丢弃，另一张放回，由此重复一直到只有一张卡片。求最终最小的分数。没有经受住过小数据的诱惑，直接爆搜了下，复杂度$O(2^N * N^2)$。查看题解，题解使用图论的观点来看，由于每次操作都有一张卡片被消去，我们假设卡片$i$被$j$消去，可以看做从$i$到$j$存在一条边。于是恍然大悟，这条就是个最小生成树啊，套个模板就出来了。注意大数据需要用LL。AC代码 C. Matrix Cutting有一个N*M的矩阵，现在按照行或列切分矩阵，每次讲一个大矩阵切分为两个小矩阵，就奖励原矩阵中的最小值对应的分数。整个过程一直以得到N*M个1*1的矩阵为止，求可能得到的最多分数。这条小数据只有一行哎，于是暴搜（都可以不加记忆化）过了小数据。大数据看起来有可以用二维线段树做，不过由于本人还是太弱，所以最后没时间做了。后来发现可以直接套用二维记忆化搜索强行莽掉。AC代码在实际跑的时候，常数太大了，我用VS开Release才能在6分钟左右算完。我打算写一个CodejamSolver来多线程跑，然后再join。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>codejam</tag>
        <tag>数论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haskell编程实战]]></title>
    <url>%2F2017%2F10%2F17%2FHaskell%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[在学习完Haskell学习笔记后，在使用Haskell编程时需要用到的技巧 调试可以使用import Debug.Trace来调试，他可以加在表达式里面，有点像$的作用。 trace :: String -&gt; a -&gt; a 1solve triangle len i = trace ("i is " ++ show i) zipWith max choice1 choice2 常用的模组模组是类似于库，Prelude是自动import的模组。可以使用import导入其他模组，在GHCI中可以使用:m导入。这类似于Python中的from X import *可以在括号中选择导入某些模组 import Data.List (sort) 使用hiding可以选择不导入某些函数 import Data.List hiding (nub) 或者使用qualified强制使用全部限定名，类似于Python中的import X import qualified Data.Map 也可以为前面的限定名起个别名，类似于Python中的import X as Y import qualified Data.Map as M 动态规划比较方便的是动态规划每次迭代时传入dp数组，并且返回本次迭代后的dp数组 Rank-N types在使用支持了Existential Quantification扩展的Haskell时，查看map的定义，可以看到forall关键字，它表示对于任意的，即∀。 map :: forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>Haskell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Win10“目录不是空的错误”解决方案]]></title>
    <url>%2F2017%2F10%2F16%2FWin10%E7%9B%AE%E5%BD%95%E4%B8%8D%E6%98%AF%E7%A9%BA%E7%9A%84%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[昨天帮助别人解决了一起在删除文件夹时出现的“错误0x80070091：目录不是空的”的问题。 问题由来使用移动硬盘从电脑上复制了配置好的hadoop文件夹，之后试图删除该文件夹时出现错误。hadoop-2.8.0\share\hadoop\httpfs\tomcat\webapps\webhdfs\WEB-INF\lib目录无法删除，提示以上错误。尽管里面的文件已经清空。 问题解决根据百度经验上的提示，在管理员权限下运行了rmdir命令，但是并没有作用。在资源管理器中结束了持有相关句柄的进程，亦无效。灵机一动，它既然提示不是空的，那我就真让它不是空的，于是填了一个文件进去，该目录遂被删除。]]></content>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微软2017年预科生笔试第二场]]></title>
    <url>%2F2017%2F10%2F14%2F%E5%BE%AE%E8%BD%AF2017%E9%A2%84%E7%A7%91%E7%94%9F2%2F</url>
    <content type="text"><![CDATA[微软2017年预科生笔试第二场的题目比9月份的校招要难一点。 hiho1497 Queen Attack为了不MLE，需要按点判断，二分即可代码 hiho1498 Diligent Robots这道题目思路也不复杂，首先机器人肯定是越早造越好，因此早期我们投入全部能力造机器人。假设机器人数量为$R$（包括一开始的一个），需要时间 $$T = T_{build} + T_{work} \\T_{build} = q \, \lceil log_{2}R \rceil \\R_{idle} = 2^{\lceil log_{2}R \rceil} - R \\T_{work} = \frac{n-q \, R_{idle}}{R}$$下面就可以枚举$R$，注意由于任务数取值$n$可能到1000000000000，因此单纯的枚举会超时。但事实上可以证明$R$可以只取2的整数幂，即最后一轮的复制也不存在让一群机器人去复制，另一部分去工作的，假设第$X$轮复制时已有$R$个机器人和$n$个任务，如果让所有的机器人参与复制则到全部完成工作耗时$$T_{all} = \lceil \frac{n}{2 \, R} \rceil + q$$让$S$个机器人参加工作$$T_{R - S} = \lceil \frac{n - S \, q}{2 \, R - S} \rceil + q$$特别地，让所有机器人参加工作（此情况等于最后一轮为$X-1$的情况，可以不考虑）$$T_{none} = \lceil \frac{n}{R} \rceil$$通过解不等式，可以发现不管怎么样全复制都是好的。这里说明一下若$\lceil a \rceil &gt; \lceil b \rceil$，那么$a &gt; b$。由定义$[a] + 1 &gt; [b] + 1$，则$[a] \ge [b] + 1 \gt [b] + (\lbrace b \rbrace - \lbrace a \rbrace)$，即$a &gt; b$。代码 hiho1499 A Box of Coins]]></content>
      <tags>
        <tag>ACM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数理统计复习]]></title>
    <url>%2F2017%2F10%2F11%2F%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%A4%8D%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[辨析了数理统计中的一些重要的基本概念与定理。 样本、总体、样本观测值和统计量有什么区别总体记为$X$样本是从总体中通过抽样方法（例如简单）获得的统计量是关于样本的函数，并且不包含任何未知的参数。对样本$X_i$观测产生观测值$x_i$，对统计量$g(X_1, X_2, …, X_n)$观测产生观测值$g(x_1, x_2, .., x_n)$ 样本方差为什么分母是$n - 1$方差可以表示为$D(X)$、$Var(X)$、$\sigma^2$，没有区别。$\sigma^2$常用来表示总体方差首先回顾方差定义$$\sigma^2 = \mathbb{E}[(X_i - \mathbb{E}[X])^2]$$这里$E(X)$也可记作$\mu$，等于总体均值（期望），也等于样本均值的期望。现在我们估计样本均值（期望）$\bar{X}$，显然$$\bar{X} = \frac{\sum{X_i}}{n}$$下面试图估计样本方差$S$，其定义为$$S^2 = \frac{\sum{(X_i - \mu)^2}}{n}$$为什么定义的时候用$\mu$而不是$\bar{X}$呢？主要是这样下来对总体方差$\sigma^2$的估计是无偏的。这时候发现$\mu$还不知道，很自然会想到能不能用$\bar{X}$代替，这种是没有修正过的方差$S_1$，经过计算比较$$\mathbb{E}S_1^2 = S^2 - Var(\bar{X}) \\\frac{\sum{(X_i - \bar{X})^2}}{n} = \frac{\sum{(X_i - \mu)^2}}{n} - (\mu - \bar{X})^2$$可是$\bar{X}$只是样本期望而不一定等于总体期望，所以实际上估计值是要小的。因此在修正后可以得到$$S^2 = \frac{\sum{(X_i - \mu)^2}}{n} = \frac{\sum{(X_i - \bar{X})^2}}{n - 1}$$这两个估计都是无偏的，但使用$\mu$比$\bar{X}$有效 实际上，用极大似然估计来估计$\sigma^2$得到的就是有偏的$\frac{\sum{(X_i - \bar{X})^2}}{n}$ $\chi^2$、$t$、$F$分布到底是做什么的矩估计和极大似然估计有何异同参数估计是指的总体$F(x, \theta)$已知情况下如何通过样本估计出未知参数值$\theta$点估计的思想是构造统计量$\hat{\theta}(X_1, X_2, .., X_n)$，通过其观察值$\hat{\theta}(x_1, x_2, .., x_n)$来估计位置参数$\theta$。包括了矩估计和极大似然估计。矩估计的思想是用样本矩$A_k$估计总体矩$\mu_k$，这是由大数定律得到的性质。$k$表示第$k$阶矩，与未知量$\theta$是有关的。首先回顾一下，期望可以看做一阶原点矩，方差可以看做二阶中心距。于是我们的$A_k = \mu_k$便可以化为关于总体分布中参数$\theta$的值和样本期望、方差等属性的方程。最后就可以用样本期望、方差去表示出要求的$\theta$。但是出于简便考虑，当只有一个未知数时，选用一阶原点矩和样本期望是很合适的，而且方便计算。当出现两个未知数时一般额外选择二阶原点矩，然后可以应用公式$E(X^2) = E^2(X) + D(X)$转换成方差例如对于样本$X_1, X_2, .., X_n$，估计$\mu$和$\sigma^2$ $$\mu = \bar{X} \\\sigma^2 + \mu^2 = \frac{1}{n} \sum_{i = 1}^{n}{X_i^2} \\\sigma^2 = \frac{1}{n} \sum_{i = 1}^{n}{(X_i^2 - \bar{X}^2) }$$而$$\sum_{i = 1}^{n}{(X_i - \bar{X})^2 } \\= \sum_{i = 1}^{n}{(X_i^2 - 2 \, X_i \bar{X} + \bar{X}^2) } \\= \sum_{i = 1}^{n}{X_i^2} - 2 \, \bar{X} \, \sum_{i = 1}^{n}{X_i} + \bar{X}^2 \\= \sum_{i = 1}^{n}{(X_i^2 - \bar{X}^2) }$$因此$$\sigma^2 = \frac{1}{n} \sum_{i = 1}^{n}{(X_i - \bar{X})^2 } = \frac{n - 1}{n} S^2$$ 极大似然估计的思想是小概率事件发生概率也小，因此如果在试验中观测到一次事件发生则这次事件发生的概率就应该最大，由此计算参数的取值。]]></content>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[帝国时代AI开发]]></title>
    <url>%2F2017%2F10%2F03%2F%E5%B8%9D%E5%9B%BD%E6%97%B6%E4%BB%A3AI%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[帝国时代2的AI是比较弱智的，因此网上出现了一些比较厉害的AI，例如Barbarian（野蛮人）、The Horde等，甚至出现了一个AI Ladder对市面上的AI进行排行。恰逢国庆，打算首先来研究一下帝国时代AI的原始DSL以及UserPatch补丁修改后增加的功能，并且结合一些著名AI探讨一些常用的手法。 Native DSL简介帝国时代2 AOK（即红帽子）版本的DSL文档可以从这里下载，翔鹰帝国提供了有点奇怪的中文翻译。此外外国一款针对1.0c版本的UserPatch加强了DSL，有了一些新的特性，目前已更新到v1.4，它的官网是userpatch.aiscripters.net。一套ai包含两个文件，.per即personality文件，包含着所有的ai部分，ai文件一般只做占位符类似的作用。如果per文件是空的，那么就会弹出一个错误，并且农民会四处跑，进行牧羊。 def语法总的来说，这份DSL类似于lisp语言，主要由下面的defrule语句构成12345(defrule (some facts) =&gt; (some action takes place) ) 一个defrule可以看做地图编辑器里面的一个触发项。下面的fact/action可以包含若干个条件/动作。rule一旦被定义，系统就会不断轮询检查是否符合facts所描述的条件，如果符合，就执行action语句。脚本不会像C++一样只采用最匹配的规则，如下面两个规则都是适用的，所以我们细化战略时，必须同时写真条件和假条件。1234567891011(defrule (cc-players-unit-type-count any-human-enemy town-center &gt;= 1)=&gt; (chat-to-all "aaa"))(defrule (current-age == dark-age) (cc-players-unit-type-count any-human-enemy town-center &gt;= 1)=&gt; (chat-to-all "bbb")) 对于一些只想执行一次的语句就可以通过最末尾的(disable-self)来禁用这条规则。除了defrule，还有defconst，用来定义常数，defconst可以重复定义（如果值相同）。 load语法这个有点类似于C++中的include了。常常针对各个民族的特点包括陆/海/游/移民等不同形式各写一套ai，然后在一个总的per文件里面针对不同情况来load。 随机加载可以通过load-random指令按照一定比率随机加载per文件，这样可以做到一定程度的随机ai。 条件加载通过#load-if-defined和#load-if-not-defined可以实现条件加载。这两个命令接受System-defined symbols，来自于开始游戏时的设定，例如初始资源选项就有LOW-RESOURCES-START/MEDIUM-RESOURCES-START/HIGH-RESOURCES-START三种，分别对应了游戏下拉列表里面的三个选项。条件加载有点类似于C++中的预处理指令，但实际上帝国时代引擎中没有预处理阶段，条件加载所包裹的指令只是不被load，但会被parse的。不加载一些rule能够有效提高性能，这样轮询的对象就会少一点。 通配符（wildcard）any-和every-可以引导通配符，其中any-引导的需要一个为真，every-引导的则需要全部为真。特别地this-any-里面有any，但实际上它是variable。通配符包括 any-ally、any-computer、any-computer-ally、any-computer-enemy、any-computer-neutral、any-enemy、any-human、any-human-ally、any-human-enemy、any-human-neutral、any-neutral、every-ally、every-computer、every-enemy、every-human、every-neutral根据科技的研究骑士可以升级为重装骑士和圣殿骑士，这时候就需要使用-line是这个通配符，knight-line表示骑士，这样我们就不需要去判断是否研究过cavalier或者paladin了。 facts、actions、parameters、variables和goal事实(facts)一般用作rule的条件。例如military-population这个fact表示自己此时的军事人口。不过我们不能把这个值取出来，只能用一个比较运算符和某个立即量进行比较，形成一个predicate。例如military-population &gt; 10。fact或action的参数称为parameter。this-引导的为变量(variable)，variable的生存空间只存在于当前规则中，并且variable都是由系统隐式定义的，例如this-any-enemy表示选定的任一敌人。那么这个this-any-enemy具体是是怎么决定的呢？这由facts中的通配符来匹配得到，例如在facts中匹配了哥特文明的任意敌人，那么下面的this-any-enemy就指的上面的敌人。123456(defrule (players-civ any-enemy gothic) =&gt; (chat-to-player this-any-enemy "I know you are a Goth") (disable-self)) 需要再次强调的是在这个规则之外，本次匹配得到的this-any-enemy就不能适用了。有没有用户能控制的全局的变量呢？最接近的应该是目标(goal)。goal可以由(set-goal goal-id value)来定义，goal-id范围一般是从1-70（HD版本），为了方便阅读，常使用defconst常数。可惜的是goal的读取很不方便，因为它只能通过(goal goal-id value)来判断是否相等，甚至连比较运算符都不支持。 定时器注意enable之后必须要disable掉当前语句，不然会一直enable导致无法trigger 关系运算符游戏难度的关系运算符是和想象相反的，即easiest&gt;easy&gt;moderate&gt;hard&gt;hardest。 策略sn-引导的为策略。城镇规模town-size指的是一个城镇建筑所覆盖的面积。 escrow预留资源escrow-amount命令可以将某一类的资源预留一部分作为储备，这样所有的资源会被分成两块，便于管理。release-escrow可以取消预留资源 AI基本操作调试我们可以看到大多数时候，变量都是不能直接获取值的，而是通过比较是否相等（goal）或者比较运算符比较（如building-type-count）实现，对这些数值的调试只能写一条defrule然后在里面判断数值输出。但是还有一类sn-开头的strategic-number，这个可以通过chat-trace这条指令输出。 使用taunt调试taunt-detected和acknowledge-taunt这两个可以实现由用户输入某个数字taunt，然后输出相应值的功能。 补人口默认1.5倍时间下，TC造一个农民大概在13秒左右，一个农民造房子大概在15秒左右，所以当人口差两个的时候就需要造房子了1234567(defrule(can-build house)(housing-headroom &lt; 2) (population-headroom &gt; 3)=&gt;(build house)) can-build会检查该building是否符合当前的文明、科技树以及资源量（减去escrow预留的资源）。不过即使不加can-build，电脑也不会在文明、科技、资源量不满足的情况下造，而是作为一次失败的build尝试。一旦一次build失败了，此趟执行的所有build x都不会被运行了，即使后来条件全部满足。类似的还有can-train和can-research，不过这两个还要注意建筑物在研究科技/造兵时被占用的问题。如果不幸卡农民了，可以升级织布机12345678(defrule (current-age == dark-age) (not (can-train villager)) (can-research ri-loom)=&gt; (research ri-loom) (disable-self)) 城镇规模(TSA)进攻一般的进攻有(attack-now)语句，该语句会造成一队士兵以编队形式过来进攻，不过有些问题，例如在编队行进过程中受到进攻也不还手。由于attack-now是一队一队地出发的，所以可以通过改小sn-percent-attack-soldiers然后多次attack-now实现多波的、相互呼应的进攻。TSA即Town Size Attack，相对于(attack-now)的直来直去，TSA进攻更分散、更操作性一点。它通过增加城镇的面积，这样己方就会对城镇面积内的敌人进行攻击。注意要区分TSA和日常随着经济发展的城镇增长，城镇增长相对TSA还要额外扩大sn-camp-max-distance和sn-mill-max-distance用以获得更多资源。为了测试，我们可以做一个场景地图。1234567891011121314(defrule (true)=&gt; (set-strategic-number sn-home-exploration-time 0) (set-strategic-number sn-maximum-town-size 255) (set-strategic-number sn-number-attack-groups 200) (set-strategic-number sn-maximum-attack-group-size 200) (set-strategic-number sn-minimum-attack-group-size 1) (set-strategic-number sn-attack-intelligence 1) (set-strategic-number sn-enemy-sighted-response-distance 200) (set-strategic-number sn-disable-attack-groups 0) (set-strategic-number sn-percent-attack-soldiers 100)) sn-attack-intelligence表示智能进攻系统。该系统尝试在攻击时躲避敌人单位，尝试从多角度进攻。配合sn-attack-coordination设为2能够实现多线作战效果。sn-disable-attack-groups会禁用自动进攻编组，TSA必须不禁用。类似的选项还有sn-disable-defend-groups。结果调试发现，首先所有的兵力沿着城镇方向散开，直到有一个军事单位发现敌人。当战斗单位还存在的时候TSA农民是不怎么参与战斗的，即使设置了123(set-strategic-number sn-allow-civilian-defense 3)(set-strategic-number sn-allow-civilian-offense 2)(set-strategic-number sn-number-civilian-militia 200) 但如果放到一个纯农民的地图里面，农民就都会上去搏。sn-percent-attack-soldiers似乎并不对TSA有作用，它仅针对attack-now命令，指的是进攻士兵占防守士兵的比例。官方说明中提到用它时最好不用sn-number-defend-groups（注意是defend）。sn-enemy-sighted-response-distance指敌人攻击自己时，什么范围内的己方单位会作出反应，为了调试效果，我们把这个值设得非常大。 sn-special-attack-type1(2/3)是个很有用的命令，它设置了首要的攻击目标（单位、建筑等），在UP的注释中却有不同的说明，当它为1时会攻击僧侣。我在论坛上确认了使用UP时UP的注释是正确的，此外原版DSL中更本就没有sn-special-attack-type2和sn-special-attack-type3与之对应的是sn-gold-defend-priority等一系列防守重要性等级策略，从0到7防守力度越来越大。 sn-number-attack-groups、sn-minimum-attack-group-size、sn-maximum-attack-group-size及sn-attack-group-size-randomness是一套指令。 修建围墙围家是帝国时代做经济的一个军事支撑，如果在前方给敌人足够压力可以借助TC和军事建筑，如果想直城或直帝则需要木头墙+石墙围一道。围墙建造第一步是enable-wall-placement这个命令，这个命令会通知将来的建筑离未来的围墙至少距离1格(tile)，因此最好在初始化中就做好。enable-wall-placement带一个参数perimeter，设为1就是小围，2是大围。build-wall是建造围墙命令1234567891011121314151617181920212223242526(defrule (true)=&gt; (enable-wall-placement 1) (disable-self))(defrule (current-age &gt;= castle-age) (stone-amount &gt; 300) (can-build-wall 1 stone-wall-line)=&gt; (build-wall 1 stone-wall-line))(defrule (or (wall-completed-percentage 2 &gt;= 20) (wall-completed-percentage 1 &gt;= 20) ) (or (can-build-gate 2) (can-build-gate 1) )=&gt; (build-gate 2) (build-gate 1)) 小围技术小围技术包含两个方面，一是如何让房子等技术修成圈，另一个是如何让农民在第一个建筑没修完时赶快桥第二个建筑 Native AI赏析之BOOM IIBOOM II ai是一个比较厉害的ai，特点是疯狂爆兵。和他打了几把，它不喜欢杀敌人的农民，后期也不会清理空闲农民（倒是UserPatch里面有个相关的清理命令），多人的时候不太喜欢在后面圈贸易，所以经济有点吃亏，黑暗时代不喜欢拉猪赶鹿可能是AI的一个通病，可能做不到这么细致。 防守塔爆GOAL-DEF-TRUCH指的是防御塔爆（defend tower rush） 塔爆状态流第一步是发现修塔，如果在封建时代前的前期（前1200秒）内探查到敌人修塔，就切换GOAL-DEF-TRUCH到7。(goal GOAL-ADDRESOURCE 1)这个条件我不太明白是怎么回事值得注意的是building-type-count和 building-type-count-total，前一个只计算现存的建筑数，后一个计算包括正在队列（正在建造）中的建筑数。注意摧毁了的建筑不会增加到这个里面。unit-type-count和 unit-type-count-total的区别也在此，不过unit-不仅对建筑用，也可以对军队等单位用。123456789101112(defrule (goal GOAL-ADDRESOURCE 1) (game-time &lt; 1200) (current-age &lt;= feudal-age) (goal GOAL-DEF-TRUCH 0) (players-building-type-count any-human-enemy watch-tower &gt;= 1)=&gt; (set-goal GOAL-DEF-TRUCH 7) (chat-to-player this-any-human-enemy "修塔...") (set-strategic-number sn-maximum-town-size 35) (disable-self)) 第二步是发现塔爆1234567891011121314151617(defrule (goal GOAL-ADDRESOURCE 1) (game-time &lt; 1000) (current-age &lt;= feudal-age) (goal GOAL-DEF-TRUCH 7) (players-military-population any-human-enemy &lt;= 1) (enemy-buildings-in-town)=&gt; (chat-to-player this-any-human-enemy "塔暴?!") (set-goal GOAL-DEF-TRUCH 1) (set-strategic-number sn-maximum-town-size 20) (set-strategic-number sn-camp-max-distance 25) (set-goal GOAL-SPECIAL-AID 1) (disable-timer TIMER-SPECIAL-AID) (enable-timer TIMER-SPECIAL-AID 300) (disable-self)) 首先需要经过第一步GOAL-DEF-TRUCH已经到7，然后敌人的军事人口应该小于等于1（相对于黑快的大于等于4），并且有建筑在城镇范围内部了。这时候切换GOAL-DEF-TRUCH到1，并且调整城镇规模，此外切换GOAL-SPECIAL-AID到1，并启动定时器TIMER-SPECIAL-AID。此外脚本对前置塔攻的情况进行了特殊处理。前置塔攻相比塔爆多了军事人口，更厉害。在处理时切换GOAL-DEF-TRUCH到2，启动SPECIAL-AID一套流程，但不调整城镇规模。第三步，检查敌人是否使用木墙或者石墙围，并根据具体情况不同重置TIMER-SPECIAL-AID为400（前置塔攻490）、900、16001234567891011(defrule (goal GOAL-DEF-TRUCH 1) (players-building-type-count any-human-enemy watch-tower &gt;= 1) (players-building-type-count any-human-enemy stone-wall &gt;= 2)=&gt; (chat-to-player this-any-human-enemy "24你死定了!!") (set-goal GOAL-SPECIAL-AID 1) (disable-timer TIMER-SPECIAL-AID) (enable-timer TIMER-SPECIAL-AID 900) (disable-self)) 下面讨论ai防御塔爆的行为，这在Defend Truch部分有定义。这些防御行为的产生条件是封建时代且GOAL-DEF-TRUCH为1，即防御塔爆状态 首先取消GOAL-FAST-ATTACK计划 如果发现有石矿，造采石场 如果能造塔，并且已造塔数小于4，那么就造塔 注意下面的造塔命令，能够粗略地控制造塔范围 123(set-strategic-number sn-maximum-town-size 12)(build watch-tower-line)(set-strategic-number sn-maximum-town-size 20) 如果每个敌人都没到城堡，如果能造塔，并且已造塔数小于8，那么反塔爆别人 这里用了build-forward命令，即前置造建筑物。 当自己到了城堡之后，如果塔还没清掉（估计是石墙搞了一波农民搏不掉），那么就造BK（siege-workshop）。下面不用多说，造攻城车（battering-ram-line）。然后就等着攻城车自己清理吧。 最后是防御塔爆的结束条件： 城堡时代、农民数大于50 时间超过1020，塔全部被清理，农民数大于28 前置塔攻就不详细讨论了，下面的是在成功防御前置塔攻之后的行为。1234567891011121314(defrule (game-time &gt; 900) (goal GOAL-DEF-TRUCH 2) (or (goal GOAL-FORCE-COMPARE 3) (goal GOAL-FORCE-COMPARE 4)) (players-building-type-count any-human-enemy watch-tower &lt;= 0)=&gt; (chat-to-player this-any-human-enemy "11") (set-goal GOAL-DEF-TRUCH 0) (set-goal GOAL-FAST-ATTACK 1) (set-goal GOAL-SPECIAL-AID 2) (disable-timer TIMER-SPECIAL-AID) (disable-self)) 防守TC暴TC暴（Douche）是种比较恶心的塔爆，玩家在黑暗自爆自己的TC，然后农民跑到对家的基地附近建TC，然后TC对射和对方耗。BOOM II对TC暴有着绝妙的应对方法，那就是不打TC暴、、、12345678910(defrule (game-time &lt; 900) (goal GOAL-PVP 1) (current-age &lt;= feudal-age) (cc-players-unit-type-count any-human-enemy town-center &lt;= 0)=&gt; (chat-to-player this-any-human-enemy "不会吧？TC暴？") (set-goal GOAL-DEF-TRUCH 3) (disable-self)) cc-players-unit-type-count是一个作弊命令，相对于不加cc-的命令，它获取玩家某一种类建筑的数目，不管自己能不能看到。这里判断如果在黑暗时代TC的数量变成0，那么对方很可能就是TC爆了。将GOAL-DEF-TRUCH改成3表示当前是TC爆。1234567891011(defrule (goal GOAL-DEF-TRUCH 3) (goal GOAL-TOWN-SIZE-ATTACK 0) (enemy-buildings-in-town) (town-under-attack) (players-building-type-count any-human-enemy town-center &gt;= 1)=&gt; (chat-to-all "不打TC暴！") (set-goal GOAL-RESIGN 1) (disable-self)) 城快进攻UserPatch v1.4简介我们发现帝国时代内置的ai命令还是比较弱的，我们很难实现一些逻辑。简单地说，删除所有闲置的农民就难以实现。为此使用UserPatch提供的增强版Scripting是个不错的选择。 UP的安装在网站userpatch.aiscripters.net上下载，里面包含一个Reference文件夹和一个exe程序。Reference里面Scripting文件夹里面的per文件是需要load进去的常量，另一个Reference.html与网上在线的Guide相同。此外，网站的论坛也能提供更详细的资料。 UP基础语法变量在Native DSL中goal的值既不能直接拿出来，也不能直接比较，UP改善了这个特性。首先引入了三个类型运算符c:、g:、s:。c:表示作为常数值，g:表示作为goal值，s:表示作为sn值。举一个例子12345678(defconst gl-slot0 100)(defrule (true)=&gt; (set-goal gl-slot0 77) (up-chat-data-to-all "gl-slot0 key is: %d" c: gl-slot0) (up-chat-data-to-all "gl-slot0 value is: %d" g: gl-slot0)) 以上rule的结果是 gl-slot0 key is: 100 gl-slot0 value is: 77 可以发现现在goal可以真正地作为变量使用了，在定义变量的时候，我们通常以gl-为前缀，这样的gl-类似于一个整型指针（只不过由我们自己规定地址），g:可以将它解引用。但是注意不能在set-goal里面用g:1(set-goal gl-slot1 g: sl-slot0) 替代方案是使用up-modify-goal。 get系列函数既然goal可以作为变量使用，那么我们肯定希望用它来保存一下有用数据，up-get-系列函数能够将我们需要的一些数据取到变量中。 get fact系列up-get-fact是最基础的get fact函数。在先前，我们不能获取military-population的值，我们只能拿它进行比较，如(military-population &gt; 10)。但现在我们可以将它保存在gl-data中了。遗憾的是似乎这个函数只能获取UserPatchConst中定义的fact，另外的一些，例如villager-hunter之类的就没办法获取。1234567(defconst gl-data 101)(defconst military-population 31)(defrule (true)=&gt; (up-get-fact military-population 0 gl-data)) 但是UP还可以为我们做更多，我们可以获得某些玩家（由every/any通配符指定）事实集合中的最大/小值以及和，如12345678910111213141516(defconst gl-my-civ-sum 101)(defconst gl-ene-civ-sum 102)(defconst gl-cmp 103)(defconst civilian-population 32) ;any(defrule (true)=&gt; (up-get-fact-sum any-enemy civilian-population 0 gl-ene-civ-sum) (up-get-fact civilian-population 0 gl-my-civ-sum) (up-modify-goal gl-cmp g:= gl-my-civ-sum) (up-modify-goal gl-cmp g:/ gl-ene-civ-sum) (up-chat-data-to-all "me is: %d" g: gl-my-civ-sum) (up-chat-data-to-all "ene is: %d" g: gl-ene-civ-sum) (up-chat-data-to-all "comparation of ene and me is: %d" g: gl-cmp)) 这个可以输出敌人的农民人口与自己的农民人口的比值，可惜是整数，这里因为我们没有探测到敌人的家，所以gl-ene-civ-sum值是0或-1，结果是0。 成本函数up-reset-cost-data将四种资源成本全部置零，例如12345678910(defconst gl-military-cost-food 111)(defconst gl-military-cost-wood 112)(defconst gl-military-cost-stone 113)(defconst gl-military-cost-gold 114)(defrule (true)=&gt; (up-setup-cost-data 1 gl-military-cost-food) (disable-self)) 当第一个参数为1的时候，将所有的成本设置为0，真是够奇葩的，为啥不搞个memset一样的呢？为什么第二个参数是gl-military-cost-food呢？因为可以把gl-military-cost-food到gl-military-cost-gold看成一个四个元素的数组，而gl-military-cost-food相当于传入了一个头指针。在使用up-reset-cost-data，其他的成本函数都是对当前选定的“数组”进行操作了。下面的代码往总成本上加了两份军事成本（每份成本包含一个骑士）123456789101112131415161718(defrule (true)=&gt; (up-setup-cost-data 1 gl-military-cost-food) (up-add-object-cost c: knight-line c: 1) (up-setup-cost-data 1 gl-cost-food) (up-add-cost-data gl-military-cost-food c: 2) (up-chat-data-to-all "wood is: %d" g: gl-cost-wood) (up-chat-data-to-all "stone is: %d" g: gl-cost-stone) (up-chat-data-to-all "food is: %d" g: gl-cost-food) (up-chat-data-to-all "gold is: %d" g: gl-cost-gold) (up-chat-data-to-all "mit wood is: %d" g: gl-military-cost-wood) (up-chat-data-to-all "mit stone is: %d" g: gl-military-cost-stone) (up-chat-data-to-all "mit food is: %d" g: gl-military-cost-food) (up-chat-data-to-all "mit gold is: %d" g: gl-military-cost-gold) (disable-self)) up-add-object-cost第一个参数表示单位id，第二个参数表示数量，相对up-setup-cost-data还有科技研发成本up-add-research-costup-setup-cost-data第一个参数表示一个goal，第二个参数表示份数up-get-cost-delta计算当前资源与建造成本的差值，负的表示不够。这个值与escrow无关。12345678910(defrule (true)=&gt; (up-setup-cost-data 1 gl-cost-food) ;(up-modify-escrow wood c:= 100) (up-add-object-cost c: archer-line c: 200) (up-get-cost-delta gl-delta-food) (up-chat-data-to-all "delta is: %d" g: gl-delta-wood) (disable-self)) 坐标代数UP提供的坐标代数能实现高级AI的精细控制，如此篇帖子。为了表示坐标，首先定义一个点对。类似于上面up-reset-cost-data操纵资源的方式，点对的地址应当是连续的（形成一个二维数组），如下面的100和101，这样gl-point-x可以看做指向该点对的指针。12(defconst gl-point-x 100)(defconst gl-point-y 101) 我们可以将gl-point-x点对设为目标点，供如up-build等命令使用1(up-set-target-point gl-point-x) up-lerp-percent和up-lerp-tiles这个用来计算坐标偏移，将第一个点对作为基点，第二个点对作为位移值进行偏移。up-lerp-tiles会偏移固定的格数，up-lerp-precent则按百分比。 up-cross-tiles我写了段代码测试了一下，并没有看出来有啥用，应该结果保存在第一个点 流程控制在同一个文件里面rules的执行可以看成是从上至下的，因此可以利用up-jump-rule来实现选择或者循环结构，但注意#load块可能影响位置。 直接寻的系统find过滤器过滤器由up-filter-distance、up-filter-exclude、up-filter-garrison、up-filter-include、up-filter-range构成注意以下命令中-1表示忽略此过滤条件 选择目标点周围10个内单位：(up-filter-distance c: -1 c: 10)，其中两个参数分别为最小距离和最大距离 派出具有某个编号的单位：(up-filter-exclude cmdid-trade -1 -1 -1)，其中四个参数分别表示命令编号、行动编号、执行编号和类别编号。例如(up-filter-exclude -1 actionid-explore orderid-relic warship-class) 选择驻扎了至少5个单位的建筑：(up-filter-garrison c: 5 c: -1)，两个参数同样是最大值和最小值 up-filter-include这个和exclude是相似的，不过第四个参数改为了是否在主大陆上 一般重置需要同时重置search结果和过滤器，即12(up-reset-search 1 1 1 1)(up-reset-filters) 使用直接寻的系统找到的对象可以利用up-set-target-object设为目标，然后通过up-object-data等语句对目标进行操作，下面的语句摘自拉猪部分12(up-set-target-object search-local c: 0)(up-object-data object-data-hitpoints &lt; 40) 人员控制包括驻扎、巡逻、删除冗余人员 驻扎up-gather-inside可以指定建筑生产集合点是自己本身。这在操作的时是很有用的一个特性，一方面敌人不容易观察你到底生产了什么，第二个单位不至于瞎跑，或者被泼粪车泼到。1234567891011(defrule (true)=&gt; (up-gather-inside c: dock c: 1) (disable-self))(defrule (unit-type-count warship-class &gt;= 10) ; warship-class = 922=&gt; (up-gather-inside c: dock c: 0)) 直接驻扎的命令是up-garrison，如1(up-garrison battering-ram c: infantry-class) ; infantry-class = 906 将所有步兵驻扎到工程车中，注意指定建筑不能使用battering-ram-line这种带wildcard的。 up-guard-unit UserPatch AI赏析之BruteforceBruteforce是一个适合新手练习的AI。 AI概览AI预定义了定义了一些城堡时代的打法，有些英文属于可以查询网站，对应着各个per文件。1234567891011121314151617(defconst sn-castle-age-strategy 182)(defconst xbow 1)(defconst end-game 2)(defconst krush 3)(defconst EAGLE-RUSH 4)(defconst fast-castle 5)(defconst eagle-rush 6)(defconst conquistadors 7)(defconst naval-fun 8)(defconst klew 9)(defconst castled 10)(defconst booming 11)(defconst lsr 12)(defconst PIKEMAN 13)(defconst DRUSH 14)(defconst RUN 15) ; https://youtu.be/mw2kKyJu9gY?t=2m11s end-game应该表示此战术已失效xbow是打弩手。Krush指的是城快马爆，28p升封建。Scrush是打肉马（配合弩手和散兵），24p到封建。Skirm是打散兵（掷矛战士），24p到封建。GenericAra是通用阿拉伯，以打弓箭为主，23-24p升封建。KLEW(Kidd’s Lightning Eagle Warrior Rush)是美洲民族的打法，主张直城，然后雄鹰快攻，24p到封建，卖石头点城堡。Booming是暴经济直帝，30p到封建PIKEMAN是长枪兵。TRASH是垃圾兵（长戟和掷矛）。MAA是打装甲步兵。HCA是打骑射手。Sling是打进贡。CASTLED(Castle Drop)是打前置城堡。 开局现在选择我最喜欢的蒙古民族，在阿拉伯地图上进行开局。我们看到蒙古民族会随机加载一些策略文件。123456789#load-if-defined MONGOL-CIV#load-if-defined UP-POCKET-POSITION(load "Brutal2\Krush")#else(load-random 45 "Brutal2\GenericAra" 52 "Brutal2\Scrush" 3 "Brutal2\Krush")#end-if#end-if UP-POCKET-POSITION指的是玩家是否坐中，那1v1的时候玩家始终坐中，于是就用马爆策略。 造房子123456789101112131415#load-if-not-defined CHINESE-CIV(defrule (up-gaia-type-count c: livestock-class == 0) (building-type-count-total town-center &gt;= 1) (population-headroom &gt; 0) (housing-headroom &lt; 3) (up-pending-objects c: house &lt; 1) (building-type-count-total house &lt; 1) (up-can-build 0 c: house)=&gt; (up-assign-builders c: house c: 2) (set-strategic-number sn-placement-zone-size 1) (up-set-placement-data my-player-number villager c: 1) (up-build place-control 0 c: house)) up-gaia-type-count用来表示尚存的的自然资源的数目，例如(up-gaia-type-count c: livestock-class &gt; 6)表示是否还存在超过6只绵羊或火鸡。与之对应的是up-gaia-type-count-total，表示所有曾经发现过的自然资源的数目，但是对鹿和羊来说没有相关数据，所以其实返回的是up-gaia-type-count的结果。注意，看到的羊可能还是灰色，并不等于自己拥有的羊。看自己的羊应该用up-object-type-count，并且羊被杀了之后up-object-type-count会减少，而不是吃完会减少。population-headroom指的是游戏设置最大人口和目前住房提供人口的差额。housing-headroom指的是目前住房提供人口和实际人口的差额。上面这段是造第一个房子，由于中国城镇中心提供10个人口，所以中国不需要造第一个房子。up-assign-builders为指定类型建筑分配农民数，由于一开始就只有一个人口富余，容易卡房子，所以分配两个农民造。有意思的是up-build命令，它的第二个参数可以取place-normal、place-forward、place-control、place-point。这里的place-control是与up-set-placement-data配合使用的。例如1(up-set-placement-data my-player-number -1 c: -25) ; home town center = -1 表示在主TC后面25格。本段代码的意思即在村民旁边建造房子。而place-point则是利用up-set-target-point储存的地点。sn-placement-zone-size在place-forward、place-control这两个选项时。下面是另外一个造房子的条件，在开局的时候并没有被触发。由于这两个行为是全部一样的，所以其实我感觉做简单一点，这两个可以合为一个。123456789101112131415(defrule (game-time &lt; 7) (up-gaia-type-count c: livestock-class &gt; 0) (building-type-count house &lt; 1) (building-type-count-total town-center &gt;= 1) (population-headroom &gt; 0) (housing-headroom &lt; 3) (up-pending-objects c: house &lt; 2) (up-can-build 0 c: house)=&gt; (up-assign-builders c: house c: 2) (set-strategic-number sn-placement-zone-size 1) (up-set-placement-data my-player-number villager c: 1) (up-build place-control 0 c: house)) 如果房子超过一个了，开局就不会卡农民了，这样将造房子的农民减少到一个。1234567(defrule (building-type-count house &gt; 0)=&gt; (up-assign-builders c: house c: 1) (disable-self))#end-if 注意开局的时候我们一般是造两个房子，一个分配2农民，一个分配1农民，这样会导致超过sn-cap-civilian-builders的默认值2，所以最好在一开始扩大一下，例如设为25。最重要的是sn-enable-new-building-system必须设为1，否则村民只能同时建造一个建筑。 农民调配可以结合这篇帖子和这篇帖子来理解AI的一些思路。123456789101112131415(defrule (up-compare-goal gl-map-style != LAND-NOMAD) (up-compare-goal gl-map-style != NOMAD) (current-age == dark-age) (game-time &lt; civilian-exploration-time) (unit-type-count livestock-class &lt; 1) (strategic-number sn-number-explore-groups != 4)=&gt; (set-strategic-number sn-cap-civilian-explorers civ-explorers) (set-strategic-number sn-cap-civilian-gatherers 100) (set-strategic-number sn-percent-civilian-gatherers 100) (set-strategic-number sn-percent-civilian-explorers 100) (set-strategic-number sn-number-explore-groups civ-explorers) (set-strategic-number sn-total-number-explorers civ-explorers)) 以上部分是早期探索阶段，阿拉伯地图的civilian-exploration-time为60。根据调试，实际上更多运行的是下面这个rule，因为通常农民很快就能找到一个羊群。这时候设置农民探索者最大数量为0，采集者最大数量为100，并且所有的农民都去采集。探索者的队伍容量为1人。这里注意与sn-number-explore-groups和sn-total-number-explorers区别，前者指的是陆地上的探索者数量，后者指的是村民探索者和军队探索者的总和。但是当有军队进行探索的时候似乎不会派村民进行较多的侦查活动。1234567891011121314151617(defrule (up-compare-goal gl-map-style != LAND-NOMAD) (up-compare-goal gl-map-style != NOMAD) (building-type-count town-center &gt; 0) (current-age == dark-age) (or(game-time &gt; civilian-exploration-time) (or(building-type-count-total mill &gt; 0) (unit-type-count livestock-class &gt;= 2))) (strategic-number sn-number-explore-groups != 4) =&gt; (set-strategic-number sn-cap-civilian-explorers 0) (set-strategic-number sn-cap-civilian-gatherers 100) (set-strategic-number sn-percent-civilian-explorers 0) (set-strategic-number sn-percent-civilian-gatherers 100) (set-strategic-number sn-number-explore-groups 1) (set-strategic-number sn-total-number-explorers 1)) 再往后，根据战术的不同，资源调配的方案有很大不同。 sn设置下面是strategy number设置，这里分了几部分是因为rule里面action的条数限制12345678910111213141516171819202122(defrule (true)=&gt; (set-strategic-number sn-cap-civilian-builders 25) (set-strategic-number sn-livestock-to-town-center 1) (set-strategic-number sn-enable-new-building-system 1) (set-strategic-number sn-enable-training-queue 1) (set-strategic-number sn-allow-adjacent-dropsites 1) ;(set-strategic-number sn-dropsite-separation-distance 5) (set-strategic-number sn-disable-builder-assistance 1) (set-strategic-number sn-camp-max-distance 16) (set-strategic-number sn-mill-max-distance 32) ;(set-strategic-number sn-defer-dropsite-update 1) ;(set-strategic-number sn-task-ungrouped-soldiers 0) (set-strategic-number sn-enable-patrol-attack 1) (set-strategic-number sn-maximum-hunt-drop-distance 12) (set-strategic-number sn-maximum-town-size 10) (set-goal gl-new-town-size 10) (set-strategic-number sn-max-retask-gather-amount 10) (set-strategic-number sn-retask-gather-amount 0) (disable-self)) sn-camp-max-distance表示伐木场和矿场和城镇中心最远的距离，不可能说我们的一个伐木放到敌人家门口的，对应有sn-mill-max-distance。BF将这两个值分别设为16和32sn-defer-dropsite-update策略，设为1的时候当新资源放置点建好时才更新dropsite-min-distance，否则刚建造就更新。sn-task-ungrouped-soldiers策略在TSA攻击时比较有用，它设定未编组部队是否分散开并保卫城镇地区。如果说是1，那么非编组军队（可以认为是空闲的军队）就会在城镇范围内散开并“游荡”。sn-enable-patrol-attack为巡逻式攻击命令，可参见heavengames上的说明sn-allow-adjacent-dropsites指的是否将资源放置点建到紧贴资源，这里选择的是1，但是我觉得0更好，这样资源放置点与资源之间会有一格距离，农民和资源放置点之间的接触面会更大sn-enable-training-queue允许在训练队列中pending一个单位。我们实际操作的时候可能喜欢按shift，然后一下子让电脑造5个甚至填满训练队列，这样会预先一次性支出所有单位的训练资源，但好处是防止我们操作不过来延误暴兵。但是电脑没有这方面的烦恼，rule的触发条件满足了，就会造单位，所以没必要把训练队列里面塞满。由于计算机对所有rule的一趟遍历是周期性的，所以这个命令使得，例如前期一个农民造好后能够立刻开始造下一个农民，而不是可能会等1-2秒。1234567891011121314151617181920(defrule (true)=&gt; (set-strategic-number sn-intelligent-gathering 1) (set-strategic-number sn-use-by-type-max-gathering 0) (set-strategic-number sn-gather-defense-units 1) (set-strategic-number sn-military-level 0) (set-strategic-number sn-enemy-sighted-response-distance 0) (set-strategic-number sn-percent-enemy-sighted-response 0) (set-strategic-number sn-percent-attack-soldiers 0) (set-strategic-number sn-enemy-current-age dark) (set-strategic-number sn-dropsite-separation-distance 1) (set-strategic-number sn-local-targeting-mode 1) ;(set-strategic-number sn-ttkfactor-scalar 200) (set-strategic-number sn-percent-building-cancellation 10) (set-strategic-number sn-zero-priority-distance 250) (set-strategic-number sn-initial-exploration-required 0) (set-strategic-number sn-enemy-sling-target-player 0) (disable-self)) sn-intelligent-gathering是智能采集系统，有什么用呢？从论坛上有 If you do up-retask-gatherers without sn-intelligent-gathering on, then the villagers will lose their load. If you do it with sn-intelligent-gathering then you don’t lose the load. sn-military-level并没有在UP或者原生DSL中出现，从gist上的这份源码，应该是自己的军事力量越强，sn-military-level就被设得越高sn-initial-exploration-required是修建建筑前最少的探索地图比例，由于农民直接在身后拍房子，所以应当为0。注意它的默认值不是0！所以一定要显式地修改回0。1234567891011121314151617181920(defrule (true)=&gt; (set-strategic-number sn-percent-attack-soldiers 100) (set-strategic-number sn-minimum-attack-group-size 1) (set-strategic-number sn-preferred-trade-distance 255) (set-strategic-number sn-consecutive-idle-unit-limit 0) (set-strategic-number sn-attack-winning-player 0) (set-strategic-number sn-attack-winning-player-factor 0) ;(set-strategic-number sn-placement-fail-delta 1) ;(set-strategic-number sn-placement-to-center 1) (set-strategic-number sn-blot-exploration-map 0) (set-strategic-number sn-blot-size blot-size) (set-strategic-number sn-escrow-level 0) (set-strategic-number sn-allow-direct-unit-control 0) (set-strategic-number sn-maximum-fish-boat-drop-distance 5) (set-goal gl-slain-deer 0) (up-setup-cost-data 1 gl-cost-food) (disable-self)) sn-preferred-trade-distance偏好贸易距离，由于贸易越长越好，所以设为255. 1234567891011121314(defrule (true)=&gt; (set-strategic-number sn-archer-threat 0) (set-strategic-number sn-infantry-threat 0) (set-strategic-number sn-cavalry-threat 0) ;(set-strategic-number sn-disable-trade-evasion 1) ;(set-strategic-number sn-disable-villager-garrison 1) ; 2 affects towers too ;(set-strategic-number sn-target-point-adjustment 3) ; right (set-strategic-number sn-allow-drush-defense 0) (set-goal temporary-goal12 1) ; player 1 as default. (up-change-name "BruteForce") ; Make it easier for 1.5 (disable-self)) 其中LAND-NOMAD为陆游，NOMAD为游牧。下面这段造农民的代码来自Krush部分。我们实际上看到在主per文件里面也有相应的造农民代码，但这个是互相不冲突的，因为条件写得很严格。1234567891011(defrule (up-compare-goal gl-map-style != WATER) (strategic-number sn-castle-age-strategy == krush) (unit-type-count-total villager &lt; max-civ) (up-research-status c: ri-loom &lt; research-pending) (unit-type-count villager &lt; 10) (can-train villager)=&gt; (train villager) (enable-timer 46 21)) 牵羊小马斥候有时候可能看到羊，但不会多走几步取得这头羊控制权，并将其派回TC，因此需要进行牵羊。 放伐木场、磨坊伐木一般要晚于磨坊。虽然农民一般先狩猎，但当羊比较难找时草料丛就起作用了，还有一点是为了种田的方便，最好让农民先把TC旁边的树木全部伐倒。resource-found语句中food参数特指草料丛，wood参数特指树林（而不是单棵的树）。但有时候（如存档aitest_farwood）即使找到了森林，伐木场依然可能建在单棵树的旁边，解决方案可以是延缓伐木场的建造时间，例如在第一个房子建成后。注意这条命令是一次性的，即使后面树木全部被挖完了，也依然是ture。如何检测是否还有树呢？可以使用下面的命令，如dropsite-min-distance wood &lt; 255在修建完伐木场后，可以检查dropsite-min-distance，dropsite-min-distance是个fact，用来检测从资源点到资源放置点的最少距离。如果说这个值比较大，那么我们的伐木场的效率就不算很高。 为什么农民建完伐木场不呆在伐木场旁边采木头，而是回去牧羊了呢？这时候可以利用up-target-objects命令，强制农民走到伐木场处1234567891011121314151617; Task villagers to lumber-camp(defrule (current-age == dark-age) (building-type-count lumber-camp &gt; 0)=&gt; (up-reset-search 1 1 1 1) (up-reset-filters) (up-find-local c: villager-m-lumberjack c: 240) (up-find-local c: villager-f-lumberjack c: 240) (up-modify-goal temporary-goal s:= sn-focus-player-number) (up-modify-sn sn-focus-player-number c:= my-player-number) (up-find-remote c: lumber-camp c: 1) (up-target-objects 0 action-default -1 -1) (up-modify-sn sn-focus-player-number g:= temporary-goal) (chat-local-to-self "task villagers to lumbercamp") (disable-self)) up-target-objects将被选择的up-find-local以普通模式action-normal（还可以选择action-patrol巡逻模式）指引到(direct against)up-find-remote除此之外，第三四个参数分别为阵型（formation-line, formation-box, formation-stagger, formation-flank）和动作（stance-aggressive, stance-defensive, stance-stand-ground, stance-no-attack） BTW，我在搜sn-intelligent-gathering时意外的发现了相反的问题 拉猪这段代码来自于Bruteforce电脑拉猪一般是用农民拉猪，升级织布机农民能够减少长距离拉猪农民死亡的可能性。1234567891011(defrule (up-research-status c: ri-loom &gt;= research-pending) (or(unit-type-count-total villager &gt;= 11) (game-time &gt; 275)) (strategic-number sn-enable-boar-hunting != 2) (dropsite-min-distance live-boar != -1) (dropsite-min-distance live-boar s:&lt; sn-maximum-hunt-drop-distance)=&gt; (set-strategic-number sn-enable-boar-hunting 2) (set-strategic-number sn-maximum-hunt-drop-distance 32)) sn-enable-boar-hunting设为1是会杀鹿和猪，2则只杀猪。首先当农民数大于等于11的时候，织布机升完了，此时如果猪距小于sn-maximum-hunt-drop-distance就设置sn-enable-boar-hunting为允许。注意特别判断值为-1，即未定义的情况，不然-1恒小于任何数会出错。下面就开始拉第一头猪。12345678910111213141516171819(defrule (strategic-number sn-enable-boar-hunting == 2) ;(dropsite-min-distance boar-hunting &gt; 10) (dropsite-min-distance live-boar != -1) (dropsite-min-distance live-boar != 255) ;(dropsite-min-distance live-boar s:&lt; sn-maximum-hunt-drop-distance) (dropsite-min-distance live-boar &lt; 32) (unit-type-count villager-hunter == 0) (up-timer-status 7 != timer-running)=&gt; (set-strategic-number sn-minimum-number-hunters 1) (set-strategic-number sn-minimum-boar-hunt-group-size 1) (set-strategic-number sn-minimum-boar-lure-group-size 1) ;(up-chat-data-to-self "sn-maximum-hunt-drop-distance: %d" s: sn-maximum-hunt-drop-distance) (chat-local-to-self "Begin luring boar") (up-retask-gatherers food c: 1) (up-request-hunters c: 1) (enable-timer 7 5)) up-retask-gatherers重新指派给定数量的村民收集某种资源。up-request-hunters尝试请求给定数量的猎人加入采集猪肉的队伍，不能保证到达给定的全部数量。villager-hunter是一个在UserPatch之外的常数，表示猎人的数目。经过测试，牧羊人不能称作猎人。下面两个命令容易混淆，sn-minimum-boar-hunt-group-size指的是达到多少个农民就可以开始猎杀野猪（此时猪可能已经被拉到TC下）。而sn-minimum-boar-lure-group-size指的是使用多少个农民拉猪，由于猪只同时对一个农民仇恨，所以一般设为1sn-minimum-number-hunters用来强制至少有多少猎人，一般在杀猪时结合sn-minimum-boar-hunt-group-size和up-request-hunters使用。enable-timer 7 5这个是干什么用的呢？这是为了防止之前杀猪的农民挂了，可以重新拉猪拉猪是拉猪，拉到TC下还要杀猪，下面的rule用来处理杀猪。123456789101112131415(defrule (strategic-number sn-enable-boar-hunting == 2) (dropsite-min-distance live-boar != -1) (dropsite-min-distance live-boar &lt; 5) (or(unit-type-count 122 &gt;= 1) (unit-type-count 216 &gt;= 1)) (unit-type-count villager-hunter &lt; 6) ; 8=&gt; (set-strategic-number sn-minimum-number-hunters 8) (set-strategic-number sn-minimum-boar-hunt-group-size 8) (set-strategic-number sn-minimum-boar-lure-group-size 8) (chat-local-to-self "Request support hunters") ;(up-retask-gatherers food c: 8) (up-request-hunters c: 8)) 这里122指男猎人 ，216指女猎人，当猪离TC很近了（小于等于5），这时候就用猎人来杀猪。下面的规则用来拉第二头猪。经测试“Attempting to lure another boar”、“Injured villager found – search again.”、“Begin luring boar (2)”三条规则依次触发。123456789101112131415161718(defrule (strategic-number sn-enable-boar-hunting == 2) (dropsite-min-distance live-boar s:&lt; sn-maximum-hunt-drop-distance) (dropsite-min-distance boar-hunting &lt; 10) (up-remaining-boar-amount &lt; 195) (strategic-number sn-minimum-number-hunters &gt; 1)=&gt; (set-strategic-number sn-minimum-number-hunters 1) (set-strategic-number sn-minimum-boar-hunt-group-size 1) (set-strategic-number sn-minimum-boar-lure-group-size 1) (chat-local-to-self "Attempting to lure another boar") (up-reset-search 1 1 1 1) (up-reset-filters) (up-set-target-point gl-position-self-x) (up-filter-distance c: -1 c: 10) (up-find-local c: villager-class c: 1) (set-goal gl-boar-lurer-search 1)) up-remaining-boar-amount检查当前猪所剩食物量。只有在另一猪可捕猎时，本数据才有效。否则数据会是65535（似乎65535等于-1，不知道为啥不设为0或者-1），以显示这是最后一头猪。Barbarian野蛮人ai似乎都没有用过这个fact。因为第二头猪通常比较远，而且拉完第一个猪农民会有残血，所以这里检查当前农民的血量是否足够，不够的话会(up-jump-rule -1)回到上面的“Attempting to lure another boar”，重新搜索一个农民。12345678910(defrule (goal gl-boar-lurer-search 1) (up-set-target-object search-local c: 0) (up-object-data object-data-hitpoints &lt; 40)=&gt; (up-reset-search 0 1 0 0) (up-find-local c: villager-class c: 1) (up-jump-rule -1) (chat-local-to-self "Injured villager found -- search again.")) up-object-data检查选定目标物件的特定信息，object-data-hitpoints常数表示生命值。12345678910111213(defrule (goal gl-boar-lurer-search 1) (up-set-target-object search-local c: 0)=&gt; (up-filter-distance c: -1 s: sn-maximum-hunt-drop-distance) (set-strategic-number sn-focus-player-number 0) (up-find-remote c: wild-boar c: 1) (up-find-remote c: javelina c: 1) (up-set-target-object search-remote c: 0) (up-target-objects 0 action-default -1 -1) (chat-local-to-self "Begin luring boar (2)") (set-goal gl-boar-lurer-search 2)) sn-maximum-hunt-drop-distance设置电脑玩家捕猎时资源距离资源放置点的最大距离。这里wild-boar和javelina都表示野猪。下面的这个规则就很有意思了，为啥会有这个条件呢？首先触发条件，主要包括3部分： (goal gl-boar-lurer-search 2) 当”Begin luring boar (2)”对应规则被触发后即满足，也就是说它只发生在拉第二头猪 dropsite-min-distance live-boar &lt; 5 表示当猪足够近的时候 up-timer-status 7 != timer-running 这个条件似乎正常情况下并不会满足1234567891011121314151617181920(defrule (strategic-number sn-enable-boar-hunting == 2) (dropsite-min-distance live-boar != -1) (dropsite-min-distance live-boar &lt; 5) (goal gl-boar-lurer-search 2) (unit-type-count villager-hunter &gt; 0) (up-timer-status 7 != timer-running) ;(unit-type-count villager-hunter &gt;= 8)=&gt; (up-reset-search 1 1 1 1) (up-reset-filters) (up-set-target-point gl-position-self-x) (up-filter-distance c: -1 c: 10) (up-find-local c: villager-class c: 6) (set-strategic-number sn-focus-player-number 0) (up-find-remote c: wild-boar c: 1) (up-find-remote c: javelina c: 1) (up-target-objects 0 action-default -1 -1) (enable-timer 7 10)) 我们看看(up-set-target-point gl-position-self-x)，通过检查前面的代码gl-position-self-x指的是TC的坐标。所以说它的作用是当第二只猪很近的时候，隔一段时间选择6个农民走向它，这是在杀猪么？然而同样触发的是“Request support hunters”，并且可能会触发好几次。 赶鹿下面这条规则是当没有猪时开始杀鹿123456789101112131415161718(defrule (up-research-status c: ri-loom &gt;= research-pending) (unit-type-count-total villager &gt;= 11) (strategic-number sn-enable-boar-hunting == 2) (unit-type-count-total villager &gt;= 20) (up-compare-goal gl-my-boars &lt; 1) (or(dropsite-min-distance live-boar == -1) (dropsite-min-distance live-boar s:&gt; sn-maximum-hunt-drop-distance))=&gt; (set-strategic-number sn-enable-boar-hunting 1) (set-strategic-number sn-minimum-number-hunters 0) ; 4 (set-strategic-number sn-minimum-boar-hunt-group-size 1) (set-strategic-number sn-minimum-boar-lure-group-size 1) (set-goal gl-boar-lurer-search 0) ;(up-retask-gatherers food c: 4) (up-request-hunters c: 4) (chat-local-to-self "No boar in range, allow deer hunting")) 种田空闲的农田初期农田会空闲，这是因为农民要去杀猪和杀羊，如果不去杀动物，那么它们的尸体会慢慢腐烂，食物就浪费了，但是田一旦建好了就不会坏，所以可以先杀动物，再种田。当城镇被攻击后农民会空闲。 升级时代1234567891011121314151617181920212223242526272829303132333435363738(defrule (game-time &gt; 132) (food-amount &lt; 50) (up-research-status c: feudal-age &lt; research-pending) ; current-age &lt; imp (up-pending-objects c: villager &lt; 1)=&gt; (up-drop-resources sheep-food c: 5) (up-drop-resources farm-food c: 5) (up-drop-resources forage-food c: 5) (up-drop-resources deer-food c: 20) (up-drop-resources boar-food c: 7) ; 10)(defrule (game-time &gt; 132) (food-amount &lt; 50) (food-amount &gt;= 44) (up-research-status c: feudal-age &lt; research-pending) (up-pending-objects c: villager &lt; 1)=&gt; (up-drop-resources sheep-food c: 2) (up-drop-resources farm-food c: 2) (up-drop-resources forage-food c: 2) (up-drop-resources deer-food c: 20) (up-drop-resources boar-food c: 2) ; 10)(defrule (current-age == dark-age) (strategic-number sn-enable-training-queue == 1) (up-pending-objects c: villager &lt; 2) (food-amount &lt; 50) (timer-triggered 46)=&gt; (up-drop-resources sheep-food c: 5) (up-drop-resources farm-food c: 5) (up-drop-resources forage-food c: 5) (up-drop-resources deer-food c: 20) (up-drop-resources boar-food c: 10)) 这里up-drop-resources指的是让至少携带若干资源的村民上交资源，例如当初期要断农民或者差一点点封建的时候，就可以使用这个命令争取时间。在黑暗时代农民只能携带10单位的资源，在后面升级了手推车等科技之后农民携带的资源会增多。此外如果让一个携带某种资源的农民去采集另外的资源，那么已采集到的资源会被丢弃，但是如果是去修建筑资源不会被丢弃。也可以通过up-garrison指令让农民进入TC交资源再出来，节省走路时间。 放兵营为啥兵营会放在不前不后的地方？ 侦察敌情一般小马探路只会在家里转，这叫explorer。那么如何让它探对手家里呢？up-send-scout加上position-位置常数可以做到这一点 强行建造征服者的默认AI建造工事的时候，如果被攻击就会立刻取消建筑，事实上这是不完善的，比如有时候我们就想强行肛一个城堡。sn-percent-building-cancellation可以提供这样的功能 建造第二个TC123456(defrule (building-type-count-total town-center &gt;= 1) (building-type-count-total town-center &lt; 2)=&gt; (set-strategic-number sn-town-center-placement mining-camp))]]></content>
      <tags>
        <tag>游戏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[苏州无锡连云港游记]]></title>
    <url>%2F2017%2F10%2F02%2F%E8%8B%8F%E5%B7%9E%E6%97%A0%E9%94%A1%E8%BF%9E%E4%BA%91%E6%B8%AF%E6%B8%B8%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[连云港、无锡、苏州虽然是7-9月份不同时间玩的，但都是本省景点，所以合并为一篇游记来记录 连云港当时正值盛夏最热的时候，我们不想待在家里吹空调，出于交通方便的考虑，而且连云港靠山靠海，我们报了一个低价团（400块）前往连云港两日游。一早上到了金融中心乘上了去日照的车，到了老圩收费站我们和直接从泰州过来去连云港的大巴交换了人。上了大巴便感到一股热浪，这空调也太次了点了吧。到了连云港，先去了高速口附近的一个叫云龙涧的地方，导游说连云港的花果山其实属于云台山，是沂蒙山的余脉，云龙涧属于中云台山，花果山属于前云台山，而今天下午要去的东西连岛属于后云台山。云龙涧据说有江苏省落差最大的瀑布。晚上宾馆空调仿佛被大巴车传染了一样，一点用没有。我们去了街对面一家人特别多的饭店吃。这家饭店没有菜单，客人直接去后厨房看食材然后点菜。我们点了鱿鱼汤、一盆小鱼一道素菜，还有一盘饺子才一百多。而且非常好吃。回来洗澡，水像开水一样，非常烫。第二天去了花果山，据说花果山的猴子是非常有意思的多的 无锡我们乘坐神车之一D2281前往无锡，当时正值某会议，所有途径厦门的车辆都要二次安检，到了候车室要上个厕所都得出去。刚出无锡站地下通道便有中铁国旅的人问我们要不要参加他们的一日游，出于节省交通时间的因素我们报了他们的团。他们说这时候想玩鼋头渚和无锡影视基地有点晚，便推荐我们选择一个人一百二，包车去三国城水浒城。去火车站外面的一间小屋签了旅游合同之后我们便上了一辆MPV。这个团是没有导游的团，导游负责买好门票，然后把你带到三国城看完一个表演，然后就给你自由活动了。由于我们是晚上八点多的火车，还是想问问能不能帮我们买一下鼋头渚的票。导游说玩完三国城水浒城已经差不多要两三点了，来不及去鼋头渚，而且鼋头渚的樱花是最好看的，值得每年春上单独来看一下。然后她给我们推荐了蠡园。看完三英战吕布，导游带领我们乘船，她极力向我们推荐30块的交通车，说影视基地很大，走过去太累了，但我们没坐。磨了半天嘴皮子，导游说下午水浒城还有个大型演出，你们不坐车不一定能赶得上。但是从竞技场绕了圈，决定放弃赤壁栈道，上古城墙，古城墙上去的路还有点陡，不过风景比下面的赤壁栈道要好很多。下来就到了七星坛，从七星坛下来我们坐20路公交车来到了蠡园，前面有个旅行团正在走侧门（渔庄）进，我爸OS我偏偏要从正门进，于是我们到正门，交上了导游写过我们的凭条，工作人员便放我们进去了。我爸说之前来过蠡园，说蠡园很小，自己当时一日游玩了七八个景点。同其他的园林一样，蠡园也是内敛的，我们从入口绕了会，经过了百花山房和西施传说廊，眼前才豁然开朗。无锡园林和苏州园林不同的地方在于苏州是假山假水，无锡是假山真水，例如蠡园依靠太湖，远远看去一道长廊沿湖蜿蜒，湖心更有一座小岛。我们进园时已是四点，已经没有游船了。沿着进来的路往南走，蠡园被一道墙分割为西部和东部，西部比较大，里面有很多园艺展览，应该是后来扩建的部分，我们先去的是精华的东部。左手边是一片巨大的荷花塘，一直连通南面的太湖，在荷叶荷花的掩映中、层层叠叠的堤桥间矗立着各式各样的一些亭子，后来看地图知道这是蠡园非常著名的春夏秋冬四座亭子。我们沿着长堤继续往东行走。在大堤引领下我们观赏了一片湖景，往东边望去，有一座摩天轮，这应该就是蠡湖公园，我高三去蠡湖小学参加一个组装机器人的比赛后曾经被带到那里玩过那里。大堤往岸的方向转去，塘两边开始出现黄色的睡莲，前方便是进门看到的长廊，称为千步长廊。长廊里面传来刚才团队的导游的解说声，我说要不然还是蹭导游吧。可是往前走却便是一处四个方向的“立交桥”，下了桥前方便是假山石了，这里有一方泉井，称为洗耳泉。绕过洗耳泉是一座巨大的阴暗的亭子，那边似乎没去过，但是是和千步长廊的反方向，于是我们往回走。往前走右边出现一道墙，应该是千步长廊的墙，导游的声音却从墙那一面传来，尴尬了，我们怎么绕过了这个长廊？继续往前走，左边是一片池塘，池塘中矗立着一座西施的雕像，西施正对着一座拱桥，拱桥的桥洞倒影在波澜不惊的水面上，形成一个圆，宛如一轮明月，这个景点就叫做西施映月。西施映月的映月桥往东，左边有另一篇一片小池塘，池塘对面就是春秋阁。春秋阁后面又是一片池塘，这时候应该已经到达蠡园的边缘了，外面的高楼（湖滨饭店）仿佛紧贴着青山绿水后面拔地而起。这景点称为层波叠影，其实是后来拓建的景区。右手边是一道架立于水上的廊桥，当时没怎么注意，等游完拙政园的小飞虹之后觉得这个挺厉害的。过了层波叠影，再往后面走，出现了最后一片池塘，池塘北面有一座两层黄墙绿瓦的别墅，很是别致。从这里可以上到千步长廊，往东看去是一座五层红墙宝塔（凝春塔），不过这里已是长廊的最东段，一道门阻挡了我们，因此去不到宝塔处，不过通往湖心亭还是可以去的。从湖心亭可以看到湖中的岛，如果早一点我们应该是能够乘船去岛上玩一玩的，不过现在已经四点半了，于是我们沿着长廊往回走。从长廊上下来到春秋阁那里看到有卖烧饼的，我们中午都只是吃的干粮，已经有点饿了，感觉还挺好吃的。从长廊上下来，往北面走了会，回到了洗耳泉，于是我们继续往北走，从西施映月穿过。又看到一座假山，上面有一座亭子，叫归云峰。我往上爬了一段，觉得还有点高，便说不爬了，选了另一条路继续往前走。从归云峰上下来，我们觉得蠡园太乱了，准备回到入口处要张门票。不过如何去到入口也是一个技术活，我们绕了一会儿到了之前导游带队进去的入口。 经过了之前的假山，我已经明白了，它的设计就是只闻其声不见其人，有时候近在咫尺的东西需要绕上一段路才能够到达，于是我果断往反方向走，绕了一个360度的大弯，终于到达了矮墙另一边的石舫。 苏州我们进拙政园是两点四十左右，一进门就是游客服务中心，我发现一个柜台上说有免费的讲解服务，赶快喊上堂高，我们要不跟着讲解走吧，堂高欣然同意。不过排到我们的时候工作说三点钟的讲解刚好排满了，她拿着我们的身份证反复地刷了刷，确定是不行的。便要我们等三点半的，这时候外面还在下雨，于是我们勉强同意了。我顺便去穿了鞋套，回来的时候和堂高说没几分钟就能预约下一班了，我就在这儿等着吧，省得又没排上。发现身后有六个人正在联系收费的讲解服务（80分钟，免费讲解服务只有40分钟），不一会儿有两个人来退免费导游的预约了，我看了看时间两点五十四，快到预约截止时间了，就赶快和工作人员说现在有名额了我们想改成三点的一班。 古代园林中借景这一手法非常常用，报恩塔远香堂是拙政园主人的会客厅。导游指着远香堂对面一座假山后面说这里有一道两米高的木门，虽然十分不起眼，但这是以前拙政园的正门。走过远香堂便到了著名的两个景点小飞虹和香洲。香洲上的牌匾原迹是文征明所作，后来果然又在文革中被摧毁了。中花园是明式的，西花园则是清式的。导游带领我们“别有洞天”的一石拱门穿过，便进入了西花园。卅六鸳鸯馆反面则是十八曼陀罗馆，这就如同一张纸的正反面一样。卅六鸳鸯馆部分建造在水面之上。从卅六鸳鸯馆出来边到了一座铁桥，传说文革时为了避免这座铁桥被破坏，主人将铁桥拆解，然后沉入水底。过了铁桥便到了最后一个景点留听阁，所谓留得残荷听雨声，这阁名便是源自此诗。导游将我们带到盆景园便解散了，这里的盆景并没有之前在虎丘万景山庄的多，也没有蠡园的园艺别致。于是我们开始拙政园景点打卡旅程。]]></content>
      <tags>
        <tag>游记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Kickstart 2017 Round F题解]]></title>
    <url>%2F2017%2F09%2F25%2FKickstart2017F%2F</url>
    <content type="text"><![CDATA[Google Kickstart 2017 Round F，当时做了两条就睡觉了，早上把剩下两条也过了。感觉不算是很难，可能也和这场限时24h有关吧。不过提交的时候倒是手忙脚乱，第一条交了三发，第一发是从VS迁移到DevC上是DevC由于之前配了个C++14所以崩了，第二发输出里面是Unicode BOM，WA了，蛋疼。 A. Kicksort找规律发现每次找的pivot的位置是从原数组的中心点（奇）或中心线靠左（偶）开始，如果小于原数组的中位数，则下一个位置是其轴对称，否则是其左边一个位置。这样从数组的中部交替往外移动，结束条件是pivot到达原数组的最后一个元素。由于这个过程中所有选为的pivot都是最大/小值才返回YES，否则直接返回NO，所以只要迭代继续，我们去掉的就一直是最大/小值。因此使用l和r记录此时所有还没被作为pivot去掉的数中的最大/小值，判断新的pivot是否等于l或r。AC代码 B. Dance Battle由于Delay和Truce规则，我们实际上并不需要考虑舞者的顺序问题。我们将舞者的S值从小到大排序，从小端开始Dance，从大端开始Recruit。当在l位置处e不够的时候去Recruit是不亏的，因为虽然在大端位置r处损失了一点honor，但是大端增加的S[r]肯定至少能够干掉S[l]获得一点honor了，除非l = r，这时候应该直接Truce。AC代码 C. Catch Them All有个无向图，N点M边，第i条边要走$D_i$分钟，宠物小精灵以$1/(N-1)$的均匀几率出现在你不在的地方，直到你抓到后另一个小精灵才出现。求抓到P个小精灵的时间期望。首先自然是floyd求一下最短路。然后是一个没有环的概率DP，可以正着迭代掉。 D. Eat CakeLeetcode原题Perfect SquaresAC代码]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>codejam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记忆化搜索和动态规划]]></title>
    <url>%2F2017%2F09%2F24%2F%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2%E5%92%8C%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[记忆化搜索和动态规划常常是两种成对出现的解法。 合唱这道题来自网易2018校园招聘编程题真题集合的倒数第二题。 记忆化搜索偏重于在传统的递归搜索中复用一些中间结果。其框架大致为result = search(start)形式，并且在能够复用前必定已经到达过一次递归底部。对于本题，记忆化搜索是简单易懂的。123456789101112131415161718192021222324252627282930int solve(int i, int j) &#123; if (dp[i][j] == -1) &#123; int next = max(i, j) + 1; if (next &gt; n) &#123; return 0; &#125; int ch1 = i == 0 ? solve(next, j) : solve(next, j) + abs(a[next] - a[i]); int ch2 = j == 0 ? solve(i, next) : solve(i, next) + abs(a[next] - a[j]); dp[i][j] = min(ch1, ch2); &#125; return dp[i][j];&#125;int main() &#123; int T, cas = 0; scanf("%d", &amp;n); for (int i = 1; i &lt;= n; i++) &#123; scanf("%d", &amp;a[i]); &#125; memset(dp, -1, sizeof dp); printf("%d\n", solve(0, 0));#ifdef __ACM system("pause");#endif return 0;&#125; 常可以借助于反向DP来取代记忆化搜索里面的递归。正向DP的方法容易进入一个误区，这里的dp[i][j]并不一定从dp[i - 1][j]和dp[i][j - 1]之间转移得到，例如dp[3][2]完全可以是由dp[3][0]得到的。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDU 2089 不要62 数位DP]]></title>
    <url>%2F2017%2F09%2F23%2FHDU2089%E4%B8%8D%E8%A6%8162%2F</url>
    <content type="text"><![CDATA[这条题目是典型的求[L, R]区间内满足某性质的整数的数目问题，通常解法是用[0, R]区间的数目减去[0, L-1]区间的数目。数位DP是此类问题常见的解题思路。 数位DP模板数位dp其实类似于中记忆化搜索。数位DP由最深$N$（$N$为$R$的十进制位数）层dfs组成。出于实现方便，数字$123$映射到int nums[]数组中，首尾颠倒变成$[3, 2, 1]$。由于从原数字的最高位往最末位递归，因此记忆化搜索的每次递归pos是从$N-1$递减的。123456789101112LL solve(int x)&#123; memset(nums, 0, sizeof nums); memset(dp, -1, sizeof dp); int ppos = 0; while (x != 0) &#123; nums[ppos++] = x % 10; x /= 10; &#125; // 开始dfs记忆化搜索 LL ans = dfs(ppos - 1, 0, true); return ans;&#125; flag表示在遍历当前pos位时，比pos位低的$[0..pos-1]$位是否有限制，其初始值为true，因为最高位肯定是有限制的。例如数字$234$，在遍历到$cur[2]$为$1$时，$cur[2..1]$能够取遍$[10..19]$，但是当$cur[2]$为能取的上确界$2$时，低位的$cur[1]$只能够在$[0..nums[1]]$的范围里面取了，$cur[2..1]$取值为$[21..23]$。总结规律，只有前缀$[pos+1 .. N-1]$的flag为true（前缀的所有位都取到了上确界），且当前位pos的当前值$cur[pos]$也取上确界$nums[pos]$或$9$时，低位$cur[pos-1]$只能取$[0..nums[pos-1]]$，否则能自由取$[0..9]$。status用来表示状态，这个状态被用来计算当前子问题的结果，例如在这道题目中，status用来记录是否存在62或者4。 子结构一般为$dp[pos][..]..$的多维数组。后面的几维与状态有关，有时候可能还需要进行离散化。从上面可知当flag为true的时候，不能取满$[0..9]$，此时我们就没必要记录下结果，因为显然取满的情况是占绝大多数的。因此dfs的结构如下12345678910111213141516171819202122232425LL dfs(int pos, int status, bool flag) &#123; if (pos == -1) &#123; // 如果到达最深层，check是否继续满足题目中的性质 return check(status) ? 1 : 0; &#125; if (!flag &amp;&amp; dp[pos][status] != -1) &#123; // 如果此层能够取满，那查看能不能复用存储的结果 return dp[pos][status]; &#125; LL ans = 0; int end = flag ? nums[pos] : 9; // 如果flag为true就是不自由的，end只能取到nums[pos] for (int i = 0; i &lt;= end; i++) &#123; int newstatus = ...; // 如果最终结果与前缀的结果满足and或者or的性质，这里还可以剪枝 bool newflag = flag &amp;&amp; (i == end); // 下一层的flag，注意要满足两个条件才会有限制 ans += dfs(pos - 1, newstatus, newflag); &#125; if (!flag) &#123; // 只保存任何层取满[0..9]的结果 dp[pos][status] = ans; &#125; return ans;&#125; 题解AC代码]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>数位DP</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式一致性和分布式共识协议]]></title>
    <url>%2F2017%2F09%2F20%2Fdistributed-system-consistency-and-consensus%2F</url>
    <content type="text"><![CDATA[分布式系统中常出现以下的一些应用场景：分布式锁、负载均衡、发布订阅模型、选举、分布式队列。为了提高在这些场景下的高可用或者容错特性，常常采用维护多个冗余副本的办法来实现，因此需要维护这些副本之间的一致性。 相比单机，分布式集群搭建在网络上，而网络通信是复杂的，数据包的丢失、重复、乱序需要被妥善处理，此外节点宕机或者网络分区的情况也需要被考虑。事实上，CAP理论认为一致性C、可用性A和分区容错P不可能同时做到。因此如何在分布式系统下实现事务是一个有趣的课题。 本篇文章以DDIA以及作者的讲解视频为骨架，辅以业界的相关实现，来综述性探讨上述的一些问题。 分布式系统的相关性能要求可用性和可靠性可用性(availability)需要系统在任何给定的时刻都能够正确工作。可靠性(reliability)需要系统可以无故障地持续运行。这两者的区别是可靠性强调的是较少的崩溃次数，而可用性指的是较长的服务时长。例如，系统A可以运行一年，但每隔一个月会崩溃一次，并花费1s恢复；系统B无崩溃工作一年，但需要每年停机维护2小时。那么系统A的可用性会强一点，但系统B的可靠性会强一点。 而根据《InnoDB存储引擎卷1》 P274页的论述，可靠性强调系统本身的能力，而不考虑在遇到不确定的环境因素，例如地震海啸破坏硬盘等情况导致的问题。 高可用性HA与容错FT根据DDIA，首先应当区分fault和failure，故障Fault通常定义为系统的一部分状态偏离其标准，而失效Failure则是系统作为一个整体停止向用户提供服务。能预料并应对故障的系统特性可称为容错(fault-tolerant)或韧性(resilient)。单点(Single point of failure, SPOF)表示因为某个fault(比如网络或者节点的)导致的failure。而FT即Fault Tolerant，表示在一定fault规模下，系统还能够持续运行，而不failure。 从定义上来看，Fault tolerant的系统不允许服务中断(service interruption)，但其开销较高；High availability的系统追求最小的服务中断。 衡量容错能力通常可以通过MTBF、MTTR、MTTF等指标，分别表示开始工作到第一个故障的时间的平均值，平均修复时间和平均失效时间。 Failure detectorFailure detector检查节点是否失效。Perfect Failure detector会在当且仅当一个节点失效的时候标记它是失效的。 通常实现 发消息等待超时。对crash stop和crash recovery是有效的。 无法区分无响应、丢包和延迟消息。 Eventuall perfect failure detector 安全性安全性强调的是在故障的情况下系统能够正确操作而不造成灾难。 可维护性可维护性描述发生发生故障的系统被恢复的难易程度。 分布式系统模型网络行为假设 Reliable 如果消息被发送，那么就会被收到。 但是，信息可能是被乱序收到的。 我们将在后面对广播和全序广播的讨论中继续看到Reliable的链接。 Fair loss 消息可能丢失、重复、乱序。但如果不断重试，消息最终会被送达。 Arbitrary(active adversary) 消息可能会被损坏 节点行为假设 Crash(Fail) stop 当节点crash后，就会永远停止运行 Crash(Fail) recovery 当节点crash后，可能在某个时刻恢复 Byzantine 同步假设 同步 消息延迟不会高于某个上限。 部分同步 在某些有限时间段中，系统是异步的。 异步 所有信息可以被任意地延迟，各个节点可以任意地停止工作。 分布式系统上的数据存储分布式存储架构的演变主要源于三点需求：扩大数据在地理上的分布范围从而减少延迟(latency)，为系统提供容错/高可用性从而提高可用性，通过将请求负载均衡到各个机器上以提高伸缩性(Scalability)（例如读写分离）。 在高并发的场景下，我们对服务器和数据库性能的扩展方案可以分为两种思路水平扩展(horizontal scaling, scale out)和垂直扩展(vertical scaling, scale up)。在这两种思路的领导下有三种方案，即共享内存(shared-memory)、共享磁盘(shared-disk)和无共享(share-nothing)。 复制(replicate)复制(replicate)，指通过网络连接的多台机器上保留相同数据的副本(replica)。复制可以是single leader的、multi leader的或者leaderless。 一个最原始的系统为了理解复制的作用，我们首先引入一个最原始的系统。它通常是单服务器单库的架构。但它显然不能应付高并发的场景，因此需要逐步进行升级。首先我们可以对服务器进行集群化和负载均衡。这个并不难，因为用户的请求从接入层打过来，通常已经经过了一系列路由、鉴权、限流、降级、LB等过程。在业务层通常就是去处理每一个请求，其中涉及到与各种中间件和数据库交互，比如ES、Redis、MySQL、Kafka、ZK、ETCD等等。对于这些场景，因此对业务层动态扩容并不是很麻烦。但是业务虽然扩容了，所有的请求还是打到同一个数据库上，数据库成为瓶颈。当然我们可以在业务侧做些聚合啥的，但这不是一个通用的方案。我们在服务器和数据库之间加上一层缓存。鲁迅说过，计算机科学领域的任何问题都可以通过增加一个间接的中间层解决。缓存的加入是为了减少数据库的压力，但显而易见的，和CPU一样，如果我们双写缓存和数据库，那么就一定需要解决一致性问题。比如我们先写库，再删缓存(Cache Aside Pattern)，那么在这一段时间中缓存就是脏的；又比如我们先删缓存再写库，那么只要这个操作不是原子的（绝大多数情况下就不是原子的），那么就可能中间有个读线程在读库的时候再重新写一遍旧数据到缓存中。我们有一些方案能够尽可能处理缓存和数据库一致的问题——再不济我们按照分布式事务提交的方式（例如在MySQL里面就用2PC来处理binlog和redolog的一致性），或者借助于一个队列维护。随着数据库压力的进一步增大，我们使用主从架构。对于更大并发的要求，我们还可以采用分区的方案。这些是和数据库实现直接相关的，也是我们主要论述的部分。 主动复制和被动复制primary-backup system的代表是zab协议。state machine replication的代表是paxos协议。 这里引用Vive La Différence: Paxos vs. Viewstamped Replication vs. Zab的观点。state machine replication 也称作active replication，而primary-backup system(主从复制)也称作passive replication。SMR上每个节点维护一个确定状态机，彼此一致性协议来返回给client。primary-backup system中，只有primary维护确定性状态机，然后通过一致性协议备份到backup。 SMR和primary-backup的区别还体现在，SMR更讲究“过程”： 例如x=1和x=2这两个操作，primary-backup只需要复制一个最终的x=2即可，但是SMR需要两条日志表示过程； 因为SMR要在所有的机器上apply过程，所以不支持诸如随机、时间相关的操作。 Single Leader架构（主从复制）最常用的是leader-based replication，又称为active/passive或者主从(master/slave)架构，由一个Leader(Master/Primary)负责协调多个Follower(Read replica, Slave, Sencondary)。主从架构是一个HA解决方案，能实现读写分离，从而提高读写效率。主从方案可以通过MySQL Proxy等机制实现，阿里巴巴有一个Canal的数据库中间件，能够实现数据库的增量订阅和消费业务。主从数据库可以互为热(hot)/温(warm)备份(standby)，但会带来一些一致性的问题。主从架构下的复制可以是同步的，也可以是异步的。异步复制在性能上是美好的，具有高吞吐量和低延迟，但是在一致性和持久性上会打折扣，每个节点上的数据可能是不一样的，并且主库已经向客户端确认的写入可能会丢失。异步复制的一个典型是Redis的哨兵机制。同步复制的情况下一旦一个从库失去响应，就会阻塞所有写入操作。在下图中，Follower1是同步的，Follower2是异步的。通常情况下的同步复制指的是半同步(semi-synchronous)，即设置一个Follower为同步的，其余的为异步的。 主从架构下，通常会涉及到下面几种中间件 处理集群成员变更处理宕机在主从架构下的从节点宕机的处理采取简单的catch up recovery。 我们讨论主节点的故障的处理方式，即故障切换(failover)。Failover主要涉及确认Leader失败、选举新Leader和重新配置系统三个主要步骤。对于确认Leader失败步骤，我们应当审慎地选取一个Timeout时间，因为Leader的超时可能是由于网络负载导致的，此时如果我们认为Leader宕机而开始选举会导致网络负载进一步恶化。对于选举步骤，我们需要在剩余的节点中决议出一个拥有旧Leader中最新数据副本的Follower以期最小化数据损失，一般通过共识协议解决。 对于集群成员变更，我们需要处理新Leader选出后老Leader重新连接的情况。一方面这可能导致脑裂(split brain)，即新老Leader同时接受来自客户端的写请求，从而导致冲突。错误地解决脑裂问题可能导致新老Leader都被关闭，从而导致集群无主的现象。另一方面，在异步复制的环境下，新Leader可能没收到老Leader宕机前的写入操作，此时这部分的写入可能被丢弃掉，从而影响到持久性。 日志复制Leader节点负责将日复制到Follower节点上。日志复制有如下的几种形式。 基于语句 这种模式下，主库直接记录下每个写入请求如INSERT等，并转发给从库。这种方式存在一些弊端，例如SQL语句中可能存在随机函数或者时间函数导致每个库上的执行结果不一致，或者数据库中使用了AUTO INCR等语句时，对每个副本上语句的执行顺序也有要求。 基于WAL 无论是为存储日志结构的LSM树还是覆写单个磁盘块的B树，其修改都涉及预写式日志WAL。在这些情况下日志是包含所有写入的仅追加序列，因此通过相同的日志可以在另一个节点上构建相同的副本。 缺点是WAL的信息和数据库的底层存储紧密耦合，这使得更改底层存储格式变得困难。例如通常不可能在Leader和Follower上运行不同版本的数据库。 逻辑日志复制/基于行的日志复制 基于触发器的复制 一致性问题日志复制的不同实现方式可能产生一致性问题。例如在读写分离的架构下，同步复制对可用性的损害是很大的，但如果采用异步复制的方式，在从库落后的情况下，同时对主库和从库的查询可能产生不同的结果，从而产生一致性问题。主从复制的架构是最终一致的(eventually consistency)，也就是在副本之间实现同步间存在不一致窗口，称为复制延迟(replication lag)。复制延迟的持续时间是不确定的。 从CAP的观点来看，主从复制实际上是在最大可用(Max Availability)和最大保护(Max Protect)之间的一个trade-off，其核心原因是网络分区和宕机是不可避免的。如果我们允许主从节点在某个Slave宕机到恢复的时间段内继续服务，那么我们就必然要为不一致窗口付出代价。如果我们不容许一致性受到损害，那么就必然要等到这个Slave恢复或者超时并切换到备用机之后。哪怕只有一个机器宕机，这段时间内的可用性也无法保证。 但这个是不符合常识的，比如说我想知道我们班新的班长是谁，我首先找室友问，发现室友出去和女朋友High了，或者室友给了我一个错误的答案，难道我就不能真正知道班长是谁了么？事实上我只要问足够多的人就行。例如如果每个人都是言行一致的话，那么过半数人认为的班长就是班长了。这个原理，就对应到Lamport提出的基于复制自动机的分布式集群，它使用共识算法来维护一致性，能够承受不多于半数的节点失效。 Multi Leader架构Leaderless架构分区分布式集群分布式集群相比主从架构提供了更好的冗余方式，集群可以管理超过两个节点，并且所有节点都是对等的，称为replica，这些replica可以（并且应当）在空间位置上广泛分布，并且具有负载均衡的能力。而主从数据库一般将一主n从整体视为一个节点，并不适用分库分表。 缓存我们基于上一章来扩展讨论一下缓存相关的问题，主要以Redis为主。 缓存双写最经典的缓存数据库双写模式是Cache Aside Pattern，也就是先更新库，再删除缓存，与之配合的是先读缓存，如果缓存没有的话就读库，顺便更新缓存。为什么选择删除缓存，而不是更新缓存的原因是更新缓存的代价比较大，例如缓存中有数据库里面a和b两个字段的缓存，还有一个缓存c是由一个复杂的函数func(a, 6b)计算得到的，那么单独更新a之后，还需要重新计算一下c，而事实上这个c并不一定是被频繁使用到的。在先前，我们提到了Cache Aside Pattern模式的可能存在的不一致问题，它常常在高并发场景下出现，对于这种问题，可以采用队列进行优化。假设A写B读，我们需要防止B脏读，那么我们把A删缓存、A写库、B读都入队，并使用若干工作线程加速处理这个队列。如果我们在A删缓存后写库前从队列中取到了B读的请求，那么我们将这个请求重新放回队列。对于对同一值的多个更新缓存请求，可以进行归并。这个方案的一个注意点是读请求可能被长时间阻塞，例如当数据更新很频繁时，这时候需要做好压测。此外，需要注意对同一个数据的读写请求必须要在一个节点上完成，此时，一些热点数据的存在会导致某个节点的压力过大。 缓存雪崩、穿透和击穿缓存雪崩、穿透和击穿是使用缓存时出现的致命性问题。缓存雪崩主要出现在缓存宕掉后，所有的流量会打到数据库上，从而数据库也挂了，导致整个服务崩溃，“雪崩”二字，形象生动。对于这种情况的处理方案分为： 事前：redis高可用，主从+哨兵，redis cluster，避免全盘崩溃。 事中：限流降级（例如本地ehcache缓存+hystrix），避免MySQL被打死。 事后：redis持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。 缓存穿透是一种恶意攻击的手段，它会构造大量的请求，去查询一些缓存中肯定没有的数据，迫使所有的请求都打到数据库上面，从而导致数据库宕机。解决方案就是对所有查不到的值，在缓存中创建一个空值。 缓存击穿指的是一个热点Key在失效的瞬间，大量对它的请求会击穿缓存，打到数据库上面。和雪崩相比，它更接近于在缓存上凿了一个洞。解决方案包含： 如果更新频率低，可以设置为永不过期 如果更新频率较低，可以通过分布式锁来保证只有少数的请求能请求数据库并更新缓存，其余的线程在所释放后再请求缓存 如果更新频率高，可以用定时线程在过期前主动构建缓存，或者延迟缓存过期时间 并发竞争写这个问题出现在多客户端并发写一个key时，其中A读和B读可能乱序，A写和B写也可能乱序。对于这个问题，可以采用分布式锁来解决。并且维护一个时间戳，往数据库更新时，必须要满足缓存的时间戳要比数据库的时间戳大。 缓存Demo：RedisRedis内存淘汰机制详见我的专题文章 Redis主从模式Redis主从模式 Redis集群模式在之前版本的Redis中，多节点部署需要依靠诸如codis、twemproxy等中间件实现，我们对中间件读写，由中间件管理Redis实例。现在版本的Redis原生支持了Redis Cluster方式。相比于sentinel的高可用和一写多读，Redis Cluster能够真正在多个Redis节点之间共享数据。 生产环境下的Redis部署生产环境下的Redis部署 Redis持久化方式详见我的专题文章 分布式系统上的一致性和Order从概念上分布式中的一致性(CAP中的C)和事务一致性(ACID中的C)是完全不一样的，CAP中的一致性要求多副本的系统的行为表现得像单系统一样，并且对这个系统的修改是原子的。而事务一致性强调事务前后不变量不能改变。 强一致性分布式系统，特别是CAP理论中对一致性(consistency)的定义是all nodes see the same data at the same time，这个要求是比较高的，通常也称为强一致性(Strong consistency)、线性一致性(Linearizability)、外部一致性(External consistency)、原子一致性(atomic consistency)。强一致性强调each operation appears to execute instantaneously, exactly once, at some point between its invocation and its response。考虑一个简单的主从架构的例子(来自Designing Data-Intensive Applications)，在下图中比赛结果由Referee写入Leader主库，并向两个Follower同步复制，线性一致性需要这个过程是透明的。在本场景中即当我们任何一个读取返回新值后，所有后续读取都必须返回新值（可以参考C++内存模型中的可见性一块）。但简单的读写分离主从复制会出现当Leader只同步了Follower1而没有同步到Follower2时，对两个副本的读取结果分别返回新值和旧值的现象。 通过线性一致性可以实现分布式锁、选举、和唯一性约束等功能。我们使用共识算法实现的是线性一致性，而主从复制则不是。由此可见，分布式一致性(Consistency)和共识(Consensus)是完全不同的两个概念，但是后者是实现前者的一个工具。 我们还需要区分Linearizability和Serializability。线性一致性(Linearizability)来源于分布式系统和并发编程，其语境是single-operation, single-object, real-time order，线性一致性保证了写操作对后续的读操作是可见的。线性一致性往往对应于CAP中的C，线性一致性是composable 即local的，即如果每一个对象上的操作是线性的，那么系统上的所有操作都是线性的。Serializability来源于数据库，其语境是multi-operation, multi-object, arbitrary total order，它是一个有关事务的保证，涉及一组操作。它保证了在多个对象上执行的多个事务等同于某个序列化的执行过程。顺序一致性(Serializability)相当于ACID中的I，如果用户的每一个事务都能保证correctness即ACID中的C，那么顺序执行的事务也能保证correctness。不同于Linearizability，Serializability本身不给事务的执行顺序加上任何的real-time约束，也就是不需要操作是按照真实时间严格排序的。Serializability 也不是composable的，它也不表示任何的确定性的顺序，它只是要求存在一些等价的执行序列。另外一位博主给出了如下的论述，即“线性化的一致性要求操作生效的顺序等于实际的实时操作排序。顺序一致性允许操作被重新排序，只要在每个节点上观察到的顺序保持一致。作为用户, 能区分两者的唯一方法是，观察系统的所有输入和时间. 从客户端与节点交互的角度来看，两者是等价的”。 Serializability + Linearizability = Strict Serializability。 弱一致性有的时候系统保证在更新操作后的一段时间后，系统能够达到一致性状态，这称为弱一致性。弱一致性和强一致性的区别是弱一致性存在“不一致窗口”，在不一致窗口中系统不一定保证用户总能看到最新的值。弱一致性可以分为最终一致性、因果一致性、单调读一致性、单调写一致性、有界旧一致性、前缀一致性等。在Azure Cosmos中将一致性的强弱程度建立以下的关系。Strong–Bounded staleness–Session–Consistent prefix–Eventual。从前向后的延迟。可用性和扩展性越好，但一致性会差一点。 最终一致性最终一致性也被称为乐观复制(optimistic replication)，是一种获得HA的常见方式，要求当没有新的对X的提交发生时，最终所有对X的访问都返回最后一次更新的值。最终一致性通常用来提供BASE语义。我们常见的异步复制的主从架构实现的是最终一致性。它的一个典型常见是用户读取异步从库时，可能读取到较旧的信息，因为该从库尚未完全与主库同步。注意，同步复制的主从架构会出现任一节点宕机导致的单点问题。 读己所写一致性读己所写一致性(read-your-writes consistency)又称为read-after-write consistency，如下图所示，读己所写一致性要求客户端总能读到自己最新提交的写入。特别地，读己之写一致性不对其他用户的更新做出承诺。 读己所写一致性可以通过以下的一些方式实现： 当读取可能被修改过的内容时，强制从主库读。 对于大部分内容都可能被修改的系统来说，以上的方法并不适用，此时可以跟踪上次被更新的时间，并强制在上次更新后的某段时间内强制从主库读取。 客户端维护最近一次写入的时间戳，系统只从至少拥有该时间戳的修改的从库中进行查询。 当数据副本分布在多个数据中心时，可能带来额外的复杂性，这里略过，详见DDIA。 会话一致性会话一致性能够保证在该会话内一致前缀读、单调读、单调写、读己所写、write-follows-reads一致性。 单调读一致性单调读一致性要求客户端在已经读到某个数据的某个版本之后，不可能在稍后的读中读到该数据先前的某个版本。如下图所示，User2345首先从Follower1读到了55555这个评论，但是在稍后的对Follower2的读中却没有读到，这是因为Follower2此时还没有收到Leader异步复制过来的日志。令User2345读Follower1的时刻为X，则User2345在晚于X的一个时刻读取到了数据早于X时刻的版本，这违背了单调读一致性，即发生了时光倒流的“现象”。 DDIA指出单调读一致性介于强一致性和最终一致性之间，保证了先前读取到较新的数据的情况下后续不会读到更旧的数据。 一致前缀读有界旧一致性有界旧一致性(Bounded staleness)保证了读到的数据和最新版本最多差K个版本。 可调一致性诸如Cassandra的系统在最终一致性的基础上提供了可调一致性。对于任何读写操作，系统允许用户配置成功写操作的最小节点数W、成功读操作的最小节点数R和副本节点的数量N。我们可以根据读写请求的数量来动态调整可用性C和一致性A之间的trade-off。 因果(Causal)一致性因果一致性(causal consistency)是在ZAB协议中常常见到的一种一致性。因果一致性要求如果A在因果上先于B（在实际场景中可以表现为B依赖A的结果、A先于B发生等），那么A一定先于B被提交。因此，因果一致性实际上是偏序的，如果A和B之间没有先后关系，那么A和B就是可以以任意顺序被提交的。因此，可以看出，因果一致性是比线性一致性要弱的一个一致性，因为线性一致要求全序关系。 在单核单线程上的因果一致就是线性一致，这是因为整个程序是顺序执行的。 因果(Causal)一致性和Lamport Clock由于在集群中维护以现实为标准的物理时钟的性价比是较低的，而从对因果一致性的讨论中可以看出，节点之间只需要在需要共同访问的时间的先后顺序上达成一致，那么此时逻辑时钟是一个很好的工具。Lamport Clock或者Lamport timestamp，即逻辑时钟的定义如下 在同一进程中，如果A先于B发生，那么C(A) &lt; C(B) 注意，反过来，这个是不成立的。一个平凡情况，就是进程p1上面有一个事件a，LC是1。另一个进程p2上面发生了非常多的事件b1..b100，b100的LC是100。两个进程没有任何交互。那么肯定是没有happen before的关系 如果消息M从进程P1发送到进程P2，令P1的发送事件为a，P2的接收事件为b，有C(a) &lt; C(b) 如果C(a) &lt; C(b)，C(b) &lt; C(c)，则C(a) &lt; C(c) 它和happen before关系是很像的。a happens before b，即a -&gt; b表示下面一些情况： a和b需要在同一个进程里面，a在b前面发生； a发送消息，b接受消息； 具有传递性，即如果a-&gt;c、c-&gt;b则a-&gt;b 逻辑时钟Lamport clocks和Vector clocks常被用来描述因果一致性。Lamport时钟的算法可以被描述如下。注意在这里Wikipedia与诸如文章1和2在表述上有一些冲突，这里没有time + 1。但通过看下面的图可以发现，其实说的是一个意思，也就是说发出去会+1，收到也会+1。只是他们把产生一个事件和发送打包成一个整体来讨论了。1234567# 事件在当前节点发生time = time + 1;# 发送事件 send(message, time);# 接收事件(message, time_stamp) = receive();time = max(time_stamp, time) + 1; 通过下图，我们可以从这个偏序关系整理出若干种全序关系（一个常用的方式是按照进程号进行排序），虽然真实发生的是其中的一种情况。 通过逻辑时钟，我们可以解决对共享状态访问的竞态问题了，但诸如节点故障单点问题等问题还需要容错机制来解决。 广播和全序广播全序广播(total order boardcast)有关一致性的另一个概念。首先，total order即全序关系，是相对于偏序关系(partial order)的一个概念。全序要求在序列中的任何元素都能有确定的先后关系，而偏序则只要求序列中某些元素具有先后关系。整除关系是一个典型的偏序关系。 广播主要分为几个过程，首先是从发送方发出消息的broadcast过程，消息在网络中传播的过程（可能会丢包乱序重复等），以及最后送达接受方的deliver过程。广播有下面几种类型，这些类型是依次增强的，从FIFO开始，对各种乱序的情况进行了规范。 best effort广播 reliable广播 引入重传 FIFO广播 如果m1和m2来自同一个node，并且broadcast(m1)-&gt;broadcast(m2)（这里箭头表示happen before关系），那么m1也要在m2前面被deliver。 通俗一点讲，就是从同一个节点broadcast出来的消息的书序和他们被deliver的顺序是一致的，但是对于不同节点出来的，是无所谓顺序的。 对于下面的图，到C节点的deliver顺序可以是213，123，132。 Causal广播（Causal表示因果的，不要和casual搞混） 如果broadcast(m1)-&gt;broadcast(m2)，那么m1也要在m2前面被deliver。 看起来，只是比FIFO广播少了“在同一个node上的条件”而已，实际差别是什么呢？其实在后面的文章中定义了happen before，照着happen before的三种情况，就容易理解了。这里多了的就是A发消息，B收消息这种跨node的happen before关系。 对于下面的图，如果broadcast(m1)-&gt;broadcast(m2)且broadcast(m1)-&gt;broadcast(m3)，那么合法的deliver顺序是123和132。 Total Order广播 如果在一个node上，m1在m2前面被deliver，那么在所有node上，m1都在m2前面被deliver。 既可以像下面的图一样，所有节点都按照123的顺序deliver。这里需要看到来自node A的请求m3，必须要delay到来自node B的请求m2被deliver之后才能deliver，即使这个请求是自己发给自己的。 当然了，所有节点也可以按照132的顺序来deliver。 FIFO Total Order广播 就是FIFO和 Total Order的结合。 各类广播的实现reliable一个naive的想法是重传，同时处理重复包（例如可以通过编号的方式）。但如果在重传前传播的节点就宕掉了，那么reliable就无法保证。一个简单的修复，就是每个节点在第一次收到消息之后，往其他节点转发一下消息。但这个行为会导致为了广播每一条消息，整个集群中总共发送$O(n^2)$个消息。Gossip协议是对上述的一个优化。每个节点在第一次收到消息之后，会随机发送给fanout个节点（例如随机发给3个节点），有点像流行病毒传播一样。Gossip协议能以很高的概率实现reliable。 FIFO对于每一个node，维护下面几个变量： i 表示发送方node的编号 seq 每个节点维护自己broadcast的信息的序号 delivered[j] 是一个数组，表示对于node j，我们总共deliver了几个序号 buffer 用来存放尚未准备好deliver的信息 发送方发送信息m，格式是(i,seq,m)。在发送后，需要自增seq。接收方在接收来自i的信息后，先放到buffer中。接着在buffer中寻找seq等于delivered[i]的信息，如果存在，就deliver，并且自增delivered[i]。这个方案实际上就是说接收方给每个发送方维护一个队列，通过这个队列保证自己收到来自i连续递增seq的信息。 Causal对于发送方，需要复制自己的delivered数组为dep数组，设置dep[i]为seq。发送方发送(i,deps,m)。在发送后，需要自增seq。接收方在收到某个消息(i,deps,m)之后，需要满足deps&lt;=delivered条件之后，才能deliver这条信息。不过这个涉及到了比较两个数组，其规则就是所谓的vector clocks ordering： T=T&#39; 等于关系表示两个向量的每个对应元素都相等 T&lt;=T&#39; ……都小于等于 T&lt;T&#39; T&lt;=T&#39;且非T=T&#39;，也就是说只要有一个不等于，那就是小于 T||T&#39; 平行关系，既不T&lt;=T&#39;，也不T&#39;&lt;=T Total Order通常有两种方式： 借助Leader 如果需要广播信息，则发送给Leader。Leader按照FIFO的方式广播信息。 这种方式需要解决Leader可能存在的单点问题。 借助于Lamport timestamp 对每个消息加上Lamport时间戳，并且按照Lamport时间戳deliver消息。 这种方式的问题是如何判断自己已经收到了所有timestamp小于T的所有消息。这需要使用FIFO连接，并且等到所有node上大于等于T的信息。 实现全序广播等价于实现线性一致的存储。 可用性可用性即reads and writes always succeed。这个要求系统能够始终在正常时间内对用户的请求进行响应。当然由于可能出现的一致性问题，这个响应不一定是正确的。 分区容错性分区容错性即the system continues to operate despite arbitrary message loss or failure of part of the system。由于分布式集群中常出现网络分区情况，即集群中的一部分机器与另一部分机器中断连接，这可能是由于网络故障，产生网络分区；也可能是由于某些节点宕机。网络分区可能产生的一个后果是脑裂(split brain)，也就是存在多个节点认为自己是领导者。 我们除非设计出一个永远不会出故障的网络，否则我们必须要容忍P。于是C和A便成为了trade-off。由于网络分区的概率比较小，并且是易于探测的，所以C和A大多数情况是能够比较好地满足的，所以说我们要做的不是根除网络分区及其导致的部分失效(partial failure)问题，而是去正确地处理它，这就引入了诸如2PC、RWN、Paxos等协议。 分布式事务由于分布式系统中存在多个副本，所以维护这些副本的一致性成为核心问题之一。分布式事务相对于仅涉及单个数据库事务的难点在于其提交或回滚不仅决定于自身，还决定于其他节点上事务执行的状态。从理想考虑，只要有一台节点失效，其他节点就要进行rollback。为了实现这一点，需要一个协调者(Coordinator)来根据所有参与者(Cohorts)的情况判断是否完成提交或终止提交。同时协调者的故障称为单点故障，也就是这个故障能够直接导致集群无法运行，需要特别考虑。 2PC和3PC对于分布式事务处理，MySQL引入了XA机制，也就是所谓的2PC、3PC的算法。这种方案是在数据库层面的，也就是通过一个事务管理器去协调各个事务的提交，因此往往不能很好地适配现在微服务的框架，因为微服务下不允许访问其他服务的数据库。出于篇幅限制，见文章2PC和3PC。 TCC补偿事务(Try-Confirm-Cancel, TCC)的中心思想是：针对每个操作都要注册一个与其对应的确认和撤销操作。相比于2PC等算法，TCC是一个应用层面的协议。这个方案对应用架构是强侵入性的，因为要求每个业务的接口都要实现TCC三个接口。所以一般用在金融领域。 分布式锁在使用分布式锁前，可以先考虑是否能够通过一（原子）写多读来维护分布式状态。 通过Redis实现分布式锁 SETNX命令 这里NX表示会创建也就是说如果不存在就创建一个key，表示这个进程获得了锁。 解决持锁进程崩溃带来的死锁问题 给锁字段加一个超时时间，即使用EXPIRE命令。 现在需要SETNX和EXPIRE两条命令，不是原子的了 有两个选择： 对于旧版本，可以使用LUA脚本 对于新版本，可以使用新的SET命令 确定锁的所有权 有人问，为什么要确定锁的所有权呢？我加锁的进程自己知道，没加成锁的进程也自己知道。其实不然，假如说进程A加锁之后，锁过期了，被进程B重新获得，那进程A是不知觉的。他可能直接把锁DEL掉了，但实际上他DEL的是进程B的锁。但如果每个进程，用随机数，或者pid来标记，并且在删除的时候判断下，就不会有这个问题了。 分布式共识分布式共识的特性我们需要区分分布式共识和分布式事务。分布式共识协议被用来解决分布式系统上出现的一致性问题。通过共识协议，我们能够让一个集群的行为如同一个单机版的可靠的节点一样，即使其中有一小部分的节点宕机或分区。具体地讲，一个正确的分布式共识算法应当满足以下三个特性。 agreement 决议需要得到所有节点的认同，通常是首先批准一个多数票的决议，然后进行同步。 validity 决议的值需要满足合法性要求。 termination(liveness) 决议过程能够在有限步内结束，并产生结果。 以上的三个特性可以总结成两点，safety和liveness。safety要求系统不会产生一个错误的值，而liveness要求系统不至于陷入阻塞。对于分布式事务来说，safety要求一个进程提交则全体进程提交，一个进程回滚则全部进程回滚，liveness要求如果没有故障，并且可提交则立即提交；如果有故障则立即回滚。 FLP定理论文Impossibility of Distributed Consensus with One Faulty Process证明了在异步系统中，只要有一个进程出错，那么系统就不一定能达成共识（不满足termination要求）；而在同步系统中，即使是拜占庭条件下却能够达成。 首先，FLP定义了一个异步系统，它应该满足如下的特点 非拜占庭的Fail-stop模型 最多一个进程失败 可靠通信、原子广播 即通信最终会被送达，且仅被送达一次。但是消息消息可任意延迟、可乱序。例如基于TCP的通信并不满足这个条件，因为TCP承载的消息是不可以乱序的。 异步通信 没有时钟、不能时间同步、不能使用超时。 此外，进程之间还不能探测失败，因为我们无法判定一个异步进程到底是宕机了还是只是算得太慢。 系统中包含一系列进程，他们之间通过全局消息队列进行通信。例如进程p1可以用send(p2, m)向进程p2发送消息m，进程p2通过持续不断receive(p2)来获取自己的消息，并event(p2, m)来执行这个消息，这称为一个step，一系列连续的step组成一个run。我们定义一个configuration为当前所有进程和消息队列的状态（也就是整个系统的状态），那么一个step就会使得系统从一个configuration到达另一个configuration。当然，可能p2由于分区等原因接受不到消息，这时候就表示为m为NULL。 假定所有进程以一个输入yp的{0, 1}初始值开始，并试图达成一个{0, 1}的某个值上达成一个决议，并输出到寄存器yp。yp的值为{b, 0, 1}，其中b表示未产生表决结果的初始状态，一旦yp从b变为0或1，这个值就不再可以被修改。如果某个configuration中存在进程的yp是v，那么就可以说这个configuration是v-valent的。如果只有一个这样的v，那么就是univalent，否则就是bivalent。我们期望所有的正常进程最终都能达成正确的决议，但实际上FLP定理的证明中构造了一种情况，即使某些进程能够最终进入univalent的这一点都无法保证。 最后，还有一些定义。如果一个进程p在一个run中能运行无数个step，那么它是非故障的。定义能从初始configuration到达的configuration是accessible的，一个共识算法是部分正确的，当 所有accessible的configuration都有相同的决定值 所有accessible的configuration里面不能只有0或者1，不然这样我搞一个系统永远输出0，那不是永远部分正确了么？我们不允许这样的平凡解 整个的FLP定理的证明分为三个引理。第一个引理很直观，把进程分为两个不相交集合P1和P2，往P1和P2分别发送R1和R2，那么R1和R2的提交顺序不影响最终结果。这个对Lamport时钟有了解的都能够想明白。第二三引理类似于归纳法。第二引理证明了在有一个进程失败的系统中，一定存在一个不确定的初始configuration。证明用到了构建相邻环的思路，用大白话讲一下就是反证法假设系统从某个univalent开始，根据部分正确的条件2，我们要求有两个configuration为C0和C1分别是0/1-valent的。l论文中指出，必然存在decision value为0的系统C0和为1的系统C1只差一个进程p。例如三个进程的状态110和100就只差一个p2，但我们设计一个投票制的共识算法，那么前者决议为1，后者为0。现在我们假设p故障了，然后我们尝试以C0或C1为初始configuration来进行admissible deciding run。那么C0和C1必然会进入同一个值，假如说我们令它为1，那么C0的decision value就是{0, 1}了，它就不是univalent的了，从而推出矛盾。第三个引理中指出在某种情况下，如果C是bivalent的，那么从它可达的Y也是bivalent的。首先，我们定义事件e=(p,m)，可以分出不应用e可达的configuration的集合X和对X中的configuration应用e可达的configuration的集合Y。因为e能应用到C，并且可以被任意延迟，所以它肯定也能应用到E。现在同样使用反证法，假设Y中不含有bivalent的configuration，Ei是从Ci到达的某个i-valent的配置，由于Ci是bivalent的，所以i能够取0或1。如果Ei属于X，那么对它应用e得到Fi，则Fi肯定就属于Y了。如果Ei不属于X，说明Ei已经在之前收到过消息e了，那么它会先到达一个属于Y的配置Fi，然后再到达Ei。总而言之，无论走那条路，我们都会得到一个Fi的configuration，它是落在集合Y中的。那我们开始的集合是bivalent的，最后又都会落到同一个集合中，那么Y中肯定既有0-valent又有1-valent的configuration，到这里为止和假设还是不矛盾的。我们定义两个configuration相邻，当其中一个在一个step里面会产生另一个时，也就是C0和C1都属于X。不妨设C1=e&#39;(C0)，其中e&#39;=(p&#39;, m&#39;)，当然反过来假设也可以。容易得到，对于这两个Ci，D0=e(C0)是0-valent，D1=e(C1)是1-valent的。我们可以得到一个如下图中实线所表示的有向图。下面展开讨论 如果p不等p&#39;，我们可以将它们划分到两个不相交集合中，所以根据引理1，可以得到D1=e&#39;(D0)（上图中的虚线）。那么这也就意味着从一个0-valent的节点到达一个1-valent的节点，而这是不可能的，因为0-valent的后继只能是0-valent的。 那么p等于p&#39;了，也就是说从C0到D0和从C0到C1都源于同一个节点进行的step。那么我们将这个进程独立出来，假定它宕掉了。那么从C0就能通过σ到达一个A状态。看图的左半部分，假设对于这个A状态应用e，可以到达E0，那么根据引理1，对D0应用σ得到E0。同理，可以构造右边的一个E1，从而发现A既可以变到E0又可以变到E1，它是bivalent的，与假设矛盾。 拜占庭将军问题拜占庭将军问题指在一个有N个节点的集群内部，有F个节点可能发生任意错误的情况下，如果N &lt;= 3F，一个正确的共识不可能达成。这里的任意错误包括节点前后的行为不一致，例如在投票时投给两个不同的节点。 诸如Paxos之类的算法只能对节点宕机进行容错，而不能对节点的拜占庭故障进行容错。这类基于复制状态机实现的协议，需要N &gt;= 2F + 1才能确保共识的达成。 实用拜占庭容错算法(Pratical Byzantine Fault Tolerance, PBFT)是一种多项式复杂度的状态机复制算法。 CAP理论CAP理论认为一致性(consistency)、可用性(availability)和分区容错性(partition tolerance)是不可能同时被满足的。这里的一致性指的是强一致性。如果我们将这里的Consistency替换为Consensus（实际上两者说的不是一个东西），那么根据FLP定理，对于一个异步系统，我们无法保证CA。当然，在工程上，CAP理论的情况还是能够被极大程度绕开的。例如我们可以引入同步机制，当一个节点与其他节点分区达到一定时间后，就会去声明自己宕掉了。或者，我们可以使用像Redis Sentinel一样的机制，使用另外一套班子来检测集群的状态。 复制状态机复制状态机(Replicated State Machine, RSM)由Lamport提出，源自Paxos算法。复制状态机通过同步日志，使得多个节点从相同的初始状态开始，按顺序执行相同的命令，转移到相同的状态。容易看出，复制状态机的关键点是如何让每个状态机就提交顺序达成一致。因此，分布式共识协议常被用作在复制状态机的上下文中。复制状态机中向所有节点同步的内容是操作本身，我们可以理解为同步的是某个值的增量。与复制状态机相对应的是在ZAB等协议中常出现的primary backup system，它向所有节点同步的是操作的结果，我们可以认为同步的是值本身。容易看出RSM的设计使得我们回滚操作变得简单，仅仅删除掉后面的日志即可，但不好的地方在于RSM往往需要比PBS系统较多的日志条目，因为PBS可以只保存对状态机有修改的操作。 基于RSM的日志复制形式是State-machine replication，能够实现FT。通常地，一个支持F个（独立随机的）故障的系统需要2F+1个replica，对于Fail-Stop情况，即故障的系统保证不产生任何输出时，只需要F+1个replica即可。特别地，对于拜占庭故障，即某个节点向不同方向发送不同值的情况下，根据消息是否加密验证需要2F+1和3F+1个replica。 通常的SMR的实现是串行的，即每一个SMR的副本以单线程的形式处理Propose-Append-Broadcast-Apply的过程，只有当客户A的请求Apply之后，才能继续处理客户B的Propose。事实上，SMR的一个实现细节就是为所有的输入选择一个特定的顺序，注意到现实中的输入是偏序的，但SMR要求一个全序(total order)的输入。这样每一个非故障的副本才能在同样的状态通过同样的输入到达同样的结果。 Pipeline是对串行方式SMR的一个优化，即使用一个线程接收请求，一个线程处理请求，一个线程响应客户端。 分布式共识算法被用来解决SMR中存在的问题，例如如何选主，如何处理网络分区等，常见的分布式共识算法包括Paxos和Raft等。这里的共识(Consensus)指的是由一系列独立的实体为一个值进行投票。 2PC、RWN、Paxos等算法的区别首先从设计上讲2PC和Paxos之流就奔着不同的目标而去。诸如2PC之类的协议是为了实现分布式事务，因此它涉及到的是对多个值修改的ACID性质，而分布式共识协议是为了管理一个值的多个replica。例如，我们可以认为2PC针对多个Partition，而共识算法针对于多个Replication。 再从可用性上考虑，分布式共识协议是为了维护复制状态机，即通过Leader保证复制状态机的输入是全序(total order的)，从而可以通过复制状态机保证各个节点上的日志是一致的。进一步地，共识协议提供了Leader宕机情况下的选主策略，从而保证了集群的HA。特别注意到在这里，2PC算法中的Leader，也就是协调者在宕机之后集群会整体阻塞，而利用分布式共识算法实现选主策略之后能够极大程度避免这一点。 从CAP理论上来讲，2PC是CA的，它要求所有节点保持全体一致。诸如Paxos的Quorum类算法是CP的，它仅要求实现多数一致。RWN是AP的，因此它实现的是可调一致性而不是强一致性。 常见的共识算法介绍Raft出于篇幅限制，有关Raft已经移到新文章Raft共识算法中。 Paxos出于篇幅限制，有关Paxos已经移到新文章Paxos算法中。 Reference除去在原文中标注引用的内容外，本文还参考了一下内容： DDIA 本文中提到的所有概念的原论文，例如FLP定理等。 Staring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores High Performance MySQL, 3rd edition Zookeepers’s atomic broadcast protocol: Theory and practice ZooKeeper: Wait-free coordination for Internet-scale systems A simple totally ordered broadcast protocol http://duanple.com/ https://danielw.cn/FLP-proof https://www.cnblogs.com/firstdream/p/6585923.html http://loopjump.com/flp_proof_note/ https://www.cnblogs.com/grefr/p/6087942.html https://www.bilibili.com/video/BV17A411W7Cr?p=12]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>raft</tag>
        <tag>paxos</tag>
        <tag>一致性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库系统中的事务]]></title>
    <url>%2F2017%2F09%2F20%2Ftransaction%2F</url>
    <content type="text"><![CDATA[本文主要讲述数据库中事务的控制模型、事务隔离等级和事务并发控制。 本文从分布式一致性和分布式共识协议一文中分离。 我们首先回顾一下非分布式系统上一致性的相关知识。 两种事务控制模型ACID对于关系型数据库，存在ACID事务控制模型维护事务的正确可靠性。 原子性(atomicity) 事务中的所有操作要么全部完成，要么全部不完成（回滚），不会出现中间状态。以转账为例，假设A向B转账200元，那么原子性要求事务不存在A的钱扣了，但是B的钱没到账。 原子性实现需要REDO/UNDO。例如故障恢复时，如果我们决定回滚事务，我们就得参照UNDO来回滚；如果我们决定提交事务，我们就得根据REDO来提交。 一致性(consistency) 在事务开始前和结束后完整性约束（不变量）不被破坏。这里的“一致性常被称为“内部一致性”，以区别分布式系统中的外部一致性C。 隔离性(isolation) 数据库支持多个并发事务同时进行增删改。以转账为例，假设A和B同时向C转账200元，那么结束后C应当收到400元，而不存在只收到200块的情况。 隔离性通过并发事务控制手段，如锁等解决。 持久性(durability) 事务结束后对数据的修改是持久化的。例如系统发生宕机后，已提交的事务不应当消失。丢数据的一个常见例子是主从架构+异步复制，这种情况下durability难以保证。 BASEBASE理论，即Basically Available、Soft State和Eventually Consistent，是相对于ACID准则的另一种事务控制模型，常被用在一些非RDBMS的事务控制的NoSQL中。 在分布式系统的上下文下，BASE可以看做是对CAP理论做出的一种权衡，通常被以最终一致性的形式实现。我们将会在分布式一致性和分布式共识协议中进行讨论。 故障恢复WAL在关系数据库中常使用预写式日志Write ahead log(WAL)算法，WAL要求在数据实际写入之前先写日志，这样能够保证在故障发生后能通过日志进行恢复。相比于将数据实际插入数据库，WAL由于是顺序读写，所以相对来说要快很多。事务有只有两种完成方式，提交即全做事务中的操作，和回滚即全不做事务中的操作。在事务的中间过程中可能对数据块的值进行修改，但最终这些修改必须要通过提交和回滚来实现持久化。AI（后像，After Image），指的是每次更新时数据块的新值。对于一个已提交的事务，当故障发生时应当REDO它的后像。注意一旦事务提交，就不能UNDO它的前像，会破坏完整性约束；但是事务提交前任意的删改都可以通过UNDO来撤销。事务提交和往数据库写值（执行事务）是两个不同概念。BI（前像，Before Image），指的是每次更新时数据块的旧值。对于一个未提交的事务或提交进行到一半，当故障发生时应当UNDO它的前像。UNDO和REDO操作具有幂等性，即对前像UNDO或对后像REDO任意多次，结果都是相同的。 那么REDO操作和UNDO操作是不是缺一不可的呢？通过undo和redo的配合，能够提供更好的ACID特性。我们在有关innodb介绍的这篇文章中会详细介绍。 Shadow paging事务更新的两条规则提交规则后像必须在提交前写入非易失存储器（数据库或运行记录）中。当后像只写入日志而没写入数据库中也可以提交事务，因为出现故障之后可以REDO后像实现恢复。 先记后写规则数据库中有先记后写原则，如果在事务提交前将后像写入数据库，则必须首先把前像记入日志。这样做的好处是在事务提交完成前如果出现故障，可以通过日志文件中的该前像进行UNDO。此时即使数据库没有被修改，也只是进行一次多余的UNDO操作。 事务的隔离等级介绍在了解并发事务控制前，首先需要了解事务的隔离等级。事务具有ACID的要求，隔离性I要求数据库能够支持并发事务。隔离性I的要求主要对应了四种隔离级别，分别是Read uncommitted、Read committed(Sql Server、Oracle等的默认隔离级别)、Repeatable read(MySQL的默认隔离级别)、Serializable，分别可以解决脏读、不可重复读(Nonrepeatable Read)、幻读(Phantom Read)几类问题。 Read uncommitted(RU) 事务A在访问数据时，如果另一个事务在并发修改了该数据且未提交，在Read Uncommitted隔离级别下可能产生脏读(Dirty Read)。脏读指读取了未提交的数据。考虑下面的序列。 A写入X值为x1 B读出X值为x1 A回滚 B读出的X=x1是不合法的 Read committed(RC) 事务A在访问数据时，如果另一个事务在并发修改了该数据且已提交，在Read committed隔离级别下可能产生不可重复读。RC隔离级别下，一个事务开始到提交之前，做出的修改对其他事务是不可见的。不可重复读会导致两次同样的查询得到不同的结果，可以考虑下面的序列。 A读取X值为x1 B写入X为x2 B提交 A读取X值为x2!=x1 A提交失败 Repeatable Read(RR) 在Repeatable Read隔离等级之下，事务A在访问数据时，事务开始后其他事务就不能对该数据进行修改了，因此杜绝了不可重复读。但是如果另一个事务在对其他的数据进行修改，例如在数据表中插入了一个新数据，那么会产生幻读现象，也就是一个事务的两次查询中数据笔数不一致。 幻读的一个典型常场景就是事务t1去insert一个id，但没有commit，这时候事务t2去select一个id，发现没有，那么他就也insert这个id，发现主键冲突了。但select还是select不到，就好像出现幻觉一样。 Serializable(S) 等同于在每个读的数据行上加S锁，从而解决了幻读的问题。但这种方法具有很差的并发性，会导致大量超时和锁竞争。 就我理解而言，RU/RC/RR这三个事务等级都是对于一个记录R而言的，但是S隔离等级涉及多个记录R。我们可以类比记录到变量？ InnoDB可以通过间隙锁Next key lock解决了幻读的问题，因此实际上实现了串行化级别的效果，而且保留了比较好的并发性能。 MySQL可以通过SET TRANSACTION ISOLATION LEVEL设置隔离级别。 Demo考虑下面的代码Case11234567Ta Tbbeginselect x from table, x=10 begin update table set x = 20 commitselect x from table, x=? 对于： RU、RC 读到的是20 RR、S 读到的是10 再考虑下面的代码Case21234567Ta Tbbeginselect x from table, x=10 begin update table set x = 20select x from table, x=? commit 对于： RU 读到的是20 RC、RR、S 读到的是10 Snapshot Isolation(SI)和Write skew问题A Critique of ANSI SQL Isolation Levels这篇文章指出了ANSI SQL-92给出的四种隔离级别存在的问题，并提出了Snapshot Isolation。在这篇文章中，作者提出SERIALIZABLE被描述成不会发生脏读、不可重复读以及幻读的一种隔离级别。但这和“可串行”并不等价，例如我们可以构建出一个Write skew的情形，它能满足上述条件，但是却违反了可串行化。 Snapshot Isolation也是来解决2PL系列算法带来的并发度低的问题的 每一个数据都多个版本 每个事务相当于看到数据的一个快照 写写不能并发，写写操作时需要加上行锁 得到行锁的事务可以进行，后面的写事务要么abort，要么block。 Snapshot Isolation相对于SERIALIZABLE的隔离级别要低一些，诸如Oracle宣称提供的SERIALIZABLE实际上也是Snapshot Isolation。 Snapshot Isolation可能带来写偏斜问题。此时，两个并行事务都基于自己读到的数据集去覆盖另一部分数据集，在串行化情况下两个事务无论何种先后顺序，最终将达到一致状态，但SI隔离级别下无法实现。考虑事务P和Q，P试图执行x=y，Q试图执行y=x，那么我们期望的结果是最终x等于y，但是SI可能存在下面这种情况： P读x Q读y P将读取的值写入y Q将其读取的值写入x 也就是说，x和y的值交换了。 并发事务控制为了保证并发执行的事务在某一隔离级别上的正确执行的机制，我们需要并发事务控制。并发事务控制实际上是解决并发事务之间隔离性的问题。并发控制的主要思想可以根据乐观程度进行分类： Lock 这个方法是最悲观的，也就是在访问资源之前，需要加锁。如果获取不到锁，就阻塞事务。 如2PL Timestamp 在每个事务开始时，获得时间戳，并期望事务按照时间戳的顺序执行。如果发现冲突，可以选择阻塞或者回滚。 如Basic T/O Validation 在事务提交时，再进行验证。如果发生冲突，只能回滚。 如OCC系列算法 容易发现，越乐观的策略下，对冲突的检查就越迟。从最悲观的访问资源之前加锁，到最乐观的Commit前验证，并发的能力是加强的，但是失败回滚的可能性也就越来越大。 需要注意的是，以上的策略都有单版本和多版本的实现。这个应该是能比较容易理解的，对于MVCC，因为一次对数据库的修改都会生成一个新的版本，所以实际上在处理隔离性上会更加的灵活。因为我们成功把问题转化到了如何选取版本和管理版本上。 可串行性和冲突可串行性(Conflict Serializability)可串行性要求事务并发执行的效果和事务单独执行的效果是一样的。 关于这一点，我们可以类比到CPU并行编程里面的内存模型。如下图所示，左边的是串行调度，因为事务和事务之间都是串行的了。右边的是不可串行调度，因为右边的结果和左图（先T1再T2）不一样，并且和先T2再T1也不一样。中间的图并不是串行调度，因为T1和T2是彼此交织的，但是它的结果和左边的图是一样的，所以是可串行调度。 和并发编程里面一样，除了读读操作，诸如读写、写读、写写之类的操作都是冲突操作。 一个调度S在保证冲突操作的次序不变的前提下，通过交换非冲突操作的次序得到另一个调度S’，同时如果S’是可串行的，那么我们就说S是一个冲突客串行化的调度。一个调度是冲突可串行化的，那么它一定是可串行化的调度。 如下面这一组图所示。图1就是一个冲突可串行化的调度，因为它可以通过交换顺序得到图3。但是图4就不是一个可串行化。 2PL我们知道死锁有四个条件：互斥、占有且申请、不可抢占和循环等待。而为了解决死锁问题，一个方案就是一次性获得所有的锁，这样实际上破坏了占有且申请的条件。如何避免死锁？我在文章中进行了较为详尽的讨论。避免死锁的一个可行的办法就是一次性请求所有锁（1PL），但这个对数据库来说很困难，因为我们很难知道我们具体要那些资源，并且这样一次性锁协议牺牲了并发性。为此我们引入了2PL，2PL将加解锁过程分为两个阶段，在第一阶段只能加锁或者操作数据，不能解锁；在第二阶段只能解锁或者操作数据，不能加锁。2PL不能避免死锁，如下所示。两个事务按照2PL加锁，假定第一个事务1请求到了4，第二个事务请求到了3，那么1和2就会陷入死锁。那么我们就必须干掉其中一个事务。123456789START TRANSACTION;UPDATE StockPrice SET close = 45 WHERE stock_id = 4;UPDATE StockPrice SET close = 19 WHERE stock_id = 3;COMMIT;START TRANSACTION;UPDATE StockPrice SET close = 22 WHERE stock_id = 3;UPDATE StockPrice SET close = 44 WHERE stock_id = 4;COMMIT; 【Q】我们知道指定加锁顺序，可以避免死锁。例如我们在遍历链表的时候，始终沿着同一个方向遍历等。但是2PL这里的顺序并不是锁的顺序，例如我们先获取第一个锁，然后才能获取第二个锁，而是强调所有的加锁工作必须在解锁工作完成前完成，那么显然这里是不能避免死锁的。既然如此，为什么还需要引入2PL呢？2PL的目的是为了保证可串行性，进而是为了保证隔离性。如果不满足2PL，那么可串行性就可能出问题。考虑下面的Case12345678910Ta Tbbeginx-lock(A)write(A)release(A) x-lock(A) write(A) release(A)s-lock(A)read(A) 容易看出，Ta先后申请并释放了两次A的锁，在这过程中，Tb修改了A的值，结果第二次对A的读取就是有问题的了。 我们需要注意的是，即使遵守2PL，还可能会出现问题。考虑下面的Case123456789101112Ta Tbbeginx-lock(A)write(A)read(B)release(A) x-lock(A) read(A) write(A)write(B)release(B)commit Tb出现了RU的情况。如果此时Ta回滚，那么Tb也要回滚，这称为级联回滚。所以一般数据库会有S2PL和SS2PL，分别要求写锁和读写锁在事务Commit后再释放。 数据库实现了死锁检测和死锁超时机制。以InnoDB为例，如果启动死锁检测(innodb_lock_wait_timeout)，那么会在死锁发生时会选择将持有最少行级X锁的事务进行回滚。当然也可以选择等待(innodb_lock_wait_timeout)超时。 意向锁数据库里面至少有表和行两个层级，我们考虑对某张表里面的一万行加锁，我们有锁表和分别锁一万行两个选择： 表锁 会降低并发度。 行锁 对内存的消耗比较大，同时大量时间会消耗在检查锁。 意向锁的产生就是为了解决这个问题。意向锁要求如果对一个下层节点加锁，那么我们会对上层节点加意向锁。 考虑一个数据表中有一些行正在被锁定，而现在试图加一个表级锁，这显然是要被阻塞的。但阻塞前我们需要遍历数据表的每一行才知道我们表中有些行被锁定了。为此意向锁要求在锁定行时对数据表也维护一个状态，表示当前数据表中有些行时被锁定的，因此你意向是获得表锁，那么请原地阻塞，别往下找了，现在是不可能的。这样在试图加表锁的时候，就不要逐一遍历检查是不是有行被锁住了。 如果把上下层节点组合起来看，能组合成四种锁的类型即SIS、SIX、XIS、XIX。介绍如下： 意向共享锁IS 如果我们想对一行加S锁，那么我们先要对表加IS锁，表示我们对表中的某一行有加共享锁的意向。 意向排它锁IX 同理。如果我们发现一张表加了IX锁，说明里面有一或者若干行被X锁保护。 共享意向排他锁SIX 表明内部至少一个对象被X-Lock保护，并且自身被S-Lock保护。例如某个操作要全表扫描，并更改表中几行，可以给表加SIX。 其他的一些锁的形式并不常见，原因是除了SIX之外其，他的锁并没有提高强度，实际上可以退化为一个表级锁或者行级锁。以SIS为例，我们要读取整个表，对表加S锁，然后要读取其中一行，对表加IS锁，实际上可以简化为一个对表加S锁的操作。 Wait-Die和Wound-Wait这两个策略都是用来解决在锁冲突时，如何共同点： 总是牺牲较新的事务，这里牺牲的意思就是回滚 这是因为老事务往往会持有较多的锁，并且作了不少对数据库的修改，回滚老事务的成本比较大。 这个策略是公平的 当事务重新开始的时候，应当保留自己的时间戳。 最终，被牺牲的事务会变得足够老。 不同点： Wait-Die策略在新事务发请求时将新事务杀死 这里发请求指的是请求lock，这个锁被老事务持有。 Wound-Wait策略在老事务发请求时将新事务杀死 这里发请求指的也是请求lock，这个锁被新事务持有。 我们比较一下两者的性能： Wait-Die会导致较多的回滚，但是这些回滚的事务只会进行很少的修改 Wound-Wait会回滚较少的事务，但这些回滚事务可能已经进行了比较多的修改了 Timing Order(T/O)基于TO的并发事务控制，也就是给每个事务分配一个timestamp，用它来决定事务的执行顺序，其中timestamp较小的事务优先执行。这里的timestamp可以是物理时钟，也可以是逻辑时钟。 下面我们以Basic T/O为例介绍。和MVCC类似，每条记录里面也要增加一些标记，这一次增加的是最近一次读和写记录X的事务的时间戳，记为WTS(X)和RTX(X)。我们再令当前事务的时间戳是TTS。 考虑读： TTS &lt; WTS(X) 即有一个比TTS更新的事务写了X记录。那么这个X对TTS是不可见的，我们要abort掉TTS。 TTS &gt; WTS(X) 记录X对事务TTS是可见的，更新RTS(X) = max(TTS, RTS(X))。 考虑写： TTS &lt; WTS(X)或TTS &lt; RTS(X) 需要abort掉。 为什么要求TTS大于WTS(X)呢？这个很简单，我们不能覆盖更新的写。 为什么要求TTS大于RTS(X)呢？我们不妨思考什么时候出现TTS &lt; RTS(X)这个情况？这说明在这个事务之后，有事务(令为Tb)已经读取了X的值了。如果我现在修改X的值，就会破坏RR的约束。因为如果Tb再次读X，会发现和之前的结果是不一样的。 否则 可写，并且更新WTS(X) = TTS OCCMVCC多版本并发控制(Multi-Version Concurrency Control, MVCC)是相对于单版本的概念， 有不同方式的实现，如基于锁的MV2PL，基于时间戳的MVTO，基于乐观并发控制(Optimistic Concurrency Control, OCC)的MVOCC。MVCC是为了提高数据库的读性能产生的一种思路，是一种解决读写冲突的无锁并发控制方式。 根据Wikipedia，MVCC意图解决读写锁造成的多个、长时间的读操作饿死写操作问题。每个事务读到的数据项都是一个snapshot并依赖于实现的隔离级别。写操作不覆盖已有数据项，而是创建一个新的版本，直至所在操作提交时才变为可见。快照隔离使得事务看到它启动时的数据状态。 具体来说： 当事务Ti读取对象P时，只有比Ti时间戳更早的最新对象版本是可见的。 当事务Ti写入对象P时，如果Tk要写同一对象，那么Ti必须早于Tk才能成功。【Q】这个说法就很奇怪，那对称地，Tk不是也要早于Ti么？ MVCC实现(InnoDB)我们主要讨论RC和RR下的MVCC。至少对于InnoDB而言，RU和S是不兼容MVCC的。容易想到，RU始终读取最新的记录，并不需要考虑版本，而S默认要加锁，并不需要考虑并发。 记录结构在使用MVCC时，InnoDB需要对每一条记录多存储一些字段： trx_id 标记最近一次修改这个记录的事务的ID。 db_roll_ptr 回滚指针，指向Undo。 因此，一次UPDATE事务的流程可以如下所示： 事务begin 对记录申请X锁 写REDO 写UNDO 实际修改Record 除了修改值之外，还需要修改trx_id指向当前事务，修改db_roll_ptr指向UNDO。 RC下的MVCC在ReadView中维护一个列表m_ids，里面存放了所有当前活跃事务的ID，可以和每条记录里面的trx_id对应，其中trx_id能够代表事务开启的先后顺序。令其中最小值是low，最大值是up。假设我们现在需要访问某一条记录，我们进行如下的判断 被访问的trx_id小于low 说明生成该版本的事务在ReadView创建前就提交了，所以可以被访问。 被访问的trx_id大于up 说明该事务在ReadView创建后在生成，所以不能被当前事务访问。需要通过Undo Log找到上一个版本，再判断一次可见性。 【Q】这个规则有点奇怪，例如对于上面的Case1而言，这里应该是返回新值的。但这个规则导致新值不能被使用。 如果trx_id落在[low,up]之间 需要判断trx_id是不是在m_ids中。 如果在，说明在ReadView创建时，生成这个版本对应的事务还是活跃的。因此不能访问，需要回溯Undo Log。 否则，说明在创建时，这个事务已经提交了。【Q】那为啥trx_id还会落在low和up之间呢？我想可能是因为这个事务非常短，例如同时有123事务开启，然后2就结束了，但是1和3一直延续到ReadView创建时。 在RC下，每一个SELECT都会生成一个ReadView。 RR下的MVCC在RR下，在第一次读的时候创建一个ReadView，在创建ReadView之后，即使有其他事务提交，也不会对ReadView的内容造成影响。 例如，事务Ta的ID是200，在没有提交时，事务Tb开始查询。假如事务Tb的ID是300，此时生成ReadView的m_ids为[200,300]。那么一直到这个事务结束前，m_ids都不变化了。假设现在Ta提交了，但由于它的ID在m_ids中，所以事务Tb还是只能回溯访问版本链中的记录，对应的值是10。 S下的MVCC不需要MVCC，因为一定要加锁了。 Reference https://houbb.github.io/2018/09/01/sql-2pl https://draveness.me/database-concurrency-control/ 讲解了并发事务控制 http://www.mathcs.emory.edu/~cheung/Courses/554/Syllabus/8-recv+serial/deadlock-compare.html 讲解了wait-die和wound-wait https://www.huaweicloud.com/articles/15e862d136110a0b026c911ace78caa7.html MVCC等 https://zhuanlan.zhihu.com/p/91208953 事务隔离级别，以及MVCC的实现和比较 https://zhuanlan.zhihu.com/p/130242140 介绍了TO和OCC https://csruiliu.github.io/blog/20180215-db-serialization/ 介绍可串行性 http://blog.kongfy.com/2019/03/serializable/ 介绍另一种隔离级别的认知 介绍了各个主要数据库的隔离性 http://www.nosqlnotes.com/technotes/mvcc-snapshot-isolation/ 介绍Snapshot Isolation https://pingcap.com/blog-cn/take-you-through-the-isolation-level-of-tidb-1/ tidb对事务隔离等级的论述]]></content>
      <tags>
        <tag>数据库</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黄山游记]]></title>
    <url>%2F2017%2F08%2F20%2F%E9%BB%84%E5%B1%B1%E6%B8%B8%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[黄山之行屡屡被耽搁，终于在第四次勉强成行。 D0黄山分为屯溪区、徽州区和黄山区，其中黄山风景区位于中间的汤口镇。南京只有到黄山市区的K字头，为了避免麻烦的中转，我们选择了直达黄山风景区的客车。上午宵哥来到龙江，我们在新城市广场吃了午饭，又去金润发买了点吃的。中午在家里休息了会便前往车站。到了小红山车站检票时发现这辆车还要到一个叫泾县的地方。上车发现人很少，坐我旁边的也是一个搞土木的，现在工地轮休，他放了一个月假，便出来玩玩。我们天南地北地聊了一阵，他是徐州人，公司是做地铁的，现在主要在做前期地质勘探之类的任务。这辆车和我们预想的路线一样，到了芜湖南便下了高速，不过下面的G205居然修得不错，还是高架的快速路，外面阳光普照。这时候大概四点半不到，小猪说她已经到了。不过后来发现是太平镇，她还需要转车到黄山风景区。不过过了南陵县进入了宣州路况便越来越差。可能是泾县没有客人，我们并没有停靠车站，过了泾县，便进入了两车道的盘山公路，天也渐渐阴了下来。五点半时炜哥和小猪都到了，这时候黄山风景区开始下雨了。 D1早上五点半起，在宾馆吃了十块钱一碗的鸡蛋面，老板驱车把我们送到黄山南门。购买了19元的新国线班车到达云谷寺索道站，买完票差不多已是七点一刻。索道非常长，但也非常得快，上下车时缆车由一个转动缓慢的轮盘牵引，然后又过渡到一个转动迅速的轮盘上出发。一路上风飕飕地吹，远处的云海若隐若现。没一会我们就到了白鹅新站，下了索道跟着路牌就可以到达第一个景点始信峰。旅店老板给的登山拐杖刚度太高，我斜敲了敲地面下面一截就断了。 参观完始信峰路过连理松可以走到黑虎松，这里是个三岔路口，从在这里应该往下走，便能到达北海宾馆。途中我们能够看到梦笔生花景观。最容易发现的是笔架峰，它像一个手掌五个指头，顺着笔架峰往右看可以发现一个长瘦的孤峰，上面长有一棵松树，这便是梦笔生花。 到达北海宾馆后有一个岔路，可以去看猴子观海、清凉亭等景点。清凉台是一个崖壁上向外伸出的一条长桥，我开始以为这只是黄山上常见的一个供拍照的设施，下了山才知道这就是曙光亭。 从北海宾馆继续前行便进入了西海大峡谷地界，路上我们可以看到团结松，原来这棵松被称作多子多孙松，后来出台了计划生育政策，遂改名团结松。据说这松有56枝，代表着团结的56个民族。从这里往西看去可以看到高处的“飞来石”（不确定）和一个电视塔。 过了西海饭店，便进入了西海地界。据说为了保护原始环境，西海的栈道都是附着于崖壁之外，螺旋地往下延伸，往上看可以清晰地看到深深嵌入山体的外伸梁以及其承载的阶梯，往下看，一道五彩斑斓的蜿蜒的人流如同排列整齐的蚂蚁群一般，为我们标记了前方拥挤的道路。阶梯开始变得越来越窄也越来越陡，人却渐渐变得很多，我们前后都被旅行团包围了，时而不时反方向往上的游客也越发增加了我们前行的难度。我们脚下一直是壁立千仞的深切峡谷，可惜我们去的时候天气很好，并没有什么云雾缭绕的景象，我们甚至可以远远地看见谷底宛如一道轻轨一样的地轨缆车。往对面看还可以看到光明顶上的球和左边的电视塔。峡谷有点像图片上的张家界一样，矗立着许多石柱，还有一片片的山脊，如同刀锋一般，宛如骆驼的头与驼峰。 这时看向地轨缆车，我们发现轨道是有相当的坡度的，而车身则顺应这坡度成平行四边形状。由于是单轨，所以应该只有一辆缆车来回带客。 终于我们顺着队伍从石阶下到了平地地轨缆车售票处，往前已经被栏杆画成一块一块的迷宫，工作人员走出了售票亭，沿着迷宫站着，游客们纷纷伸出手，向他们买票。终于我们坐上地轨缆车。到了天海站，赶快去上了趟厕所。天海站有一片观景台。 俗称爬上光明顶看个球，原来光明顶上还真有个球，也就是气象雷达。光明顶的最高处是一个气象站，气象站下面还有一个直升机停机坪。从光明顶往南望，是一片云雾缭绕，旁边的导游在给团员解说，雾气之后便是黄山第一高峰，海拔1864的莲花峰。光明顶是黄山前后山的分界，还是安徽境内长江和新安江的分水岭，以北的河流汇入长江，以南汇入新安江。爬上光明顶，日落还有一段时间，一看飞来石只有700m，我便想去飞来石逛一逛。大家比较累，走到一半发现飞来石还有一公里，霄哥看去三岔口的另一端的群峰顶只要0.1km，便建议我们去群峰顶看日落。群峰顶非常好爬，而且的条件比光明顶要好很多了，没有树木的遮挡。我站在群峰顶上往飞来石看去，发现这一公里的路竟然出奇得短，于是便自己爬下群峰顶飞奔去看飞来石。 从天海往光明顶方向走不了多远就是白云宾馆。为了以防下雨，我们奢侈地住了300块钱一张床位六人间而不是帐篷，这里一个标准间要2400，一个套房要5800，惊人的房价着实吓了我一跳。我们的六人间并不在富丽堂皇的大厅，而是在靠近天海的1号楼北楼二层。白云宾馆不同于青年旅社的地方是男女分宿，我们到了房间后床位还余四张，而且都是可能闻臭脚的位置。 晚上回来，炜哥下铺是一个苏州来的老爷爷（瞬间发现苏南上海这边的老人真是老当益壮啊，上次去敦煌也是遇到一队上海的老人），问了我们去了哪些地方，我们说在西海大峡谷混了两个小时，他便问我们有没有坐地轨缆车。当然有啊，还真感谢坐了这缆车，老人知道了莞尔一笑，你们要趁人少的时候去啊，周五人已经开始多了。原来老人家已经是第七次来黄山了，他基本上每年都要来次把次黄山，他又为我们解惑，如果我们不坐地轨缆车，那就得没到谷底的时候就走岔道去，到谷底就迟了。后来他听到我们吐槽宾馆贵，告诉我们周日到周四这里一张床只要170块，同样是周五会贵一点。黄山最好看的时候反而是冬天，老爷爷说，虽然说西海大峡谷和天都莲花 D2早上四点半起床硬是拖到五点才出发，匆匆抢爬光明顶，右手边已是红光一片。到了光明顶上往炼丹峰方向走有一个很大的平台，上面已经乌央乌央站了好多人。看完日出已是六点左右，我们往玉屏楼方向走没多远便看到一片视野极好的观景地，坐在石头上可以毫无遮拦地观赏日出。我们在那里歇息了一会，吃了点早饭，天上开始飘起毛毛雨，身后挂起一道彩虹，与蔚蓝的天空相映成趣。上了百步云梯便到了莲花峰登临起点。此时我们的水已经消耗一空了，炜哥还是忍不住了，在联华超市买了两瓶水，这里的价格已经涨到了10元。往下走一段有一个岔路，问路人玉屏楼和厕所都是往左边走，我和徐炜往左走到一半发现人不见了，徐炜说小猪往右边走说有个莲花洞景点，于是我折返过去寻找他们。那是依着崖壁建造的有顶石廊，凌空看去，对面风光尽收眼底，不一会我们下到了莲花洞，莲花洞洞门巨大，但往里走却仅有一条狭窄的短通道，穿了过去傻眼了，前面正是登百步云梯时遇到的那一个岔道。于是我们又哼哧哼哧爬了上来回到三岔口往左走，过了金龟探海景点走不了多远便到了厕所，这个厕所很有意思，它需要走一段楼梯到达下面一层才能进去，我差点都没发现。上完厕所刷了刷朋友圈，居然看到了法的留言，他说他今天早上刚好也到了黄山，天呐果然是2017与法同行，法真是无处不在。聊了聊，原来法正好今天陪着（政治任务）爸妈和邻居一起过来玩。天都峰是黄山的第三高峰（爬上去从手机上看是高1840），却是最险峻的一座。在玉屏楼看完迎客松后顺着步行下山到慈光阁的牌子下山，瞬间人便少了很多，我们前面只有一个老外。我们从玉屏峰顶继续往下走，经过一个叫蓬莱三岛的地方，那就是三座石柱山，若是云雾缭绕，确是犹如仙境一般。可惜我们去的时候是晴空万里，更能看见远处天都峰的上山台阶犹如一头巨龙一般蜿蜒盘旋，上面有着星星点点的人群。这里是个四岔路口，往上（玉屏楼）有两个岔道，往下（天都超市）也是两个岔道。往上的岔道间刻着一“好”字，我们笑道，估计等爬上天都峰上面还有一“傻”字。往下走腿已经开始酸了（都怪刚才看什么莲花洞），霄哥们首当其冲探了左边的道，在下面徘徊了很久，不会不通吧，我和炜哥很犹豫，有有点窃喜，便和大多数人走了右边的道。不过左边的也是通的，我们在下面汇合了。再往下走，越来越见天都峰登山石阶的陡峭，旅馆老板说的75度一点都不过分。难道这一条长龙就是鲫鱼背？从蓬莱三岛往下走了几段石梯，迎面出现一副摩崖书法，往右边看便是蒲团石。从玉屏楼上下来便是天都超市，这里有免费的行李寄存（如果原路返回的话可以考虑）。我们在这里歇息了很久，并吃了一些东西，然后向着天都峰前进。一上天都峰感觉就不一样，石阶变得十分粗糙，似乎是直接打磨出来的，而不是浇筑的混凝土，每一级的台阶也是高，走在上面有一种就要仰头滚落下去的心惊胆战之感。一路上石阶连绵不断向上，仅有几个侧边的平台可供停顿休息。为了确保安全，我们手都尽力地扶着旁边的缆绳，登山杖倒显得无用了，在一个休息平台上我看到了丢弃的两根拐杖。前方出现一段由山崖间树木遮蔽成的通道，据路过的人说爬到这里一半还没到而且前面这一段是最陡的，又有人说还要半小时能登顶，但是到了顶上还要往上登一段。宵哥惊讶，前面最险的应该就是鲫鱼背了吧，那人说鲫鱼背反而不险，现在都有护栏了（卧槽以前没有么），就在上面的大正方体石块那儿，我们看了看高度表，离天都峰海拔还有不到200米了。于是我们就近在这个平台进行了休息，吃东西喝水以求减负。期间遇到了一穿拖鞋爬山的大佬，据说已经是毕业十年了，看起来却还如大学生一般，还有一帮老年人背着单反，他们都休息了一会儿便嗖嗖嗖上去了。再往上台阶果然越来越陡，变成交错的三段，突然路往左转了个弯，树木渐稀，阳光探了进来，往对面看蒲团石、玉屏楼和迎客松清晰可见，远远地还能望见光明顶的球，原来我们已经走了这么远啊！这时很多人从上面下来，我们在台阶山勉强与他们错开，真是对平衡能力的极大挑战。毕竟我们虽在靠右的山体一侧，但我们除了崖壁却没有什么可以攀扶，而对面下山的人则有缆绳可扶，并且崖边的孤石和山松遮挡视线，倒也不觉恐怖。路过的人都是已经经过鲫鱼背登上天都绝顶好汉，可是都纷纷说到从对面下太难了，选择了走回头路。终于眼前豁然开朗，前方出现平路了，从崖壁向右看可以看到汤口镇，向左看玉屏楼和光明顶也尽收眼底。我们往前来到一片长约十米，两边由巨石的走廊上，风在耳边猎猎地吹。走过这段平缓路段便重新开始了上坡，坡度较之前缓了一些，两边又出现了一些树木。不过再往前什么都没了，这里便是在山脊上开凿出来的路了，路两侧的山松怪石陪伴着我们，左右看去，群峦尽收眼底，耳畔是呼呼的风，我穿着衬衣，竟也感到一阵凉意。突然前方开始堵车，有一个人说前面太险了不敢走便要下来，我们看旁边有一处伸出崖面的观景平台，便走上去拍了照片，感觉手机都要被风吹掉了。继续往前，我们选择从左边的一条路，这是明智的，爬上去后我们看了下右边上来的道，那垂直落差简直吓死人。再往上走人慢慢变多，一道石桥架立于万丈深壑之上，旁边有一名牌，谓之为天桥。这石桥位于转弯处，又十分窄，都不到旁边的护栏那里，走的时候是胆战心惊，三步并两步就过去了。从天桥往上便到了著名的鲫鱼背了。从前我们以为鲫鱼背是像田埂一样，或者是刚才上来的移到近乎九十度的石阶长龙。但实际上鲫鱼背宽一米不到，长约十余米，高低起伏，两边狂风阵阵，幸好两侧有扶手，我们需要弯着腰小心翼翼地攀着扶手才能敢过。过了鲫鱼背选择左边的一条路可以到达天都绝顶，右边的一条路（或者拍照点）是在崖壁上开凿的一条险路，我们没敢过去往下走，不知道通哪里。左边的一条路则通向天都绝顶，我们需要弯腰侧身从石缝间经过。中途在山洞里面我们还遇到了之前那穿拖鞋的人和他的同伴，他们已经在顶上呆了好久了，准备从原路下山去玉屏楼。天都峰顶上游三条岔路，一条是我们从鲫鱼背过来的路，另一条是从半山寺上山的道路，在这条道路左边有第三条往上大概50米的斜坡，通往天都峰的最高点天都绝顶，这条路上排了长长的一条队伍等着拍照。不过实际上拍下来的效果并不好，因为别人是站在低处往高处拍，取景受到限制。在下山时，我们选择了传说中更难的另一条路，也就是从半山寺到慈光阁乘车点的路线。第一段下山的石阶就是下马威，这段台阶临崖壁修建，外侧的石栏由水泥浇筑而成，根本没有扶手的地方，更没有缆绳，由于台阶过高，下到一半我的书包就卡在上面一级台阶上，往下即感觉一股力量急急往前推。无奈只好选择在台阶上转体一百八十度，倒着走下去。下山的路不停刷新难度，有的地方由于太险，上路和下路分成了两条。最险的一处是由两块巨石形成的石缝，仅容一人通过。我们当时正准备往下走，忽然发现最前方的小猪停了下来，前面好吓人。往前一看是一段阴暗无比的连续石阶，这段石阶深不见底，完全看不见其尽头。我们小心翼翼地扶着两边潮湿的崖壁往下走，暗自祷告着跟在后面的一群大爷不要脚滑一个呲溜。石阶路往下向左拐了点，我们看到下方出口的光线，此时有人试图从我们的路上来，被我们高声喝住。 离半山寺大概还有三四段台阶的地方我们遇到了攀山上来的法。先前法一直在和我们联系，问我们怎么爬比较好，说自己带了大人。 从黄山风景区回南京有三点和五点的车，回杭州是四点半的车，据说都是从屯溪发来的正规车，在这里带客。旅店老板帮我们联系好了车后，炜哥和宵哥买了点包子和西瓜，我们坐下来掼了回蛋。五点五分车来了，我们坐上车，发现还挺空。随着车在汤口镇花了半小时晃了一圈带客，我们上高速真正离开时，车已经一个空位都没有了。 车过了芜湖便开始下起了暴雨。]]></content>
      <tags>
        <tag>游记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Manacher算法]]></title>
    <url>%2F2017%2F08%2F11%2FManacher%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[我们知道优化非启发性算法的方法常常包括使用定理、利用计算机的架构特点、使用恰当的数据结构以及动态规划等。而动态规划的核心理念就是减少重复计算。对于回文串问题的Manacher算法来说，我们要重用0..(i-1)的结果，那怎么重用呢？假设i和j关于p(i &gt; p &gt; j)对称，那么R[i]便可通过R[j]求得。计算最长回文串的暴力算法是O(n^2)，而马拉车算法能够在O(n)时间内解决问题。 Manacher算法我们使用$ R[i] $表示$ i $位置处的回文半径，即字符串$ aba $中$ b $字符的回文半径为2。我们现在使用$ i $从左开始遍历字符串求$ R[i] $，为了能够DP，我们假设有一个合适的$ p \lt i $，我们把$ i $关于$ p $做对称得到$ j $。注意到$ R[j] $、$ R[p] $是已求得的，待求$ R[i] $。此时字符串坐标轴上出现了五个刻度：$p$、$j$、$i$、$j+R[j]$、$p+R[p]$，我们需要讨论他们的位置关系。由假设有$j &lt; p &lt; i$，可是$j+R[j]$、$p+R[p]$关系不好确定，为了方便讨论，我们可以假设这个“合适的”$p$满足$p+R[p] &gt; j+R[j]$。这是因为在后面的讨论中我们发现要使得$p+R[p]$尽可能大，假如$p+R[p] &lt; j+R[j]$，也就是以$j$为中心的回文串的右边界比以$p$为中心的右边界还要靠右，那么我们与其取$p$，不如直接取$j$，而且$j$也是在$p$前面被遍历。现在我们可以得到三组位置关系 $$\begin{equation}\begin{split}j &amp;&lt; j + R[j] &lt; p + R[p] \\j &amp;&lt; p &lt; p + R[p] \\p &amp;&lt; i \\\end{split}\end{equation}$$ 可以看出只有$j + R[j]$与$p$、$i$和$p + R[p]$这两个位置关系尚未确定。在下面的讨论中，我们发现只有这两个都满足一定关系时，才能够重用结果。 $p + R[p]$和$i$的位置关系当$i \ge p + R[p]$时，$i$已经在$p$为中心的回文串外面了，以$i$中心的回文串看来是借不了这个$p$的东风了，我们需要重新找一个“回文边界”更靠右的$p$。所以我们直接维护一个$p’$，使得$p’+R[p’]$始终是最大的，如果这最大还不够大，即这边界最靠右的$p$都包不住$i$，那$i$便只能自力更生暴力一波了。 $j + R[j]$与$p$的位置关系根据上节讨论，$i &gt; p + R[p]$时只能暴力，并且$j$有可能越界到小于0，所以只有$i \le p + R[p]$是才会执行这一步，我们认为现在$j \lt p \lt i \le p + R[p]$。$j+R[j]$与$p$的位置关系决定了$i+R[j]$和$p+R[p]$的位置关系。 在内部 当$j+R[j] \le p$，则$i+R[j] \le p+R[p]$，这就相当于以$i$至少有一个以$R[j]$为半径的回文串，并且在以$p$为中心的回文串的内部。预示我们只需要从$R[j]+1$开始检测$i$位置是否具有更大半径即可。 在外部 当$j+R[j] &gt; p$，则$i+R[j] &gt; p+R[p]$，这就相当于$j$中心回文串的边界在$p$中心的回文串的边界之外，所以我们只能重用$j$中心回文串在$p$内的对称部分，其半径为$2 \times R[j] - R[p] + j - p$，然后从这个半径向外开始暴力 我们发现这两个情况可以直接合并取一个半径的最小值$min(R[j], 2 \times R[j] - R[p] + j - p)$ 偶数长度的回文串这个时候就没办法定义“半径”这个概念了，有一个巧妙的方法是将其变为奇数长度的回文串，也就是在头尾以及每个字符中间加入一个特殊字符。 模板代码]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>动态规划</tag>
        <tag>序列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不动点组合子Y-Combinator]]></title>
    <url>%2F2017%2F07%2F28%2FY-Combinator%2F</url>
    <content type="text"><![CDATA[Python中的lambda用起来还是很爽的，不过坑也有很多，比如说这个early binding和late binding的问题，或者lambda中只能有一个语句（实际上是表达式）。不管怎样，可以把lambda当做一个匿名函数来看待，那么这个匿名函数如何在递归调用的时候引用自己呢？Haskell B. Curry给出了Y不动点组合子(Y Combinator, 当然不是那个著名的公司啦)可以解决这个问题。 定义问题考虑计算阶乘函数，Python可以很容易写出下面的代码：1fac = lambda x: 1 if x &lt;= 1 else x * fac(x - 1) 我们注意到在lambda中存在对自己的引用fac。不过对于某些其他的语言，例如C#，就没那么轻松了，于是我们希望有一个类似this指针的东西，能够在lambda函数体中用来表示自己。 函数的不动点不动点的数学定义如果f(x) = x那么x是f的不动点，因此不动点指的是那些被函数仍然映射到自身的点。当然并不是所有函数都有不动点，因为上面给出的方程不一定有解。容易发现不动点和我们的问题之间有明显的关联性，因为我们实际上是要在函数fac中递归地调用fac，因此我们函数调用的形式是fac(fac(...))这样的。如果我们能把这个递归 构造函数F下面我们考虑下面的函数F，我们看到F的功能是和fac相同的。F对原版的fac进行了一番封装，将原版的fac作为了自己的第一个参数，将原版fac的参数x作为自己的第二个参数，在函数体中，我们简单地复制了之前的定义。123#define B 1 if x &lt;= 1 else x * fac(x - 1)fac = lambda x: BF = lambda fac, x: B 审查这个函数，我们发现非常奇怪的一点是我们找不到fac的定义了。如果我们把F和fac视为未知数，那么就定义了F和fac之间的一个方程。下面我们将F柯里化成下面的等价形式，也就是说F接受了一个函数作为参数，并且返回了这个作为参数的函数的定义。1F = lambda fac: lambda x: B 因此我们可以得到下面的等式1F(fac) = fac 因此我们将如何在lambda内部引用fac的问题转化为求函数F的不动点的问题。而这个就借助于Y不动点组合子，它满足下面的特性，对于任意的函数F，存在不动点Y F1(Y F) = F (Y F) 定义lambda演算为了能够将上面的数学思路推广到lambda中，首先需要简单了解lambda演算(Lambda Calculus)。lambda演算是图灵完备的，邱奇利用lambda演算证伪了可判定性问题。 形式化定义lambda演算文法非常简单，只由下面三个lambda term组成 引用标识符(Variable) $a$ 定义函数(Abstraction) $(\lambda x. M)$，括号可省略。 此时变量$x$被绑定到了这个lambda表达式，而这个绑定的作用域便以括号为界。 应用函数(Application) $(M \, N)$ 在lambda演算中函数作用是左结合的，即$s\,t\,x$实际上是$(s\,t)x$。 例如$\omega$组合子$\lambda x.x\,x$，它可以被看做$(\lambda x.x) (x)$，而不是$\lambda x.(x\,x)$ 括号lambda演算中的括号在无歧义的情况下是可以省略的。因此式子$(\lambda x.x \, x)(\lambda y.y)$可以写成$\lambda(x.x\,x) \lambda y.\,y$。式子$\lambda x.((\lambda x.x)x)$和式子$(\lambda x.(\lambda x.x))x$并不能作为同一个lambda term。其中第一个式子中外面的lambda是返回的一个值，而第二个式子中外面的lambda是返回的一个lambda。 绑定一个合法的lambda函数不应当出现自由变量。如$\lambda x.(x\,y)$中，$x$是被绑定的，但是$y$没有被绑定到在表达式中的任何一个$\lambda$上。 lambda演算规则首先定义$E[V:=W]$，这表示一个表达式$E$，这个表达式中的所有$V$的自由出现都替换成$W$。 α-转换(Alpha equivalence)这个变换的意义是被绑定变量的名称是不重要的，所以我们可以用任何的其他名字来替换，其定义为$\lambda V.E = \lambda W.E[V:=W]$。当然，前提是首先要是被绑定的，我们看前面的一个例子$\lambda x.x\,x$，它相当于$(\lambda x.x) (x)$。这里面有两个$x$，但这两个变量却不是一个变量，因为只有前一个变量被绑定到了$\lambda$上，而后一个是自由变量 β-归约(Beta reduction)这个类似于C等语言中的传参，或者数学里面的代入。其定义是$\lambda x.t$能够归约成$t[x:=s]$，这个beta reduce过程表示为$(\lambda x.t)s \rightarrow t[x:=s]$。在这时，相当于我们将$x$的值赋为了$s$。这个过程必须要确保$E’$再替换后仍然是自由的。 绑定与自由例如$\lambda z.(\lambda x . x + z)(x + 2)$，和我们在α-转换中看到的例子一样，$(\lambda x . x + z)$中出现的$x$是绑定的，但是$x + 2$中的却是自由的，因此我们不能直接把这个自由的$x$代入到绑定的$x$里面去。如对于任意的“自变量”$s$，有$(\lambda x.x)s \rightarrow x[x:=s] = s$，因此该函数是个恒等函数。又如$(\lambda x.y)s \rightarrow y[x:=s] = y$，这说明$\lambda x.y$是个常量函数。 通常形式beta可归约式(redex)具有以下的形式$((\lambda x.A(x))t)$。例如$(\lambda x.x\,x)(\lambda y.z) \leftarrow (\lambda y.z)(\lambda y.z)$对于无类型的lambda演算来说，这个规约过程还可能是无法终止的。考虑下面的$\Omega$算子$\Omega = (\lambda x.x\,x)(\lambda x.x\,x)$ $$\begin{equation}\begin{split}&amp; (\lambda x.x\,x)(\lambda x.x\,x) \\\rightarrow &amp; (x\,x)[x:=\lambda x.x\,x] \\= &amp; (x[x:=\lambda x.x\,x])(x[x:=\lambda x.x\,x]) \\= &amp; (\lambda x.x\,x)(\lambda x.x\,x)\end{split}\end{equation}$$ η-变换(Eta conversion)η-变换体现了外延性(extensionality)的思想，即两个数学对象是相等的，如果没有区分它们的检验。对于lambda中的函数来说，如果两个函数对于任意的输入都能产生相同的行为（即返回相同的结果），那么可以认为这两个函数是相等的。η-变换的一个用途是$\lambda x.f\,x$和$f$是等价的（注意它们不一定性能相同，详见Haskel里有关where的一个例子），只要$x$不是$f$中的自由出现。 Y Combinator的实现我们定义Y组合子为$$Y = \lambda f . (\lambda x. f(x \, x)) (\lambda x. f(x \, x))$$ 证明我们证明这样的$Y$满足$$(Y g) = g (Y g)$$首先我们根据beta归约，将函数$g$带入$$Y g = (\lambda x . g (x \, x)) (\lambda x . g (x \, x))$$下面我们使用alpha法则来修改一下绑定的变量名字，以便后面的带入，有$$Y g = (\lambda y . g (y \, y)) (\lambda x . g (x \, x))$$下面我们将所有的$y$替换成$(\lambda x . g (x x))$，同样是根据beta法则$$Y g = g ((\lambda x . g (x \, x)) (\lambda x . g (x \, x)))$$而后面的又是一个$Y g$，于是得证。 类型分析下面我们进一步探究一下我们这样的构造为什么能得到一个递归。y接受一个函数，返回这个函数的不动点，因此类型应该是这样的。1y :: (a -&gt; a) -&gt; a 把\x -&gt; f (x x)作为一个整体g，那么y的工作就是将g作为唯一参数来调用自己，这有点像我们证明停机问题的时候的操作。1y = \f -&gt; g g 现在我们查看这个g，它接受一个可调用的x作为参数，并且做f (x x)这样的调用。首先我们看x x这个调用，我们令1x x :: a 则有1x :: b -&gt; a 其中a，b为未知类型。在另一方面，我们还能推导出1b :: b -&gt; a 这是因为我们作为函数来考虑x，它接受一个b类型的x作为参数，而根据前面的式子x又具有类型b -&gt; a，所以我们可以得出b的类型是b -&gt; a。因此这个类型是递归的 备注递归类型List就可以看做一种递归类型1data List a = Nil | Cons a (List a) 在函数式语言例如Haskell/OCaml中，递归是不能以type synonyms的形式来实现的，例如下面这些使用type的语句是不合法的。我们可以简单地想象在C++里面的typedef关键字定义的“类型”，在实际上他们并不是正在的类型，而是alias构成的语法糖。如果我们使用这样的定义，那么在编译时就会因为简单的替换而导致死循环的发生12type Bad = (Int, Bad)type Evil = Bool -&gt; Evil 解决之道就是按照下面的方式去新建一个ADT(Algebraic data type)12data Good = Pair Int Gooddata Fine = Fun (Bool-&gt;Fine)]]></content>
      <tags>
        <tag>Haskell</tag>
        <tag>lambda</tag>
        <tag>combinator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神器Continuation]]></title>
    <url>%2F2017%2F07%2F24%2FThe-Continuation-Tech%2F</url>
    <content type="text"><![CDATA[Continuation、Coroutine和Generator是异步编程中的一些概念。通过Continuation能够实现Coroutine和Generator。 Continuation常有两种实现，一种是以call/cc(call with current contination)为代表的语言级别的实现；另一种对于不能原生支持Continuation的语言但是支持闭包（函数作为一等公民）的语言，可以使用CPS(continuation-passing style)来实现Continuation。 Continuationcall/cc以维基百科上面的一个例子来说 (define (f return) (return 2) 3) (display (f (lambda (x) x))) ; displays 3 (display (call-with-current-continuation f)) ; displays 2 其中(define (func_name arg1 ... argn) exp)表示定义函数。查看第一行调用，display打印得到3，这是由于f始终返回最后一个表达式的值3。无论return是个什么，哪怕return是个回调函数，f的计算结果也是3。查看第二行调用，display打印得到2。这是由于在调用call-with-current-continuation时，首先Lisp会把当前的环境打包成一个叫Continuation的东西，并且以它作为参数调用f Continuation。查看f的代码，下面我们要执行return 2，也就是Continuation 2。而call-with-current-continuation打包的Continuation这个东西可以看做一个的函数，调用Continuation就会f会退出，程序上下文返回到调用call-with-current-continuation时的状态，并且(call-with-current-continuation f)会被替换成Continuation的参数2，于是实际上运行的是display 2。 还可以这样理解，在本来程序是要执行(display xxx)的，Lisp一看xxx原来是一个call/cc f，那就把现在的状态（下面要运行display啦）打包成一个Continuation，然后程序就不往下面运行了display了，而是立即跳转去执行f函数。那这个f函数有点特别，他会被系统喂刚才得到的Continuation参数return，函数通过调用return就相当于从f函数中退出，并继续执行调用f前要执行的display，这里display需要一个参数，所以调用return 2，这里可以近似理解Continuation参数return就是下面要执行的display函数的别名。 CPS对于没有call/cc这机制的语言，可以使用闭包进行模拟。 callback通常的语言如C++中，常使用return命令返回结果，例如1234int add(int x, int y)&#123; return x + y;&#125;int result = add(1, 2); 其中int result = add(1, 2);语句将result与add函数的返回值return x + y进行了绑定。这样的方式对我们屏蔽了绑定的细节。我们需要通过额外的了解能够得知，并且还要取决于具体的代码和编译环境。例如一般int返回值会被放入eax中，再调ret，而有些时候浮点数会被放在FPU或XMM上返回。当然也许会说编译语言没必要去讨论它的目标代码，不过至少我们只有通过把函数的返回值和某个名字进行绑定这一种默认的处理返回值的方式。对于有些异步的需求，常常有回调函数的概念。函数接受一个额外的回调函数作为参数callback。1234567template &lt;typename F&gt;void add(int x, int y, F f)&#123; return f(x + y);&#125;add(1, 2, [&amp;] (int result) &#123; &#125;); 将这段代码与上面的代码进行对比，我们发现实际上我们返回的是一个函数，而不是一个值。 CPS functionContinuation和callback都是可以调用的，不同的是在A里面调用一个callback B后，程序进入B然后从B返回到A继续执行；而在A里面调用一个Continuation B后，程序立刻进入B运行，并且不会在B再返回到A。因此对于没有call/cc这样的first-class Continuation的语言可以通过callback实现CPS function。方法如同上面的add函数一样，add函数通过在函数结尾调用该回调函数，自己的计算结果传给该回调函数，来完成返回操作。这样的回调函数方案借助了尾递归（在函数的末尾调用另一个函数）。此时，函数实际上将自己的剩余部分作为callback（此时该callback称为continuation），该函数即CPS function。相对于命令式语言的if/else、do/while/break/continue、try/catch/finally、goto等控制语句，CPS function的好处是能够更灵活地操作control flow，因为下一步要做什么不是根据你是顺序结构/选择结构/循环结构，而是你在continuation里面写了什么。这样还会带来一个好处是程序可以任意被中断（此时只需要保存回调函数的指针f），然后从中断的地方调用f开始继续执行。于是常常使用Continuation/Coroutine代替多线程（毕竟线程的开销还是很高的）。]]></content>
      <tags>
        <tag>Continuation</tag>
        <tag>Coroutine</tag>
        <tag>多线程</tag>
        <tag>CPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贵州游记]]></title>
    <url>%2F2017%2F07%2F11%2F%E8%B4%B5%E5%B7%9E%E6%B8%B8%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[一直以来，贵州一直出现在卓林的自黑之中。什么江苏六州、南京四省省会，和伟哥那段“贵州山水甲天下”、“贵州简称赣”的梗更是屡屡被提起。于是今年暑假在他的热情邀请下，我们去贵州进行了一次非常幸运与快乐的旅行。主要行程包括镇远-凯里-安顺-麻尾-荔波。 B1 Jul.3 南京原计划我们需要在7月3号坐D655+K495一波24的火车到镇远。早在7月1号的时候，就看到群里说7月2号的K495由于湖南的水害取消了，当时十分高兴，毕竟自己的7月3号精准地避开了这次调图。不料三号下午3点钟，我东西打包好，连方便面都买好了，短信过来了说K495取消了，顿时群里乱成一锅粥。最先安顿好的是小姐姐们，她们换了一列和刘鹏一样的K473列车。我们就很伤了，湖南似乎成了我们越不过去的障碍，从南京到镇远附近的火车，甚至是高铁都处于取消和无座状态，大家建议我们考虑4号的K495或K111，我们觉得这样就有可能耽误大家的行程。在比较了南京飞贵阳的机票（这机票在10分钟内涨了80）后，加上考虑了飞机场与火车站的距离，我们接受了卓林的建议，选择HO1657(12:55-14:45)赶K495(16:58)和刘鹏他们会合。不过考虑到南京和张家界的天气，真不知道明天飞机回延误成什么样子。 D0 Jul.4 南京-张家界-镇远今天我们实施昨天的南京-张家界-镇远HO1657+K473空铁联运计划。我们早上七点多就起来了，和法9点钟在地铁站会合前往机场。到了机场，没下雨，不多云还是挺多的，天气预报说降雨概率60%。前序航班是从大连飞南京的，大连天气也不好，起飞晚了12min，在我们的祈祷中，这架飞机不负使命，提早了4分钟降落。不一会儿，飞机就开到了我们登机口的廊桥了。我们看看外面云还是挺多的，不过天还是亮的，也不下雨，本以为这次应该是不会延误太久的，不过机场广播不停传来的“很抱歉地通知您”还是给了我一点不安的感觉。看到延迟未定的时候我们是绝望的，我们已经准备张家界一日游了。法开始有点懊恼了，觉得他这次没空参与，行程就安排成这样了，买飞机票亏了不到500块。我也觉得南京-镇远和安顺-麻尾的行程看起来非常地不靠谱。我们估计来不及吃晚饭了，便请刘鹏哥帮我们带点泡面。刘鹏说张家界现在是大晴天，到张家界应该不会延误了。有着急的大哥问登机口的工作人员啥时候能飞，答曰飞行员还没上呢。感情我们白对着廊桥外的飞机大眼瞪小眼了。一点半的时候，飞行员终于上飞机了，打开航旅纵横，依然是流量管控延误。我也感觉这次去贵州成行机会不大了，不想去赶那班到镇远的火车了，劝法计划下张家界-凤凰的游览线路。飞机在14:36起飞，中间很瓜皮地只发了水和三明治，旁边阿姨看我饿得，把自己的三明治给我吃了，我后来又要了两个还给阿姨。飞机不久便到达了张家界，在降落的时候我们看到了远处天门山上的天门洞，和脚下的张家界火车站（真想直接跳下去）。飞机四点整停靠了廊桥，我们估么着去火车站还来得及，便赶快出机场。张家界是大太阳，感觉自己快热化了，我和法叫了辆不打表的出租车30块把我们送到了火车站。想着董董一直想来未成行的张家界，而我在出租车上“一日游”了，我给她发了她一条定位。到了火车站才16:25，我们取完票和刘鹏哥汇合了。刘鹏和他的弟弟坐了火车的硬卧，上了车发现小姐姐们也是和我们一辆车，她们刚在凤凰玩，正好从吉首上车与我们汇合。上了车赶快发说说感慨一下这波紧张刺激的空铁联运。由于我们是从五点到十一点半将近六个多小时的硬座，机智的法出了去餐车休息的馊主意。一到餐车坐定便见到桌上的牌子上明码标价，并分为四个时段早餐午餐晚餐夜宵，夜宵还特意注明30块包含荤素饭汤各一。不一会儿乘务员便来了，“牛肉鸡肉带鱼排骨”她很不耐烦地说道。法计算了一下，15块的晚饭在这里卖40，划一个座位25块钱，可以歇到22点，其实是比软座划算了。吃完晚饭感觉本来不舒服的肚子彻底爆发了，还有一点发烧，把衬衫穿上。这时候两位小姐姐们从吉首上来了，于是开始打掼蛋。我和欢欢姐把法政和团长组合秒了两把23333。打牌打到十点，乘务员把我们从餐车赶了回去，我们回到人声嘈杂的硬座。在厕所旁，已经有人铺开凉席就地睡着了，有一位妇女将小孩背在小背篓里面，在车厢里来回走动。我的位置似乎已经被人占了，我想着自己肚子还是有点闹腾，倒也不介意。不过走到车厢临头发现居然还有若干座位，于是我坐到了一个应该是农村妇女身边。车子在不停地颠簸，手机信号忽有忽没，车厢里的人也都看起来行色疲惫，也没见到有上次从常州回来时的一秒脱裤带的表演。对面的小孩醒了并开始哭闹，于是他的母亲替他解开裤子，便朝地板上把尿。将近十一点的时候，身边的那位妇人突然拿出手机，然后操着一口浓厚的口音，开始对我讲话。结果几次沟通，我搞明白了她在问我现在几点了，又问我下一站是什么，于是便回答了她。紧接着她拿出自己的火车票，我看有两张，第一张上面写的是怀化-昆明，第二张则是到涪陵的票，她说她火车做错了，要在下一站下车。到了晚上将近11:25时，火车窗外突然一亮，我们仿佛进入了千与千寻的世界，两边吊脚楼上的灯光勾勒出一道穿越古城的蜿蜒的河，在更高处有闪着光的四个大字“名城镇远”。下了火车，帮大家把箱子扛下火车站，打了两辆车去旅店。 D1 Jul.5 镇远今天我们简单地逛了镇远古城。早上起来出了一身的汗，感觉烧是退了，但肚子依然是照拉的。硬撑着出去和法、刘鹏在对面的瘸子饭店吃了肉末粉。接着我和法沿着河南岸翻过新大桥进入镇远古街，往祝圣桥方向漫步。沿河畔走，是真的明白什么青山绿水是真的一点不假，这里的绿水其实不是富营养化或者工业污水造成的，而是水中的矿物质遇到阳光吸收不同波长产生的。镇远古城里面的路都是石板路，比较窄，但也能容纳轿车和公交车的通行。镇远（以及我们后面去的同时黔东南的雷山西江苗寨）商业化还是比较浓的，而且每一家店面门前都会有一幅镇远公安的二维码，我想可能是用来投诉的吧。我们顺路打听明天的漂流、晚上的游船以及去苗寨的车，一路上问下来发现高过河漂流基本都是统一价，是景区规定的，接送258，不接送220。而舞阳河的游船（画舫）晚上是80元。一路上我们找一个叫歪门斜道的景点，后来才知道歪门斜道就是描述的镇远古镇的格局，镇远城依山而建，里面的道路错综复杂，故有歪门斜道称呼。到了祝圣桥边有经营50元的船，不过那船可以说非常简陋，就是一个小艇上搭的棚子。我们在祝圣桥下面的水关拍了照片，法不小心手被仙人掌划伤了。再往前走有一个女人在炎帝庙前拉客，只要一块钱便可以参观景点，于是我们进了。从炎帝庙出来，我们去爬石屏山。我们是走东边的口子买票进入的，石屏山学生票是15元，但是可以逃票，方法是从西边的一条叫四方井的巷子上去，这条巷子可以通过地图上唯一的公厕来定位。爬石屏山简直去了我半条命，爬一路，肚子是闹一路，气涨着胃，想从食道涌出。爬石屏山沿路并没有什么风景，我们路过了“名城镇远”几个大字中的“远”字。山顶上崖边建有一个亭子，在那里可以俯瞰镇远全城，在亭子进口处有一卖水的老妪，右眼睛好像受过什么创伤，变成一个鲜红的圈，很恐怖。我们在上面吹了一会儿凉风，眺望镇远全景。㵲阳河从峡谷间蜿蜒而来穿过镇远城，流向远方，远远地是我们过来时的铁路湘黔线，可以看到火车通过。从亭子出来往上走有一段古城墙，不太清楚为啥要在这么高的山上建城墙。下山时，我们在山腰的三岔路口选了另外一条道，于是从不要门票的四方井巷子出来。四方井就是一个正方形的井，里面的井水据说从前供全镇远的人使用。在四方井旁有一个壁龛，里面有上着很多香。在我们爬山时，另外的人去玩了青龙洞，据说非常没意思。我们在祝圣桥上汇合，然后去大众点评上的一家袁家豆腐。袁家豆腐据说也是上过舌尖上的中国的，他家的豆腐不说多香，但巷子一定是深的，我们从大街上拐进一个小巷，七拐八拐往上爬了好几段台阶才找到。上来的是他们家特色的豆花，桌子上配了五六瓶的佐料，有花生碎、酱油、糖、醋、辣椒粉、辣椒等。我觉得贵州辣椒好，就吃酸辣的吧，妈的难吃死了，汤汁倒是特别酸，这豆花却一点不入味，吃起来一口酸辣一口寡淡，简直受不了。于是换成了甜的，咱当布丁吃行不行结果更差了，半碗豆花大都没吃完全倒了，不过他们家的苗家老豆腐是挺好吃的，外面就像油炸干一样，里面又包了层嫩豆腐。何卓林点了一道贵州特色的折耳根，又叫鱼腥草想让我们尝尝。应该是类似鱼香肉丝之类的东西吧，于是上来一盘像豆芽菜一样的东西，我想着便尝了一口，妈的妥妥的黑暗料理，这是一种特别冲的腥味夹杂着特别冲的草药味，我挣扎着嚼了两口，结果硬是没咽下去还是吐了出来。吃完饭我们就去我们联系了几家上午看到的接送高过河漂流的旅行社，他们漂流项目未成年儿童必须也得买成人票，感觉就有点坑了。然后我们考虑到赶时间去凯里，想早一点结束漂流，就和他们约早一点接，比如9:30接。但是他们说要根据景区的安排，10:30去是正好，有时候即使去了早了也没得漂。回来的路上法想买双拖鞋，我们想看看有没有泳裤，于是我们路过超市，不过并没有找到，于是回到宾馆休息。醒来之后我发现自己的水杯丢在袁家豆腐了，从百度地图上找到电话问问老板，他问了问她妈说不在。晚上，我们在舞阳河边的一家苗人饭店吃了烤鱼和酸汤鱼，可能是酸汤鱼曾经出现在舌尖上的中国吧，这路边的每一家店的招牌都是舌尖上的中国。欢欢嗓子不太舒服，去了附近的医院看病，没有来吃。我们点了一矿泉水瓶的米酒，它不同于我们在兰州吃的醪糟，或是我们自己的米甜酒，带有固体物质，而是纯液体的酒。我觉得喝起来口感并不好，非常的涩。卓林还请我们吃了一个叫冰凉粉的东西，它出人意外是甜的，有芝麻的香味。我觉得如果能够冰镇一下会很好吃。河边不时有驻唱歌手唱着改编的镇远版《成都》，还不时教我们点歌。结账一看，648元，吓尿了，讲了下价，520成交。结完账林欢也找来了我们吃饭的地方，她去了医院看了嗓子，医生特别好，知道她没有医保后就给她开了处方，要她到药房去买，这样会便宜一些。我们走过新大桥，小姐姐听到我们坐游轮的计划，说游轮一定要还价，自己在重庆把两百多块钱还到了五十多块钱。卓林从中午就一直唠叨着什么长江语系和珠江语系（在我们看来都是西南官话），自己是珠江语系，和这边的话不一样，说刘鹏的方言可能要更接近点。于是最后遵义的小姐姐上去侃了半天，上来还价到20，不过可能这是政府搞的东西吧，最后没成功。 D2 Jul.6 镇远高过河-凯里西江苗寨今天是最刺激的高过河漂流了。搞笑的是接送的车一早9:20车就到了天主堂，于是我们饭都没来得及吃，慌忙地收拾东西。我们首先要去高过河漂流的游客服务中心，我们走了有将近一个小时的盘山公路，刘鹏的弟弟还给搞吐了。在游客中心，20块钱可以买一个寄存的蛇皮袋，还附送一个瓢和一个防水袋。刘鹏弟弟身体不适不漂流了，我们共八个人四艘船进行漂流，于是另买了5块钱的两个瓢。后来发现，这两个瓢的作用是非常大的。高过河漂流是不能穿拖鞋的，据石头可能会划伤脚，于是我们换上了景区提供的白球鞋，并套上了护膝和护腕，然后我发现我的毛巾掉到了旅馆没拿。在寄存完东西和换完衣服后（等的司机不耐烦了），我们又坐上包车来到起漂点。高过河漂流耗时是非常长的，由许多起伏和起伏间较为漫长的平缓河段组成。我们从起漂点遇到的第一个起伏就把我们的衣服全部打湿了。既然都湿了，那大家就干水仗吧。拉起瓢一舀水，瓢的把手断了，幸亏邻船的人捡了送还给我。刚准备继续攻击，我们的船就搁浅了，这次是因为一块石头比较高，我们的船直接开到这块石头上面了，加上右舷还有一块石头挡着。我们在这里耗了很久，最后靠撑附近的石头得以出来。高过河共有11个急流，每个急流前都会有一块牌子说明。船经过急流总会激起比头还要高的浪，然后船会灌进好多水。于是我们在遇到急流前后都会疯狂地拿着瓢将船里面的水舀出去。每次进过急流前都要死命地用腿夹着或者压着瓢，生怕它跑掉。到了后半段这基本不灵了，就是一个小起伏，我们的船都会进半船水，遇到一个急流，我们基本就是水比船高了，后来发现我们的船并不漏气，所以也不会沉下去，舀不舀水倒无所谓了。而且，但凡我们的船进了急流，那便是被浪裹挟着地往下冲，等到碰到岸边或者中央的石头，便会反弹并旋转，冲到了最下面便会被一道大浪狠狠迎面打来，船也会用力往下一挫，刚才辛辛苦苦舀的水也白舀了。这时如果你是背对着浪，那是最好的，顶多是被吓一跳，若是正面硬肛那大浪，那便是要被那冷水浇个一身了（人正面更怕冷）。不过最惨的是侧面迎水，这样耳朵基本上都是水。经过了一两段急流，加上拼命划船，我们赶上了之前甩下我们的小伙伴，又开始愉快的水仗。水仗之猛烈，我们瓢都搞丢了，其他三条船笑尿了，觉得我们必须失去战斗力了。我心想不能啊，没瓢这帮小逼崽子还不搞死咱们，于是拼命地用木棍划船，最后靠一个筏子360的转弯抓到了瓢，站起来舀起一瓢水就泼了过去。高过河漂流大多数是纯天然的，我们大多数时候在山谷中漂流，两边的高崖边长满了绿色植物，石头上也有苔藓。我们路过的一些地方两边还有一米高的小瀑布。但对于比较险要的地方，景区就会直接建一个滑道，船从这个滑道上嗖地滑下去，船最后重重挫入水中，摔起一团浪花。比较好玩的是，中间有一个滑道急流，救护员钩过我们的船问我们两个是谁重，还问了两次，默默吐槽，这还要问？不是显然的么？后来想想其实有道理，我们可能是重量太不均衡才会搁浅的。一般经过急流后，总会有一段比较长的平缓河段供休息调整（当然对于我们来说这意味着和搁浅的漫长搏斗），这时候我们会疯狂舀出船里的水，或者划到岸边的浅滩上稍作调整。浅滩上上通常有买食物的商贩，也有帮船打气的。有的时候水流速度比较快，需要死命扎着水才能划到岸边，岸边的人会伸出竹竿拖你上岸。上了岸想抬起船把水倒掉，发现船垫子里面也进了水，特别重，往往需要两个人合力才能翻过来。但并不仅是急流，非急流同样也会让人很难受，法和学义的船就在一个地方翻船了。我没有看清楚具体情况，便见到法跌倒顺流向右侧的在一块礁石上，学义在法后面几米的对岸的浅滩上。我们将船划靠岸，走上前看学义的伤势。他半跪着，捂着腿，面部表情痛苦，再看对岸的法正在脱开护膝，他似乎膝盖被磕破了。后来据法说，当时自己脑子里面一片空白，只想抓着一块东西，于是被船拖拽着往下游走。当时岸边的救生员从岸上拉着安全绳探身下去，硬是抓了他两次还没抓着。即使是平缓的地方也不好过，我的船经常搁浅，于是得十八般武艺都用上，用木杆撑，使劲往下面扎着划水，几番下来，腰都快断了。可是到了后来，搁浅的姿势也是百花齐放，常常我们的船是被两块石头夹着，必须要下来推。有次我们的船没走社会主义的阳关大道，而是拐进了旁边资本主义的羊肠小道里面，我下船推了半天也没用，最后是我们两人全部下船，走到岸上（幸亏搁浅到的左舷石头离岸边近），硬是把船拖上了岸。当然最恶心的还是在进入险滩前被搁浅，生怕推多了船飘走自己跟不上，腿都是在抖的。随着漂流的进行，我们觉得越来越冷，特别是船半进水的时候，恨不得站在船上，这时候瓢的作用又显示出来了。距结束还有两公里的地方，我们拉着横贯水面的绳索上了岸，岸上的小马哥提供免费的生姜茶，我们都喝了若干杯，感觉身上重新开始暖洋洋的了。一问原来之前又是进水又是翻船又是搁浅的我们才过了三公里，只有刘鹏那一艘已经远远超过我们。于是大家相约都快点结束，而且真是冻得受不了了。不过我们还是遇到一个大一点的摊子就停下来倒水。到了最后一个险滩前，老板说可以等玩完再用微信支付，于是我们上岸吃了一点粉（妈的里面有折耳根），法和卓林点了糍粑和干子，总共居然花了70块钱，我们顺便叫老板给船充了气。到了最后一个急流时，当时欢欢和我已经冻得不想玩了，我感觉自己肚子又在抽搐了，心里数了数，觉得前面就是最后一个古耳洞瀑布，于是都想快点过完这个急流早点结束，也不愿意舀水了。刚开始时这个急流并不是很急，水都没怎么进我们船里面，突然水流变快，我们被裹挟着往下进入一个S型的道。伴随着船的碰撞，我左右转动身体使得正面对着前进方向以免耳朵进水。正当我看到船已经要落至最低点，深吸一口气准备承受那一击时，突然感觉船碰了一个东西，下一刻自己已经在水里面了，惊慌失措地踩了两下水，好像没踩到下面的石头，不过得亏穿着救生衣，我很快浮上来并看到自己的船从左上方迅速飘走，我本能地想抓住船，不过又想起法的遭遇，便放弃了。喊了下发现欢欢就在我旁边，我赶快抓住她防止被两人冲散。这时救生员和我说到岸边上岸走吧，这是最后一个急流了，前面就到终点了。我摸摸眼镜发现还挂在脖子上，看来这次绳子立大功了，戴起眼镜发现抬脚发现右边就是有几块礁石露出水面，我们跨过石头来到岸边，又顺着崖边长满青苔的石头爬上岸上的栈道。到了岸上往下走才发现我们船翻在了第一道落差上，后面至少还有100米的急流，最恐怖是有一个高接近两米的瀑布，不禁暗暗庆幸自己不是在那里翻的船。遇到小伙伴们，一见面就说，果然是你们的船翻了，原来我们的船先我们到了终点，大家甚至就是不是我们的船还产生了一些争论……然而我们还是不辱使命，追随者我法的脚步翻了船。高过河漂流结束，看了看，时间也不早了，我们遂要求包车司机走高速直接把我们送到了镇远火车站。贵州高速常常是两车道的，并只有非常窄的紧急停车道，在某些路段会设有紧急停车带，我甚至看到了一条避险车道。我们坐着深深伤害了我们的K495来到了凯里，火车上居然遇到了一个高邮在兴化打工的人，他和另外一个昭通人一起从上海乘火车准备到遵义，据说是为了做生意，我们在火车上吹了好一会牛逼。到了凯里，刘鹏说自己老师找他，还要顺便回家歇两天，便先走了，我们乘坐联系好的SUV前往西江苗寨。SUV就是好，空间宽敞，我们虽然行李箱特别多，但是全塞后面居然还撑得下。在火车站，司机和我们讲待会儿出去不要说我们给钱，而是说酒店接客，一路上司机侃侃而谈，于是我们被贵州人的热情好客吓到了。司机说自己是西江人，之前和凯里的出租车司机为接客人打了起来，他觉得是自己接自己的客人理所应当，于是一个人干翻了三个司机。后来凯里出租车司机看到凯里的牌照都要抬一杠子。我们去西江苗寨也是直接走的高速，不过司机开的特别快，问问才得知这里的高速基本上超速都没人查的。一路上是各种隧道，什么脚勇隧道、摆底隧道，据说都少数民族的语言。路上学义在纠结去成都的事情，。到了苗寨，发现这里的门禁很严格，我们的车被保安拦住了，我们游客需要在另一个入口验票进入苗寨才行，于是司机只能先把我们送到那个入口，然后自己进来开过来接我们。我们在千户苗寨住的是吊脚楼一样的房子，爬上一段室外的石阶，才是“一楼”，也是我们住的标准间，从刚才的石阶再往上爬一段，便是二楼。二楼往里走有一个大客厅，里面居然还有三国杀。客厅往里走左边有个厨房，里面煮了一锅超级多的杨梅汤。厨房隔壁是厕所，这间厕所也是有个性，朝外还有另一扇虚掩的门，处理个人问题的时候门外可以看到人影攒动，生怕风或人把门推开。厕所对面是一段室内的楼梯，往上走第三层的露台+阁楼，在上面走啪啪的脚步声和木板的吱呀吱呀声从楼下的客厅听得一清二楚，感觉用点力楼板就要塌下来一样。小姐姐们的三人间便在这层上。我们找老板分配房间的时候，学义在一楼门口的花坛上看到了一条蛇。安顿好了，我们便出发准备逛逛苗寨的夜景。从我们的宾馆去观景台需要朝着苗寨博物馆的方向走，穿过一座桥再往上爬一段路。观景台是一个大的平台，平台两边还有一些店铺，一块石头上书天下西江。晚上回来，考虑到要送欢欢去机场，我和法打算研究一下黄果树的宾馆，尽可能地早点结束，我们也总算把张家界刘鹏买的泡面吃完了。 D3 Jul.7 凯里西江苗寨-关岭-黄果树景区今天我们在千户苗寨，经过了一天的漂流，大家都很累，于是早上其实就废了。我法早上出去吃早饭了，我随即出去买了条毛巾，不过此时天上微微下起了小雨，于是就回去收衣服，一看发现衣服都被淋湿了，于是和宾馆老板借了个电吹风，吹了一上午的衣服，可惜漂流时穿的那个踢设是棉的，一早上都没吹干。于是我放弃了，去苗族文化博物馆逛了下，其实苗族的一些生活用具比如面盆架，织布机或者各种厨房用具以及农具和我们汉族都是很相像的，据说早上的是有表演的，不过我们都错过了。中午我们去卓林之前计划上的西月火塘吃正宗的酸汤鱼。讲道理这次的酸汤鱼和米酒比前天吃的要好吃太多了！吃完酸汤鱼我们还意犹未尽地喝了酸汤汤底。去西月火塘吃完，便走到西江边上逛，这时候太阳出来了，感觉先前吹了一上午衣服也是不够机智。大概四点四十左右，昨晚送我们来的大哥来接我们了，将我们送到了安顺西站，我们乘坐高铁前往关岭。贵州的高铁也是瓜皮，感谢盛高祖，原先的350高铁变成了250，动车组好的时候能开到220了不得了，要是进了隧道或者其他的一些情况就只能开到80几，只有靠近贵阳的一段能开到280。关岭有著名的花江狗肉，到了关岭，是一个瘦猴儿司机开着他的破MPV来接我们。我们咨询他从黄果树到龙宫的事情，他便开始说不靠谱什么的，要花两个多小时什么的，但是我们查了下走高速只有30-40分钟左右。到了宾馆，我们在附近的一个小饭店吃了晚饭，我们惊讶的发现这里的菜不仅略贵，而且是政府定价的，也许就是为了防止景区及附近的饭馆疯狂涨价吧。吃完，我卓林和法一起找景区车和售票处，大家在黑漆马虎的地方绕了好一段路，法还把我们甩掉了，最后我和卓林通过查看百度地图在发之前找到了售票处，原来之前我们走过头了，从宾馆到售票点真的很近。 D4 Jul.8 黄果树景区-龙宫-安顺今天我们7点钟便起来前往黄果树瀑布景区。外面下的是小雨，还没出宾馆，我们就被各种卖雨衣和鞋套的人包围了，在宾馆里，大家勉强买了六件雨衣。然后到进口附近吃了点粉，期间有买鞋套的还一直追我们到店里。黄果树景区的寄存是承包给外人收费的（敦煌的是免费的），但放到宾馆在回来拖又太累了，于是我们还是花了这钱。在寄存行李的时候，有人来来生意说50元一人包车，这个价格和景区观光车一样，但是就不要我们等了。商量完，我们就去对面的游客中心买票，然后得知今天天星洞、水上石林、水帘洞都不开了。黄果树瀑布从北到南分为陡坡塘、大瀑布、天星桥，我们首先参观的是最近的陡坡塘瀑布。陡坡塘瀑布是黄果树瀑布的上游，是《西游记》电视剧片尾曲的拍摄地，比下游的黄果树大瀑布还要宽。其实后来我们发现从陡坡塘走到大瀑布景区是非常近的，可能是为了渐入佳境的缘故吧，我们先去了天星桥景区，也就是黄果树景区的最下游。相比于陡坡塘和大瀑布单纯的壮美，天星桥更偏向于秀美。天星桥的美景主要集中在后半段，例如银练坠潭瀑布和星峡飞瀑等。在出发前司机提醒我们不要跟着旅行团在高老庄的地方提前出。进入天星桥首先便是一道从崖壁上坠落的瀑布————马尾瀑布，我们必须打着伞才能保证通过。顺着栈道往下走便是数生步景点，数生步由366个石阶组成，领着我们在水潭与石洞之间上下穿行，每一块石子都是表示一年366天中的一天，有些石头上面刻着出生在这天的伟人的生卒年份。再往前有侧身石、寻根岩和美女荣等景点，有需求的朋友们→_→可以去玩玩。再往前走眼前豁然开朗，这里便是天星湖。天星湖在群山环抱之间，往上看，青山笼罩在一片云雾之间，敢问那高山之上是否有仙人常驻呢？环湖一圈便到了半程出口高老庄，出于赶时间，我们在这里并没有久留，据说这里就是猪八戒娶亲时的高老庄，也是巧了，我们在敦煌的时候也见过一个高老庄呢，感情这猪八戒不只娶了一个老婆呀？过了高老庄继续往前走是一道万丈深壑，顺着吊桥往前走便到了桥上桥上桥景点，这其实就是一道悬崖上的桥，这个“桥”实际上两边伸出来的石壁组成的，但中间一块石头像个锲子一样钉入石壁之间形成了一道独特的石桥。从桥上桥上桥往前应该是进入天星洞参观，但由于下雨的水位的原因，天星洞关闭了，我们只能顺着山侧的栈道往下走。到了谷底，渐闻水声隆隆，原来河水在天星洞时便进入了地下暗河，于是整个天星洞范围便形成了一座大桥，也就是桥上桥上桥的最后一个桥字。而这暗河的出口便是冒水潭这个景点。自此从上游流下来的河流又重见天日，奔涌向下，直到银练坠潭瀑布，这这波澜壮阔的景象有个恰如其分的名字：跌浪飞雪。 瀑布下端似乎是个无底洞一般吞噬了上方翻滚着的汹涌一片，水流经过短暂的驰骋又重新进入了暗河，我们顺着栈道向上走便到了水上石林景区，可惜也关闭了。在大瀑布外吃了德克士，44元的汉堡套餐，配有原味鸡，还送一个装满可乐的杯子，感觉相比16块钱一个的汉堡也不是不划算了。最爽的是站在犀牛潭了，由于水帘洞和第五观瀑台的关闭，这里实际上是离瀑布最近的地方了。黄果树瀑布倾泻而下，蒸腾起漫天水雾。离开的时候太阳出来了，不禁有点后悔，如果现在在瀑布下面，一定是能拍到彩虹的吧。大瀑布的人越来越多了，我们也赶时间去下一个景点。还没出黄果树景点，我们就和司机打了电话，要他赶过来接我们，可是等我们到了之前吃德克士的广场上，他还没来，打电话也是敷衍，我们一直等了半小时。这瓜皮一定是中途又带客了，由于他违反了约定，所以我们也没按照约定给他钱，只给了300，所以我觉得黄果树景区还是坐大巴好。贵州的旅游其实做的并不好，就拿安顺来说吧，从安顺西高铁站就没有直达黄果树的班车，如果不想打车，就只能到安顺东站坐车。而欢欢要在今天飞回南京，所以昨天大家就行程商量了下。卓林提议可以由他送欢欢去机场，我们其余的去龙宫，大家都同意了。不过欢欢今天觉得这样太麻烦卓林了，可能还有点事生他的气，所以就自己一个人坐了去安顺的大巴。卓林送完欢欢回来，流鼻血了当司机把我们从大瀑布景区接回来时已经差不多两点了，而龙宫景区在五点半之前停止售票。想从黄果树到龙宫，发现这趟班车今天并没有开（难道现在还不算旺季么），于是重又联系昨天的司机，司机带我们去龙宫，并送我们到安顺站，司机要价280。到了龙宫景区大概花了35分钟，我们一进售票厅便看到告示说连日下雨，二进龙宫不让进了。其实我们这次很多溶洞都没有看到，例如今天上午的天星洞，这次也不例外。进了龙宫，迎面而来一个小瀑布，不禁莞尔，我们刚去过黄果树瀑布好不好。但当转了一个弯后我们就被眼前之景吓到了。只见眼前是一个大山洞，山洞里弥漫着雾气，传出隆隆的声响，仿佛有仙人降临一般，这便是龙门飞瀑。龙门飞瀑正对面有一座桥，从桥上走过去有一个平台可以更近距离地观赏瀑布，我们争相到平台处和瀑布合影，短短几秒钟的时间，衣裤竟然全部湿透，可见水汽之盛。从这个平台还有石阶可供攀登，登临到离飞瀑更近的地方，不过我们没人敢去。从龙门飞瀑旁边可以坐观光电梯上去（要钱）也可以走电梯旁边的溶洞走上去，推荐还是走溶洞，还挺长的，走一走蛮有意思的。法一直心心念念龙宫的龙字田，想停在那里拍照。还在南京计划行程的时候，卓林就说之前看到过晚上有一班安顺到麻尾的列车，但却找不到了，唯一能用的是K1222这趟耗费一个上午的火车，因此他计划我们在安顺开个KTV，或者做个大保健，一直到早上乘车去麻尾。不过司机说安顺大保健还比较贵，可能要三四百的那种。司机把我们送到了安顺火车站边上，我们觉得他人挺实在的，就没跟他讲价，给了他280。我们在附近马鞍山路的一家餐馆吃了晚饭，这是一家很脏的餐馆，有点像室内版的大排档，垫桌布上面有着厚厚的油渍。吃完饭外面下起了蒙蒙小雨，我们想走到应该是位于黄果树大街上的一家KTV，可是刚走上过街天桥，雨突然刷得就变大了，我们只得匆匆下了天桥，顺这路边找有麻将房的宾馆。我们在麻将房里打了一会贵州（贵阳）麻将，贵州（贵阳）麻将感觉很是奇特，我搞了半天还是不怎么玩的起来。首先它牌非常少，没有我们这边的花啊东南西北风啥的，其次它的胡牌也很有特点，例如有小七对、大七对和清一色这样的胡法。小七对指的就是对对胡，而大七对就是三张的胡。对于除此之外的其他胡法必须要有杠之后才能胡牌，否则只能自摸。另外，麻将中的一条（幺鸡）是一张特殊的牌，如果别人你听牌了，那么可以根据手中的幺鸡数量赢筹码。特别地，如果你先前打出这张幺鸡，那么你的胜负筹码会加上一番，如果恰巧你是第一个打出这张牌的，那么你的胜负筹码会加上三番。打了一会儿法可能嫌我们有点吵了，就出门了。躺在床上玩手机传照片，突然学义喊了下我，一只虫子从我床上爬过，钻到不知道什么地方，我们挪了挪法的行李箱，发现它从床底又钻了出来，我怕它是臭虫，没敢踩。后来看清楚是蟑螂，学义一觉将它艹飞了，我拿了一个拖鞋把它打死。我们打算把三张床其中的两张搬到一起，这样我们三个男生可以合起来睡两张床。把边上床一挪，好家伙又是一只蟑螂，我们又开始灭蟑行动。这时法来消息说自己找了一个118的大保健，管饭还包夜，发了个定位在2km以外。果然跟着我法还是得吃啊。 D5 Jul.9 安顺-麻尾今天的任务主要是从安顺到麻尾。我们一早从麻将房起来准备赶去麻尾的火车，打法电话，法不接。心想这小子不会真去做“大保健”了吧，过了一会儿法和学义通了电话，原来真是睡着了。到了车站，法吐槽说自己做完按摩之后人家“体贴”地把他手机收起来了，导致他没听到起床闹钟，幸亏自己每天有五点多起床的习惯，才不至于误了车。火车晚点了一个小时十分钟。上车后，我们三个三个在不同的车厢。据卓林说，从都匀到麻尾要过58个洞，最长的一个洞要五分钟。具体多少个洞呢我是没数，但手机是根本用不了。躺在床上，上铺和下铺是一对母子，两个孩子睡在上铺，不停地在卧铺上爬上爬下，我是很担心他们会摔着。到了麻尾，卓林带我们来到了他家。是一栋三层的自建房。中午卓林爸妈请我们吃了牛肉牛杂火锅，和自己酿的葡萄酒（一汽油瓶）。那个葡萄酒真是特别的好喝，相对于市面上葡萄酒，更类似于葡萄汁，感觉没什么单宁，而是特别得甜。卓林爸爸非常热情，我们喝了好多杯。饭吃完投昏昏的，这葡萄酒后劲还是有的。酒醒了已经是六点多了，天还亮着，我们布依风情园是来不及去了，于是我们就简单地在镇子上逛了逛，顺便看看卓林家还没有装修的新房子。晚饭是喝茅台酒。 D6 Jul.10 麻尾-荔波小七孔-麻尾卓林的叔叔将我们从麻尾送到小七孔进行游玩。麻尾到小七孔有麻驾高速，不过这是噩梦的开始。刚下高速的地方是小七孔西门，那里在修路，黄埃散漫，路是非常地颠，我们不得不绕一个大圈从东门的服务中心进去，花了不到一个钟头的时间。小七孔东门离大七孔非常地近，但是卓林说大七孔实际上很瓜皮，所以只玩小七孔，在旅客中心买好了门票，我们去坐观光大巴到小七孔的一个临时入口，大家走过悬索桥，看到一个三孔桥“小三孔”，戏谑地说这小七孔还有四孔在哪儿呢？过了桥，下到地面，又得坐大巴，这趟大巴直接把我们送到了靠近西门的卧龙潭处，然后我们往回游览，最后回到东门。在乘坐大巴的过程中，我们匆匆看过68级水跌瀑布、拉雅瀑布等景点，还有一道瀑布从我们车上经过，越过盘山公路直接注入左边的河中。卧龙潭是一个半环的瀑布，在见过黄果树和龙门飞瀑之后，其实这个瀑布并没有引起我的惊艳，它近乎完美的半圆形有点让我觉得有点人造的。反倒是在瀑布前硬堵着莫名其妙载歌载舞的大妈们引起了我的反感。从卧龙潭可以选择50元的漂流到下面的鸳鸯湖景点，不过我们还是选择了乘坐大巴前往。在等车的时候，我们顺便到对面的坡上参观了娃娃鱼。到了鸳鸯湖，不禁吐槽这特么太坑了，两个项目鸳鸯湖划船(30)和天钟洞(8)都要付费。否则几乎没办法观赏鸳鸯湖的景色，在经过商量之后我们决定六个人正好划一艘船。事实上这波体验还是比较充实的（主要是累得）。我们拿到的桨有的是木头的，比较重，有的是合金和塑料的，比较轻，划起来很爽。由于我们的划力不对称，而且预判做的不好，我们的船经常方向调整过当，在湖里面转圈子。划船的时候我们又遇到了之前载歌载舞的大妈们，她们分了三四条船在湖中浪荡，唱和着（走调的）青藏高原。我和卓林便也和他们起哄，唱起了（完全不在调上的）《我的祖国》、《天路》，并很快与大妈们拼起了嗓门。排队坐车从鸳鸯湖到翠谷瀑布时，队伍正好截断了，我和卓林只能等下一趟大巴。从翠谷瀑布出来到水上森林我们没有坐车，我也脱掉了鞋套，换上了拖鞋。事实证明是我是对的，水上森林应该是小七孔最有意思的一个景点了，他和我们这边的水上森林不一样，湍急的水流从生长在乱石上的树木中流过，发出哗哗的声响。从水上森林出来坐上车，越过石上森林、拉雅瀑布等景点直接把我们送到了小七孔桥。为了看上游的68级水跌瀑布、拉雅瀑布等，我们又往上走。公路很窄，并且经常有大巴车从我们身边经过，在临崖面上有些地方已经修好了人行栈道，不过更多的地方还正在修，我们可以看到很多工程设备，工人们站在外伸梁和脚手架上在忙碌。我们看完那道越过盘山公路的瀑布后往回走，来到最后的景点小七孔桥。小七孔桥下面的河水叫做响水河，当它经过上游的大大小小的68级水跌瀑布来到小七孔古桥身前时，却是静的可怕。碧绿色的湖水犹如一面镜子一般，静谧的不想打破。据说小七孔古桥是清朝时黔南通往广西的交通要道，过了桥便到了广西地界。晚上，卓林爸妈请我们吃了狗肉、排骨、口条、大肠以及当地的小螃蟹小虾。狗肉是火锅的主料，非常的香，是卓林爸妈走很远的地方买过来的。排骨是预先炸好的，鲜红鲜红的，有点老了，但是非常好吃。大肠有点像机油渣子了，焦油味特别浓，但是有嚼劲，挺好吃的，不过我知道是大肠后就没怎么吃了。酒依然是之前的葡萄酒，我们最后把一汽油瓶的酒全部干完了。 D7 Jul.11 麻尾-贵阳-南京昨晚葡萄酒又喝醉了，吃晚饭一直睡到十一点多，洗了个澡继续睡，早上小轿车把我们送到火车站。路上司机和我们介绍说那个葡萄酒其实是用米酒泡葡萄的，我们觉着后劲非常大。这里必须吐槽一下贵阳的交通了，我们从火车站出来，走过一个天桥，到了遵义路上，希望能够找到空港巴士。到达机场发现还有个从福州过来的前序航班，估计又要延误了，不过后来换成从济南过来的一架飞机。临走时，卓林送了一些锅巴给我们，吃起来又油又甜，不过却非常酥脆，还是挺好吃的，午饭就吃这个了！飞机到了万州机场经停，我们在飞机上等待，空姐发放了贵州都市报，打开一看，这两天龙门飞瀑水量为十年来最大值，看来我们真是运气好，虽然二进龙宫没看到，但是那个瀑布着实还是震撼。从万州机场起飞后，天气一直很好，飞机有段时间沿着长江走，可以从飞机上我看到了三峡。 总结心得贵州是一个多民族的省份，在旅行过程中，卓林也一直和我们介绍贵州的风土人情。卓林是布依族人，据他介绍，布依族和广西的壮族（北壮）基本一致，可以认为在贵州境内称为布依族的，在广西境内就称为壮族，这时候他通常又会教我布依语，什么萌得了骨，古德亚梦啥的。贵州的行政区划也很有意思，例如少数民族比例比较高的铜仁被划为了地级市（之前是地区），而比例较低的黔东南则划为自治州。各地级区划上也是犬牙交错，如更亲近于贵阳的贵定被划入了黔南州。 当前的我国维稳第一，在我们的教育中，只讲要团结少数民族，但具体怎么个团结法呢？我们只能看到通过利益输送笼络各少数民族，而主体民族也容易产生反感，实际上这会产生不利于民族团结的结果。例如，在主体民族中，常常就会把各少数民族进行脸谱化，这是非常不好的。无论是团结或者尊重，都要始于了解。 贵州旅行建议贵州的交通是非常瓜皮的，由于山多，快速列车只能开到最高90km左右，而动车也就最高220km，同时如黔桂线是单线铁路，让车也会耗费较多的时间，因此贵州的铁路交通会耗费较多时间，比汽车要慢，而且不够舒适。此外，贵州交通的配套也做得很奇葩，例如荔波现在没有铁路，公路也很瓜皮（只有通麻尾的高速），但偏偏就有一个机场，而安顺到荔波却没有直飞的航班，因此去荔波的路就非常难走。此外铜仁也是比较尴尬的一个地方，它的铁路和湘黔线是两条平行的线，因此我们直接忽略过去了，事实上铜仁更适合放在张家界-凤凰-铜仁线上。在本身交通并不便利的情况下，景区为旅游也没有过多地去打算。此外在贵州走路要十分当心，贵州的很多路是不使用红绿灯的，取而代之的是他们的减速、停车让行比较严格，不过难免可能碰上冲的司机，所以还是小心为上。]]></content>
      <tags>
        <tag>游记</tag>
        <tag>贵州</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[魔方公式总结]]></title>
    <url>%2F2017%2F06%2F09%2F%E9%AD%94%E6%96%B9%E5%85%AC%E5%BC%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[基本规律 x, y, z系操作后不影响面的转动方向 例如对于公式y’ U’ (R’ U R)，经过y’后变为U’ F’ U F，只有转R变成了转F，但方向是不变的 常用手法 fsc1: R U R’ U’ 将当前槽起到顶层 fsc2: U R U’ R’ fsc1的反操作 s: U’ F’ U F t: U R U’ R 层先法底层底层只需要记住底面分别在前(fsc2)、上(R U’ R’ U’2 R U R’)、右(R U R’)的三个公式即可。 第二层比较好记的是五逆五顺。在右面对成3x3的倒T，向顶面棱块顶面颜色相同的方向转，顺时针就用五顺公式，反之五逆。还有一种使用s和t公式，方法是和五逆五顺一样对齐，然后根据起手U’或U使用s-t或t-s。起手往要归位的相反方向转动顶层。 顶部十字一个公式F(R U R’ U)F’，分别是点、左上角小L和一字形态，其中后两种可以不回F’连转。 顶部角块R2 F2 R’ B’ R F2 R’ B R’，注意B’ R的方向不要转反掉 简单的CFOPCrossCross要抓准面的相对位置关系，不需要直接与侧面四个中心块对齐。当白面朝上时，逆时针依次是红-蓝-橙-绿，当黄面朝上时，逆时针依次是红-绿-橙-蓝。推荐转的时候黄面朝上，以红色为基准，口诀是男(蓝)左女(绿)右。 F2L以魔方小站上的公式为准，一共有两类基础情况，这两类基础情况中角和棱都在顶层。 顶层异色 第一类情况其特点是顶层异色，最基础的一种是可以通过一步R(RUR’)或F’(F’U’F)能够将角块和棱块的相对位置做正确。 对于其他的底色块在角块侧面的情况，可以转化为以上的格式。这时候需要将R(‘)或L(‘)将角转下去“藏”到底面，转动顶层使得相对位置变为基本情况。这个操作会将你要藏角的槽的对面的槽转上来，所以特别注意不要破坏已经对好的槽，比如可以借用（也就是把这个槽起上来，角块藏下去，再还原底层十字）自己的槽，这可以借助U/U’或者d/d’实现。这里d/d’实际上是更好的一种做法，对于新手能够避免频繁的xyz操作。 顶层同色 另一类情况是角块和棱块相对位置已经正确了，但是全部在顶层，还未归如槽位，根据不同情况有U’F’UF和URU’R两种公式。 对于剩余的顶层同色的情况，可以转化为以上的格式。这时候需要将F或将角转下去“藏”到侧面，转动顶层使得相对位置变为基本情况。同样特别注意不要破坏已经对好的槽。注意这里空间位置要难一点，可以区分白色块在前侧面和右侧面（需要先U一下把右侧面的角转到前侧面处理）进行记忆。 白色块在顶层 将白色块转到侧面，按照1或2处理 OLL首先，鱼头和层先法是一样的。对于十字有两种情况。对于缺两角有三种情况。 PLL记住三棱换公式F2 X M’ X2 M X F2，其中X为恢复方向，取U或U’。记住四棱换公式： 十字对换 M’2 U M’2 U2 M’2 U M’2，M’即中间块向前转。可以发现这是一个关于(M’2 U)2的对称公式 平行对换 这里的平行对换指的是左上对换、右下对换，公式是 (M’2 U M’2 U) (M’ U2) (M’2 U2) (M’ U2)，记法考虑除了(M’2 U2)，其余都是M’2，U就转1次 CFOPF2L常见的非基本情况有角块底面（一般为白色）色块朝上、棱不在顶层、角块在底层。 1. 对于角和棱在一个槽里面，且白色块朝侧通过把棱起上来的可以将它转化为基本形式。在起的时候要注意尽量不要把白色小块转到朝上（因为这肯定不是标准形式）。其实这部分被公式更为快，因为不需要小心翼翼将棱起上来，并花费时间观察了。根据相对位置的不同，可以根据是否有颜色相同的侧面和与两侧中心块的位置关系（槽两边中心块的相对位置存在正反两个方向）分为四种情况。有的时候棱块角块位于错误的槽中，但假设我们按一个方向旋转这个槽，总可以将这个槽转对，所以与两侧中心块的位置关系只有两种情况 对于这四种情况有如下的套路：对于同侧面同色的情况，将角块逆时针转到侧面并旋转侧面藏下角块，此时棱块被起上来了，则向靠近角块的方向旋转，做正相对位置。对于同侧面异色的情况，这时候角块只有一个面是与中间棱块的位置是正确的，那就要用U或者U’使得角块上的这个面转到和棱块上的对应颜色位于相同的旋转盘上，然后通过向下藏角起棱的方式将棱转到（U或U’）合适地方，这样就能做到顶层异色的基本情况。如果转反了很容易想到会造成顶层同色的情况。在转动的时候为了不破坏转好的棱，常使用d转动下面两层，然后U’起上来的就是自己的槽了。 2. 对于角和棱在一个槽里面，且白色块朝上相对方向正确的话直接起上来即可。相对方向不正确，3次fsc1即可 3. 对于角和棱位于顶层且相离，且白色块朝上这时候应该藏棱（顺时针和逆时针对应两种情况），转动顶层使得角块与棱块对齐。 4. 对于角块在底面有的情况角块不在顶层，而在底层 对于角和棱在一个槽里面，白色块朝下 用公式(R U’2 R’ U)2将它们起上来，并且做对相对位置]]></content>
      <tags>
        <tag>魔方</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Word用法]]></title>
    <url>%2F2017%2F05%2F20%2FWord-Usage%2F</url>
    <content type="text"><![CDATA[微软Office产品的特点是看上去非常弱智，但实际用起来各种棘手。比较麻烦的有自动添加引用文献、设置多级标题、自动续表等工作。这里介绍以下我的方法。 自动添加引用文献网上描述的脚注的work around不是最好的方法，最好的方式是直接使用插入引文，然后对样式进行配置。配置方法参考我的Github项目 设置多级标题设置多级标题是为了实现这样的效果方法是先实现一个多级列表这里需要注意几点： 编号之后不能添加制表符，否则样式会乱掉 选择正规形式编号 对于每一级的列表，选择将它链接到样式 设置为左对齐，对齐位置0厘米 自动续表选择标题行，在表格属性中选择“在各页顶端以标题行形式重复出现” 使用主次坐标轴右击需要设置坐标轴的折线，选择设置系列格式 设置页眉从某一页开始设置奇数偶数页眉 在页面布局下方的分隔符菜单中选择“下一页”分隔符，则可以单独设置这页以下页面的页眉 选定需要设置的页眉，取消“链接到前一条页眉” 选定第一个奇数页眉，添加固定文本 选定第一个偶数页眉，添加StyleRef域分别选中和不选中插入段落编号各一次]]></content>
      <tags>
        <tag>word</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[明史之太祖本纪]]></title>
    <url>%2F2017%2F05%2F20%2F%E6%98%8E%E5%8F%B2%E4%B9%8B%E5%A4%AA%E7%A5%96%E6%9C%AC%E7%BA%AA%2F</url>
    <content type="text"><![CDATA[去敦煌玩回来的时候，卓林兄说其实明史是写的不错的，建议我读读。 一朱元璋籍贯濠州钟离（安徽凤阳），排行老小。出生时自然是天降异像，长大后自然是资貌雄奇。朱元璋十七岁的时候父母和（长）兄因为饥荒都死掉了，朱元璋只能进入皇觉寺当僧人。当时盗贼四起，刘福通供奉韩山童（红巾军），假称自己是宋朝的后裔，在颍地起兵。徐寿辉（红巾军天完政权）僭越称帝，在蕲地起兵。李二彭大赵均用（响应刘福通起义）在徐州起兵，方国珍早已在海上起兵。十二年春二月，郭子兴和孙德崖起兵濠州，元将彻里不花惮不敢镇压，只能欺负老百姓，朱元璋占卜决定投奔郭子兴造反。郭子兴看重他，又因为每战必胜，所以将至交马公的女儿许配给他，后来成了皇后。郭子兴和孙德崖不合，朱元璋经常从中调解。至正十二年九月，元军收服徐州，李二死于逃跑图中，其余两人投奔孙德崖。郭子兴礼遇彭大却轻视赵均用，孙德崖和赵均用于是合谋，在郭子兴外出时拿下，准备干掉他。这时候朱元璋在淮北，知道后赶回告诉彭大，彭大非常生气，和朱元璋一起率兵救出郭子兴，背着回来，郭子兴这才免于一劫。这年冬天，元将贾鲁围兵濠州，朱元璋和郭子兴共同抗击。到了第二年春天，贾鲁死了，包围解除了。朱元璋回家乡招募了七百人为兵，郭子兴非常高兴，让他当了镇抚。这时候彭赵两系比较跋扈，朱元璋就把兵权给其他将领，自己和从家乡招募的少时伙伴徐达、汤和、费聚等人进攻南方的定远，用计招降了驴牌寨的三千民兵，在横涧山夜袭元将张知院营地，收了两万兵，路上遇到李善长，（与之交流平定天下之术，）聊得很开心，于是和他一起攻下滁州。至正十三年的时候张士诚（江苏兴化人）在高邮自称诚王，到了十四年十月，元朝丞相脱脱在高邮大败张士诚并包围六合。朱元璋认为六合一旦攻破，滁州就不能免于灾难，于是和耿再成在瓦梁垒救援，将老弱病残护送回滁州。元军进攻滁州，朱元璋设伏击击败了元军。朱元璋（揣）度元军士气旺盛，肯定会再来，于是认了怂，归还缴获的马匹，让父老答谢元军，并说我是在守护城池防备其他反贼，为何要舍弃大盗而来追杀良民呢？元兵离去，滁州城得以保全。脱脱由于攻破张士诚，气势大盛，却中谗言，突然（遽）失去兵权，导致江淮更加混乱。至正十五年，郭子兴采用朱元璋的计策，派遣张天祐（郭子兴妻弟）占领和州（安徽和县），檄命朱元璋带领和州的部队。朱元璋将领们各不相让（不相下），于是先不公开檄文，等到第二天早上（旦日）再说。当时坐次以右为尊，将领们先进入，都坐在右边，朱元璋故意后到，坐在左边。到了讨论军机要事（比视事）的时候，朱元璋分析头头是道，大家都瞠目结舌，开始渐渐拜服（稍屈）。讨论分工筑城，约定三日，朱元璋做完了，其他将领都落后。朱元璋于是拿出檄文，朝南而坐，说“我奉命统领你们的兵权，现在筑城只是都落后了，按照军法要如何处置？”，将领们都惶恐谢罪。朱元璋于是将军队劫掠的有夫之妇搜出放回家，民众非常高兴。元军十万兵马进攻和州，朱元璋守城三个月，食物将要（且）吃完，然而太子秃坚、枢密副使绊住马等人在新塘等地断绝粮道。太祖率领大军大破元兵，元兵渡江逃走。三月份郭子兴死了，当时刘福通在亳州迎立韩山童的儿子韩林儿（小明王）建国号为宋。檄令郭子兴儿子郭天叙为都元帅，张天祐、朱元璋为左右副元帅，朱元璋慨然说“大丈夫怎么能够受制于人呢？”于是不受。但是考虑到韩林儿势盛可以依靠，于是用他的年号来率令军中。四月份常遇春归顺。五月份朱元璋想渡江却没有船，正好（红巾军）巢湖帅廖永安等人带领千艘船来归顺（附），朱元璋非常高兴，前往安抚。元中丞蛮子海牙扼守通程闸等关隘，巢湖舟师无路可出。忽然天降大雨，朱元璋说真是天助我也，于是趁着水涨，从小港乘船出来。趁机（因）在峪溪口击败海牙。于是定下渡江之计，众将领请求直捣集庆，朱元璋说要攻下集庆必须经过采石，而采石是重镇，防守一定坚固，而牛渚面临大江，难以防守，可以去攻下它。六月乙卯，乘风直达牛渚。常遇春先登陆攻克。采石元兵也溃逃，于是沿（缘）江各个堡垒全部（悉）归顺。众将领因为和州饥荒，争相去粮食准备回去。朱元璋和徐达说“渡江侥幸成功，如果舍弃回来，江东就不归我了”，于是将船缆全部断掉放在急流中（以断绝退路），和将领们说“太平（马鞍山当涂）此地比较近，我和你们一同攻取”，于是乘胜攻克太平，抓获（执）万户那哈出来。总管靳义透水自杀，朱元璋说这是义士啊，以礼埋葬他。朱元璋宣布禁止剽略，有士卒违背命令，斩首示众（徇），军中肃然。改路曰府，置太平兴国翼元帅府，自领元帅事，召陶安参幕府事。这时候太平四面都是元兵，右丞蛮子海牙等堵截姑孰口，陈聎先（陈野先？）的水军统帅康茂才率令数万人攻城，朱元璋派徐达、邓愈、汤和逆等人正面迎战，另外派将士潜入其后夹击，擒获野先，降其众，阿鲁灰等人逃跑了。九月份，郭天叙（郭子兴儿子）和张天祐等人进攻集庆，野先背叛了，两人都战死，于是郭子兴部将都归顺朱元璋。野先不就被民兵所杀，他的从子兆先收服他的部众，屯兵方山，和海牙掎角以窥太平。十二月壬子，释纳哈出北归。十六年春大破海牙于采石。三月癸未（2.25日），进攻集庆，擒获陈兆先，降其众三万六千人，他们都疑惑害怕不能保全自己。朱元璋选择五百人当守卫，解甲酣寝达旦，众心开始安定。庚寅，再败元兵于蒋山。元御史大夫福寿，奋力战斗，为之而死，蛮子海牙逃遁归顺张士诚，康茂才投降朱元璋。朱元璋进入城池，召集官吏父老说：“元朝政治腐败，干戈四起，我来为民除乱，请各位安于职守。贤士我以礼相用，旧政不便者除之，官吏不能贪暴殃及我的百姓。”民乃大喜过望。改集庆路为应天府，征召（辟）夏煜、孙炎、杨宪等十余人，葬御史大夫福寿，以表彰它的忠心。那时，元将定定扼镇江，别不华、杨仲英屯宁国，青衣军张明鉴据扬州，八思尔不花驻徽州，石抹宜孙守处州（浙江丽水一带），他的弟弟石厚孙守婺州，宋伯颜不花守衢州。而池州已为徐寿辉将所据，张士诚从淮东攻陷平江（今苏州）后，转掠浙西。朱元璋已经平定集庆，考虑到张士诚、徐寿辉实力强大，江左、浙右诸郡都被他们吞并，于是派遣徐达攻克镇江，定定战死。夏六月，邓愈攻克广德。秋七月己卯，诸将拥护朱元璋为吴国公，置江南行中书省，自己总领省事，设置官僚协助。朱元璋送（贻）文书给张士诚，张士诚不回复（报），却引兵攻镇江。徐达击败张士诚，进军包围常州没有攻下。九月戊寅，朱元璋前往（如）镇江拜谒孔子庙。派遣儒士告谕父老要勤于农桑，不久朱元璋回到应天。十七年春二月，耿炳文攻克长兴。三月，徐达克攻常州。夏四月丁卯，朱元璋亲自率兵攻克宁国（安徽），别不华投降。五月，上元、宁国、句容献瑞麦。六月，赵继祖攻克江阴。秋七月，徐达攻克常熟。胡大海攻克徽州，八思尔不花遁逃。冬十月，常遇春攻克池州，缪大亨攻克扬州，张明鉴投降。十二月己丑，释囚。第二年，徐寿辉的将领明玉珍占据重庆路。十八年春二月乙亥，朱元璋任命康茂才为营田使。三月己酉，审查囚犯（录囚）。邓愈攻克建德路。夏四月，徐寿辉率领陈友谅派遣赵普胜攻陷池州。第二月，陈友谅占据龙兴路。五月，刘福通攻破汴梁，迎接韩林儿在此建都。当初，刘福通派遣将领攻破山东、秦晋、幽蓟，使得中原大乱，太祖因此得以依次（次第）安定长江沿岸（江表）。朱元璋所过之处不杀百姓，收召有才之人，因此人心日益归顺。冬十二月，胡大海久攻不下婺州，太祖亲自率兵前往。石抹宜孙派遣将领率战车从松溪赶来来援，朱元璋说“道路狭窄，车战是在自取其败”。于是命令胡德济在梅花门迎战，大破婺州。婺州投降，执石厚孙。在攻克前一天，城中人望见城西五色云如车盖，认为是异象，到现在才知道那里是朱元璋驻兵的地方。朱元璋进入城中，发粮食赈济贫民，改婺州为宁越府。征召（辟）范祖干、叶仪、许元等十三人分直讲经史。戊子，派遣使者招抚方国珍。十九年春正月乙巳，朱元璋谋取浙东，却没有攻克各路。他告诫各个将领说“用武力攻克城池，用仁义平定战乱（戡乱）。我等到（比）进入集庆的时候，秋毫无犯，所以能一举而定。每次听到各个将领攻下一座城池却不妄杀，就会喜不自胜。军队行洞如火，不（控制）戢就成燎原之势。作为将令能够以不杀为武，不知国家能得到利益，更能够造福子孙”。庚申，胡大海攻克诸暨。第二月，朱元璋命令宁越知府王宗显设立郡学。三月甲午，赦免除大逆之罪以下的罪犯。丁巳，方国珍想要献出温州、台州、庆元（浙江宁波），派遣其子关为质，朱元璋不接受。夏四月，俞通海等收复池州。当时耿炳文守长兴，吴良守江阴，汤和守常州，都几次击败张士诚的兵。朱元璋借故久留宁越，巡视浙东。六月壬戌，返回应天。秋八月，元朝的察罕帖木儿收服汴梁，刘福通和韩林儿退保安丰（安徽寿县）。九月，常遇春攻克衢州，擒宋伯颜不花。冬十月，派遣夏煜授予方国珍行省平章，方国珍以疾病为由推辞。十一月壬寅，胡大海攻克处州，石抹宜孙遁。时元守兵单弱，并且听闻中原大乱，人心离散，因此江左、浙右诸郡，朱元璋的兵只要到达都能攻克，朱元璋于是向西进发，与陈友谅相邻。二十年春二月，元朝福建行省参政袁天禄以福宁降。三月戊子，征刘基、宋濂、章溢、叶琛到任。夏五月，徐达、常遇春败陈友谅于池州。闰月丙辰，友谅陷太平，守将朱文逊，院判花云、王鼎，知府许瑗战死。没多久，陈友谅谋杀自己老大徐寿辉，自称皇帝，国号汉，拥有江西、湖广地，与张士诚相约合攻应天，应天城内非常震惊。诸将商议先收复太平来牵制，朱元璋说“不行，张士诚他们占据上游，舟师十倍于我，难以收复。”有人（或）请求朱元璋亲自（自将）出击，朱元璋说“不行。他们用小部队（偏师）牵制（缀）我，而大军前往金陵，顺流半日即可到达，我们步骑难以及时返回，百里趋战，兵法所忌，这不是良策”。于是飞马告知胡大海攻打信州牵制他们的后方，命令康茂才（陈友谅的旧友）欺骗（绐）陈友谅，让他赶快来（进攻）。陈友谅果然领兵东进。于是派遣常遇春在石灰山设伏，徐达在南门外设阵，杨璟在大胜港屯兵，张德胜等率领舟师出龙江关，太祖亲自在卢龙山督军。乙丑，陈友谅至龙湾，大家想开战，朱元璋说“天色将要（且）下雨，催促（趣）吃饭，乘雨攻击他们。”须臾，果然下大雨，士卒竞奋，雨止合战，水陆夹击，大破陈友谅军队。陈友谅乘船走。于是朱元璋收复太平，攻下安庆，而胡大海也攻克信州。当时，太祖命令康茂才欺骗（绐）友谅，李善长对此很不解。朱元璋说“二寇联合，我首尾受敌，只有让他先来从而攻破他，那么张士诚就会闻风丧胆了”后来（已而）张士诚终于（竟）还是没有出兵。丁卯，设置儒学提举司，设置宋濂为提举，派遣自己的儿子朱标学习（受）经学。六月，耿再成在庆元（浙江宁波）打败石抹宜孙，石抹宜孙战死，遣使祭之。秋九月，徐寿辉旧将欧普祥以献上袁州投降。冬十二月，再次派遣夏煜以书传谕方国珍。二十一年春二月甲申，朱元璋设立盐茶课。己亥，设置宝源局。三月丁丑，改枢密院为大都督府。元将薛显以泗州降。戊寅，国珍遣使来谢，饰金玉马鞍以献。却之曰：“现在应当经营（事）四方，需要人才和粟帛，宝玩不是我所喜好的”。秋七月，陈友谅部将张定边攻克安庆。八月，朱元璋遣使去访问元平章（官名）察罕帖木儿。当时察罕平定山东，降服田丰，军声大振，故朱元璋与他通好。恰好（会）察罕方攻益都没有成功，朱元璋于是亲自率领舟师征讨陈友谅。戊戌，攻克安庆，陈友谅部将丁普郎、傅友德迎降。壬寅，到达（次）湖口，在江州追击战败的陈友谅，攻克其城，陈友谅奔逃武昌。朱元璋分别巡行（徇）南康、建昌、饶、蕲、黄、广济，所到皆攻克。冬十一月己未，攻克抚州。二十二年春正月，陈友谅江西行省丞相胡廷瑞献出龙兴（南昌）投降。乙卯，朱元璋到（如）龙兴，改为洪都府（南昌）。拜谒孔子庙，告谕父老，废除陈友谅的苛政，取消诸军需，抚恤贫无依靠（告）者，民大悦。袁、瑞、临江、安相继下。二月，朱元璋返回应天。邓愈留守洪都。癸未，归降之人蒋英杀金华守将胡大海，郎中王恺因此而死，蒋英叛降张士诚。处州归降之人李祐之闻变，亦杀行枢密院判耿再成并谋反，都事孙炎、知府王道同、元帅硃文刚因此而死。三月癸亥，归降之人祝宗、康泰谋反，攻陷洪都，邓愈出走应天，知府叶琛、都事万思诚因此而死。当月，明玉珍在重庆称帝，国号夏。夏四月己卯，邵荣收复处州。甲午，徐达复洪都。五月丙午，朱文正（朱元璋侄子）、赵德胜、邓愈坐镇洪都。六月戊寅，察罕帖木儿写书信来通报，留我使人不送回（遣）。察罕不久被田丰所杀。秋七月丙辰，平章（官名）邵荣、参政赵继祖谋逆，伏诛。冬十二月，元遣尚书张昶航海至庆元（浙江宁波），授朱元璋江西行省平章政事，朱元璋不接受。察罕的儿子扩廓帖木儿致书归使者。二十三年春正月丙寅，朱元璋派遣汪河回复（报）扩廓帖木儿。二月壬申，命令将士屯田积谷。这月，陈友谅部将张定边攻陷饶州。张士诚部将吕珍攻破安丰，杀死刘福通。三月辛丑，朱元璋亲自率兵救援安丰，吕珍败走，和韩林儿归滁州，朱元璋于是回到应天。夏四月壬戌，陈友谅大举兵围洪都。乙丑，诸全守将谢再兴叛，归顺（附）于士诚。五月，朱元璋建筑礼贤馆。陈友谅分兵攻陷吉安，参政刘齐、知府硃叔华为此而死；攻陷临江，同知赵天麟为此而死；攻陷无为州，知州董会为此而死。秋七月癸酉，朱元璋亲自率兵救援洪都（南昌）。癸未，达到（鄱阳）湖口，先在泾江口和南湖觜设下伏兵，遏制陈友谅的退路，檄令信州（江西上饶）兵守武阳渡。陈友谅听闻朱元璋来了，解了洪都的围，逆战于鄱阳湖。陈友谅兵号称有六十万，联巨舟为阵，楼橹高十余丈，绵亘数十里，旌旗戈盾，望之如山。丁亥，遇于鄱阳湖的康郎山，朱元璋分军十一队以御之。戊子，合战，徐达击其前锋，俞通海以火炮焚其舟数十，杀伤略相当。陈友谅骁将张定边直犯太祖舟，朱元璋的船在沙中搁浅，不得退，十分危急，常遇春从旁射中张定边，俞通海也（复）来援助，舟骤进，水涌进朱元璋的船里，这才得以脱身。己丑，陈友谅悉巨舰出战，诸将舟小，仰攻不利，大家都面有惧色。朱元璋亲自指挥，大家仍然不敢前进，斩退缩者十余人，人皆殊死战。到了下午三到五点（晡，申时），大风起东北，乃命敢死士操七舟，把火药放在芦苇里面，用火烧陈友谅的船。风烈火炽，烟焰涨天，湖水尽赤。陈友谅兵大乱，诸将鼓噪乘之，斩首二千余级，焚溺死者不计其数（无算），陈友谅彻底泄了气（气夺）。辛卯，复战，友谅复大败。于是陈友谅敛舟自守，不敢更战。壬辰，太祖移军扼左蠡，友谅亦退保渚矶。相持三日，其左、右二金吾将军皆降。陈友谅势益蹙，忿甚，尽杀所获将士。而太祖则悉还所俘，伤者傅以善药，且祭其亲戚诸将阵亡者。八月壬戌，友谅食尽，趋南湖觜，为南湖军所遏，遂突湖口。太祖邀之，顺流搏战，及于泾江。泾江军复遮击之，陈友谅被流箭射中而死。张定边带着（以）陈友谅的儿子陈理奔武昌。九月，朱元璋回到应天，论功行赏。先前，朱元璋想要救援安丰，不听刘基的劝阻。现在对刘基说“我不应当去安丰。使得陈友谅乘虚直捣应天，大事去矣。乃顿兵南昌，不亡何待。陈友谅死了，天下就不难平定了。”壬午，亲自征讨陈理。当月，张士诚自称吴王。冬十月壬寅，朱元璋围攻武昌，分徇湖北诸路，皆下。十二月丙申，朱元璋回到应天，常遇春留督诸军。二十四年春正月丙寅朔，李善长等率群臣权朱元璋当皇帝（劝进），朱元璋不同意。在众人坚持下，才即吴王位。建百官。任命李善长为右相国，徐达为左相国，常遇春、俞通海为平章政事，谕之曰：“立国之初，当先正纪纲。元氏暗弱，威福下移，驯至于乱，今宜鉴之。”立子标为世子。二月乙未，朱元璋再次亲自率兵征伐武昌，陈理投降了，汉、沔（湖北仙桃）、荆、岳皆下。三月乙丑，回到应天。丁卯，设置起居注（官位）。庚午，罢诸翼元帅府，置十七卫亲军指挥使司，命中书省辟文武人材。夏四月，建祠，祀死事丁普郎等于康郎山，赵德胜等于南昌。秋七月丁丑，徐达攻克卢州。戊寅，常遇春徇江西。八月戊戌，收复吉安（江西吉安），遂围赣州。达徇荆、湘诸路。九月甲申，下江陵（湖北荆州），夷陵（宜昌）、潭、归皆降。冬十二月庚寅，徐达攻克辰州（湖南怀化），遣别将下衡州。二十五年春正月己巳，徐达下宝庆（湖南邵阳），湖湘平。常遇春克赣州，熊天瑞降。遂趋南安，招谕岭南诸路，下韶州、南雄。甲申，如南昌，执大都督硃文正以归，数其罪，安置桐城。二月己丑，福建行省平章陈友定侵略处州，参军胡深击败之，遂下浦城。丙午，张士诚部将李伯升攻诸全之新城，李文忠大败之。夏四月庚寅，常遇春徇襄、汉诸路。五月乙亥，攻克安陆。己卯，下襄阳。六月壬子，朱亮祖、胡深攻建宁，战于城下，胡深被抓获（执），死之。秋七月，令从渡江士卒被创废疾者养之，赡养死者的妻儿。九月丙辰，建国子学。冬十月戊戌，下令讨张士诚。是时，张士诚占据的地方，南至绍兴，北有通、泰、高邮、淮安、濠（安徽凤阳）、泗，又北至于济宁。乃命徐达、常遇春等先规取淮东。闰月，围泰州，克之。十一月，张士诚寇宜兴，徐达击败之，遂自宜兴还攻高邮。二十六年春正月癸未，张士诚窥江阴，太祖自将救之，张士诚遁，康茂才追败之于浮子门。太祖还应天。二月，明玉珍死，子升自立。三月丙申，令中书严选举。徐达克高邮。夏四月乙卯，袭破士诚将徐义水军于淮安，徐义遁逃，梅思祖以城降。濠、徐、宿三州相继下，淮东平。甲子，如濠州省墓，置守冢二十家，赐故人汪文、刘英粟帛。置酒召父老饮，极欢，曰：“我离开家乡十多年了，艰难百战，乃得归省坟墓，与父老子弟复相见。今苦不得久留欢聚为乐。父老幸教子弟孝弟力田，不要去远的地方从上，淮河两岸的郡县尚苦于寇掠，父老善自爱。”令有司除租赋，父老乡亲们都顿首谢。辛未，徐达攻克安丰，分兵败扩廓于徐州。夏五月壬午，至自濠。庚寅，求遗书。秋八月庚戌，改筑应天城，作新宫钟山之阳。辛亥，命徐达为大将军，常遇春为副将军，帅师二十万讨张士诚。御戟门誓师曰：“城池被攻克的时候，毋杀掠，毋毁庐舍，毋发丘垄。张士诚母葬平江城外，毋侵毁。”既而召问徐达、常遇春，用兵当何先。常遇春欲直捣平江。太祖曰：“湖州张天骐、杭州潘原明为张士诚臂指，平江穷蹙，如果这两人悉力赴援，我们难以取胜。倒不如先攻湖州，使敌人疲于奔命。羽翼既披（靡），平江的势力孤单，就可以攻破矣。”甲戌，朱元璋败张天骐于湖州，张士诚亲率兵来援，复败之于皁林。九月乙未，李文忠攻杭州。冬十月壬子，遇春败士诚兵于乌镇。十一月甲申，张天骐投降。辛卯，李文忠下余杭，潘原明降，旁郡悉下。癸卯，围平江。十二月，韩林儿卒。以第二年为吴元年，建庙社宫室，祭告山川。所司进宫殿图，朱元璋命令除去雕琢奇丽者。是岁，元扩廓帖木儿与李思齐、张良弼构怨，屡相攻击，朝命不行，中原民益困。 二十七年春正月戊戌，谕中书省曰：“东南久罹兵革，民生凋敝，吾甚悯之。且太平、应天诸郡，吾渡江开创地，供亿烦劳久矣。今每家每户都很空虚（比户空虚，比：挨着），有司急催科，重困吾民，将何以堪。其赐太平田租二年，应天、镇江、宁国、广德各一年。”二月丁未，傅友德败扩廓将李二于徐州，执之。三月丁丑，始设文武科取士。夏四月，方国珍暗中（阴）遣人联系扩廓帖木儿和陈友定，移书责之。五月己亥，初置翰林院。是月，朱元璋因为干旱减膳素食，复徐、宿、濠、泗、寿、邳、东海、安东、襄阳、安陆及新附地田租三年。六月戊辰，大雨，群臣请复膳。太祖曰：“虽雨，伤禾已多，其赐民今年田租。”癸酉，命朝贺罢女乐。秋七月丙子，给府州县官之任费，赐绮帛，及其父母妻长子有区别（有差），书面写出为规章制度（著为令）。己丑，雷震宫门兽吻，赦罪囚。庚寅，遣使责令方国珍贡粮。八月癸丑，圜丘、方丘、社稷坛成。九月甲戌，太庙成。朱亮祖帅师讨方国珍。戊寅，诏曰：“先王之政，罪不及孥。自今除大逆不道，毋连坐。”辛巳，徐达克平江，执张士诚，吴地平。戊戌，遣使致书于元主，送其宗室神保大王等北还。辛丑，论平吴功，封李善长宣国公，徐达信国公，常遇春鄂国公，将士赐赉（lai，赠送）不一（有差）。朱亮祖克台州。癸卯，新宫成。冬十月甲辰，遣起居注吴琳、魏观以币求遗贤于四方。丙午，令百官礼仪尚左。改李善长左相国，徐达右相国。辛亥，祀元臣余阙于安庆，李黼于江州。壬子，置御史台。癸丑，汤和为征南将军，吴祯副之，讨国珍。甲寅，定律令。戊午，正郊社、太庙雅乐。庚申，召诸将议北征。太祖曰：“山东则王宣反侧，河南则扩廓跋扈，关陇则李思齐、张思道枭张猜忌，元皇位（zuo，祚）将亡，中原涂炭。今将北伐，拯生民于水火，何以决胜？”常遇春对曰：“以我百战之师，敌彼久逸之卒，直捣元都，破竹之势也。”太祖曰：“元建国百年，守备必固，悬军深入，馈饷不前，援兵四集，危道也。吾欲先取山东，撤彼屏蔽，移兵两河，破其籓篱，拔潼关而守之，扼其户槛。天下形胜入我掌握，然后进兵，元都势孤援绝，不战自克。鼓行而西，云中、九原、关陇可席卷也。”诸将皆曰善。甲子，徐达为征虏大将军，常遇春为副将军，帅师二十五万，由淮入河，北取中原。胡廷瑞为征南将军，何文辉为副将军，取福建。湖广行省平章杨璟、左丞周德兴、参政张彬取广西。己巳，朱亮祖克温州。十一月辛巳，汤和克庆元，方国珍遁入海。壬午，徐达克沂州，斩王宣。己丑，廖永忠为征南副将军，自海道会和讨国珍。乙未，颁《大统历》。辛丑，徐达克益都。十二月甲辰，颁律令。丁未，方国珍降，浙东平。张兴祖下东平，兗东州县相继降。己酉，徐达下济南。胡廷瑞下邵武。癸丑，李善长帅百官劝进，表三上，乃许。甲子，告于上帝。庚午，汤和、廖永忠由海道克福州。 二洪武元年春正月乙亥，祀天地于南郊，即皇帝位。定有天下之号曰明，建元洪武。追尊高祖考曰玄皇帝，庙号德祖，曾祖考曰恒皇帝，庙号懿祖；祖考曰裕皇帝，庙号熙祖，皇考曰淳皇帝，庙号仁祖，妣皆皇后。立妃马氏为皇后，世子标为皇太子。以李善长、徐达为左、右丞相，诸功臣进爵有差。丙子，颁即位诏于天下。追封皇伯考以下皆为王。辛巳，李善长、徐达等兼东宫官。甲申，遣使核浙西田赋。壬辰，胡廷瑞克建宁。庚子，邓愈为征戍将军，略南阳以北州郡。汤和克延平，执元平章陈友定，福建平。是月，天下府州县官来朝。谕曰：“天下始定，民财力俱困，要在休养安息，惟廉者能约己而利人，勉之。”二月壬寅，定郊社宗庙礼，岁必亲祀，把这作为常态。癸卯，汤和提督海运。廖永忠为征南将军，朱亮祖副之，由海道取广东。丁未，以太牢祀先师孔子于国学。戊申，祀社稷。壬子，诏衣冠如唐制。癸丑，常遇春克东昌，山东平。甲寅，杨璟克宝庆。三月辛未，诏儒臣修女诫，戒后妃毋预政。壬申，周德兴克全州。丁酉，邓愈克南阳。己亥，徐达徇汴梁，左君弼降。夏四月辛丑，蕲州进竹簟，却之，命四方毋妄献。廖永忠师至广州，元守臣何真降，广东平。丁未，祫享太庙。戊申，徐达、常遇春大破元兵于洛水北，遂围河南。梁王阿鲁温降，河南平。丁巳，杨璟克永州。甲子，幸汴梁。丙寅，冯胜克潼关，李思齐、张思道遁。五月己卯，廖永忠下梧州，浔、贵、容、郁林诸州皆降。辛卯，改汴梁路为开封府。六月庚子，徐达朝行在。甲辰，海南、海北诸道降。壬戌，杨璟、硃亮祖克靖江。秋七月戊子，廖永忠下象州，广西平。庚寅，振恤中原贫民。辛卯，将还应天，谕达等曰：“中原之民，久为群雄所苦，流离相望，故命将北征，拯民水火。元祖宗功德在人，其子孙罔恤民隐，天厌弃之。君则有罪，民复何辜。前代革命之际，肆行屠戮，违天虐民，朕实不忍。诸将克城，毋肆焚掠妄杀人，元之宗戚，咸俾保全。庶几上答天心，下慰人望，以副朕伐罪安民之意。不恭命者，罚无赦。”丙申，命冯胜留守开封。闰月丁未，至自开封。己酉，徐达会诸将兵于临清。壬子，常遇春克德州。丙寅，克通州，元帝趋上都。是月，征天下贤才为守令。免吴江、庆德、太平、宁国、滁、和被灾田租。八月己巳，以应天为南京，开封为北京。庚午，徐达入元都，封府库图籍，守宫门，禁士卒侵暴，遣将巡古北口诸隘。壬申，以京师火，四方水旱，诏中书省集议便民事。丁丑，定六部官制。御史中丞刘基致仕。己卯，赦殊死以下。将士从征者恤其家，逋逃许自首。新克州郡毋妄杀。输赋道远者，官为转运，灾荒以实闻。免镇江租税。避乱民复业者，听垦荒地，复三年。衍圣公袭封及授曲阜知县，并如前代制。有司以礼聘致贤士，学校毋事虚文。平刑，毋非时决囚。除书籍田器税，民间逋负免征。蒙古、色目人有才能者，许擢用。鳏寡孤独废疾者，存恤之。民年七十以上，一子复。他利害当兴革不在诏内者，有司具以闻。壬午，幸北京。改大都路曰北平府。征元故臣。癸未，诏徐达、常遇春取山西。甲午，放元宫人。九月癸亥，诏曰：“天下之治，天下之贤共理之。今贤士多隐岩穴，岂有司失于敦劝欤，朝廷疏于礼待欤，抑朕寡昧不足致贤，将在位者壅蔽使不上达欤？不然，贤士大夫，幼学壮行，岂甘没世而已哉。天下甫定，朕愿与诸儒讲明治道。有能辅朕济民者，有司礼遣。”乙丑，常遇春下保定，遂下真定。冬十月庚午，冯胜、汤和下怀庆，泽、潞相继下。丁丑，至自北京。戊寅，以元都平，诏天下。十一月己亥，遣使分行天下，访求贤才。庚子，始祀上帝于圜丘。癸亥，诏刘基还。十二月丁卯，徐达克太原，扩廓帖木儿走甘肃，山西平。己巳，置登闻鼓。壬辰，以书谕明升。 二年春正月乙巳，立功臣庙于鸡笼山。丁未，享太庙。庚戌，诏曰：“朕淮右布衣，因天下乱，率众渡江，保民图治，今十有五年。荷天眷祐，悉皆戡定。用是命将北征，齐鲁之民馈粮给军，不惮千里。朕轸厥劳，已免元年田租。遭旱民未苏，其更赐一年。顷者大军平燕都，下晋、冀，民被兵燹，困征敛，北平、燕南、河东、山西今年田租亦与蠲免。河南诸郡归附，久欲惠之，西北未平，师过其地，是以未逞。今晋、冀平矣，西抵潼关，北界大河，南至唐、邓、光、息，今年税粮悉除之。”又诏曰：“应天、太平、镇江、宣城、广德供亿浩穰。去岁蠲租，遇旱惠不及下。其再免诸郡及无为州今年租税。”庚申，常遇春取大同。是月，倭寇山东滨海郡县。二月丙寅朔，诏修元史。壬午，耕耤田。三月庚子，徐达至奉元，张思道遁。振陕西饥，户米三石。丙午，常遇春至凤翔，李思齐奔临洮。夏四月丙寅，遇春还师北平。己巳，诸王子受经于博士孔克仁。令功臣子弟入学。乙亥，编《祖训录》，定封建诸王之制。徐达下巩昌。丙子，赐秦、陇新附州县税粮。丁丑，冯胜至临洮，李思齐降。乙酉，徐达袭破元豫王于西宁。五月甲午朔，日有食之。丁酉，徐达下平凉、延安。张良臣以庆阳降，寻叛。癸卯，始祀地于方丘。六月己卯，常遇春克开平，元帝北走。壬午，封陈日煃为安南国王。秋七月己亥，鄂国公常遇春卒于军，诏李文忠领其众。辛亥，扩廓帖木儿遣将破原州、泾州。辛酉，冯胜击走之。丙辰，明升遣使来。八月丙寅，元兵攻大同，李文忠击败之。己巳，定内侍官制。谕吏部曰：“内臣但备使令，毋多人，古来若辈擅权，可为鉴戒。驭之之道，当使之畏法，勿令有功，有功则骄恣矣。”癸酉，《元史》成。丙子，封王颛为高丽国王。癸未，徐达克庆阳，斩张良臣，陕西平。是月，命儒臣纂礼书。九月辛丑，召徐达、汤和还，冯胜留总军事。癸卯，以临濠为中都。戊午，征南师还。冬十月壬戌，遣杨璟谕明升。甲戌，甘露降于钟山，群臣请告庙，不许。辛卯，诏天下郡县立学。是月，遣使贻元帝书。十一月乙巳，祀上帝于圜丘，以仁祖配。十二月甲戌，封阿答阿者为占城国王。甲申，振西安诸府饥，户米二石。己丑，大赉平定中原及征南将士。庚寅，扩廓帖木儿攻兰州，指挥于光死之。是年，占城、安南、高丽入贡。 三年春正月癸巳，徐达为征虏大将军，李文忠、冯胜、邓愈、汤和副之，分道北征。二月癸未，追封郭子兴滁阳王。戊子，诏求贤才可任六部者。是月，李文忠下兴和，进兵察罕脑儿，执元平章竹贞。三月庚寅，免南畿、河南、山东、北平、浙东、江西广信、饶州今年田租。夏四月乙丑，封皇子樉为秦王，晋王，棣燕王，橚吴王，桢楚王，榑齐王，梓潭王，巳赵王，檀鲁王，从孙守谦靖江王。徐达大破扩廓帖木儿于沈儿峪，尽降其众，扩廓走和林。丙戌，元帝崩于应昌，子爱猷识理达腊嗣。是月，慈利土官覃垕作乱。五月己丑，徐达取兴元。分遣邓愈招谕吐蕃。丁酉，诏守令举学识笃行之士。己亥，设科取士。甲辰，李文忠克应昌。元嗣君北走，获其子买的里八剌，降五万余人，穷追至北庆州，不及而还。丁未，诏行大射礼。戊申，祀地于方丘，以仁祖配。辛亥，徐达下兴元。邓愈克河州。丁巳，诏开国时将帅无嗣者禄其家。是月旱，斋戒，后妃亲执爨，皇太子诸王馈于斋所。六月戊午朔，素服草屦，步祷山川坛，露宿凡三日，还斋于西庑。辛酉，赉将士，省狱囚，命有司访求通经术明治道者。壬戌，大雨。壬申，李文忠捷奏至，命仕元者勿贺。谥元主曰顺帝。癸酉，买的里八剌至京师，群臣请献俘。帝曰：“武王伐殷用之乎？”省臣以唐太宗尝行之对。帝曰：“太宗是待王世充耳。若遇隋之子孙，恐不尔也。”遂不许。又以捷奏多侈辞，谓宰相曰：“元主中国百年，朕与卿等父母皆赖其生养，奈何为此浮薄之言？亟改之。”乙亥，封买的里八剌为崇礼侯。丙子，告捷于南郊。丁丑，告太庙，诏示天下。辛巳，徙苏州、松江、嘉兴、湖州、杭州民无业者田临濠，给资粮牛种，复三年。是月，倭寇山东、浙江、福建滨海州县。秋七月丙辰，明升将吴友仁寇汉中，参政傅友德击却之。中书左丞杨宪有罪诛。八月乙酉，遣使瘗中原遗骸。冬十月丙辰，诏儒士更直午门，为武臣讲经史。癸亥，周德兴为征南将军，讨覃垕，垕遁。辛巳，贻元嗣君书。十一月壬辰，北征师还。甲午，告武成于郊庙。丙申，大封功臣。进李善长韩国公，徐达魏国公，封李文忠曹国公，冯胜宋国公，邓愈卫国公，常遇春子茂郑国公，汤和等侯者二十八人。己亥，设坛亲祭战没将士。庚戌，有事于圜丘。辛亥，诏户部置户籍、户帖，岁计登耗以闻，著为令。乙卯，封中书右丞汪广洋忠勤伯，御史中丞刘基诚意伯。十二月癸亥，复贻元嗣君书，并谕和林诸部。甲子，建奉先殿。庚午，遣使祭历代帝王陵寝，并加修葺。己卯，赐勋臣田。壬午，以正月至是月，日中屡有黑子，诏廷臣言得失。是年，占城、爪哇、西洋入贡。 四年春正月丙戌，李善长罢，汪广洋为右丞相。丁亥，中山侯汤和为征西将军，江夏侯周德兴、德庆侯廖永忠副之，率舟师由瞿塘，颍川侯傅友德为征虏前将军，济宁侯顾时副之，率步骑由秦陇伐蜀。魏国公徐达练兵北平。戊子，卫国公邓愈督饷给征蜀军。庚寅，建郊庙于中都。丁未，诏设科取士，连举三年，嗣后三年一举。戊申，免山西旱灾田租。二月甲戌，幸中都。壬午，至自中都。元平章刘益以辽东降。是月，蠲太平、镇江、宁国田租。三月乙酉朔，始策试天下贡士，赐吴伯宗等进士及第、出身有差。乙巳，徙山后民万七千户屯北平。丁未，诚意伯刘基致仕。夏四月丙戌，傅友德克阶州，文、隆、绵三州相继下。五月，免江西、浙江秋粮。六月壬午，傅友德克汉州。辛卯，廖永忠克夔州。戊戌，明升将丁世贞破文州，守将硃显忠死之。癸卯，汤和至重庆，明升降。戊申，倭寇胶州。是月，徙山后民三万五千户于内地，又徙沙漠遗民三万二千户屯田北平。秋七月辛亥，徐达练兵山西。辛酉，傅友德下成都，四川平。乙丑，明升至京师，封归义侯。八月甲午，免中都、淮、扬及泰、滁、无为田租。己酉，振陕西饥。是月，高州海寇乱，通判王名善死之。九月庚戌朔，日有食之。冬十月丙申，征蜀师还。十一月丙辰，有事于圜丘。庚申，命官吏犯赃者罪勿贷。是月，免陕西、河南被灾田租。十二月，徐达还。是年，安南、浡泥、高丽、三佛齐、暹罗、日本、真腊入贡。 五年春正月癸丑，待制王祎使云南，诏谕元梁王把匝剌瓦尔密。祎至，不屈死。乙丑，徙陈理、明升于高丽。甲戌，魏国公徐达为征虏大将军，出雁门，趋和林，曹国公李文忠为左副将军，出应昌，宋国公冯胜为征西将军，取甘肃，征扩廓帖木儿。靖海侯吴祯督海运，饷辽东。卫国公邓愈为征南将军，江夏侯周德兴、江阴侯吴良副之，分道讨湖南、广西洞蛮。二月丙戌，安南陈叔明弑其主日熞自立，遣使入贡，却之。三月丁卯，都督佥事蓝玉败扩廓于土剌河。夏四月己卯，振济南、莱州饥。戊戌，始行乡饮酒礼。庚子，邓愈平散毛诸洞蛮。五月壬子，徐达及元兵战于岭北，败绩。是月，诏曰：“天下大定，礼仪风俗不可不正。诸遭乱为人奴隶者复为民。冻馁者里中富室假贷之，孤寡残疾者官养之，毋失所。乡党论齿，相见揖拜，毋违礼。婚姻毋论财。丧事称家有无，毋惑阴阳拘忌，停柩暴露。流民复业者各就丁力耕种，毋以旧田为限。僧道斋醮杂男女，恣饮食，有司严治之。闽、粤豪家毋阉人子为火者，犯者抵罪。”六月丙子，定宦官禁令。丁丑，定宫官女职之制。戊寅，冯胜克甘肃，追败元兵于瓜、沙州。癸巳，定六部职掌及岁终考绩法。壬寅，吴良平靖州蛮。甲辰，李文忠败元兵于阿鲁浑河，宣宁侯曹良臣战没。乙巳，作铁榜诫功臣。是月，振山东饥，免被灾郡县田租。秋七月丙辰，汤和及元兵战于断头山，败绩。八月丙申，吴良平五开、古州诸蛮。甲辰，元兵犯云内，同知黄理死之。九月戊午，周德兴平婪凤、安田诸蛮。冬十月丁酉，冯胜师还。是月，免应天、太平、镇江、宁国、广德田租。十一月辛酉，有事于圜丘。甲子，征南师还。壬申，纳哈出犯辽东。是月，召徐达、李文忠还。十二月甲戌，诏以农桑学校课有司。辛巳，命百官奏事启皇太子。庚子，邓愈为征西将军，征吐番。壬寅，贻元嗣君书。是年，琐里、占城、高丽、琉球、乌斯藏入贡。高丽贡使再至，谕自后三年一贡。 六年春正月甲寅，谪汪广洋为广东参政。二月乙未，谕暂罢科举，察举贤才。壬寅，命御史及按察使考察有司。三月癸卯朔，日有食之。颁《昭鉴录》，训诫诸王。戊申，太阅。壬子，徐达为征虏大将军，李文忠、冯胜、邓愈、汤和副之，备边山西、北平。甲子，指挥使于显为总兵官，备倭。夏四月己丑，令有司上山川险易图。六月壬午，盱眙献瑞麦，荐宗庙。壬辰，扩廓帖木儿遣兵攻雁门，指挥吴均击却之。是月，免北平、河间、河南、开封、延安、汾州被灾田租。秋七月壬寅，命户部稽渡江以来各省水旱灾伤分数，优恤之。壬子，胡惟庸为右丞相，八月乙亥，诏祀三皇及历代帝王。冬十月辛巳，召徐达、冯胜还。十一月壬子，扩廓帖木儿犯大同，徐达遣将击败之，达仍留镇。甲子，遣兵部尚书刘仁振真定饥。丙寅，冬至，帝不豫，改卜郊。闰月乙亥，录故功臣子孙未嗣者二百九人。壬午，有事于圜丘。庚寅，颁定《大明律》。是年，暹罗、高丽、占城、真腊、三佛齐入贡。命安南陈叔明权知国事。 七年春正月甲戌，都督佥事王简、王诚、平章李伯升屯田河南、山东、北平。靖海侯吴祯为总兵官，都督于显副之，巡海捕倭。二月丁酉朔，日有食之。戊午，修曲阜孔子庙，设孔、颜、孟三氏学。是月，平阳、太原、汾州、历城、汲县旱蝗，并免租税。夏四月己亥，都督蓝玉败元兵于白酒泉，遂拔兴和。壬寅，金吾指挥陆龄讨永、道诸州蛮，平之。五月丙子，免真定等四十二祎府州县被灾田租。辛巳，振苏州饥民三十万户。癸巳，减苏、松、嘉、湖极重田租之半。六月，陕西平凉、延安、靖宁、鄜州雨雹，山西、山东、北平、河南蝗，并蠲田租。秋七月甲子，李文忠破元兵于大宁、高州。壬申，倭寇登、莱。八月甲午朔，祀历代帝王庙。辛丑，诏军士阵殁父母妻子不能自存者，官为存养。百姓避兵离散或客死，遗老幼，并资遣还。远宦卒官，妻子不能归者，有司给舟车资送。庚申，振河间、广平、顺德、真定饥，蠲租税。九月丁丑，遣崇礼侯买的里八剌归，遗元嗣君书。冬十一月壬戌，纳哈出犯辽阳，千户吴寿击走之。辛未，有事于圜丘。十二月戊戌，召邓愈、汤和还。是年，阿难功德国、暹罗、琉球、三佛齐、乌斯藏、撒里、畏兀儿入贡。 八年春正月辛未，增祀鸡笼山功臣庙一百八人。癸酉，命有司察穷民无告者，给屋舍衣食。辛巳，邓愈、汤和等十三人屯戍北平、陕西、河南。丁亥，诏天下立社学。是月，河决开封，发民夫塞之。二月甲午，宥杂犯死罪以下及官犯私罪者，谪凤阳输作屯种赎罪。癸丑，耕耤田。召徐达、李文忠、冯胜还，傅友德等留镇北平。三月辛酉，立钞法。辛巳，罢宝源局铸钱。]]></content>
      <tags>
        <tag>历史</tag>
        <tag>文学</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[敦煌游记]]></title>
    <url>%2F2017%2F04%2F25%2F%E6%95%A6%E7%85%8C%E6%B8%B8%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[三月份，我法发现去敦煌非常实惠，于是招贤纳士，最终克服重重阻碍，确定4月19日前往兰州，20日晚从兰州前往敦煌，4月21日和22日在敦煌游览两天并在23日前往嘉峪关，23日晚从嘉峪关到兰州，并于24日晚从兰州返程。 D1 兰州早上醒来法同学已经来到了我们住的太空舱旅馆（神了怎么找到的），给我们带来了兰州特色的醪糟和包子。退房后我们来到兰州站寄存行李。寄存行李是火车站最为实用的功能了，我之前都不知道，往往会浪费很多精力在背负行李上。在法同学的带领下我们打算前往参观黄河景观带。不得不说兰州的交通真是很差，大多数路是双向四车道，而且红绿灯大多数只有两个灯，因此从非机动车道左转过十字路口很难，甚至直行过马路也不容易，好几次绿灯过马路右拐车还加速的。加上兰州本身是一座挣扎在河谷中的城市，南北发展受到非常大的限制，感觉交通实在需要加强！到了兰州必须得吃牛肉面，兰州管牛肉面叫牛大，外面的兰州拉面大多数是青海人开的。临近中午我们骑到位于大众巷的一家马子禄牛肉面。马子禄牛肉面是兰州非常正宗的一块牌子，我们吃的家更为特殊，过了下午两点就不开了。进了这家店确实奇怪，没有洗手间，没有免费餐巾纸，我们吃得满嘴是油还擦不了很尴尬。店门外一位流浪汉一直在逛来逛去，后来发现他在店里领了一碗面坐到对面台阶上心满意足地吃了起来。兰州是唯一被黄河横穿的省会（济南为啥不算啊）城市。从马子禄出来走不了多远就到了黄河边上。说起黄河，不得不提《黄河钢琴协奏曲》，黄河钢协有四个乐章《黄河船夫曲》、《黄河颂》、《黄河愤》、《保卫黄河》组成，其中我最喜欢的是第二乐章《黄河颂》。《黄河颂》讲述的是我们先辈在这片土地上辛勤劳动、保家卫国、艰苦卓绝、生生不息的民族气节。乐章采用大提琴奏出引子，低沉而宏伟的旋律是黄河宛转曲折、奔流不息的浩荡。由钢琴奏出的主题铿锵有力，壮美而深情，充满着华夏儿女对脚下这片土地的热爱。接着我们来到了兰州著名的黄河铁桥。这座桥已经有一百多年的历史了，造型很像上海的外白渡桥。我们在桥首拍完照片，法同学就回去考试了，我们继续游玩桥对岸的白塔山公园。从白塔山下来我们坐的是黄河索道，这索道挺老的，每经过塔柱时都要晃一晃，然后我的心也晃一晃，跨黄河时我们看到下面的羊皮筏子，感觉挺有意思的，于是下了索道就去问价钱，一问不得了，一个人80块，那人还追着我们半天，价钱砍到60块单程才罢休。最后我们一路西进，在上游一个地方人家60块羊皮筏子去快艇回，感觉很棒，便真正体验了一下黄河船夫的生活。不过真正上了筏子可不像曲子里面那么豪迈啦。法第一个上了筏子，一脚踏在洞里面，鞋光荣地湿了。到了河心，一趟快艇驶来，心里暗道不好，果不其然，妈的下面全湿透了。羊皮筏子顺流而下把我们带到离中山桥不远的一处石矶上，没多久快艇来了。快艇相比我们在厦门的那次环鼓浪屿要逊色很多了，但是还是挺爽的。我们在码头的凉棚里面歇了会，这时候裤子也干了，但是我法的鞋子依然湿漉漉的，做为能给我法提鞋的人，我帮法晒了鞋子，大家都很羡慕。我们顺便定了敦煌第二天的跟团游。在逛完黄河母亲像后已经是四点了，我们准备骑酷骑去火车站前往敦煌，却正好碰上他们服务器宕机，整个街上没一辆车能扫码打开。试图转而骑小黄，所及之处小黄三五辆已不算少，然而要么轮胎没气，要么号码被涂，更有胜者遇到一辆内胎被拽出，脚蹬子也少了一只。当时已经是四点十分，路上已经开始堵车了，我们变得十分着急，最后还是法提出还是乘公交车吧，我们一咬牙还是同意了。路上看到甘肃省政府位于酒泉路和张掖路的交叉口，感觉很有深意，张掖称甘州，酒泉称肃州，两者合起来便是甘肃省的由来，非常有底蕴。到了车站已是五点，我们打算去吃开封菜，排队一看，妈的最便宜的汉堡套餐要48块，心想算了，正好旁边有一家德克士，一个汉堡16块钱，勉强吃得起。顺便去火车站的超市买明天的早饭，我们去敦煌的火车叫Y667，没错，Y代表游，这是一趟旅游列车，叫敦煌号。火车的过道上都是铺的地毯，卧铺的墙壁上有敦煌的景点介绍。不过设备虽然好，我们车票却定晚了，余票14的时候定的，果断一车厢全是上铺。出了兰州很快进入河西走廊，火车上播放敦煌的介绍和各种歌曲，往北看可以看到丹霞地貌。河西走廊分隔青藏高原和蒙古高原，狭窄的地方仅有几千米。这种大自然的鬼斧神工只有身临其境才能感受得到。没过一会儿，东哥说他的手机不见了，我们慌乱找了一会还是没找到，于是喊了乘警。不过其实我是不慌的，毕竟我们车厢大部分都是单位组织从上海过来的游客，他们是没道理偷一部华为手机的。过了会找到了，原来夹在作业本里，当时这位准清华学子还在疯狂学习。七点三十七分左右，在出了一段非常长的隧道后，我们第一次看到了远处的祁连雪山。祁连山又叫南山，在河西走廊的西南面。接近八点时天已经暗了下来，车厢中广播在8车的酒吧（没错居然有酒吧）有舞蹈表演。走了过去，发现居然不要买东西就能坐下，大受感动点了一瓶黑啤78块。拿到手发现这拉环咋拉不开，东哥还为此英勇负伤，最后我法又一次显示其“法力无边”，用餐巾纸把拉环按下去了，我们又一次体会到“有法可依”的重要性。灯熄了后，大家睡觉，迷迷糊糊中听到卓林在问我要餐巾纸，第二天早上起来才知道气候太干，他流鼻血了。 D2 敦煌第一次遇到火车早点，提前20分钟抵达敦煌站。六点二十我们出站，正好看到敦煌的日出。敦煌，敦者大也，煌者盛也。敦煌是汉武帝设立的河西四郡凉甘肃沙中的沙州，位于河西走廊的最西段，是中国的旱极。莫高窟位于三危山的岩壁上，据传有一个叫乐尊的和尚到敦煌，在傍晚太阳要落山时看到三危山的岩壁上光芒万丈，乐尊和尚觉得这是佛光，是佛祖在显灵，于是在三危山上开凿了第一个洞窟，在洞窟中坐禅修行。从北魏开始，统治者迷信佛教，莫高窟开始快速发展。我对莫高窟的最初了解并不是语文课本，而是来自于徐迟先生的报告文学《祁连山下》。莫高窟是神圣的，但是我觉得这神圣的从来都不是什么菩萨或是神仙，而是人。常书鸿放弃了在法国优越的生活条件和工作环境，甚至牺牲了家庭，毅然决然回国来到条件极其艰苦的敦煌，在敦煌过着他的“。无期徒刑”进入莫高窟，讲解员为我们发放了专门的耳麦，进入后我们跟随自己的讲解员参观了10个洞窟，我们仅在每个洞窟停留两分钟左右。我们分别参观了094/096/100/148/244/251/259/335/16/17窟。最后我们又跟着另一个导游看了71窟，然而人太多，我们又没有耳麦，所以最后还是放弃了。094窟在清代被翻新过，并且前面还加了一座道士的塑像，据说这和当年驻守这里的王道士有关，这个窟和下面看到的窟不太一样，它不是传统的中心塔柱形式，缺少中间的柱子，将天花板的重量分到四面墙上。讲解员说别看这里空间看起来很小，到了旺季这里容纳200人并不为过。地下的砖头据说是西夏时期的原砖头，讲解员说另有凹下去的是后期仿制的。096窟即九层楼，里面是莫高窟第一大佛像，中国第三大佛像（第一大是乐山大佛），中国第一大室内佛像。原来只有七层楼，后来为了整个盖住佛像，修了九层。据讲解员说，每年四月初八，莫高窟都会开放石窟内的围栏，敦煌的市民能够绕着柱子转一圈。为了方便行走，在这个佛的座下修了两个正方形的孔以透光。100窟是一个家族窟，属于当时驻守这里的曹家，进了甬道之后可以发现两边有很多女子的画像，前三位衣着黑色（不知道是被氧化了还是就这样）分别是回鹘国的公主和嫁到回鹘国的女儿，到了第四个女子才是家族的女主人。讲解员说到这么做是为了体现对他国的尊重，当时曹家镇守敦煌，远离京城，有能力自立为王，但是却能够镇守这里150年，并和周边搞好关系，让人十分敬佩。讲解员说莫高窟中的大多数窟都是敞开的，墙和铝合金门都是建国后后加上去的。但是这个窟在平时都设有木门封闭，曹家有专门的人看守，只有到了家中重大事情发生时才会开启。148窟里面有一座卧佛，画的是释迦摩尼圆寂时的场景。释迦摩尼身边有72位徒弟，面部表情又哭又笑，和修为深浅有关。讲解员说这些徒弟是清代加上的，是仿照孔子门下七十二仙人所作。讲解员指向我们身后的墙，我发现上面有很多乱涂乱画的内容，如“信士XXX一家XXX”的。除了这些乱涂乱画，墙上还有一些黑色的矩形方块，讲解员说这里原先写着画中人物的名字，但是由于时间太久，画中的字已经看不清了。244窟建于隋代，在左中右有三座佛雕像，分别是过去佛、现在佛和未来佛。这里的佛像已经更接近于唐朝，而不是隋朝流行的头大肚圆造型。作为装饰的飞天也由V字形逐渐变成一字形。251窟开凿于北魏时期，这个窟和我们之前见到的窟有很大的差异，首先它是中心塔柱式的，但是在窟的前部是人字顶，并且正对着窟内的佛像有一道明窗（现在已经被封了），当太阳升起时会照到佛的脸上。这里的佛像和之前看到的也不一样，衣着要朴素地多，并且穹顶上也不是各种小佛像，而是三个点和一个圈。259窟建于北魏，特点是双佛同坐，据法华经记载，多宝佛说如果有人讲法华经能比自己讲得好，就会给他一座宝塔，于是当释迦摩尼讲法华经时，地上凭空出现一座宝塔，多宝佛显圣和释迦摩尼一同讲经。塑像的手大多数都没了，露出了用来作为框架的木头。335窟是一副经变图。经变指的是将经中的内容通过画表现出来。此窟主要表现的是维摩诘和文殊菩萨辩法经变。传说维摩诘是个特别吊的神仙，他虽然是佛教中人，但是却花天酒地，纸醉金迷，简直浪翻了。偏偏此人佛法高深，别人论辩法都辩不过他，于是大家对他敬而远之。维摩诘不爽了，他想和别人辩法虐别人，于是托病在家，由于他很有声望，于是大家都得来看他。文殊菩萨来了，一眼就看出他在装病。于是指出了这点，可是维摩诘不以为然，他说不是自己病了，而是他看到天下人仍然生活不甚幸福，心中烦忧。在壁画的下面两角，中国的皇帝和番邦的皇帝都来看两人斗法。16/17窟即王道士的藏经洞。17窟其实很小，里面放着一尊真人像，后面画上是一株菩提树，树上挂着一直单肩包，很有现代风味。那位高僧就在树下打禅。据说宋代人们把这幅塑像移开，在这里面塞进了四万本经书。后来这个洞窟被风沙所埋藏，一直到王道士清理泥沙时才发现（至今墙上还有当年被风沙覆盖位置的一道道斜痕迹）。看完莫高窟，我们乘坐公交车前往敦煌市区。我们在沙洲夜市下车，准备前往位于党河边的旅社。中途我们吃了敦煌著名的驴肉黄面，驴肉黄面是拌面，口味并不突出，感觉驴肉和牛肉口感差不多。由于甘肃普遍不习惯使用支付宝和微信，我们的现金很快用完了，于是我和法去取钱，居然还要收手续费。下午一觉睡到四点出门准备前往鸣沙山，等了半天三路车放弃了，旁边的敦煌公共自行车也扫不开，最后分两辆滴滴过去。敦煌的司机特别热心，还喜欢给我们名片。鸣沙山被看做库木塔格沙漠的最东段。鸣沙山的门票十分便宜，我们的半价票只需要30块，但是里面项目一点不便宜，骑骆驼100块，带你去鸣沙山走一圈，最后到月牙泉附近下；越野摩托有三种线路，最便宜的120块，你可以自己开到山上，再由那边师傅带你下来。越野摩托附近有直升机和滑翔机体验项目，我们囊中羞涩，直接放弃了，晚上出园时我看了一下价格，乘坐滑翔机要480块，直升机1280块，还是最便宜的，真是吓人。虽然骑骆驼时间比较长，要40分钟左右，但是因为能够直接到月牙泉，我们听从东哥的建议，放弃了越野摩托，骑了骆驼。骆驼一队整好五人，但老板不肯把我们凑到一队，所以我们拆成两队，我和法一队。驼队有一个师傅在前面步行牵着沿着鸣沙山走。中途师傅向我们每人收取20元帮我们拍摄照片，他放下缰绳，教我用脚踹骆驼，让骆驼往前走，可是每次我踹骆驼总是爱理不理的，非常懒。倒是我后面法骑得骆驼像劳模一般，总想着超车。骑完骆驼我们脱掉鞋子，奔跑着去看月牙泉，从热气蒸腾的沙漠中走到月牙泉边，温度突然就变化了。滑沙费用15元，非常有意思，有点像漂流，但是速度要略快，而且中间不会有起伏。我们首先顺着竹梯爬到山腰指定地点（好难受，踩沙子踩不稳，踩竹梯又磨脚），然后那边人员将一块长方形略带有弧度的筏子背了上来，我们坐在上面，双脚分开顶住木筏前端，双手抓紧，工作人员就把你给推下去了。筏子很快加速到一个最大速度，只感觉风在耳边嗖嗖飞过，有一种喘不过气的感觉。到了接近山脚的时候，坡度渐渐变缓，筏子速度减慢并停下。我是最后一个滑的，还算成功，东哥非常悲惨，他的筏子一开始就偏离航线了，虽然试图用脚控制，但是由于失去了一开始的加速机会，很不过瘾。敦煌的日落比兰州还要晚半个小时，到八点半太阳才下山，感觉敦煌真是一个适合学习的地方，最适合我们这种晚上不睡早上不起的人。日落后，法提出大家一起去看上灯了的月牙泉，并比赛微信运动里面的步数。大家像傻逼一样在月牙泉边的栈道上原地踏步走来走去，我们发现沙漠中的温度电话非常敏感，我们在栈道上经过一个路灯都能发现那边的温度明显比这边要低。从月牙泉回来的时候，天色已黑，我们发现找不到回去的路了，遂穿沙而过。沙地上分布着骆驼屎，我们必须小心翼翼走一些被踩硬的地方才能避免沙子进鞋里面以及踩到骆驼屎。到门口发现没车了，联系之前给名片的司机，说自己不方便。最后我们在景区门口挤了一辆黑车去了敦煌夜市，司机满不情愿的收了我们的讲价，说要是被警察查到超载，自己实际上就亏了。到了敦煌夜市准备吃饭，刚走进去两步就被一群热心的民族同胞拦住了要我们吃饭，摆脱之后我们打算到别的地方。在找了一家火锅（很贵）后，我们最后去了一家川菜馆。法显得很不高兴（不能吃辣），偏偏我们点了都是辣的菜。 D3 敦煌西线在兰州时在携程上报了今天的团，早上九点半车来接我们，司机大伯开起来五六十岁的样子，等到市区晃完一圈接完客，他停车起来自我介绍，他叫老马班长，经营这条旅游线路已有十余年，这十年里他一人身兼司机、导游、“保姆”数职，自我要求要打造“航空品质”的旅游服务。事实也证明，他的团在充实度、舒适度、趣味性各方面都非常好。一路上老马班长给我们普及历史，先从莫高窟介绍起，莫高窟得名有两重意思，第一取“漠高”之意，表示在沙漠中建在高处的窟，第二重指天地间没有比佛祖更高大的形象。没过多久到了第一个景点，敦煌古城。这个景点其实挺没意思的，就是一个影视基地，什么天将雄狮神探狄仁杰啥的都在这拍过。讲解员讲解的超级不负责，直接就去念门上的对联。影视城有体验射箭的地方，10块钱10箭。这时候法又很吊了，第一箭直接八环，第二箭稍差，但也没有脱靶。我们其余的四个人就比较惨了，除了东哥还中一箭，其他人人脱靶，卓林还秒射，笑死了。到了西千佛洞老马班长与我们约定参观40分钟，因为西千佛洞的规模比较小，并且一次只能进15人，我们感觉进去的希望不大，但是我还是坚持大家去买票参观，果然最后讲解员带着我们浩浩荡荡的“15”人参观团进入窟区了，其实中间还有个小插曲，东嫂拿着票四处走动时成功把票根搞丢了，最后只好拿着小小的一张副券进门，还好讲解员没怎么阻拦。西千佛洞比莫高窟还要早，它和莫高窟的都有在原画上重画的情况，但是莫高窟会先在原画上敷上一层泥再重新画，但是西千佛洞直接重新画了，在某些窟中能够看到下层壁画的颜料。讲解员补充道对于这样的壁画是很难复原得到下面一层的壁画的。听了讲解员的讲解我才知道在莫高窟看到的西魏的天花板周围不断出现的黑色的三个点和一个圈实际上是莲花的造型，只是因为有些颜料经过长时间的氧化已经变得稀薄，唯独这三个点和一个圈仍然“健在”。讲解员用手电筒照了点和圈之间的部分，果然我们能够看到水印一样的东西，讲解员说过几年这个水印也看不到了。我们参观了8/9/11/6/7五个洞窟。6号窟和7号窟也是连在一起的，6号窟中我们看到了两块哈达，6号窟进门左手边的7号窟里面什么都没有，据说是打坐修禅用的。在某个窟中我们还看到一座尚未修完的塑像。第11窟的壁画中出现一副被称作“东方的蒙娜丽莎”的女子，讲解员用手电筒从上方和下方分别打灯，可以看到“蒙娜丽莎”会出现时隐时现的双下巴，时而像一位害羞的少女，时而像一位安静的夫人。隋朝的历史虽然短小，但是却留下了非常多的洞窟。隋代的洞窟，工匠们已经开始大胆地给塑像的人物穿上华丽的衣服了。辨别隋代的窟也很简单，其穹顶的佛有四种，沿对角线的佛都是一样的。值得一提的是西千佛洞中已经体现出伊斯兰文化的影响了，在一个洞窟中，佛身后的宝座采用的伊斯兰清真寺穹顶的造型。在莫高窟中更有道士形象出现。其实中华文明自古以来就是宽容、博采众长、兼容并蓄的，反之一个固执的、不愿意接纳外物、融入现代社会的“文明”是不可能长久的存在的。出了西千佛洞，我们继续向西，穿过一片大漠，到达南湖乡。老马班长说这是仅次于敦煌市区的第二片绿洲，也是出敦煌以后的最后一片绿洲，而前方便是罗布泊和塔克拉玛干大沙漠。要到南湖乡的路上，司机提醒我们右边即将路过西游记中猪八戒被收服的高老庄。在南湖乡老马班长组织我们吃了农家乐，每人35块，九菜一汤，其中包括新疆大盘鸡、羊肉和南湖鱼。据说南湖鱼是由祁连山上的雪水供养的，肉质非常鲜嫩可口，不过实际吃来其实一般，倒是他们的番茄汤一点汤都没有，和我们的番茄炒蛋一模一样。和我们一桌的是一群上海过来的老人，其中一个我印象特别深，不仅仅是他一直在说的上海话，而且之前在西千佛洞时他为了不误老马班长设定的时间，没有参观最后一窟，直接翻闸门跑回去了。饭桌上他说他是1949年生人，我不禁为他身手之矫捷赞叹。他们从上海坐火车两天两夜过来（据说是有个人坐不了飞机），准备接着去玩新疆。从农家乐出来走没多远就是阳关，老马班长介绍说我们现在常说的“关照”就是来源于阳关通关的关照，类似于现在的护照和签证一样，有了它就可以走出国门，（然而几天后碰巧在知乎上看到，其实关照这个词是明朝才有的，指的是“通嘉峪关口照会”。一进入阳关，便是一尊张骞铜像。阳关有专门的讲解员带领我们参观阳关博物馆，博物馆中陈列着一些青铜器铁器等文物，记录着仰观昔日的辉煌。出了博物馆再往前，经过一些仿古建筑和兵营，便到了阳关都尉府，这里卖所谓的阳关通关文牒，游客们先手写一封“敦煌阳关都尉府关照申报书”（不让你拍照带走），然后由穿着官袍的官爷为你写一个通关文牒，讲道理还是挺有纪念意义的。劝君更进一杯酒，西出阳关无故人。出了阳关都尉府后，大家都装着不认识对方。不过马上就要去阳关烽燧了，一共有三种方式，骆驼、驴车和电瓶车，其中电瓶车是不要付钱的，断选择的电瓶车。在阳关烽燧上极目远眺，一片雪山矗立眼前，便是甘肃和新疆的界山阿尔金山。在阳关往玉门关的车上，老马班长提醒我们注意看前方，只见公路左侧是一片绿洲，绿洲前面有一汪水塘，水塘上甚至还有游船的倒影，老马班长说这就是海市蜃楼，他又领着我们看向公路的尽头，那里湿漉漉的，宛若刚下过雨，还泛着光，那也是海市蜃楼。老马班长说等到七月沙漠里变热后，这种现象会更加明显。回想起在阳关时，我在阳关烽燧后的塔亭上往西远眺，能看到一片绿洲外有一汪水像极了月牙泉，当时没在意，估计那也是海市蜃楼吧。那位上海老人听到海市蜃楼，立马跑到车辆最前方副驾驶座位拍摄，感觉非常可爱。玉门关和汉长城相距不远，可能由于地处无人区，并没有像阳关那样建立了博物馆、观景台等设施。“明月出天山，苍茫云海间。长风几万里，吹度玉门关。”玉门关在古时候是商旅通行的要道，古时候这里甚至还有水源，但后来水源枯竭了，现在玉门关所在地是一片戈壁保护区，我们只能沿着划定的路线参观（跨越围栏罚款500）。玉门关又称为小方盘城，据说从前西域和田地区的人在朝见汉武帝的路途中来到这里后生了重病，问了当地人后，在这城上献上美玉，第二天果然病都好了，于是后来人路过这里都要往城墙上献上几块美玉，所以玉门关得名。参观完玉门关差不多五点半了，老马班长有点着急，我们得赶六点半到雅丹坐最后一班车。于是我们匆匆赶到汉长城。汉长城其实很是简单，感觉像是一个个沙包叠起来的，倒是那边有个老马班长说的“五星级厕所”，让我们一定得上一上。进去一看其实挺普通的，倒是有很多是卖东西的。参观完汉长城时间已经不早了，一路向西前往敦煌雅丹。在路上我们跨过了疏勒河大桥，然而桥下并没有任何水。疏勒河是中国少有的从东往西流淌的河，敦煌的母亲河党河是它的一条分支。手机很快陷入了无服务状态，老马班长告诉我们我们左手边是我国导弹的一个靶场，某次演习时甚至可以看到导弹的拦截，亮如白昼，而右手边是河西走廊北山之一的马鬃山，他将一直伴随我们直到雅丹。过了一会儿左边出现了第二尊卧佛，它是由几座山组成的，随着汽车的不断移动，卧佛的体态越来越明显。最激动的一刻莫过于看到北面的马鬃山余脉渐渐消失，最终汇入一片大漠之中，此时打开地图，发现自己身处甘肃和新疆的边界处，河西走廊走到了尽头，老马班长告诉我们罗布泊就在前方。罗布泊是一个神秘的地方，据传外星人在这里建有基地，自从上世纪科学家彭加木在这里失踪后，更有传说甚嚣尘上。敦煌雅丹位于罗布泊的风口，俗称魔鬼城，而雅丹这个名字源自维吾尔语里面的亚尔当，据说这里磁场非常强烈，人容易迷失方向，前些年一个安徽学生打算横穿雅丹时迷失方向，虽然最后拨通报警电话，但仍不幸身亡，从此景区禁止进入木牌之后的区域。一路上我们手机都在无服务状态，到了景区瞬间4G满格，朋友们纷纷想发一张在罗布泊的定位，我也打开微信，可惜上面明明白白还是酒泉市。老马班长说看完阳关是一个小土堆，看完玉门关是一个大土堆，看完雅丹是一个土堆接着一个土堆。这句话的意思是雅丹地貌是风的杰作，而在世界的很多地方都有这样的地貌，都称为雅丹。敦煌雅丹比较独特的是这里的沙漠是黑色的，但是被风侵蚀的石头却是黄色的。到了景点我们赶上了景区的最后一趟电瓶车，应该是有赚钱和是怕你下来瞎走。不过我在车上看到一个赴新疆车辆检查站，难道这条路还是可以供自驾游走的。观光车经过一个由两个石柱组成的大门，讲解员说过了这个门，就意味着进入了荒无人烟的新疆罗布泊地界，而一段艰苦的旅程就即将开始了。我们的第一个景点是金狮迎宾，下了车讲解员告诉我们不能走过景点牌子后面，所以其实我们只能简单地逛一逛拍个照就上车了。第二个绩点狮身人面也是这样。到了第三个景点孔雀回眸，随车讲解员告诉我们可以乘坐越野车去雅丹未开发的南区游玩，那里有雅丹的制高点，可以观看全景，不过吉普车太贵了，而且只能坐4个人。这个节点我们终于可以往里面走走了，我们顺着沙地上护绳围住的通道往里走，很快到了脚下。这是一块在一个浅坑中送立的巨石，犹如一只优雅傲立的孔雀。我们在最后一个景点西海舰队（舰队出海）是已是邻近落日，我们在马路上拍了很多照片，此时我心里就萌生了一个想法，好希望能够去马路的另一端，罗布泊，以至更深的新疆去探索一下啊，那里一定有更奇特的风景！观看落日，这应该是雅丹之行最美丽的风光了。敦煌雅丹的日落从八点左右开始，天空被一片红霞笼罩。西北是干燥的，西面的天空被一层薄薄的云笼罩，被染成金红一片，却丝毫阻碍不了太阳最后的光芒。从雅丹回来后，老马班长已经为我们准备了晚饭，有面包牛奶火腿肠酱蛋之类的东西，让我回想起之前打ACM现场赛的日子。最后一站，老马班长将车开到无人区，我们夜观星象。不同于我的想象，夜空中并没有出现绚烂的银河，但是星星却是十分明亮。当晚正值流星雨，西方天空有一道道流星划过，不过它们不一定都是流星，也可能是飞掠而过的人造卫星。仰望天空，七颗星星组成勺子形状，这就是北斗七星，北斗七星位于大熊座，其实非常好观测，因为七颗星星的亮度十分相似。猎户座是冬天天空最耀眼的星座，我们的时候刚从天边升上来一半，顺着猎户座，很容易找到冬季大三角，也就是参宿四、天狼星、南河三组成的等边三角形，这也是我在家中唯一能够辨认的星星。顺着大三角向上看可以看到双子座，顺着双子座所在的黄道继续往上，可以发现我的狮子座。由狮子座逆时针转九十度，在天空的中部，有一颗星非常耀眼，它就是大角星，其实我非常奇怪，毕竟天狼星是天空第一亮恒星，但是大角星明显比它亮很多，即使老马班长开始指出的火星甚至都没有天狼星亮。从大角星继续逆时针转，到星空的另一面，可以看到织女星和天津四，然而牛郎星还没有升上来（还是已经落下去了？），于是夏季大三角并没有看到。我们试图用手机拍下星空的照片，可一直是黑乎乎的一片，老马班长说得用单反+三脚架进行长时间的曝光才行，但是我们只有一个数码相机。最后机智的法将数码相机放到地上往上拍，终于拍到了清晰的照片。最后在车上，那位可爱的老人和我们合了影，他说最喜欢看我们年轻人，这让他感到特别有活力。晚上卓林又开始流鼻血，他一宿没睡，把晚上在车上看的《继父》电视剧看完了。第二天他和我们诉苦，说自己不适合在西北生活，到贵州就不会流鼻血了（真的么？）。 D4 嘉峪关早上九点我们告别敦煌，乘坐K369到达嘉峪关市。由于买的是硬座，加上昨天浪了一天，我们本来以为是艰苦的行军，没想到车上人特别的少，以至于我们一个人躺在三连排的硬座上狠狠地睡了一觉。到了站，法钦点去天下第一墩，关城由于只能买通票有点浪费，所以我们打算就在外面看看。嘉峪关的旅游氛围明显比不上敦煌了，门口的出租车都透露着一股黑车载客的样子。于是我们选择滴滴（等了好久），而东哥情侣组打了出租车，往天下第一墩进发。在车上东哥打电话说长城第一墩不出售单独票，必须买160的通票，大家很疑惑，不过也只能叫他买。到了景区发现先出发的东哥不在，而且售票处分明注明票价21元优惠票11元（原来四舍五入是这么算的），通票120元，东哥是走错了吧。打电话扯了半天，最后定位一看，东哥确实错了（估计是被司机坑了），于是东哥很绝望地又打车过来。到了嘉峪关的一路上祁连山一直在我们的身边，但是只有进了景区才真正感受到祁连山的雄姿，据说从这里去祁连山需要4个小时，爬山需要2个小时。这个景区其实说是天下第一墩，但是我们完全被一道深深的峡谷吸引住了注意力。下了观光车，可以走进一个依壁雕凿（确实是建在峡谷两侧的峭壁里面的）的地下展厅，里面主要介绍了嘉峪关地理地貌的起源，各地的长城，我看到一个外国人从嘉峪关顺着长城一直走到山海关，还有一个滑索，可惜并没有开放。地下展厅的最里面往外伸出一个玻璃地板观景平台，这张照片也是在那里拍摄的，站在玻璃板上其实还挺吓人的，不过很快我们就发现了更刺激的，也就是图上的那道悬索桥。走悬索桥要先从观景平台回到地下展厅，然后反方向走很远绕过去。我们于是往悬索桥走，路上顺便可以拍长城第一墩的照片。第一墩也有一个一个滑山的地方，居然要收30块。我们拍会车照片耽搁了一会儿，东哥已经下到峡谷了。我们从一段阶梯走下峡谷，我们的右侧是一片兵营，里面有红衣大炮，往左侧沿着路走就到了悬索桥了，如果再往前走还可以走下峡谷，不过却被拦了起来，禁止我们翻越。上了铁索桥看河谷两岸风光，可能是春季的原因吧，水量不是很充沛，但是水却是非常地清澈。走过悬索桥，东哥已经不见踪影。原来是顺着土坡爬到了前面的高地上。我们顺着坡爬上去，上面很是荒芜，到处是各种硌脚的碎石与拦路的大石块。又走了一段，我们觉得还是从悬索桥回来比较靠谱，卓林一听脸又绿了，这小子原来恐高啊。这下大家又可以整卓林了，东哥故意在铁索桥上来回跺脚，卓林铁青着脸强行装不怕，然而腿已经在抖了，于是我和东哥便不再继续搞他。出了第一墩，东哥过来的两辆车准备把我们拉到关城外面拍拍照片，到了关城，司机说有个北门可以带我们进去一道关卡，在里面可以看到关城的城墙，也就是第二道关卡。可是到了那里保安说现在太晚了，这个门已经不开了，于是我们简单地一起拍了张照片就走了，也是蛮遗憾的。我们请司机帮我们拉到了嘉峪关的老城区，这一趟下来连等带走花了一部车60块。晚上在附近的夜市里一个叫小党烧烤的地方吃了烤串，上烧烤时各种短斤少两，由于我们串串都是平分的，所以立刻被发现。餐桌上我们和法比党性，法很生气，说我们的认识是错误的，我们是坏的群众，我非常生气，实践才是检验真理的唯一标准，为什么这么说我们。吃完临走时服务员拿着纸巾盒让我也顺便带走。出了烧烤店，路过一家名叫“周六黑鸭”的烤鸭店，我们找到了一直想喝的杏皮水。昨天老马班长提到这里的杏子称为李广杏，是李广将军从中原带来栽种的，像蜜糖一样甜，当地老百姓非常感谢李广将军，便把它叫做李广杏。卖完杏皮水还没喝，肚子开始痛了，慌忙找了商城下面的一家开封菜去“蹲黄”，不仅很钦佩20分钟前烧烤店服务员的未雨绸缪，让我带走餐巾纸。坐嘉峪关的公交车到了火车站，终于可以喝杏皮水了，感觉酸酸甜甜的，有点像酸梅汤，但是香气会更浓一点。大家相继蹲完之后时间也不早了，上了公交车直抵火车站。 D5 兰州昨夜我们乘坐T6602前往兰州，这辆车比来的Y667敦煌号要难受好多，晚上先是特别热，夜里又被冻醒，下了车一个2车软卧的乘客说软卧特别冷，他已经去投诉了。到了兰州大家都特别不舒服，果断去锦江之星开了一间钟点房，六个人洗了一轮澡。差不多呆到中午了，法的同学也来了。他带我们到兰州的“王府井”去吃那里的鸭爪干锅。这家鸭爪干锅挺有意思的，首先是鸭爪和鸭翅一起做的干锅，分量还挺大的，吃完之后锅子收走还可以当成火锅继续吃，有点像我们这里龙虾的烧法。吃完鸭爪干锅，大家准备去兰州一家著名的咖啡店“放哈”咖啡店喝茶。“放哈”是兰州有名的咖啡店，原来叫“放下”，因为商标保管不力，被别人侵权了，遂改名兰州话“放哈”。我点了一杯大杯甜胚子柠檬茶11元，拿到手瞬间被它的剂量震撼了，这何止是杯，我看得叫桶了吧！从放哈出来，大家准备去水车园，我们兵分两路，我和法、法同学一起骑车过去，路上我们经过一条路名叫读者大道，猛然想起这本著名的杂志总部也就是在兰州。到了水车园，看到东哥他们早已到达（卧槽一路堵成这样还早到），东哥很是着急，书包又掉了，据他回忆，很可能是掉在之前的放哈咖啡店里面，我们打美团上的电话给店里面，回复说没有。大家都很焦急，想一起回去找店家。这时候法挺身而出说这是放心，交给我。法在法律知识和维权意识上确实非常强，我们都很信任他，于是他带着东哥和他女票去了放哈咖啡（叫我看看有啥水车的纪念品）。与此同时，法的同学也没有闲着，她在微博上发了一条寻物启事，并at了店主。没多久她兴奋地说店主回复了，确实有个包在店里面。过了一会儿我们打电话和确认。出水车园的时候发现一家纪念品店，便和法一起去，一看小水车都要两百多块，法想想还是不买了。兰州机场离市区特别远，据说是离市区最远的机场了，有C字头的高铁从兰州站过去，于是我们机智的买了高铁票过去。过安检的时候法被拦了下来，说买的啥水晶球里面有煤油，不能携带，也不能托运。可怜的法只好花了30块又寄了回去，虽然他买的水晶球才值20块。我们乘坐的ZH9584是个经停西安的飞机波音737，一路上颠得要死。我们0:40才到南京机场，那时候机场大巴只有城东线了，城东线到终点站南京站已经是两点了。东哥和他女朋友就很机智地去开房了，法也机智地订了个青旅。我本来是想带卓林回去挤我租的房子的，不过后来听法说这么晚会宿舍也不好，加上我们回去肯定要洗澡的，于是想想还是和卓林去麦当劳刷夜了。真的是困得一笔，麦当劳里面还遇到一个民科，南京本地人，喋喋不休，一个劲给我吹牛逼。说自己是啥英国硕士毕业，要移民到美国，然后自己和好几个诺贝尔奖获得者谈笑风生过。然后掏出他的英文词典和世界地图说自己在背单词啥的。后来我抓狂了，就冲卓林发了顿火。 总结去了河南，能够感受到华夏民族的源远流长；去了南京，能够感受到华夏民族的艰苦卓绝。去了河西走廊，我感受到了华夏文化的博大精深、中华民族的兼容并蓄和从古至今历代戍守苍凉的河西走廊的人民的无私奉献。与此同时，我更强烈地意识到中华民族的成长是伴随着巨大的苦难的，我们的历史就是一部我们的前辈靠着自己勤劳的双手，从苦难中挣脱，创造出无数物质财富与精神财富的血泪史。我们中国之所以能够屹立于世界民族之林，靠的是这些前辈们的无私奉献和伟大牺牲。 反观现在很多所谓的“小粉红”，以“腹黑流氓兔”为骄傲，沾沾自喜甚至觉得是一种可以大肆发扬的正能量，心里怀着的是一种将国运当儿戏心态，丝毫没有意识到上下五千年历朝历代的先贤们勤勤恳恳为国捐躯，为的是强大的国家、挺直腰杆的人民，而不是让一群从小娇生惯养的熊孩子玩过家家。又譬如很多的“公知”，以反对政府为荣，天天宣扬着“西吃草”、“国等民”的理论，是一种不负责任的表现，也是可悲的，这些人不过是那些娇生惯养的熊孩子被社会狠肏一遍之后的形态罢了。所以虽然他们看似对立，但实际在思想上如出一辙：因为不爱思考，所以热爱站队；因为不学无术，所以不明事理；因为娇生惯养，所以妄自菲薄。要成为真正的爱国者，首先必是自爱的。在充分认识了自己后才能够悦纳自己，在充分了解了国家民族的历史文化后，才能真正爱国家。在那些嘴里口口声声喊着的，都不是真正的爱国者，他们少数是坏，多数是蠢。]]></content>
      <tags>
        <tag>游记</tag>
        <tag>敦煌</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[multiprocessing模块用法]]></title>
    <url>%2F2017%2F04%2F18%2Fmultiprocessing%E6%A8%A1%E5%9D%97%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[由于一些历史原因，我们常用的CPython具有全局解释器锁(GIL)机制，这把全局大锁导致Python的多线程性能非常糟糕，为了解决这个问题，一种方案是使用协程代替多线程，由于自带了yield，Python实现协程相对于C++那种动辄setjmp或者CPS，抑或利用Linux.ucontext等基于运行时的组件的方式相比要优雅了一些。不过协程对于IO密集型的程序用处很大，但如果我们想要实现并行，那么使用多进程来取代多线程就是一个必由之路。multiprocessing和multiprocessing.dummy是Python下两个常用的多进程和多线程模块。 multiprocessing提供的多进程与多线程机制multiprocessing和multiprocessing.dummy分别为多进程和多线程模块，但是两者的调用方式基本相同 进程池/线程池multiprocessing.Pool(processes = pop_size)和multiprocessing.ThreadPool(processes = pop_size)可以创建不同大小的进程池和线程池。这两个函数还可以传入initializer和initargs两个参数，用于进行初始化。默认情况下Pool会创建process数量的进程/线程，但是maxtasksperchild参数可以控制一条进程/线程最多处理的任务数，当超过这个数量时会重新启动一个新的进程/线程。 调用并取回结果这里我们实际上实现了一个future需要的功能下面我们以多进程为例来展示一下12345678910111213141516task_size = len(tasks)ans = [None] * task_sizeresult = [] multiprocessing.freeze_support()pool = multiprocessing.Pool(processes = task_size)for (i, task) in zip(count(0), tasks): run = pool.apply_async(callee, args = (task, i)) result.append( (i, callee) )try: pool.close() pool.join() for res in result: ans[res[0]] = res[1].get()except Exception, e: print ereturn ans 其中对于多进程，multiprocessing.freeze_support()语句在windows系统上是必须的，这是因为windows的API不包含fork()等函数。apply_async表示异步调用，此时各进程在运行完毕后pool.join()回到主进程，主进程通过res.get()函数获得callee返回结果。 freeze_support123456789101112131415161718192021222324252627282930313233343536def is_forking(argv): # 子进程带有--multiprocessing-fork标记 if len(argv) &gt;= 2 and argv[1] == '--multiprocessing-fork': assert len(argv) == 3 return True else: return False def freeze_support(): ''' Run code for process object if this in not the main process ''' if is_forking(sys.argv): main() sys.exit()def main(): ''' Run code specified by data received over pipe ''' assert is_forking(sys.argv) handle = int(sys.argv[-1]) fd = msvcrt.open_osfhandle(handle, os.O_RDONLY) from_parent = os.fdopen(fd, 'rb') process.current_process()._inheriting = True preparation_data = load(from_parent) prepare(preparation_data) self = load(from_parent) process.current_process()._inheriting = False from_parent.close() exitcode = self._bootstrap() exit(exitcode) 进程间通信对于Python2而言，进程间通信借助于multiprocessing模块提供的Queue、Manager等数据结构 子进程入口点在使用多进程时，如果需要兼容windows，则最好不要使用全局变量。这是因为Python代码的执行顺序是从前往后的，而window又没有类似Linux的fork机制。所以当子进程被创建后，会重新执行一次全局变量的初始化。这可能就会覆盖掉主进程中已经被修改了的值。对于这种情况，有两种方案，第一就是通过IPC将需要传递的全局函数传过去，第二就是借助于仍然可以正常使用的sys.argv来重新初始化一遍。1234567891011121314151617181920import multiprocessing, subprocessfrom multiprocessing import Process, Arrayimport osg = 1000print "进程&#123;&#125;：g的初始值是&#123;&#125;".format(os.getpid(), g)def inner(): print "进程&#123;&#125;：g在子进程入口函数inner的值是&#123;&#125;".format(os.getpid(), g)if __name__ == '__main__': global g g = 2000 print "进程&#123;&#125;：在主进程fork前的值是&#123;&#125;".format(os.getpid(), g) proc = multiprocessing.Process(target=inner) proc.start() g = 3000 print "进程&#123;&#125;：在主进程fork后的值是&#123;&#125;".format(os.getpid(), g)print "进程&#123;&#125;：最终的值是&#123;&#125;".format(os.getpid(), g) 子进程import的情况如果主进程和子进程同时import了一个文件，那么其中的变量是共享的么？1234567891011121314151617181920# subglobal_x = 1000# mainfrom sub import global_ximport multiprocessing, subprocessfrom multiprocessing import Process, Arraydef inner(): print("global_x before inner is &#123;&#125;".format(global_x)) global_x = 3000 print("global_x after inner is &#123;&#125;".format(global_x))if __name__ == '__main__': global_x = 2000 print("global_x before sub is &#123;&#125;".format(global_x)) proc = multiprocessing.Process(target=inner) proc.start() proc.join() print("global_x after sub is &#123;&#125;".format(global_x)) multiprocessing使用实例使用multiprocessing与subprocess协作这个案例来自于我毕业论文的一个需求。为了提高计算效率，可以编写一段主程序，用它来启动若干个外部程序，并把总的计算任务拆分发送给这些外部程序并行计算。运行外部的可执行程序可以使用subprocess模块，主程序通过PIPE和该外部子程序进行通信，这样的通信会阻塞主程序，不能达到并行的效果。为了能够异步地对多个subprocess进行通信，可以使用multiprocessing的多进程，每条进程中调用subprocess，subprocess在进程结束后取回输出，并交回给主进程合并。这样的方法对于n个任务需要启动n个外部程序，如果外部程序的初始化成本比较大，这样的设计方案成本是划不来的，Windows系统下有不能直接fork。比较好的方法是预先初始化m个外部程序作为进程池，然后进程池中的每个外部程序依次处理[n/m]个任务，外部程序和外部程序之间是并行的。为了管理这些子程序，我们可以借助于multiprocessing的多线程，由子线程负责和外部进程进行通信。这样子线程是彼此并行的，而主线程可以阻塞起来，等所有的线程计算完毕join回来即可。虽然说Python自带的GIL给多线程的带来阻碍，但是主要的计算工作主要存在于subprocess所调用的外部程序中，因此性能损失有限。并且采用多进程由于不能共享内存，因此很难将初始化好的外部程序的句柄交给相应的子进程。 初始化外部进程对于这样的多线程方案，首先通过以下语句启动proc_size个外部进程，并且注册proc_size个线程负责和各个外部进程进行交互。主线程使用join函数等待所有子线程返回结果。123456for index in xrange(proc_size): subproc = subprocess.Popen(['XXX.exe'], stdin = subprocess.PIPE, stdout = subprocess.PIPE , stderr = subprocess.PIPE, bufsize=1, close_fds='posix' in sys.builtin_module_names) t = Thread(target = initial_method, args = (index, subproc, call_back)) t.daemon = True ths.append(t) 有关subprocess模块的用法我已经另外开了一篇文章来记录。这里的t.daemon = True表示该线程是主线程的守护线程，守护线程会在主线程退出时自动退出。对每个线程调用start方法，线程才会启动，这时候线程使用给定的args参数调用target参数传入的initial_method方法。1234for i in xrange(proc_size): ths[i].start()for i in xrange(proc_size): ths[i].join() 调用外部进程计算由于n远大于m，因此对每一个外部进程需要使用互斥锁threading.Lock()维护。将线程i按照模m分组，同剩余系的线程共享一个进程。线程取得进程资源后调用lock.acquire()为进程资源上锁，这时候如果其他线程再次调用lock.acquire()则会陷入阻塞状态，直到获得锁的线程调用lock.release()释放资源。]]></content>
      <tags>
        <tag>python</tag>
        <tag>多线程</tag>
        <tag>并行计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕业实习报告]]></title>
    <url>%2F2017%2F04%2F14%2F%E6%AF%95%E4%B8%9A%E5%AE%9E%E4%B9%A0%E6%8A%A5%E5%91%8A%2F</url>
    <content type="text"><![CDATA[为期五天的毕业实习，我们参观了位于溧水的宁溧城际铁路交通路地铁站TA08标段、苏州虎丘塔、上海青浦区金泽水库、上海石洞口无水处理厂、无锡雪浪山边坡治理工程、南京双子楼及南京眼。 Day 1今天我们前往溧水参观了某地铁站的施工，这并不是我们第一次参观地铁站，去年的实习我们曾经参观过南京地铁四号线草场门车站的施工，不过这一次我们得以近距离观察盾构机施工。南京至高淳城际轨道禄口机场至溧水段土建工程施工TA08标段共包含团山站至溧水站区间、溧水站、溧水站至中山东路站区间。其中团~溧区间位于郊区，采用明挖施工，包含明挖敞开段和明挖暗埋段。溧水站为地下两层的单柱双跨（部分为三跨）岛式站台。溧~中区间采用盾构施工，分为左右线。我们首先参观了地铁站的基坑，接着我们下到站台层，参观已浇筑的主体结构。接近中午的时候，有老师率领大家前往盾构机内部参观，不过我漏了队伍，所以没进成，据说里面特别狭窄闷热。上图是地铁站的一个出口，可以发现此处施工采用灌注桩来挡土，由于钻孔灌注桩挡水性能较差，在浇筑钻孔灌注桩放模板前，会加上止水帷幕。我们在参观时，发现靠灌注桩上有一根比较细的水管，不明白它的用途，问了工程师后了解到原来就是用来排水的、我们在地铁站旁的鱼头馆吃了午饭（并没有鱼头），饭后我们来到项目部参观，看到tacs GmbH的一个检测软件，感觉特别高端。工程师们为我们讲解了盾构机的原理。其实盾构机的刀盘和泥土仓前面我们也是进不去的，而一个螺旋运输机负责将渣土送到皮带机上，并由渣土车排出。 Day 2今天我们从南京出发前往苏州虎丘公园。虎丘在古代就是著名的景点，有“吴中第一名胜”之誉。山丘上及附近有多处古迹，其中最古的距今已有2500多年历史，宋代苏东坡曾有“到苏州不游虎丘乃憾事也”的赞誉。虎丘塔又称云岩寺塔，从公元959年开始建造，到961年建成。虎丘塔是一座仿木结构楼阁式大型砖塔，塔身为八角塔，高七层，共47.7米。与杭州雷峰塔合称为“江南二古塔”虎丘塔基岩走向南高北低，它的自重是的北部的填土层压缩产生不均匀沉降，导致塔整体向北倾斜。明代1638年进行修葺时，发现塔身向东北方向倾斜，于是在重建第七层时采取了补救措施，将第七层的重心南移。虎丘塔身结构为套筒结构，由外筒和内筒组成，加上塔砖独特的砌筑方式，塔体上下左右结合紧密，起到了互相牵制的效果。此外六个梯洞的实际是塔的重心南移，增加了塔体的安全程度二十世纪后继续整修，已经控制了倾斜的问题。我们在虎丘公园进行了简单的游玩。 Day 3上午我们参观了位于上海青浦区太浦河旁江浙沪三省市交界处的金泽水库。过往我们参观的水库往往承担调洪蓄水功能或者抽水发电的功能，但是金泽水库的主要功能是为上海西南五区（青浦、金山、松江、闵行、奉贤）金泽水库属于黄浦江上游水源地工程项目，总投资88亿元，日供水规模大351万立方米。金泽水库有乌家荡和李家荡两个天然湖泊构成，设有一个取水口和一个泵站。取水口位移太浦河北岸，从太浦河取水。取水口设有五道污染物屏障。闸门前是一条十几米的栅栏和拦油网，接着是回转式格栅清污机，经过这两个处理太浦河的水通过取水闸门，进入引水河河道，引水河两岸，各安放了15台微纳米充氧设备，起到混合增氧作用，可以促进水中的富营养物质的降解。通过引水河后，水流经李家荡库区，李家荡库区设置一道导流潜堤，进一步净化水质。我们从坝上走到位于水库中的导流堤上，注意到水面上分布种植有许多水生植物。接下来我们上车来到泵站参观，泵站是金泽水库的唯一出口，负责将水库中的水泵入管道中送给上海市区。参观完水库，汽车开了好一段，带领我们来到项目部，金泽水库所处的金泽镇是一个传统的农业镇，且被列入作为泄洪通道。在2016年的汛期，金泽水库的水位一度达到4.7m，逼近5m的最高水位。但是金泽水库本身不作为蓄洪功能，其通常水位为2.4m左右。当洪水来临时或者太浦河水质受到污染时，金泽水库会紧急关闭太浦河取水口，利用自身的储备可以支持三天左右的供水能力，这三天中可以通过控制上游水库，将污染物冲走，恢复供水能力。金泽水库贮存的水经过连通管工程输送到上海西南五区，金泽水库连通管工程起点为金泽水库输水泵站，终点与闵奉支线工程衔接，并与松浦原水厂相连，总长度约41.8公里。连通管全线采用顶管技术施工，以最大程度降低项目实施对周边环境的影响。工程采用直径4米的超大口径钢顶管，全线顶管施工，最长单段顶距长达1667米，在长距离高压原水输送领域尚属国内外首次。工程沿线穿越了多条河道和高速公路，并在列车全速运行的条件下穿越了多条铁路运输干线，施工工期紧，沉降控制要求高。 下午我们参观了位于上海东北角的宝山区石洞口污水处理厂，路途也十分遥远，一路赶来大家饥肠辘辘，虽然走到蕰川公路临近污水厂的时候空气中传来一股恶臭，但是架不住没吃中饭，好在工地给我们发了酸奶和蛋炒饭，大家一抢而空，又一人吃了一桶泡面。石洞口污水处理厂承担了北上海三个区的污水处理，其改造工程主要提升了污水处理的工艺，先前的工艺有一个缺陷是每3小时的工作周期中都有20分钟是不能正常工作的。这20分钟内出的水称为混水，混水的微生物数量是不达标的，要作废打回重新处理；此外对于“比较干净”的雨水，微生物往往不能完美地降解。因此，石洞口污水厂改造使用了新的解决方法，将这20分钟的水打入综合池AB中进行处理。现阶段的雨污混流现象也是值得重视的，旱季的石洞口污水厂一般有不到40万吨的来水，但是到了雨季，来水会变到44-48万吨左右。雨水中有机物比较少，用来分解有机物的细菌吃不饱，导致水质不达标。为了解决这个问题，设置了综合池C池。感觉这个工地是我们毕业实习参观下来比较好的一个工地，整个工地布满了摄像头，设有一个监控中心，监控中心中可以看到各个摄像头的数据。此外工地上的每个设备都有一个二维码，通过扫描二维码可以联系设备负责人、验收等工作。在项目部有一个工地安全体验处。那是一个两层的集装箱，一层展示了防护服、灭火器、安全帽等等防护设备，还提供了模拟电击、高空摔落、安全绳等体验项目。其中高空摔落非常有趣，我们爬上集装箱的二层，从两米高出往下跳，摔落在塑料球和软垫上。虽然整个过程毫无危险，但是我们也感受到了落地时的巨大冲击力，要是直接撞在水泥地上非得摔断腿不可。 Day 4今天我们离开上海，前往无锡雪浪山边坡治理工程。横山寺位于雪浪山山脚下，始建于北宋淳化年间，共占地60亩，横山寺殿宇庄严，香火鼎盛，常年“红烛高照香火旺，钟声不断佛事忙”。由于长年滥采滥开，2013年雪浪山边坡被列为地质灾害隐患点，管理工程项目于2014年12月2日正式出场施工。共三个管理分区：横山寺北坡（I区）、横山寺西南坡（II区）、香草园西坡（III区）。2015年底，横山寺西侧山体边坡前缘出现长50-60米、深10-20米、最宽处达3.5米的裂缝。雪浪山边坡是江苏省内仅次于南京牛首山的第二大边坡。由于牛首山的边坡太过陡峭，工人得挂着安全绳吊在空中打入锚杆。由于坡体在在土坡挖方后产生了滑动，因此进行了一期治理和二期治理，在一期治理过程中边缘的坡体再次被联动，这是因为滑坡方向并不是沿着最高点向下滑动，而是一个侧向滑坡，而前期地质勘测没有做到位。在打入边坡锚杆时因为都是垂直于之前认为的滑动面，因此实际上是平行于滑动面的，因此没有起到作用，严重威胁到山脚的寺庙和居民区。汽车顺着盘山公路把我们带到山顶，我们需要沿着很陡的边坡一直走到山脚下（其实挺刺激的）。边坡治理采取了逐级放坡的方法，越下层的边坡，越是滑坡面越深。每一级边坡之间都有排水沟隔断沿途的边坡采用了若干种加固的方式，例如格构梁、锚杆（8m、10m、15m，越往下越深）、植物。上层边坡的每块格构梁中间都种植了植物作为美化。同时还要做好施工期监测（水平位移、纵向位移、锚杆内部受力），但是实际上由于仪器收到较大的扰动影响，所以实际上只测了锚杆的内部受力。下图是一个锚杆检测器，使用了光纤传感器。随着逐渐往下走，土质也产生了较大的变化，我们看到一些工人在坡体上钉入木钉，用来固定铁丝网，由于铁丝网是柔性的，因此可以挂住坡体。下山后，我们进入横山寺，来到寺庙的背后，据说在那里需要安放一个卧佛。因此在此处采取了灌网分家的措施，设置很多铁丝网。山下可以看到有很多明显的地质构造。 Day 5这是实习的最后一天，我们参观了南京双子塔和南京眼。一路上的风是特别的大，也非常地冷。由于时间限制，我们只是短暂地参观了江苏大剧院和双子塔。然后我们绕路到江心洲，下车行走了一千多米，来到了南京眼下方。南京眼并不是摩天轮，而是一座连接主城和江心洲的供行人行走的桥。该桥为主跨240米的双塔双索面钢塔钢箱梁斜拉桥。]]></content>
      <tags>
        <tag>土木工程</tag>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用tensorflow训练神经网络]]></title>
    <url>%2F2017%2F04%2F02%2F%E4%BD%BF%E7%94%A8tensorflow%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[tensorflow是一个采用数据流图(data flow graph)的机器学习平台，其特征在于用点和线来表示状态和计算过程。 tensorflow配置tensorflow最方便的配置方式是在Ubuntu下直接使用pip安装wheel包。对于使用Windows的需求，可以选择Python3的版本，但是Windows下没有Python2的tensorflow版本，所以使用虚拟机或者Docker等容器或者Win10自带的Linux子系统是个可能的选择。 基本概念 Tensor 张量tf.python.framework.ops.Tensor是tensorflow的基础，表示一个多维向量，在Python中，Tensor就是numpy.ndarray类型。一个Tensor其接受若干个Tensor的输入，并产生若干个Tensor的输出。这称为一个操作op(operaton)。 tf.Tensor.op 产生这个Tensor的Operation tf.Tensor.consumers 使用这个Tensor的Operation的列表 tf.Tensor.graph 这个Tensor所属的图 tf.Tensor.name 这个Tensor的名字 tf.Tensor.get_shape()和tf.Tensor.set_shape(shape) 这个Tensor的形状，是一个TensorShape类型 Operation 操作tf.python.framework.ops.Operation是tensorflow计算流图中的一个节点。Operation可以通过调用op constructor（例如tf.matmul）或 tf.Graph.create_op()来产生，并通过tf.Session.run()或op.run()（tf.get_default_session().run(op)）来执行。 张量和操作的区别似乎是模糊的，根据Quora，可以把Operation对象当做一个void函数，例如a = tf.initialize_all_variables()返回的a是一个Operator。而Tensor对象是一个返回若干个Tensor的函数。 Graph 一张Graph由若干个Operation组成，用来描述数据流图的运算，还由若干个Tensor组成，表示在各个Operation之间传递的数据。一个op constructor 产生的Operation是属于默认Graph的，例如对于c = tf.constant(4.0)，调用assert c.graph is tf.get_default_graph()可以确认。通过with g.as_default()，可以将with作用域的默认Graph设为g。 Variable 神经网络是有多个感知机(perceptron)组成的，其中的例如W和b参数是训练的目标，随着迭代过程被优化，因此使用tf.Variable来表示它们。Variable是代表一个可修改的张量。 Session 通过定义op，定义的是计算流图的计算过程，但在未执行Session.run()前这操作并不会被执行，可以理解tensorflow中的op是“懒”的。 下面的代码相加两个tensor：op1和op2 123456789101112import tensorflow as tfimport numpy as npop1 = np.array([1, 2])op2 = np.array([3, 4])res1 = op1 + op2res2 = tf.add(op1, op2)print res1print res2with tf.Session() as sess: result = sess.run(res2) print result res1使用加法运算符，这等价于相加两个numpy.ndarray，因此立即输出[4 6]结果 res2使用tf.add方法，此时得到了一个tensorflow.python.framework.ops.Tensor类型的Tensor(&quot;Add:0&quot;, shape=(2,), dtype=int64) 之后使用Session.run()方法计算res2节点的值，得到了[4 6]的结果 根据StackOverflow上的这个回答，tf.add和+的具体使用区别是，只要两个操作数中有一个是tf.Tensor，那么tf.add和+是等价的，都是创建一个新的tf.Tensor。当需要给新创建的Tensor显式的名字的时候，一般会选择tf.add，否则重载了的+会更简便。 Session.run Session.run()的第一个参数接受一个或一组（以list表示）需要被计算的op节点，并返回这些节点之后的计算值： 对于下面的代码： 1234567891011input1 = tf.constant(3.0)input2 = tf.constant(2.0)input3 = tf.constant(5.0)intermed = tf.add(input2, input3)# tensorflow 1.0.0 release notes:# tf.mul, tf.sub and tf.neg are deprecated in favor of tf.multiply, tf.subtract and tf.negative.mul = tf.mul(input1, intermed)with tf.Session() as sess: result = sess.run([mul, intermed]) print result result返回list类型的[21, 7]，分别是mul节点和intermed计算值 由于Variable也是一个tensor，所以也需要通过Session.run()来获得它的值 特别地，session.run(tensor)也可以写成with语句中的tensor.eval()，这两个写法是等价的 placeholder和feed 在使用op建立整个网络的数据流图之后，我们希望这个模型能够接受不同的输入进行训练，所以相对于上面直接相加两个tensor的方法，可以使用placeholder和feed在Session.run()时指定输入 1234567891011import tensorflow as tfimport numpy as npop1 = tf.placeholder(tf.int64, [2])op2 = tf.placeholder(tf.int64, [2])res2 = tf.add(op1, op2)with tf.Session() as sess: i1 = np.array([1, 2]) i2 = np.array([3, 4]) result = sess.run(res2, feed_dict = &#123;op1:i1, op2:i2&#125;) print result 在上面的代码中，首先并没有op1和op2直接赋值为numpy.ndarray，而是指定了作为placeholder，在Session.run()使用feed_dict参数将op1和op2传入。 数据类型 在调用tf.matmul时常出现类型错误，需要注意tf.matmul等函数要求严格的类型，例如tf.float32并不能直接和tf.float64相乘，而应该在相乘前使用tf.cast函数进行转义。例如tf.cast(a, tf.int32)返回一个取整了的a的拷贝。 共享变量 训练神经网络常常是分批的，因此需要将初始化各权值和使用给定训练集训练这两个操作分成两个函数，调用一次初始化各权值操作，然后将训练集分成若干批，对每批数据进行训练。显然这两个函数之间需要共享权值这个tf.Variable变量，相对于使用Python提供的global，tensorflow提供了tf.variable_scope()和tf.get_variable()来实现这一点。 get_variable用来引用一个带名字的变量（如果不存在，则创建该变量）： tf.get_variable(&lt;name&gt;, &lt;shape&gt;, &lt;initializer&gt;): 其中initializer指定初始化方式，可以选择： tf.constant_initializer、tf.random_uniform_initializer、tf.random_normal_initializer等，对应着random_uniform(a, b)、Constant(value)、truncated_normal(mean, stddev) variable_scope指定命名空间： tf.variable_scope(&lt;scope_name&gt;) 这个语句常和with搭配使用，这样在该with作用域内的所有get_variable是针对这个variable_scope而言的了。这很类似于C++中的namespace的概念。 使用神经网络进行拟合训练样本分批tensorflow在优化目标函数的时候常使用SGD梯度下降的方法SGD分为三种方法：batch gradient descent方法一次更新使用全部样本，具有比较慢的收敛速度stochastic gradient descent方法一次更新使用1个样本，梯度下降波动太过随机综合考虑选择mini-batch gradient descent方法，一次更新比较小的batch 选择传输函数 sigmoid、tanhsigmoid和tanh更适合解决分类问题，且其值域是[0, 1]，容易产生saturation的情况，当函数的输入绝对值比较大的时候函数输出无限接近于1。此外sigmoid恒为正，所以常使用sigmoid(x) - 0.5或tanh(x) = 2*sigmoid(2x) - 1比较好的方法是根据具体数据规模在里面除个东西或开个根号来控制数据范围，或者可以选择归一化（如softmax）输入 purelinpurelin作为一个值域正负无穷的函数，也不适合作为激活函数，对于一般的数据，如果学习速率比较大很容易算到inf relurelu是没有负值的purelin，定义为max(0, x)，同样不能使用过大的学习速率，否则容易让神经元die，也就是权值变成0 softmax当问题是多个不相交的多类分类的问题时，使用一个softmax分类器比若干个logistic分类器要好 选择损失函数常用的损失函数有均方误差、交叉熵和log-likelihood等 选择Optimizer在之前一直使用的是SGD梯度下降(mini-batch gradient descent)的方法tf.train.GradientDescentOptimizer，这个方法是固定学习速率的，而且容易收敛到局部最优点或者鞍点如果需要自适应的学习速率或者使用动量等方法可以使用其他的Optimizer。所有的Optimizer继承自tf.train.Optimizer特别地，如果不要求在运行时可变学习速率，可以将learning rate作为一个placeholder保存，并feed给session.run() 可视化可以将训练的过程写成summary到文件，并使用tensorboard --logdir=&lt;path&gt;来可视化，得到的结果在http://localhost:6006显示主要步骤是先注册要记录的对象1234567with graph.as_default(): for value in [scalars]: tf.summary.scalar(value.op.name, value) for value in [tensors]: tf.summary.tensor_summary(value.op.name, value) summaries = tf.summary.merge_all() 注意到可能会发生叫”tags and values not the same shape”这个错误。这是因为试图summary一个张量，对于一个标量，例如loss函数的值，应当使用tf.summary.scalar(value.op.name, value)，但是对于一个权值矩阵，应当使用tf.summary.tensor_summary(value.op.name, value)tf.summary.scalar接受第一个参数表示在TensorBoard中显示的名字；第二个参数是一个仅有一个数字的Tensor在训练时12345with tf.Session(graph=graph) as session: summary_writer = tf.summary.FileWriter('log_simple_stats', session.graph) computed_summaries = session.run([summaries]) for step in xrange(num_steps): summary_writer.add_summary(computed_summaries, step) FileWriterFileWriter可以创建一个event文件，并且把summary和event添加进去。FileWriter具有下面的方法： add_summary(summary, global_step=None) add_session_log(session_log, global_step=None) add_event(event) add_graph(graph, global_step=None, graph_def=None) 模型保存可以使用tf.train.Saver保存模型123456with tf.Session(graph=graph) as session: saver = tf.train.Saver() # 从已保存的模型中恢复 saver.restore(session, "save/ada.ckpt") # 保存到指定模型 saver.save(session, "save/ada.ckpt") No variables to save错误出现这个错误是因为saver = tf.train.Saver()出现在with块外部了]]></content>
      <tags>
        <tag>python</tag>
        <tag>机器学习</tag>
        <tag>tensorflow</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[coq学习笔记]]></title>
    <url>%2F2017%2F03%2F12%2Fcoq%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[因为没找到比较好的Coq中文学习资料，所以主要根据官方doc和tutorial-nahas等国外的教程来学习 预备知识 形式证明 首先了解形式证明(formal proof)，可以通过下面的链接进行了解 http://en.wikipedia.org/wiki/Intuitionistic_logic http://en.wikipedia.org/wiki/Curry-Howard_correspondence http://en.wikipedia.org/wiki/BHK_interpretation 注释 使用(* COMMENTS HERE *)进行注释 分隔符 每个Coq命令都要加上.表示结束 IDECoq有自带的CoqIDE，另有命令行程序coqtop和Emacs扩展Proof General hello worldmy_first_proofCoq应该是少数的不能输出Hello, World的编程语言之一了。而对应于HelloWorld的是一个简单的命题 for all things you could prove, if you have a proof of it, then you have a proof of it. 它的证明是这样的 Theorem my_first_proof : (forall A : Prop, A -&gt; A). Proof. intros A. intros proof_of_A. exact proof_of_A. Qed. 首先通过Theorem（还可以使用Lemma(引理)、Remark、Fact、 Corollary(推论)和Proposition(命题)，它们的含义是相同的）来声明一个定理my_first_proof：(forall A : Prop, A -&gt; A)下面的Proof表示证明开始，Qed（还有Admitted、Defined它们的含义是不同的）表示证明结束。 vernacular、tactics和GallinaCoq中有三套不同的语言： vernacular 用来处理定义，使用大写字母开头，例如Theorem、Proof、Qed tactics 用作证明过程，以小写字母开头，例如intros、exact Gallina 用来描述定理，例如(forall A : Prop, A -&gt; A) 查看证明过程Coq是可以查看证明的中间过程的，在菜单栏或者工具栏选择GoTo Cursor即可。现在将运行到intros proof_of_A这行上，可以发现右上角输出如下 1 subgoal A : Prop proof_of_A : A ______________________________________(1/1) A 在水平线上的称为假设(hypotheses)或上下文(the context)，在水平线下的是要证明的东西，称为the current subgoal我们要证明的定理(theorem)称为goal，而subgoal指的是我们在证明过程的任意一点需要证明的东西 tactic首先回到开始状态 1 subgoal ______________________________________(1/1) forall A : Prop, A -&gt; A 可以看到目前context啥都没有，goal是要证明的theorem。这里的A : Prop表示一个具有Prop类型的A。类似的有0 : nat表示一个自然数0，true : bool表示一个布尔值true。-&gt;是for all的缩写，A -&gt; A表示(forall something_of_type_A : A, A)。证明开始，首先遇到第一个tacticintros，intros等于assume，作为我们的假设。于是现在假设有一个任意的假设A，它在可能情况下要和subgoal中的变量同名 1 subgoal A : Prop ______________________________________(1/1) A -&gt; A 在运行完intros A.后，subgoal变成了A -&gt; A，在context中我们有了一个Prop类型的A下面运行第2个intros]]></content>
      <tags>
        <tag>coq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用deap实现遗传算法]]></title>
    <url>%2F2017%2F03%2F02%2F%E4%BD%BF%E7%94%A8deap%E5%AE%9E%E7%8E%B0%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[最近在做毕业论文，其中涉及到一项是检验某个为有限元程序优化参数的遗传算法的正确性。deap是Python上的一个遗传算法库，主要封装了和遗传算法相关的生成population、select、mutant这些相关的操作。比较方便的是deap框架允许自定义个体类型、种群生成方法、评价函数等，所以灵活性比较高 任务简述可以把有限元程序想象成一个有六个参数的黑箱函数f(X | args)，现在对于数据X计算得结果Y = f(X | args)和实际值T有偏差，现在希望通过参数优化（参数值必须在一定范围内）使得计算值尽可能接近实际值。不考虑泛化能力等问题， deap框架前期工作安装deap，pip install一如既往地失败了，幸亏还可以通过setup.py安装。 creator和register这两个模块起到语法糖的作用 creator基于给定的类创建一个派生类，生成的类通过creator.ClassName访问 不同于creator，register创建为一个函数创建别名，并且可以绑定其中的一些参数，生成的函数通过tools.func_name访问1toolbox.register("select", tools.selTournament, tournsize=3) 表示注册一个tools.select作为tools.selTournament的别名，并绑定tools.selTournament的参数tournsize为3 评价函数定义评价值类我们希望用一个scalar或者一组scalar来量化对个体的评价，它的值由评价函数tools.evaluate计算得到。在使用deap时，评价值应当继承自base.Fitness，这个类包含一个values字段，它是一个tuple，实际上是评价值。下面创建一个评价值类1creator.create("FitnessMin", base.Fitness, weights=(-1.0,)) 这里的weights表示每个scalar的权重，当weights=(-1.0,)时说明评价值是一个scalar，并且值越小，评价越高。所以我们看到不直接使用元组，而选择继承封装元组的的Fitness类是为了更方便地比较评价值 评价函数使用均方误差作为评价函数。整个评价函数的实现流程应当是： 使用当前参数值调用有限元程序（fortran77） 获得有限元程序中返回结果 计算均方误差由于整个源程序是5000+行的比较乱的fortran77代码，还要外部link一个obj文件，所以无论是强行转换到C++还是在上面继续实现都比较麻烦，所以使用Python通过管道来调用fortran77程序中的有限元函数，并获得返回结果。 定义初始化个体一个个体应该包含若干数量的基因，也就是我们要优化的参数，通常可以用一个list来存储，类似于Fitness类的方法，我们不直接使用这个list，而是通过creator来创建一个继承自list的类 creator.create(“Individual”, list, fitness=creator.FitnessMin)这个类包含有fitness字段，也就是它的评价值下面我们使用这个类生成若干个体，这可以分解为两步： individual函数为某个个体的基因提供随机的初始值 可以使用tools.initIterate函数，这个函数在/tools/init.py中定义如下 12def initIterate(container, generator): return container(generator()) 其中container就是你定义个体的类Individual generator是一个生成器来提供初始值。假设一个个体有6个基因，可以参照以下代码 123def f(): for gene_index in xrange(6): yield random_value_for_gene_index population通过调用若干次individual函数生成种群 方便起见可以使用/tools/init.py钟提供的另一个tools.initRepeat函数： 12def initRepeat(container, func, n): return container(func() for _ in xrange(n)) 这个函数将func执行n次 运行遗传算法在deap的文档中，可以下载到deap_onemax的源码这份代码使用了定义的四个函数，分别是evaluate、mate、mutant、select，分别对应计算评价值、交配、突变、选择等四个原子操作下面给出的是遗传算法的主程序，在修改时需要注意其中的突变函数toolbox.mutate(mutant)，如果不希望突变，应该把这里注释掉，否则应该手动实现一个自己的突变函数，否则容易随机出无效值。特别地，在deap_onemax的源码中，这个函数时是直接01取反，所以新的程序中出现除0错误很可能是这个原因。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354pop = toolbox.population(n=20)CXPB, MUTPB, NGEN = 0.5, 0.2, 4# Evaluate the entire population# fitnesses = list(map(toolbox.evaluate, pop))fitnesses = []for (i, ind) in zip(count(0), pop): mse = toolbox.evaluate(ind) fitnesses.append(mse)for ind, fit in zip(pop, fitnesses): ind.fitness.values = fit # print(" Evaluated %i individuals" % len(pop))print "Start GA Loop" for g in range(NGEN): print("-- Generation %i --" % g) offspring = toolbox.select(pop, len(pop)) offspring = list(map(toolbox.clone, offspring)) # offspring是个体组成的`list` for child1, child2 in zip(offspring[::2], offspring[1::2]): if random.random() &lt; CXPB: toolbox.mate(child1, child2) del child1.fitness.values del child2.fitness.values for mutant in offspring: if random.random() &lt; MUTPB: toolbox.mutate(mutant) del mutant.fitness.values invalid_ind = [ind for ind in offspring if not ind.fitness.valid] fitnesses = map(toolbox.evaluate, invalid_ind) for ind, fit in zip(invalid_ind, fitnesses): ind.fitness.values = fit # print(" Evaluated %i individuals" % len(invalid_ind)) pop[:] = offspring fits = [ind.fitness.values[0] for ind in pop] length = len(pop) mean = sum(fits) / length sum2 = sum(x*x for x in fits) std = abs(sum2 / length - mean**2)**0.5 print(" Min %s" % min(fits)) print(" Max %s" % max(fits)) print(" Avg %s" % mean) print(" Std %s" % std) best_ind = tools.selBest(pop, 1)[0]best_ind = tools.selBest(pop, 1)[0]print("Best individual is %s, %s" % (best_ind, best_ind.fitness.values))return best_ind]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haskell学习笔记]]></title>
    <url>%2F2017%2F02%2F28%2Fhaskell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Channel 9上有个非常好的介绍Haskell和函数式编程的视频，这个视频是根据Programming in Haskell这本书讲述的。Slides和Codes可以在http://www.cs.nott.ac.uk/~pszgmh/上下载，不过后面几章会和实际的课程内容有出入。此外Learn You a Haskell上的教程，以及Wikipedia上有关Haskell的词条也是非常有用的。相对于其他的一些Haskell的教程，通过这本书/视频进行学习能够了解Haskell的好处以及设计原理 Ch0先吐槽一下教授的口音。。。 配置Haskell环境使用sublime text 2，可能会出现一些问题 Decode error - output not utf-8 在Haskell.sublime-build里面把encoding改为cp936（也就是GBK）即可 Not in scope: main Perhaps you meant min (imported from Prelude) 这是因为编译命令行默认调用runhaskell，它会自动调用main程序，所以把命令行改为ghci即可现在可以愉快地写Haskell啦 end of file &lt;stdin&gt;: hGetLine: end of file 这是Haskell的一个bug，参考StackOverflow上这篇回答 Ch1 IntroductionHaskell大法好！函数式大法好！ 现代软件危机： 如何处理现代程序大小和复杂度问题 如何减少程序开发的时间和代价 如何提高程序可靠性 解决方案： 更清楚、简明、高度抽象的代码 可重用的组件 形式证明(formal verification)的使用 rapid prototyping 函数式编程(functional language) 是一种把函数应用到参数(application of function to arguments)作为基本运算的编程风格 Alonzo Church：lambda演算 John McCarthy：Lisp John Backus：FP，high-order functions and reasoning about program，类似于Linq Robin Milner：ML，type inference and polymorphic types Peter Landin：ISWIM，没有赋值的纯函数式编程语言 David Turner：lazy evaluation SKI组合子演算(Haskell Curry等人提出) 一个非原地的快速排序，类似于Linq(where语句)或派通(Python，神奇的口音)一行版本的写法。 Ch2 First Steps首先是讲了一堆Prelude大法好 列表处理在Ch4中会看到部分函数，例如head、tail是如何实现的 获取列表片段 返回移除列表首元素的新列表，类似car 12&gt; head [1,2,3,4,5]1 返回移除列表首元素的新列表，类似cdr 12&gt; tail [1,2,3,4,5][2,3,4,5] 返回移除列表前n个元素的新列表 12&gt; drop 3 [1,2,3,4,5][4,5] 返回前n个元素组成的新列表 12&gt; take 3 [1,2,3,4,5][1,2,3] 返回列表第n个元素 12&gt; [1,2,3,4,5] !! 23 连接两个列表 12&gt; [1,2] ++ [3,4][1,2,3,4] 列表属性 获得列表长度 12&gt; length [1,2,3,4,5]5 获得列表和/积 12&gt; sum/product [1,2,3,4,5]15/120 翻转列表 12&gt; reverse [1,2,3,4,5][5,4,3,2,1] 生成列表 注意生成的是中括号区间 12&gt; [1..5][1,2,3,4,5] 而 1&gt; [1..] 生成一个无尽的列表，类似python中的生成器count，不同于python，Haskell的实现是因为它是lazy evaluation的 判断元素属于列表 12&gt; 1 `elem` [1..5]True 三种编程语言的比较 C#(OOP) [1,2,3].drop(3) receiver.method(arguments) 这里receiver和arguments不是等价的参数，一切围绕receiver对象为基础 Haskell drop 3 [1,2,3] method receiver arguments 这里receiver和arguments是等价的参数，可以更方便地match每个参数的特定值 F# [1,2,3] -&gt; drop 3 函数调用 使用空格而不是括号+逗号来分离函数名以及参数 函数调用比其他运算符，如+具有更高的优先级（毕竟你连括号都没有），因此比较好的书写习惯是，如果都是函数调用，需要把内层参数括起来Mathematics : f(g(x)) Haskell : f (g x) Mathematics : f(x, g(y)) Haskell : f x (g y) Mathematics : f(x + 1, y - 1) Haskell : f (x + 1) (y - 1) 这样写有最少的语法噪音 $运算符 $运算符实际上表示“应用”的意思。常常可以用来改变运算顺序，从而省略括号，它可以看做id函数对函数的特化 id :: a -&gt; a id x = x ($) :: (a -&gt; b) -&gt; a -&gt; b -- -&gt;是右结合的 ($) :: (a -&gt; b) -&gt; (a -&gt; b) ($) = id f $ g x，即($) f (g x)，等价于f (g x) 如果不加上$，那么g和x都会被当成一个二元f的两个参数，可以参照下面的例子理解： Prelude&gt; (+) 1 (+2) 1 error Prelude&gt; (+) 1 $ (+2) 1 4 type class这里的a称为类型参数，注意这里面的类型参数是静态的而不是动态的，编译器/解释器会自动进行类型推导a是什么的。如对于double函数 double :: Num a =&gt; a -&gt; a 这里出现在=&gt;符号前的Num a作用是给类型参数a加上类型约束，称为类型类，或type class、type/class constraint、context(?)。当有多个类型约束时，用小括号括起所有的类型约束。虽然type class和type都是大写字母开头的，但两者是不一样的，type class通过class等语句定义，type根据type、data等语句定义。type class类似于C#中的接口interface，在功能上也有点类似于C++中的concept123T quadruple&lt;T&gt; (T x) where T:INumeric&lt;T&gt;&#123; return double(double(x));&#125; 类型类通常通过class语句来定义，下面是一个最简单的示例 class BasicEq a where isEqual :: a -&gt; a -&gt; Bool isNotEqual :: a -&gt; a -&gt; Bool 有关类型类的更多细节会在Ch10探讨。 instance然后我们可以用instance语句来创造这个类型类的实例类型(instance type)，也就是a。首先我们需要区分几个类似的用法：第一个是上面见到的函数定义中的Num a，这是type constraint，说明函数中的类型变量a应当满足给出的type class。第二个是马上要见到的foldr中的t a，这是由一个type constructor产生的concrete type（简称type）。下面的语句定义了一个Bool的类型，它实现了BasicEq的constraint或者说type class。 instance BasicEq Bool where isEqual True True = True isEqual False False = True isEqual _ _ = False isNotEqual True True = False isNotEqual False False = False isNotEqual _ _ = True 不过我们发现同时定义两个明显互补的函数是浪费而不美观的。Haskell中允许我们通过定义默认实现的方式来避免这个 class BasicEq a where isEqual :: a -&gt; a -&gt; Bool isEqual x y = not (isNotEqual x y) isNotEqual :: a -&gt; a -&gt; Bool isNotEqual x y = not (isEqual x y) composition我们可以通过double来定义一个四倍函数 quadruple x = double (double x) double x = x + x 更Haskell一点的方法，使用composition(fusion, pipe to) quadruple = double . double (f . g) x = f (g x) 这里的.类似于数学里面的复合函数，可以写出它的签名 &gt; :t (.) (.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c 例如 length = sum . map (\_ -&gt; 1) 由于Haskell是lazy的，所以看到map时，并不立即计算map .运算符和$运算符的比较.运算符的作用是 (f . g) x :: f (g x) $运算符的作用是 f $ g x :: f (g x) 看起来他们具有相同的作用，但实际上两者具有差别。.的作用实际上是生成一个新的函数，比如f . g是合法的，但是f $ g就不合法了。$的作用实际上是消除一些括号，于是haskell不会像lisp一样骚。 将函数作为操作符123factorial n = product [1..n]average ns = sum ns `div` length nsmain = print (average [1,2,3,4,5]) 这里的div实际上是一个函数，加上`后变成了一个运算符，这称为gave accent或backquote，有点类似于fortran中的.op.运算符。相反地，可以在运算符两边加上小括号(op)将其作为柯里函数使用，称为prefix notation或者operator section，这将在后面讲到 :reloadHaskell使用:reload命令通知GHC重新加载hs文件 命名规则 Haskell的函数或者参数名字必须以小写字母开头 类型名必须以大写字母开头 通常列表以s结尾 layout rule 为了省略大括号，Haskell并列语句不能随意缩进（对的游标卡尺），并且缩进只能用空格，而不能够用tab a = b + c where b = 1 c = 2 d = a * 2 的大括号(explicit grouping)形式是 a = b + c where {b = 1; c = 2} d = a * 2 再次说明Haskell消除了不必要的冗余语法 对Haskell缩进规则的补充 如果写过Python，一定知道冒号后面要缩进，tab缩进和空格缩进是不同的，并且每个缩进的长度一定是与层级有关的，但是Haskell并不是。 主要原因是Haskell不强制在“冒号”后面换行。例如在do语句中，如果按照Python的语言习惯，do后面就该直接换行了。但是Haskell可以将do结构里面的第一个语句写到do的同一行，这时候下一行的语句应当和第一个语句是并排的，例如 putStrLn&apos; xs = do putStr xs putChar &apos;\n&apos; 注意putStr的p和putChar的p是并排的，又比如 f x = case x of 0 -&gt; 18 1 -&gt; 15 这里面的0和1也是要对齐的 但是如果我们偏偏在关键字处换行呢？那至少要缩进一个空格，例如 putStrLn&apos; xs = do putStr xs putChar &apos;\n&apos; 和 f x = case x of 0 -&gt; 18 1 -&gt; 15 Ch3 Types and Classes表达式的类型如果一个表达式e的计算得到类型是t的结果，那么称为e具有类型(has type)t，写作 e :: t 由于Haskell是静态类型的(static typed)，所以编译器能够通过类型推导(type inference)得到所有表达式的类型 :t或:type使用:t或:type可以获得参数的类型 Haskell的基本类型Bool | 布尔 Char | 字符，字符直接量用单引号括起 String | 字符串，字符串直接量用单引号括起，也可以看做Char的List Int | 固定精度整数 Integer | 任意精度整数 Float | 浮点数 [t] | 类型t的列表 (t1, ..., tn) | 元组 特别地，使用中括号括起数据生成列表时，中括号起到data constructor作用，括起类型生成列表类型时，中括号起到type constructor作用 函数的类型函数也就是映射，Haskell中使用t1 -&gt; t2表示函数将t1类型映射到t2类型我们可以用type form去“声明”函数，这就是先前看到的e :: t这样的语法。我们也可以使用value form直接来“定义”函数，我们还可以使用lambda表达式来定义一个函数，做法是在最前面加一个反斜杠，\x -&gt; y。特别地，lambda表达式也可以拥有多个参数，可以写成\x y -&gt; x + y由此看出，由于Haskell的类型推导机制，函数的type form在具备value form是并不是强制的（但并不总是可以省略），这和C++等强制性声明函数类型(function type)是不一样的。当然在C++模板编程中可以推导部分参数的类型/返回值，但在编译器层面，每个重载/特化版本的函数签名也是确定的。在实际书写Haskell程序时，先写一遍type form来限定来限定参数的类型、规定函数的签名写出来是一个非常好的习惯，这被称为类型驱动开发（Type Driven Development）。 unit()称为unit，类似于void，会在monad中用到 柯里化对于一个多元函数，例如div，设想它的类型是这样的 add :: (Int, Int) -&gt; Int add = \(x, y) -&gt; x + y 但实际上它的类型是这样的 &gt; :t div div :: Integral a =&gt; a -&gt; a -&gt; a 事实上这是因为add x y实际上接受一个参数a，并返回一个一元函数（闭包），这个函数的类型是a -&gt; a。这个一元函数的作用是将自己的参数b和add的参数a相加，这样的函数称为柯里函数因此实际上div的类型是 div :: Integral a =&gt; a -&gt; (a -&gt; a) 注意到Haskell中的-&gt;符号是右结合的，因为柯里化是从左边开始的，所以可以省略括号写成a -&gt; a -&gt; a使用lambda可以写为 add = \x -&gt; (\y -&gt; x + y) add x = \y -&gt; x + y 多态函数关于这一部分，在文末有专题讨论。Haskell中的函数默认可以接受任意类型的参数，这称为Haskell的类型多态。但有时需要限定类型，例如sum函数，去接受一个Bool类型是没有意义的。因此我们需要引入另一种多态即Ad-hoc多态。Ad-hoc多态的实现是基于typeclass和class instance的。 typeclass下面的语句为a提供typeclass为Num的类型约束1sum :: (Num a) =&gt; [a] -&gt; a 如前面Ch2.5提到过的那样，typeclass类似于C#中interface而非class。不过相比interface，我们看到typeclass中可以定义具有ad-hoc多态类型的值的。此外我们也注意到其实Haskell中，值也可以看成一种特殊的函数：123class TypeClassWithValue t where plainValue :: t functionValue :: t -&gt; t 在typeclass中定义的函数也可以是类型多态或Ad-hoc多态的，例如典型的Monad12class Monad m where (&gt;&gt;=) :: m a -&gt; (a -&gt; m b) -&gt; m b 这里的Monad是一个typeclass，m将来是可以用instance产生的实例(instance)类型，也是一个type constructor，类似C++中的模板，可以用来构造类型。而m a则是由type constructor产生的具体类型(concrete type)——这里概念有点乱的话是正常的，可先查看instance与type的相关章节——我们注意到实例m受到Ad-hoc多态的typeclass Monad的约束，但它自己确是类型多态的，因为它可以是任意的类型a。 常用的typeclasse有 Eq：表示能判断相等的类型 Num：表示数字，不继承Ord。Num没有(/) Real：实数，继承了Ord Integeral：整型 Ord：表示能比较大小的类型 特别注意，Ordering是一个类型，包含GT、LT、EQ三个constructor Show：可以被转成字符串的类型，Haskell中除了函数都能被表示成字符串 Read：可以从字符串被读取的类型 Enum：能被枚举的类型 Bounded：有界的类型 Fractional：具有除法的数字类型类(/) Floating：浮点 Existential Quantification作为拓展，必须介绍Existential Quantification这个Haskell类型系统中的重要概念，Haskell借助于此实现类似OOP中的多态。 Ch4 Defining FunctionsifHaskell中的if语句和其他语言的并无二致 if cond then exp1 else exp2 但是else分支是必须的，毕竟是强类型语言 guarded equations这个名字还挺熟悉的，原来是在《程序设计语言原理？这本书上看到过，当时翻译成守卫。这里的guard指的是|符号，注意|在list comprehension另有用途。guarded equations是Haskell比较独特的一种表示条件分支的办法，有点类似于数学公式里面的条件，或者说其他语言中的select case的用法 abs n | n &gt;= 0 = n | otherwise = -n 偏函数应用与部分函数不同于Scala，Haskell中的部分函数，相对于全函数(total function)是不被鼓励的。一个部分函数类似于div、(!!)，它并不是对于指定类型的所有值都有定义。以head为例，它的参数是所有的列表，可是对于一个空列表应用head会抛出一个异常。 Prelude&gt; head [] *** Exception: Prelude.head: empty list 在Haskell中，偏函数应用(partial application)和部分函数(partial function)是两个不同的概念。偏应用在随后会有介绍。 where语句这里补充一下where，这是一个类似占位符placeholder的语句，让我们的代码更漂亮一点，同时能够在guard、do这样的结构中复用一些结果。 f x | cond1 x = a | cond2 x = g a | otherwise = f (h x a) where a = w x 可以看出来where的缩进应当与其所在的结构下属的语句相同，而不是与所在的结构平齐。并且where作为一个结构，其下属语句也需要缩进。where也可以通过模式匹配来定义函数 fib = (map fib&apos; [0 ..] !!) where fib&apos; 0 = 0 fib&apos; 1 = 1 fib&apos; n = fib (n - 1) + fib (n - 2) 此外go惯用法里面也常用到where where的作用域根据stackoverflow上的这篇回答对于下面的这个式子 someFunc x y | guard1 = blah1 | guard2 = blah2 where {assignments} {assignments}域中只能够访问x和y，但guard1、guard2、blah1、blah2都能访问{assignments}。 where存在的问题一个不恰当的where语句会导致性能的降低，比较一下下面的两段代码12345678910111213-- 1fib = (map fib' [0 ..] !!) where fib' 0 = 0 fib' 1 = 1 fib' n = fib (n - 1) + fib (n - 2)-- 2fib x = map fib' [0 ..] !! x where fib' 0 = 0 fib' 1 = 1 fib' n = fib (n - 1) + fib (n - 2) 这两种写法互为eta-conversion(η-conversion)。eta-conversion是lambda演算中的一种变换，指\x -&gt; f x和f这两种写法在语义上是等价的。但实际上第一段代码要比第二段代码要快，这是因为第一段代码满足了Constant applicative form(CAF)，因此编译器默认会进行优化，而对于第二段代码由于x不确定，所以对于每个x，编译器都要重新计算一遍fib&#39;函数。使用GHC的float-in/float-out能够进行优化。 where、let in与let的区别首先let和前两者是非常不同的。 pattern matching模式匹配(pattern matching)可以用来进行解构绑定(deconstruction binding)借助于Haskell的模式匹配还可以实现下面的写法。 not :: Bool -&gt; Bool not True = False not False = True 这可以借助OOP中的虚函数(dynamic dispatch)实现，例如下面的C#伪代码12345678910111213class Bool&#123; Bool Not();&#125;class True : Bool&#123; Bool Not()&#123; return new False(); &#125;&#125;class False : Bool&#123; Bool Not()&#123; return new True(); &#125;&#125; 特别地，下划线_表示可以匹配任何参数，称为wildcard。例如 True &amp;&amp; b = b False &amp;&amp; _ = False lazy evaluationlazy evaluation相对于eager evaluation有相当的好处，阐明这点将贯穿整个课程，这里讲了一个比较具体的例子 f x = 4711 于是可以有下面的求值方案，这里X是某个任意值 f(True &amp;&amp; X) = f(X) = 4711 这样的好处是避免了对X的求值（注意这里X没有被逻辑与短路），因为X可能是不可计算的：假如定义并求值X = X或者X = head []，那程序是不能终止(non-terminating)的，在Haskell中是通常的一种错误(Error)形式。但是f(X)是可以计算的。采用eager evaluation的大多数其他语言会在True &amp;&amp; X表达式时就对X求值，而这时会造成问题的。此外，lazy evaluation无论对于什么样的求值顺序结果都是不变的，这是由于Haskell语言本身（除了Monad）不会造成副作用。例如对于上面的例子可以直接根据f x = 4711归约 f(True &amp;&amp; X) = 4711 pattern具有优先级对于这个例子中，值永远是False，因为第一个规则的优先级更高 _ &amp;&amp; _ = False True &amp;&amp; True = True 所以我们在写规则的时候，会把更特化的规则写在前面，这是非常需要重视的一点。 重复的名字不能出现在pattern中此外还需要注意重复的名字(patterns may not repeat variables)，例如下面的代码是错误的 b &amp;&amp; b = True 会输出错误 ? Conflicting definitions for ‘b’ Bound at: F:\Codes\Haskell\3.hs:2:1 F:\Codes\Haskell\3.hs:2:6 ? In an equation for ‘Main.&amp;&amp;’ 这是为什么呢？其实这样的东西称为nonlinear pattern。理想情况下，我们希望通过使用同一个字符b来限定&amp;&amp;的左操作数和右操作数是相等的。但是这是不可能实现的，因为当左右操作数出现lambda时，是没有一个统一标准判断lambda是否相等的 list pattern和:运算符:(cons)可以构造列表，下面的第一行代码称为list constructor，我们常喜欢用的第二行可以看做第一行的语法糖。 1:(2:(3:[])) [1,2,3] 然而它还可以用在pattern matching中，例如实现head和tail head :: [a] -&gt; a head (x:_) = x tail :: [a] -&gt; [a] tail (_:xs) = xs 注意点： 用x:xs去pattern matching空list是未定义行为 x:xs一定要用括号括起来，因为函数调用(application)的优先级比:的优先级要高 注意区分**(x:y)**和**[x:y]** [x:y]匹配具有一个参数的list，这个参数满足匹配x:y (x:y)匹配具有x作为head和y作为tail的list 总之，[]匹配是固定个数的，可以利用这个来匹配终结条件，例如 product [] = 1 product (x:xs) = x * product xs 或 product [x] = x product (x:xs) = x * product xs as sign(@) 有时候会见到这样的代码ps@(x:xs)，这时候我们可以同时给列表、列表中的第一个元素、列表的剩余部分同时命名。 有办法去pattern matching列表的最后一个元素么 为什么要去这样做呢？我们要注意到haskell中的列表是lazy evaluate的，也常是无尽列表，而无尽列表是不存在最后一个元素的。 integer pattern 这是一个类似数列递推公式的pattern，可以使用n + k这样的形式使用。这时候n是一个变量，而k是一个常数 pred :: Int -&gt; Int pred (n + 1) = n fib :: Integer -&gt; Integer fib 0 = 1 fib 1 = 1 fib n = fib (n-1) + fib (n-2) main = print (fib 5) 函数调用(application)的优先级比+等代数运算的优先级要高，所以同样要用括号括起来 lambda在上一Chapter中通过add的例子讲到Haskell如何通过柯里化让一个函数返回另一个函数，而使用lambda可以更清晰地表现出一个函数究竟是返回的一个值还是另一个函数。例如 const :: a -&gt; b -&gt; a const x _ = x 也可以写成柯里形式，接受一个参数，返回一个接受一个参数的函数 const x = \_ -&gt; x 使用lambda同时还可以声明一个匿名函数，然后避免定义这个只用一次的具名函数。对于多元的lambda表达式 \x -&gt; \y -&gt; f x y 可以简写为 \x y -&gt; f x y section与偏函数prefix notation是Haskell独有的特性，即之前(Ch2.6)上在运算符两边加上小括号(op)将其作为柯里函数的用法。因为在Python中要不自己定义一个lambda x,y: x + y要不传一个operator.add注意到既然是柯里函数，意味着说我们还可以这样写，这称为section1234&gt; (1+) 23&gt; (+2) 13 而不要写成lambda x: 1 + x 作为补充，提及一下。类似于(1+)的写法称为偏函数应用(partial function application)。偏函数是对于柯里化来说的，类似于C++中的偏特化，其目的是固定一个多元函数中的某几个函数的值，产生一个新函数。例如对于add函数 add :: Int -&gt; (Int -&gt; Int) add x y = x + y 我们可以特化出一个addOne函数 addOne :: Int -&gt; Int addOne = add 1 在定义偏函数应用的时候，要注意我们partial的是application而不是function。例如偏函数应用也能对下面比较复杂的高阶函数奏效 comp2 :: (a -&gt; b) -&gt; (b -&gt; b -&gt; c) -&gt; (a -&gt; a -&gt; c) comp2 f g = (\x y -&gt; g (f x) (f y)) 现在我们试图特化g为add，可以记住一条简单的规则偏应用的定义式右部必须出现原函数，例如addOne函数的右部出现了add函数。因此尝试comp2&#39; f = (\x y -&gt; add (f x) (f y))是不对的，它实际上定义了一个新的函数，而正确的偏应用应当为 comp2&apos; f = comp2 f add Ch5 List Comprehensions顾名思义，这章讲的是Haskell的列表生成器 [x + 1 | x &lt;- [1..5]] 这个最近的C++标准/草案中也有类似的range可以生成笛卡尔积 &gt; [(x,y) | x &lt;- [1,2,3], y [(x,y) | y &lt;- [4,5], x [(x,y) | x &lt;- [1..3], y &lt;- [x..3]]它还可以做 concat :: [[a]] -&gt; [a] concat xss = [x | xs &lt;- xss, x &lt;- xs] 这类似于派通(Python，老外奇妙的口音)中的 [item for sublist in [[1,2], [3], [4,5,6]] for item in sublist] 还可以加上guard [x | x &lt;- [1..10], even x] 下面是一个质数暴力筛程序 factors :: Int -&gt; [Int] factors n = [x | x &lt;- [1..n], n `mod` x == 0] prime :: Int -&gt; Bool prime n = factors n == [1,n] primes :: Int -&gt; [Int] primes n = [x | x &lt;- [2..n], prime x] zip常用函数不解释 zip :: [a] -&gt; [b] -&gt; [(a, b)] Haskell中的zip函数同样是不要求两个list长度匹配的，于是可以写出这样的代码 &gt; pairs xs = zip xs (tail xs) &gt; pairs [1,2,3,4] [(1,2),(2,3),(3,4)] zip的反函数是unzip unzip :: [(a, b)] -&gt; ([a], [b]) stringstring是Char的list Ch6 Recursive Functions 介绍Why Functional Programming Matters这本书 为什么lazy和pure的functional programming很重要 证明 product [1..n] = recfac n 递归的作用 容易 自然 能够使用数学方法induction lazy evaluation和purity 这块讲得比较抽象，实际上就是不同的函数有一些相似点可以提炼成一个大操作，这个大操作中包含着若干实现不同的小操作（初始条件，迭代更新规则），由于小操作是不互相影响的(purity)，所以可以只实现提炼出的大操作，然后对于每个函数实现对应的小操作。这些在下一章会有详细说明 多元函数的递归 zip :: [a] -&gt; [b] -&gt; [(a,b)] zip [] _ = [] zip _ [] = [] zip (x:xs) (y:ys) = (x,y) : zip xs ys drop drop需要处理两个初始条件 drop :: Int -&gt; [a] -&gt; [a] drop 0 xs = xs drop _ [] = [] drop n (_:xs) = drop (n-1) xs quick sort 下面是出现在整个课程开头的快速排序 qsort :: Ord a ⇒ [a] -&gt; [a] qsort [] = [] qsort (x:xs) = qsort smaller ++ [x] ++ qsort larger where smaller = [a | a &lt;- xs, a &lt;= x] larger = [b | b &lt;- xs, b &gt; x] Ch7 Higher-Order Functions上一章讲了如何使用递归来实现某些函数，这章学习通过高阶函数如map、filter、foldr来实现它们高阶函数(Higher-Order Functions)指的是接受一个函数作为参数，或者返回一个函数的函数（然而Haskell天生自带Currying，所以参数大于等于2就一定是高阶函数了啊）首先介绍一些关于Combinator的书 高阶函数用途 common programming idiom 写出更短小精炼的程序 DSL 可以方便地定义领域特定语言(DSL)，例如一个简单的加法器的语法 data expr = value = add expr expr 可以发现这和我们常用来描述文法的BNF是非常类似的，而下面需要parse的话可以实现一个eval函数 eval :: expr -&gt; Int Haskell相比C++方便多了，要是C++的话可能会想着自己撸个逆波兰式或者LL/LR解释器啥的 另外Haskell的模式匹配也减少了大量的代码 algebra properties 高阶函数具有一定的代数性质可以进行宏观变换，而不要担心实现细节，类似于上一章讲到的分为大操作小操作 mapmap接受一个函数和一个列表，将这个函数应用到列表中的每个元素中，并返回一个列表 map :: (a -&gt; b) -&gt; [a] -&gt; [b] 注意不要错写成 map :: a -&gt; b -&gt; [a] -&gt; [b] 在一些函数式编程语言中还可以见到flatMap这个函数，它和map有本质的不同，它的签名可以写为flatMap :: (a -&gt; [b]) -&gt; [a] -&gt; [b]。当作用在一个[a]数组时，可以理解成它首先生成[[b]]数组，再将这个数组拍平成[b] filter可以通过guard或者list comprehension来实现filter foldHaskell或者C++17中的fold expression，类似于python等语言中的reduce函数。这两者的区别在reduce只能处理一个相同类型（fold前），但是fold可以处理两个不同类型（fold前和fold的结果）Haskell中分为foldl和foldr，其中foldr比较常用，将归约到的值作为运算f的右操作数 foldr :: Foldable t =&gt; (a -&gt; b -&gt; b) -&gt; b -&gt; t a -&gt; b foldr f v [] = v foldr f v (x:xs) = f x (foldr f v xs) 它接受三个参数： (a -&gt; b -&gt; b)：一个接受a和b类型参数并返回b类型参数的函数 b：归约到的类型 t a：这个表示一个t a的类型。这里t表示一个Foldable的类型。 在C++中有叫模板参数的东西，例如std::vector&lt;int&gt;表示一个用int特化的向量表vector。Haskell中的t a类似于这个，其中t对应着类模板vector，a对应着类型int。 因此可以理解成一个叫t的函数，接受一个类型变量(type variable)a作为参数，产生了一个新的类型t a。这里的t称为type constructor，而a是一个concrete type。 一个concrete type是具有值的，例如Int之类的，它通常是由data声明的；但一个type constructor function必须接受一个type parameter才能成为一个concrete type，例如，当t为list时，t a就是[a]，这里[a]是一个语法糖，等价于[] a。type constructor通常是由class声明的并可以由instance提供实现的，例如instance Applicative []。这里注意，这里的t并不一定是容器类型，例如它不局限于list、tuple这样的东西，所以我们不能局限地认为fmap是“对于某个容器里面的所有元素都进行XX操作”。 =&gt;：我们之前见过在=&gt;左边的Num a，这个称为类型约束。而=&gt;右侧的函数签名部分，称为type form。 因此这个函数可以理解为 foldr f 当前/初始归约的结果 用来归约的列表 reduce可以用fold来实现，例如Python中的 print reduce(lambda x, y: x + [y], [1,2,3,4], []) 可以用foldr实现为 main = print (foldr (\x -&gt; \y -&gt; [x] ++ y) [] [1,2,3,4]) 类似的有foldl函数 foldl :: Foldable t =&gt; (b -&gt; a -&gt; b) -&gt; b -&gt; t a -&gt; b 上面的reduce可以用foldl实现为 main = print (foldl (\x -&gt; \y -&gt; x ++ [y]) [] [1,2,3,4]) foldl和foldr的区别从定义上看，这两个函数的区别在第一个参数f上，这实际反映了运算顺序的不同。查看定义 foldlX f acc [] = acc foldlX f acc (x:xs) = trace (&quot;acc == &quot; ++ show acc) foldlX f acc&apos; xs where acc&apos; = f acc x foldrX f acc [] = acc foldrX f acc (x:xs) = trace (&quot;acc == &quot; ++ show acc) f x (foldrX f acc xs) 执行结果 &gt; main = print $ foldlX (+) 0 [1..5] acc == 0 acc == 1 acc == 3 acc == 6 acc == 10 15 &gt; main = print $ foldrX (+) 0 [1..5] acc == 0 acc == 0 acc == 0 acc == 0 acc == 0 15 提炼出来 foldl = foldl f(x, acc) xs foldr = f x foldr(acc, xs)可以发现foldl是从左到右计算的，但foldr是从右到左计算的。由此导致的foldl会产生一个尾递归（右递归），foldr产生一个左递归。由于编译器可以针对尾递归优化，所以foldl可能会快一点。此外，利用strict特性（详见Ch12 strict application）的foldl&#39;能够减少空间。那么foldr的优势在于处理无穷列表的时候，考虑 myAndL = foldl (&amp;&amp;) True myAndR = foldr (&amp;&amp;) True &gt; myAndL (repeat False) &gt; myAndR (repeat False) 那么foldr由于f = (&amp;&amp;)的性质被短路，所以能够返回。但是foldl的f在内部，而foldl本身不具备短路原则，会陷入无限的尾递归 部分内容来自文章进行说明 使用fold实现函数fold是被提炼出的一种“大操作”，利用foldr可以实现很多函数，之前这些函数往往要递归地通过guard、if或者list comprehension来实现 sum = foldr (+) 0 这是因为 sum [1,2,3] = foldr (+) 0 [1,2,3] = foldr (+) 0 (1:(2:(3:[]))) = 1+(2+(3+0)) 类似地可以定义 product = foldr (*) 1 or = foldr (||) 1 and = foldr (&amp;&amp;) 1 对于length函数可以如此定义 length = foldr (\_ n -&gt; 1 + n) 0 length = sum . map (\_ -&gt; 1) 对于reverse函数可以如此定义 reverse = foldr (\x xs -&gt; xs ++ [x]) [] 这是因为 reverse [1,2,3] = reverse (1:(2:(3:[]))) = (([] ++ [3]) ++ [2]) ++ [1] 所以可以看到foldr接受a类型的x和b类型的xs，然后反向地去连接xs和[x]，最后得到的是另一个列表，这和上面的length函数是不一样的特别地，可以重新定义++ (++ ys) = foldr (:) ys 这是因为 (xs ++ ys) = foldr (:) ys xs 这表示把Foldable类型的xs中的每个元素:到ys的前面，这就相当于 foldr (:) ys [1,2,3] = foldr (:) ys (1:(2:(3:[]))) = (1:(2:(3:[ys]))) 继续改写 (xs ++ ys) = (++) xs ys -- 这里原版写的是(++) ys xs但是我觉得应该是(++) xs ys = foldr (:) ys xs 因此可以得到 (++) ys = foldr (:) ys = (++ ys) = foldr (:) ys fold的作用 有些递归函数用foldr更容易实现（可以从之前的讨论中看出） 有些函数的性质可以通过foldr的代数性质推导得到，例如fusion规则和banana split规则 fusion fusion(composition)是之前讨论过的.运算符，用来实现复合函数，其具有类型 (.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; (a -&gt; c) banana split 这个会在后面提及 使用foldr而不是递归，可以方便进行优化 unfoldrunfoldr为foldr的对偶函数，定义为 unfoldr :: (b -&gt; Maybe (a, b)) -&gt; b -&gt; [a] 一般可以理解为a为生成的list里面的每一项，而b是下次迭代的时候的b，类似于for循环中的更新规则 unfoldr具有性质 unfoldr f&apos; (foldr f z xs) == xs scanlscanl和foldl非常相似，只不过它是“扫描”获得列表，而不是将列表“折叠”起来 (a -&gt; b -&gt; a) -&gt; a -&gt; [b] -&gt; [a] 更多的高阶函数all、any、takeWhile（常常被用来读无尽列表）、dropWhile fmapfmap与Functor息息相关，Functor在下章会进行补充。首先比较一下fmap和map的定义 Prelude&gt; &gt; :t fmap fmap :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b Prelude&gt; &gt; :t map map :: (a -&gt; b) -&gt; [a] -&gt; [b] fmap接受一个(a -&gt; b)函数，这个函数负责将一个f a转换为f b。这里注意f是一个type constructor。如果我们把fmap的f替换成[]，便可以发现map实际上是fmap对list即[]的特化。 instance Functor [] where fmap = map Ch8 Functional Parsers在官网上下载的PPT中第8章是Declaring Types and Classes，但实际上这章在课程中被放到了第10章。本章是Functional Parsers，会讲授重要的概念Monads，于是教授穿了件自己设计的（密集恐惧症）衣服这一章会有点突兀，有比较多的没学过的东西，在我学习的过程中，最让我感到困惑的并不是Monad本身，而是教授讲授时定义的复杂的类型，例如即将看到的IO a和Show a这样的类型，有时这会导致运行教授讲授的代码存在困难，不得不说是课程的一个缺憾。首先要补充一个控制结构，对于下面的guard f 0 = 18 f 1 = 15 f 2 = 12 f x = 12 - x 这种写法又称为piece-wise version，因为实际上定义了4个f函数。如果用case，可以写作 f x = case x of 0 -&gt; 18 1 -&gt; 15 2 -&gt; 12 _ -&gt; 12 - x 课程开始，照例讲了点别的，介绍Functional Portal Parser Type在本章中，我们要实现一个类型Parser，通过实现这个Parser，我们也就实现了Monad的核心部分。很自然地，在Haskell中，用函数来表示Parser type Parser = String -&gt; Tree 但是有时候Parser只处理输入串String的一部分，所以Parser也要返回未使用的String type Parser = String -&gt; (Tree, String) 有时候输入串String不能生成语法树Tree，于是Tree并不是一定有的，是一个optional值，这在Haskell中可以用Maybe来表示 data Maybe a = Nothing | Just a Maybe在Haskell中用来处理optional值，它是一个Monad，data语句在第10章会有介绍，Nothing和Just a是Maybe a的两个constructor，它们看起来像为C++中的enum，但实际上更类似于C++中的构造函数。Maybe一个类型可以从Nothing构造，但返回一个非Nothing的值a时就需要返回Just a。Nothing很好理解，类似于其他语言中的null、None、nil在没学习Ch10 Declaring Types and Classes时，Just是个比较奇怪的概念。首先查看它的定义 Just :: a -&gt; Maybe a 从定义中可以看到Just返回的是Maybe a对象，这有点类似于函数重载或者SFINAE的意味，我们可以理解为调用了Maybe不同的构造函数，并且Nothing可以表示另一个构造函数，不过这个构造函数不接受参数罢了。如果我们把data语句当成了enum，这里就不好理解了。教授认为出于方便考虑，并不需要使用Maybe这东西，用一个简单的list就可以了 type Parser = String -&gt; [(Tree, String)] 因此这个list要不是一个单元素的列表(singleton list)，要不是个空列表最后，Parser并不一定返回一个语法树，所以加上一个泛型 type Parser a = String -&gt; [(a, String)] 总结一下，现在我们已经知道了list的作用是为了实现optional，tuple的作用是辅助类似于遍历字符串的一个指针。事实上这个Parser是一个Monad雏形。注意如果使用附带的代码Parsing.hs会发现视频隐藏了Parser的一些关键定义，这会导致直接键入并运行视频中的代码可能会出现错误（接下来会看到）。视频中给出上面这样的Parser定义是为了方便理解的考虑，实际上也是实现了一个Monad的type class。 Bottom我打算在这里插进来介绍一个_|_，它叫Bottom。当我们在讨论编程语言时，我们常常厌恶null。但实际上null的语义是无法避免的，因为停机问题是没有解的。Haskell中也有Bottom这个东西。 一些简单的语法分析器item这个Parser在输入为空是fail，否则读取输入的第一个字符，下面根据type Parser a = String -&gt; [(a, String)]来推导item的类型 item :: Parser Char :: String -&gt; [(Char, String)] :: [Char] -&gt; [(Char, [Char])] 下面查看item的定义 item = \inp -&gt; case inp of [] -&gt; [] (x:xs) -&gt; [(x,xs)] failure和名字一样，这个语法分析器总是失败 failure :: Parser a failure = \inp -&gt; [] return这个语法分析器的定义不太一样了，它返回一个接受任何输入的一个语法分析器，这个语法分析器对于任意输入返回v。 return :: a -&gt; Parser a return v = \inp -&gt; [(v, inp)] 我们分析一下返回类型 Parser a :: String -&gt; [(a, String)] :: [Char] -&gt; [(Char, String)] 原来返回的是个函数，测试一下 main = print $ (return &quot;123&quot;) &quot;xxx&quot; 发现结果是&quot;123&quot; return关键字的辨析Haskell中的return的和大多数语言中return关键字名字相同，也都经常出现在语句的末尾。但两者的意义却完全不同。Haskell中也不需要什么return，语句自身就是返回值，所以不要把两个混淆在Haskell的Prelude中定义有类似以上代码实现的return函数 &gt; :t return return :: Monad m =&gt; a -&gt; m a 实际上return是Monad里面的一个非常重要的运算，在后面即将讲到。 +++这个语法分析器类似于一个选择结构，实际上它是一个存在的运算符&lt;*&gt;的重新实现。它表现得像语法分析器p，如果p能succeed，否则表现得像语法分析器q (+++) :: Parser a -&gt; Parser a -&gt; Parser a p +++ q = \inp -&gt; case p inp of [] -&gt; parser q inp [(v, out)] -&gt; [(v, out)] parseparse是个很重要的语法分析器，如果实际运行附带代码里面的Parsing.hs，就会发现 print (item &quot;123&quot;) 是会报错的，正确的方式是运行 print (parse item &quot;123&quot;) 这类似return的问题，这是因为Parser的定义不同导致的，在现阶段应该使用视频中给出的代码再看一下parse的定义 parse :: Parser a -&gt; String -&gt; [(a, String)] parse p inp = p inp 值得注意的是parse函数将这个语法分析器（再次强调根据type Parser定义，Parse实际上也是一个函数）p应用(apply)到inp上。它的作用是让代码更清晰 检验上面的语法分析器检验上面的语法分析器需要Parser类型的定义。 item&gt; parse item &quot;&quot; [] &gt; parse item &quot;abc&quot; [(&apos;a&apos;, &quot;bc&quot;)] failure&gt; parse failure &quot;abc&quot; [] return&gt; parse (return 1) &quot;abc&quot; [(1, &quot;abc&quot;)] +++&gt; parse (item +++ return &apos;d&apos;) &quot;abc&quot; [(&apos;a&apos;, &quot;bc&quot;)] &gt; parse (failure +++ return &apos;d&apos;) &quot;abc&quot; [(&apos;d&apos;, &quot;abc&quot;)] Sequencing到目前为止，我们都是使用递归来描述一系列的操作的，借助list comprehension或者高阶函数也可以实现循环操作，借助if、guard或者case实现选择语句。但是顺序操作，这个命令式语言最常见的操作却一直没有办法实现，事实上由于Haskell的lazy特性，其更倾向于是并举的。而Monad正是解决这个问题的 do可以用do来表示顺序操作，do能够作用在任意的monadic类型上 p :: Parser (Char, Char) p = do x &lt;- item item y &lt;- item return (x, y) 注意：这段代码需要通过附带的代码Parsing.hs运行，因为Parser类型实际上要实现Monad类型类，才能够使用&gt;&gt;=、&lt;-等运算符如果仅仅使用type来定义 type Parser a = String -&gt; [(a, String)] 简单地推导下可以发现 :: Parser (Char, Char) :: [((Char, Char), String)] 但是在错误信息中发现编译器实际上推导出的(x, y)是 :: [(([(Char, String)], [(Char, String)]), String)] 同样，在Parsing.hs运行下面的代码可能会报错，因为使用了newtype定义的类型和[(a, String)]是两个完全不一样的类型了，所以要在前面加一个P。可以参考Parsing.hs里面的item和parse函数。 在下面两节将要介绍&gt;&gt;=运算符，这个运算符和do同样可以描述序列化的操作，而序列化是Monad的一种用途。 Select和SelectMany在了解&gt;&gt;=前，教授提到了C#中的Select方法和SelectMany方法，其中Monad类似于SelectMany方法，因为Monad可以控制如何返回结果。1234567891011121314151617181920212223242526static void Main(string[] args)&#123; List&lt;string&gt; animals = new List&lt;string&gt;() &#123; "cat", "dog", "donkey" &#125;; List&lt;int&gt; number = new List&lt;int&gt;() &#123; 10, 20 &#125;; var select1 = number.Select(num =&gt; animals); var select2 = number.SelectMany(n =&gt; animals); foreach (var x in select1) &#123; foreach (var y in x) &#123; System.Console.WriteLine(y); &#125; &#125; System.Console.WriteLine("-----------------------------"); foreach (var x in select2) &#123; System.Console.WriteLine(x); &#125; System.Console.WriteLine("-----------------------------"); var zipped = number.SelectMany(n =&gt; animals, (n, a) =&gt; new &#123; n, a&#125;); foreach (var x in zipped) &#123; System.Console.WriteLine(x); &#125; System.Console.ReadKey(true);&#125; 输出值是 cat dog donkey cat dog donkey ----------------------------- cat dog donkey cat dog donkey ----------------------------- { n = 10, a = cat } { n = 10, a = dog } { n = 10, a = donkey } { n = 20, a = cat } { n = 20, a = dog } { n = 20, a = donkey } 可以看到，SelectMany能够将结果“拍平”成一维数组。并且可以多接受一个函数，表示如何返回结果。 >>=这个操作称为bind，是Monad中最重要的一个运算符，在C#中称为SelectMany，先查看它的定义 (&gt;&gt;=) :: Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b 【注】实际上在Haskell源码（在安装目录下的doc文件夹）中，该运算符是以如下形式出现的(&gt;&gt;=) :: forall a b. m a -&gt; (a -&gt; m b) -&gt; m b。forall关键字来自Existentially quantified types这个扩展，并且作为默认的选项，这里可以直接忽略。因为Parser是一个Monad，为了直观一点，所以对应到Parser类型 (&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b 这个运算接受一个参数Parser a，将它给一个函数(a -&gt; Parser b)，随后得到结果Parser b。于是我们产生了几个问题： 这看起来就是提供了一个策略，能通过a -&gt; Parser b实现函数m a -&gt; m b能实现的功能，感觉没什么了不起的，为什么不能直接定义一个m a -&gt; m b的函数呢？ 首先在m a -&gt; m b的函数里面，Haskell无法从m a类型把a提取出来，这样就不能完成需要直接操作a的运算了。 如果我们把m a想成有副作用的a，那能不能把m a当成a来操作，这样定义了a -&gt; b相当于也定义了m a -&gt; m b呢？答案是也不能的，因为还有一个具有另外含义的Monad，如list, Maybe 这个操作有点类似于前面见到过的复合运算(.)，或者($)，他们之间有什么关系呢？ 事实上($)、(&lt;$&gt;)(fmap)、(&lt;*&gt;)(apply)、(&gt;&gt;=)(bind)四个运算符有着相似的性质，在下面的。 为什么要专门拿出来这个操作大书特书呢？ 其实这和Haskell需要实现的纯洁性有关。在看完&lt;-的介绍和下章的内容后会有更深的体会。 Monad根据Wikipedia，Monad具有两个操作，第一个是之前看到的return，另一个是上面的bind return return操作又称为unit，从一个普通类型a构造一个具有类型M a的monadic value bind 这个操作接受一个M a的monadic value，将a从M a类型的变量里面拆出，并传给函数(a -&gt; M b)来，输出具有类型M b的另一个值。有点类似linux里面的管道命令。 此外，之前看到的failure其实都可以作为Monad的一部分，除此之外还有第四个运算符&gt;&gt;。这个运算符实际上是&gt;&gt;=的一个简化版本 (&gt;&gt;) :: m a -&gt; m b -&gt; m b 这个操作的意义实际上也是合成两个操作，起到语法糖的功能，例如a &gt;&gt; b实际上等价于a &gt;&gt;= \ _ -&gt; b，也就是对于任意的a返回常量b。其实do操作也可以看做&gt;&gt;的语法糖 do action1 action2 action3 可以写成 action1 &gt;&gt; action2 &gt;&gt; action3 不过由于没有&gt;&gt;=，do中必须通过下面的&lt;-来从Monad中“提取”值 List Monad和&lt;-在list comprehension中出现了&lt;-这个运算符，例如在下面的例子中，&lt;-从[a]中“提取(feed)”了a： [x | x &lt;- xs] 但是对于do中的x &lt;- item，item是语法分析器，类型Parser Char，而通过&lt;-得到Char类型，这是为什么？其实这和Monad中的&gt;&gt;=是一个道理。在do语句中，&lt;-运算符称为single assignment operator，或binding operator。这个被用作在monadic computation中提取一个值。准确一点说，&lt;-将Monad内的一个计算结果和一个名字绑定，或者可以说&lt;-类似于赋值的等号。例如这里的item是一个Parser a，在提取后得到一个a。这有点类似于C#中的装箱拆箱操作，如果把return当做一个“装箱”，那么&lt;-就可以看做一个“拆箱”。但是必须记住的是，Parser或者后面提到的IO这样的Monad，拆箱操作必须只能通过&gt;&gt;=或等价的do语句执行，这样保证了Haskell语言本身的无副作用性。在&gt;&gt;=里面不需要&lt;-，因为“拆箱”操作由被隐式地实现。观察&gt;&gt;=的第二个参数a -&gt; Parser b，这个a从第一个参数m a中被隐式地提取出来了。而对于do中，我们必须要用&lt;-来显式地提出。 作为补充，提及一下list monad。从上面的讨论中我们可以发现list comprehension和monad中的do语句有着异曲同工之妙。事实上list也是一个monad，我们可以用do来实现list comprehension。 [(i,j) | i &lt;- [1,2], j &lt;- [1..4] ] 对于上面的list comprehension，我们可以使用do来改写 do i &lt;- [1,2] j &lt;- [1..4] return (i,j) Maybe Monad之前提及的Maybe也是一个Monad，我们可以给出如下的定义 return :: a -&gt; Maybe a return x = Just x (&gt;&gt;=) :: Maybe a -&gt; (a -&gt; Maybe b) -&gt; Maybe b (&gt;&gt;=) m g = case m of Nothing -&gt; Nothing Just x -&gt; g x 结论再一次说明，可以看出，这四行首先调用item获得一个x，然后再次调用item，获取并discard掉一个结果，然后再次调用item，获得一个y。最后返回一个tuple(x, y)这类似于Linq中的from-select notation from x in item from dummy in item from y in item select new {x, y} 最后关于Monad，推荐一篇文章 Monad与Continuation从这里开始是我的一些补充。Monad和CPS有一些类似之处，事实上这篇文章中提及了两者之间的关系。 Continuation简介单独列了一篇文章 Continuation MonadFunctor在上章的fmap部分我们了解了函子(Functor)。Functor是一个type class，实际上Functor和fmap是紧密联系的，一个能被mapped over(即能够fmap)的类型即是Functor，我们定义一个Functor f class Functor f where fmap :: (a -&gt; b) -&gt; f a -&gt; f b (&lt;$) :: a -&gt; f b -&gt; f a (&lt;$) = fmap . const 其中fmap有对应的操作符 (&lt;$&gt;) :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b 这里f a称为上下文中的值(in context value)，因为a被f包装了起来。从定义中可以看出，fmap把Functor f a从上下文中的东西拿出来，然后交给一个函数(a -&gt; b)，函数处理完又封装进contextf b中。此外，由于我们的函数是柯里函数，并且-&gt;是右结合的，所以fmap还可以理解为 fmap :: (a -&gt; b) -&gt; (f a -&gt; f b) 即接受一个(a -&gt; b)类型的函数，并返回一个函数f a -&gt; f b，这个函数接受一个Functor f a并返回一个Functor f b，例如 fmap (*2) :: (Num a, Functor f) =&gt; f a -&gt; f a Maybe Functor之前看到的Maybe也是一个Functor instance Functor Maybe where fmap f (Just x) = Just (f x) fmap f Nothing = Nothing Function Functor不过首先来看一个运算符-&gt;，对，就是用来定义函数的。r -&gt; a可以写成(-&gt;) r a。由于type constructor能且只能接受一个参数，所以(-&gt;)不是Functor，但是(-&gt;) r即(r -&gt;)是Functor。既然函数-&gt;是Functor，那就得定义它对应的fmap啊，于是 instance Functor ((-&gt;) r) where fmap f g = (\x -&gt; f (g x)) f (g x)看起来很眼熟，不禁联想到前面的 (f . g) x :: f (g x) 我们是不是可以直接给出如下定义？ instance Functor ((-&gt;) r) where fmap = (.) 于是我们再直接代入一下看看 f :: (-&gt;) r fmap :: (a -&gt; b) -&gt; f a -&gt; f b :: (a -&gt; b) -&gt; ((-&gt;) r a) -&gt; ((-&gt;) r b) :: (a -&gt; b) -&gt; (r -&gt; a) -&gt; (r -&gt; a) (.) :: (a -&gt; b) -&gt; (r -&gt; a) -&gt; (r -&gt; b) 可以发现这个((-&gt;) r)其实等价于composition(.)。 fmap的性质fmap具有下面的性质 fmap id = id fmap (p . q) = (fmap p) . (fmap q) 第一条看起来很简单，第二条讲的是fmap对.有分配律。对于第二条，我们假设另一个Functor X fmap (f . g) X = (fmap f) . (fmap g) X 不妨令f :: b -&gt; c，g :: a -&gt; b首先看左边 fmap (f . g) X :: fmap (a -&gt; c) X a -&gt; X c :: X a -&gt; X c 再看右边 (fmap f) :: f -&gt; X b -&gt; X c (fmap g) :: f -&gt; X a -&gt; X b (fmap f) . (fmap g) X :: (X b -&gt; X c) . (X a -&gt; X b) :: X a -&gt; X c 因此等式成立。在推导的时候需要注意，里面的fmap和.都是函数应用而不是函数定义，带入定义式是不对的。 ApplicativeApplicative定义如下，这里省略了(*&gt;)和(&lt;*)的默认实现 class Functor f =&gt; Applicative f where pure :: a -&gt; f a (&lt;*&gt;) :: f (a -&gt; b) -&gt; f a -&gt; f b (*&gt;) :: f a -&gt; f b -&gt; f b (&lt;*) :: f a -&gt; f b -&gt; f a 先看一看这个东西怎么用吧 &gt; [(2*),(5*),(9*)] &lt;*&gt; [1,4,7] [2,8,14,5,20,35,9,36,63] 在这个例子里面Applicative((&lt;*&gt;))想计算笛卡尔积一样，将一列表的函数应用到另一个列表的整数上，然后列表的长度改变了。首先class Functor f =&gt; Applicative f where，我们知道这里出现在=&gt;前的Functor f是type constraint，所以一个Applicative也是是Functor。这意味着Applicative类型（List、Maybe等）不仅可以当成Functor来用，还具有Functor没有的一些用法。 &gt; (+3) &lt;$&gt; (Just 5) Just 8 &gt; Just (+3) &lt;*&gt; (Just 5) Just 8 &gt; Just (+3) &lt;$&gt; (Just 5) pure可以参照理解成Monad里面的return，相当于我们把一个a打包放到了一个Applicative Functorf a里面。&lt;*&gt;的定义就有意思了。首先查看第一个参数f (a -&gt; b)，这是把一个函数作为type parameter给f。从前我们的Functor里面包含的是值，不过这次里面包含着Function，例如本节开头的例子中，f是List，f (a -&gt; b)便是一个List的Num a =&gt; a -&gt; a函数，所以f (a -&gt; b)在这里被称作上下文中的函数(in context function)。如果把这个函数从上下文中拿出来一看，原来就和fmap的第一个函数一样了。第二个参数是一个Functor f a。然后(&lt;*&gt;)做的事情是把Function从Function Functor中“提取”出来，fmap到第二个Functorf a上，这个fmap就和Functor一致了。为了观察具体流程，下面的代码对比实现了Maybe的Functor和Applicative instance Applicative Maybe where pure = Just Nothing &lt;*&gt; _ = Nothing (Just f) &lt;*&gt; something = fmap f something instance Functor Maybe where fmap f (Just x) = Just (f x) fmap f Nothing = Nothing 首先我们看到(Just f)似乎通过pattern match提取出了f，而Nothing里面并没有任何的函数可以被提取，如果我们第一个参数的类型不是f (a -&gt; b)而直接是a -&gt; b，那我们就不能传入Nothing这样的参数了。可以发现，Applicative的特点是&lt;*&gt;运算符的两边都可以使Applicative，而Functor的特点是fmap/&lt;$&gt;只有第二个参数能够是Functor。 Applicative还有一个性质是Sequencing，也就是我们在本章看到的Monad所具有的性质。它的表现是Applicative Style，也就是对于一个多元的普通函数，也可以通过&lt;*&gt;来应用到多个带上下文的参数中。 pure f &lt;*&gt; x &lt;*&gt; y &lt;*&gt; ... fmap f x &lt;*&gt; y &lt;*&gt; ... f &lt;$&gt; x &lt;*&gt; y &lt;*&gt; ... 注意到pure f、fmap f x、f &lt;$&gt; x是等价的。例如 &gt; (\x y z -&gt; [x,y,z]) &lt;$&gt; (+3) &lt;*&gt; (*2) &lt;*&gt; (/2) $ 5 [8.0,10.0,2.5] 在本节开头，我们接触了List Applicative，[(2*),(5*),(9*)] &lt;*&gt; [1,4,7] = [2,8,14,5,20,35,9,36,63]，下面我们看看居停的定义 instance Applicative [] where pure x = [x] fs &lt;*&gt; xs = [f x | f &lt;- fs, x &lt;- xs] Monoid幺半群(Monoid)即带有单位元的半群，因此幺半群满足封闭性、结合律、单位元 import Data.Monoid class Monoid m where mempty :: m mappend :: m -&gt; m -&gt; m mconcat :: [m] -&gt; m mconcat = foldr mappend mempty Monad和Functor以及ApplicativeMonad是一个Applicative，而Applicative是Functor，所以所有的Monad都是Functor(因为Applicative都是Functor)。这三者有着类似的定义，和各自的独特之处 class Applicative m =&gt; Monad m where (&gt;&gt;=) :: m a -&gt; (a -&gt; m b) -&gt; m b (&gt;&gt;) :: m a -&gt; m b -&gt; m b return :: a -&gt; m a fail :: String -&gt; m a 如果把(&gt;&gt;=)的参数掉个个成=&lt;&lt; (=&lt;&lt;) :: Monad m =&gt; (a -&gt; m b) -&gt; (m a -&gt; m b) (&lt;*&gt;) :: Applicative m =&gt; m (a -&gt; b) -&gt; (m a -&gt; m b) (&lt;$&gt;) :: Functor m =&gt; (a -&gt; b) -&gt; (m a -&gt; m b) 可以发现fmap的返回值都是(m a -&gt; m b)，三者差距在于“定义域”的不同。其中Functor能够接受任意函数，但是(&lt;*&gt;)能接受m (a -&gt; b)（其实这都不一定是个函数），而(&gt;&gt;=)只能接受(a -&gt; m b)。从fmap到(&lt;*&gt;)再到(&gt;&gt;=), 我们对于值的控制力和计算的灵活性逐渐增加, 但这是以结果性质的弱化为代价的。这里的控制力和灵活性取决于是我们传入的函数对m的信息有多少。即使这三个操作符会再接受一个m a值的参数，但m a这个值对其实际的操作者，即传入的函数来说是一个黑箱。 对于fmap来说，我们传入的(a -&gt; b)一点都接触不到m这个东西，m是List，抑或是Maybe，我们的函数根本不需要去考虑，m a的拆箱和结果的装箱，Functor m已经包办了，你自己是一点主都做不了的。 但是对(&lt;*&gt;)来说，我们的函数和值f a一样都是in context的，因此在函数里面我们是知道“容器类型”m是个啥的。例如我们可以知道(&lt;*&gt;)包装的是列表还是Maybe (&gt;&gt;=)比Applicative更进一步的是，它可以自行制定如何将结果包装成m b类型，而这在Applicative都是由具体的instance来规定的。 Derived Primitive 一个判断一个Char是否满足给定谓词(Predicate)的语法分析器 sat :: (Char -&gt; Bool) -&gt; Parser Char sat p = do x &lt;- item if p x then return x else failure 使用sat digit :: Parser Char digit = sat isDigit many :: Parser a -&gt; Parser [a] many p = many1 p +++ return [] many1 :: Parser a -&gt; Parser [a] many1 p = do v &lt;- p vs &lt;- many p return (v:vs) 还有若干代码，这里先告一段落 Monad的性质 All told, a monad in X is just a monoid in the category of endofunctors of X, with product × replaced by composition of endofunctors and unit set by the identity endofunctor. 幺半群(Monoid)在前面已有介绍自函子(Endofunctor)即一个将范畴映射到自身的函子(Functor) do do {e} -&gt; e 一个操作用do包裹起来等于它自己 do {e; es} -&gt; e &gt;&gt; do{es} 这就是前面的&gt;&gt;的语法糖 do {let decls; es} -&gt; let decls in do {es} 这里面用到了let和let...in两个不同的结构块。 &gt;&gt;= return a &gt;&gt;= f = f a 这个性质相当于是将一个普通值a穿上Monad的衣服，传给一个函数f，相当于直接调用这个函数f a m &gt;&gt;= return = m 这个性质是因为对于一个Monad m，m &gt;&gt;= return动作相当于先通过&gt;&gt;=把衣服脱掉，然后在通过return重新穿上Monad的衣服 f &gt;&gt;= (\x -&gt; g x &gt;&gt;= h) ≡ (f &gt;&gt;= g) &gt;&gt;= h Monad相关函数操作Liftingfmap是一个lifting操作，lifting操作一般作用于一个函数，并把它变为另一个相关的函数。 Ch9 Interactive Programs上一章讲了什么是Monad，并了解了一些常见的Monad。通过将Functor和Applicative和Monad比较，我们能看出Monad使用的方便之处。这章进一步讨论了IO Monad，并以此体会Monad的独特之处。IO和上一章见到的Parser一样，都是Monad。我们将只在开始接受所有输入、只在最后返回所有输出的程序称为批处理程序batch program，如果这个程序能够在运行时从键盘等设备获取输入，并将结果写到屏幕上，这样的程序称为交互式程序interactive program。交互式程序是有副作用的，是顺序操作，因此使用Haskell实现交互式程序的难点在于Haskell作为纯函数式语言是没有副作用的（也可以看做是优点），类似于数学函数和批处理程序。为了能够引入IO操作，Haskell借助了Monad这个抽象来描述IO操作，很容易发现Monad带有的Sequencing特性非常适合。Monad将副作用排除在了“纯函数式”之外的另一个世界，我们从代码角度来看，整个IO过程“投射”在Haskell代码的部分是纯函数式，无副作用的，而将副作用投射到另一个“里世界”中，Monad成为了这两个世界之间沟通的桥梁。考虑最简单的一个情况，一个纯交互式程序是没有返回值的，对于“没有返回值”，可以将其定义为IO ()，()在先前提到过，称为unit，是一个空的tuple，类似于C++中的void。这样你就可以在不破坏无副作用的情况下到另一个次元做坏事了。下面我们看看具体的一些函数 基本函数getChar :: IO Char，从键盘读取一个字符，显示到屏幕上，并且作为返回值输出。在C++中，它可能对应着int ::getchar(void)函数，但在Haskell中它的定义并不是一个函数，例如可以写成getChar :: () -&gt; IO Char。教授讲解由于Haskell是lazy的，所以上述的函数形式虽然显得更熟悉一些，但是并没有必要写成这样。在Scala中，函数就是对象，但在Haskell中，我们可以感受到“对象”就是函数，在下面的章节中，我们很快就会看到邱奇编码的概念，展示了如何用函数（lambda演算）来表达数组、元组、整数等常见的数据结构。IO是一个Monad typeclass的实现，它“封印”了IO操作中和副作用相关的部分。putChar :: Char -&gt; IO ()将一个Char打印在屏幕上，不返回值。return :: a -&gt; IO a，接受一个a类型，并返回一个IO a类型。 Sequencing前面提到do语句可以将多个操作合并成一个复合操作。考虑下面的一个do语句 a :: IO (Char, Char) a = do x &lt;- getChar getChar y &lt;- getChar return (x, y) 根据上面的分析，其中x和y是Char类型，return将(x, y)的tuple转变为一个IO tuple类型。这样的do也可以通过&gt;&gt;=来写（在上一章已经了解了怎么用&gt;&gt;来改写do） getChar &gt;&gt;= \x -&gt; getChar &gt;&gt;= \_ -&gt; getChar &gt;&gt;= \y -&gt; return (x, y) Derived Primitives可以从getChar定义getLine getLine = do x &lt;- getChar if x == &apos;\n&apos; then return [] else do xs &lt;- getLine return (x:xs) Haskell中，字符串就是Char的list，下面是和字符串有关的函数 putStr&apos; :: String -&gt; IO () putStr&apos; [] = return () putStr&apos; (x:xs) = do putChar x putStr&apos; xs putStrLn :: String -&gt; IO () putStrLn xs = do putStr xs putChar &apos;\n&apos; 同时我们可以使用foldr来定义putStr函数，这里同样用&gt;&gt;=来代替do表示顺序操作 putStr2 :: String -&gt; IO () putStr2 = foldr (++++) (return ()) where x ++++ p = putChar x &gt;&gt;= \_ -&gt; p 下面是一个求字符串长度的函数 strlen :: IO () strlen = do putStr &quot;Enter a string:&quot; xs &lt;- getLine putStr &quot;Length is&quot; putStr $ show $ length xs 可以看出，Haskell程序解决副作用的方法是将副作用放在执行IO ()时了，但是这个语句对于Haskell本身而言，是pure functional的。注意IO对象是不能够被print的 a = do x &lt;- getChar return x main = print a 这个代码中a通过return返回了一个IO，因此是有副作用的，如果print能够处理，那副作用就“蔓延到”无副作用的代码里面了。所以可以认为IO这样的Monad是有传染性的。如果要实现这样的操作应该借助于&lt;-运算符 f = do x &lt;- getChar return x main = do x &lt;- f print x 或者&gt;&gt;=运算符 f = do x &lt;- getChar return x main = f &gt;&gt;= print Hangman游戏Haskell语言是一个非常好的脚本语言。使用Haskell实现一个猜单词游戏。 Ch10 Declaring Types and Classes观察Monad m a中的m，在这里被用作type constructor，所以m可以是Parer可以是IO，这种higher kinded polymorphic并不是使用type parameter，而是使用一个从type到type的函数(type function)来实现。这种Higher Kinded Types实现的方式是Haskell的一个特别的性质。在Haskell中，我们可以定义具有&gt;&gt;=bind运算，就可以被称作Monad，但是在C#等语言中，没有这样的概念(notion)，有这样的模式(pattern)。 有关type function我们知道普通的函数，例如a -&gt; b表示从类型a的值到类型b的值的一个映射。而type function中，把类型本身当做了“操作数”，即a -&gt; b是类型a到类型b的映射，我们甚至可以把a -&gt; b看做(-&gt;) a b。这两者的概念有点类似type constructor和data constructor的区别。类似于对于普通函数的type(:t)我们可以使用kind(:t)来描述type function。容易理解type的kind是*，而Functor/Monad这些类型类的的kind就是* -&gt; *。有趣的是-&gt;也有kind，即* -&gt; * -&gt; *。 Type Declarationstype语句为一个已有类型提供别名，类似于C/C++中的typedef或using。 type String = [Char] type语句可以拥有参数，所以我们可以把它看做类型上的一个函数，可以发现type level和value level上的函数形式上非常相似 type Pair a = (a, a) pair a = (a, a) 下面是一个mult函数的定义 mult :: Pair Int -&gt; Int mult (m, n) = m * n 很多其他的函数式语言完全模糊了这两者的界限，如Agda、Cayenne这两个类似Haskell的语言，和有关函数式编程本质有关的Coq语言等。还有一个替代的方案叫做lambda cube。介绍Phil Watler（音）的论文。 Type Declaration是可以嵌套的，下面的代码是正确的： type Pos = (Int, Int) type Trans = Pos -&gt; Pos 但是递归是不可以的，显然这会得到一个无尽的定义 type Tree = (Int, [Tree]) Data Declarations使用data语句可以定义一个新的类型 data Bool = False | True 这类似于C#中的抽象类（为什么不是enum哦），或者用来描述上下文无关文法的BNF。 abstract class Bool {} sealed class True : Bool {} sealed class False : Bool {} 这表示我们定义了一个Bool类型，其中True和False是具有一个Bool类型的值的constructor。True和False还可以被称为subtype。在定义类型的时候，type constructor和value/data constructor的名字都应该以大写字母开头。由于True不是类型，所以定义函数的时候不能写成 f :: True -&gt; ... 而只能 f :: Bool -&gt; ... 然后True等constructor可以用来做pattern matching，这称为deconstructing。这看起来像C++中的downcasting f True = ... 使用data定义的类型的值(values)和内置类型的值使用方式是类似的 data Answer = Yes | No | Unknown answers :: [Answer] answers = [Yes, No, Unknown] 注意answers类似于上章遇到的getChar，可以看做一个接受0个参数的函数。在定义type的时候constructor也可以拥有参数（所以上面会理解成抽象类）。如下面的代码所示，我们可以在Shape的定义外部对Circle和Rect进行“特化”。 data Shape = Circle Float | Rect Float Float square :: Float -&gt; Shape square n = Rect n n 由于Haskell很难添加一个subtype到已有的type中，例如想要给Shape加上一个Polygon的subtype是不容易的，但是用上面这种“虚函数”的方式确实简单的。这和C#等OOP语言是截然相反的，OOP的语言往往继承是容易的（假设去掉sealed），但是给一个写好的类里面增改一个虚函数确实不容易的。这是一种难以两全其美的问题，有许多论文研究这点。上面的代码中，Circle和Rect被看做类型Shape的“构造函数”(constructor functions)。特别注意，Circle和Rect是constructor，但不是类型，他们构造出的是Shape类型。 Circle :: Float -&gt; Shape Rect :: Float -&gt; Float -&gt; Shape constructor functions和普通函数的区别是前者不用=来定义(no defining equations)。 同样地，data语句也可以带参数，例如经典的Maybe： data Maybe a = Nothing | Just a 这里教授又讲授了一遍自己prefer list to Maybe的理由，然后其实Maybe和list都是Monad，其实看到这里我还是挺惊讶的。于是不妨推导一下为什么list是Monad：首先介绍一个concat函数，其定义为 concat :: Foldable t =&gt; t [a] -&gt; [a] 为了理解这个定义，可以把Foldable t看做它的一个特例，也就是[]，那么concat就是将一个二维数组拍平 concat :: [[a]] -&gt; [a] 而list的&gt;&gt;=运算，即list &gt;&gt;= f可以理解为等价于concat (map f list) 特别地，对于仅有一个constructor的、一个field的类型，可以使用newtype替代data关键字 data/value constructor和type constructor作为扩展，解释一下data/value constructor和type constructor之间的联系与区别。这其实在stackoverflow上讲得很清楚。两者区别是： data/value constructor可以看做一个返回值的函数 例如本章讲的Circle和Rect，它们都能够返回一个Shape类型的值。 type constructor可以看做一个返回类型的函数 如fmap定义中的f，Monadm a中的m，实际上是产生了一个新的类型。这个有点类似于C++中的模板类，不过Haskell在这方面要更加深层次，我们将在最后的多态性专题进行讨论。 两者联系以data Tree a = Tip | Node a (Tree a) (Tree a)为例。 等式左边的Tree称为type constructor。而Tree a是一个type。 等式右边具有两个data/value constuctor，因此这个data type是多态的。 instance、type和data语句的区别instance根据class定义的type class来产生一个type constructortype用来从一个type constructor产生一个具体类型concrete typedata用来为一个type constructor提供一系列data/value constructor得到value Recursive types使用data语句定义的type可以是递归的。例如我们可以定义一个自然数类型（邱奇数） data Nat = Zero | Succ Nat 这里的Nat是一个新类型，Nat有两个constructor，它们分别具有类型Zero :: Nat和Succ :: Nat -&gt; Nat，由Ch3中学习过的，这里的::表示“具有类型”。于是我们实际可以得到这样的一个无尽序列 Zero Succ Zero Succ (Succ Zero) ... 我们看看能不能输出它 Prelude&gt; (Succ Zero) &lt;interactive&gt;:15:1: error: ? No instance for (Show Nat) arising from a use of ‘print’ ? In a stmt of an interactive GHCi command: print it Prelude&gt; print $ (Succ Zero) 可以先转换成Int nat2int :: Nat -&gt; Int nat2int Zero = 0 nat2int (Succ n) = 1 + nat2int n 然后输出 print $ nat2int (Succ Zero) 下面实现自然数类型的加法，对于C++来说，这意味着定义operator+ add :: Nat -&gt; Nat -&gt; Nat add m n = int2nat (nat2int m + nat2int n) 上面是一个很直截了当的做法，先转换成Int，加完后再转回Nat，有没有不需要借助Int的方法呢？ add&apos; :: Nat -&gt; Nat -&gt; Nat add&apos; m Zero = m add&apos; m n = (iterate Succ m) !! nat2int n 首先想到的是add m n等于n次Succ m，不过这种方法还是需要转换，于是有下面的方法 add Zero n = n add (Succ m) n = Succ (add m n) 我们把n看做常数，将add转换为一元函数g，Succ类比做+1，这就有点类似数学归纳法的味道： g (x + 1) = (g x) + 1 Church encoding和Scott encoding刚才我们看到了邱奇编码的一个常见形式，即邱奇数。邱奇数使用lambda构成的高阶函数来描述自然数。事实上邱奇编码可以用来描述一些很基本的结构，例如布尔值、元组、列表和tagged unions。以邱奇数为例，可以将0表示为\f x.x，1为\f x. f x，2为\f x. f(f x)，因此n可以表示为n F x = ($) f^n x，可以看成一个递归的函数。下面可以借助已有的邱奇数实现加法函数plus(m, n) = m + n，plus = \m n f x. m f(n f x)。这里用到了性质f^(m+n) x = f^m f^n x。 Arithmetic Expressions下面我们来为代数运算的“AST”实现一套类型系统 data Expr = Val Int | Add Expr Expr | Mul Expr Expr 注意我们将所有的代数运算定义到一个Expr类型里面，这是一个“比较Haskell”的写法。我们的代数式可以写成下面这样，从计算一个“函数”变成了构造一个Expr“对象” Add (Val 1) (Mul (Val 2) (Val 3)) 我们使用eval来计算这个Expr，可以写成 eval :: Expr -&gt; Int eval (Val n) = n eval (Add x y) = eval x + eval y eval (Mul x y) = eval x * eval y Binary Tree二叉树由叶子(Leaf)和节点(Node)构成 data Tree = Leaf Int | Node Tree Int Tree 定义了occur用来查找具有某个值的节点 Ch11 The Countdown Problem这次换了一位讲师 Countdown游戏介绍Countdown游戏中使用若干个正整数（每个数最多使用一次），使用四则运算来计算得到一个指定值，其中所有的中间结果也必须是正整数。 Haskell建模首先我们把运算定义成一个Op类型 data Op = Add | Sub | Mul | Div 然后定义一个apply，apply将一个Op作用到它的两个操作数上。 apply :: Op -&gt; Int -&gt; Int -&gt; Int apply Add x y = x + y apply Sub x y = x - y apply Mul x y = x * y apply Div x y = x `div` y 由于游戏中有正整数的限制，所以使用valid来判断某运算是否可以执行 valid :: Op -&gt; Int -&gt; Int -&gt; Bool valid Add _ _ = True valid Sub x y = x &gt; y valid Mul _ _ = True valid Div x y = x `mod` y == 0 下面定义Expr data Expr = Val Int | App Op Expr Expr 相比上一章看到的Expr，这里将Add、Mul等constructor合并成了App(application)constructor。例如1 + 2可以写成 App Add (Val 1) (Val 2) eval函数能够计算一个Expr的值 eval :: Expr -&gt; [Int] eval (Val n) = [n | n &gt; 0] eval (App o l r) = [apply o x y | x &lt;- eval l , y &lt;- eval r , valid o x y] 虽然eval返回的是一个列表，但到最后列表里只会有一个数，除非出现问题列表里一个数都没有。这里eval匹配了Expr的两个data constructor。在第二个pattern matching条件中使用到了Ch5中讲到的list comprehension，特别地，valid o x y称为guard。注意到在eval (App o l r)中，list comprehension右部给出了三个条件，这三个条件只要有一个不满足，这个list就会变成空的。 Brute force solution定义values函数，列出一个表达式中所有用到的数定义exprs函数，得出一组Int能够构造出的所有Expr，这是一个关键的函数 exprs :: [Int] -&gt; [Expr] exprs [] = [] exprs [n] = [Val n] exprs ns = [e | (ls,rs) &lt;- split ns , l &lt;- exprs ls , r &lt;- exprs rs , e &lt;- combine l r] 对于空列表和单元素列表(singleton list)这是显然的。对于多元素有序列表，我们进行divide and conquer。可以用split ns将列表ns进行分划，对于长度为l的序列，我们有l - 1中分划方案。然后我们对于每一个分划(ls,rs)，对其左右部分别递归调用exprs。于是定义split函数，列出一个列表所有的分划得到l::Expr和r::Expr，最后将这两个列表分别合并，得到App Add l r等四个结果。于是可以定义combine函数 combine :: Expr -&gt; Expr -&gt; [Expr] combine l r = [App o l r | o &lt;- [Add,Sub,Mul,Div]] 其中 perms :: [a] -&gt; [[a]] perms [] = [[]] perms (x:xs) = concat (map (interleave x) (perms xs)) 现在我们可以解决这个问题了，我们对于exprs构造出的每个expr，使用eval expr == [n]即可filter出所有可能的结果。注意到我们不一定要用尽给定的数，也不一定这些数就按照从小到大等特定的顺序排列，所以我们需要尝试给出的数的所有子集。于是可以定义choice函数，列出一个列表所有的子集 choices :: [a] -&gt; [[a]] choices = concat . map perms . subs 现在我们可以列举出所有的结果了 solutions :: [Int] -&gt; Int -&gt; [Expr] solutions ns n = [e | ns&apos; &lt;- choices ns , e &lt;- exprs ns&apos; , eval e == [n]] 此外我们还可以判断某输入能否构成一组解 solution :: Expr -&gt; [Int] -&gt; Int -&gt; Bool solution e ns n = elem (values e) (choices ns) &amp;&amp; eval e == [n] 剪枝优化考虑到valid的计算式时很少的，所以可以通过earlier rejection策略进行剪枝。 Ch12 Lazy Evaluationlazy evaluation是Haskell的一个独特的性质 求值顺序以自增函数inc为例，inc (2*3)有两种求值顺序。第一种是intermost call-by-value，先对2*3求值为6，然后计算inc 6；第二种是outmost call-by-name，先计算inc (2*3) = (2*3) + 1，然后再计算6 + 1。接着和C#中的带副作用的impure运算进行比较，说明的求值顺序不同的影响。 下面是一个Church-Rosser证明的定理，如果a可以归约为b和c，那么一定有一个d，b和c可以归约到d。 下面介绍带lambda的情况，如mult (1+2) (2+3)可以归约为mult 3 (2+3)、(\y -&gt; 3 * y) (2 + 3)、(\y -&gt; 3 * y) 5。这里教授讲了一个lambda只有在被apply的时候，才会对其内部的东西进行计算，也就是no evaluation under lambda。 call-by-value容易造成陷入无限循环，因为它必须做完所有的求值。例如fst (0, inf)，设inf = inf + 1，很显然call-by-value并不能结束(terminte)，而call-by-name能够将inf“短路”掉返回0。此外，我们还可以想到之前的无限列表。call-by-name相比call-by-value效率就会低一点了，它需要稍多一点的步骤。 综合两种求值顺序的优点Lazy evaluation通过call-by-name和sharing的方式综合了两者的优点。例如square (1+2)，可以归约为(1+2) * (1+2)，由于这里重复了(1+2)，所以可以使用late binding的原理，进行下面的归约 square (1+2) =&gt; let n = (1+2) in n*n =&gt; let n = 3 in 3*3 =&gt; 6 lazy evaluation依赖于改变计算先后不影响计算结果 bottom下面比较两个函数 filter (&lt;=5) [1..] takeWhile (&lt;=5) [1..] 这两个函数有什么区别呢？在GHCI中运行第一个函数，发现lazy evaluation并没有发生，其结果可以表示为 1: (2: (3: (4: (5: _|_)))) 这里的_|_即⊥，称为bottom，在之前的课程中也出现过，表示something that won’t terminate。而第二个函数则能够正常结束 1: (2: (3: (4: (5: [])))) strict application可以用($!)，称为strict application运算符来强制计算函数的参数 f $! _|_ = _|_ f $! x = f x 对于有多个参数的情形，可以按照以下方法 (f $! x) y -- 强制计算 x (f x) $! y -- 强制计算 y (f $! x) $! y -- 强制计算 x和y 有的时候强制计算的eager evaluation反而是更好的，例如 -- lazy sumWith v [] = v sumWith v (x:xs) = sumWith (v+x) xs -- strict sumWith v [] = v sumWith v (x:xs) = (sumWith $! (v+x) ) xs 这两者的计算结果都是6，但是中间过程会有区别。事实上，strict版本会更加节省空间，因为如果我们对lazy版本展开会发现存在以下两步的推导过程 sumwith (((0 + 1) + 2) + 3) [] ((0 + 1) + 2) + 3 所以在每一步计算中，我们都要维护一个逐渐增长的列表。但是如果使用strict版本，我们实际上维护的只有一个累加值。 Ch13 Reasoning about programs总结与专题论述Haskell的特性 柯里化和高阶函数（包括section） 惰性求值 模式匹配和guard（包括where） 类型系统和多态（包括泛型、类型类、抽象代数类型(ADT)、higher kinded polymorphic、type defaulting等） 具体特性的部分解释可以查看这个网站 Monad（包括ST Monad） 强类型、静态类型 有关多态多态(polymorphism)在C++/Java等面向对象语言中常指子类多态(Subtype polymorphism)，也就是在继承关系中子类可以修改或者扩展父类中的方法，但此时在包含关系上它也被视作是父类型的对象。例如在C++中调用虚函数时会根据当前this的类型查阅虚函数表从而选择正确的函数，这个多态是在运行期的。在Real World Haskell一书中指出Haskell虽然不具有子类(subtype)多态，但它有类型多态和参数多态。类型多态是我们之前提过的higher kinded polymorphic（注意区别higher rank polymorphic），比如Haskell中的列表[]就是类型多态的，因为我们常常可以见到如map这样的函数中出现[a]，也就是说我们不关心a到底是什么，这里的[]也被称为一个type constructor。与此同时我们称map :: (a -&gt; b) -&gt; [a] -&gt; [b]为参数多态(Parametric polymorphism)，因为map接受的参数可以是符合其signature的任意（unconstrained 的）类型的。Ad-hoc多态强调一个值对应于不同类型时拥有分别的定义。显而易见的，函数重载也被视为一种Ad-hoc多态，一个例子是12345678// https://www.jianshu.com/p/b641cf2908cfclass BasicEq a where isEqual :: a -&gt; a -&gt; Boolinstance BasicEq Bool where isEqual True True = True isEqual False False = True isEqual _ _ = False 有关Parametric polymorphism、higher kinded polymorphism和higher rank polymorphism的概念我们将在另外一篇文章中进行探讨。 备注在学习完这本书后，能够对Haskell的关键概念有比较清晰的理解，但是如果需要应用Haskell编程还有一些困难，这时候可以再看看另一本很好的书《Haskell趣学指南》此外，我这个笔记其实有部分的碎碎念，这导致笔记的逻辑可能不太连贯。但是我还是记录下这部分，如果有和我一样在某些地方钻了牛角尖的，至少我这里能给出我的一些见解。 【未完待续】]]></content>
      <tags>
        <tag>Haskell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++右值]]></title>
    <url>%2F2017%2F02%2F11%2FC%2B%2B-rvalue%2F</url>
    <content type="text"><![CDATA[C++11标准引入的是右值引用的概念来方便我们操作右值，但右值的概念是在之前的版本中就有的。在引入右值引用概念后，左右值也被分为左值(lvalue)、将亡值(xvalue)、纯右值(prvalue)。其中将亡值和左值合称为泛左值，将亡值和纯右值合称为右值。左值例如字符串字面量（对，这是左值，因为能取到地址）。纯右值例如整型字面量或者求值结果相当于是字面值或者不具名的临时对象。将亡值包括类似T &amp;&amp; foo()函数返回的右值引用或由std::move强转来的右值引用。将亡值属于泛左值，又属于右值。属于泛左值是由于将亡值作为右值引用是具名的，这和纯右值（如字面量）不一样，所以被视为左值。作为右值是由于将亡值具有可移动性。而将亡值之所以又具名又能移动，是因为它要死了。注意类似T foo()的函数返回值是纯右值。在使用右值和移动语义时容易产生下面的问题： 右值、右值引用之间有什么区别 重载决议中右值引用、左值引用、通用引用有什么区别 右值、(N)RVO之间的关系是什么 移动语义在哪些地方可以提高性能 右值与右值引用左值是不能绑定到右值引用的，如下面的代码是错误的123456789101112// code 1int i = 42;int &amp;&amp; ir = i; // error// code 2int test(int &amp;&amp; ir)&#123; // ...&#125;int main()&#123; int i = 42; test(i); // error&#125; 正确的做法是使用std::move()函数将它转换成一个右值，而这个函数实际上就是调用了static_cast进行一次强转，得到的是一个将亡值xvalue。将亡值表示在逻辑上当做右值来用的左值。查看下面的代码，发现编译错误，为什么？1234int main()&#123; int &amp;&amp; i = 42; test(i); // error&#125; 42是右值，但i是个右值引用，右值引用并不等于右值，它和引用类型、指针类型一样，属于一个新的类型，通常被认为是左值，一个右值引用能够接受一个右值，而一个左值引用不能绑定到一个右值，这是区别。在绑定之后，i是个具名对象，是个左值。 函数返回右值与(N)RVO什么是RVORVO不能解决callee内部的临时对象的问题，考虑下面的代码12345678X fun()&#123; X x1; // ... return x1;&#125;int main()&#123; X _x = fun(); // RVO&#125; RVO的目的是fun()的返回值在main中不会产生一个临时对象，但并不会优化掉fun中的x1。 什么是NRVO12345678X fun()&#123; X x1; // ... return x1; // NRVO&#125;int main()&#123; X _x = fun();&#125; 别忘了编译器并不一定会进行NRVO，例如编译器遵循下面一些规则： return的类型和函数签名中的返回值类型相同 return的是局部变量 条件语句返回时会抑制NRVO 使用移动语义从函数返回12345678X &amp;&amp; fun()&#123; X x1; // ... return std::move(x1);&#125;int main()&#123; X _x = fun();&#125; 这似乎“替编译器做了”RVO同样的工作，这是一个比较好的实践么？事实上这是大错特错的。首先x1是一个自动变量，它在栈上，它的生命周期到fun函数结束就终止了。std::move将x1强转成X &amp;&amp;返回，然而到了调用者main那里，x1对象早已被析构了，这个右值引用X &amp;&amp;和相应的左值引用X &amp;、悬挂指针X *一样，对该对象的生命进程是无能为力的。因此不要返回局部变量的右值引用。在StackOverflow上有关于Best Practice的讨论唯一能正常运行的代码是这样的12345X fun()&#123; X x1; // ... return std::move(x1);&#125; 在这段代码中，从函数签名上来看，我们返回的不是右值引用，而是一个对象了；但是从return语句上看，我们返回的是一个右值引用，因此阻止了编译器执行NRVO。因此这个std::move除了潜在地暗示编译器不要进行NRVO外并没有任何作用。在上面的讨论中我们知道x1自动变量并没有得到续命，我们返回的是通过X的移动构造函数创建的一个新临时变量X{std::move(x1)}。如果要返回的对象定义了一个良好的移动构造函数，那么使用这种方式返回一个非局部变量尚可一议，否则最佳的实践是直接依赖编译器提供的NRVO。12345X fun()&#123; X x1; // ... return x1;&#125; 使用移动构造如果要根据一个对象创建另一个对象，传统的方式是调用复制构造函数12X a&#123;b&#125;; // orX a = b; 让我们重新考虑之前的代码1234567891011121314151617X fun()&#123; X x1; X()&#123; puts("default constructor"); &#125; X(const X &amp; _x)&#123; puts("default constructor"); &#125; ~X()&#123; puts("destructor"); &#125; // ... return x1;&#125;int main()&#123; X _x = fun();&#125; 现在我们知道，由于(N)RVO的存在，这段代码中实际上值调用了一次默认构造函数。 虽然右值引用的“光辉”常被(N)RVO掩盖，但其能够对资源移动行为进行更精细化的定义。进一步看，右值包括将亡值和纯右值是一个临时的、字面的，或者即将被销毁的对象，在一定程度上它是可有可无的。因此我们有了移动构造函数和移动赋值运算符，现在我们需要构造我们的对象，如果别人传进来一个左值，那我们只有老老实实地调用复制构造或者复制赋值，但现在如果别人传进来一个右值引用T&amp;&amp; other，那就是一个赤裸裸的暗示，“我现在没人要，你可以来掏空我啦~”。所以移动构造或者移动赋值就会直接掏空other，因为它知道other没人要了。但我们同样需要注意在之前的讨论中提到的，在等号右边接受一个X &amp;&amp; fun()的返回值这样大错特错的使用方法，我们会在下文中进一步讨论。123456789101112struct A&#123; A(A &amp;&amp; a) : p(a.p) &#123; a.p = nullptr; &#125; ~A() &#123; delete p; &#125; int * p;&#125;; 查看上面的代码节选，右值引用A &amp;&amp; a接受并绑定到一个右值，移动构造函数将a持有的指针a.p直接取出来，然后将其设为nullptr。这一步是非常重要的，因为如果不设为nullptr，在a销毁时会执行delete p，那么this好不容易从a那里掏来的p就会被销毁，this-&gt;p会变成悬挂指针。这样，传进来的右值a里面的东西通过了this的皮囊得到了续命。而this也避免了调用一个拷贝构造函数的开销。 类似地我们可以写出这样的代码1234X fun()&#123; ...&#125;int &amp;&amp; x = fun(); fun返回值的生命在x中得到了延长。但在cppreference的value_category词条上我看到了这样的阐述：右值可以用于初始化右值引用，这种情况下该右值所标识的对象的生存期被扩展到该引用的作用域结尾。由于将亡值也是右值，所以是不是下面的代码中也存在续命呢？1234567891011// case 1X &amp;&amp; fun()&#123; X x1; return x1;&#125;int &amp;&amp; x = fun();// case 2X get_x()&#123; return X&#123;&#125;;&#125;int &amp;&amp; x = std::move(get_x()); 首先看case 1，x1的什么有没有通过x得到延长呢？就算是延长了，也是延长了fun()的返回值的寿命，而不是fun里面的x1得到了延长，作为自动变量，x1是肯定要在栈上被销毁的。如果我们加上了一次隐式转换，可以发现这和之前在NRVO讨论的情况是一样的，自动变量只会被销毁。此外，在StackOverflow中我找到了答案，它阐释了cppreference的论点，因为有一种叫dangling reference的东西，如果将xvalue绑定到rvalue reference上就可能会产生这个。这也说明了为什么函数返回T&amp;&amp;是危险的。对此SOF上还有进一步的讨论。综上所述，当fun返回一个prvalue时，用T &amp;&amp;来续命是合法的。 注意，我们虽然定义了移动构造函数可以从old_x构造new_x，但是old_x和new_x在地址上仍然是不同的，例如被移动对象指针被其他对象持有的话，同样会发生错误。这是因为move语义并不是单纯的“移动”，而是通过默认或自定义的移动构造等函数掏空对象的过程。 pass by value，pass by const reference，还是pass by rvalue referenceEffective Modern C++中指出在需要copy的情况下，与其传const T &amp;不如直接传T。我们查看SoF上的一个例子。提问者认为1需要copy一次再move一次，而2只需要copy一次，为什么1的效率会更好。回答指出2中的copy可能不一定发生，这是由于对临时对象可能做copy elide的缘故。1234// 1. Better than 2Dog::Dog(std::string name) : _name(std::move(name)) &#123;&#125;// 2. Not badDog::Dog(const std::string &amp;name) : _name(name) &#123;&#125; 在爆栈网中讨论了是通过值还是右值引用来传递lambda。首先这里的“右值引用”实际上是通用引用，而在非传递副本的语境下，传递通用引用可以实现完美转发（将在后面介绍），而传递值并不会造成复制开销，因为编译器会进行优化。特别地，当我们创建一个lambda时，它是一个临时对象，因此我们不能将一个左值引用绑定到它，如auto &amp; f = [](){}是不正确的。 拷贝构造函数与移动构造函数的关系如果一个程序中显式定义了拷贝构造函数，编译器便不会合成移动构造函数。这会造成下面的效果，如果程序中没有定义移动构造函数，那std::move会调用拷贝构造函数。 将移动构造函数声明为noexceptnoexcept在C++17标准中成为了函数类型的一部分。通常来说应该将移动构造函数声明为noexcept。特别是当你的类型会和STL中的容器一起用时，如果移动构造函数不是noexcept的，那么容器会调用复制构造函数。一个类似的考虑是是否需要将拷贝构造函数设为noexcept。 标准库容器中的右值在C++11后，诸如std::vector&lt;T&gt;的容器的push_back方法也能接受右值了，这样他们会直接移动我们传入时创建的临时对象。不过更有效的方式是使用另一个添加的emplace_back的方法。这个函数直接免去了创建临时对象的成本，而直接在原地进行构造，一如我们的placement new的行为一样，它调用std::allocator_traits::construct这个函数来创建对象。 有关右值引用的类型推导注意在使用decltype(t)时，如果t是一个右值引用，那么推导出来的类型需要std::remove_reference_t&lt;decltype(t)&gt;一下才可以使用。 通用引用和完美转发完美转发是来自于C++的引用折叠特性，也就是右值引用叠加到右值引用，还是右值，其他所有引用类型的叠加会变成左值。通用引用是针对模板编程的一个概念，当T是一个模板参数（这个强调的是T是要被推导的）时，T&amp;&amp;是一个通用引用。 辨析在CFortranTranslator的ImpliedDo实现中，我们发现将构造函数的F func改成F &amp;&amp; func就会编译错误：1error: cannot bind ‘io_implieddo2_Test::TestBody()::&lt;lambda(const fsize_t*)&gt;::&lt;lambda(for90std::fsize_t)&gt;::&lt;lambda(const fsize_t*)&gt;’ lvalue to ‘io_implieddo2_Test::TestBody()::&lt;lambda(const fsize_t*)&gt;::&lt;lambda(for90std::fsize_t)&gt;::&lt;lambda(const fsize_t*)&gt;&amp;&amp;’ 其实这对应了Effective Modern C++ 条款24中的一个case，也就是模板类的成员函数实际上没有经过推导，所以实际上是右值引用12345class vector&lt;Widget, allocator&lt;Widget&gt;&gt;public: void push_back(Widget&amp;&amp; x); // rvalue reference ...&#125;; Reference https://www.zhihu.com/question/302399669/answer/531401332]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode解题报告]]></title>
    <url>%2F2017%2F02%2F09%2FLeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A%2F</url>
    <content type="text"><![CDATA[寒假没事情，在家里刷Leetcode。这里放的是LeetCode解题报告【更新中】，代码在GitHub上，有些被坑的题目会专门写一篇post。必须先对Leetcode吐个槽，这复杂度卡的真是魔幻，同样的复杂度C++能过，Python就不能过，而且都是卡在最后两三个样例上（不会就最后两三个大数据吧？）Leetcode上面有题解，不过有时候很奇怪他们算复杂度的时候会强行令某些操作，比如判断字符串是否相等(Problem 14)，std::map查找元素(Problem 1)的复杂度为1，感觉这并不是很严谨的，后来在Google Codejam/Kickstart的官方题解上也看到类似的算法，只能说这是一种计算方式吧。在刷Leetcode的时候，取得Accepted通常是容易的，但是如果能够翻翻Submissions里面速度靠前的答案，看看人家是怎么在同复杂度下进行常数优化也是很有必要的。 1. Two SumK-Sum经典题目，给定一串序列，找到a+b等于给定的n。$O(n^2)$要T的，正解对任意的i，判断target - i是否在集合s中，如果不在，把i加到集合s中。注意因为Python中dict用散列表实现，所以查询复杂是$O(1)$的，这和C++中的std::map（RBT实现）不一样。另外考虑如果给定数列是有序的，还可以使用二指针来做，这个在下面的3Sum等中非常常用了，因为sort的复杂度是$O(nlogn)$，可以直接忽略不计了。测试了一下，如果对这道题先sort一下，居然速度要快十倍。 2. Add Two Numbers链表比较麻烦，注意在两个链表全部遍历完毕后检查是否还有进位 3. Longest Substring Without Repeating Characters计算最长不重复子串从头开始遍历字符串S，记录字符S[i]出现位置到ex中。若ex[S[i]]已存在，即字符S[i]在ex[S[i]]（前出现）和i（后出现）出现过，这时候我们的最长长度便不能继续增长了，尝试用字符串S[start, i - 1]来更新最长字符串，并令start = ex[S[i]] + 1，即从S[i]前出现的下一个位置开始重新计算最长长度。这时相当于把字符S[i]从前出现移到了后出现，因此ex[S[i]]需要被更新到当前的i。有个注意点，在更新start的过程中，我们实际上重复利用了[ex[S[i]] + 1, i]这段肯定不重复的序列，包括它们的ex值，但同时我们也舍弃了[start(原), ex[S[i]]]这区间，因此在下面的遍历过程中如果字符ch对应的ex[ch]值出现在这段区间中，那实际上应该等同于它未出现处理。 4. Median of Two Sorted Arrays见文章 5. Longest Palindromic Substring马拉车算法模板题 6. ZigZag Conversion对模numRows * 2 - 2讨论 7. Reverse Integerpython转成string在转回int强行干 8. String to Integer (atoi)看图说话题 9. Palindrome Number通过整除和取余算出倒过来的数，比较和原来的数是否相等 10. Regular Expression Matching编译原理复习题，撸个DFA。这里注意一下对.规则的处理，虽然NFA比DFA多了ε规则，但是NFA对于一个某个输入符号的下一个状态是确定的。而对于.*c这样的规则，如果读取到c，那么可以仍然在本状态，也可以通过c到下一个状态，因此是冲突的，要向前看一个字符。在本题中因为字母表就在[a-z]上，于是添加26条规则就可以了。实际上可以DP搞 11. Container With Most WaterWA了n次，原来是和HDU1506直方图中最大的矩形面积搞混掉了，这个不要求连续。不会O(n)算法，看了答案发现也是DP。主要原理是对于令i, j分别为数组的左右边界，显然这样的容器最宽。把i, j相对移动，要想还比它容积大，就要比它高。于是对于任意的ii, jj，如果height[ii] &lt;= height[i]或height[jj] &lt;= height[j]那就不行了。注意不是height[i + 1] &lt; height[i]，这样遇到两个都不满足的情况就死循环了。 14. Longest Common Prefix看名字想到后缀数组，然而并不是。直接O(nm)暴力就可以了，也可以用二分，还不如直接暴力 15. 3Sum乍一看以为是01背包，然而并不是，看题目应该是和第一条类似，暴力就行了。于是照搬第一条撸了个$O(n^2)$的交上去，居然T了，看了一下T在倒数第二个点，卧槽还卡常啊。查看题解，把对j的循环和仿照2Sum的使用dict查k去掉改成双指针夹逼法。这个方法在于遍历每个i，然后对剩下的两个数j和k从j = i + 1，k = n - 1开始相向搜索。不过这次还是还是超时，根据这里的解释：But according to my submissions, this way will cause you double your time consuming almostly.，可能是我取unique拖慢了（然而排序后求unique是O(n)的啊）放一张图 16. 3Sum Closest这k-Sum的题目没完没了了。这道题也是先排序，然后双指针相向移动，同时用update函数维护一个best表示最优解。 17. Letter Combinations of a Phone Number问手机九宫格键盘上的若干数字总共能构成哪些字母，直接暴力模 18. 4Sum先放这儿吧。。 19. Remove Nth Node From End of List链表的基本操作，维护[before, begin, end]三个指针即可，注意head被删除的情况。 20. Valid Parentheses开一个栈维护就行了，注意pop的时候要先判断是不是空栈 21. Merge Two Sorted Lists归并两个数列，手残忘了cur = cur.next，然后又RE了，原来是注释的预定义部分自己不要附上去 22. Generate Parentheses卡塔兰数C(n)也表示所有在n*n格点中不越过对角线的单调路径的个数，所以直接递归搜索就全部能列出来。 23. Merge k Sorted Lists一开始是硬上21条的解法，结果T了。假设n个列表中总共有p个元素，那么外层的while循环一次添加一个元素，共O(p)次，内层的for循环是一趟n次。这种算法复杂度上限是O(p*n)。Leetcode上的top解法是(C++)调用n-1次的MergeTwoList，归并一次的复杂度是两个列表长度之和，所以这种复杂度上限依然是O(p*n)。以上两种做法Python全被卡常卡掉了（而且卡在最有一个样例，那你告诉我为啥你不也把C++卡掉）。正解是二分分治对这k个List归并，这样可以优化到O(p*logn)的复杂度。另外也有大佬直接上堆排了，我也是服 24. Swap Nodes in Pairs又是链表题，直接记录[before, begin, end]交换就行了。标算是递归，我用的迭代，迭代在更新end时要注意begin为None的情况 25. Reverse Nodes in k-Group链表逆置问题 26. Remove Duplicates from Sorted Array两个指针，i用来遍历，j用来维护插入位置即可，注意到i始终是要比j快的，所以不会产生覆盖的问题 27. Remove Element同26 29. Divide Two Integers不使用乘除和模实现整数除法，这里也不使用加减法 使用位运算实现整数加减法两个比特$x (b)$和$y (b)$相加，结果需要两个比特来盛放，可能为$00 (b)$、$01 (b)$、$10 (b)$。注意到高位的比特值为$x \, and \, y$的结果，而低位的比特值为$x \, xor \, y$的结果，于是整个结果是$(x \, xor \, y) \, or \, (x \, and \, y)$ 减去一个数等于加上这个数的补码 使用加减运算实现整数除法这里需要使用快速幂的思想，减去小于被减数$a$的尽可能大的$b \times 2^n$。这里注意的是Python中的Integer是没有范围的，所以不能使用补码等运算，对于溢出的情况也要专门判断。 1return min(max(-2147483648, res), 2147483647) 30. Substring with Concatenation of All Words题目中一个不和谐的点是字典中的所有的字都是一样长的。这个条件有点强啊。写了一发暴力搜，也就是从i开始查看能否得到合法的子串。WA了一发发现字典中可能存在重复的字，这就说明要在提出的s的子串中出现两次。果断T了。后面就是利用这个一样长的条件，这意味着我们可以不要从所有的i开始搜。我们令所有词的长度都是l。那么我们只需要从[0..i)位置开始按词搜索就行了。我们用st维护我们搜索的起点，用used维护目前已经找到的词。那么如果我们在j处成功，那么就执行j += l，将j指向下一个词（因为后面仍然可能有符合要求的）；如果我们在j处失败，也就是出现了不在字典d或者多于字典d中的词时，就执行st += l右移一个词，并且从used中移除原先st对应的词。特别地，我们要维护st不能超过j。 31. Next Permutation在我的某篇文章里讲过直接求nth perm的做法这道题目首先是找规律，还是挺有意思的。我们从倒数第二个数开始倒序取i，不断尝试把nums[i]与其后面满足nums[j] &gt; nums[i]的最小的nums[j]交换。实际上我们要一个在尾部的最长的下降序列[i-1, end)。我们应当从尾到头找，因为i位置后数列一定是降序的，否则i + 1位置时算法就应当结束了。交换完后，我们将i位置后的序列片段按升序排列好（这时候该片段是最小的）便得到了最终答案。如果没有的话我们令i--继续循环。 此外，Python2里面的list切片是返回的一个新list而不是引用，写代码的时候被坑了次。 32. Longest Valid Parentheses好像17年哪个公司的笔试题里面出现过这一条的。简单的思考了下，这条是DP。我们令dp[i]表示字符串在i位置最长括号串的左边界，初始化为dp = range(i)。因此对于每一个s[i] = &#39;)&#39;，我们从j = i - 1开始根据dp[j]往前跳转，直到dp[j] == j，此时我们看s[j]是否为&#39;(&#39;即可。注意最后还要根据dp算一个ans，否则()()这种情况就是2而不是4了。写的时候很粗心，WA了n次。 33. Search in Rotated Sorted Array先二分一次找到第一个比arr[0]小的点，也就是唯一一个下降点，以此点将串一分为二，对两边数组分别进行二分 34. Search for a Range同样是二分两次，第一次找到最左边边界，第二次找到最右边边界 35. Search Insert Position简单的二分 37. Sudoku Solver使用回朔法求解，代码修改自我的github在修改代码时类back_solver方法和里面的solve_iter在返回结果res时出现了为None的问题，后通过改为self.res解决。 39. Combination Sumdfs即可 40. Combination Sum II解法类似，这次每个数只能使用若干次 41. First Missing Positive在一个无序列表中找第一个没有出现的正整数。这是一个很有意思的桶排序的题目。遍历数组，使用$h(x) = x - 1$将值为$x$($0 &lt; x &lt; length$)的数与$x - 1$位置上的数进行交换，这样经过$O(n)$后数组便会变成有序的。 42. Trapping Rain Water看上去类似于第11题。首先先想naive的$n^2$解法，对于每一个位置i，分别寻找其左右侧最高的柱子l[i]和r[i]，那么i处水柱的“海拔”是min(l[i], r[i])。显然我们发现寻找左右侧最高的柱子这个过程可以DP。下面使用HDU1506直方图中最大的矩形面积的方法进行dp优化。其原理是如果j+1处水柱比j处的高，那么它肯定比r[j+1]处水柱高。 43. Multiply Strings大数相乘，瞎搞一下就行 44. Wildcard Matching类似第10题，可以通过DFA来做。这里使用DP来做 45. Jump Game II青蛙跳，给定数组nums，nums[i]表示在i位置能跳的最远距离，求达到最后坐标跳的最小次数。不禁想起悲惨的LCM Walk推公式题。记到i点的最少步数是l[i]，这条naive的方法自然是对于每一个i，用它来尝试更新自己的跳跃距离范围[i, i + nums[i]]内的所有的l[j]，这样是个$O(n^2)$的复杂度，会超时。查看题解，实际上这是一个贪心问题，我们使用l记录跳s步达到的最远距离，这说明数组整个[0..l]片段至多s步便能到达。使用r记录跳s + 1步达到的最远距离，显然r &gt; l。下面我们对于每一个i，查看它需要用几步才能到达，期间需要同步更新l和r： 正常情况如果说i小于等于l，这说明i肯定是能够在s步内达到的。下面我们要尝试更新r。i位置能够达到的最远范围是nums[i] + i，这说明如果我们在s + 1选择在i位置跳，那么能够覆盖[i, i + nums[i]]这段距离。因为i &lt; l，所以在i位置跳能够覆盖[0, i + nums[i]]这段距离，我们用它和r取大值来更新r，如果需要记录起跳点p[s + 1]，这时候也应当同时使用i比较更新。 额外情况如果i大于l，即跳s步肯定不能达到了，就必须多跳一步了，此时总步数变为s + 1。这种情况是可能发生的，虽然我们遍历i是一次一格，跳是一次若干格，但遍历到i时可能已跳次数s远少于i。我们来看看跳完这s + 1步后能够达到的最远距离是什么呢？答案是i - 1位置时的范围[0, r]，起跳点p[s + 1]在小于等于i - 1的某处。如果r &lt; i的话，那么终点便是不可达的，但题目中保证了终点可达。所以我们用r来更新l。接下来，i小于等于l，我们按照正常情况继续处理。 46. Permutations47. Permutations II我这里使用了字典来维护重复的数，在Leetcode里面我看到了一个较为巧妙的处理重复的方法1234for(int i=0;i&lt;nums.length;i++)&#123; if(used[i]) continue; // 在同一个循环里面，如果i位置的值和i-1位置的值相同，而i-1位置的数没有被使用，那么i位置肯定也不会被使用 if(i&gt;0 &amp;&amp; nums[i-1]==nums[i] &amp;&amp; !used[i-1]) continue; 48. Rotate Image这让人联想到$O(1)$空间转置矩阵的题目，但本题是顺时针旋转而不是转置。由旋转公式得$ \begin{bmatrix} x \\ y \end{bmatrix} $变成$ \begin{bmatrix} y \\ -x \end{bmatrix} $。如果把这个变换看成两个变换的组合，第一个是关于次对角线的对折，第二个是关于横轴的对折，那么代码会更容易写，因为不要想inplace矩阵转置一样需要考虑一个链的问题了。这里注意一下python的列表生成器可以使用两个循环变量，如[(x, y) for x in xrange(m) for y in xrange(m - x)]，但注意x一定要在使用前有定义。本题也可以使用矩阵转置的方法来做。以3行3列的矩阵为例，将其按行展开为一维数组。得到三条变换链：0-2-8-6-0、1-5-7-3-1、4-4。容易发现对于每个链，我们用前一个位置的值给后一个位置赋值即可，如2号位的新值为0号位的旧值。不过我们还要防止重复遍历链，例如我们首先以0号位为链头遍历完第一条链，以1号位为链头遍历完第二条链，但是位置2已经在第一条链中遍历过了。为了解决这个问题，我们在位置i处要确定是否要以这个位置作为新链的链头，例如我们以2位链头开始遍历，发现在2-8-6-0-2的序列中出现了位置0是小于2的，这种情况是不可能的。容易发现每条链的链头都是这条链中位置号最小的元素，这是因为我们是从0开始按顺序以每个位置作为链头的。 49. Group AnagramsAnagrams指的是将原单词或短语字母打乱顺序，形成新的单词或短语，如“Tom Marvolo Riddle”变成“I am Lord Voldemort”这道题将单词的每个字母sort作为key，然后用dict记录每个key拥有的所有单词，最后遍历输出即可。 50. Pow(x, n)快速幂模板题 51. N-Queens在Submission里面看到有人用位运算（因为Python里面int无限大所以都不需要bitset）来搞的 52. N-Queens II受上题影响这次用位运算搞一波首先同样是按行搜索，每一行尝试放一枚棋子，递归深度$O(n)$。 53. Maximum Subarray这是一个经典的动态规划问题。由于在每一点i都可以选择继续延伸之前的串（其和为acc）或者打断重新开始。明显当acc + nums[i] &gt;= 0时保留之前的串是有增益的，否则就打断重来。使用m维护历史上最长的串的长度。 54. Spiral Matrix这条题目我思路不够清晰，主要是找规律发现数列+(n-1), +(m-1), -(n-1), -(m-2), +(n-2), -(m-3), -(n-3), ...，对第0项特别处理，然后x、y往下递推即可。查看题解发现思路更便捷一点，它的想法是依次循环将最上、最右、最下、最左的行/列添加入ans数组中，每次添加完后更新指针。终止条件是上下界或者左右界溢出。在discuss里面还看到一个骚气的Python解法，这个感觉就像我们把梨子拿在手上一边转一边削梨子一样。其中zip(*matrix)实际上转置了矩阵，如[[1,2,3], [4,5,6]]变成[(1, 4), (2, 5), (3, 6)]。而zip(*matrix)[::-1]实际上逆时针旋转了矩阵。12def spiralOrder(self, matrix): return matrix and list(matrix.pop(0)) + self.spiralOrder(zip(*matrix)[::-1]) 这里似乎在Python二维数组切片上遇到了坑，对二维数组a进行数组切片a[1:2][0]返回的是一个二维数组，而不是一维数组。由此我们看出，在写题时要是能做到先动脑，再动手，那么是事半功倍的 55. Jump Game同45，这次只要输出能否到达。 56. Merge Intervals首先是区间合并的原理，假设两个区间$(l, r)$和$(l2, r2)$，令$l2 \ge l$，则当$r \ge l2 \ge e$时区间能够合并。因此，首先对intervals数组按照左边界大小排序，然后从头开始遍历该数组，每次试图运用上面的规则合并区间。如果不满足上面的规则，那么先前已合并了的区间就是最大的区间了，将其添加入结果数组中，并对下面的数组重新开始运用该规则。 57. Insert Interval这道题一开始想用二分，不过写砸了，因为可能原先的区间也要合并一部分。后来直接O(N^2)解决了。 58. Length of Last Word简单题，注意要strip下 59. Spiral Matrix II这条是简单的模拟，分为4个方向，长度从l - 1到0，注意0是一个合法状态。 60. Permutation Sequence类似next_permulation函数，见POJ 1037这篇文章 61. Rotate List链表题，看图说话 62. Unique Pathsm - 1个向右和n - 1个向下自由排列共有$\frac{(m + n - 2)!}{(m - 1)! (n - 1)!} $中方案 63. Unique Paths II二维dp模板题注意初始化二维数组时不要犯[[0] * 5] * 3的常见错误，最好用列表生成器 66. Plus One处理一下进位即可 67. Add Binary见29 69. Sqrt(x)二分即可，注意取整 70. Climbing Stairs第i级可以从第i - 1级过来，也可以从第i - 2级过来 72. Edit DistanceDP是肯定的，定义数组dp[m][n]，dp[i][j]表示word1[1..i]和word2[1..j]的编辑距离，从1开始方便后面边界。首先要先确定添加、删除和替换三个操作对应到状态转移上，这容易想到对于word1来说，删除i位置意味着忽略i位置对结果的dp[i][j]的影响，所以是 dp[i-1][j] + 1，其中+ 1是删除的成本。其他两个操作可依次得出。当word1[i-1] == word2[j-1]时dp[i][j] = dp[i-1][j-1]不能漏掉。然后还要确定递归边界，不只是dp[0][0] = 0了，也要设定dp[i][0]和dp[0][j] 73. Set Matrix Zeroes根据Follow up的要求，一个使用$O(mn)$的方法是遍历一遍matrix，然后将0的格子全部填好，最后and下一个使用$O(m+n)$空间的方法是遍历一遍matrix，然后对每个0格子，标记其行号和列号，最后把所有的被标记行列全部置零最好的是$O(1)$方法，把这$O(m+n)$的空间移到matrix的第0行和第0列上。注意整个过程不是迭代的，如果一个格子被设为0，它不可以再将自己所在行列设为0。特别是第0行列的清空工作一定要在最后完成。 74. Search a 2D Matrix按行二分 75. Sort Colors根据Follow up要求，需要一趟遍历搞定。解法如26题，这里使用三个指针，i负责遍历，l维护0值区间$[0,l)$，r维护2值区间$(r, length-1]$，注意到整个过程中$i \gt l$且$r \ge l$。使用多指针维护插入位置是一个常用的方法，在三向快速排序中也有用到。题解给出了四种方法 76. Minimum Window Substring感觉有点像3，不过这道题需要考虑每个字符的数量，如minWindow(&quot;a&quot;, &quot;aa&quot;)结果是&quot;&quot;不是&quot;a&quot;这一条的思路是先找到T的匹配，然后试图移动窗口的左边界，使得匹配最小当d[ch] == cd[ch]而不是d[ch] &gt;= cd[ch]时自增计数器，这样能够保证每个不同字符在达到规定数量时刻只会被统计一次（由于先保证有匹配，再保证匹配最小，所以每个字符数量一旦达到规定数量后就会一直保持在规定数量之上）。 77. Combinations这条递归容易写T，不能新建list，题解使用了里面数组生成器，涉及到它的一些的性质。 78. Subsets此题有非递归解法123res = [[]]for i in nums: res.extend([[i]+x for x in res]) 此外对于C++可以借助于位运算的性质来做123for(int i=u; i; i=(i-1)&amp;u)&#123; // bit map i to array&#125; 81. Search in Rotated Sorted Array II要求在一个旋转了的有序序列中查找是否存在某项。相比之前那一题，现在允许重复了。同样，我们要去寻找序列里面存在唯一一个下降点。我们讨论一下新的二分情况 arr[l] &lt; arr[r] 则下降点只可能位于[r, ]，类似[5,6,7,5]中r为7 arr[l] == arr[r] 则下降点位于内部，类似5,6,7,5中r为5。 有个特例是当l==r时，两个必然相等的。 arr[l] &gt; arr[r] 下降点只可能出现在[l, r]区间内部，如[6,7,1,2] 注意，这一条有个corner case就是[1,1]，很难找到splitter。特判一下这种情况，返回0就行。 82. Remove Duplicates from Sorted List II简单题 84. Largest Rectangle in HistogramHDU1506老题新做 85. Maximal Rectangle这似乎是我做过的NUAA-HHU的一条赛题啊，典型的二维DP，不过实际上细节还是比较多的。思路就是从左、右、左上角三个位置DP，其中左右是最优化最长的宽为1的“条”，左上角向下拓宽是要同时考虑dp[i-1][j-1]形成的矩形的左边界以及i行的左边界取大值，向右拓宽同理。题解是借助于Largest Rectangle in Histogram的思路做的，可以参考 86. Partition List简单题 87. Scramble String一开始觉得这道题可以形成所有的排列，于是统计字符数量1WA。后来重新理解了题意，原来是树只能建一次，然后可以不停调换。显而易见这种变换有一个性质，如果我们选择一个分割点，我们便能够将其分为左右儿子，之后的调换顺序只会改变左右，不会影响分组，于是我们想到递归地枚举所有的分割点，这样可以先递归判断子树是否是Scramble的。将原问题分解为子问题（子树）的时候需要考虑两种情况，即如果我们对s1枚举到分割点为i时，那么对应到s2可以在i和len - i处分割。这条击败的不多，常数优化有待完善。 89. Gray Code格雷码，公式忘了，可以用三位找规律，注意格雷码是不唯一的 90. Subsets II这一条就是加上了去重，也没啥花头，毕竟要全部列出来嘛，那我还不如直接借助于set来判定了。不过似乎go不能够使用list作为key。那就用str并编码一下咯。。。。另外一种方法是排序，然后统计相同值的有多少数，例如有l个，那么对于每个现在已有的结果，都分别加上1到l个这个数。这种思路常常出现在有重复项的题目中。在写代码的时候发现，似乎不能指望append不会改变顺序， 现象是使用[]int{0,3,5,7,9}作为测试集时，下面的代码在最后一个循环中ret[a]的值会有变化。TODO12345678910111213nr := len(ret)fmt.Printf("=== %v %v %v\n", i, j, ret)new_ret := make([][]int, nr)copy(new_ret, ret)for a := 0; a &lt; nr; a++&#123; // 对于每一个已有的lst，分别添加0-l个当前的数 for k := i + 1; k &lt;= j; k++&#123; fmt.Printf("%v/%v %v %v", a, nr, ret[a], nums[i:k]) new_slice := append(ret[a], nums[i:k]...) fmt.Printf("%v\n", new_slice) new_ret = append(new_ret, new_slice) &#125;&#125; 改成下面这样就行了，看起来是append会改变第一个参数。12345r := make([]int, len(nums[i:k]))copy(r, nums[i:k])l := make([]int, len(ret[a]))copy(l, ret[a])new_slice := append(l, r...) 这条题目涉及下面的知识点： copy slice 91. Decode Ways觉得很好的一题，建议先写一下练习一下搜索。Corner case是特别特别地多。这道题的正解是DP。 96. Unique Binary Search Trees想想二叉排序树的性质，再从对称的观点看看样例，就解决了。 97. Interleaving String暴力复杂度是$2^{min(len_1, len_2)}$，为了减到多项式复杂度，通常就是上DP，和LIS啥的一样，也是二维DP。首先看最优子结构，显然在每一步，我们要么选择s1（从dp[i-1][j]过来），要么选择s2（从dp[i][j-1]过来）。然后还要与s3建立联系，于是我们定义dp[i][j]为最远可以达到的s3边界交了一发，只击败了10%。。。这常数可以的，看了看题解，还有用dfs做的 98. Validate Binary Search Tree从这题开始有一堆二叉树的题目验证一个二叉树是否是二叉搜索树，注意二叉树需要左子树上所有的节点都小于根节点，所以这条也是递归地。 99. Recover Binary Search Tree困难的地方是需要保持二叉树的原先结构 101. Symmetric Tree递归比较l.left和r.right以及l.right和r.left。 102. Binary Tree Level Order Traversal层次遍历，就是把指针形式的二叉树转成数组形式 104. Maximum Depth of Binary Tree简单题 105. Construct Binary Tree from Preorder and Inorder Traversal构造树是一个递归的过程。对于前序来说，我们很容易找到root，剩下来的工作是把剩余的列表分给两个儿子。对于中序来说，我们找到root，它左边的点和右边的列表就分别是左儿子和右儿子。这道题要注意一下split的情况。另外递归方法简单，但非递归方法。。。 106. Construct Binary Tree from Inorder and Postorder Traversal由后序和中序生成树。 107. Binary Tree Level Order Traversal II简单题 109. Convert Sorted List to Binary Search Tree将一个有序链表转成平衡二叉搜索树。这道题应该就是不停找中点。 110. Balanced Binary Tree平衡二叉树高度差不能大于1。于是就是判断每个子树的高度差，注意还要检查子树是否递归地满足平衡性质 111. Minimum Depth of Binary TreeBFS 113. Path Sum II一个基本的遍历 114. Flatten Binary Tree to Linked List看上去就是把这个树preorder到链表上，但要求原地修改树。看起来，我们把每一个节点左子树遍历完的最后一个节点缓存下来，并且连接到右子树上面 115. Distinct Subsequences注意边界条件是dp[0][1..j] = 0和dp[1..i][j] = 1，不能全为0。 117. Populating Next Right Pointers in Each Node II简单题 120. Triangle动态规划模板题 121. Best Time to Buy and Sell Stock在扫描时维护一个当前的最小值和当前的最大利润即可（一开始还想复杂了，是Easy提醒了我）。这种方法比较常用，在求最大权子矩阵中也会用到。 122. Best Time to Buy and Sell Stock II相比上面的题，我们可以进行任何次数的交易，但是不能engage in multiple transactions。只要知道(b-a)+(c-b)=(c-a)这道题目就很简单了，能赚就卖，不能赚就进 123. Best Time to Buy and Sell Stock III由于不能engage in multiple transactions，首先想到的是枚举断点，将本题转成两个Best Time to Buy and Sell Stock问题。不过显然$O(n^2)$是超时的，得DP下。所以仿照前面直方图的思路，维护一个$[0,i]$的解和一个$[i,length-1]$的解。然后再一遍扫描。这条也常数也比较大，只击败了20%左右 124. Binary Tree Maximum Path Sum说实话Leetcode的链表题和二叉树题我都不喜欢做，它的表示方法让人感觉很蛋疼，因此我写了两个辅助调试的函数，详见Github上的代码。这道题就是两次dfs，第一个dfs是求出从某个节点往叶子方向权最长的一条链，类似于求和最大的子串一样。第二次dfs连接一个节点的两个儿子，看是否能得到一个更长的链。写的时候粗心得一腿，各种漏考虑条件。有很大的常数优化空间，可以优化成一个dfs 125. Valid Palindrome这个题目挺没意思的，这里Python有个方法.isalnum() 126. Word Ladder II这道题，一看就是个bfs搜索。不过它一定要输出全部结果的全部路径，这就很麻烦。一开始写了个程序不仅T了还会M。此外“Note that beginWord is not a transformed word”并不意味着beginWord不会在wordList里面出现。最后还是T了，这条有点麻烦。 127. Word Ladder在接受了上一条T的教训后这次改用了双向BFS搜索，虽然还是T，但是点从Case22变成了Case29。后来用C++重写了一遍才过。这里先说明一下这条双向BFS写法上注意点，首先介绍一个很好的双向BFS的模板。我们首先对模板进行改进，首先如果点c被正向bfs所发现，则将vis[c]标记为1，若是反向bfs，则标记为-1。然后我们定义一个bfs(q, flag)函数，flag表示我们现在是搜正向队列还是反向队列。那么在搜索过程中，一旦我们遇到一个vis[mat[c][i]] == flag，这就说明了我们的双向bfs相遇了，于是就返回。下面的问题就是如何记录搜索深度，一开始我的想法在两个队列q1和q2中记录当前节点c的访问深度，例如正向搜索首次发现了c节点连通的子节点mat[c][i]，那么就向正向搜索队列q1中增加(mat[c][i], d + flag)，其中d是c节点的搜索深度，容易得到起始节点的搜索深度是1，紧接着的正向队列的深度依次取2、3、4等。终点的搜索深度是-1，紧接着的反向队列的深度依次取-2、-3、-4等。与此同时使用deep1和deep2来分别维护正向和反向bfs达到的最大深度。但是在提交时发现这是不对的，例如当反向队列与正向队列相遇时，相遇点不一定是正向队列最深的点。例如从cat到fin可以有下面的搜索路径，我们看到走cat -&gt; can &lt;- fan &lt;- fin是最优解，但是如果按照维护的最大值的话，我们会算上pat -&gt; paw这没用的一步。 q1 1: cat -&gt; pat q1 1: cat -&gt; can ================= q2 -1: fin -&gt; fan ================= q1 2: pat -&gt; paw ================= q2 -2: fan -&gt; can 所以我们将deep1和deep2去掉，而借助于vis[c]数组记录访问到c节点时的深度，这样我们就可以精确地知道相遇节点被正反向队列所访问的时间了。 128. Longest Consecutive Sequence这条我是用反查字典+并查集实现的，不过其实可以直接用反查字典。 129. Sum Root to Leaf Numbers水题 130. Surrounded Regions一个DFS了，比较取巧的是可以从边界先把能保留的O筛出来，然后将剩下的O清空。 131. Palindrome Partitioning这道题很无聊，就是要你列出所有回文串的分隔可能性，有趣的是下面一条 132. Palindrome Partitioning II这道题不太会，看了题解，原来就是首先找出来所有的回文数，然后套Word Break的模板。T了一发，这是因为我是找出了所有的回文串文本，但实际上我们应当用dp[i][j]记录[i,j]是否是回文串。这个记搜一波即可 134. Gas Station首先只要gas和cost的sum至少相等就可以实现，可以用归纳法证明。其次，发现题意要求一个从唯一解起始节点i起经过所有节点的油量都大于零的性质，我们要找这个起始节点。进而可以发现从哪个节点开始找是无所谓的，因为每个节点总要经过一次。所以我们可以从例如0节点开始，在满足性质的情况下将序列向左右扩展，直到遍历玩所有的节点。一个具体的方法为首先尽可能往右移动左边界l，当l不能移动时则往左移动右边界r，直到l可以再次往右移动 135. Candy一上来就理解错误，只有当严格大于的时候才要求糖数多，例如5 5 5 5这种，每个人可以分糖2 1 1 2（当然最优解是1 1 1 1啦）然后就是硬写，首先将原数组分成上升段、平行段和下降段，如1 2 3 | 3 3 | 4 5 | 4 3。标记每一段的长度为segs[i]，每一段最后一个人的糖果为last_candy[i]个。上升段一定是从last_candy[i-1]+1开始以1为公差的等差数列。下降段末项一定是1，为了尽可能小，所以是以seg[i]为首项，-1位公差的等差数列。但如果last_candy[i-1]小于等于seg[i]，那整个下降数列放不下，所以此时要提升last_candy[i-1]到seg[i]+1（注意只要改前一个数列的末项哦） 136. Single Number老题新做 137. Single Number II这道题同样可以用异或来解决（当然也可以借助于set）。在上一题中，我们通过异或的性质，实现了值相同的数两两相消。在这一题中，我们希望出现三个相同的数才相消。 123456ones = 0twos = 0for x in nums: ones = (ones ^ x) &amp; ~twos twos = (twos ^ x) &amp; ~onesreturn ones 考虑一个比特位的情况。观察上面的代码，对于序列1 1 1能够得到(ones, twos)的值分别是(0, 0), (1, 0), (0, 1), (0, 0)。这里的&amp; ~twos用来表示进位，当twos = 1时说明目前已经出现了两次，于是我们归零ones。 138. Copy List with Random Pointer一个单向链表，有一个random_index可以指向随机的节点，或者null，要求深复制这个链表。一个很Naive的办法就是先构建next指针，再构建random指针。不过也可以一趟构建完。 139. Word Break要根据字典进行分词。看起来是一个Trie的题目，题目也没规定大小写怎么说，而且也没说是否存在唯一表示。花了很久尝试用AC自动机做，不过失败了。其实这道题根本就不是AC自动机，直接DP[pos]维护一下从pos往后的子问题的答案就行了。 140. Word Break II类似139。 141. Linked List Cycle这种链表题一般都要考虑快慢指针的解法。首先只可能有一个环，所以直接搞。 142. Linked List Cycle II比上面的一题要求找到环的起始点的位置。可以发现若第一次快慢指针交于点X，则环的长度$c$等于下次快指针追上慢指针时慢指针走过的距离。设链表头到环起点距离$s$，环起点到交点X距离$a$，交点X到环起点距离$b$，有$a + b = c$。且$2(s + k_1 \, c + a) = s + k_2 \, c + a$，有$s + a = k \, c$，即$s = kc + b$。则将两个指针分别置于链表头和交点X，其交点就是环的起始点。 144. Binary Tree Preorder Traversal前序遍历，xjb写了个非递归版本 145. Binary Tree Postorder Traversal经典的二叉树后序遍历问题，xjb写了个非递归版本 146. LRU Cache在$O(1)$复杂度下，免不了Hash。但是为了能够方便进行排序，我们又要采用一个双向链表组成队列。于是就用一个dict来定位链表里面的各个Node。 147. Insertion Sort List链表的插入排序，一开始写砸了，后来发现其实分成两个链表，从未排序的free list不停往排好序的sorted list插入元素。这道题Python居然T了、、、我也是服气。 148. Sort List写了几个辅助函数用来调试。这条就是按照CLRS上的思路写的快排，可参照第215条。居然T了后来换成归并排序过了。 149. Max Points on a Line这是一条神经病题目，两个相同位置的点居然算不同点。所以我是不知道它怎么解释$[[1,1],[1,1],[1,1]]$输出3，$[[84,250],[0,0],[1,0],[0,-70],[0,-70],[1,-1],[21,10],[42,90],[-42,-230]]$输出6的？所以说这些相等的点互相组成直线，但是和任何其他直线都不共线是吧、、、那你告诉我为什么TestCase31输出25而不是56。。。我最后HardCode了$[[1,1],[1,1],[1,1]]$才AC的。 151. Reverse Words in a String这题有一点无理取闹的地方是要先将连续的空格合并成一个，然后就是一条经典的题目。原地解法是翻转每一个单词，再翻转整个字符串，代码只有很骚的一行1return ' '.join(map(lambda x: x[::-1], filter(lambda x: x, s.split(' '))))[::-1] 152. Maximum Product Subarray注意这条是子串而不是子序列。这个不同于最大和，可以维护一个全局最大和当前最大来做。Bruteforce的做法是$O(n^3)$的，遍历所有可能的数组，并累乘。一个动态规划的思路是维护$dp[i]$作为一个累乘序列，这样的话是复杂度是$O(n^2)$。注意遇到0之后可能认为当前数组结束了，0后面的作为一个新数组处理。不过正解是$O(n)$的，相比先前的最大和，它的转移方程考虑三个分支，分别是使用前一个dp的最大值、最小值（因为存在负数翻转的现象），或不使用。 153. Find Minimum in Rotated Sorted Array旋转数组求最小元素，这是一道经典的二分搜索题目。 154. Find Minimum in Rotated Sorted Array II一个恶心的题目，要是能一遍做对就很厉害了。这题告诉我二分法在查找更新的时候不能激进地r = mid + 1，也要考虑下r = mid这样。一般能确定mid肯定不对，那就用前者。由此严格地来做，我们可以将二分分为两种类型，F/T…TTT和TTT…F/T型，由于我们始终是要找第一个T。对于前者，如果我们fail了mid，那么我们就要更新l到mid + 1，否则更新r到mid，注意我们不能激进地更新到mid - 1，因为mid可能是第一个T。对于后者我们就要更新r到mid - 1，否则更新l到mid。下面我们考虑mid的求法时需要做到极限情况下不陷入死循环，以区间[3,4]为例。假设mid = (l + r) / 2，即mid = 3。对于前一种情况，我们OK之后会更新到[3,3]，这时候l == r，我们可以成功返回结果。对于后一种情况，我们OK之后会更新到[3,4]，这时候死循环发生了。由此我们对于后者应该做mid = (l + r + 1) / 2的更新。特别地，如果对于668题这种暂时无法确定是F/T…TTT和TTT…F/T型的，我们可以直接判断它是r到mid - 1型的还是l到mid + 1的，如果是r到mid - 1的算mid就要+1。默认while (l &lt; r)。 155. Min Stack设计一个最小栈，要求能够满足三个原语之外，还支持getMin操作，要求常数代价。这个和单调栈还不一样。解法很神奇，就是每次入栈的时候多入一个当前元素的最小值。。。真贱。。。 160. Intersection of Two Linked Lists找到两个链表的交点。注意一下链表的相交，在没有环的情况下一定是Y型而不是X型的，在有环的情况下那么两个链表一定最后进入同一个环。本题是没有环的情况，容易发现将headB的链表头接到headA的尾巴后面，那么就能把本题化为第142题。下面讨论有环的情况，首先判是否相交，根据上面的性质，我们只要找到A环上的一点，判断在不在另一个链表的环上就行了。链表相交常被用在求普通二叉树的最近公共祖先上。 162. Find Peak Element裸二分吧 164. Maximum Gap这题是求一个未排序数列的有序形式相邻两个数的最大差，要求线性复杂度。不会，Related topic显示还是sort，难道是考桶排序？xjb写了个，然后面向OJ二分桶大小就过了、、、但是这条还是需要改一下的，自己做法其实很慢，只击败了2%的人。看了一下题解，首先他根据鸽笼原理求出最大差值的下界，即$(mx - mi) / (n - 1)$，我们把它作为桶的大小，这样的好处是我们的最优解肯定不在某个桶内求得，而一定在桶间。 165. Compare Version Numbers简单题，注意补零 169. Majority Element一个很有趣的Brain teasing，要求找到出现超过floor(n / 2)次的元素 174. Dungeon Game这一条是倒推的动态规划，我们将原数组改为从1开始的数组，用need[i][j]表示从(i, j)到达公主所需要的最少HP，那么need[n][m]显然为1，我们要求need[0][0]。容易看出递推式为need[i][j] = min(need[i][j + 1] - mat[i][j + 1], need[i + 1][j] - mat[i + 1][j])。当need[i][j] &lt;= 0时，也就是说从need[i][j]往下走还会盈余HP，但是我们不能结算给(i, j)前的位置，这是由于在过程中的任何时候HP都不能小于等于0，因此不能先欠再还。实际上我们的need[i][j]必须始终大于等于1。 179. Largest Number在贪心时我们需要考虑一个问题，即类似[76, 7621]和[76, 7698]的情况，这两种情况下最优解分别为76 7621和7698 76，但是考虑[7676, 76, 98]和[7676, 76, 54]的情况就难以处理了。但其实这种情况不会存在，因为98一定会在7676前面被去掉。写了一份提交，发现死在了219Case上，简化一下发现[2, 213, 2281]这个样例，原因是2281还是比2大的。这个判断太麻烦了！后来发现还不如在两个字符串不相等时把两个字符串两种组合s1 + s2和s2 + s1都试一下看哪个大呢。在第321条中我们发现了类似的归并的问题。 182. Duplicate Emails写了半天子查询，似乎不行。主要原因是必须要用到GROUP BY123456789101112131415SELECT Email FROM PersonGROUP BY EmailHAVING COUNT(Email)&gt;1SELECT Email FROM( SELECT Email, COUNT(1) as Num FROM Person GROUP BY Email) as ewhere Num &gt; 1SELECT DISTINCT a.Email from (SELECT p.Email, COUNT(p.Email) as cnt from Person as pGROUP BY p.Email) as awhere a.cnt &gt; 1 187. Repeated DNA Sequences暴力dict一波？ 188. Best Time to Buy and Sell Stock IV相比III，现在我们最多可以执行k次而不是两次交易。首先想了一个xjb搞的算法，将所有的连续上升串找出来，然后排序并尝试提取出差最大的k个，这里注意如果不足k个的话也不影响，因为性质(a - b) + (b - c) = a - c。但是发现WA在了2, [1,2,4,2,5,7,2,4,9,0]，因此当我们的串的个数大于k时，我们需要尽量把这些区间合成到k个。上面的想法想了半天不知道怎么搞，于是从Best Time to Buy and Sell Stock With Cooldown那条下手，用两个数组sell和buy分别表示第i天（从1开始）做至多j个任务的最大收益。写了一个O(nk)的算法，TLE了。most_trans表示第i天最多能做(i + 1) / 2个交易。1234567for i in xrange(1, n + 1): # at day i most_trans = min((i + 1) / 2, k) for j in xrange(1, most_trans + 1): # this is j-th transaction buy[i][j] = max( buy[i - 1][j], sell[i - 1][j - 1] - prices[i - 1] ) for j in xrange(1, most_trans + 1): # this is j-th transaction sell[i][j] = max( sell[i - 1][j], buy[i - 1][j] + prices[i - 1] ) 用C++改写了一下，发现k可能非常大，虽然后来将buy和sell优化成滚动数组，但还是开不了这么大的数组。于是发现当k &gt; n时这道题实际上退化为Best Time to Buy and Sell Stock II，于是可以$O(n)$时间，常数空间解决。题解里面用最大堆的那个没有看懂。 189. Rotate Array简单题，rev两次 190. Reverse Bits这个很简单，直接不停n &amp; 1然后n /= 2即可 191. Number of 1 Bits这里使用n &amp; (n - 1)去掉末尾的0，或者使用x &amp; -x取到末尾的0 195. Tenth LineLinux命令，，简单题 198. House Robber简单的动态规划 199. Binary Tree Right Side View简单题 200. Number of Islands一看应该就是条DFS裸题，转念一想像这种可以用搜索解决的集合分划问题也能用并查集搞。 201. Bitwise AND of Numbers Range只要高位有进位，后面就肯定有0。只要有0，那一位AND的结果肯定为0。 204. Count Primes求小于n的质数的数量，经过实测，n有至少499979的规模。因此打表的话就wa了。 205. Isomorphic Strings同构，很范畴论了。现在要判断两个字符串是不是同构的。办法很简单，我们用第一个字符串构建一个查询字典，如果出现冲突就不同构。但是要正过来比一次，再反过来比一次 206. Reverse Linked List特别经典的链表反转问题，迭代方法借助prev和cur指针。题目还要求使用递归方法。 207. Course Schedule判断一个有向图中是否存在环，拓扑排序。有关拓扑排序的内容，具体可见我的一篇博客。这边额外说一下有向图和无向图判环的方法。首先补充一下DFS的相关知识，一个无环的有向图当且仅当DFS中没有后向边，关于这个推论可以查看我的一篇博客，因此我们只要做一次DFS搜索（使用黑白灰标记），并观察是否出现后向边即可。相对于有向图，无向图还有一些额外的判环方法。首先是并查集。 208. Implement Trie (Prefix Tree)我先研究了Word Break那条，写了个AC自动机，没过，于是先把这条给水掉 209. Minimum Size Subarray Sum双指针经典题，一定要会！我好久不写了，WA了好久 210. Course Schedule II看起来是个拓扑排序 213. House Robber II相比前一条，现在要求在环上DP了。当时觉着能够化为前一条来做，不过没怎么搞明白。其实给一个Hint就是第一个和最后一个房子不能同时被抢，所以问题就分解了。 214. Shortest Palindrome这道题对我来说蛮难的，首先KMP比较难想，然后我KMP还写错了。 215. Kth Largest Element in an Array快排模板题，居然卡了（天哪噜，原来是两种常见写法混起来用了），既然如此就来介绍一下快速排序的两种常见方法吧。快速排序的一种经典写法挖坑法是先取p = arr[fr]为支点元素，然后我们一定要先从arr[to]开始遍历，这么做的目的是将第一个不符合的arr[j]直接赋值给arr[fr]（注意不需要交换了）。注意一些错误的算法的实现总是不能有效地将arr[fr]移动到中间位置，所以我们必须得先把arr[fr]的槽空出来。建议在写快排时每次递归始终是在[fr, pos - 1]和[pos + 1, to]递归，并且arr[pos]放支点元素。我们还要考虑把等于的放到哪边，一般来说，如果我们取arr[fr]为支点，那么我们就要把等于支点的放到右边，这样才能够先把arr[fr]空出来，在下面的一个算法中，我们看到它使用fr, l, r, to将数列分为了四个部分，从而能在最后找到arr[fr]所放置的位置。但是对于上面的挖坑法来说，这是不必要考虑的，因为它保证了将第一个换掉arr[fr]。此外，在手写快排时写完一定要查一下当第一个元素是最小时是否成立，一般算法错就错在这里。另一种方法，也是算法导论中介绍的，是仿照三路快排来做的。这种方法的主要特点是不再在数列两端来维护了，而是根据CLRS P96的那张图来维护，并且在最后唯一一次移动arr[fr]到准确位置。注意如果说要找出前K个的话，可以使用$O(n)$建一个最小堆，然后做$k$次$O(lg \, n)$的弹出。此外对这一题我还实现了一个堆排序，堆排序要稍微简单一点，我们主要注意在pushDown交换的时候，我们应当选择两个son最大的那个进行交换 218. The Skyline Problem这题实际上就是插线问点的问题，首先就是想到用离散化+线段树/树状数组来做。 221. Maximal Square这条比之前的第85条多了是正方形的条件，我们当时应该是做的这条，比矩形要简单很多 222. Count Complete Tree Nodes经典题，计算完全二叉树的最后一个节点。这道题其实就是比较左右子树深度。 223. Rectangle Area这道题蛮巧妙的，计算方法是容斥原理，找intersect蛮难的。因此我们要找到上/下/左/右除去边框的次级值。 228. Summary Ranges题目给定一组已经排序好的整数，要求将连续的部分克兵成一个区间表示这个我是维护每一个[fr, to]的区间，然后对每一个x二分出index表示x应该在index前面，接着查看能否将x贴到index - 1或者index上。最后查看能否合并index - 1和index。这里二分偷懒用了bisect_left，这里可以看出来。不过其实这道题很简单，因为是排好序的，所以直接xjb跑一下就完了。 229. Majority Element II这次是[x / 3]的。我们这次依然使用打擂法，也就是Boyer-Moore投票算法。不过这次我们需要维护一个大小为3的集合（即最多容纳三种不同值的数字），例如1 1 1 2 2 2 3表示成[(1, 3), (2, 3), (3, 1)]，当随后出现一个4时，集合的容量不够了，那么这一个4就会和集合中的所有元素进行一次湮灭，例如现在的即可变成了[(1, 2), (2, 2)]，其中3的数量不够了，就从集合中被去除。 230. Kth Smallest Element in a BST随便写了一下，常数应该比较大，居然还击败了66%。用一个函数index求一个节点下的count。接着用函数dfs递归，首先看左儿子的节点数是否满足k &lt;= cntl，注意k == cntl时答案不是左儿子，而是左子树中的最大值。看到一个很简洁的答案，其思路就是不停地递归左儿子，并在k上减掉已经遍历过的数量n，并返回n处的值x。容易看到当k == 0时，要求的值在左子树上，k == 1时要求的值是根，否则递归右子树。1234567891011121314151617181920int kthSmallest(TreeNode* root, int&amp; k) &#123; if (root) &#123; int x = kthSmallest(root-&gt;left, k); return !k ? x : !--k ? root-&gt;val : kthSmallest(root-&gt;right, k); &#125;&#125;int kthSmallest(TreeNode* root, int&amp; k) &#123; if (root) &#123; int x = kthSmallest(root-&gt;left, k); if(k == 0)&#123; return x; &#125;else if(k == 1)&#123; k --; return root-&gt;val; &#125; else&#123; k --; return kthSmallest(root.right, k); &#125; &#125;&#125; 233. Number of Digit One可以用数位DP硬刚，设置状态status为高位上1的数量（之前以为不需要设的）。当然这道题也有神奇的解法，具体还没研究123456int countDigitOne(int n) &#123; int ones = 0; for (long long m = 1; m &lt;= n; m *= 10) ones += (n/m + 8) / 10 * m + (n/m % 10 == 1) * (n%m + 1); return ones;&#125; 236. Lowest Common Ancestor of a Binary Tree经典的求LCA的题目。一个straightforward的做法是计算得到两个链然后求交。一个通常意义的解法是离线的tarjan。Python的Hash啊，简直蛋疼，又不能自定义数据结构，解决不了并查集的问题。用C++写了发终于过了，这里提醒一下，Leetcode的全局变量一定每次计算时要清空。 238. Product of Array Except Self这道题蛮有意思的，维护一个left和right累计积，然后对于i，就是它的左边乘以它的右边。 239. Sliding Window Maximum如果说需要查任意区间的最大值那么线段树是比较好的办法，不过这道题要求是用$O(n)$时间解决。这道题做完之后我看题解上是用了啥deque，但我自己做的时候直接维护了窗口两端的指针，然后分类讨论。居然击败了96% 240. Search a 2D Matrix II二分，upper_bound行，然后lower_bound列。 241. Different Ways to Add Parentheses问怎么可以通过加括号，让一个包含+-*表达式，要求输出加括号能得到的所有值。对于每一个op，我们可以在两边加括号，从而进行分治。于是这种题的思路是确定的，就是我们遍历每一个op，并且用一个字典记忆左右两边能得到的所有值。然后WA了，原来不能用set输出。。。 258. Add Digits求数x0的数位和得到x1，重复上一过程直到得到个位数。要求$O(1)$复杂度。打表发现规律1 + (num - 1) % 9，然后发现其实可以用数学归纳法证明这个规律的。 260. Single Number III老题新做 263. Ugly Number没啥好说的 264. Ugly Number II定义Ugly Number是所有包含2/3/5为因子的正整数，求第n个。想一开始用筛法预处理打个表，然而TLE了。也没发现能够从各因数的幂上发现子结构。解决方案还是从$O(n^2)$的筛法上下手，原筛法是对第$i$个丑数，看看能从先前的丑数中进行更新得到的最小值。容易发现这个过程存在很多冗余计算。例如在计算$ugly[i]$时，我们需要知道满足$x * 2 &gt; ugly[i - 1]$的最小的$x$，显然我们不需要在所有$ugly[1..(i-1)]$遍历$x$。不过我们发现每次使用$* 2$规则生成新丑数时，我们的$x$是严格递增的。递增很简单，因为新丑数比就丑数大，所以$x$要大。严格是因为所有的丑数都是偏序的。 274. H-Index桶排序，注意要是min(tot, i) 275. H-Index II这道题就是二分答案$[0, citations[-1]]$啊。123456789101112class Solution &#123; public int hIndex(int[] citations) &#123; int len = citations.length; if(len == 0) return 0; int h = 0; for (int i = 0; i &lt; len; i++) &#123; if (citations[i] &gt;= len - i) return len - i; else if (citations[i] &gt; h &amp;&amp; citations[i] &lt; len - 1) h++; &#125; return h; &#125;&#125; 其实之前是考虑不二分答案而是二分index，我们试图找到最靠左的位置l使得[l, n)里面的数都大于citation[l]，这是一个TTT..T/F型的，不过我们应该返回什么呢。返回citation[l]吗？答案不一定出现在citation数组里面，例如[0,0,4,4]，在位置1的右边有2个数大于2，这个答案是2。返回n - l吗？还考虑[0,0,4,4]，二分下来l是1，n - l等于3了。这里是因为虽然1位置的0满足了二分的条件，也就是说这是二分的边界情况，但这个边界情况不一定成立，我们得验证citation[l]要足够大，不然我们就要从l + 1位置开始算。这个答案击败了100%，此外还有一个二分也值得一看，看起来我完全可以把二分的条件写得更严格一点，我当时是怕写出来不满足二分的性质了。12345678910111213start, end = 0, n-1while start &lt;= end: mid = start + (end-start)/2 acc = n - mid cite = citations[mid] if cite == acc: return acc elif cite &gt; acc: end = mid-1 else: start = mid+1return n-start 279. Perfect Squares点开Playground看一下它附加的后台代码，发现我们打表不能打在Solution对象的__init__上，而应该打在全局。1234line = lines.next()n = stringToInt(line)ret = Solution().numSquares(n)out = intToString(ret) 注意，本题还可以使用四平方和定理进行优化。 282. Expression Add Operators一开始打算二分，砸了。后来打算dfs，这道题的话我们可以将算式看为若干个乘积式的加和 283. Move Zeroes这道题直接统计0的数目然后覆盖移动就行了，前面有类似的题目 284. Peeking Iterator简单题 287. Find the Duplicate Number这道题目很有意思，有n + 1个数，他们的值域为[1, n]，里面只有一个数会出现&gt; 1次（不一定只出现两次），要求找出来。这道题要求在$O(n log n)$时间，$O(1)$空间解决。那就是二分答案啊，然后我一开始想歪了，想通过和来比较，但其实是通过小于/大于mid的数的数量进行二分的。 295. Find Median from Data Stream299. Bulls and Cows很有趣的xAyB的猜数字游戏，一道小模拟。注意有易错点11和10是1A0B而不是1A1B，因此要用dict来统计一下overlap的个数 300. Longest Increasing Subsequence最长上升子序列模板题 301. Remove Invalid Parentheses这道题要输出所有结果，那考虑考虑暴力咯。仔细查看样例，我们发现不能简单地消除能够匹配的括号。看了题解，这道题和之前的某道题一样，就是挨个从原字符串中去掉1、2、3个字符，直到形成一个合法串，然后把相同长度的都列出来。注意为了加速使用一个set来做记忆搜索。 304. Range Sum Query 2D - Immutable求一个不变的矩阵的某个子矩阵的和。由于不变，所以我们不需要用到线段树。这一条要做到常数的查询复杂度，其实很简单。我们维护dp[i][j]表示(0,0)-(i-1,j-1)张成的矩阵的大小即可。特别地，如果求最大权子矩阵的解法是$O(n^3)$的，详见红宝书。 307. Range Sum Query - Mutable线段树模板题 309. Best Time to Buy and Sell Stock with Cooldown首先要思考的是如何维护DP的状态，我觉得可以直接用一个二维数组来表示，因为每一天有三种行为，买、卖和不买不卖，分别导致三种状态，因此我们可以设置数组dp[n][3]，紧接着在推导公式时我们发现一个问题，我们计算不买不卖这个状态很有难度。看答案才知道其实是想复杂了。首先它只设两个变量buy[i]表示第i天买彩票能获得的最大利润，sell[i]表示在第i天卖彩票获得的最大利润。下面我们考虑计算sell[i]，最容易想到的是如果第i - 1天买了，那么利润就是buy[i-1]+prices[i]，但是如果我第i - 1天不买不卖呢？那我们就直接使用第i - 1天的结果sell[i - 1]。计算 310. Minimum Height TreesFloyd一波T了。。。因为是无权的嘛，所以BFS咯、、、$O(n^2)$的BFS也T了，看来是$O(n)$的了，这让我想到834这道题。细究下来这道题还蛮有意思的，首先需要明白MHT的数量只可能为1或者2。知道这一点，我们就不停地把叶子剥掉，这个过程有点类似于拓扑排序。 312. Burst Balloons一条蛮久之前就准备做的题目了。这道题的话首先是DP如何维护状态，一般来说有用bitset维护的，或者我们去跟踪某个点i的状态，一个i就是一维，抑或我们去跟踪ANY/NONE/ALL这样的状态，抑或我们进行二分然后合并左右两个区间的结果，这样我们只需要考虑相邻节点的状态。于是我首先推出方程，使用dp[L][R]维护打爆[L, R]处所有气球的最大值12for burst in [L, R]: dp[L][R] = dp[L][burst-1] + dp[burst+1][R] + nums[burst-1]*nums[burst]*nums[burst+1] 但我突然意识到我们是仅仅消掉burst，所以两边的burst-1和burst+1不能分治，那怎么办呢，且慢，好像有哪里不对劲。反省一下上面的dp，我们犯的最大的错误是认为消掉burst和burst-1和burst+1有关，实际上这是不可能有关的，因为在这种假设下此时这两个气球应该是已经爆掉的，于是我们恍然大悟，应该和L和R有关啊。于是此时burst就是我们最后打爆的气球。然后这一条如果DP的话因为是从[l, burst-1]和[burst+1, r]更新的，所以不能for l for r这样，比较好的是for l for len或者直接记搜。 313. Super Ugly Number要求找到第n个Super Ugly Number。这个数的定义它的所有的因数来自给定一组素数prime，其中1是第一个。其中n是10**6的规模。这条和第264条有点像。看上去我们可以维护一个最小堆，对于每一个新来的数，就依次乘上prime的每一个数，再放到这个堆里面。这一条是用go写的，需要用到container/heap去维护一个优先队列，它实际上是一个最小堆。 315. Count of Smaller Numbers After Self我是从逆序对的经典问题出发找到这条题目的，这一条朴素解法是$O(n^2)$的，但似乎不太好套逆序对的模板，因为需要求每个位置的结果，而中途的sort会改变位置。一个straightforward的做法是线段树/树状数组神器（其实逆序对也可以用树状数组做），不过常数是比较大的。但是还有一种思路，我们可以理解成从最后一个元素开始构造一个新的数列，对于每一个元素bisect_left查找它的插入位置，这就是解，搞了一发T了。通过查看Related topics我发现了二叉搜索树(BST)其实就是用来做这个的，它能够进行动态插入。这里注意一下，不要用数组来实现二叉树，容易爆内存，而且要在每个节点上维护count，否则会爆内存 316. Remove Duplicate Letters一开始想的是怼每一个字符维护一个harm和benefit表示为了减少害处或者增加益处需要保留下来的index。不过这个在样例阶段出现了错误，因为我们还需要考虑各个保留下来的字符之间的相对位置。其实这道题实际上是个贪心，我们试图将s逐一append到ans上，然后如果当前的x比ans[-1]要小，那我们肯定是倾向于用x替换ans[-1]的，只需要ans[-1]在后面还有备胎。 319. Bulb Switcher【这道题直接打表解决了】解释一下题意，灯有1表示开、0表示关两个状态。一开始都是1，之后选择%2=1的所有灯切换状态，之后是所有%3=2的灯，一直到%n=n-1的灯。问到最后有多少盏灯是亮的。写了一个O(n^2)的T了，那应该是推一个很容斥原理一样的公式了吧？然后我打了个表。。。发现答案是3个1、5个2、7个3、、、原来是个等差数列，求和公式也忘了，直接打表和表然后二分AC 321. Create Maximum Number【这一条目前还是T的状态，加个剪枝就过了。。。C++还写WA了一发】题目要求是在nums1和nums2中总共取k个数，然后进行归并，要求组成的数最大。这道题目一开始的思路就是枚举k，然后分别对nums1和nums2生成最大的数，最后进行归并。 从nums数组中取出按顺序的req个数使得组成的数最大。 一个错误的思路是首先取ans = nums[0..req-1]，然后对于从req开始的每个数，我们找到它能替换ans的最小index位置和最大长度，例如[8,5,3,6,7]中[6,7]能够替换[5,3]。不过这个思路是错的，例如[9,7,9,1]，显然[9,1]不能替换[9,7]，但是第2个9可以替换第一个7。此外也不能从req位置开始，而应该从1位置开始。 实际上我们可以维护一个大小为req的栈，来表示这个最大可能的数。我们遍历数组A，对于每一个nums[i]，我们试图用它来替换最靠栈底的数，除非剩下来的数不够填满栈了。 归并我们要注意当nums[i]和nums[j]相等时需要继续向后比较，如果当其中一个数列耗尽还没比较出来大小，那就选择另外的数列为大，因为另一个数列可能下面的元素就大了。例如[0]和[0, 6]。 322. Coin Change这是一道完全背包的问题。完全背包朴素的状态转移是f[i][j]=max(f[i−1][j−k∗w[i]]+k∗v[i])∣0&lt;=k∗w[i]&lt;=j，但实际上可以做到O(VN)。dp[i][j]表示只使用前i个物品，总价值在j时的最小数目。完全背包不一样的地方是对j的循环策略123for i in xrange(1, n + 1): for j in xrange(amount + 1): dp[i][j] = min(dp[i][j - coins[i - 1]] + 1, dp[i - 1][j]) 而01背包是123for i in xrange(1, n + 1): for j in xrange(amount + 1): dp[i][j] = min(dp[i - 1][j - coins[i - 1]] + 1, dp[i - 1][j]) 对于01背包而言，要保证f[i]全部是从f[i - 1]更新的，而完全背包需要复用一部分dp[i]的结果 324. Wiggle Sort II【这一条蛮难的】这道题比前面的Wiggle Sort去掉了可以相等的条件。平凡解法依旧是$O(n log \, n)$的，使用排序之后一头一尾接着取，也能AC。题目要求的$O(n)$时间复杂度和$O(1)$空间复杂度就有难度了，首先DP肯定不行了。一个初步的策略是首先算出中位数，这个有一个$O(n)$的第k大数的算法std::nth_element，然后将大于中位数的放在奇数位，小于等于的放在偶数位。注意当数列为奇数个时，中位数放在偶数位作为一头一尾。因此我们必须新开一个数组，造成$O(n)$的空间开销。题解用了一个很巧妙的思路，首先将原数列映射成[1, 3, 5, ... , 0, 2, 4, ...]的形式，然后考虑这个“新数列”。它的前半部分都大于中位数，后半部分都小于中位数。这又回到了之前的快速选择的问题上。不过这个做法还是有问题，例如[1, 3, 2, 2, 3, 1]的结果是[1, 3, 2, 2, 3, 1]。正确答案需要三向快排来处理相同值的情况。与二向划分不同的是，三向划分虽然拥有l、r、eq三个指针表示小于等于大于三个边界。但它只使用一个循环，即用eq指针从前到后遍历数组，而不是使用两个指针相向移动。当遇到大于pivot的数的时候，就把它扔到r指针位置，并更新r。当遇到小于pivot数的时候就把它和l指针互换，保证l左边都是小于pivot的数 326. Power of Three一道很有趣的题，要求不使用循环和递归来判断一个数是否是3的整数幂。我能想到是log，还有一个蹩脚的二分搜索。一个应该是最优解使用int范围内最大的3的幂1162261467来模这个数看是否能整除。这里解法就和Power of Four啥的不一样的这里用log+python的is_integer写了一发，发现math.log(243, 3).is_integer()返回False，所以还是要自己用eps判定下。 327. Count of Range Sum同样类似560，注意LL 328. Odd Even Linked List这道题很简单，实际上是一个无状态迭代的过程，可以想象为不断地take 2 lst。注意判断None。我们实现一个函数12def solve(odd, even) return nxt_odd, nxt_even 329. Longest Increasing Path in a Matrix这道题挺有意思，Topic有拓扑排序、DFS和记忆化搜索在里面。这道题同信封那条一样是天生偏序的，所以我们不需要vis数组，所以可以通过非常基础的DFS解决。题解中还提到了可以借助于拓扑排序来做，原理也很简单，因为矩阵中相邻节点的偏序关系可以类比成有向边，因此拓扑序一定存在。 330. Patching Array【这道题很有趣】首先我们计算nums中的数能够组成多少个和，我们对于每一个nums[i]，尝试加到集合中。这道题没有思路，后来接受了一个Hint，也就是考虑miss为[0, n]中间第一个不能表示的数。然后是一个key observation，当我们能表示[0, miss)时，如果引入一个新的x，那么我们能够表示[0, x + miss)的数了。那么我们希望这个x等于miss，这样能够最大化利用率。 332. Reconstruct Itinerary这道题之前好像在哪个微博上看到的，我还评论了一种可能的拓扑排序的做法。不过这道题目并不能这么做，因为我们可能重复到达某个机场（例如case2），因此并不存在一个特定的拓扑排序。那这道题就是一个简单的DFS么？也不是，虽然我们要求出发机场相同时按字符串大小选择目的机场，但这一切要建立在整个行程单存在的情况下！例如[[&quot;JFK&quot;,&quot;KUL&quot;],[&quot;JFK&quot;,&quot;NRT&quot;],[&quot;NRT&quot;,&quot;JFK&quot;]]就应该选择先去NRT而不是KUL。 335. Self Crossing给定一个长度为n的数组，表示分别向北、西、南、东走了多少铬，要求用一趟遍历和O(1)的空间去判断线路是否发生自交。这一道题我完全不会，为啥复杂度能做到这么低呢？其实这是有限制条件的，因为我们每一步一定是有方向转换的，我们没必要考虑全局。而这个实际上只有三种情况。分别对应于和-3、-4、-5相交。能不能和-1、-2相交呢？不可以，因为两个不在一个方向上。如果和-6相交（实际上是重合的情况），那么必然要和-5相交，同理，对-7也是这样。因此我们只要追溯到-5即可。具体地，我们是要追溯0和-3， 0和-4，0和-5的相交情况。用了这个模板算cross，其原理也就是跨立实验。即以一条线段为标准，另一条线段的两端点一定在这条线段的两边。但互相跨立并不能解决共线问题，所以还需要继续快速排斥实验。 336. Palindrome Pairs拿到题，想的是反向建Trie，然后对每一个终止状态判剩下的是不是回文串。然后我们对每个串遍历树，讨论到底是树短还是串短。对于树短，我们判断串多余的部分是否是回文；对于串短，我们dfs那个trie树，找到所有的合法路径。 337. House Robber III/这贼真是辛苦啊，这次是带权二叉树，同样不能相邻。感觉是树形DP模板题吧，一搜POJ2342。我们使用dp[i][0/1]表示是否抢劫第i个节点的情况，那么可以得到 dp[i][0] = max(dp[lson(i)][0], dp[lson(i)][1]) + max(dp[rson(i)][0], dp[rson(i)][1]) dp[i][1] = value[i] + dp[lson(i)][0] + dp[rson(i)][0] 容易看到这个DP可以用一次DFS求得 338. Counting Bits这条虽然可以按191的思路做，不过更好的方法是DP，以0011b为例，它中1的数目ans[0011b] = ans[0011b &gt;&gt; 1] + (0011b &amp; 1) 341. Flatten Nested List Iterator用个栈维护一下 342. Power of Four注意这一题是求是否是4的幂，而不是是否是4的倍数。这个很简单了，4的幂都是1(00)*这样的形式的 343. Integer Break经典的整数划分问题。这道题我记得看过推导是分成$N/e$个数为妙，不过我最后还是做了下记忆化搜索解决的。注意因为题目要求至少分两块，所以我们要存两个dp，一个是必须要分的，一个是可以不分的。这里额外说一下几个常见的整数划分问题： 将n划分为若干整数之和 这里设置一个k是为了去重 12// 这里k表示不超过k的整数dp[n][k] = dp[n - k][k] + dp[n][k - 1] 将n划分为若干不同整数之和 12// 这里k表示不超过k的整数dp[n][k] = dp[n - k][k - 1] + dp[n][k - 1] 将n划分为k个整数之和 12// 其中第一项为划分中不包含1的情况，第二项为划分中包含1的情况，注意不是dp[n][k - 1]dp[n][k] = dp[n - k][k] + dp[n - 1][k - 1] 将n分为k个整数的积，要求积最大，这也是最大分解问题 1dp[n] = max(dp[:k-1] * dp[k:]) 但是这一条有数学方法，主要可以考虑下面的性质： n的最大分解中不可能出现大于4的数 反证法，如果出现了m大于4，那么可以用(m-2)和2替换m，得到的积是2m-4&gt;m，矛盾 存在不含4的n的最大分解 这是因为我们可以把任意的4变成2*2，而不影响结果 最大分解中，一定不会出现1 综合上面三点，最大分解中一定只含有2和3，并且2的数量只能为0/1/2 这是因为3*3*3大于2*2 347. Top K Frequent Elements找到k个最频繁的数。我直接map+sort搞了。 352. Data Stream as Disjoint Intervals从一个流持续读取非负整数，要求随时输出当前所有整数构成的区间。这个有点类似于第228的Summary Ranges，但要求支持在线查询。此外，还有一个Follow Up，问如果合并次数非常多，不相交区间的数目很少，应当如何优化？应该是用一种树的数据结构来进行维护。我直接看题解了，原来使用红黑树进行维护。接着我们用类似于228的思想，查看是否需要合并左右区间。此外，似乎也可以用并查集来做，我们使用并查集来维护每一个节点属于哪一个集合。剩下来的就是我们需要知道这个节点是否存在，这个可以借助于一个map来实现。本题我是参照着题解用go实现的，主要涉及以下知识： 自定义struct 基于Node而不是数组实现的并查集，因为这条题目没有办法知道总的数据规模 在并查集Merge的时候同时更新状态 使用map，和用struct做结构的map go里面的“指针” 354. Russian Doll Envelopes这题很好用记忆化搜索做，因为信封之间是偏序的，即如果信封A能dfs到信封B，则信封B肯定不能dfs到信封A，因此dfs的时候不需要维护状态。不过撸了个Python版本的，超时了。后来发现要$O(nlogn)$才能保证过，不过C++又没卡住$O(n^2)$的复杂度。后来发现这道题可以转化为LIS来做，把w看成横坐标，h看成纵坐标，我们实际上是要找h的最长的上升子序列。注意为了处理横坐标相等的情况，需要在此时将纵坐标从大到小排列，以便bisect_left能够定位到准确位置。 357. Count Numbers with Unique Digits又到了我喜欢的数位DP时间。又被算公式的大佬虐了，由于这条的区间很整，所以算公式反而简单。 363. Max Sum of Rectangle No Larger Than K这道题到现在还是T的状态。这道题和前面的Maximal Rectangle有点像，这次我们来看一个不一样的DP方法，也就是将其转化为一维DP问题来做。这条的复杂度应该是$O(X^2 \times Y \, logY)$，其中$X, Y$分别为矩阵的长和宽之间的较小/大值。前面的O(X^2)很简单，可以仿照红书上的最大权自矩形来做。假设这个矩阵列数很多，我们维护一个列的累加和sum 1 1 1 1 1 1 1 1 1 =&gt; 2 2 2 1 1 1 3 3 3 然后我们枚举所有的(up, down)，例如当枚举到(1, 2)时，我们计算一个sub表示所有上底为第1行下底为第2行的“棍状数列”的和。接下来我们采取同样的办法计算sub的累加和arr sub = (3-2) (3-2) (3-2) = 1 1 1 arr = 1 2 3 于是我们的任务就变成了在arr中找到$l &lt; r$，使得$arr[r] - arr[l]$是满足小于$k$最大的数。因此我们可以从i开始遍历arr，然后在一个数据结构内花$O(log n)$查询最接近$arr[i] - k$的值，然后再花$O(log n)$将$arr[i]$放到这个数据结构里面。显然我们可以用一个二叉树来维护，但是我T了，不知道为啥这里说明一下题解上有人用bisect.insort()，注意这个复杂度是$O(n)$的，我之前写的代码效率不高，所以被卡常了。倒是C++里面的set和map啥的有lower_bound。使用二叉树之后反而更垃圾了。 368. Largest Divisible Subset第一眼看到，觉得是一个LIS的题目。结果也确实就是这么简单，$O(n^2)$直接过了 371. Sum of Two Integers用位实现加法，我可是刷过CSAPP的人啊。 372. Super Pow请移步Kickstart2017G题目A 373. Find K Pairs with Smallest Sums这道题就是在[i+1,j]和[i,j+1]里面选一个 375. Guess Number Higher or Lower II简单写了个dfs结果T了，加了个二维的记忆化搜索就AC了。。。注意数组要开到1000。 376. Wiggle Subsequence一开始的想法是仿照直方图那一条，对于每一个位置i，找到它前面的up和down位置，然后统计lenup和lendown，但这个思路是错的，因为我们不一定会从前一个位置开始。现在我们考虑能不能将这道题转化为最长上升子序列LIS来做。用up[i]表示长度为i的最后为上升序列的末尾元素的值，而down[i]为最后为下降序列的末尾元素的值。不过后来发现这个不能做到是有序的，所以没办法二分。因此实际上我们只要从尾部开始遍历即可。然后发现题目要求是$O(n)$的，看了题解，这道题有一种很妙的贪心方法。1234567891011121314151617def wiggleMaxLength(self, nums): """ :type nums: List[int] :rtype: int """ p = 1 q = 1 n = len(nums) if n == 0: return 0 for i in xrange(1, n): if nums[i] &gt; nums[i - 1]: p = q + 1 elif nums[i] &lt; nums[i - 1]: q = p + 1 return min(n, max(p, q)) 377. Combination Sum IV看起来这道题目要求一个完全背包有多少组解。不过后来发现，我们要求的是排列数而不是组合数。这反而简单了，事实上这类似之前的整数划分问题。我们用dp[i]维护和为i有多少种方案，则我们对于所有i，尝试对所有的nums[j]，更新dp[i + nums[j]] += dp[i]。这类似于之前算平方数的解法。 378. Kth Smallest Element in a Sorted Matrix这道题很简单，直接模拟归并排序就行了，我用了堆来简化。二分答案应该也可以做，没有试。 381. Insert Delete GetRandom O(1) - Duplicates allowed用O(1)的复杂度实现insert()、remove()和getRandom()。其中getRandom()要根据每个数字的出现次数来平均分配。首先，既然需要随机，那么我们肯定要维护一个向量表，然后随机它的索引。既然如此，我们如何去对这个向量表进行动态增删呢？主要问题就是删，这里可以借助于C++里面的库函数pop_heap的类似做法来实现，也就是说将要删除的元素和列表末尾的某个元素交换，然后再把列表末尾的元素给pop掉。为了实现这一点，我们就需要为这个向量表建立一个索引表这个题目的insert和remove的返回值的要求很奇怪，WA了半天 382. Linked List Random Node从长度未知的链表中随机取出一个节点。这一道题是非常著名的水塘抽样算法。我们首先清楚一个事实，n件物品让n个人选，那么先拿的人和后拿的人获取物品x的概率是一样的。第一个人的概率是$\frac{1}{n}$，第二个人的概率是$\frac{n-1}{n} \times \frac{1}{n-1} = \frac{1}{n}$。这道题也是一样，我们对于第$i$个数，按照$\frac{1}{i}$的概率替换掉已有的数。 386. Lexicographical Numbers又是和数位DP类似的题目，各种WA。总结一下 如果pos &lt; ll - 1，那么从0一直dfs到9 如果pos == ll - 1，此时我们在处理最末位。我们考虑目前的前缀prev 如果是一个不合法的前缀。我们更新prev考虑两种情况，第一个是原prev不合法，那么新prev也不合法；第二个是prev虽然合法，但是是满的，而当前的位超过了nums。对于不合法的前缀，我们不能往下dfs。 如果是一个合法的前缀。我们dfs到nums 387. First Unique Character in a String一开始做了个字典，居然T了。得手动维护一个vis数组 390. Elimination Game这道题和经典的约瑟夫和问题看起来有点像。当时觉得每次的起始值难算，所以就简单模拟了下，T了。继而我们发现对于任意偶数n，n + 1的答案和n肯定是相等的。看来需要$O(logn)$的复杂度了。于是觉得确实可以把每次扫描数列作为一个子问题，但是我们现在对某个子问题不生成新数组，而是在原数组上进行操作。于是我们维护了s和e，表示我们的起始点和期望的结束点（也就是现在子数列的最末端），设置step为当前的公差。如对1 2 3 4而言，s为1、e为4（不是3），而step为2。容易发现由于我们是偶数项，所以我们只能遍历delta = 2项，并没能遍历到4。我们发现规律，我们每次遍历，要不能遍历到e要不我们能遍历到actual_e，并且actual_e和e相差step / 2。于是我们能够得到新的起点的位置12345if actual_e != e: news = e // Or news = actual_e + step / 2else: news = e - step / 2 392. Is Subsequence求串s是否是串t的子序列，s范围到500000。朴素做法就是贪一下，$O(n^2)$。【这道题还有Follow Up】 396. Rotate Function一看这道题想到的第一就是排序不等式，不过这道题只能rotate而不是任意shuffle，所以不能直接套排序不等式。一个直截了当的办法，根据Topic中Math的提示，我们需要推一个公式。首先我们设首项$X_0 = \sum^{n - 1}_{0}{i \times a[i]}$，则$X_k = \sum^{n - 1}_{0}{((i + k) \% n) \times a[i]}$，发现减不了。不过如果直接找规律的话，我们发现$X_i$就是将第$(-i) % n$项置为0，然后其他项都自己加上自己下。因此递推公式很好求了$X = X - (n - 1) * A[(-i \% n)] + s - A[(-i \% n)]$ 397. Integer Replacement一开始我的想法是能/2就/2，因为除法始终能减少一位，而减法只有在2的整数次幂的时候才会减少一位。下面要考虑的就是当低位为k个0的时候我们如何选择是+还是-。显然如果低位只有一个连续的1，那么肯定选择-，如果低位只有两个连续的1，我们分别计算，如果选择+，那么最快的转化是0b11 -&gt; 0b100 -&gt; 0b10 -&gt; 0b1，如果选择-，则最快的转化是0b11 -&gt; 0b10 -&gt; 0b1，因此选择-。同理我们发现当7时两者相等。不过这种解法WA在了1234，我的答案是17，而标准答案是14。后来发现把if n &amp; x == x写成了if n &amp; x，不过10000WA成了17。于是对拍了一下，发现59（0b111011）这个点WA了，正确答案应该是8，应该首先变为0b111100，这样前面就变成了4个1了。这是因为末三位011的策略被选为了-，而正确的策略应该是+。因此我们发现先前的最优策略建立在不考虑高位的情况下，而这对于3来说是不适用的。现在我们综合考虑高位有1的情况，如1011/10011等，我们发现这种情况下应当选择+。12345678910// ACelif (n &amp; 3 == 3) and (n != 3): n += 1else: n -= 1// WAelif n &amp; 7 == 7: n += 1else: n -= 1 400. Nth Digit居然打败了100%，这道题WA得好苦，其实细心一点就行 403. Frog Jump有n个石头，坐标给定。青蛙在第一个石头上，希望能到最后一个石头上。青蛙第一次只能跳一格，假设第i次跳了k格，那么青蛙第i + 1次能跳[k - 1, k, k + 1]格，注意青蛙只能往前跳。问青蛙能否做到。记搜一波呗，T在Case 34，后来加了个剪枝，A了，不过只打败了3.9%。题解给出了一种更好的办法，也就是用int key = pos | k &lt;&lt; 11;做key，然后hash，而不是用二维数组。 406. Queue Reconstruction by Height这道题让我想起了315的那个树状数组的题目，其实这道题为了不T，还真的要树状一下。注意当有多个k符合条件的时候我们要选择h最小的。卧槽不仅要树状还要离散化。。。然后还是T了。其实这道题应该是$O(n^2)$的，是一个类似插入排序的思路。 407. Trapping Rain Water II这次是二维的问题了，然后我们要注意边缘没有“墙”，也就是四周无法盛水。一开始想的是假设从点$(x, y)$往下倒水，那么水最多能流到哪里，后来发现不好操作，因为每一点的水位高度取决于其周围的方块高度，而这个是递归的。后来发现我们不考虑灌水而考虑漏水，可以将场景看成亚特兰蒂斯，然后水从边缘逐渐退去。我们用level[x][y]表示点$(x, y)$处的水位，我们查看从$(x, y)$能不能放跑其周围方块$(nx, ny)$中的水，这体现在$(x, y)$处的水位level[x][y]低于$(nx, ny)$的水位。我们注意要保证$(nx, ny)$的水位是至少heightMap[nx][ny]的，这样就相当于没有存水。但是我们却不能一开始就设置level[nx][ny] = heightMap[nx][ny]，这样我们就无水可漏，倒是在边缘的level要这么设，因为他们一定不能存水。然后发现其实一开始的思路也可做，不过我们首先需要按高度从低到高选取方块。为了实现这个顺序，我们需要进行优先队列+BFS。每次我们从优先队列中取出水位level（注意不是heightMap）最低的方块，然后查看它是否可以存放更多的水。这里有两种情况，第一种是该方块的四个邻居严格高于自己，这样我们可以补齐该方块的水位。第二种是出现了水位相同的邻居，这时候我们需要用一个dfs来搜一下。 410. Split Array Largest Sum将长度为n的串分为m块，要求最小化最大的块的和。能贪么？想了想[2, 5, 6]分两块，贪的话就[2]、[5, 6]了。用DP做，发现我们要求的是min-max在i位置在第j块的和。这道题的DP做法我们同样是维护dp[i][j]为前i个数字分成j组的最小的子数组最大和。计算dp[i][j]时我们可以考虑将它放到前一块中去，或者新开一个块，因此递推方程是dp[i][j] = min(max(dp[i - 1][j - 1], nums[i]), dp[i - 1][j] + nums[i])。但这个递推式是错的，连题目给的样例都通不过。这是因为我们不能断定在i - 1时就是最优子结构，因此我们需要遍历所有的dp[0..(i-1)][j - 1]才行。题解还说原来这条可以二分答案。。。。因为是非负整数。。。。唉，果然二分答案和记搜是拯救DP苦手的神器啊！ 413. Arithmetic Slices给定一个序列，问有多少个子串是等差的。感觉很简单啊，因为是子串而不是子序列嘛，直接统计一下完事了。 414. Third Maximum Number水题，用个优先队列 416. Partition Equal Subset Sum背包问题不解释 417. Pacific Atlantic Water Flow据说是Google北美的面试题。所以你家你家现在输出又是[]不是[[]]`了，真的搞不懂。。。这道题就是dfs两次啊，matrix需要预先包裹处理一下。注意填充的初始值是-1而不是0，因为有0的cell。 421. Maximum XOR of Two Numbers in an Array要求在线性时间内找到数组中两个元素的异或的最大值。看看相关Topic，居然是Trie？想了想确实有道理，整个过程类似于在Trie树上递归，对于Trie树的某个节点有0个或1个孩子的情况都很好处理。但当某个节点具有两个孩子时就比较麻烦，我们需要跨两个树进行比较，看来我们不应该在树上递归。这道题目挺难的，我直接看题解了。首先我们尽可能地希望高位是1，然后对后面的位我们迭代解一个子问题，迭代次数是和字长相关的常数。因此在第i次迭代中我们希望能够用少于$O(n^2)$的时间来判定当前i - 1位是最优的情况下，第i高位是否能取到1。以样例3, 10, 5, 8为例，其二进制[0011, 1010, 0101, 1000]。首先查看这四个数的最高位[0, 1, 0, 1]，我们需要检测是否有两个数满足$a \hat{} b = 1$，这同样是个$O(n^2)$得到过程。为了能够减少复杂度，我们可以运用异或的性质$a \hat{} b = x \Rightarrow a \hat{} x = b$，将问题转变为是否存在$a, b$满足$1 \hat{} a = b$，因此我们只要维护一个Map或者Dict对于任意的$a$，寻找Map或者Dict是否存在$1 \hat{} a$，总复杂度可以降为$O(n)$或者$O(n \ lgn)$。在实现的时候，我没有用Map或者Dict，而是用了Trie，这样做前缀比较方便。【这道题还有其他的解法】 424. Longest Repeating Character Replacement允许替换X次，求最长的Repeat子串。这道题我们要注意必须向两边搜，例如BAAAB，不能以开头的B为主元。因此朴素是$O(n^{2k})$的，我们需要枚举向两边搜的长度。然后我想到能否二分答案，对于每一个可能的长度length，我们找到所有的s[i:i+length]，来验证它们是否可行。这样的验证是平凡的，我们只需要找到数量最多的元素，看看它的数量加上k能不能大于等于length即可。这个方法是$O(n^2 lgn)$的，T了，这是因为check函数是$O(n^2)$的，我们可以优化掉一个$n$，但这仍然是T的。后来我发现其实完全没有必要二分答案啊，我们将k移到不等号的右边。 427. Construct Quad Tree给定一个N*N的矩阵，N是的幂，要求构造一个四叉树。递归搞一下就行了 434. Number of Segments in a String简单题 435. Non-overlapping IntervalsTODO给定一些区间，问至少移除多少区间，才能让它们彼此都不重叠。这道题看起来就是一个贪心。我尝试以每条线段和其他线段的overlap的次数做参考，每一次选择次数最多的线段删掉。但是这样会WA在\[\]\[\]int\{\{0,2\},\{1,3\},\{1,3\},\{2,4\},\{3,5\},\{3,5\},\{4,6\}\}这个case上面。猜想是重复的问题，于是我尝试去重，结果倒在倒数第二个case上面。那个case真大，希望后面能找到一个简洁的反例。。。。最后解决方案是按照右边界排序，然后贪心过一遍就行。其实我觉得这一类区间Interval相关的问题，一般都会涉及按照左端点或者右端点进行排序。 437. Path Sum III建一棵和树st，然后dfs这个树，并且按照类似560的办法维护一个哈希集。WA了蛮多次，都是粗心，比如说要有d[need] &gt; 0的判断，和+= d[need]而不是+=1 440. K-th Smallest in Lexicographical Order这道题其实就是对一个十叉树进行先根遍历，不过普通的搜会T。所以要做到log的复杂度，不过我WA了好多发。一开始我希望能够仿照数位DP，计算长度为len的以i开头的数字有多少个。不过这道题这么做并不讨巧，因为我们只限定了长度len，而没有限定位置pos，而在不同的pos，由n给定的end是不同的。而我使用了三维数组之后发现这次记搜根本不会被Hit了。这道题的正解，可以分为两步，第一步是求一个节点包含自己的所有子孙的节点总数；第二步是找出第k个节点。 442. Find All Duplicates in an Array【这一条有多种解法，值得一看】这是第287条的升级版，我们记得上一条是用的二分答案，但这一条不行了吧。但是我们发现Range是[1..n]，我们可以从这上面下功夫。这个有点类似于第41条的思路，我们希望通过交换将nums[i] = x移到x - 1的位置上去。如果此时x - 1位置上的值nums[x - 1]也是x，那么我们就可以知道x是重复的了；如果是y，那么我们就将x与y交换，这样x就回到了正确的位置上，而我们下面继续将nums[i] = y归位，这个循环一直执行到nums[i] = i + 1，然后我们处理下一个位置i + 1。这道题击败了99.93%。。。 446. Arithmetic Slices II - Subsequence首先来一波暴力的dfs，果断T了。看看能不能改成记搜，这里的麻烦之处是状态很难解决，因为公差和末项可能很大，难以存储。然后我想到$N$只有1000，所以可以离散化公差是一个思路，不过好像还是会超空间。通过题解，发现可用数列的末两项（用首两项也行）来离散化首项+公差，不过这次T在了69/101，比之前的39/101稍有进步。后来给l == 1也加上记搜，发现就WA了，后来想想居然也不知道为啥l == 2情况记搜就能过，先放这儿把。不过发现都不能记搜l == 1的情况，否则结果都会被置为0（如果先搜不选的情况的话）。以末两项[2, 4, 6]为例，考虑我们2不取，这时末两项为(4, 6)且l == 2，不能构成等差数列，那么搜索会记dp[1][2] = 0，仔细考虑这种情况，是因为我们没有将l`纳入考虑。再考虑首两项的情况也类似。 这道题之前一直尝试记忆搜索，不过一直没搞定，后来发现直接DP反而更简单。不过后来发现O(n^3)会T在78/101。后来看了题解知道由于可能的差是很少的，所以我们可以维护一个反查的dict。 448. Find All Numbers Disappeared in an Array简单题，类似于442题 449. Serialize and Deserialize BST由于是BST，所以根据中序遍历就行了，但是这道题我用Python写在最后一个点MLE了。。。 451. Sort Characters By Frequency简单题。 452. Minimum Number of Arrows to Burst Balloons有若干起点和终点的horizontal线段，问最少用多少条vertical直线才能全部与它们相交。这道题并不是问若干直线最多能经过多少条线段，而是需要全部相交，那么方法就很明显了，按照起点排序然后贪心。 453. Minimum Moves to Equal Array Elements操作只能是对n-1个元素进行自增。我们注意到对n-1个元素自增相当于对唯一一个元素自减。 456. 132 Pattern这道题非常好，我只想出了$O(n^2)$的方法，但正解要$O(n)$。具体做法看我源码里面的注释。 459. Repeated Substring Pattern很好地简单题，细节蛮多的 462. Minimum Moves to Equal Array Elements II相比上一题，这道题允许选择任意元素+1或者-1。一开始我觉得是尽量往平均数靠拢，但Case[1,0,0,8,6]会WA。其实这道题是求绝对值距离最小，通过Google，这其实是最小一乘法的一个结论，应当选取中位数。Leetcode上还提供了一个类似贪心的解法，也就是先排序，然后每次选取一个最高分一个最低分，让他们相等，然后去掉。 463. Island Perimeter这条不需要DFS哦 464. Can I WinAlice和Bob轮流从[1..maxChoosableInteger]中取数字加到一个总和上，不能重复取，最先达到或者超过desiredTotal的就胜利。问先手能不能胜利，maxChoosableInteger小于20，desiredTotal小于300。先来个AlphaBeta剪枝（原理见486），WA了，10 40的样例我输出true。去掉剪枝，连dfs都是错的，反省一下自己的思路，我是直接dfs，然后当和大于desiredTotal，就更新self.best，这是错误的，因为没有考虑对手的optimal选择。其实来一波记搜就好了。注意记搜不要和AlphaBeta剪枝一起使用。 467. Unique Substrings in Wraparound String这道是DP，由于要考虑重复的问题所以不能直接算。蛮要想的，原理是dp[x]表示以x结尾的连续串的最长长度。这样最末位的元素不同就能保证了。然后注意不是dp[p[i]] = dp[p[i - 1]] + 1啊，因为dp[p[i - 1]]的最大值不一定在这里取到。 473. Matchsticks to Square由于火柴棒长度很长，所以不能背包（超大背包啥的也算了）。这道题就是老老实实DFS，然而我怎么样都TLE。记忆化+bitmask居然更慢。有人说先DFS分成两个，再分成四个，不过很慢。网上看到一个题解，使用了一个非常好的DFS方法，它每一个dfs枚举火柴i放在第j个边上。这样相比我们每一个dfs试图把剩余的某个火柴加到现在的和里要快些。 474. Ones and Zeroes二维费用背包模板题 475. Heaters476. Number Complement还是得while x &gt;&gt;= 1一下的。。。 477. Total Hamming Distance这条直接按位统计0和1的数量，然后计算乘积的和就可以了 478. Generate Random Point in a Circle如果去sample一个圆周，很简单，那么如何sample一个圆呢？最简单的方法是所谓的rejection method，我们去sample圆的一个外接正方形是容易的，然后我们while掉在圆外面的点即可。但其实我们可以通过修改sample圆周的方法来解决这个问题，令随机量为$u$，我们也就是将$r = R * u$改为$r = R * \sqrt{u}$即可。为什么其sqrt，其原因很简单。因为对面积均匀划分，我们实际上要$\pi r^2 * u$是要得到这样的一个均匀的统计量。化简一下就能得到一个根号了。 480. Sliding Window Median这个得用C++做，其原理是利用multiset的动态排序功能 481. Magical String一个很有趣的问题。给定序列1 22 11 2 1 22 1 22 11 2 11 22，我们统计连续数字的长度，得到如下的序列1 2 2 1 1 2 1 2 2 1 2 2。发现这两个序列是同构的。现在要问前N(N&lt;100000)里面有几个1。这个可以顺着推出来，类似DNA转录那样，我们双指针维护一个转录列表指针和读取指针即可。 483. Smallest Good Base这个妹(ti)妹(mu)我是见过的，其实就是算满足$x^0 + x^1 + … + x^{k-1} == n$的最小$x$。要解这个方程，不会怎么办，考虑到n才到10 ** 18，令x == 2的话k也才到61，这里就枚举k咯，然后x直接二分即可，下界注意是2不是3，我在这里WA了一次，上界的话我不会解那个不等式，直接令到10 ** 18居然也过了 486. Predict the Winner【本题是AlphaBeta剪枝暴力掉的，但可以DP】两个人轮流从数组两端取数字，和最大的胜利。数组最长为20。本题可以用AlphaBeta剪枝来做，Python会被卡掉，但是C++能过。AlphaBeta剪枝的主体仍然是一个dfs，并且我们需要一个评价函数来评估目前的局势。Alpha指的是在自己的回合（MAX节点），自己能确保的最利于自己的值。Beta指的是在对手的回合（MIN节点），对手能确保的最不利自己的值。MINMAX博弈假设对手拥有完全信息，总是能做出完美决策，所以对手要最小化评价函数的增益。容易发现初始情况下取Alpha/Beta为-Inf/+Inf，由于我们还没进入游戏，所以这是可能的最高/低分。容易发现我们的目标是尽可能提高Alpha值。现在考虑DFS的过程，我们首先以一个MAX节点作为根往下遍历，我们首先递归地计算其第一个MIN子节点的Beta值（MIN节点的计算将在下面论述），这时候根节点取该Beta值为自己的Alpha值。从目前看，结果不会比它更坏，但是我们不能就此停住，而是要接着遍历，看看有没有更好的结果，即我们取所有的Beta值里面最高的作为我们MAX节点的Alpha值。在计算完第一个节点后，我们递归计算第二个MIN节点，在计算开始时，我们要通知这个MIN节点当前的Alpha值。下面我们来跟踪这个MIN节点计算自己的Beta值的过程，MIN节点的子节点是MAX节点，所以这个MIN节点需要取自己所有子节点的最小的Alpha值作为最终的Beta值。ALphaBeta剪枝认为此时不需要遍历所有的节点，因为一旦我们发现当前的Beta值低于父MAX节点所通告的Alpha值，那么我们在父MAX节点肯定不会选择我们当前的MIN节点了，于是可以剪枝，即我们不需要算完这个MIN节点了。同理，以某个MIN节点为根向下遍历，也是先选取第一个子MAX节点的Beta值，然后通告给第二个子MAX节点。由于根节点MIN要选择尽可能小的，所以如果子MAX节点的Alpha值大于通告的Beta值，也进行剪枝。对于本题，剩下的工作就是选取一个适合的评价函数，这里选取两者和的差即可。 491. Increasing Subsequences【不使用set如何做呢？Leetcode上似乎有一个Discuss】用一个set来维护已有的上升序列，对于i位置的考虑能否扩展set中的序列。注意需要去重，这里用了一个很投机取巧的办法，虽然Python不能序列化list，但是可以序列化str或者tuple，所以。。。不过下面我们来考虑普通的DFS的方法，我们如何来去重？一开始我想的是根据长度和最后一个元素来去重，认为以某个元素结尾的固定长度的递增序列是固定的。 493. Reverse Pairs这是一个变种的逆序对，即现在逆序对不仅是nums[i] &gt; nums[j]，而要满足nums[i] &gt; 2*nums[j]。一般逆序对可以借助于树状数组和分治法来做。树状数组的做法基于它能够在$O(log n)$的时间内求出$A[1..n]$的和。这里的A其实是一个01数组，A[x]表示数字x是否存在。因此我们小于x的元素的数量是A[1..x-1]的和，可以通过树状数组快速求出。现在我们遍历nums中的每个数字x，并修改A[x] = 1，那么包含x的逆序对的数量就是目前树状数组中值大于$x$的元素的数量，因为这些本来应该在x遍历到之后再被遍历的。这条如果用树状数组来做的话，A需要离散化。在离散化的同时需要处理好找不到的两种情况。 494. Target Sum这是一条变种的01背包，我们需要求一个和为(S + sum(nums))/2的子集。 495. Teemo Attacking这道题就是说在技能冷却的时候放技能不能重复统计技能有效时间，数组是有序的，因此我们直接维护一个边界r，每次根据起始时间是否与r重叠讨论，最后更新r即可。 498. Diagonal Traverse对角遍历矩阵。这道题其实不难了，遍历就两个方向交替，主要就是越界时改变方向需要想几个样例找规律即可。总结下来就是一般出格时只需要将导致出格的那个速度分量保持不动，另外一个坐标直接+1。不过还有一个特殊情况就是在矩阵四角，两个速度分量都会导致出格。 502. IPO一开始有W的钱，用它在n个项目里面选k个来做，项目i需要C[i]的启动资金，带来P[i]的纯利润，问最后能够达到的最大的资本是多少。用两个PQ维护一下就行了。 503. Next Greater Element II数组复制一遍，然后对于每一个元素如果比栈顶小就入栈，否则就出栈 504. Base 7简单题 513. Find Bottom Left Tree ValueBFS即可 514. Freedom Trail很明显是DP，用dp维护准备填入i字符时轮盘指向j的最少步数，那么对于每一个(i, j)，我们查看所有的k到j的最短距离。这里要注意一下最短距离是min((j - k) % m, (k - j) % m)，而不是abs(j - k) % m。 515. Find Largest Value in Each Tree Row二叉树层次遍历，么得意思 516. Longest Palindromic Subsequence最长回文序列（不是串了）。这道题又是$O(n^2)$然后Python的T，C++的AC的题目。。。我们用dp[i][j]维护[0,i]和[j,n-1]这两个区间上对称字符串的长度。例如bbbab中[0,1]区间上是bb，[4,4]区间上是b，左边的一个b能和右边的一个b对应，因此dp[1][4]是2。而我们最长的回文序列的长度有两种情况。第一种是[0,i] [i+1,n-1]这样，那么结果是dp[i][i+1]；第二种是[0,i] [i+2,n-1]这样的，也就是说长度是奇数，中间夹了个i+1位置的，这种结果是dp[i][i+2] + 1。注意初始化的时候应该首先将dp设为0（而不是1），然后预先计算dp[0][j]和dp[i][n-1] 517. Super Washing Machinesemmmm，洗衣机，让我想到某次区域赛的赛题。题意是有n个洗衣机，里面衣服的数量用一个数组machines表示。每一次行动时，需要选择任意的m个洗衣机，同时将每个洗衣机中间的一件衣服移到相邻的洗衣机中。要求输出使得每个洗衣机中衣服数量相等的最少的移动次数。每个洗衣机里面最多有1e5件衣服，最多有10000个洗衣机。从数据规模上来看，我们无法维护每一个洗衣机的状态。其实，我们可以算出最终一个洗衣机里面要放多少衣服，因为衣服是要逐个洗衣机进行移动的，所以我们可以统计每一个洗衣机左边和右边分别有多少衣服，就能知道这个洗衣机要执行多少次移动操作了。问题是，但是这里面有多少移动操作是可以并行执行的呢？我们可以算得lb[i]表示洗衣机i左边还需要多少衣服，rb[i]表示右边还需要多少衣服，m[i]表示i当前有几件衣服。如果m[i] &gt; 0 &amp;&amp; lb[i] &gt; 0，那么则可以进行一次向左移动，m[i] &gt; 0 &amp;&amp; rb[i] &gt; 0则可以进行一次向右移动。那么，只要能整除，就一定能达到最后的解。这个解法T在第105/120个TestCase 题解是O(n)的，很神奇。我们从左到右遍历数组，维护一个balance是累计和，表示到现在为止，需要向右边拿/然后，我们还要考虑每个洗衣机都要送多少衣服，这个也要最大值。我们不考虑每个洗衣机要拿多少衣服，因为它可能从不同的洗衣机拿衣服，例如我们取Abs，就会WA在[9,1,8,8,9]这个case上面。上面两个检验是必要的，但为什么是充分的呢？TODO 518. Coin Change 2见343 523. Continuous Subarray Sum【有趣而且坑多】这道题很有趣，我虽然过了，但是$O(kn)$而不是最优解$O(n)$。题目要求判断是否存在一个长度大于等于2的子数组，它的和是k的倍数。那么我们维护到i为止所有以nums[i - 1]为结尾的后缀和到一个集合s中，对于i，我们检查(k - nums[i]) % k是否存在于set中即可。我们注意要在检查完之后更新集合s，也就是将集合中的所有数（同余地）加上nums[i]，并且在集合中加上nums[i]。枚举一下这道题一不小心会遇到的坑：k为0（数组中含有/不含有/连续/不连续的0），k为1（这个一定成立），k为负数。下面是这道题的$O(n)$解法，如果当前的累加和除以k得到的余数在set中已经存在了，那么说明之前必定有一段子数组和可以整除k。 524. Longest Word in Dictionary through Deleting这道题先排个序，然后对d中每一个x用$O(n)$的时间来计算一下能否通过删除s中的某几个字符得到。 525. Contiguous Array用C++做，本题可以规约到560这种形式 526. Beautiful Arrangement记搜 528. Random Pick with Weight让我想起了382的那个水塘抽样算法。这道题实际上是有放回的，所以很简单。直接二分累积和，找最小的大于ran的self.r[i]。其中ran = random.randint(1, self.r[-1])，注意不是1，因为至少要取一个。 540. Single Element in a Sorted Array异或的基本性质 546. Remove Boxes有点像312那条打气球的题目和488的Zuma球。这条裸DFS显然会T，如果使用普通的记搜，下层递归如何处理由于上层递归中的某个Box被移除导致两边颜色相同的Box连起来的情况呢？我们如果记录一下哪些Box被移除了，那我们status的长度最多是100位，这肯定是要爆的，所以我们得想想用其他的东西来描述状态。在另一方面，根据经验，使用dp[l][r]维护一段区间内的最优解是容易想到的。进而我们想到dp[l][r]的最优解一定是盒子被全部移除之后的（否则我们总可以再移除一个盒子以得到更优解），而在dfs(l, r)前这段区间里面的Box都是存在的。于是我们实际上就可以特判一下L[take-1][0]和L[take+1][0]是否相等然后做个合并就行了。但这样是错误的，因为我们是二分的区间，只切一刀，这样无法得到下面这种情况的最优解。 (1,1) | best_solution | (1,1) 因为无论我们这一刀切在哪里，中间的best_solution都会错误地和后面的(1,1)做合并。于是我们 (1,1) | not_best_solution 于是我们的应对之策就是在枚举一下第一刀切在哪里，不过这个做法也不行，我们看下面的样例，正解应该是14。但是我们切两刀也是不行的，于是乎发现这道题似乎不能靠切。。。 1, 2, 2, 1, 3, 1 所以最终结果是这一条我不会。。。看题解，dp[l][r][k]表示有k个后缀和nums[r]一样的情况下l到r得分最大。于是我们有两种case，将L[r]和后面的k个合并，或者将L[r]和某个l &lt;= pos &lt;= r合并。https://leetcode.com/problems/remove-boxes/discuss/101314/C++-29ms-dp-solution! 547. Friend Circles统计连通分量了，和之前一条海岛的题目挺像的，直接DFS。 552. Student Attendance Record II这道题当时想直接推个公式，但是好像比较难。然后我决定分两部分来考虑，首先不考虑缺席A的情况。那么问题变成计算不能超过连续两个迟到L的方案数。这是一个简单的DP。我们分别用P[i]和L[i]表示第i天选择出勤和迟到的方案数，则递推关系如下。1234# 第i天出勤则第i-1天可以出勤或者不出勤P[i] = (L[i - 1] + P[i - 1]) % M# 第i天不出勤，要么第i-1天出勤，要么第i-2天出勤，不能两天都不出勤L[i] = (P[i - 2] + P[i - 1]) % M 下面我们考虑缺席A就很简单了，假设一次不缺席，问题退化成上面的解答。假如缺席一次，我们就枚举缺席的那一天，然后题目变为了两个上面的情况。 553. Optimal Division这条随便写一下居然击败了99.4%的人，感觉写的常数很大啊。mx和mi维护了区间[i,j]上的最大值，计算这个枚举分割点k就可以了。WA了一次是因为可能不分割，例如[6,2,3,4,5]应当是6/(2/3/4/5)，后面的2,3,4,5不需要分隔。我们还要返回一个具体的括号方案，这个就使用pmx和pmi来维护两边的字符串，注意当只有一个数字的时候不要加括号。 554. Brick Wall556. Next Greater Element III这个类似Next Permutation那条，直接找到第一个上升型，然后用它之后的大于它的最小数来交换。注意要判断爆int的情况，WA了好几次。 560. Subarray Sum Equals K这是类似Two sum一类的Hash经典题，我们要求是否存在j使得sum[i]-sum[j]==k也就是求对于任意的i，是否存在sum[j]==sum[i]-k 561. Array Partition I排序一下，然后就是结果。。。 576. Out of Boundary Paths哎，和之前那个骑马的概率DP蛮像的，这边其实也能正过来推的哦。 583. Delete Operation for Two Strings最短编辑距离模板题 594. Longest Harmonious Subsequence找最长的子序列，要求序列中的值的差为1。简单题 600. Non-negative Integers without Consecutive Ones无脑数位DP 605. Can Place Flowers简单题，注意边界情况 611. Valid Triangle Number首先sort一下是肯定的。枚举i、j二分最后一个长度，T在了219/220。那应该是$O(n^2)$了。我们考虑每个数的范围最多直到1000，因此考虑统计le_n[x]为小于等于x的数的数量。那么我们考虑a[i] &lt; a[j] &lt; a[k]，我们从0开始遍历j（为什么是j不是k稍后说明），此时我们的le_n更新到nums[j]了。我们考虑，要满足a[i] + a[j] &lt; a[k]，我们不妨考虑反例，也就是a[i] &lt;= a[k] - a[j]。那么我们从j + 1开始遍历k，我们就可以得到满足以上条件的a[i]的上界。因此我们可以le_n来确定有多少个这样的x &lt;= a[i]。注意一下这里a[k] - a[j]是可能大于a[j]的，这样就不满足a[i] &lt; a[j] &lt; a[k]，因此我们查表的时候应当是取min(a[k] - a[j], a[j])的，否则会重复计算。 617. Merge Two Binary Trees简单题 621. Task Scheduler假设在i时刻执行了任务A，那么任务A下一次至少在i + n + 1时刻才能执行，问全部执行完的时间。由于最多26个任务，我们统计一下对应的Nd(task_name, count)，然后每一次选取能够执行的、并且数量最多的任务来执行，否则这个时间就闲置。有一个WA的点是要考虑到比较Nd涉及到与当前时间相关的全局变量global_t，所以每一次时间戳更新之后堆里面的排序都要重新调整。考虑到最多26个项目，所以我直接用了一个list，然后每次sort一下。然后开始疯狂T，这里我的d = {i:tasks.count(i) for i in tasks}写法又贡献了一点功劳，但修改之后还是只能过35/62个样例。其实题解根本就不要考虑global_t，而是直接算。这和之前做过的一条有点像，就是就着数量最多的来。我们考虑假设有most_cnt个数量最多的任务，例如这里most_cnt为2，设这两个任务为A和B，各有most个。那么根据上面的结论最优解是ABXXXABXXXABXXXAB，其中X`首先用其他的字母填，不行了就得补空。 662. Maximum Width of Binary TreeBFS 630. Course Schedule III首先想到的是区间段问题，首先是不停地贪最早的结束时间，果断WA了一波。后来我意识到这个问题结束时间是由起始时间来动态调整的，我们不妨反方向，从结束时间开始贪，每次希望找开始时间最晚的课程。然后又WA了一波，Case是[[9,14],[7,12],[1,11],[4,7]]，我第一步贪的是[1,11]，但实际上[9, 14]更好。这个原因不在于区间段的问题的解法是错的，而是我们不能认为每个课程从结束时间就是最优的，对于[1,11]这样的课程，它的性能非常好，它固然能用来替换[9,14]以最右化右边界，但是更好的去处是到最前面。这道题还和最长上升子序列有点像，不过最长上升子序列有个固定的取用顺序，但是这道题没有。题解借助了优先队列。每一次我们的课程X不能满足deadline时，我们取出长度最长的课程Y，并用X替换Y。容易看出这一道题其实和开始时间无关，我们应该上完一门之后立即上下一门。 632. Smallest Range638. Shopping Offers这个就7**6个状态，很好做hash，所以直接记搜。 646. Maximum Length of Pair Chain魔改LIS即可，可参考我的文章，我们把右端点放入dp里面，然后bisect找左端点。注意是bisect.bisect_right(dp, s - 1)不是bisect.bisect_right(dp, s)，这里WA了一发。 647. Palindromic Substrings计算一个字符串中有多少个回文串（看位置而不是值来区分异同）。这道题不复杂，因为$O(n^2)$就能解决了。就是按照Manacher那样扩充一下，然后枚举每一个中心i，向两边扩展直至找到对应最长的回文串，然后枚举下一个中心i + 1，容易看出这样的结果是依照对称中心而不会重复的。 649. Dota2 Senate这道题就是模拟啊，只要前面健在的R的数量大于0，那么当前的D就滚蛋。注意可能会转好几圈，所以要mod一下。 650. 2 Keys Keyboard首先我们考虑一下最优策略，肯定是能复制就复制，因为这两种情况A -&gt; AA和AA -&gt; AAAA复不复制次数是相等的。然后我们要注意到我们每次复制必须复制全部，所以这道题不是说我尽量减去2的$k$次方这种。事实上我们将n做因式分解，然后从小到大得进行复制黏贴即可。例如30可分为[2, 3, 5]，那么最优的算法就是先复制黏贴成两个A，然后变成3个AA，最后变成5个AAAAAA，对于因数i，一次这样的翻倍耗费1 + (i - 1) = i个操作。特别地，我们可以验证有多重因数的情况，例如8，也应该分成2*2*2 652. Find Duplicate Subtrees简单题，Hash一下子树即可 654. Maximum Binary Tree这也太简单了吧，，，我还以为会有重复的元素然后两种树有个大小的比较呢 657. Judge Route Circle弱智题 658. Find K Closest Elements给定一个有序数组，要求找到第k接近x的数，其中x不一定出现在数组里面。初步想法是先二分搜索，然后分能够找到（一个或多个）x和不能找到x两种情况进行讨论。 659. Split Array into Consecutive Subsequences这道题我一开始就是用tail[i]维护所有以i结尾的序列。tail[i]是一个优先队列，里面存放着所有序列的长度，每一次我们遇到值x时就tail[x] = tail[x-1].get()+1，也就是增长tail[x-1]中最短的一项，结果T了。用C++写就能AC。。。 664. Strange Printer【这题Python目前还是T】这道题蛮有意思的，我用Python的$O(n^3)$T了，但是C++的过了。首先不难想的是用dp[fr][to]来记录从fr到to的次数，然后我们从2开始枚举step，然后对每个位置的fr对应的to = fr + step计算dp[fr][to]。我们也容易知道dp[i][i] = 1，dp[i][i + 1] = s[i] == s[i + 1] ? 1 : 2。不过下面的递推方程就蛮考验的。我们考虑情况a***a其中***表示任意的字符，为了生成它，第一种方案是a -&gt; a*** -&gt; a***a，第二种方案是aa...a -&gt; a***a，其中aa...a表示与***长度相等的a，我们于是发现，只要两端相等，那么使用第二种方案总是最优的。 668. Kth Smallest Number in Multiplication Table这道题其实就是摆明了的一个二分答案。 673. Number of Longest Increasing Subsequence令dp[i][j]为以i结尾的长度为j的自增序列的个数，则$$dp[i][j] = sum(dp[k][j - 1]) for k in [0, i) if nums[k] &lt; nums[i]$$朴素的DP是$O(n^3)$的会T。然后我们可以想到一个优化方案，也就是去掉j这个维度，这样可以做到$O(n^2)$，因为我们发现我们不会从j - 2去更新j。 674. Longest Continuous Increasing Subsequence简单题 684. Redundant Connection无向图删除连通图上唯一多余的一条边，这个很简单，并查集维护一下即可。注意我一开始想使用DFS三色法来解决，但实际上这个是不行的，因为我们要输出最后出现的边 685. Redundant Connection II从无向图改成有向图就难了很多，这道题我们要根据是否成环（至多一个环）和是否有点入度为2来讨论。 687. Longest Univalue PathDFS一下咯 688. Knight Probability in Chessboard感觉就是一个概率DP啊。求概率正推，求期望逆推。因此这道题我们可以正推，我们设dp[k][i][j]为第k步走到(i, j)的概率即可，特别地，dp[0][r][c] = 1.0。 670. Maximum Swap逆序排一下，然后贪心交换就行 678. Valid Parenthesis String首先觉得就统计star的数量，然后当左括号不够的时候就用star补，最后看多下来的左括号能不能用star搞掉。结果WA在*((*。仔细分析，如果左括号不够，确实可以用star补，但并不是所有多出来的左括号都能用star补，如上面的错误，我们不能用左边的star去补。因此对于每一个剩下来的左括号我们都需要知道它右边有多少个star。于是我们可以维护一个SL数组表示[0,i]之间有多少个star（注意要减掉补左括号的），然后算出dp表示[i,n-1]有多少个star，然后把每一个还在栈里面的左括号弹出来，看看它的右边还有没有star可以当右括号用了。 696. Count Binary Substrings简单题 698. Partition to K Equal Sum Subsets状压DP了一波，从过3到了过7，并无卵用。后来发现是写挫了，剪枝应当在dfs递归调用前就做。 699. Falling Squares离散化+线段树，和218很像。可以直接套218的模板，顺便还发现218里面Query有个地方写错了，幸亏那个是改线查点，所以没有WA。这道题需要注意的是Case 2那样两个正方形共边的情况，我们可以对于正方形[l,r]查看[l+1,r-1]的最大值，但是对于l &gt;= r - 1的情况，我们需要特殊处理下，看它能不能放在[l-1,r+1]上。这道题居然击败了96%。 712. Minimum ASCII Delete Sum for Two Strings字符串编辑距离的魔改版，挺简单的。注意dp[i][0]和dp[0][j]要作为边缘条件提前算好。 713. Subarray Product Less Than K很基本的双指针了，注意我们动态维护prod而不是预先计算，否则会T，而且你做那么多乘法再除也是等着溢出吧 714. Best Time to Buy and Sell Stock with Transaction Fee现在买卖股票需要缴手续费了。相比Best Time to Buy and Sell Stock II，我们需要知道并不是交易越多越好了，例如[1,3,7,5,10,3], 3。一开始我打算生搬硬套Best Time to Buy and Sell Stock IV的办法，然后T了。然后发现这道题和交易次数没关系，所以将内层循环去掉了，就过了。 718. Maximum Length of Repeated Subarray一道类似于最长公共子串的题，不过更新规则略有不一样，只有A[i - 1] == B[j - 1]时才去做更新。居然WA了两次，sad。 719. Find K-th Smallest Pair Distance这个并不是最近点对，因为它是一维的。这道题解法挺多的，我建议最后都看一下题解。主要思路是二分答案gap，然后有两种方法来算有多少个点的距离小于等于gap。第一种方法我们维护lt_cnt[v]表示小于等于v的点的数量，那么我们就可以用lt_cnt[nums[i] + gap] - lt_cnt[nums[i]]来计算对于点i有多少个点j和自己的距离小于等于gap的。然而这是错的！因为我们还要考虑到i重复值的情况。因此我们需要用strk[i]来维护下连续的i的个数。我们注意下这种方法彻底避免了其他的办法陷入重复统计的困扰，因为它值使用一个指针i。第二种方法是使用滑动窗口来直接算，这个方法需要小心避免重复计算的情况。 730. Count Different Palindromic Subsequences一开始想到516题，但这道题需要去重，如样例1所示。 729. My Calendar I首先是看到732，然后回来看得这一条。这一条一看就是个线段树，但是这条比较蛋疼的是要离散化，而且是在线的。这里借鉴了732 Discuss里面的做法，用指针来维护，这样就不要4N的开销了。这里注意在query时如果没有子节点需要返回root节点的值，我们可以查看样例\{\{6,14},{0,7\}\}，因为在update的时候，如果一个节点下面的结果是一致的（类似决策树里面，是“纯节点”），那么我们会剪枝掉下面的子树，我们需要将这种情况和因为update时没有覆盖到对应区间所以直接没有这个子树的情况区分开来。1234if(!root-&gt;left &amp;&amp; !root-&gt;right)&#123; // IMPORTANT ans = root-&gt;data;&#125; 732. My Calendar III这一题是对一段区间的值+1，然后查看一个区间中的最大值。这属于查线改线的，所以需要lazy。不过根据样例，上面的思路还是有问题的，如下图所示，简单得求最大值的算法，我们得到的结果是2，而这个区间实际上和两个独立区间重合，所以结果应该是3，这种错误的解法在leetcode.732.1.cpp。 |-------| |--------| |--------------| 735. Asteroid Collision从后往前扫一遍即可 738. Monotone Increasing Digits找到小于等于n的单调递增数（不一定要是严格地）。这一条就是贪，一直按着上界来，直到遇到下降走不下去，例如1332会死在最后一个2上。这时候我们开始回退到132-&gt;122，最后在后面补全9。 739. Daily Temperatures直方图那条吧，水题 740. Delete and Earn简单DP 743. Network Delay Time看题目就猜到了这题是干什么的。裸dijkstra，注意是有向图。。。 747. Largest Number At Least Twice of Others简单题 753. Cracking the Safe保险柜的密码是由k个字母组成的长度为n的串。问密码多长能覆盖所有情况。其实这道题是欧拉回路。我们首先乐观地想是不是可以每一次复用前面的n - 1的长度，我们将证明这是可行的。将k ** n的每一种情况视为图上的一个节点，而每一次添加的字母看做一条边，那么我们实际上就是要找一条欧拉回路。例如 00 -&gt; 01 -&gt; 11 -&gt; 10 -&gt; 00 | | &lt;----&gt; 我们知道有向图欧拉回路的存在条件是所有节点出度等于入度，但是我们如何找到这个回路呢？我们这里使用套圈法，其基础是一个DFS123456789101112def dfs(prev_state): for j in xrange(k - 1, -1, -1): next_state = ... if not (next_state in self.visp) and not next_state == prev_state: self.visp |= set([next_state]) check_end() update_path(next_state) dfs(next_state) check_end() self.visp = set([start_state])ans = dfs(start_state) 我们注意到，DFS中首先会找一个环，但这个环不一定就通过所有的节点，这时候我们就从上一次分叉的地方继续遍历出一个环，然后我们可以连接这两个环组成一个更大的环，如此循环往复即可。DFS的栈式递归优雅地实现了这一点。我们应当注意的是遍历欧拉回路中的点是可以访问多次的（等于度数），但边只能访问一次。不过在上面的模板代码里面，我们却用visp数组来维护点（其实在我的上一次提交中额外使用了vis数组来为边，但后来发现这是没必要的），因为我们每个点虽然有很多出度和入度，但在DFS搜索序列中他们只会出现一次，我们用for循环来枚举节点p所有未访问的出边，然后这些出边会各自形成环回到节点p。 757. Set Intersection Size At Least Two首先我们可以用函数inter求出两个interval的交集。如果这两个区间的交集容量等于1或2，那么这个交集一定出现在答案里面。如果交集容量等于0，那么这两个区间就需要和别的区间试试运气，直到最后将自己全部加进去。容易看出，上两种情况是确定性的。但是考虑容量大于2的情况，交集的一部分一定算在答案里面，问题是哪一部分呢？这个问题困扰了我一会，后来通过查看题解发现我们可以考虑不相交和交一个的情况，而不是容量大于2的情况。对区间排序，然后对于不相交的情况就贪心，取最大的两个加入集合，这样加入集合的两个元素最可能能够被后面的覆盖到，从而不浪费。注意我们sort的时候要按照右端点sort，这是显然的，因为我们的贪心策略是希望尽可能覆盖到右边。下面我们从左到右遍历，设置already数组表示目前已经得到的集合。对于新的区间[s, e]，我们尝试将其与already中的所有项匹配。注意这里不能默认匹配already[-1]，因为可能出现[5, 9]匹配[[6,6], [8,8]]的情况。我们使用flag记录[s, e]中总共有多少个数字已经被覆盖到了，显然当flag大于等于2时我们就可以直接结束。每一次计算[s, e]和already中元素相交[s1, e2]的时候，我们根据交集part大小更新flag。特别地，当交集大小是1时，我们需要记录下[s1, e1]，我们不能在这里立即处理，原因同样是上面的这种情况。下面当我们遍历完后，检查flag，对于等于0和大于等于2的情况很简单。对于等于1的情况需要特别考虑。我们需要看两种特殊情况match [2,6] in [[0,1], [4,4]]和match [16,18] in [[18,18]]。我们注意对于后一种情况我们不能向右扩展右边界，而只能扩展左边界。 761. Special Binary String【WA】这题真恶心，建议不要做。 763. Partition Labels这道题很简单，我们就不停地扩大右边界，直到我们目前的集合实现distinct。 765. Couples Holding Hands这道题其实可以贪，还有一些并查集的做法，是一道好题目 766. Toeplitz Matrix简单题，Pick One太差劲了。。。 767. Reorganize String一开始觉得直接按item出现次数sort然后双指针头尾就行了，后来发现我们应当先尽量用item个数多的。然后就用一个方向的双指针还是不行，这是因为可能前面item的用掉一些次数之后就不是最多的了，所以我们应该用优先队列来动态维护。 768. Max Chunks To Make Sorted II题目是将一个int数组切成若干块，并且对每个块进行排序，我们将排序好的块再次按顺序连接起来，应该能够得到一个有序的数组。那么我们最多能切成几块呢？这种序列的题目，我们往往能够联想到直方图问题和逆序对问题。这道题比769要复杂一些，首先arr[i]的值域变到了10**8，我们不太方便用树状数组（当然我们可以离散化）来做了。其次，增加了一条限制是可能出现重复项。我一开始的想法是sort一下数组变成lst，这时候lst[i]实际上就是lst[0..i]上的最大值，那么当lst[i]和arr[i]相等时可以认为i前面可以通过一次sort来变得有序了。但这个假设实际上是错的，我们考虑[1,1,0,0,1]这种情况，由于重复元素的出现，我们无法通过这个条件来判断arr[i]应当位于已排序数组的哪一个位置。即使我们维护一个mx表示arr[0..i]的最大值，然后要求arr[i] == mx == lst[i]也不行，可以考虑[0,3,0,3,2]的情况，下面错误的代码会输出3而不是正确答案2，这同样是重复元素的锅。1234567891011121314def maxChunksToSortedWA(self, arr): n = len(arr) inf = 5555555555 ans = 0 lst = sorted(arr) mx = -inf for i, x in enumerate(arr): mx = max(x, mx) y = lst[i] if mx == x: ans += 1 return ans 然后这道题解法出奇的简单，我们维护lst和arr的前缀和，然后统计他们在对应位置相等的数量即可。【后面还有线性解法】我们维护i位置遍历到的最大值left[i]和未遍历的最小值right[i]。我们知道有序数列lst[i]的左边肯定没有比他大的数，右边没有比他小的数（但可以相等），也就是right[i] &gt;= lst[i] &gt;= left[i]。对于乱序数组arr[i]，我们希望将到i的部分割出来进行排序，这样肯定是安全的，因为i右边不存在比left[i]要大的数了。也就是需要max(left[i], arr[i]) &lt;= right[i]，注意我们这里不需要right[i] &gt;= arr[i] &gt;= left[i]这么强的条件，因为可以通过对(?, i]区间的sort来满足arr[i] &gt;= left[i]这个条件。【此外还有一种单调栈的解法】单调栈具有线性复杂度，并且一趟遍历，也就是每个元素只会一次进栈。通过单调递增栈可以找到左起第一个比当前元素小的元素，也就是当前栈顶。如果当前元素比当前栈顶小，我们就一直进行出栈操作。那么我们现在维护一个单调递增栈，他其中的元素数目表示遍历到当前数字前，可以拆分成块的数目。因为一旦出现一个数使得这个栈不单调了，我们必然要进行一次排序。 注，文章中列出了这道题的四种解法，还是很有趣的一条题目。 769. Max Chunks To Make Sorted首先题意理解一下，不是reverse而是sort。这道题就是逆序对。对于位置i，查看它之前出现了多少个大于等于i的数字，只要有那么这个数字就不能分割。注意使用树状数组的时候必须从1开始，所以要对arr的值统一右移一位。 732. My Calendar III733. Flood Fill简单题 775. Global and Local Inversions这道题就是数学题，要求A[i] &lt; A[j] forall j &gt; i + 1，我们可以反过来计算A[i] &gt;= A[j] forall j &gt; i + 1即是否存在A[i] &gt;= A[j] forall i &lt; j - 1即可。 777. Swap Adjacent in LR String任意次数反转某个区间，问能够得到目标串。 778. Swim in Rising Water其实就是要求从(0, 0)到(n - 1, n - 1)路径上的最大值的最小值其实这道题又是可以二分答案糊弄过去的，但我们是体面人。。。所以研究一下搜索的解法。这道题我从前一直尝试用记搜来做，但一直失败。后来从题解上看到一个简化思路，为了尽快游泳，我们肯定尽量从高度低的地方走，因为水会尽快漫过去，所以我们这次做BFS，然后维护一个当前路径上的最大值即可。 779. K-th Symbol in Grammar一开始以为是个DP，后来发现这样不就直接生成答案了吗，而且这个依赖状态也有限，所以直接DFS了。这道题就是想第n行怎么从第n-1行过来，然后就很简单了。 780. Reaching Points按照(x, x+y)或(x+y, y)的规则走路，问是否能够从(sx, sy)走到(tx, ty)。这道题挺有意思的，让我想到LCM Walk这道题。LCM这道题是按照LCM(x,y)来更新的，实际上是一道数论题。这道题更简单，肯定也是用数学做，当然你爱用矩阵搞事情也行、、、这一道题的简单之处在于我们不需要证明从终点往起点走的唯一性，因为数都是大于0的。这里注意一个细节，为了不t，我们会批量减，但是我们要注意减去的tx和ty最少要是1个，最多不能使得到的差小于sx和sy，否则会丢失结果。 781. Rabbits in Forest排序的话要O(nlgn)，但是可以由于值域不大（1000），所以可以直接用桶。我们知道如果有dp[i]个人说和自己相同颜色的还有i个人，那说明有i + 1人有相同的颜色。当dp[i]大于i时，那么就说明有这dp[i]个人至少有$\lceil dp[i]/i \rceil$组不同的颜色。 785. Is Graph Bipartite?判断是否是二分图。我们可以联想到匈牙利方法是怎么找增广路径的。因此我们直接一个DFS，然后在vis数组上进行标记，对于节点pos，设其vis为1，表示在二分图的一边，那么它能访问到的所有nxt的vis一定是-1，表示在二分图的另一边。那么一旦我们找到一条边其vis与nxt相同，那么就不可能是二分图了。注意二分图可以是不连通的，所以我们应当DFS完毕。在这里WA了次。 786. K-th Smallest Prime Fraction【本题Python TLE了】这道题其实蛮好的，主要有用堆和二分答案。其中用堆的我Python是TLE，C++倒是能过。不过用了vis数组，其实可以不用vis数组，只添加(p, q - 1)。我们考虑一下[1, 2, 3, 4]的情况，我们首先添加(1,4), (2,4), (3,4)，然后我们出(1,4)，只添加(1,3)，那么(2,3)在哪里添加呢？因为(2,3)肯定在(2,4)后面，因为2/3比2/4大。 790. Domino and Tromino Tiling问用2x1和短L型方块铺满2xN的板子有几种方案。这道题是一个有趣的动态规划，我们可以设dp[i][0]为刚好填满第i个槽的方案数，设dp[i][1]为填满第i个槽但是在第i + 1个槽鼓出来的方案数。我们可以对五种情况进行讨论，具体可以见我代码里面的注释。在写的时候WA了几次，都是方案没有考虑周全。 795. Number of Subarrays with Bounded Maximum这道题蛮有意思的，我们还是用了在题目【】中防止重复统计区间的办法，也就是对于i，我们统计以i为结尾的合法区间数。接下来分三种情况讨论即可，我WA了很多次，都是因为没有考虑周全所致。 796. Rotate String复制一份即可，简单题 797. All Paths From Source to Target简单的dfs 799. Champagne Tower这个倒酒的题目我是在哪次ICPC热身赛上做过的，当时好像直接大模拟了。这道题其实也是模拟，我们第一步是对每一层，将每一个酒杯应得的酒（由上一层计算而来）冻成棍子全部塞进去，然后我们让棍子融化，让多出来的酒流到下面的1/2个杯子里面。 801. Minimum Swaps To Make Sequences Increasing咋一看因为是逆序对。不过这个是在两个数列对应位置之间进行交换。这个直接xjb动态规划了，按照套路设S和NS两个数组表示是否交换i位置，然后根据是否交换i - 1地推即可。 802. Find Eventual Safe States这道题就是DFS，黑白灰染色法，根据前向边后向边和横边讨论。这道题WA了两次，第一次是将横边和后向边一起处理了，第二次是忘了flag |=，写成了flag = 803. Bricks Falling When Hit很有趣的问题，n行m列的墙上有砖头靠四边和天花板连在一起。现在有Q次查询，要求输出敲掉(i,j)之后会掉落多少块砖头。首先莽了一个DFS的，也就是直接模拟，对于每一个格点，DFS它能不能到天花板。T了之后优化了一下，从每个天花板DFS看能不能到达，然后check所有不能到达的节点，还是T。后来想到可以反过来考虑这个过程。是机械的时候WA翻了。首先我们敲掉的那个砖块不算掉落的，但是我们在处理的时候是将(hx, hy)周围的所有点进行merge的，我们在一些时候不能直接进行d -= 1，例如当(hx, hy)在天花板上，或者已经连到了天花板上，那我们merge的时候实际上就没有算上(hx, hy)，自然也没有必要减掉了。锤子可以空敲，所以我们不能凭空往上面加东西。WA了一次是因为DFS时候没有初始化fa。WA了一次是因为并查集merge的时候，没有判断pfa == qfa的情况。最后一次WA是在第15个点上，调试了半天，把hits简化到了[[1,4],[1,6],[0,2],[0,5],[1,5]]。原来错误是我们要考虑天花板上的砖块被敲掉的情况，例如[[1,0,1],[1,1,1]], [[0,0],[0,2],[1,1]]这个Case，如果不经过处理就会WA。我当时是选择在添加这个天花板上的(hx, hy)时DFS一下，构建以(hx, hy)为基元的并查集。但在这第15个点上就发现这个方案不行。因为这个Case中我们先添加了(1,5)，然后添加了(0,5)，这时候DFS一下就会直接将(1,5)添加到(0,5)的集合中了。 805. Split Array With Same Average如果是和相等而不是平均数相等，那就是一道背包问题，因此我们的思路一是能不能转化为len(A) / 2个背包问题来做。于是我们的问题变为是否存在有恰好m个数的和加起来为need。这个实际上就是01背包，然后在dp数组上dfs找是否有一条到(0, 0)长度为m的路径，可参考这篇文章的track方法。 此外，本题还有其他解法，如https://xingxingpark.com/Leetcode-805-Split-Array-With-Same-Average/ 807. Max Increase to Keep City Skyline这个很简单，维护一下行列的最大值 808. Soup Servings记搜呗，概率正推，期望逆推。注意虽然我们数组开不了那么大，但是我们可以默认在N很大时概率趋于1。这道题需要按照25离散化一下，不然会MLE 810. Chalkboard XOR Game组合博弈咯。。。我们知道必败态P的下一步一定是非必败态，而非必败态存在下一步是必败态N。我们研究最简单的必败态1，非必败态1,1，因此先手者只要保证自己手里的数字都是成对的就行了。当然如果果然这样那么先手者直接赢了，因为XOR下来就是0。当然肯定有成单的，我们只要保证成单的也是偶数个就行了。然后发现这道题还要特判一下[1,2,3]这种一开始XOR下来就是0的。因为我们要考虑成单的数异或起来是不是为0，因为我们担心像前面多个数异或起来为0的情况，例如1^2^3==0这样会不会影响结果。我们先考虑成单的是偶数，但是Alice先手会输，也就是说当Alice取了数x之后，剩下的XOR起来为0了，例如[1,2,3,4]，取了4，剩下的为0，因此我们肯定不能取这个4，而应该取那XOR起来为0的奇数个数中的一个数，我们可以将这奇数个数的异或等价为两个相同的数a ^ a == 0，因此我们取走任意一个a != x，就会给对手留下奇数个成单的数，并且XOR的值非0这样的情况，这肯定是对方的一个必败态。下面我们需要注意在成单的是奇数个的情况下我们是可能赢的，当XOR起来为0的情况，这个只可能发生在一开始，因为往后我们不可能给对方留下这个状态，除非我们自己是必输的。 813. Largest Sum of Averages这道题一开始是想的一个淳朴的$O(n^2)$的DP，即设dp[i][k]表示到第i个数split了k次的最大值。那么我们在i处有两个策略，一个是跟之前的队，另一个是在这里split下来自立门户。由此写出一个WA的算法，对[2561,9087,398,8137,7838,7669,8731,2460,1166,619], 3会WA。正解是需要$O(n^3)$，我们需要额外的一个j表示我们的区间是[j+1, i]。这是因为我们虽然跟之前的队，但是此时之前最优的队不一定到这里就是最优的了，这题实际上有点类似于410这条。 814. Binary Tree Pruning在微软的面试题，注意要去掉没有儿子的节点 815. Bus Routes这道题的关键在于要对Stop和Routine同时建立vis数组维护。 818. Race Car首先我们的翻转方向一定要尽可能在前面，因为$2^i - 2^{i+1}$是小于0的，而$2^i - 2^{i+1} + 2^{i+2}$是超过$2^{i+1}$的，因此如果我们追求在$2^i$和$2^{i+1}$之间的值那么我们递归的深度是有限的。然后看清题目我发现R会重置速度绝对值为1，这道题就有点类似于650这种题目了，但我们同样要知道最多加速的次数是有着固定的上界，也就是我们最多走到$S = 1 + 2 + … + 2^i \ge target$，不会再往后面加速了。现在我们得到DP的思路，也即是我们在这个$2^0$到$2^i$的加速区间内我们可以在任何时候选择R然后重新来过。一开始我分为两种情况，第一种我们先走过target，然后R回来变成子问题。另一种我们在中间任意的时刻连R两次，将速度减少为1，我们稍后看到第二种情况是不全面的，因为我们可以以退为进一段，而不需要连R。一个难点是target=5的情况，它的结果并不是我之前算的8而是7，也就是AARARAA，究其原因是因为我们从3到5时不能直接套用dp[2]，因为我们在3处的前进方向不同了。 823. Binary Trees With Factors这道题要求用数组A中的数组成二叉树，要求二叉树的父亲等于两个儿子的乘积，问有几种方案。这题显然就是dp了，我们首先sort一下，然后用dp[i]表示第i个节点为根的二叉树有多少种排布方案。我们只需要枚举[0, i)区域内节点作为lson，然后查看是否存在rson即可。 826. Most Profit Assigning Work这道题就是贪，因为任务可以重复完成，所以每个人做能力范围内利润最高的工作 827. Making A Large Island用0和1表示的矩阵，1是岛屿，问最多将一个0改成1，能形成的最大的岛屿的面积是多少。这道题就是先找出所有的连通分量并染色，记录每个连通分量的大小。然后对于所有的0，尝试改为1，并且查看这次变动能否合并上/下/左/右四个方向中的两个或多个（WA了一次是因为漏掉了这个）连通分量。此外我们还要判断这两个连通分量是否已经是连通的，例如下面的情况，括号处的0实际上并没连接上下两个连通分量，因为他们本来就是一体的。12341 1 11 11 (0)1 1 1 828. Unique Letter String看起来是个双指针维护，然后我们同样是按照r坐标来计数以防止错漏。我们知道一个显然的性质，如果在[l, r]区间中没有任何重复的元素，那么这个区间的输出是(l + r) * (r - l + 1) / 2。如果我们考虑在[l, r]中存在一个old_i使得S[old_i] == S[r]（我们可以使用一个哈希表来维护这个性质），那么我们可以将区间分为[old_i+1, r]和[l, old_i]来计算。现在的问题是，如果这个区间中出现了不止一个的重复元素怎么办？我们注意到在任意的区间中如果字符x出现重复，那么它对整个结果都没有贡献，因此我们可以围绕每个字符来做，也就是求每个字符contribute多少次自己。 829. Consecutive Numbers Sum不等式限制一下k的范围就行了。有点类似483题。 834. Sum of Distances in Tree求一棵树上每个端点到其他端点所有距离的和。一个朴素的肯定会T的方法是维护一个数组dist[N][N]表示从点X到Y的距离，那么就可以对每一个点X来DFS一下，是平方的复杂度。优化的方案来自一个观察，也就是两个节点之间的最短路径是唯一的，并且一定会经过两个节点的LCA。因此可以引入第二个观察，也就是说给定一个遍历顺序，例如从X到Y，或者从Y到X，那么子树的数量是固定的。那么其实我们只需要两次DFS就行了。下面就很简单了，比如我们从X遍历到Y，那么从X到Y的所有孩子的距离等于从Y到它所有孩子的距离（这是一个子问题），再加上孩子的个数。 835. Image Overlap837. New 21 Game我们注意到分数是只增不减的，所以这道题很好递推，写了个$O(WK)$的结果T了。后来发现其实dp[i]可以由sum(dp[i-W..i])/W求得，于是动态维护一个和tot就行了。这里我们要注意一下，当i - 1 &gt;= K时就不能加到tot上了，因为这时候游戏已经结束了。 838. Push Dominoes这道题首先要注意的是样例2的情况，不是RRRL或者RRRR哦……然后我们的主要关注.，比如R...这样就会引发骨牌效应变成RRRR，也就是多个L或者R的力量是不能叠加的，因此一开始推的骨牌的命运是注定的。于是第一个想法是维护l[]和r[]表示每个L或R向两边传播的“力”的大小，例如R...就表示成[1, 2, 3, 4]，不过这没卵用。后来发现我们可以通过简单的判断每一个.到两边的L和R的距离来判定这个.究竟倒向谁。然后我们要讨论几个特殊情况，因为有的时候骨牌不能往左或者往右倒。我们考虑i能否向左倒： 假设最近的r从i右边往左倒，从而往左撞倒i。我们应当注意到r可能不存在，也就是r == inf的情况 假设r向左撞倒i前碰到了向右倒的rb，即出现i(.) rb(-&gt;) r(&lt;-)的情况，这时候i也是倒不了的 对于以上的两种情况，我们要先预先处理，然后再进行左右的力量较量 840. Magic Squares In Grid我特么看成行列对角线和相等了，，，还有个distinct的条件要考虑 841. Keys and Rooms判断一个图是否是连通图 842. Split Array into Fibonacci Sequence这个就暴力枚举下fst和snd，然后check就行了。注意范围是int，并且fst和snd的大小没有要求。 846. Hand of Straights用一个dict来维护每个元素的个数，然后从小到大依次check还在的元素。 847. Shortest Path Visiting All Nodes要求最短的汉密尔顿通路，但不要求只访问一次。此外网上有解法是Floyd+松弛，对S*V的这个状态空间进行遍历并松弛。要注意这里不能再Floyd之后直接记搜，除非在Floyd要维护一下mask的情况。 848. Shifting Letters简单题 849. Maximize Distance to Closest Person简单题 851. Loud and Rich给定一个偏序关系richer[i] = [x, y]表示人x比人y要富裕。给定每个人一个quiet[x]值。对于每一个人，找到所有钱大于等于x的人中quiet值最小的人。所有人的quiet是不同的。如果我们反向建立一个有向图，那么答案就是每个点的所有子树中quite最小的点。 852. Peak Index in a Mountain Array最基础的二分查找 853. Car Fleet 车子相撞后的速度是多少？被撞的车的速度 Car fleet彼此相撞吗？根据1，我们可以认为后面的车撞上前面的车之后就消失了。。。因此我们可以统计最后剩的车的数量即可。 所以我们计算出每辆车在到达终点时能不能超过自己前面的车辆，这道题一个WA点是不能简单比较一辆车能够超过前面的车。比如下面的这个case，即10, [0,4,2], [2,1,3]，车位置A B C，其中C最慢，B最快，于是B和A先后粘住C，但A却没有超过B。所以这一题的思路应该是对于每一辆车，我们统计后面有多少车的时间比自己短，然后把它们去掉。这个朴素算法是$O(n^2)$的，但实际也能过。我们可以优化成$O(n)$的，此时我们只要维护一个ctime来表示当前最慢时间，然后我们从后往前遍历，如果有比这个时间还要慢的，那么这辆车一定不能粘在前面的车子上。 854. K-Similar Strings如果可以通过将 A 中的两个小写字母精确地交换位置 K 次得到与 B 相等的字符串，我们称字符串 A 和 B 的相似度为 K（K 为非负整数）。给定两个字母异位词A和B，返回A和B的相似度K的最小值。A和B只包含集合{&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;}中的小写字母。这道题让我想起来之前O(1)空间矩阵转置的问题，我们实际上知道始态和终态，现在问如何通过两两交换来达到。假设我们需要把a移动到b的位置，那么我们建立一条从a到b的有向边，可以看出如果从b到a也有一条有向边，那么我们就可以消去这两条边。那么剩下来还有的就是长度大于2的环。对于长度为n的环，需要n-1次操作进行消除。所以问题变成了我们需要去迭代地把图里面的环去掉。写了一个DFS找后向边的方案，WA在了A = &quot;aabbccddee&quot;, B = &quot;cdacbeebad&quot;这个case上面，发现是a&lt;-b&lt;-c&lt;-a和a&lt;-e&lt;-d&lt;-a和b&lt;-d&lt;-e&lt;-c&lt;-b这三个环，而不是之前的小环b c和e d。TODO 我们如何修改这个方案呢？一般来说，找最小环，就是给定一条边(i, j)，找(j, i)的最短路，这个可以借助于dij来做，不过看起来开销有点大。。。直接看题解，首先是一个类似DP的seen，用来记录到seen[S]至少要经过多少步，然后用一个BFS去计算这个seen数组。现在就是我们如何找到所有能从S一步到达的T。 855. Exam Room贪心即可，注意特别处理0和n - 1的情况。注意两点，max_dis()相等时根据l来判断，合并区间时需要注意单独一个p的情况。 856. Score of Parentheses一看就是和栈有关，不过具体思路还是蛮麻烦的。首先我们知道维护一个计数器，当一个右括号出现的时候我们就将计数器乘2，那么我们什么时候重置这个计数器呢？这一题我们可以借鉴逆波兰式这样的思路，使用一个栈去维护我们的中间结果，每一次右括号会double掉栈顶到最近的左括号的所有值的和。 857. Minimum Cost to Hire K Workers有N个工人，具有quality[i]和wage[i]两个属性。现在需要雇佣K个工人，要求每个工人按照他们的quality[i]的占比给付工资，每一个工人必须给到wage[i]的工资，求最小需要的钱。其中1 &lt;= K &lt;= N &lt;= 10000。首先，我们不能按照wage[i]来贪心，不然，如果出现一个人他的性价比quality[i]/wage[i]超级低，那么即使wage[i]很低，也会把总工资搞得很高。我们也不能按照性价比quality[i]/wage[i]来贪心，因为考虑极端情况，我们只需要一个人，那么我们肯定选工资最低的，而不是性价比最高的。二分答案是不可行的，因为似乎答案不一定是整数。DP的话，我们需要假设DP[K]能从DP[K-1]中推出，但这也不行，我们可以考虑quality = [1,5,5], wage = [10,11,11]的情况，那么DP[1]选0，而DP[2]选1,2。那么我们能够DP[N]么？也就是我们先随便放K个人进队伍里面去，然后我们从第K+1个人开始尝试能不能用他把队伍里面最坏的一个人换掉，从而减少工资总额。我认为已经被淘汰的人不会在后面的轮次中被再次添加上去，因为至少我们已经有K个比他好的结果了。它的复杂度是O(N(尝试替换的人)*K(与K个人比较)*K(计算总工资))。计算总工资的流程是把所有人的quality[i]加起来得到Q，然后求max(wage[i]/(quality[i]/Q)))，这个复杂度看上去就是要T的。。。不过我先写一遍，万一过了呢？并且这种方案如何处理换不换工资总额一样的情况呢？跑了一下，WA了。算了，直接看题解了。题解同样指出我们实际上是要维护两个指标，一个是性价比，一个是工资。总的思路是，我们首先按照性价比对员工进行排序入堆，按照能力值出堆，优先出能力值最大的员工。在这个方案来自于一个观察，即max(wage[i]/(quality[i]/Q)))是由性价比最低的人决定的，因此这个就类似一个滑动窗口问题，我们移出堆里面要吃最高工资比例的人，这是有利于减少总工资的，但现在就少了一个人了，所以只能入一个对总工资增加影响最少的人。 859. Buddy Strings简单题 860. Lemonade Change没啥好说的，就是贪 861. Score After Flipping Matrix首先我们希望能够将高位尽可能变成1，我一开始的思路就是通过行变换一定能够让最高位变为1的，然后我们进行列变换，使得每一列上的1也是最多（过半数）的。WA了一次之后发现我们还需要考虑先对第一列进行一次列变换，继续WA，原来是犯了个低级错误，行和列搞混了。 862. Shortest Subarray with Sum at Least K同样要考虑为负数的情况。这道题如果直接做是$O(n^2)$的，类似560这道题，但实际我们可以做到$O(n)$。我们还需要注意Google的Kickstart2018 Round D的第一条也是这种类型的，不过使用了一个set。因为题目要求找最小的i &gt; j满足B[i] - B[j] &gt;= K，其中B是前缀和，我们使用一个deque来维护所有可能成为j的数。这是一个很奇怪的话，难道有的数不可能成为j么？我们需要考虑两种情况。 出现一个更好的结果 例如A = [1,2,7]; K = 3，我们实际遍历序列B = [0, 1, 3, 10]，当我们遍历到10时，q = [1, 2]（稍后我们能够自己得到这个结果），现在我们读取到10，然后从左边尝试出队。也就是说当x - B[q[0]] &gt;= K，我们会得到一个可行解，用它来更新ans。容易看出只要后面的数是合法的，那么前面的数肯定是没用的。 出现一个更差的结果 这个对应于负数的情况，例如A = [1,-2,7]; K = 3，对应的B = [0, 1, -1, 6]，我们发现当遍历到-1时它都小于前面入队的1了。那么这个1肯定是不会被取的了，因为我的-1不仅比你小，还比你靠后，肯定是不可能成为j的，因此我们从队列中删除这个-1。 863. All Nodes Distance K in Binary Tree给定一个二叉树root，返回到目标结点target距离为K的所有结点。先转成一个图，然后在图上面bfs 864. Shortest Path to Get All Keys从此往后的四题发生了题号的更改，原先是从865开始的。【Contest 92.4 没做】 865. Smallest Subtree with all the Deepest Nodes【Contest 92.2 1A】二叉树上多个节点的LCA，拉出链表来搞一波 866. Prime Palindrome【Contest 92.3 1A】老哥你才10**8，还回文数+质数，我直接打一个表然后bisect完事。。。 867. Transpose Matrix【Contest 92.1 1A】矩阵转置，没啥好说的 868. Binary Gap【Contest 93.3 1A】简单题 869. Reordered Power of 2【Contest 93.3 2A】Python居然T，C++就过。。。这题感觉只能暴力啊 870. Advantage Shuffle【Contest 93.3 1A】这个就是田忌赛马嘛，排序贪心就行，用了del A[i]都能过 871. Minimum Number of Refueling Stops这道题很难过了，本来以为可以贪的，导致上一条看都没看。当时想法首先是维护have数组表示从i往后所有加油站的存油量，然后贪心的情况就是看当前油量能不能到下一点，以及将来的总油量能不能到终点。后来发现100,25,[[25,25],[50,25],[75,25]]会WA，便使用max_need维护从i往后从j到j + 1需要的油量的最小值，这个思路也是错的，因为我们前面可以存油。也就是说[1..j]的最优解不一定是[1..i]的最优解。所以这道题还是要老老实实DP。一开始我想到类似于第45条一样，维护到i点的最小加油站数l[i]，不过这道题i很大。我们实际上使用dp[i][j]维护到第i个加油站时候总共在j个加油站加油的最大剩油量。然后这条题目相同的代码一发T一发AC，我也是醉了。。。 873. Length of Longest Fibonacci Subsequence维护dp[i][j]为满足A[i] + A[j] = A[k]的k。我们逆序遍历i &lt; j，然后使用一个集合s维护，我们在这个s里面找有没有A[k]。T了，原来我们要在预处理阶段就算出最长的长度，改一下过了。 875. Koko Eating Bananas有N组香蕉，每一组有piles[i]个。猴子每小时选择一组，然后吃掉这一组中的K个香蕉。问在H小时内全部吃完的最小K是多少。这条应该是一个裸的二分答案。K最大值是一次吃完一组香蕉，所以是max(piles)/N，最小值是一次吃sum(piles)/H个香蕉，少了肯定不行。注意写的时候要max(1, s / H)，不然可能为0。然后X/Y向上取整是(X+Y-1)/Y 877. Stone Game记搜 880. Decoded String at Index这个很蛋疼，要求多个层次重复的字符串中的第K个是什么。这种问按照一定规律生成的串中的第N个元素是什么的题目一直困扰着我，因为每次都没有总结出一个比较优雅的解法。本题我们首先不停地扩展我们的字符串，直到超过了需要的长度K。 881. Boats to Save People经典的装箱问题，贪一下咯。用C++写，std::multiset很方便。取个负数方便用lower_bound找最大的小于X的数。 887. Super Egg Drop【强烈建议看官方的Solution学习】这一条注意没碎的鸡蛋仍然可以用来二分，所以我们最坏的情况应该按照碎的来算，所以我们不能裸算二分的次数加上最后线性搜的次数。算了我还是记搜吧。。。TLE。。。看题解，实际上我们可以二分这个drop，因为我们取的是max(if_break, not_break)，所以实际上我们希望它们尽可能接近。还可以根据鸡蛋数和行动数DP。 889. Construct Binary Tree from Preorder and Postorder Traversal从前序遍历和后序遍历构建二叉树。 896. Monotonic Array简单题 897. Increasing Order Search Tree简单题 898. Bitwise ORs of Subarrays$O(n^2)$的解法是TLE的，我又XJB搞了半天，想用201的那个做法。其实我们不需要将A[i]去or上s中[0..i-1]的所有结果，我们只要or上s中i-1对应的结果就行了，因为i-1之前有的，or到i-1肯定也有。此外还有的$O(logn)$的解法。这道题蛮好的。 899. Orderly Queue有意思的脑筋急转弯，当K&gt;1时始终可以得到最小字符串。这是因为我们首先可以将已排序部分调整到串的尾部，然后我们可以利用字符串顶部的2个空间来维护出剩余字符串中的最小值。 901. Online Stock Span找到i位置之前的最长的值比prices[i]小的连续序列的长度。这是直方图那条的模板题，例如11题。 903. Valid Permutations for DI Sequence从0到n的数字组成排列，对于任意的i，要求第i位和i+1位满足一定的大小关系，求所有排列的数量。从排列本身查看局部特征是并不明显的，例如DI的D实际上不禁止01的排列，但I会禁止01排列。显然，dp思路是设dp[i][j]是满足长度为i的序列的末维a[i]==j的排列的数量。不放假设S[i] == D，那么它等于sum dp[i+1][k∈[0..j-1]]。又考虑计算dp[i+1][k]，假设S[i+1]=I，那么在计算时需要sum dp[i+2][l∈k..n-1]，那么a[i+2]可能和a[i]去到同样的数。因此，我们不妨加一个约束，也就是dp[i][j]是使用数字[0..i-1]的排列，那数字就不可能重复了。 905. Sort Array By Parity双指针简单题 931. Minimum Falling Path Sum从棋盘A的左上角到右下角，输出和最小的路径，注意A[i][j]可能为负数。啊 题目理解错了，是一行一行往下找，例如(i,j)的下面是[(i+1,j-1), (i+1,j), (i+1,j+1)]这个应该是一个裸DP。 950. Reveal Cards In Increasing Order定义一种操作，每一次取牌顶的一张牌，如果还有牌，将现在牌顶的牌放到最下面，如果还有牌，重复前面一个步骤。已知输出序列是升序的，求输入序列。第一眼想到的就是倒推。 962. Maximum Width Ramp一个ramp满足i &lt; j且A[i] &lt;= A[j]，定义宽度是j - i，求一个数组里面宽度最大的A。显然我们可以有一个O(n^2)的Naive的办法解决这个问题，那么我们现在显然是希望找一个复杂度较低的办法。看起来有点类似直方图的那条题目？也许我们可以使用类似逆序对的方法，二分解决问题？解法有点类似第768，用的单调栈。维护一个单调递减的栈，然后我们二分查找栈里面第一个小于等于当前数的位置。这是一个F/T…TTT形式的二分。 1011. Capacity To Ship Packages Within D Days用传送带往船上运东西，要求D天内运完，船不能超重。求满足要求的最小的船的载重。因为验证很容易，并且上下确界是已知的，所以可以二分答案。 1012. Numbers With Repeated Digits给定正整数N，返回小于等于N且具有至少1位重复数字的正整数。感觉这是一个数位DP啊，写了一下，很多报错。原因是要处理高位为0的情况。TODO看了一下题解，发现还需要存当前出现过哪些数字，这一点是我没想到的。题解还保存了flag维，但实际上不需要，加上反而更耗时间 1013. Partition Array Into Three Parts With Equal Sum有N个数组成的序列，可能为负数，问能不能分成和相等的三份。注意，我们不是随机存序列中挑，而是直接往序列中切两刀。因此这个就很简单的，我们扫一遍求和就行 1014. Best Sightseeing Pair给定正整数数组A，A[i]表示第i个观光景点的评分，并且两个景点i和j之间的距离为j - i。一对景点i &lt; j组成的观光组合的得分为A[i] + A[j] + i - j，返回一对观光景点能取得的最高分。朴素做法是平方复杂度，这个肯定是想办法线性了。对于每个A[j]，我们希望找它前面尽可能近的A[i]。也许我们可以把A[i] + i整体放入一个单调栈里面，对于每一个A[j] - j，我们尝试找一个最大的A[i] + i，不过等等。。。我们直接维护一个最大的A[i] + i就行了啊，不需要单调栈。 1027. Longest Arithmetic Sequence给定一个整数数组A，返回A中最长等差子序列的长度。这题目有点似曾相识啊。。。数列长度是2000，值是10000，不过这个应该没有二分的性质。首先想到的是确定一个等差数列需要两项，那么选择前两项还是末两项呢？从之前的做题经验来看，选择后两项的比较方便DP。那么我们用dp[i][j]表示末项为i，公差j的等差数列的最长长度，那么它的值等于dp[i - j][j] + 1。因此，我们想到一个方案就是对于每一个i，我们先检查它能否和之前的某个数组成新的序列，然后我们再查看，它是否能拓宽已有数列的长度。这个也很容易做到，我们遍历前面所有的数j，然后得到一个公差d，我们尝试能不能更新dp[j][d]即可。dp可以用map来维护。不过上面这个逻辑有点问题，实际上我直接查看能否从dp[j][d]更新dp[i][d]即可，不要什么两次遍历了。不过WA了。原因是要用dp[i][j]表示末项为A[i]，公差j的等差数列，而不是i。 1036. Escape a Large Maze一个100万乘以100万的迷宫，有一些格子是被blocked的，问两点间是否存在通路感觉直接对这个图进行搜索就行，但进行搜索需要维护一个vis数组，而显然我们开不了这么大的数组。于是我们注意到最多有200个区块被阻拦。所以我们完全可以对源和汇单独进行一下一个有限宽度的BFS。我一开始觉得遍历半径为200应该，只要能走到100开外就够了，因为事实上一个200×200的正方形上面的对角线也是200长度的，因此我们至少要走到200步开外才行，这样BFS会T。后来看题解才发现，其实我们只需要不停的BFS，直到走到第19900个格子还能走，那么就肯定在外面了。 1049. Last Stone Weight II有n个数，我们随便取两个数x和y进行下面的变换，如果x == y，则得到新的数0，否则得到max(x, y) - min(x, y)。问如此循环下去，得到的最小的数是什么。最多有30个数，每个数最大是100。如果采用记搜的方案，复杂度是C(30,2)*C(29*2)*...这样的规模，看起来不能够承受。这个有点辗转相除的味道，但其实不是，因为每一次会少一个数，所以实际上可以看做用加减和括号将这几个数连接起来，考虑到括号可以脱掉，所以实际上就是在这些数前面加上加号和减号，从而得到去最小值，而这个是一个很简单的DP问题。一开始我希望尝试dp[i][j]表示用到i个数能够达到的最接近j的数。后来发现两个问题，首先，也许可以估算到整个过程中最大的合法的j大概是30*100/2，但是我们如何处理在dp更新的过程中发生的上下溢出的问题呢？其次，比如我们要求的j是2，我们通过加法和减法能够分别得到0和4，那么其中哪个更好呢？因此后来直接可以维护用到i个数能够得到的所有的数字了。 1054. Distant Barcodes一个有重复数的列表，要求去重新排序它，使得没有重复元素相邻。如果我们仅仅去sort的话，那么显然相邻的元素会靠在一起，但是如果我们给值相等的元素编号，并且再sort，应该就是成了。但其实不成，比如第二个case[1,1,1,1,2,2,3,3]。解决方案就是用一个pq维护每个数的个数，然后拿最多的出来填。但是要注意可能填完一个A之后发现A还是最多的，这时候需要将a放到一个no_use里面冷却一下。 1079. Letter Tile Possibilities看起来是给定一些字母，问用这些字母能够组成多少单词。看起来是可以推一个公式的，但是有点困难。先尝试用最简单的方法做，我们从长度为1开始维护一个集合，然后依次尝试往这个集合中添加一个合法的元素。它的复杂度是O(l^3)的，令l是给定tiles的长度。这个是会T的。然后还是推推公式吧，其实还是比较容易的，我们把每个元素的个数标成一个排列。例如aaabbc可以表示成3 2 1，那么其能组合出的数量就是(3+2+1)!/(3!2!1!)，然后我们去计算它的所有子集就行了。考虑到最长为7，所以可以用字符串编码进行记搜。不过这样似乎在1这个情况下会被重复统计。看了题解，这道题的其实不需要O(l^3)这样遍历，直接按字母种类按照顺序往下填就行。 1092. Shortest Common Supersequence先求一个LCS，然后往上面补数字即可。类似于gcd和lcm。 1103. Distribute Candies to People简单题 1115. Print FooBar Alternately并行算法问题，Python依然始终T。。。 1116. Print Zero Even Odd并行算法问题，Python始终T。。。 1123. Lowest Common Ancestor of Deepest Leaves在二叉树上LCA，老题新做，得到两个List，然后zip比较即可 1124. Longest Well-Performing Interval一条讽刺996的题目。数组hours的一个子数组中大于8的数字的个数严格大于小于等于8数字的个数，那么这个数组是好的，问最长的好数组是多长。朴素做法是O(n^3)的，包含一个O(n^2)的循环用来遍历所有区间，然后用一个循环来检查区间是否合法。我们能用双指针来去掉一个循环么？考虑一下双指针的适用场景。比如分别从左和从右相向移动的双指针，这种方案是我们能够保证当指针已经移到(i, j)时，不会产生一个情况(i-1, j)这样的最优解。其实我发现可以用O(1)来判断是否是好的，就用+1或者-1维护一个累积和acc就行了，得到一个O(n^2)的方案，但是T了。看了题解，其实最佳解法是O(n)的，使用单调栈去处理累积和acc。单调栈适合解决对i, j和arr[i], arr[j]同时有要求的题目。例如这条题目，我们就是要求一个最大的跨度(i, j)，满足acc[j] &gt; acc[i]，这样我们保证这段区间内1是比-1要多的。到这里可以发现，本题类似于第962题。不过令人遗憾的是我似乎没有学会962的方法。。。照搬一下，发现会WA在[6,9,6]这个case上，错误地输出2。比了一下逻辑，发现其实和数组acc[0]应该设置为0，从而得到一个WA3。最后终于过了，原因是首先要在二分完之后看一下l是否合法，可能l也不合法，然后要在acc前面加一项0，不然第一项为1的情况可能不被计算，因为我们是算得(i, stk[l]]。TODO 1125. Smallest Sufficient Team一个项目要选几个人来完成，req_skills表示完成这个项目需要哪些技能，people表示每个人的技能。现在要求找到最小的人的集合。这道题的Naive解法是幂的复杂度，二分答案的话验证也不好做，所以应该是一个DP或者记搜，并且是要压缩状态的。我们定义dp[s]表示要达到状态s需要哪些人的参与。不过这样的记搜面临一个问题，也就是说例如我们最终需要1245，现在有一个1需要一个2，我们有123和124的选项，那么选哪个好呢？反而是用DP的方式推要容易一点 1130. Minimum Cost Tree From Leaf Values给定所有的叶子节点，构造一个二叉树。每一个非叶子节点的值等于左子树最大值和右子树最大值的乘积。问所有非叶子节点和最小是多少。先扯一点别的，给定N个点，能形成多少个二叉排序树？这个是Leetcode96。那么给定N个点，能形成多少个二叉树？可以看这篇文章回到这一题，看起来有点线段树的构造啊。于是令dp[i][j]表示[i..j]区间上的非叶子节点的值的和。不过WA在了[15,13,5,3,15]上，原因是我是fori、forj，但实际上应该先短后长。 1143. Longest Common SubsequenceLCS老题老做 1155. Number of Dice Rolls With Target Sum有d个骰子，每个有f面，问这些骰子朝上面总和是targe时有多少种情况，要求模10^9 + 7。每个骰子是独立计算的。看起来是一条数学题，继续看下数据范围1 &lt;= d, f &lt;= 30，1 &lt;= target &lt;= 1000，似乎可以DP。一个容易的想法是dp[i][t]表示用前i个骰子达到target有多少种方法。那么dp[0][1..f]的取指肯定都是1。对于dp[i][t]，那么其方案总数就是for 1..f尝试去更新一下。 1222. Queens That Can Attack the King从king处按照八个方向找到第一个Queen即可。 1227. Airplane Seat Assignment Probabilityn个人坐座位，第一个人没带票随机坐，有1/n的概率坐到自己对应的座位上。后面的人座位没被占的就坐自己的，不然就随机坐。问第n个人坐到自己座位上的概率是多少？一个直截了当的做法就是算dp[i][j]表示第i个人坐到第j个座位上的概率。然后T了，看Hints，似乎可以打表找规律。结果发现从1之后都是0.5。。。这个题目很有意思，应该可以用数学归纳法证明一下P[i]==P[i+1] 1232. Check If It Is a Straight Line检测一条线是不是直线 1239. Maximum Length of a Concatenated String with Unique Characters给定一个字符串数组arr，选择其中一些串组合起来，要求组合之后的串没有重复字符，问能组成的最长的串的长度是多少？其中1 &lt;= arr.length &lt;= 16，1 &lt;= arr[i].length &lt;= 26。这个题目感觉很熟悉。。。类似于我们要选择价值最大的几个元素，但是要满足一些规定，例如元素A和元素B不能同时存在。没思路，直接看了题解。。。结果居然是回溯法，直接枚举也行。。。反正复杂度是2^16。回溯法相对来说比较容易，我们用一个26bit的int来压缩每个字符出现的次数。这一题要注意[yyy]这种特殊情况，字符串本身有重复，也是不可以的。 1262. Greatest Sum Divisible by Three给定一个nums数组，要求找到和最大的一个子集，要求这个和能被3整除。这个题目很简单，直接按照模分成三个数组，然后把模1和模2的数组从大到小对应相加就行。但WA了，因为两个模可以组成一个模2，这种情形要考虑进去。然后我们可以联想到是否可以通过背包问题来做。发现没有必要。我们可以设dp[n][mod]，然后查看能否用nums[i]更新dp[i - 1][0..2]。 1291. Sequential Digits一个有趣的观察是通过首位和长度，就可以唯一确定一个序列，剩下来的就是如何通过low和high去截断序列。 1298. Maximum Candies You Can Get from Boxes【TODO】status[i]表示箱子有没有打开，candies[i]表示箱子里面有多少糖，keys[i]是箱子里面的所有钥匙，containedBoxes[i]是box[i]里面包含的箱子，没搞懂最后一句什么意思。 1314. Matrix Block Sum给定K，和一个二维数组。要计算i - K &lt;= r &lt;= i + K, j - K &lt;= c &lt;= j + K范围内的所有的数的和。可以在O(n*m)复杂度完成 1334. Find the City With the Smallest Number of Neighbors at a Threshold Distanceemmmmm，这题目很长啊。。。翻译过来就是一个带权无向图，我们筛选出从每个城市能够在distanceThreshold距离内到达的所有城市，我们需要返回的是能够到达最少城市的城市。当有多个答案时，返回index最大的。其实就是Floyd模板题 1338. Reduce Array Size to The Half一个整数数组arr。选出一个整数集合，并删除这些整数在数组中的每次出现。返回至少能删除数组中的一半整数的整数集合的最小大小。看起来就是说有n个东西，每个东西有价值v，总价值V，问如何选择最少的东西使得总价值至少大于V，贪心就行了 1354. Construct Target Array With Multiple Sums给你一个整数数组target。你有一个数组A，它的所有元素均为1，重复该过程任意次以下操作，问能否得到target。 令x为你数组里所有元素的和 选择数组里面的任意元素，并将其变为x 观察一下，因为原数组都是1，所以每进行一次操作，总和x就会变大。我们不妨考虑两个的情况，令[a, b]，其中a &gt; b，那么它肯定是从[b, a - b]得到的，我们依次重复这样的操作，看看最后能不能得到一个全是1的数组即可。所以我们模拟一下就行，不过这个方案T了。下面就能够很自然想到用优先队列优化，但是我们要同时自己维护一下当前target的和。此外还有特定优化一下[1,1000000000]的情况，特判一下只有一个元素的情况。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[去除reimage repair恶意广告软件]]></title>
    <url>%2F2017%2F02%2F08%2F%E5%8E%BB%E9%99%A4Reimage%E6%81%B6%E6%84%8F%E5%B9%BF%E5%91%8A%E8%BD%AF%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[今天发现自己的Chrome上超链接被篡改了，在点击这样的超链接时，会打开一个独立窗口并跳到某个广告页面然后窗口自动消失，并且扩展程序页面chrome://extensions打不开了。后来发现这是一个叫reimage repair plus的恶意广告软件导致的 这几天发现超链接被篡改了，之前以为可能是某些网站自己的行为，后来发现Google也被篡改了，所以怀疑是恶意软件。跟踪了几个网址，发现经常转到www.reimageplus.com这个地方，搜一下，原来是个臭名昭著的软件。网上推荐了AdwCleaner，使用这个软件扫描了下，出现了一堆腾讯XX盒子、百度XX、迅雷XX的东西。可能是这些软件更毒吧。因为AdwCleaner没有用，继续搜索发现zhihu上有同样的问题，那人还说“扩展程序处 一点页面就会一闪然后自动关闭了”，这不就是我Fiddler安装之后的问题么？我马上联想到我最近安装了Fiddler，这个软件之前之前抓包的时候把我的IE给搞了（后来发现好像是加了个代理啥的，不能怪它）前几天为了抓包又装了Fiddler，没过一会儿他就自动升级成Fiddler4了。Fiddler抓包的时候需要重置默认代理，于是我把Proxy SwitchyOmega关掉，抓完之后（妈的不是HTTP包，还是用WireShark吧）想把Proxy SwitchyOmega再开下来，发现chrome://extensions打不开了。于是设置里面重置浏览器，然后就可以打开了。没想到余孽并没有被清除。于是我卸载掉Fiddler，并重置Chrome，于是这问题就不再发生了。 此外给一个删除Chrome的扩展的小Tips，有的时候我们发现自己移除扩展之后重启Chrome又出现了，这是由于Chrome的同步机制，将设置-同步-扩展程序/应用取消掉再重启即可。]]></content>
      <tags>
        <tag>病毒</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode4 Median of Two Sorted Arrays]]></title>
    <url>%2F2017%2F02%2F04%2FLeetcode4_Median_of_Two_Sorted_Arrays%2F</url>
    <content type="text"><![CDATA[LeetCode第4题，求两个数组nums1和nums2的中位数，要求对数复杂度。这个思路很清晰，就是二分。一开始想的lower_bound比较一波，算一下偏移，然后两段去掉相同数目的元素，构成一个子问题。不过实现的时候被字符串常见的边界情况和上下中位数困住了，想了好久，后来发现其实自己想复杂了，这就是一个求第k个数的问题，直接二分答案就好了。设nums1[m1]和nums2[m2]为两个数列nums1[0..n1-1]和nums2[0..n2-1]的中位数（长度为奇数）和上中位数（长度为偶数），显然当nums1[m1] = nums2[m2]时为一个结束条件，此时按照奇偶长度判断一下即可。当nums1[m1] &lt; nums2[m2]时，显然m2取大了，m1取小了，此时中位数应该位于nums1[m1..n1-1]和nums2[0..m2]里面，注意中位数仍然可能取m2的，例如nums1 = [1, 2, 3, 4]、nums2 = [1, 3, 4]的情况，同理中位数也仍然可能取m1。但是如果单独拿出这两个片段来更新，仍然得不到子问题，因为中位数虽然在这两个片段内，但是这两个片段的中位数并不一定等于原数组的中位数。因此产生了两种想法：第一种做法试图去掉相等数量的最小值和最大值，形成依然“对称”的数组；另一种做法是不追求切完的数列依然对称，而是直接记录去掉了多少个最小值，因而新的数列中还需要去掉多少个最小值，实际上转化为求第k个小数的问题。在实现上第二种方法是高效而简单的。 对于第一种方法。假定nums1[m1] &lt; nums2[m2]，令j = lower_bound(nums2, nums2 + n2, nums1[m1])，其中lower_bound二分搜索可以使用python中的bisect.bisect_left代替，显然j &lt; m1，所以如果按照(m1, j)来分割，则小端变少了m2 - j个，因此nums2的分割点应该位于[j + 1, m2 - 1]这个区间内。同理，令i = upper_bound(nums1, nums1 + n1, nums2[n2])，nums1分割点应该在[m1 + 1, i - 1]这个区间内。一个比较简单的想法是，分别对于两个数列直接去掉min(n1, n2) / 2个元素，这样是为了保证两个数组都有足够的元素可以取。此外要注意min(n1, n2) / 2 == 0的情况程序会陷入无限递归的情况，这是由于某一个数组的长度为1导致的，所以预先判定下数组长度为1的情况，写下来代码是这样的但是这样会WA，Leetcode可以直接告诉你哪一个点WA了，于是发现对于数据[1, 4], [2, 3]是不正确的。其实这个程序每次去掉的未必是最小的数，因为最小的数未必在中位数小的数列中。 下面我们查看第二种方法，这里选择直接二分值而不是下标。对每个二分出来的值，再在两个数组中找到它的插入位置i和j，并比较i + j和k的大小，如果大了，说明中位数取大了，取左区间继续二分。附上代码这里注意两点，第一是lower_bound(nums1, nums1 + len, mid)始终返回是nums1中mid上确界的下标，如果mid大于nums1中所有数，下标是nums1.end()，直接取值会造成nums1越界，例如[1, 2], [3, 4]的情况。出现这种情况是因为mid取小了，而nums1整体小于nums2，lower_bound从nums1末尾借用了一个数导致下标越界。第二是两个数列中都没有mid这个数，当i + j == k时，取到的是两个数组对mid的上确界，如[1, 1, 3, 3], [1, 1, 3, 3]中第一轮取k = 4, i = 2, j = 2, mid = 2 &lt; nums1[i] = nums2[j] = 3。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中编译器优化导致的一个问题]]></title>
    <url>%2F2017%2F01%2F27%2FC%2B%2B%E4%B8%AD%E7%BC%96%E8%AF%91%E5%99%A8%E4%BC%98%E5%8C%96%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天在MSVC2015上在用for遍历std::vector&lt;T&gt;时遇到一个Access Violation错误，关键代码如下1234for (auto i = v.size() - 1; i &gt;= 0; i--)&#123; // ...&#125; 原因是C语言中一个符号数和一个无符号数进行运算时首先要将符号数转为无符号数，所以编译器会自动推导i的类型为auto = size_t。而对于无符号整数，编译器认为i &gt;= 0是一直成立的，如果循环体中不使用i，编译器很可能会优化成死循环。但即使编译器不做优化这个代码也不正确，当v.size()为0时，无论是有符号的减法还是无符号的减法，i的二进制表示都会是0xffffffff。而0xffffffff在无符号数里面是UINT32_MAX，而在有符号数里面是-1.于是将代码改成下面这样子后运行就正常了。12345int vsize = v.size(); // 转换为有符号数for (auto i = vsize - 1; i &gt;= 0; i--)&#123; s.push(make_pair(v[i], deep + 1));&#125; 在使用无符号类型时需要特别注意溢出问题，还有一个常见的错误来自于从有符号数到无符号数的narrowing conversion，在CSAPP2.2.8中给出了一个getpeername中的漏洞以说明窄化转换造成的非法读取。其实在使用auto时坑还是比较多的，一个常见的就是std::vector&lt;bool&gt;的问题。众所周知std::vector&lt;bool&gt;被全特化了，是个超级大坑。全特化原因很容易理解，节省空间嘛，搞成一个动态的bitset。由此带来的影响是reference类型不再是bool &amp;而是一个代理类，在MSVC2015中是_Vb_reference，通过_Vb_reference重载的opertor=和operator bool进行读写。这时候用auto &amp; = vec[0]就会报错，原因是不能将左值引用绑定到右值上（不过MSVC2015很著名地允许这种写法）。]]></content>
      <tags>
        <tag>C++</tag>
        <tag>auto</tag>
        <tag>编译器优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fortran数组的C++实现]]></title>
    <url>%2F2017%2F01%2F18%2FFortran%E6%95%B0%E7%BB%84%E7%9A%84C%2B%2B%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[最近在写CFortranTranslator，一个从Fortran77/Fortran90到C++14的工具，其中涉及到使用C++为Fortran实现一个数组库。总的来讲，Fortran90的有些语言特性在编写和编译上都让人不是很舒服。比如没有头文件和前置声明，这导致了许多额外的代码和解析工作，比如INTERFACE块因此而生（但其实也是一个比较好的解决方案，和前置声明也差不多）。又比如Fortran兼容老标准的问题，这个写C++的同学也应该深有同感，C++为了保持和C的linkage做了不少擦屁股的事情，像什么POD、函数指针/函数对象啥的。Fortran老标准中允许隐式声明变量，而且可以通过名字推断变量的类型，而且由于COMMON块的存在还要兼容一些奇妙的用法。这使得处理变量声明的工作要延迟到处理函数体时。Fortran90还可以直接根据Attribute specification statements给变量加属性(ISO/IEC 1539 : 1991 ch5.2)，加上隐式声明的情况，实际上类似于INTENT、PARAMETER、DIMENSION这样的语句需要考虑是生成一段新变量声明还是修改老声明，这同样会延迟处理变量声明的工作，还会要求建立符号表。此外各种impied-do结构，虽然可以完全展开成for循环，但是为了保持Fortran源语句的抽象，最好还是做成一个表达式。还有Fortran77里面的nonblock DO construct非常恶心，从语法上完全无法解析了，最偷懒的办法就是先用start condition给flex开洞，再#define YYLEX给bison开洞。不过后来token级的continuation迫使我直接手写词法分析了，果然偷懒还是要不得的。此外Fortran的传参机制也很特别，类似于宏的形式，基于引用，具体类型和限定要在函数体中才能看到。为了能够兼容语义，我全部使用了右值作为参数限定关于C++元编程的部分可以参考C++模板编程这篇文章中，关于使用flex/bison进行语法分析的部分我放到了flex和bison使用，其他的部分放在这里。 Fortran数组简介Fortran语言的实现常常要比C快，其中数组是功不可没的。在C语言中，数组常常会被decay成指针来处理，而这会在优化时造成pointer aliasing的问题。一方面C/C++编译器遵循strict aliasing规则，即不同类型的指针绝不会指向同一块内存。具体的说下面的情况被视为相同类型： 被signed/unsigned/const/volatile所修饰 被一个聚合或联合所包含 继承自一个基类 类型char*和void**可以alias任何其他类型这样当你写出这样的神奇代码的时候，编译器至少能有个warning123456789101112int a;int f(float *b)&#123; a = 1; *b = 0; return a;&#125;int main()&#123; printf("%d\n", f((float*)&amp;a)); return 0;&#125; 在另一方面，我们还是无法容易得知道两个相同类型的指针是否alias，即指向同一块内存。这时候Pointer aliasing的问题会阻碍编译器进行优化，虽然restrict关键字可以一定程度上减少这个问题。Fortran数组就彻底没有这样的烦恼。 for1array&lt;typename T&gt;一开始的想法是实现一个for1array&lt;T&gt;，一个一维的数组。可以理解为对C++原生数组的一个包装，使得数组能够自定义上下界，和列优先的存储模式。事实上这种嵌套(nested)数组在实现Fortran的内在函数时存在相当大的麻烦。例如将初始化序列按列映射到一个嵌套的数组for1array&lt;for1array&lt;...for1array&lt;T&gt;...&gt;&gt; farr中，如果通过通常的递归来做，那么就要自结构最里面从内而外for1array&lt;T&gt;进行递归创建这个数组，但这难于实现。一个可能的解决方案对于嵌套的for1array数组按照通常一样从外到内进行递归遍历，而计算farr[a1][a2]...[an]时对应的一维序列中的位置。对于farr数组中的第k层的指针增加1，实际上相当于一维序列中向后移动size[1] * size[2] * ... size[k-1]，其中size[i]为farr中第i层的大小。但是对于transpose这样的函数使用嵌套数组实现的代价就相当大了，特别地，Fortran90标准对转置秩大于2的数组并没有规定行为： 13.13.109 TRANSPOSE (MATRIX)Description. Transpose an array of rank two.Class. Transformational function.Argument. MATRIX may be of any type and must have rank two. 因此实际上对于一个N维/秩数组$X$，假设第$i$维的取值范围是$[0, n_i]$，定义转置$X^T$，满足$X[a_1][a_2]…[a_n]$ = $X^T[a_n][a_{n-1}]…[a_1]$。 farray&lt;typename T, int D&gt;Fortran90标准中数组的维数，上下界都是确定的，称为显式形状数组(explicit-shape)。此外，除了动态数组(deferred-shape)，即使出现的可调数组(automatic explicit-shape)（类似于C99中的Flex Array）、假定形状数组(assumed-shape)（仅给出维/秩数）和假定大小数组(assumed-size)（最后一维的上下界是不定的）也是作为哑元（形参的）。Fortran77标准更是使用完全静态环境(fully static environment)的运行时（《编译原理及实践》§7），因此都不支持递归调用。因此Fortran多维数组并不需要锯齿数组，也不需要实现类似动态表的自扩，所以内部可以通过一个一维的线性表data来保存数据。相对于C的数组而言，Fortran中数组是按照列优先顺序(column-major order)存储的。在实现数组时，应当考虑空间局部性的问题，将同列的元素尽可能一同存储（注意C++是行优先顺序）。在Fortran数组的内部实现中如果出现嵌套循环、递归，也应当保证内层循环/递归处理同一列，对于多维数组则是遍历最左边下标。 编译期维护数组各维度上下界的尝试因为要尽可能保证和源代码一致性，所以不能将上界统一改为0开始，在设计时需要使用在对象中维护每一维的上下界。于是自然想到是否可以在编译期进行上下界的相关计算，一个很挫的思路是将每一维的上下界放入模板参数里面，然后通过parameter unpack提取出来。另外还有想法是借助constexpr而不是模板，例如使用constexpr构造函数（注意目前使用的MSVC2015无法编译，原因是尚不支持Extended Constexpr）。但事实上即使能编译，constexpr也不是一个强制性声明，编译器仍然可以选择将其放到运行期完成。其实constexpr也被用来“糊弄”编译器。StackOverflow上的这篇回答解释了这样做的原因。回答列举了一个希望使用for遍历std::tuple的例子，我们知道C++是静态类型的且std::tuple的参数包中可能包含不同类型，所以for (const auto &amp; x : my_tuple)这样的做法就是在和C++标准过不去；但使用一个index来“遍历”std::tuple中的元素也是不行的，例如for (constexpr i = 0; i &lt; 10; ++i)，程序员完全可以将这个i作为std::get的非类型模板参数来构造出可能属于不同类型的变量。通过答主的这个例子可以知道一个constexpr的for对当前的C++来说是不切实际的，事实上我们可以采用一些方法可以实现编译期的循环结构，比如变循环为递归，把index放到模板参数里面。对于C++14，可以借助于index_sequence来辅助进行包展开，对于C++17可以去fold一个index_sequence。 实现transpose现在实现transpose函数，transpose函数主要是通过变换$n_i$和对应的一维序列，满足上面式子。对于原矩阵$X[a_1][a_2]…[a_n]$，可以映射到$X$对应的一维序列的第$\sum_{i=1}^{N}{(a_i \times \prod_{j = i + 1}}^{N}{n_j})$项，令$\prod_{N + 1}^{N}{} = 1 $；对于转置后的矩阵$X^T[b_1][b_2]…[b_n]$，令其每一维大小为$n’_i $，可得$n’_i = n_{N + 1 - i}$，可以映射到$X^T$对应的一维序列的第$\sum_{i=1}^{N}{(b_i \times \prod_{j = i + 1}}^{N}{n’_j})$项，其中令$\prod_{1}^{0}{} = 1 $。根据$X[a_1][a_2]…[a_n]$ = $X^T[a_n][a_{n-1}]…[a_1]$，带入$b_i = a_{N + 1 - i}$，可以得到映射规则$X: \sum_{i=1}^{N}{(a_i \times \prod_{j = i + 1}}^{N}{n_j})$ $\Rightarrow$ $X^T: \sum_{i=1}^{N}{(b_i \times \prod_{j = i + 1}}^{N}{n’_j})$ = $\sum_{i=1}^{N}{(a_{N + 1 - i} \times \prod_{j = i + 1}}^{N}{n_{N + 1 - j}})$。以上是对于C-style的数组讨论的，对于Fortran-style的数组，将$\Sigma$的上下界改成$0 .. i - 1$此外，对于2维非方阵矩阵转置有$O(1)$空间的方法，主要是按照序号从小到大遍历矩阵中的每个元素，希望能够找到以它开始的环。容易看出一个环没有被遍历过当前仅当当前序号是环中最小的序号。 slice数组片段fortran中的slice是by reference的，对slice的修改也是对原数组的修改，于是要实现一个forslice函数，其返回的slice应当是数组片段的引用。对于这种情况，首先可以考虑使用std::vector&lt;std::shared_ptr&lt;T&gt;&gt; data来实现内部的线性表data，但是这样会产生不必要的空间开销。因为虽然每一个slice是不一样的，没办法对std::shared_ptr&lt;std::vector&lt;T&gt;&gt; data，但是每个slice的data部分是作为一个整体的。所以还是使用的裸指针RAII，对于从forslice函数构造的farray&lt;T&gt;，在构造时加一个tag，析构时不释放指针即可，类似view的行为。考虑到Fortran77标准本身的完全静态环境（Fortran90可能是基于栈的），所以不会出现悬挂指针导致的AV错误。此外fortran中还允许使用(/ /)这样的Delimiters来具体指定位置组成数组片段，例如A((/1,2/))表示选取A中的第1和第2个元素。要实现这个功能只需要给slice_info做一些修改，加一个迭代器即可，考虑到这个功能并不常用，所以并没有实现。 数组的秩此外fortran中有使用到数组的秩作为参数（通常参数名为dim）的函数，要注意秩是从1开始计算的。 farray&lt;typename T&gt;fortran有一个slice操作，它返回的维数是不固定的，例如a(:, 1, 1:2)返回一个2维的数组，但是a(:, 1, 1:1)返回一个三维的数组，虽然这两个数组所承载的数据是一样的。这给实现带来了困难，因为返回类型是根据slice_info的初始化列表来决定的，为了追求语法尽可能简单，贴近fortran源码，对slice_info这样的工具类模板开洞是不太好的，因此决定将维数参数也移出模板参数。因此将farray&lt;T&gt;的数据分成两块，第一块是有关形状的元数据，通过reset_array来设置；另一块是数据本身，通过reset_value来设置。在数组声明（构造函数）时，可以确定数组形状，可以顺带赋值；在数组（operator=）赋值时只能赋值，而不使用目标右值的形状。再一次说明，这样带来了额外的空间开销lb用来存储上界，sz用来存储大小。由于fortran数组是按列存储，越往后的下边周期越长，因此预先计算delta也就是第d维是i时数组的长度，用来辅助运算。可以看到是把整个数组的运算都放到了运行期，而这些东西完全是编译器决定的。显然我们可以在把fortran编译到C++的阶段处理这些东西，但是要不这让生成的代码因为带上这些附加的数据显得非常难看，要不就会损失掉fortran原来的语义，例如将fortran的数组整合成上界始终是0，按行存储的数组。所以唯一的办法是利用元编程，让C++编译器在模板阶段处理这些东西。 fortran数组的内在函数处理dim参数minloc、maxloc、all、any等函数可以传dim参数。这个dim参数实际上就是数组的秩(rank)。fortran中数组的秩类似于C++中数组的维数(dimension)，但是秩是从1开始算的（可是参数叫dim呢）。在fortran90标准中并没有签名为RESULT = MAXLOC(ARRAY, DIM [, MASK])，从gfortran的文档中了解到这个函数时从95标准后新增加的。在实现这个函数的时候产生了困惑，对于高维数组，这个maxloc函数到底返回什么呢？gfortran文档中只给出： if the DIM argument is supplied, determines the locations of the maximum element along each row of the array in the DIM direction.If DIM is present, the result is an array with a rank one less than the rank of ARRAY, and a size corresponding to the size of ARRAY with the DIM dimension removed. 后来我在这里找到了一个例程：1234567891011integer :: i6(6) = (/-14,3,0,-2,19,1/)integer :: i23(2,3) = reshape((/-14,3,0,-2,19,1/),shape(i23))write(*,'(2i4)') i23 ! writes -14 3 ! 0 -2 ! 19 1write(*,*) maxloc(i6) ! writes 5write(*,*) maxloc(i23) ! writes 1 3write(*,*) maxloc(i23,dim=1) ! writes 2 1 1write(*,*) maxloc(i23,dim=2) ! writes 3 1write(*,*) maxloc(i23,dim=1,mask=(i23 &lt; 10)) ! writes 2 1 2 maxloc(a, dim=1)这个函数返回的是[lb[dim], sz[dim]]构成的dim-1维数组，令剩下来的维数取遍所有组合，对于每一种取组合，给出取得最大值时候对应原数组第dim维的下标，即$ \underset{i_{dim}}{\arg\min}(b(i_{dim})), \forall b = a(i_1, …, i_{dim - 1}, :, i_{dim + 1}, …, i_n)$这个例子中，列是第一维，行是第二维。于是对于此类函数可以抽象成reduce函数，对于不带dim参数的重载版本，这是对于原数列的reduce操作；对于带dim的版本，这是对于一个rank-1的数组中的每个元素（是一个一维数组）进行reduce操作。 处理mask参数minloc、maxloc、all、any等函数还可以传mask参数。这个参数是一个逻辑表达式，实际上类似于一个谓词，并且这个谓词需要使用当前作用域内的变量。至此为止用实现一个[&amp;](){/* expressions directly translated from fortran */}的lambda表达式即可。比较麻烦的是这lambda的函数体内部直接使用数组名，而谓词是作用于数组的元素上的。并且在整个函数调用的可见范围内，无法判断lambda函数体中的变量究竟是数组还是标量，例如下面的情况：1234integer,dimension(8)::N1, N2integer::N3print *, maxval(N2, mask = N1 &lt; 5) ! N1 is arrayprint *, maxval(N2, mask = N3 &lt; 5) ! N3 is scalar 由于编译器实际上并没有建立符号表，在处理maxval(N2, mask = N1 &lt; 5)这个调用时并不能知道N1，N2，N3的类型与定义位置。所以也就无法将数组改为对应的元素形式了。有两种方法解决这个问题：第一种，将这个谓词作为表达式来计算，最后返回一个布尔值数组。这需要重载运算符和fortran的内在函数。第二种，是实现一个模板函数formap(F f, T x)和重载版本formap(F f, farray&lt;T&gt; x)，然后对于所有的变量x，用formap(predicate, x)包一下就好了 fortran数组中的运算符重载fortran中数组可以对同样长度的数组和标量进行算术运算和比较运算等，所以需要实现一系列重载函数 数组声明数组声明注意点比较多。首先给出fortran中声明(declare)和定义(define)的区别 The term declaration refers to the specification of attributes for various program entities. Often this involvesspecifying the data type of a named data object or specifying the shape of a named array object.The term definition is used in two ways. First, when a data object is given a valid value during programexecution, it is said to become defined. This is often accomplished by execution of an assignment statement orinput statement. Under certain circumstances, a variable does not have a predictable value and is said to beundefined. Section 14 describes the ways in which variables may become defined and undefined. The seconduse of the term definition refers to the declaration of derived types and procedures. 简而言之，声明(declaration)，指的是设置变量的type或者attribute，而定义(definition)是给变量初始化。 下面考虑数组的声明方式。首先fortran77中可以使用下面的方式声明123REAL A(10,2,3) ! 类型说明（常用）DIMENSION A(10,2,3) ! DIMENSI0N语句（常用）! COMMON fortran90中可以使用下面的方式声明12345REAL，DIMENSION(2,5):: D ! 类型说明中的DIMENSION属性（最常用）REAL，ALLOCATABLE:: E(:,:,:) ! 类型说明中的ALLOCATABLE属性REAL，POINTER:: F(:,:) ! 类型说明中的POINTER属性POINTER C(:,:,:) ! POINTER语句ALLOCATABLE B(:,:) ! ALLOCATABLE语句 根据fortran90标准section5 R501 type-declaration-stmt is type-spec [ [ , attr-spec ] … :: ] entity-decl-listentity-decl is object-name [ ( array-spec ) ] [ char-length ] [ = initialization-expr ] or function-name] [ char-length ] 其中array-spec就是dimension()语句括号中的东西，表示数组的形状。注意： 声明中并不一定要出现double colon separator::，但是当有初始化语句initialization-expr时，必须要有这个分隔符这在语法分析时可能出现语义冲突导致二义性文法，原因是integer、real等既可以作为类型限定符，也可以作为函数名，所以实际上要去掉callable_head规则，将它统一合并入callable规则 char-length仅允许给字符串指定长度，由于实现上使用的是std::string，所以可以直接去掉这个，我们只需要对变量声明中出现的*号进行特判处理即可。 考虑到可以通过REAL R(10) = (/1,2,3,4,5,6,7,8,9,0/)声明数组，所以不能在扫描完type-spec和attr-spec就确定类型，而要根据每一个entity-decl后面是否出现( array-spec )来决定。123integer::Zdimension:: Z(10)! dimension(10)::Z 注意这样的语句是不行的 这样的说明也是允许的，考虑到fortran还有隐式声明，事实上第一行还可以直接去掉。所以说即使整个声明语句读下来，仍然不能决定具体的类型是什么： 5.1.2.4 DIMENSION attributeThe DIMENSION attribute specifies that entities whose names are declared in this statement are arrays. Therank or the rank and shape are specified by the array-spec, if there is one, in the entity-decl, or by the array-specin the DIMENSION attribute otherwise. An array-spec in an entity-decl specifies either the rank or the rank andshape for a single array and overrides the array-spec in the DIMENSION attribute. If the DIMENSION attributeis omitted, an array-spec must be specified in the entity-decl to declare an array in this statement.为了解决这个问题，变量的声明必须要在整个变量声明语句块结束之后才能确定（fortran的命令语句必须在所有声明语句后面）。所以只有在program或者function_decl规则中才能对其中的suite规则中的变量名生成定义和初始化语句。这里还要注意一点，变量的隐式声明和隐式类型(implicit type indicated by the first letter)还不一样，后者指的是在声明变量的时候不指出变量的类型，这时候根据变量名的第一个字母来决定是实型还是整型。当然隐式声明和隐式类型是可以同时存在的。 数组初始化和赋值使用数组构造器Fortran中的数组构造器(array constructor)我认为是一个很方便实用的功能，根据Fortran90标准，数组构造器使用下面的语法 array-constructor is (/ ac-value-list /)R432 ac-value is expr or ac-implied-doR433 ac-implied-do is ( ac-value-list , ac-implied-do-control )R434 ac-implied-do-control is ac-do-variable = scalar-int-expr , scalar-int-expr [ , scalar-int-expr ]R435 ac-do-variable is scalar-int-variable 数组构造器始终是一个一维的数组，不能使用数组构造器直接初始化高维数组，而应该使用reshape函数。又注意数组构造器在赋值和构造时都可能用到，所以比较方便的方法是对(/ /)直接生成一维的farray实体而不是将它直接生成代码到构造函数中作为一个brace-init-list的参数： An array constructor is defined as a sequence of specified scalar values and is interpreted as a rank-one arraywhose element values are those specified in the sequence. 因为farray的构造函数用来确定数组的形状（顺带赋值是可选的），而赋值放到farray&lt;T&gt;::operator=去做。在实现时因为farray&lt;T&gt;::operator=仅仅是复制内部的线性表data，并不改变形状，可以在不同维数之间给数组赋值。 implied-do在上面的定义中ac-implied-do是个特别有意思的东西，与之类似的还有io-implied-do（用于read等io语句）和data-implied-do（用于data语句），称为隐式Do循环(Implied Do Loop)。标准中对循环的特性做出了这样的规定 If an ac-value is an ac-implied-do, it is expanded to form an ac-value sequence under the control of the ac-do-variable, as in the DO construct (8.1.4.4). 以ac-implied-do举例，隐式Do循环的的语法通常为 ac-value ::= expr | ac-implied-do ac-implied-do ::= ( ac-value-list , scalar-int-expr , scalar-int-expr [ , scalar-int-expr ] ) 在转换中为了保留隐式DO循环的结构，所以我们尽可能避免将这个Implied Do展开为C++中的for循环语句。第一个思路是把整个嵌套的Implied Do深度优先到底，得到最里面的表达式放入一个[&amp;](int do_variable1, int do_variable2, ...){...}里面，然后借助于farray里面的map函数喂给这个lambda块各层do-variable的值。不过由于ac-value-list可能包含不止一个表达式，所以这个方法实际上麻烦。于是有了第二个思路，就是按部就班一层一层处理。但这种方法仍然是要在Implied Do的上下文中处理，因为内层Do的循环过程需要依赖于外层Do对应的do-variable的当前取值。 使用DATAdata语句可以用来初始化数组，可以采用下面的语法1234data a1/1.,2.,3.,4./, a2/2.,3.,4./data b/3*1.,4*2.,3*3./data c(1),c(2),c(3),c(4)/1.,2.,3.,4./data (d(j),j=1,4)/1.,2.,3.,4./ 其中值得注意的是第二条语句中的*并不是二元算术运算符，而是表示该元素的重复次数 使用WHERE生成AST会碰到这样的问题，例如翻译上面的数组生成器，可以生成一个NT_ARRAYBUILDER节点，所以NT_ARRAYBUILDER也是一个NT_EXPRESSION节点，而数组生成器是可以出现的等号右边构成表达式，于是也可以作为赋值式归约成NT_EXPRESSION节点。所以问题存在于直接将NT_ARRAYBUILDER立即归约成表达式NT_EXPRESSION节点还是当NT_ARRAYBUILDER和新的串构成例如赋值式时再归约成表达式。对于第一种方法，会在AST的深度方向产生较多的不确定深度的节点，例如在NT_FUNCTION_ARRAY会被归约成NT_EXPRESSION。出现这种问题主要是我在列表方面有点偷懒，只设置了一个paramtable，一般非终结符必须要归约成NT_EXPRESSION才行，此外，只要列表中含有slice，所有元素都被promote成slice；进一步地，只要列表中含有键值对，所有的元素都被promote成键值对。如果修改语法，可能也要修改语义处理程序。其次是因为对于所有的运算符（除了赋值），我都将其设置为一个NT_EXPRESSION节点对于第二种方法，容易在单独使用NT_ARRAYBUILDER的时候出现问题，例如使用if(X == NT_EXPRESSION)筛选NT_EXPRESSION节点时会因为NT_ARRAYBUILDER != NT_EXPRESSION造成被误筛掉 总结Fortran数组相对于C++数组还是有很大的不同的，正因为如此，Fortran数组具有比C++要稍好的（数值计算）性能（如果能够正确使用的话）。例如Fortran的数组模型非常适合编译器针对处理器做矢量优化，而到了C++中数组往往会退化成一个指针，这可能会妨碍编译器了解内存布局，从而进行优化。此外就指针本身，Fortran也没有C++的Pointer Alias的开销。]]></content>
      <tags>
        <tag>C++</tag>
        <tag>fortran</tag>
        <tag>编译原理</tag>
        <tag>编译器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中static关键字的用法]]></title>
    <url>%2F2017%2F01%2F02%2FC%2B%2Bstatic-usage%2F</url>
    <content type="text"><![CDATA[C++中static关键字具有很多迥然不同的意义与用途，常在不同的情景下出现。例如声明局部静态变量、声明静态函数、声明类的静态成员。这三种用法的背后分别对应着不同的linkage。本文还将static与inline、extern等存储类指定符进行简单的比较，以期了解C++编译阶段和连接阶段的行为。 声明局部静态变量此时static作为五种存储类指定符storage duration specifiers(auto, register, static, extern, thread_local)中的一种，static声明的静态变量（称为local static）相对于auto(C++11标准后auto关键字另作他用)声明的自动变量，它的生存空间是从所属模块（编译单元）开始全局的，并且能够保证在函数调用之前被初始化构造完成。但是相对于直接使用全局变量，将static置于全局函数内部并返回引用可以保证在任何访问该静态对象的时候，该对象都已完成初始化（可参见Effective C++），由此可以实现单例模式，称为Meyers’ Singleton。从C++11标准开始，Meyers’ Singleton是线程安全的，这是因为新的标准规定了当一个线程正在初始化一个变量的时候，其他线程必须得等到该初始化完成以后才能访问它，而在之前的标准中可能会产生多次初始化的结果。其他的单例模式还包括使用atomtic，和std::call_once，可以访问http://www.cnblogs.com/liyuan989/p/4264889.html来了解。 静态变量和匿名名字空间注意到在C++中声明局部变量还可以通过匿名名字空间来实现，例如12static int _func();static int _var; 可以写为1234namespace&#123; int _func(); int _var;&#125; 但是匿名名字空间还适用于修饰类型的情况如1234namespace &#123; struct _struct &#123; &#125;;&#125; 但匿名名字空间和static变量还是不同的，匿名名字空间具有外部链接性（但是不知道具体名字），而static变量具有内部链接性 声明静态函数/变量在这里，static表示该函数/变量名字只能在该编译单元内部使用，而不导出。例如在不同的编译单元中使用static关键字允许出现多个同名的变量/函数。因此可以利用static实现在头文件中直接给出函数定义，也就是使用static修饰。但这是非常不好的做法，正确的做法应该是分情况使用constexpr或者inline。static常和const一起搭配用来声明一个编译期常量。 声明类的静态成员/成员函数在class声明中初始化的规定C++标准只允许static const的integral/enumeration类型(integral types)在class声明中初始化。注意在《STL源码分析一书中》指出在CB4对在类外部初始化如static int成员的支持有限，见有关组态__STL_STATIC_TEMPLATE_MEMBER_BUG的部分。在C++中禁止以下两种初始化，原因详见Stackoverflow 禁止在声明时同时初始化非const的static类成员 我们注意事实上不能static member作为类的一部分，典型的就是我们需要在类外进行定义 1234struct Foo&#123; static int i;&#125;;int Foo::i; 禁止在声明时同时初始化const的非literal的static类成员 这是由于C++ requires that every object has a unique definition. That rule would be broken if C++ allowed in-class definition of entities that needed to be stored in memory as objects C++11之后的标准似乎允许（待考证）在class声明中用默认值初始化non-static non-const的integral字段，但当定义了构造函数之后就应当用构造函数初始化。 linkage链接性(linkage)指的是一个名字在整个程序或某个编译单元中是否会绑定到同一个实体(entity)上。在上面的用法中，static都限定了一个名字的链接性，然而这三种情况下的链接性都不一样。函数中的static限定了名字只在某个函数内可见，是没有链接性的，因为它既不是全局可见，也不对当前的编译单元可见。没有链接性的实体包括局部变量和函数的形参。一个static的函数具有内部链接性，即对当前编译单元可见，而在全局不可见，即对链接器而言不可见。根据维基百科，具有内部链接性的实体包括声明、名字空间中static的自由函数（不带上下文的函数，相对于成员函数）、友元函数、变量和const常量（特别地在C++中单独的const也是内部链接性的，除非是extern const，这和C语言不一样）、enum、inline自由函数和非自由函数、class/struct、union。一个static的类成员/成员函数具有外部链接性。具有外部链接性的实体包括非inline的函数（包括非static自由函数、类非static成员函数和类static成员函数）、类的static成员和名字空间（不包括无名命名空间）中的非static变量。特别地，SoF上有一篇回答说具有外部链接性的inline函数可以出现多个定义，但我们不能认为inline函数具有外部链接性，因为他们可能实际上被内联了。 static和inline的区别单一定义原则(ODR)我们首先查看C++中重要的单一定义规则(ODR)，该规则不允许同名的强符号(strong symbol)，但允许同名的弱符号(weak symbol)。根据CSAPP，strong symbol包含了函数和已初始化的全局变量，而weak symbol包含未初始化的全局变量*。当weak symbol和strong symbol出现冲突时，链接器选择strong symbol。当没有strong symbol，而各weak symbol间产生冲突时，链接器选择占用空间最大的一个。选择占空间最大的原因在于在编译期时并不能决定这些未初始化的全局变量实际的占用大小，因为作为一个弱符号，它有可能在某个编译单元内被定义为某个4字节的长度然后在另一个编译单元内被定义为8个字节的长度。如果出现这样的情况，那么程序有大概率是出错的，但是在未开启fno-common选项时GCC并不会输出警告。但是链接期的时候链接期需要为这个弱符号在.bss注册大小，为了能够适应所有编译单元中的空间需求，所以只能取最大的一个。作为用户，为了保证weak symbol间不出现冲突，必须保证所有的声明都是一样的。特别地对于同名的重载函数，我们需要理解对于编译器和链接器，其处理的函数名字并不是其本名，而是经过mangling变成一堆乱码一样的东西以保证唯一性，这导致同一个函数通过C或C++编译出来的符号是不一样的。 inline function相对于C89标准，C++引入了inline函数。为了了解其作用，我们首先考虑一个static的函数具有internal linkage，当这个函数位于头文件中被多次包含时，编译器会生成对每个编译单元生成一个独立函数（也有可能进行内联优化），编译器不保证所有编译单元中生成的所有函数是一样的。容易发现，static会导致生成的binary变大。C++的inline关键字提供了另一个更好的方案，inline并不会保证一定会被编译器内联（可以使用__forceinline或__attribute__((always_inline))提高内联的几率），当编译器没有真正内联该函数时，就可能出现重复定义的情况（例如当这个inline定义被多次包含时），而这违背了C++重要的单一定义规则。为了解决未进行内联下的符号问题，编译器为这些inline函数创建了weak symbol。 inline variableC++17引入了inline variable，因此inline现在也可以用在变量定义上了。由于C++禁止in-class initialization of static data member of non-literal type，又禁止重复定义，需要借助下面的Workaround，通过模板的实例化阶段来获得一次“重新定义的机会”。12345678910template&lt;class Dummy&gt;struct Kath_&#123; static std::string const hi;&#125;;template&lt;class Dummy&gt;std::string const Kath_&lt;Dummy&gt;::hi = "Zzzzz...";using Kath = Kath_&lt;void&gt;; // Allows you to write `Kath::hi`. 在C++17后可以写作123456struct Kath&#123; static std::string const hi;&#125;;inline std::string const Kath::hi = "Zzzzz..."; // Simpler! 当然如果在一个编译单元内我们需要使用另一个编译单元中定义的变量时，我们还可以用extern int x;来声明，但注意extern int x = 1;是个定义。 static的可访问性static和thread_local是可以从闭包里直接访问而不需要捕捉的，使用[&amp;]形式的捕捉可能造成问题]]></content>
      <tags>
        <tag>C++</tag>
        <tag>static</tag>
        <tag>inline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++初始化方式]]></title>
    <url>%2F2016%2F12%2F30%2FC%2B%2B%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[C++新标准之后对初始化方式有了很多的变动，现在的初始化方式主要可以分为五种来讨论，分别是list initialization、aggregate initialization、zero initialization、default initialization、value initialization。本文根据标准以及cppreference上的相关资料论述了这五种初始化方式，并讨论了POD、成员初始化列表、new关键字等方面的问题。 下面是个总的例子 123456789101112// Value initializationstd::string s&#123;&#125;;// Direct initializationstd::string s("hello");// Copy initializationstd::string s = "hello";// List initializationstd::string s&#123;'a', 'b', 'c'&#125;;// Aggregate initializationchar a[3] = &#123;'a', 'b'&#125;;// Reference initializationchar&amp; c = a[0]; 博文中总结了C++11标准下的一些初始化的简要规则，但在C++14/17/20标准中，这些规则又出现许多变动。 direct initialization和copy initialization直接初始化包括 12345678910111213141516// 列表初始化T object ( arg );// This code can't be shown, or it will cause errorT object &#123; arg &#125;;// This code can't be shown, or it will cause error// 初始化纯右值T ( other );// This code can't be shown, or it will cause error// 使用static_cast初始化纯右值临时变量static_cast&lt; T &gt;( other )// 使用非空的new// This code can't be shown, or it will cause error// 使用initializer list// This code can't be shown, or it will cause error// 在lambda表达式中复制捕捉// This code can't be shown, or it will cause error 复制初始化包括 12345678T object = other;// C++11后归入列表初始化T object = &#123;other&#125; ;f(other)return other;throw object;catch (T object)T array[N] = &#123;other&#125;; 复制初始化调用复制构造函数，注意到复制初始化不是赋值，例如std::string s = &quot;hello&quot;;是（先cast再）复制初始化，std::string s; s = &quot;hello&quot;;后一句是赋值。虽然通过copy elision技术编译器可以省略复制初始化时创建临时对象的开销，但是复制初始化和直接初始化具有显著的不同。例如当复制构造函数或移动构造函数都delete时，无法进行复制初始化，典型的例子是atomic类型（不过VS2015可以编译）1std::atmoic&lt;int&gt; = 10; list initialization花括号初始化器在C++11标准中，花括号初始化器的功能被增强了。注意到在C++11前，初始化和函数声明需要区分，例如std::vector&lt;int&gt; X()既可以被看做一个变量定义，也可以被看做函数声明，这被称为Most vexing parse。Most vexing parse会造成二义性的问题，一个int f(x)，既可以被看做使用变量type_or_var来构造的对象f，又可以看做一个接受type_or_var类型的函数，这从某些方面也是不别扭的，如果将构造函数看成一类特殊的函数的话。例如在下面的语句中，TimeKeeper和Timer都是用户自定义的类型，1TimeKeeper time_keeper(Timer()); 那么time_keeper既可以按照我们希望的那样被看做一个变量定义，也可能被看做一个函数声明，这个函数返回一个TimerKeeper，接受一个参数，一个匿名的返回Timer的函数指针。对于这种二义性，C++标准指出按照第二种方式来解释。为了解决这个问题，在C++11标准前可以通过加上一组括号来强制按照第一种方式解释TimeKeeper time_keeper( (Timer()) )，但是对于具有0个参数的constructor，我们不能写成A (())的形式，StackOverflow详细论述了这一点。我们要不写成复制初始化的形式A a = A()，要不就需要写成一种很丑的办法。例如对于内置变量写成A a((0))，对于非POD写成A a利用其默认初始化特性。在我的一篇提问中详细地讨论了这个问题在C++11后，可以通过称为uniform initialization syntax的方法，使用花括号初始化的形式std::vector&lt;int&gt; X{}，通过list initialization的决议，最终完成value initialization。 列表初始化list initialization是使用braced-init-list（花括号初始化器）的初始化语句。尽管aggregate initialization被视为一种初始化聚合体的list initialization，但aggregate initialization有着自己的特点，例如aggregate initialization直接不允许有用户定义的构造函数。但是对于非aggregate的list initialization，如果提供了相应构造函数，还可以花括号列表作为一个std::initializer_list对象传给对应函数。当一个类定义了从std::initializer_list的构造函数后，对于使用{}语法将调用该构造函数，例如std::vector&lt;int&gt;(10)创建10个元素并对每个元素进行zero initialization，std::vector&lt;int&gt;{10}创建一个值是10的元素。下面的几种场景下会导致list initialization，这里根据上面的直接初始化/复制初始化分为两种。 direct-list-initialization 12345678910// 使用花括号初始化器（空或嵌套的）初始化具名对象T object &#123; arg1, arg2, ... &#125;; (1)// 初始化匿名对象T &#123; arg1, arg2, ... &#125;; (2)// 在动态存储上初始化对象new T &#123; arg1, arg2, ... &#125; (3)// 不使用等号`=`初始化对象的非静态成员Class &#123; T member &#123; arg1, arg2, ... &#125;; &#125;; (4)// 在成员初始化列表中使用花括号初始化器Class::Class() : member&#123;arg1, arg2, ...&#125; &#123;... (5) copy-list-initialization 1234567891011121314// 比1多个等号T object = &#123;arg1, arg2, ...&#125;; (6)// 函数参数function( &#123; arg1, arg2, ... &#125; ) ; (7)// 作为函数返回值return &#123; arg1, arg2, ... &#125; ; (8)// 作为`operator []`的参数object[ &#123; arg1, arg2, ... &#125; ] ; (9)// 赋值object = &#123; arg1, arg2, ... &#125; ; (10)// 强转U( &#123; arg1, arg2, ... &#125; ) (11)// 相对于4使用等号Class &#123; T member = &#123; arg1, arg2, ... &#125;; &#125;; (12) narrowing conversionC++11开始，list initialization不再允许narrowing conversion。narrowing conversion是下面的隐式转换。关于隐式转换的详细规则，可以参见我的文章《C++模板编程》。 从浮点数到整数 从浮点到整数会导致向0舍入。此外，值也有可能溢出成未确定的值。 从高精度到低精度 包括从long double、double和float三种类型之间从高到低的转换，除非是不溢出的constexpr。从高精度到低精度可能导致舍入和溢出（为Inf）。 从整数到浮点，除非是能够精确存储的constexpr 从相同字长的整数到浮点虽然不会溢出，但会被舍入 从整数或无作用域枚举类型到不能表示原类型所有值的整数类型，除非是能够精确存储的constexpr 例如从-1到(unsigned char)(-1) 下面是一个简单的例子，下面的代码都是不能编译的123vector&lt;int&gt; a&#123;1.0, 2&#125;;vector&lt;int&gt; b&#123;1.0, 2.0f, 3&#125;;vector&lt;float&gt; c&#123;float(1), 2.0f&#125;; 在Effective Modern C++中举了下面的例子12345678class Widget &#123; public: Widget(int i, bool b); Widget(int i, double d); Widget(std::initializer_list&lt;long double&gt; il); operator float() const; // convert … // to float&#125;; 这段代码在使用braced initialization时，使用Widget w{10, 5.0}初始化会调用带std::initializer_list&lt;long double&gt;的构造函数，因为优先级高。但是考虑将构造函数改为std::initializer_list&lt;bool&gt;，那么Widget w{10, 5.0}就会导致narrow conversion导致无法编译。 list initialization主要规则list initialization会按照从上到下的顺序执行。 如果初始化器列表有一个元素 如果T是聚合类型，初始化器列表包含T的相同/导出类型的单个元素，则使用该元素进行复制/直接初始化 如果T是char []，初始化器列表为一个literal string，那么使用这个string来初始化 对于其他情况，遵循下面的规则 如果初始化器列表是空的 如果T是个aggregate聚合类型，那么进行aggregate initialization 否则，如果T是class、有默认构造函数，那么进行value initialization 这里注意先后顺序，在C++14前，顺序是相反的。 考虑是否能构造std::initializer_list 如果T是std::initializer_list的特化，则从花括号初始化器列表依赖语境直接初始化或复制初始化T。 考虑T是否存在接受std::initializer_list的构造函数 首先检查所有接受std::initializer_list作为唯一参数，或作为第一个参数但剩余参数都具有默认值的构造函数。进行重载决议。 如果无匹配，则T的所有构造函数参与针对由花括号初始化器列表的元素所组成的实参集的重载决议，注意narrow conversion是不被允许的。若此阶段产生explicit 构造函数为复制列表初始化的最佳匹配，则编译失败。 如果T是一个枚举类型 如果T不是类类型 如果T是一个应用类型 在最后，如果T使用了空的{}，则使用值初始化 以下规则来自cppreference的notes部分 花括号初始化器列表不是一个表达式，所以没有类型，因此模板类型推导不能直接推导出来。auto关键字会将所有的花括号初始化器列表推导为std::initializer_list。 std::initializer_list除了在上面的list initialization使用，std::initializer_list还可以被绑定到auto，从而有下面的用法12345for (int x : &#123;-1, -2, -3&#125;) // auto 的规则令此带范围 for 工作 std::cout &lt;&lt; x &lt;&lt; ' ';std::cout &lt;&lt; '\n';auto al = &#123;10, 11, 12&#125;; // auto 的特殊规则std::cout &lt;&lt; "The list bound to auto has size() = " &lt;&lt; al.size() &lt;&lt; '\n'; aggregate initializationaggregate initialization是list initialization的特例。聚合初始化指的是可以使用一个花括号初始化器(braced-init-list)来初始化聚合对象，类似于C的初始化风格。1std::pair&lt;int, int&gt; p = &#123;42, 24&#125;; 在C++20标准草案中出现了指代初始化器，这里暂时不讨论。 aggregate（聚合）类型聚合类型包括 数组 特定的类 没有private或protected非静态成员 没有用户提供的构造函数 注意从C++11标准开始，用户可以提供=delete或者=default型的构造函数。在C++17中又限定了聚合类型也不能有inherited或者explicit的构造函数。 在C++11前转换构造函数必须是单参数非explicit的，但C++11后只要是非explicit的都是转换构造函数。 没有virtual、private或protected的基类 注意这个性质是从C++17开始的，在前面的标准中，聚合初始化必须没有基类。我觉得这个规定应该早一点出来，毕竟从C++11开始 没有虚成员函数 可以看出POD一定是聚合类型。注意聚合类或者数组可以包含非聚合的public基类和成员。 aggregate initialization规则 对于每个直接public基类、数组或者非静态成员（静态成员和未命名的位域被跳过），按照声明顺序或者下标顺序，使用initializer list中对应的initializer clause进行copy-initialization 注意直接public基类的初始化支持在C++17标准起开始支持，参照下面的这个形式 1234// aggregate in C++17struct derived : base1, base2 &#123; int d; &#125;;derived d1&#123; &#123;1, 2&#125;, &#123; &#125;, 4&#125;; // d1.b1 = 1, d1.b2 = 2, d1.b3 = 42, d1.d = 4derived d2&#123; &#123; &#125;, &#123; &#125;, 4&#125;; // d2.b1 = 0, d2.b2 = 42, d2.b3 = 42, d2.d = 4 如果对应的clause是个表达式，可以进行隐式转换（参见list-initialization） 在C++11标准开始，narrowing conversion的窄化隐式转换不被允许 如果对应的clause是一个嵌套的braced-init-list（这就不算是表达式了），使用list-initialization进行初始化这个成员或者public基类 注意public基类同样是在C++17标准开始的 未知长度的数组的长度等于初始化时的braced-init-list的长度 static成员和无名位域在聚合初始化中被跳过 如果braced-init-list的长度超过了要初始化的成员和基类数，是ill-formed，并产生编译错误 长度不足的情况 1.（C++11前）剩下来的采用value-initialization 2.（C++14开始）对于剩下来的member，如果该member的class提供default-initializer，采用default-initializer，否则采用空列表初始化（和list-initialization一样） 特别地，如果里面有引用，则是ill-formed 花括号消除value initialization下面的几种场景下会导致value initialization1234567891011121314// 使用小括号initializer创建一个匿名临时对象T(); (1)// 使用小括号initializer在动态存储上创建一个匿名临时对象new T (); (2)// 使用成员初始化列表(member initializer)初始化对象的非静态成员Class::Class(...) : member() &#123; ... &#125; (3)// 使用小括号initializer创建一个具名对象T object &#123;&#125;; (4) (since C++11)// 同1T&#123;&#125;; (5) (since C++11)// 同2new T &#123;&#125;; (6) (since C++11)// 同3Class::Class(...) : member&#123;&#125; &#123; ... &#125; (7) (since C++11) value initialization的效果是： 当一个class没有默认构造函数（或delete了默认构造函数）、具有 user-provided构造函数，default initialization这个对象 当一个class具有为delete的默认构造函数，并且没有 user-provided构造函数，首先zero initialization。如果有non-trivial的默认构造函数，再调用该默认构造函数进行default initialization。这段可以和zero initialization参照，如果默认构造函数是trivial的，则意味着编译器并不需要做任何事，这等价于只zero initialization。 数组中的每一个元素被值初始化 否则对对象进行zero initialization 引用不能被值初始化 注1：这里的 user-provided指的是用户定义的且没有显式=default的构造函数注2：由于T object();声明了一个函数，所以在C++11允许使用T object{}前，应当使用T object = T()。这种方式会导致复制，但常常被编译器优化掉 zero initializationzero initialization（如果发生）发生在其他初始化前，下面的几种场景下会导致zero initialization1234567891011// 具有static和thread\_local存储期的具名变量，包括全局变量、函数中static变量等，应当执行zero initialization// 注意常量变量应当遵循常量初始化static T object ; (1)// 作为下两种value initialization**一部分**，注意不包括default initialization// 1. 非class类型（例如primitive type） // 2. 无构造函数的对象的成员T () ; (2) (since C++11)T t = &#123;&#125; ; (2) (since C++11)T &#123;&#125; ; (2) (since C++11)// 字符数组初始化时未初始化部分被zero initializationchar array [ n ] = ""; (3) 需要特别说明，C++中的全局变量也属于静态存储期的具名变量，下面的代码中，x是一个未初始化的全局变量，它将被存储在bss(Block Started by Symbol)段中，根据CSAPP，bss段会在运行开始前被初始化为0。1int x; zero initialization效果是： 当T是一个scalar type标量类型，用0值来初始化 如果T是一个非联合(union)的class，所有的基类和非静态成员被zero initialized，所有padding被初始化为zero bits，如果有构造函数，构造函数会被忽略 如果T是一个union，第一个非静态成员用0值初始化，所有padding被初始化为0 如果T是一个数组，数组中的每个元素被zero initialize 如果T是一个引用，不做任何事情 default initializationdefault initialization发生在当一个变量未使用initializer(the initial value of a variable)构造，特别地，从C++11标准以后空的圆括号不算做未使用initializer。详情可以参照下面的初始化语句下面的几种场景下会导致default initialization 123456// 声明auto、static、thread_local变量时（还有两种是register和extern）不带任何initializer（比如小括号initializer）T object ; (1)// 在动态存储上创建对象且不带任何initializer时，特别地，C++11标准后使用空圆括号（类似`std::vector&lt;int&gt; a()`）不算做默认初始化new T ; (2)new T () ; (2) (**until c++03**)// 当基类和非静态成员不在某个构造函数的construct initializer list（类似`:a(_a), b(_b), c(_c)`）中时 default initialization效果是： 对于类类型，构造函数根据重载决议在默认构造函数中选择一个为新对象提供初始值。 注意，在C++11前的标准中中，POD的初始化是特殊的，例如new A和new A()是不一样的，new A并不会对成员进行初始化。 对于数组类型，数组中的每一个元素被默认初始化。 对于其他情况（包括基础类型），编译器不做任何事情。例如此时的自动变量被初始化到不确定的值。使用这个值会导致UB，除非一些情况。 例如标准不要求在堆和栈中的变量定义附带进行zero initialization，我们需要显式memset一下。12345void func()&#123; int x; int x[100]; int * px = new int[100];&#125; 而下面的代码则会蕴含执行一次zero initialization的语义12345void func()&#123; int x &#123;&#125;; int x[100](); int * px = new int[100]();&#125; 但是根据zero initialization的定义，具有static和thread_local存储期的具名变量，包括全局变量、函数中static变量，应当执行zero initialization，常量型应当执行constant initialization，详见zero initialization章节。 constant initialization下面的几种场景下会导致constant initializationconstant initialization会替代zero initialization（C++14标准前不是替代而是接着）初始化static和thread-local对象。发生在所有初始化前 12static T &amp; ref = constexpr; (1) static T object = constexpr; (2) 初始化方式与PODPlain Old Data是在C++03标准的一个概念，表示能和C兼容的对象内存布局，并且能够静态初始化。POD常包括标量类型和POD类类型。C++11通过划分了trivial和standard layout，精确化了POD的概念，这有点类似于C++将C风格的类型转换分为了reinterpret_cast等四个转换函数。在精化之后，POD类型即是trivial的，也是standard layout的。虽然C++11修订了POD相关内容，但是POD这一“兼容C”的特性在为C++带来人气的同时却仍然是一个巨大的包袱（虽然其他的例如C linkage也没好到那里去），有很多库都对对象的POD性质有有要求。 trivialtrivial类型首先是trivially copyable的，也就是说它能通过memcopy进行拷贝。通过简单的思考可以得知为了能够达到这样的效果，它必须具有trivial的复制、移动构造函数和操作符和析构函数。以复制构造函数为例，一个trivial的复制构造函数必须不是用户提供的，并且它所属的类没有任何虚函数（包括虚析构函数）和虚基类，并且每个数据成员都是trivial的。此外trivial的默认构造函数内部不能初始化非静态数据成员。可以发现trivial主要是对为了兼容C式的初始化、拷贝和析构行为来规定的。 standard layout成员初始化列表根据Inside the C++ object model：在构造函数体中的“初始化”实际上是对默认初始化后的该成员的进行赋值，因此浪费了一次初始化的开销。对于reference、const、有一组参数的base class构造函数、有一组参数的member class构造函数这四种情况，必须使用初始化列表进行初始化。一般地，初始化列表中的初始化顺序是按照成员在类中的声明顺序而不是在列表中的顺序，构造函数体内代码会在初始化列表“执行”完毕后开始工作。但在初始化列表中使用成员函数仍然是不好的。 委托构造函数在成员初始化列表中还可以出现委托构造函数（在新标准中），如12345678class X &#123; int a; X(int x) &#123; &#125; // 1 X() : X&#123;42&#125; &#123; &#125; // 2 X() : X(42) &#123; &#125;&#125;; 但是注意，下面这种写法是错误的1234567class X &#123; int a; X(int x) &#123; &#125; X() &#123; X(42); &#125;&#125;; 这实际上不是调用了构造函数，而是创建了一个X的右值对象。 newnew函数与new关键字我们对new的使用经常以new关键词，即new X和new X()的形式出现。但是在标准库中还存在着new函数，具体如下1234567void *operator new(size_t);void *operator delete(void *);void *operator new[](size_t);void *operator delete[](void *);// 此外还有两种noexcept的版本 这里的::operator new等是一系列标准库函数而不是运算符，它们和std::malloc等一样，用来分配未初始化的内存空间，之后可以在这段内存空间上使用placement new构造对象。所以new关键字相当于operator new加上placement new。而我们常用的new关键字实际上也都是在底层先调用operator new申请内存，然后在调用构造函数创建对象的。特别地，这种先分配内存再构造对象的思想也被用到了STL的allocator模块中，例如某些allocator实现会定义allocate()和deallocate()用来管理内存空间，而构造、析构则使用::construct()和::destroy()。在Effective C++ 要求运算符new和delete需要成对使用，原因是new []时会额外保存对象的维度，例如它会在申请的内存的头部之前维护一个size_t表示后面有n个对象（Linux以及Redis的SDS的典型构造），这样可以知道在delete []时需要调用几次析构函数，显然我们的operator new系列也是要成对使用的。当然硬要说例外也有，如果说我们初始化了一个trivial类型的数组如new int[20]，我们实际上是可以直接通过delete而不是delete []进行删除的，原因是delete最终还是会调用::operator delete释放分配的内存块，而trivial类型没有自定义的析构函数。同样的，我们可以通过观测STL的allocator模块来了解这个过程，以PJ Plauger的实现为例_Destroy_range(_FwdIt _First, _FwdIt _Last)函数会先判断is_trivially_destructible&lt;_Iter_value_t&lt;_FwdIt&gt;&gt;()是否成立，在成立的情况下就不会逐个元素地调用_Destroy进行删除了。 重载new函数在Effective C++中对这种用法进行了详尽的讨论。重载new函数能够实现“HOOK”内存分配的功能，这是具有诱惑性的。例如我们可以写出这样的new。当然一般这样写的人更有可能执着于美丽，去定义一个new的宏。1new (__FILE__, __LINE__, __FUNCTION__)Cls; 对于C，我们只要规定好调用者还是被调用者释放即可，然后malloc和free伺候。我们知道相比于C，C++的ABI是混乱的，因此我们一旦实现了自定义的new，那么一个自定义的delete是必不可少的了。但当我们的代码向外面提供接口时，事情变得复杂起来。一方面new是C++的关键词，而new函数也是new机制的关键部分，重载operator new是传染性的。一个解决的方案是在类中重载operator new函数，即static void *Cls::operator new(size_t size);，注意这里的声明是静态的，因为此时对象还没有创建，没有context。 C++对象构造顺序 Base优先于Derived 这个很容易理解，类似于云计算架构，先有个基座，然后向上有存储，然后向上有数据库啥的。 类成员的构造优先于类自己的构造函数 这也是很好理解的，一个个细胞构建好，才能构建人体嘛。不然你怎么分配空间？ 先构造的后析构 这个也是可以理解的，后构造的可能对先构造的有依赖关系。 初始化列表中的初始化顺序，是按照在类声明中定义的顺序 所以是先初始化基类，在根据类声明中的顺序初始化，再执行构造函数体]]></content>
      <tags>
        <tag>C++</tag>
        <tag>POD</tag>
        <tag>new</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++模板编程]]></title>
    <url>%2F2016%2F12%2F22%2FC%2B%2B-meta-programming%2F</url>
    <content type="text"><![CDATA[模板编程是C++的一个重点和难点，标准库中有非常多的内容都是通过模板实现的（STL）。C++11标准以来，C++在泛型编程方面引入了许多新的特性。本文讨论了围绕C++模板的诸多技术与编程方法。 C++的编译过程首先，我们来看这样一个问题，我们能否声明一个模板成员函数为虚的呢？123struct Cls&#123; template&lt;typename T&gt; virtual int a()&#123;&#125;&#125;; 答案是不行的。为此，我们需要介绍两个概念模板实例化(instantiation)，C++中的模板既不是一个类型，也不是一个对象，也不是一个实体。在C++编译器生成后的real code中，不存在任何模板的概念。那么这个实例化的顺序是怎么样的呢，是整个程序先扫一遍，完成一次性的“替换调用”，还是链式的呢？这里涉及到point of instantiation的概念，详情可参考我的文章stateful constexpr，简单地来说，就是我要用到了就去实例化。因此，某个函数模板到底会被实例化多少次，那是要等编译结束才会知道的。那么同样需要在编译结束才能知道的是一个类的布局。因为C++需要看到整个类的定义（而不是声明）才能为这个类生成代码，而虚函数所依赖的虚表需要在类被编译完成时才能确定。 各种traitstraits是C++ STL中的重要组成成分 数值部分 判断是否是整数：std::is_integral&lt;T&gt;::value 判断是否有符号：std::numeric_limits&lt;T&gt;::is_signed 迭代器部分判断迭代器种类以及内容：std::iterator_traits。这个trait实现很有意思，为了兼容指针和常指针这两个最原始的“迭代器”，这里使用了SFINAE123456789101112131415161718192021222324252627282930313233343536373839404142434445template&lt;class _Iter&gt; struct _Iterator_traits_base&lt;_Iter, void_t&lt; // 这里的void_t使得不具有下面五个成员的两种指针失配 typename _Iter::iterator_category, typename _Iter::value_type, typename _Iter::difference_type, typename _Iter::pointer, typename _Iter::reference &gt; &gt; &#123; // defined if _Iter::* types exist typedef typename _Iter::iterator_category iterator_category; typedef typename _Iter::value_type value_type; typedef typename _Iter::difference_type difference_type; typedef typename _Iter::pointer pointer; typedef typename _Iter::reference reference; &#125;;template&lt;class _Iter&gt; struct iterator_traits : _Iterator_traits_base&lt;_Iter&gt; &#123; // get traits from iterator _Iter, if possible &#125;;template&lt;class _Ty&gt; struct iterator_traits&lt;_Ty *&gt; &#123; // get traits from pointer typedef random_access_iterator_tag iterator_category; typedef _Ty value_type; typedef ptrdiff_t difference_type; typedef _Ty *pointer; typedef _Ty&amp; reference; &#125;;// 注意 const _Ty *要单独拿出来偏特化，如果用上面的偏特化的话，我们得到的是const _Ty而不是_Tytemplate&lt;class _Ty&gt; struct iterator_traits&lt;const _Ty *&gt; &#123; // get traits from const pointer typedef random_access_iterator_tag iterator_category; typedef _Ty value_type; typedef ptrdiff_t difference_type; typedef const _Ty *pointer; typedef const _Ty&amp; reference; &#125;; 对象行为部分C++新标准中使用了is_...able&lt;&gt;函数代替了之前的has_...函数 reference_wrapper显然std::vector是不能存放T &amp;的，如果不希望放指针进去，可以使用std::reference_wrapper，不过这东西用起来也并不舒服，例如C++不能重载operator.，虽然最近有一些草案正在提到这一点，所以必须得get()一下。std::reference_wrapper常用于std::bind、std::thread等函数/类上。它们为了保证传入的参数在自己的生命周期中是持续存在的，决定始终通过传值的方式接受参数，即始终拷贝一份，因此此时如果要传递引用，就得使用std::ref包装一下了。 operator重载operator=、operator()、operator[]、operator-&gt;、operator T不能作为non-member function，这是因为担心与自动合成的operator=出现行为不一致的问题。其实还可以更深入地考虑这个问题，例如对于比较大小的运算符operator&lt;123456789101112struct A;struct B;struct A&#123; operator&lt;(const B &amp; b)&#123; return true; &#125;&#125;;struct B&#123; operator&lt;(const A &amp; b)&#123; return true; &#125;&#125;; 这显然是不符合逻辑的 const不是编译期常量在C++初始化方式中已经提到常量const是不能在构造函数体中初始化的，但可以在初始化列表中可以进行初始化，对于常量数组或者标准库的std::vector等容器，现在可以使用花括号{}进行初始化。需要额外说明的是const甚至不能作为模板参数等编译期常量使用。例如在MSVC2015中，下面的代码是无法通过编译的123456789101112struct C &#123; const int x; C(int _x) :x(_x) &#123; &#125;&#125;;int main() &#123; const C c(1); int a[c.x]; system("pause");&#125; 原因是在C.x虽然是常量，但是要到运行期才能知道，这里应该使用的是static const或者constexpr，const修饰符实际上的意义更接近于readonly。如果说const能够“节省空间”，那是由于其不可变，所以发生拷贝时，const对象实际上并不发生复制，但只const修饰的类成员仍然是占空间的。 特化using与函数相同，C++中的using也不能直接特化，如12345template &lt;typename T&gt;using wrap&lt;T&gt; = T;template &lt;&gt;using wrap&lt;int&gt; = int; 必须需要借助类来workaround1234template &lt;typename T&gt;struct wrap&#123; using type = T;&#125; 函数模板的特化与函数的重载为了实现函数的“多态”，常有借助模板类偏特化和重载两种方式。 借助重载实现函数的“偏特化”虽然函数模板不能偏特化，但函数本身就有重载，因此我们可以在每个不同的函数末尾加上一个tag来达到根据某些traits进行“分类讨论“的效果。例如最常用的std::true_type和std::false_type。在STL的实现中使用了很多这样的_tag来控制行为，例如控制std::advance()函数在接受五种不同迭代器时的更新行为，或者原子库中使用tag标记六种内存模型。即使当我们要“偏特化”的是非类型模板参数时，也可以直接利用重载而不是“偏特化”，这时候我们可以在类里面用enum或者static constexpr int将这个值封装起来，也可以直接借助于标准库的std::condition等函数。在下面的例子中，我们需求模板函数的行为根据std::is_same&lt;T, C&gt;::value进行分类讨论。1template&lt;typename T, typename U&gt; when_eq(T x, U y); // 1 在没有constexpr if的情况下，用函数重载来做是一种直截了当的方案。但是重载是对类型而言的，而if只能判断true/false值，非类型模板参数又不能使用整型以外的类型。所以必须要有个机制来将整型值包装成类型，这里可以借助标准库提供的std::integral_constant&lt;typename T, T val&gt;，或者也可以自己实现一个Int2Type或者Int2Type2。这个思路可以解决很多问题，例如对成员函数的偏特化。12345678910111213141516171819202122232425262728293031template &lt;int I&gt;struct Int2Type&#123; enum &#123; value = I &#125;;&#125;;template &lt;int I&gt;struct Int2Type2&#123; static const /* or constexpr */ int value = I;&#125;;struct X&#123;&#125;;struct Y&#123;&#125;;template &lt;typename T, typename U&gt; void when_eq(T x, U y, Int2Type&lt;1&gt;)&#123; puts("eq");&#125;template &lt;typename T, typename U&gt; void when_eq(T x, U y, Int2Type&lt;0&gt;)&#123; puts("neq");&#125;template &lt;typename T, typename U&gt; void when_eq(T x, U y)&#123; when_eq(x, y, Int2Type&lt;is_same&lt;T, U&gt;::value&gt;()); &#125;int main()&#123; when_eq(X(), Y()); when_eq(X(), X());&#125; 这里特别提一下enum的性质，根据标准在使用enum E {V1, V2}的值V1、V2时是不需要加上E::限定符的。此外其具体类型可以使用std::underlying_type获得。 借助类模板实现偏特化还可以使用类模板“偏特化”函数，如果需要上下文，那么可以重载operator()的方式实现一个仿函数，如果不需要上下文，可以在里面定义一个static函数。如果一定需要偏特化，考虑在一个偏特化类中实现static函数。这又带来一个新的问题，考虑要偏特化一个类中成员函数，如果偏特化类，那其他的成员函数也要重复实现一遍，显得很麻烦，对于这个问题，可以参考这里的说明 普通函数、函数模板和全特化模板函数之间的决议在这一章节中，我们将讨论重载的普通函数、函数模板和其特化函数之间的决议顺序。模板函数一旦全特化，它就和普通函数一样成为一个strong symbol，我们应当使用inline，static，extern关键字防止重复定义。但是对于全特化的函数模板，它和不加template&lt;&gt;的普通函数还是有着很大区别的？根据C++ Premier中的说明 当调用从模板实例化的函数时，只有有限的类型转换可以被应用在模板实参推演过程使用的函数实参上；如果声明一个普通函数则可以考虑用所有的类型转换来转换实参，这是因为普通函数参数的类型是固定的 上面的话是说明template&lt;&gt;特化函数模板比普通函数的匹配要求更高，这是因为普通函数还能接受传入参数的隐式转换。在C++ Primer的16.5节中指出，我们在多个函数之间进行决议时总是选择最为精确的函数，当普通函数和模板函数同样适配时，优先选择普通函数。 在这个例子中，a是int，显然主模板0能够精确匹配，于是决议到0，输出&quot;template&quot;。 1234567891011121314// #0template&lt;typename T&gt;void promotion(T x) &#123; puts("template");&#125;// #1void promotion(double x) &#123; puts("function");&#125;int main() &#123; int a = 1; promotion(a); // template&#125; 这个例子就是一个经典的SFINAE用法了，我们知道一个数组的大小只能是整数而不能是浮点数，所以当T是double时，char(*)[T()]就是ill-formed。根据SFINAE，我们不把它作为错误，而是转而寻求次优解。 1234567891011121314// #0template&lt;typename T, typename = char(*)[T()]&gt;void promotion(T x) &#123; puts("template");&#125;// #1void promotion(double x) &#123; puts("function");&#125;int main() &#123; int a = 1; promotion(a); // function&#125; 但我们必须要考虑一个特例，也就是当有多于一个函数能精确匹配的情况，这时候优先级的顺序是普通函数、全特化、主模板。我们首先给出一个综合的实例。 普通函数先于全特化 1234567891011121314151617// #0template&lt;typename T&gt;void promotion(T x) &#123; puts("template");&#125;// #1void promotion(double x) &#123; puts("function");&#125;// #2template&lt;&gt;void promotion(double x) &#123; puts("template&lt;&gt;");&#125;int main() &#123; promotion(1.0); // function&#125; 全特化版本先于主模板 1234567891011121314// #0template&lt;typename T&gt;void promotion(T x) &#123; puts("template");&#125;// #1template&lt;&gt;void promotion(double x) &#123; puts("template&lt;&gt;");&#125;int main() &#123; promotion(1.0); // template&lt;&gt;&#125; decay 1234567891011121314// #0template&lt;typename T&gt;void promotion(T &amp; x) &#123; puts("template");&#125;// #1void promotion(int x) &#123; puts("function");&#125;int main() &#123; int a = 1; promotion(a); // function&#125; 考虑可访问性C++中的可访问性包括private、protected和public三类，可访问性是针对类而不是对象而言的。C++中重载决议是在可访问性检查之前进行的 考虑隐式类型转换在日常编程中，我们我们常常把字符串直接量当做std::string使用，但其实字符串直接量的类型是const char[]，这其中涉及到隐式构造函数或者隐式类型转换。这导致在进行重载决议时出现“不合常理”的情况。 普通情况在知乎的这篇问题中，我们看到Test中定义了两个成员函数。123456789101112131415class Test &#123;public: void find(const string &amp;first_name, const string &amp;last_name); void find(const string &amp;name, bool retied);&#125;;void Test::find(const string &amp;first_name, const string &amp;last_name)&#123; cout &lt;&lt; "find 1" &lt;&lt; endl;&#125;void Test::find(const string &amp;name, bool retied)&#123; cout &lt;&lt; "find 2" &lt;&lt; endl;&#125; 现在考虑下面的调用，我们发现是调用的find 2版本的函数。这是由于const char[]被decay成了const char *，然后隐式转换成了bool。 Test().find(&quot;a&quot;, &quot;b&quot;); 隐式类型转换的顺序类型隐式转换具有下面的顺序： 精确匹配 这里对应着几种decay，即T[] -&gt; T*、T&amp; -&gt; T、F(...) -&gt; F (*)(...)、T const -&gt; T。 我们首先来看一下什么是decay。例如，对于数组T a[n]，除了sizeof、alignof、引用限定符&amp;以及字符串常量等少数情形外，a出现时会被decay成指向T的指针。例如下面代码往char s[N]数组中读入了数据。 1scanf("%s", s); 而很多人会误写为以下的代码 1scanf("%s", &amp;s); 此时，s的类型实际上是char (*) [N]（pointer to an array of char），而scanf希望接受到的是char *（pointer to char）类型。 下面列举出了几种情况： 无转换 lvalue到rvalue、数组到指针、函数到指针 限定符转换 我们可以为任意类型加上CV限定符。对于多重指针来说，前面的重数的限制要高于后面重数的限制，如 123char** p = 0;const char** p1 = p; // error: level 2 more cv-qualified but level 1 is not constconst char* const * p2 = p; // OK: level 2 more cv-qualified and const added at level 1 类型提升转换(promotion) 即Numeric promotions，包含Integral promotion和Floating-point promotion 这里注意，非promotion的整数之间转换都作为conversion，如char -&gt; int 标准转换 包含Numeric conversions，如Integral conversions、Floating-point conversions、Floating–integral conversions、Pointer conversions、Boolean conversions 用户自定义转换 这就包括了std::string中定义的从const char *的转换了 注意能进行隐式类型转换并不意味着类型相同，所以使用std::is_same进行的判断都是false，例如下面的代码输出都是false。12std::cout &lt;&lt; std::is_same&lt;int, int &amp;&gt;::value &lt;&lt; '\n';std::cout &lt;&lt; std::is_same&lt;int, const int &amp;&gt;::value &lt;&lt; '\n'; 考虑传参时decay的特殊情况紧接着上面的讨论，我们查看下面的一段代码，这时候输出就变成true了，究其原因是因为123456789template&lt;typename T, typename U&gt;bool check(T x, U y)&#123; return std::is_same&lt;T, U&gt;::value;&#125;int main()&#123; int a = 1; const int &amp; b = a; std::cout &lt;&lt; check(int(), a) &lt;&lt; '\n';&#125; 同样是类型转换问题，在文章中提到了一个特别的情况123456789101112template &lt;typename T&gt;int compare(const T&amp; a, const T&amp; b)&#123; std::cout &lt;&lt; "template" &lt;&lt; std::endl; return 0;&#125;int compare(const char* a, const char* b)&#123; std::cout &lt;&lt; "normal" &lt;&lt; std::endl; return 0;&#125; 现在调用 compare(&quot;123456&quot;, &quot;123456&quot;); 请问是调用了那个函数呢？有意思的是，对于不同编译器，结果还不一样。作者指出对G++/clang来说是调用了模板版本，而我使用VS2015发现调用的是普通版本。调用模板版本的原因是T = const char [6]相比decay后的const char *更精确；但是调用普通版本的原因是数组传参时要decay成对应的指针。因此对于模板函数和普通函数实际上都不是精确匹配的（都要经过一次类型转换）。根据C++重载决议原则，如果调用具有二义性，则优先选择调用普通函数。在本篇结尾，作者引用陈硕的观点，认为G++/clang的实现是符合标准的，但是这属于标准的bug。其原因是模板实参推断(template argument deduction)时，除了产生新的实例化之外，编译器只会执行两种转换： const转换：接受const引用或指针的函数可以分别用非const对象的引用或指针来调用，无须产生新的实例化。也就是可以传一个非const到需要const参数的函数。 数组或函数到指针的转换：如果模板形参不是引用类型，则对数组或函数类型的实参应用常规指针转换。数组实参将当作指向其第一个元素的指针（如前文所说），函数实参当作指向函数类型的指针。 由于模板参数使用了数组的const引用类型，所以按照标准应该不将数组向指针进行decay。 考虑继承SFINAE在C++中常常出现一些ill-formed的代码，这些代码在函数体或者其他地方出现编译器都是要报错的，SFINAE(Substitution Failure Is Not An Error)规定，当推导模板参数失败(fail)时，编译器不产生错误，而是放弃使用这个重载集推导参数。我们需要注意，这样的替换发生在下面四种情况下： (Type SFINAE)所有用于函数的类型，包括函数的返回值与参数的类型 (Type SFINAE)所有用于模板参数的类型 (Expression SFINAE)所有用于函数类型中的表达式 (Expression SFINAE)所有用于模板形参声明中的表达式 这些常被使用的ill-formed代码包括下面的形式： 试图实例化含有多个不同长度包的包展开 试图创建void的数组、引用的数组、函数的数组、抽象类类型的数组、负大小的数组或零大小的数组 例如之前提到过的char(*)[0.5]，还有char [0]、void [3]等 试图在::左侧使用非类或非枚举的类型 比如int::field是错的 试图使用类型的不存在的成员 比如vector&lt;int&gt;::abcdefg是错的，因为它肯定没有这个字段 试图在错误的地方是用类型的成员（类型、模板、非类型如literal等） 试图创建指向引用的指针 试图创建到 void 的引用 试图创建指向T成员的指针，其中T不是类类型 这个常常可被用来判断T是否是类类型，代码如下所示。这里C::*表示一个指向类C中某int类型成员的指针，说明了这个指针带有C的上下文，而...相当于一个兜底的东西。 12345678910111213141516template&lt;typename C&gt; bool test(int C::*)&#123; return true; // C是类&#125;template&lt;typename C&gt; bool test(...)&#123; return false;&#125;struct X&#123; double x; &#125;;int main() &#123; cout &lt;&lt; test&lt;int&gt;(0)&lt;&lt; endl; // false cout &lt;&lt; test&lt;X&gt;(0)&lt;&lt; endl; // true&#125; 试图将非法类型给予非类型模板参数 这个SFINAE将在后面std::void_t中被广泛使用 试图进行非法转换 试图创建拥有形参类型void的函数这个SFINAE对应于前面的“试图将非法类型给予非类型模板参数” 试图创建返回数组类型或函数类型的函数 试图创建参数类型或返回类型为抽象类的函数类型 自然而然地想到如果我们需要判定某个实体是否具有某种性质，我们就可以构造一种没有这种特性就会造成ill-formed的表达式或者类型（分别对应Expression SFINAE和Type SFINAE），这样我们就可以把traits的问题转化为函数重载或者模板类的偏特化的决议问题来讨论。在函数重载使用SFINAE时，我们常常在定义函数时在函数最后放一个可能会ill-formed类型的指针，在调用时传一个nullptr过去。相对于遥不可及的concepts，SFINAE机制看起来更为神奇，它在不引入一个新的语法机制的情况下来实现了traits的功能，但伴随而来的是我们把Failure和Error都放在了模板实例化或者重载决议时处理，这样当Error发生时我们就不能得到清晰的错误报告。 使用SFINAE判断是否存在成员利用SFINAE的方式分为两种，通常见到的是Type SFINAE。关于Expression SFINAE，可以参考这个回答 模板偏特化是相对原型/初等/主(primary template)模板来说的，编译器首先匹配出原型，再根据原型找出合适的特化模板。例如对模板类型参数T而言，T*、T&amp;、const T &amp;等是它的一个偏特化。通过偏特化我们可以进行分类讨论。1234567891011// 终止条件template&lt;typename Cont&gt;bool handle_container(Cont &amp; cont) &#123; puts("not a container");&#125;;template&lt;typename Cont&gt;bool handle_container(Container&lt;Cont&gt; &amp; cont) &#123; puts("container"); handle_container(cont[0]); &#125;; 偏特化可以用来检查一个类中是否具有某个成员123456// https://www.zhihu.com/question/34264462template&lt;typename Cont, typename = void&gt; struct has_push_back : std::false_type &#123;&#125;;template&lt;typename Cont&gt;struct has_push_back&lt;Cont, std::void_t&lt;decltype(&amp;Cont::push_back)&gt;&gt; : std::true_type &#123;&#125;; 始终对std::vector&lt;int&gt;断言失败。后来查看SoF，当时以为是MSVC2015对std::void_t的支持有问题。后来在SoF的另一篇博文上发现如果我们的push_back不是成员函数而是数据成员就可以通过。去SoF上问了一波，这是因为std::vector&lt;int&gt;::push_back有多个重载版本，于是应该还要匹配函数签名，因此我们可以写成下面的形式，我们显式构造了vector.push_back(vector::value_type())这个表达式，看它是不是合法。123456789// https://www.zhihu.com/question/34264462/answer/58260115template&lt;typename Cont, typename = void&gt;struct has_push_back : std::false_type&#123;&#125;;template&lt;typename Cont&gt;using ValueType = typename Cont::value_type;template&lt;typename Cont&gt;struct has_push_back&lt;Cont, std::void_t&lt;std::declval&lt;Cont&gt;().push_back(declval&lt;ValueType&lt;Cont&gt;&gt;())&gt;&gt; : std::true_type&#123;&#125;; 注意到我们这里都是用类的偏特化来实现的，我也尝试了下使用函数搞一搞12345678template&lt;typename Cont, typename = void&gt; bool has_push_back() &#123; return false;&#125;template&lt;typename Cont, typename = std::void_t&lt;decltype(&amp;Cont::push_back)&gt;&gt; bool has_push_back() &#123; return true;&#125; 这样会出现函数模板已经定义的错误。在cppreference中给出了说明 A common mistake is to declare two function templates that differ only in their default template arguments. This is illegal because default template arguments are not part of function template’s signature, and declaring two different function templates with the same signature is illegal. 此外在SoF 上给出了如下说明 SFINAE only works for deduced template arguments 判断模板参数是否是广义函数目前广义函数包括函数、std::function、lambda、仿函数，其中std::is_function只能识别函数。C++17标准添加了std::is_invokable(即之前的std::is_callable)，用来表示可以INVOKE的类型。关于这一部分，可以参考我的博文C++仿函数的作用实现 实现member function的const版本有些member function的const版本相对于非const版本只是加上了const的限制，重复实现一遍会造成代码的浪费。根据stackoverflow，可以直接const_cast this指针即可。对一个非const加const限制是安全的，但反过来不一定。如果说const函数需要修改非mutable成员，那么可以实现一个static非成员模板函数，将this传进去 推导lambda的类型根据StackOverflow上的这个答案，lambda是函数对象而不是函数，但是可以被转换(convert to)成std::function，这是由std::function的可以有所有能被调用的类型构造，也就是说这可以这么写std::function&lt;int(int)&gt;lambda = [](int x) {return 0; };。但是类型推导是另一回事，因为lambda并不是std::function，我们只能用auto来声明一个lambda表达式，所以编译器不能通过一个lambda去推导std::function的参数。BTW，Effective Modern C++指出使用auto关键字相对于使用显式声明是比较好的。具体得来说他可以避免default initialization的变量、难以表示的类型、避免可能造成的类型截断问题。特别地，标准指出一个不捕获lambda表达式可以被转成一个函数指针，但是将这个lambda表达式转成函数指针需要一些技巧，如借助lambda表达式和不借助lambda表达式。特别地，函数指针可以看做函数的入口点，它是全局的，而一个函数对象如std::function可以携带context，所以是不能转换为一个函数指针的。在这里还需要将函数签名与函数指针区分开来，一般在使用函数签名的场合常需要考虑C linkage。因此比较好的解决方式是直接使用template&lt;typename F&gt;，所以说现在的问题是如何得到F的返回值类型。这时候可以借助std::result_of来推导typename F的返回类型，注意这里要写成decltype(lambda_func)()，而不是decltype(lambda_func)1234auto lambda_func = []()&#123; return 1 + 2;&#125;;using lambda_func_t = std::result_of&lt;decltype(lambda_func)()&gt;::type; 此外，经测试可以推导函数对象的返回类型，不能推导C原生函数的返回类型。1234567891011121314151617181920int native_func(int a) &#123; return 0;&#125;struct object_func &#123; int operator()(int a) &#123; return 0; &#125;&#125;;template&lt;typename F&gt;auto call_func(F f)-&gt; std::result_of_t&lt;F(int)&gt; &#123; return 0;&#125;int main() &#123; typename std::result_of&lt;object_func(int)&gt;::type x; // Yes typename std::result_of&lt;native_func(int)&gt;::type y; // No object_func of; call_func(of); // Yes call_func(native_func); // Yes system("pause");&#125; 参考了StackOverflow上的答案，这是因为原生函数并不是一个type，但是std::result_of&lt;F(Args...)&gt;中的F必须要是一个类型，合适的解决方法是直接使用decltype+declval，decltype(native_func(std::declval&lt;int&gt;()))，而不是用std::result_of。此外，在C++17标准之后，可以使用std::invoke_result来替代std::result_of。此外，从这个回答可以看到，可以实现一个function_traits。这个类型类似pattern matching，能够同时处理函数对象和函数的指针的情况，并且能够推导出参数和返回值。1234567891011121314template &lt;typename T&gt;struct function_traits : public function_traits&lt;decltype(&amp;T::operator())&gt; &#123;&#125;;template &lt;typename ClassType, typename ReturnType, typename... Args&gt;struct function_traits&lt;ReturnType(ClassType::*)(Args...) const&gt;&#123; enum &#123; arity = sizeof...(Args) &#125;; typedef ReturnType result_type; template &lt;size_t i&gt; struct arg &#123; typedef typename std::tuple_element&lt;i, std::tuple&lt;Args...&gt;&gt;::type type; &#125;;&#125;; 在类模板中声明友元函数模板在一个模板类farray中声明一个友元函数123456789template&lt;typename T&gt;struct farray&#123; // ... friend farray&lt;bool&gt; operator&lt;(const farray&lt;T&gt; &amp; x, const T &amp; y);&#125;template &lt;typename T&gt;farray&lt;bool&gt; operator&lt;(const farray&lt;T&gt; &amp; x, const T &amp; y)&#123; // ...&#125; 可能会报error LNK2019: 无法解析的外部符号 “struct for90std::farray __cdecl for90std::operator&lt;(struct for90std::farray const &amp;,int const &amp;)” (??Mfor90std@@YA?AU?$farray@_N@0@AEBU?$farray@H@0@AEBH@Z)错误原因是T是类模板farray的模板参数，随着类模板特化。所以应该给友元函数operator&lt;独立的模板参数，改成这样就好了1template&lt;typename U&gt; friend farray&lt;bool&gt; operator&lt;(const farray&lt;U&gt; &amp; x, const U &amp; y); 详细可以参考这篇答案 通用引用根据Effective Modern C++ Item 24的规定。函数签名中的T&amp;&amp;，如果T是需要推导得来的，这样的T表示通用引用(universal/forward reference)。通用引用是C++通过引用折叠(reference collapsing)表现出的一个特性，一个通用引用可以绑定到任何由cv修饰的引用上。容易混淆的通用/右值引用包括1234567891011121314151617181920// 以下属于rvalue referencevoid f(Widget&amp;&amp; param);Widget&amp;&amp; var1 = Widget();// 通用引用定义必须是T&amp;&amp;或者auto&amp;&amp;的形式template&lt;typename T&gt;void f(std::vector&lt;T&gt;&amp;&amp; param)class vector&lt;T, allocator&lt;T&gt;&gt;&#123;public: // 通用引用中必须发生类型推导 void push_back(T&amp;&amp; x);&#125;;// 以下属于universal referenceauto&amp;&amp; var2 = var1;template&lt;typename T&gt;void f(T&amp;&amp; param); 如果对于参数包不加上通用引用Args&amp;&amp;，那这个参数包就不能接受一个左值。1234567891011121314151617181920212223// 注意参数包的终止条件要在主模板前面template &lt;typename T, typename ... Args&gt;void test_pack_lvalue(T &amp; x) &#123; x = 1;&#125;template &lt;typename T, typename ... Args&gt;void test_pack_lvalue(T &amp; x, Args ... args) &#123; x = 1; test_pack(forward&lt;Args&gt;(args)...);&#125;template &lt;typename T, typename ... Args&gt;void test_pack_clvalue(const T &amp; x) &#123;&#125;template &lt;typename T, typename ... Args&gt;void test_pack_clvalue(const T &amp; x, Args ... args) &#123; test_pack_clvalue(forward&lt;Args&gt;(args)...);&#125;int main()&#123; int a = 0, b = 0, c = 0; test_pack_clvalue(a, b, c);&#125; 两阶段名字查找(Two-phase name look up)两阶段名字查找模型是表示一系列用来决议C++模板声明中使用到的名字的规则，它最初的提出是用来在inclusion model（现在用的）和separation model这两种模板实现方式之间进行妥协的。两阶段名字查找模型规定了模板函数体中出现的所有名字的查找方式。我们首先定义non-dependent名字，一个non-dependent名字在查找时不依赖任何的模板参数，所以对于任意实例化后的模板它都是一样的。相反一个dependent名字依赖于模板参数，例如A&lt;X&gt;::B b中的b、this都是dependent的名字。此外对于像A::B这样的名字，编译器可能并不知道它是一个函数还是一个类型或者一个变量，所以当做类型使用时，我们需要显式指定一下typename来通告编译器。不过有的时候大家就滥用，有的没的都加上typename，会报错expected a qualified name after &#39;typename&#39;。这是因为只有在嵌套从属名称前面才要加上typename，其他的例如typename C &amp; cont的用法是错误的。 对于non-dependent符号，该符号在模板定义阶段即被查找决议（all non-dependent names are resolved (looked up)），此外在第一阶段还会做一些语法检查。 对于dependent符号，查找被推迟到模板被实例化(point of instantiation, POI)时。 在早期版本中，MSVC不支持two phase name lookup，由此带来的结果就是很多MSVC能编译的代码在GCC等编译器上并不能够编译。我们查看下面的代码1234567void func(void*) &#123; std::puts("The call resolves to void*") ;&#125;template&lt;typename T&gt; void g(T x)&#123; func(0);&#125;void func(int) &#123; std::puts("The call resolves to int"); &#125;int main() &#123; g(3.14); &#125; 根据两阶段查找，func是无依赖的，由此在模板定义时就会被决议。因此虽然g中调用的func(0)函数的最佳决议应该是void func(int);，但是由于此时g尚未看到void func(int);，所以只能决议到void func(void *)，这也就是gcc的标准实现。但MSVC的某些版本很懒，根本不在模板定义阶段做事，所以在模板实例化阶段我们已经能够看到最佳适配的void func(int);了。 常用术语参数包：parameter pack类型限定符（const, volatile）：qualification adjustment返回类型后置：trailing return type函数签名：signature模板类型推导：template argument deduction聚合体Aggregates和POD(Plain Old Data)=trival+standard layout：见此解释非类型模板参数：non type template parameter包扩展：pack expansion花括号初始化器：brace-init-list省略号(…)：ellipsis符号扩展、零扩展：sign/zero extension可变参数模板：Variadic Templates pack展开模式：pattern决议：resolution]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ICPC CHINA-FINAL小记]]></title>
    <url>%2F2016%2F12%2F11%2FICPC%20CHINA-FINAL%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[退役之战 正式赛赛题热身赛虽然是GCJ或者APAC的题目，然而特意刷了一遍的我并没有什么映像啊。第一题是求2的多少进制都是1，推出一个等比数列，套求和公式，然而发现爆long long就WA了，于是我建议遍历位数，二分底数，zyyyyy很快敲了一发WA了，后来他发现还是会爆long long，于是又敲了一发又WA了。然后我看他的代码发现他的算B的n+1次幂Sn+1的时候使用Sn * B &lt; 0来判断溢出，然而只有加减法才可以这么用，于是我让他改成LONGLONG_MAX/B来判溢出，结果1A了。一进门首先发现午饭已经发了。。。Google出题一般一头一尾是水题，zyyyyy直接过掉了A，L我们在找规律，zyyyyy直接dfs过掉了，下面就是搞D和H 感受 熟悉的shu，熟悉的体育馆，熟悉的安检，熟悉的烂键盘，熟悉的小屏幕，熟悉的沙滩椅，熟悉的羽绒背心，熟悉的80元卡（终于可以挂在脖子上了） 热身赛结束的时候陈老师居然找到我们后面的sjtu退役队玩（后来发现是是叉姐的队！我们居然没认出来！），然后我们求合影，然后发现杜老师也在，酸酸地说粉丝要和你合影，于是我们和两位老师合了影（好像还是叉姐帮我们拍的照片，啊~~） 图书馆下面的超市居然这次不收税了！于是我们九张卡扫荡了一波，晚饭直接零食解决了，然后大家都好污啊。。。 抓娃娃机好坑啊 热身赛遇到了几个巴基斯坦学生 上大旁边的一条街真是无敌了，什么吃的都有 我认为对于一个努力的人来讲，他自己到最后不一定在意这个结果了，因为他自己的进步本身就是对自己的认可了。但对于我来说，我有过痛苦的经历，我希望每一个努力的人都能获得一些外界的认可，就算他自己不在乎。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>现场赛</tag>
        <tag>ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NUAA-HHU联赛小记]]></title>
    <url>%2F2016%2F12%2F04%2FNUAA-HHU%E8%81%94%E8%B5%9B%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[今天参加NUAA-HHU联赛，拿了1030分，第六，出了9条。这是排行榜 正式赛赛题一进机房发现妈的旁边的都是触屏的大屏幕，就我们是小屏幕。机器是windows，只带devc。发题目之前看了I，觉得比较难搞，纸质题目发下来我从后向前切，zzzyy从前向后，zyyyyy调完devc看了A有思路说我们不要看了，敲完1A，这时候我已经放弃了ML两条，K题面样例有问题，我和zzzyy吐槽了，于是zzzyy去看，我看J觉得是dp，推了一下有了结果，给zzzyy讲了他觉得有道理，不过这时候zyyyyy过了C在做比较麻烦的D，于是我先压着，看一看榜B过的很多，看B卧槽不就是NOI2016那条膜蛤题么，知乎上看到过的，zzzyy觉得H能做就是找出两个只出现一次的数（其他出现两次），于是搞了一波nlogn算法T了，zyyyyy说有O(n)的算法，于是他去搞D，然后我想n的算法，zyyyyy1A了D之后（我们第一了）我突然灵光一现想到只有一个出现一次的数就xor就行了，两个不知道是否可以，问zyyyyy觉得是有方法的，于是我偷着百度一下发现可以按照lowbit出来的那一位分成两组分别异或这样就是两个重复的数了。交了T，妈的有常数解法？我觉得判题有问题，于是问了贴气球（在墙上）的人，他们说没有多组样例，妈的去掉while != EOF就1A了，结束后发现nlogn也能过，真是醉了。然后搞完BH，zyyyyy写I，看榜发现GEFK有人在搞，G最多，推了一会儿G没结果，然后zyyyyy的I wa了两次然后他发现了问题准备想怎么解决。于是我说我来想你先把我有思路的J敲了呗，于是J1A了，还是一血，我很高兴于是上了个厕所，然后在厕所我突然想到可以从边界的O开始DFS，这些O肯定不会被消掉，其他的O肯定会被消掉，回来很兴奋告诉zyyyyy，zyyyyy觉得是对的，改了一下A了。所以说上厕所还是很关键的。后来zyyyyy就决定xjb搞G，直接预处理以下就过了。这时看到好多人E拿了90分估计是T了，F也有若干的过了，LM各过了一个，于是我建议zyyyyy线段树搞一下E水个90，然后我们研究下FLM，zyyyyy交了一下E发现90分不错，但是是没有错误提示的RE，赛后告诉我们90分就算A了。这时候我都在推L，首先floyd是肯定的，然后我觉得就是一个01背包，不过我以为k是定值（实际上人家是k_i），所以状态转移推错了。然后我就建议zyyyyy搞一搞F，用不等式缩小一下范围，zyyyyy上了个二分的优化居然搞出来60分，K暴力一波40分。然后搞M大模拟，zyyyyy用pq实现了一波，但是样例没过，于是换sort水了40分，后来觉得应该是平衡树，于是上map红黑树，卧槽这次只有30分了，于是放弃。后来发现其实一开始的思路是对的，只是在分蚯蚓的时候加上(i-1)q就行了。 感受 晚上吃了北京烤鸭，在那边9+1玩了狼人杀，我当了两次预言家三次警长。感觉有些人玩的挺好的，有些人是新手所以有不少漏洞可以钻。第一局大家都太水了。第二局我是预言家和警长，第一轮测了zyyyyy狼，发言的时候我先评价了别人的发言点了一下我怀疑的几个人然后归票zyyyyy，虽然我之前说了我已经我归票的人我认为狼面是最大的，不过大家显然不太适应我的套路于是把我投死了（其实我直接跳预言家得了），于是我把警徽撕了，到最后sxm的猎人被杀了，但是她忘了带人了。最后剩zyyyyy一条狼，不过最后zzzyy的解药可能因为上帝hj没提到吧没有用在自己身上所以神都死光了，所以狼居然赢了。第三局sxm上帝，我是平民，然后zzzyy（平民）选了警长，不过他第一轮就被杀了，然后他点了三个人觉得是狼（无敌了全中）就把警徽给我了（卧槽为啥这么信任我）。发言阶段wdf没说话，zjt附和zyyyyy，于是我归票wdf，只有zqh投了zjt。第二轮平安夜，hj表示很奇怪因为她是女巫然后她觉得她没救sxm，然后事情就很明显了，我甚至有点怀疑我上局杀错了wdf，因为大家毫不犹豫就投了wdf（后来发现是狼放弃铁狼了）。不过zys说怀疑zzzyy是狼，不过我觉得他要是狼完全可以把警徽给狼队友。因此我归票zjt，这时候预言家还不跳，zqh我觉得又不是预言家，不过这时候女巫和未跳的猎人（zyyyyy），所以我有点担心是不是zzzyy预言家强行装平民。第三天天黑了然后女巫毒死了最后一头狼，游戏结束。 OJ交题各种等，气球发不全，没打印服务只好强行手机调试。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>现场赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCPC2016宁波总决赛小记]]></title>
    <url>%2F2016%2F11%2F28%2FCCPC2016%E6%80%BB%E5%86%B3%E8%B5%9B%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[CCPC2016宁波总决赛小结，唉dalao太多了，这场就是去膜的。 正式赛赛题Google出题一般是一头一尾水题，就像热身赛喜欢出GCJ或者招聘笔试题一样，首先zzzyy从头开始切，我从尾巴开始切，zyyyyy调配置。我看最后的L的题目夏令时便觉得能做（之前有人在群里发白皮黄点的气球觉得这条是金牌题），简单推了下就把模板给了zyyyyy。这时候zzzyy也发现了A的规律，之前WA了一片的A后来又重测过了许多，于是先交A1Y，然后zyyyyy慢慢敲L，我切J题，讲的就是icpc出线调参的事情，就是暴力枚举一下Y。过了L之后zyyyyy敲J，不过他犯了两个低级错误，所以到了11点才写完，这时我们3Y，已经在铜末了。对面的tju一队还不如我们，后面的河南大学软件学院的老朋友（他们合肥站在我们对面）还是1个气球（话说他们热身赛第一条拿了一血），他们对面的q神已经5Y了。在zyyyyy敲J的时候我在看B，zzzyy在看H。我想了想B觉得只有洗衣机的情况那就是贪心最早结束的方案，现在再加了一个烘干机，应该还是宜早不宜迟，因为衣服尽早洗完可以再等。所以我觉得就使用一个pq来维护洗每件衣物时每个洗衣机/烘干机的结束时间选最早的就行了。zyyyyy觉得这个想法也是可以的，但是他用了一个比较复杂的线段树来实现。这时候我和zzzyy看H题，之前zyyyyy觉得是网络流，但仔细看了之后觉得这个是互斥的，所以用不了网络流，应该是个dp，我推了一会儿觉得有点问题，如果取dp值为方案数的话实际上可以有很多个最优的选择，因此具体选哪个还需要继续搜索。而zzzyy那边的搜索思路他觉得应该会超时。后来马上要封榜了我们还是卡BH，然后我就建议zyyyyy强行刚一波H，然后我和zzzyy再想点B的样例。zyyyyy不负众望在还有20分钟的时候用状压dp过了，复杂度1e10也过了。与此同时zzzyy和我想了很多B的样例结果都是可行的，于是我们觉得可能实现上有问题。比赛结束后我们问了对面天津大学的一队，结果他们用了一个奇妙的二分答案过的，对于我们的想法他们说是过不了2 2 2 5 3 3 5这样的样例的。不过其实官方解法是把烘干机当做洗衣机的逆过程，维护两个pq最后匹配一下。很多dalao陪伴我们死在这条题上，最后I题过的居然比B要多了。 感受 宁波真冷，风太大，比赛组委会居然发的长袖t恤，比赛的时候张老师给我们买了几个暖宝宝贴在肚子上和腿上 我们周五下午去了天一阁、月湖公园和南塘老街，感觉那天宁波烟雨蒙蒙特别漂亮，晚上在南塘老街吃了奉化牛肉面超级大块的牛肉感觉很好吃。 周六上午我们去了宁波博物馆，在宁波历史那边有个大叔讲的特别认真，带我们从河姆渡一直讲到清朝。 学校食堂晚上居然是自助餐，吃的撑死了，最后拿喝饮料的杯子装了三四个鸡翅回去吃 大佬太多了，开幕式和讲题看到了xiaodao，正式赛结束我们还要到了q神的签名。第一名clj队比赛结束后还在搞K题，难怪他们那么强 回南京的路上我们在高铁上和张老师朱老师一起玩你画我猜，然后发现zzzyy居然不知道费列罗（好可怜） 热身赛的时候大家发挥聪明才智测评测机的T，为了避免O2的优化，最后还用了random，后来发现评测机跑的比本地快多了 周五晚上张老师和朱老师请我们吃了12个鸡翅两块华夫饼和饮料，然后拉我们谈了超级久，从ACM队谈到学院的创训。 其实我校ACM起步很晚的，是从13年参加的邀请赛，然后打到南京赛区的名额开始的，据说那场比赛GB就和中国的组委会闹翻了（难怪2014年开始取消中国组委会，2015搞出CCPC）。其实学长不仅搞ACM，而且英特尔杯获得某评委的青睐，然后虽然做得有点离题但还是给了二等奖，说到要注册几个CF或之类账号看看训练情况，要给ACM的队员排名。然后水上明珠BBS居然是张老师上学的时候的一个土豪大神（还是我老乡）同学（后来他创业了）搞出来的，之前还写了好多小游戏，结果有人痴迷于游戏把成绩弄掉了。话说那时候还没有勤学楼，大家只有做课设的时候才有电脑，而且大四的时候有特别多的大课，比如操作系统软件工程啥的（卧槽大三都学啥啊）。大家对创训最后放弃的人进行了吐槽，然后说了说关于专利和写文档的事情。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>CCPC</tag>
        <tag>现场赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[组合博弈]]></title>
    <url>%2F2016%2F11%2F23%2F%E7%BB%84%E5%90%88%E5%8D%9A%E5%BC%88%2F</url>
    <content type="text"><![CDATA[总结一下网上教程关于组合博弈的部分要点 Nim 博弈Nim游戏的典型形式是假设有N堆石子数量是 $ a_1, a_2 .. a_n $，两人轮流从某一堆取若干个（不能一个不取），最后不能取的人算失败。为了解决这个问题，先定义必败态，也就是先手必败，这里先手必败指的不是游戏开始时的先后手，而是指的当前局面的先后手。必败态的所有的下一步都是非必败态，非必败态存在某个下一步是必败态。因此假设A此时拿到一个必败态，那么无论他如何移动，都会留给B一个非必败态；而B的非必败态经过移动可以留给A一个必败态。可以发现，如果每一堆的石子数的和异或起来为0的话，当前状态是必败态，即 $ a_1 \ xor \ a_2 \ xor \ .. \ xor \ a_n = 0 $ 是必败态（Bouton’s Theorem）。这是因为： 不能取时每一堆石子都是0，因此异或的结果还是0，因此是必败态 假设此时A是一个必败态，即 $ a_1 \ xor \ a_2 \ xor \ .. \ xor \ a_n = 0 $，假设存在$ a_i $使得取完之后的 $ a’_i $ 也满足异或结果为0。由于异或具有消去律，因此$ a’_i = a_i $ 假设此时A是一个非必败态，即 $ a_1 \ xor \ a_2 \ xor \ .. \ xor \ a_n = k \neq 0 $，总能找到一个 $ a_i $ 使得 $ a_i \ xor \ k \lt a_i $，这样的构造只需要 $ a_i $ 把 $k$ 最高位的1异或掉就行了。这样把 $ a_i $ 替换成 $ a_i \ xor \ k $ 就能得到一个新的异或为0的必败态给对方。 ICG和SG函数由此可以引出ICG和SG函数，刚才的必败态对应于SG函数中的P-position，P是Previous，指的是刚取完石子的那人赢，因为只有两个人玩，所以就是先手输。对应的状态是N-position，N指的是Next。ICG（Impartial Combinatorial Games）指的是公平组合游戏，满足下面的性质： 两名选手轮流行动，每一次行动可以在有限合法操作集合$ f $中选择一个，若轮到某位选手时，该选手的合法操作集合为空，则这名选手判负 游戏的任何一种可能的局面（position），合法操作集合只取决于这个局面本身；局面的改变称为“移动”（move） 任何一个ICG都可以通过把每个局面看成一个顶点，对每个局面和它的子局面连一条有向边来抽象成一个有向无环图。如果 $\langle x, y \rangle \in E$，表示从x局面可以到达y局面。 首先定义mex（minimal excludant）运算，这是施加于一个集合的运算，表示最小的不属于这个集合的非负整数。例如 $ mex \lbrace 0, 1, 2, 4 \rbrace = 3 $，$ mex \lbrace \rbrace = 0 $。对于ICG对应的DAG中的每一个顶点（局面），定义SG函数 $ sg(x) = mex \lbrace sg(y) \mid \langle x, y \rangle \in E \rbrace $。当 $ sg(x) = k $ 时表示 $ \forall i \ , 0 \le i \lt k, \ \exists \ \langle x, y \rangle \in E, \ sg(y) = i \ $ ，也就是说，$k = sg(x)$ 是最小的不属于 $sg(y)$的值，其中$y$是$x$的所有后继局面。下面介绍这个值的具体意义。事实上SG函数拥有和Nim游戏同样的性质，$ sg(x) = 0 $ 对应着必败态，$ sg(x) \neq 0 $ 对应着非必败态，表示通过可选操作 $ k = sg(x) $ 个可以到达一个P状态。以一个较为简单的取石子问题为例，假设有1堆n个的石子，每次只能取1、3、4个石子，先取完石子的人胜利，求各个状态的SG值。现在定义SG函数$sg(i)$为状态i下的石子数，显然有$sg(0) = 0$，设操作$f=[1,3,4]$表示可以取1、3、4个石子。当$x=1$时，可以取走$1$个石子（不能不取），$y = \lbrace 0 \rbrace$，$sg(1) = mex \lbrace sg(1) \rbrace = 1$当$x=2$时，可以取走$1$个石子，$y = \lbrace 1 \rbrace$，$sg(2) = mex \lbrace sg(2) \rbrace = 0$当$x=3$时，可以取走$\lbrace 1, 3 \rbrace $个石子，$y = \lbrace 0, 2 \rbrace$，$sg(3) = mex \lbrace sg(0), sg(2) \rbrace = 1$当$x=4$时，可以取走$\lbrace 1, 3, 4 \rbrace $个石子，$y = \lbrace 0, 1, 3 \rbrace$，$sg(4) = mex \lbrace sg(0), sg(1), sg(3) \rbrace = 2$当$x=5$时，可以取走$\lbrace 1, 3, 4 \rbrace $个石子，$y = \lbrace 1, 2, 4 \rbrace$，$sg(5) = mex \lbrace sg(1), sg(2), sg(4) \rbrace = 3$现在假设A面临5个石子的局面，他选择可选操作“取3个”，将剩2个石子的局面留给B，B发现$sg(2) = 0$，是个必败态，无论他如何取都将不敌A。对于刚才的取石子游戏，可以想象成在A和B一个有向图上从开始的点轮流沿有向边移动棋子，直到到达一个出度为0的点。而SG函数的意义表示一堆石子的个数。而现在有n堆石子，每一堆石子都对应一个SG函数，这个游戏就可以分成n个子游戏。对于这样的情况，有Sprague-Grundy Theorem给出该游戏的和的SG函数值是它的所有子游戏的SG函数值的异或，即 $ sg(G) = sg(G_1) \ xor \ sg(G_2) \ xor \ .. xor \ sg(G_n) $。 例题 POJ 2505题意设p初始值为1，A和B轮流对p乘上一个2和9之间的数，谁先大于等于n谁就获胜]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>博弈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git rebase 用法]]></title>
    <url>%2F2016%2F11%2F19%2Fgit-rebase%2F</url>
    <content type="text"><![CDATA[随着工程量的提升.git文件夹会变得越来越大。特别是我们只在master一个分支上进行提交，由于里面有很多没用的中间提交，所以希望能够将这些提交删除或者合并，这就用到git rebase这个命令。有的时候我们有若干个branch，对一个branch进行rebase会影响到其他的branch么？这里做了个实验 rebase对branch的影响新建git仓库1234567891011git initecho "1" &gt; test.txtgit add .git commit -m"1"echo "2" &gt; test.txtgit add .git commit -m"2"echo "3" &gt; test.txtgit add .git commit -m"3"git branch 0.1 查看此时log123456789101112131415161718$ git logcommit d299f0788909111c0a9d13dfb756f901092c85ceAuthor: unknown &lt;calvinneo1995@gmail.com&gt;Date: Sat Nov 19 18:12:41 2016 +0800 3commit b601f3c9e5b4b814eefb5889d5110076ec234304Author: unknown &lt;calvinneo1995@gmail.com&gt;Date: Sat Nov 19 18:12:27 2016 +0800 2commit b6a00666d366a77ab03bac5f79b035a705a9d64cAuthor: unknown &lt;calvinneo1995@gmail.com&gt;Date: Sat Nov 19 18:12:07 2016 +0800 1 rebase master将master分支的3号commit合并到2号commit上1234$ git rebase -i --root[detached HEAD 00d6d06] 2 1 file changed, 1 insertion(+), 1 deletion(-)Successfully rebased and updated refs/heads/master. 这里选项-i表示使用交互式的修改方法，你可以使用vim等编辑器来进行修改。选项--root表示从头开始，如果只想对最近的n个提交进行修改，可以使用HEAD~nrebase命令如果不跟分支，默认为当前分支。再次查看master的git log1234567891011121314$ git logcommit 00d6d06ef697290483cbab5f5e6324491abb5f85Author: unknown &lt;calvinneo1995@gmail.com&gt;Date: Sat Nov 19 18:12:27 2016 +0800 2 3commit 55cb8ae13c8cef61c3bf7b89ce3001eac29de630Author: unknown &lt;calvinneo1995@gmail.com&gt;Date: Sat Nov 19 18:12:07 2016 +0800 1 发现已经成功合并。这里额外说明一下，提交2和提交3的备注信息”2”和”3”被合并到了一起作为一个新提交，这是由于squash选项造成的，如果我们选择fixup选项，那么提交2和提交3会直接消失12345$ git logAuthor: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Fri Sep 22 19:01:48 2017 +0800 1 回到我们刚才squash得到的结果，查看0.1分支的git log12345678910111213141516171819$ git checkout 0.1$ git logcommit d299f0788909111c0a9d13dfb756f901092c85ceAuthor: unknown &lt;calvinneo1995@gmail.com&gt;Date: Sat Nov 19 18:12:41 2016 +0800 3commit b601f3c9e5b4b814eefb5889d5110076ec234304Author: unknown &lt;calvinneo1995@gmail.com&gt;Date: Sat Nov 19 18:12:27 2016 +0800 2commit b6a00666d366a77ab03bac5f79b035a705a9d64cAuthor: unknown &lt;calvinneo1995@gmail.com&gt;Date: Sat Nov 19 18:12:07 2016 +0800 1 发现并没有变化于是结论很显然，git rebase只会影响当前分支。rebase会导致git生成一系列全新的提交，但内容包括时间是保留的。 rebase对annotation tag的影响新建tag按照上面的步骤重新构建了一个git仓库，下面对提交2（a8ede39f9ff56c4a43ee89e80ba30c0aad8f2f26）打tag1$ git tag -a v0.1 a8ede3 切换到v0.1的tag12345678910111213$ git checkout v0.1Note: checking out 'v0.1'.You are in 'detached HEAD' state. You can look around, make experimentalchanges and commit them, and you can discard any commits you make in thisstate without impacting any branches by performing another checkout.If you want to create a new branch to retain commits you create, you maydo so (now or later) by using -b with the checkout command again. Example: git checkout -b new_branch_nameHEAD is now at a8ede39... 2 注意到这里说明现在在一个’detached HEAD’ state，这是因为tag 相当于是一个快照，是不能更改它的代码的，如果要在 tag 代码的基础上做修改，新建一个分支。下面看一下这个detached HEAD的提交历史123456789101112$ git logcommit ed4c38d8247a454b49a97962006ccaa659cae32cAuthor: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Sun Jan 22 14:49:32 2017 +0800 2commit 2b84833dd18c6802893029c7c0dfaa781ec20aa8Author: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Sun Jan 22 14:49:32 2017 +0800 1 发现提交1还在下面回到master分支，并将master分支压缩成一个分支1234$ git rebase -i --rootpick fea1e3c 1s a8ede39 2s 9b9a18c 3 再次查看log123456789101112$ git logcommit a8ede39f9ff56c4a43ee89e80ba30c0aad8f2f26Author: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Sun Jan 22 14:49:32 2017 +0800 2commit fea1e3cf0a1939544ae01f1160d2c87c2960e661Author: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Sun Jan 22 14:49:32 2017 +0800 1 发现tag的log并没有改变 git rebase的合并冲突解决这常发生在试图将一个分支整体与另一个分支合并的情况下首先使用git status查看冲突的文件，解决冲突后git add .，然后git rebase --continue在任何时候如果发现之前的冲突解决错误，可以通过git rebase --abort回滚到rebase前的状态 其他的修改提交的方法amendgit commit --amend指令能够修改最近的一次提交。不过commit id会变amend前123456$ git logcommit 544c674ff6ad80b87d871a1db1fe01a37536804cAuthor: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Fri Sep 22 19:01:48 2017 +0800 1 amend后123456$ git logcommit 32158167b057faacc5c91c1e63451e28612c13f6Author: Calvin Neo &lt;calvinneo1995@gmail.com&gt;Date: Fri Sep 22 19:01:48 2017 +0800 1 不过如果在amend之前将原commit push到远程仓库了的话，那会引起冲突，最省事的办法就是很不优雅地git push origin --force。对于gitlab这样的代码仓库，可能还要将Branch Protect去掉才能强行push。 hard reset]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Floyd求最小环]]></title>
    <url>%2F2016%2F11%2F17%2FFloyd%E6%B1%82%E6%9C%80%E5%B0%8F%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[使用Floyd算法求最小环 FloydFloyd算法原理是对于点k = [1..n]，尝试用它来松弛边(u, v)。在实现时维护 $ dist[n][n] $ 数组，用来表示i和j之间可以通过$ 1..k $的最短路径。因此算法复杂度为 $ O(n^3) $ ，能计算任意两点最短路径，能够处理负边。Floyd计算最小环时，考虑k的两个邻居i和j，他们三者可以构成一个至少有三条边的环（其中实际不存在的边边权为无穷大）。事实上查看算法可以发现计算最小环的操作位于Floyd算法k循环松弛操作的上方，也就是在用k松弛i和j前先计算经过k的最小环，这么做是为了防止重复计算经过同一点的最小环。 注意点 一开始定义const int inf的时候不能设太大，不然容易wrap掉 遍历k要放在最外层]]></content>
      <tags>
        <tag>ACM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HUSTOJ使用]]></title>
    <url>%2F2016%2F11%2F16%2FHUSTOJ%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[最近给 http://acm.hhu.edu.cn/JudgeOnline/ 出了一点题，总结一下这个OJ使用的一些注意点 添加题目之后题目显示的是reserved状态，这时候普通用户并不能看到这道题目 在加题界面添加的sample input和sample output都会被添加到testdata里面，因此要注意准确性 testdata里面可以存放多个.in和.out文件 此外我写了一些辅助工具一个自动重复测试数据的工具一个自动根据标程生成.out文件并计算运算时间的工具注意使用VS的Debug模式编译可能时间相比实际运行时间长很多，这是因为Debug模式自带很多检查]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>OnlineJudge</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[segmentfault 双11光棍节程序猿闯关秀]]></title>
    <url>%2F2016%2F11%2F14%2Fsegmentfault1111%2F</url>
    <content type="text"><![CDATA[双十一segmentfault推出一个双十一解密游戏，不过当时我在前往北京的火车上，于是今天从北京跪回来玩了一下，作为玩过arthurluk的人感觉还是没有压力的。 第一关https://1111.segmentfault.com/全选看到连接 第二关https://1111.segmentfault.com/?k=05f5a5b740dbba332ea21005b7214c44查看源代码发现密码 第三关https://1111.segmentfault.com/?k=c0781e0fb05d15fa6ecb71b324805f9f首先发现这个密钥都很有规律，应该是个md5，于是去www.cmd5.com这个坑比网站上试了，没用，又瞎搞了几个盐也没用，代码里面只有一个amazon的js，应该不是提示。于是猜测是不是在http响应头里面，一看果然是的，密码是The-Key-Is字段。 第四关https://1111.segmentfault.com/?k=a87ff679a2f3e71d9181a67b7542122c这一关就是md5了，响应头里面给了个X-Hit，以为是盐，用坑比网站解密发现是4。然后下一关网址就是5加密，但是怎么都不对，后来发现就是个裸的md5，没有盐，X-hit好像是用来看缓存是否命中的。 第五关https://1111.segmentfault.com/?k=e4da3b7fbbce2345d7772b0674a318d5给了个二维码，扫了之后发现是这东西。根据我玩arthurluk的经验，我把https://1111.segmentfault.com/5.png 和404的那个svg图改成了bmp、jpg、png、svg、php、txt等格式发现都没有用。于是这一关我投降了，查看题解发现要把这个图片下载下来，作为txt打开。可以看到下面的密码。 第六关https://1111.segmentfault.com/?k=bdbf46a337ac08e6b4677c2826519542题目是：f4de502e58723e6252e8856d4dc8fc3b，只能告诉你这么多。首先想到的是这可能是寻找一个二级页面，然后提示在二级页面里面。于是不管三七二十一先去坑比网站上查一下，结果查到了，要付费购买。那去不坑比的网站查一下，http://www.dmd5.com/ 查到了，是2323k14jm，显然这不对。后来发现数字可能是多个char拼起来的，但是考虑下并不是ascii或者unicode。不会了，google下，发现twitter直接给答案，这不怪我咯。 第七关https://1111.segmentfault.com/?k=1573402aa6086d9ce42cfd5991027022好吧，原来是测翻墙技术的。搞了半天，直接把这串填进去就行了 第八关https://1111.segmentfault.com/?k=110a21f15af64b25163fe67799abecda给你一个表单，input填好密码，但是没有submit按钮。查看源码发现123&lt;form method="GET"&gt;&lt;input type="text" name="k" value="cda7ea6afa6ba887e7b8695b9ebac61d"&gt;&lt;/form&gt; 卧槽这method=&quot;GET&quot;欲盖弥彰啊，改成post，过了 第九关https://1111.segmentfault.com/?k=110a21f15af64b25163fe67799abecda （注意带上post的数据）貌似是ascii构成的base64，用python硬搞一波，转成一堆乱码，但是问题是下划线不知道转成什么。仔细看一下觉得也不像π、e之类的常数，于是决定假设_始终代表0和1中得到某一个值。用0试，出现奇妙字符，用1试，是合法的base64。用工具转成文本，得到一堆乱码，于是可能是图片。试了一试也不行。那直接MD5也不行。不会，后来发现原来是保存成文件。我写了个代码在这里，特别注意的是windows有个神坑，当按照文件读写的时候\n(0x10)是默认变成\r\n(0x1310)的，因此压缩包会无法解压，如下图所示（使用Hex Compare比较）：因此应当使用wb而不是w来写文件。 第十关（通关）从解压得到的图片上可以看到通关页面：https://1111.segmentfault.com/?k=e4a4a96a69a1b2b530b3bec6734cdf52]]></content>
      <tags>
        <tag>游戏</tag>
        <tag>双11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ACM/ICPC 2016 北京站小记]]></title>
    <url>%2F2016%2F11%2F14%2FICPC2016%E5%8C%97%E4%BA%AC%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[这周六日在北京大学参加了2016年的最后一场ICPC区域赛。我们周五晚上乘坐T66列车从南京站出发，与此同时，平行世界里面同一时间参加ICPC青岛赛区的两队dalao们已经在青岛的海边玩了一个下午了。 赛题首先我先切了D题，看到一半清恒说F水题能做，于是我跳到F题开始敲，调试居然不过样例，原来是operator&lt;比较的时候用了两个this。过了之后清恒给我讲他们D题的思路，认为最大减最小就行了，我觉得他们题目理解错了，这时候我已经有了想法，然后赶快敲完过了。过了队友说K没搞懂什么意思，于是我去切K。接下来我们KE并行搞，E题通过的多，但是K题的通过率达到了惊人的100%。K题意思是问从1到N, N &le; 10100里面有多少个数等于从1到N所有数中数字”1”的个数之和。题目给了样例说明前100000000000个数里面有83个这样的数，其中最大的是11111111110。这道题我一开始觉得是dp，后来发现数字太大了，不太好做，便放弃了。队友们接过K，觉得先打表。过了一阵子他们觉得10100里面也只有83个数，交了一发发现翻了低级错误wa了，改了一阵子过了。这时候我在做E。E题是有个长度为5的由&#39;0&#39;-&#39;9&#39;组成的字符串，可以对这五个数字中任意一个进行乘2（总共3次）、加1（总共2次），和交换（不限次数），问组成”12345”需要的最少操作数，若不能就输出-1。我的想法是打表求出把&#39;0&#39;-&#39;9&#39;变成&#39;1&#39;-&#39;5&#39;需要的最少步数，然后再加上交换的次数。然后把五个数转成五个数的最小步数时候遇到了问题，这并不是一个贪心问题，我打算用bfs硬搞，算了算复杂度可能不行，于是尝试用图论算法（KM匹配）浪费了不少时间，最后时间不够了上bfs然后WA了，这时候比赛也结束了。封榜前我们是106名，想着今年据说Cu线改成605%了，应该能拿个Cu。不过后来发现还是45%的线，于是打铁滚粗。 感受 前面的队名叫latte，最后果然两题拿铁滚粗，这给我们启示比赛的时候不要喝拿铁（然而摩卡巧克力太腻，卡布奇诺有点苦）。 电子科技大学的一队拿到了AK两条的fb，于是怒拿冠军出线。这又一次给我们启示风水和气运很重要。 pku发了一人4张的20元卡（实际上除掉手续费只有16元了）。表示很奇怪为什么这卡要搞三张，难道是一张卡上只有4bit么？后来拿到发现卡上有若干洞，不禁想到多年前看到的matrix67的这篇博文，有空算一算 感觉北大好牛逼，报到的时候送了每人一个纪念U盘和水杯，开幕式和颁奖poucher和GB都出现了（GB口语好差啊），比赛午餐是开封菜，一对辣翅一个汉堡，每人一个大橘子。北大食堂只开放了艺园和农园，据说是比较差的食堂，但是依然是便宜可口。我们比赛的邱德拔体育馆整个还是北京奥运会的装扮，比赛过程和结束主办方一直强调千万不要放飞气球啦~我们很难搞啦。 北京用的hihocoder做的judge，参赛时果然没给我们CB，尿壶也不好用，但是给了个eclipse，我觉得还挺好用的。 晚上在中关村吃了东来顺火锅，因为之前吃过北京火锅的，并不喜欢那种芝麻酱，但是在北京吃到正宗的觉得还是挺好的，关键是不腻也不算太甜。本来准备去全聚德买个烤鸭寄给我姐的，但是实在没时间了 卧槽宾馆好远啊，住在人大那边的如家，而且居然是个家庭房，开暖气好热啊。早上要坐几站地铁才能到。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>现场赛</tag>
        <tag>ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDU 5074 Hatsune Miku]]></title>
    <url>%2F2016%2F11%2F09%2FHDU5074%2F</url>
    <content type="text"><![CDATA[HDU 5074 Hatsune Miku 2014 ACM/ICPC AnShan 题意使用$m$种音符组成一个长为$n$的歌曲，定义两个相邻音符$(a, b)$的美丽度是$score[a][b]$，而一个长为$n$的歌曲$a[1..n]$的美丽度是其所有的相邻音符$ (a_i, a_{i+1}) $（共有$n - 1$个）美丽度的和。现在已知在歌曲的某些位置的音符已经被钦定了，问能够达到的最大的美丽度是多少？ 思路代码常规的暴力法就是对每一位枚举并计算美丽度，复杂度是\( m^n \)。但实际上可以dp来做。定义dp[i][j]是第i个音符选j时前i个序列的最大美丽度。然后在dp的时候考虑i - 1和i分别是-1和正数的四种情况： 当i - 1位置和i位置全部已知的时候，dp[i][j]是个定值。 当i - 1位置未知、i位置已知为j的时候，dp[i][j]就是在i - 1位置枚举所有的值取大的更新，继续维护dp数组的性质。 i位置未知时候，问题实际上分解为m个小问题，令j = [1..m]，然后按照2的方法计算。 有一个坑就是最后一个数可能不是-1，所以输出答案的时候先判断是-1了，再比较输出最大的dp[n][j]。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拓扑排序]]></title>
    <url>%2F2016%2F11%2F07%2F%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[在图论中，由一个有向无环图的顶点组成的序列，当且仅当满足下列条件时，称为该图的一个拓扑排序（英语：Topological sorting）。 每个顶点出现且只出现一次； 若A在序列中排在B的前面，则在图中不存在从B到A的路径。也可以定义为：拓扑排序是对有向无环图的顶点的一种排序，其中如果图中从A到B有边（注意A到B有边那么B到A必然没有边），那么在排序中A出现在B的前面。注意拓扑排序并不一定存在，例如当图中存在环时。 拓扑排序的一种实现方式就是对每个点维护它的入度。我们假设图已经建好，如果从A到B有边，那么我们要把A放到B的前面，容易发现一个点的入度越高，那么它的前置条件也就越多。每次选取任意一个入度为0的点，然后删掉它的所有出边，更新入度。容易看拓扑排序的结果是不固定的，因为可能同时存在若干个点入度都为0，因此在拓扑排序的题型中一般还会有其他的限制条件。这样一般是从大到小或从小到大取，并且采用小顶堆或者大顶堆来形成最终的顺序。 经典题目拓扑排序常被用来解决下面的问题：给定一些课程，每个课程都有前置课程，只有完成了前置课程才可以开始当前课程的学习；我们的目标是选择出一组课程，这组课程必须确保按顺序学习时，能全部被完成。 HDU 5695 Gym Class题意思路代码同上面的，因为前面的要尽可能大，所以使用大顶堆。toposort里面遍历0入度的点应当从大到小。这条题目注意最后的方案要lld输出。 HDU 4857 逃生题意现在需要对[1..n]排序，要求编号小的一定在编号大的前面，但是此外还有若干形如(a, b)的约束条件，要求a必须在b前面。现在输出排序方案（保证一定有解）。 正确的思路代码需要反向拓扑（反向建边），维护一个大顶堆，然后反向输出 错误的思路代码读取(a, b)，对(a, b)建立有向边（正向拓扑），维护小顶堆，正序输出。 错误原因在阅读了这个帖子之后，明白了。考虑下面的例子： 1 3 1 3 1 正确的输出应当是 3 1 2 但是我的程序输出了 2 3 1 按照题意，3应该在1前面，1应该在2前面。但我的实现保证了按字典序排列，2的字典序较小，所以排在3前面，但是这就不满足编号小的在编号大的前面这个限制条件了。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>图论</tag>
        <tag>拓扑排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[岩土工程实习]]></title>
    <url>%2F2016%2F11%2F07%2F%E5%B2%A9%E5%9C%9F%E5%B7%A5%E7%A8%8B%E5%AE%9E%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[这是去年岩土工程实习的实习报告。这是学习岩土工程这一个土木工程学科下面的细分方向之后的第一次实习，也是我们进入土木院后的第一次实习，不同于水工等学科实习得跑到浙江新安江的水坝那边去，南京本身就提供给我们土木工程很多实习的场所，例如最近一直在建的地铁，过江隧道，处处加盖的高楼，以及宁镇山脉的边坡治理等等。这样带来的好处是，有很多地方，我们在之前的例如工程地质实习中已经参观过了，因此有了一定的基础知识，再来理解这一部分就减少了很多难度。此外，对于作为在江苏成长，在南京生活了两年有余的我来说，也多了一次接触认识家乡的机会。从总体的实习安排中可以看出我们这次的实习主要分为三个方面，第一天我们主要感受了两个地基处理的样例，第二天我们参观了一个边坡治理的样例，第三天我们参观了隧道的施工。它们都分别代表着岩土工程的几个不同方面的应用。第一天我们参观了位于中山东路与龙蟠中路交界处东北角的中山东路301项目和位于卡子门大街与汇景北路交界处东北角的复地宴南都项目。这两个都是在做地基处理，两者都是深基础，其中中山东路的项目尚未完成底板，复地宴南都已经完成了。进入中山东路项目的工地，首先看到的便是两个巨大的基坑，这两个基坑分别由钻孔灌注桩拼成的桩墙（A）和地下连续墙（B）围住，起到了挡水挡土的作用。听老师的讲解，钻孔灌注桩和地下连续墙虽然都能够起到这个目的，但是它们的成本和效果差别很大。其中钻孔灌注桩成本小，但是由于施工的原因其表面会有坑坑洼洼的状况，而且钻孔灌注桩只有上部的2/3有钢筋，所以质量相对于地下连续墙差，而地下连续墙是先挖一道“沟”，再往沟里面布筋，灌浆处理而来，成本比较高，在中山东路的项目中，只有靠近地铁二号线的那一侧采用了地下连续墙进行挡土防倒灌处理。接下来在钻孔灌注桩和地下连续墙内部浇筑一些纵横梁起到加固作用，当然，等到底板做好之后，这些纵横梁就失去了作用，到时候可以选择作为地下停车场的顶板或者直接敲掉，这里的项目是选择直接敲掉。当然其实钻孔灌注桩在做好底板之后也可以敲掉，转而有建筑的外墙来承担挡土的功能。由于是一个深基础，地下有好几层，一般采用的是先打好桩，然后做好第一层的纵横梁，接着往下挖出第二层并造好第二层的纵横梁，敲掉露出来的桩，使用钢结构的柱子临时顶上（由于纵横梁最后都要拆掉的，所以没必要再造个柱子出来）。然后再往下面挖第三层。值得注意的是我们发现纵横梁的接近底部处按照一定间距均匀排布的很多细的塑料管，大家都不明白这些塑料管是干什么用的，后来咨询了工地方面才了解到，在浇筑混凝土的时候往往会发生涨模现象，这个时候就要用对螺栓将模板固定好，为了能够重复利用这些螺栓，就用塑料管将它们包起来，这样可以方便地取出，实际上这些小的实用技巧存在于工地的方方面面，往往是书本上面难以学习到的。我们接着有下到工地下面去观察了一下钻孔灌注桩，如同老师所讲的那样，这种桩质量确实不好，往往经常有缩颈（桩的一段的横截面积突然变小）等现象，而且有的装孔灌注桩内侧还有渗水的现象。此外我还发现为了防止外侧水位过高，在桩中间也留了一些水管，方便外部的地下水流出。图中的弯起钢筋的作用是辅助浇筑纵横梁。在工地上，这些“脚手架“一样的建筑往往占了很大的比重。，虽然它们最终都要拆掉，但是这看似浪费成本的办法实际上往往是最合理的。下午我们又参观了位于卡子门附近的复地宴南都项目，卡子门这边的地形浅一点，据说这边已经能够挖到基岩了，而上午的中山东路那边软土层比较厚，往往达几十米，打桩也只能打摩擦桩。这边已经做好了底板和承台（承台是桩与柱或墩联系部分。承台把几根，甚至十几根桩联系在一起形成桩基础），很多台挖掘机在不停的挖土方，监理们在走来走去指挥农民工做事。总体上讲，地基处理的成本往往占到了总成本的40-50%有了一个可靠的地基，才能保证建筑物的安全。这两个项目都是采用的箱形基础，箱型基础是由钢筋混凝土的底板、顶板、侧墙及一定数量的内隔墙构成封闭的箱体。这种基础整体性和刚度都好，适用于作软弱地基上的面积较小，平面形状简单，荷载较大或上部结构分布不均的高层重型建筑物的基础及对沉降有严格要求的设备基础或特殊构筑物，但混凝土及钢材用量较多，造价也较高。但在一定条件下采用，如能充分利用地下部分，那么在技术上、经济效益上也是较好的。对应的还有沉井，又名开口沉箱，对横断面为圆形、方形或矩形，顶底都敞开的井筒，在井筒内挖土，并靠井筒自重下沉后接长井筒，继续挖土和浇筑混凝土建成的基础工程。第二天我们跟车前往南京麒麟科创园青龙山沿线矿山地质环境治理示范工程—永平治理区工程。这边位于宁镇山脉处，我们上学期的工程地质实习就在这里附近的青龙山，阳山碑材附近实习过。在上学期的工程地质实习中我们了解到，青龙山属扬子地层区下扬子分区宁镇地层小区，地层发育齐全，有从最老的志留系至第四系连续完整的分布。构造上地处下扬子台褶带宁镇褶皱束的西南缘，西临南京坳陷，南接宁芜火山岩盆地，构造线总体呈北东向展布，断裂和褶皱均比较发育。区域上岩浆活动比较频繁，但以燕山期为主，具多旋回、多阶段、多形式的特点。我们今天去观摩的，是其中的永平治理区。根据区内地貌成因和形态类型划分，这里位于青龙山山系西南端，地处山体西坡。山体总体呈北东走向，地形纵向切割较深，山脊狭窄，两侧山体坡面较平直，自然坡度一般为20-25°；横向切割较小，冲沟多呈宽缓的“U字型”。周边山体林型为落叶阔叶林和常绿阔叶混交林，植被发育良好。麒麟科创园青龙山沿线矿山地质环境治理示范工程位于主城区东侧的麒麟科创园和东郊风景区范围内，北接仙林大学城、南临江宁大学城。该区域内，早年矿山开采形成的裸露边坡和矿山废弃地，不仅破坏了区域自然景观，与周边绿荫成群的青山绿水极不协调，而且成为京沪高铁、沪宁高速公路、绕城高速公路的视觉污染源，同时矿山存在多处地质灾害隐患。其中永平治理区，就有着江苏罕见的高度的坡体（据说是江苏省最大的单体）。顺着小路上山，我们首先看到的是一个楔形体，这个还没有治理，可以看到楔形体下部到该山体底部有两三道非常粗的黄色痕迹，据老师讲解，这就是因为这两天下雨，流下来的水。此外在山体的两侧，散布着很多碎石砂砾，似乎是从楔形体出崩塌下来的。据老师讲解此处楔形体还没有治理，将来是要被直接挖掉的。边坡加固一般有三种方法，一种是加固，比如说采用预应力锚索，采用锚杆，或者抗滑桩，对于小规模的边坡，可以直接采用格栅内种植植物生态护坡的办法，一般还会配合上剪刀梁，从而防止塌土的现象；还有一种就是直接削坡。永平治理区工程综合利用了这两种方法，而且在很多地方都创造了江苏之最，比如，他们采用竖直向下打方桩（作为抗滑桩），因为方桩的防滑能力好。2.8*1.8米尺寸的方桩，我们并没有见到，但是看到它的箍筋（附照片）的时候还是吓了一跳，这种尺寸，我们很难将它们和箍筋联想起来。显然的，这种桩是很难打进去的，这边采用了人工挖的方法。此外，还有一种方法就是做一个平台，打孔插钢筋，然后往里面灌混凝土，就和地下连续墙差不多的样子。抗滑桩的理想深度（打到最深）大概50-60米左右，这里的抗滑桩大概在50-30米分了六个等级。此外还使用了锚索，锚索的长度大概在50-100多米之间，一根价格往往上万。稍后在项目工地上，我们又阅读了整个项目的工程图纸，可以看出，这是一个很大的项目，目前治理的是其中的一小部分。第三天我们参观了南京地铁四号线草场门站现场和南京纬三路施工项目部，顺路路过了已经建成的纬七路过江隧道和南京长江大桥。这两个都是隧道，但是仔细研究起来还是有很大的不同之处的。首先是草场门地铁站，这个地铁站位于北京西路和虎踞路交界处，周围有比较多的古建筑和高层建筑，此外城西干道草场门隧道下穿北京西路，因此，我们看到这里面大都采用的是地下连续墙，而且是最厚的那种，厚度达到1.2m。中间有很多横梁用来防止两侧墙的位移变形。站在工地的旁边往下看，第一个感觉就是高、深。整个地铁站分为三层，其中第一层到地面之间的水泥层占了大概一个层高。由于南京的软土环境，因此随着盾构机的推进，去加固周围的土层是很重要的。以南京为例，北京东路今年的十月份至十一月份之间就连续发生了五次塌陷。据专家称，北京东路九华山这段路地下是古秦淮河道的流沙层。古秦淮河由南向北纵贯市区，由武定门经大行宫、玄武湖菱洲和樱洲，横穿中央路、福建路，到狮子山东注入长江。古秦淮河河道非常宽，最宽处达1000多米，简直就是浩浩荡荡注水入江。1万多年前的北京东路沿线，是宽敞的河流。当古秦淮河被埋藏时，形成了厚厚的流沙层，这些流沙层中还有一定的水分。地铁挖到七八米深的地下，就会遇到古河道，只要出现裂缝，流沙中的水分流出来，流沙就会跟着水走，造成塌陷。虽然施工方已经调整了施工方案，对没有施工的路段地层进行加固，然后再进行盾构施工。但是即使施工前先对地层进行加固，但也无法完全避免塌陷，毕竟地下的地质构造太复杂了，其中可见地下水对岩土工程的影响之巨大。据工地人员介绍，目前盾构机已经掘进离草场门站两公里处，所以我们是看不到盾构机的，但是随着我们走下工地，到达最深的一层，我们看到了岛式的月台，已经两个车道。其中南侧的部分已经铺上了铁轨，甚至已经有轨道车在上面跑动，在月台的尾端，就是两个巨大的圆形隧道。我们走下月台，走到隧道内，发现整个水泥管道是由很多片宽约半米的弧形的管片（也就是衬砌）围城的，其中中下部的管片靠自重维持原位置，但是上部和底部的管片表面就布满了很多螺丝，这些都是弯螺栓，通过它们将两片管片栓到一起，这样就防止管片的错位了。此外，在底部我们还发现了一些空洞，揭开盖子，我们可以从这里面往管片外部注浆进一步提高周围土的强度。下午我们主要前往纬三路隧道项目部进行参观，在去的途中，我们经过了已经建成的纬七路长江隧道。南京扬子江隧道（即纬三路过江隧道）是双管双层八车道X形隧道，分别经南北两条线路穿越长江，上层为江北至江南方向，下层为江南至江北方向。南线全长7363米；北线全长7014米。两条隧道均为上下两层，每层双向4车道，设计时速80公里，其中S线盾构段长达4.135km，N线隧道长4.936km。具有如下特点：盾构直径超大，开挖直径达到14.98米，隧道最深处到江面约74米（本来还会深五米，但是考虑到上土下岩的问题，因此高了五米）。设计最高静水压力达到7.4bar，盾构一次掘进距离长，S线4140米，N线3533米。江底盾构覆土深度前，N线隧道上方覆土厚度最前处不及1倍洞径。地质条件复杂，需穿过卵石层，泥岩层，砂岩层。纬七路越江隧道要穿过泥层和岩层。对于泥层，我们可以采用刮刀处理，对于岩层，我们可以将滚刀伸出，这样就可以用滚刀处理，减少刮刀的磨损。这些情况都是很好处理的，最难处理的是上土下岩这种情况。这种情况会带来局部磨损，因此必须要带压开仓，通过潜水员来更换刀片。然而这里位于长江江水下70多米深处，潜水员们必须能够承受70米水头带来的压强。一般的方法是往泥浆里面注射一些东西，使得周围泥浆的强度变高，形成泥膜，但是这时候周围的压强转而由空气产生，潜水员同样要承受70m水头的压力。为了能够抵挡这样的压力，就需要潜水员经过三级加压舱的逐级适应，一般要加压到1.6MPa左右，然后在进入这个环境作业。对于纬七路隧道施工是这样做的，但是纬三路隧道施工的过程中，发生了意外，中国方面的一些工人，在更换刀片后再也没有能够回来，因此，中交轨道局（负责到定淮门大街一线，中航负责到扬子江大道一线）请了德国北海公司专业的高压隧道作业人员进行处理，当然价格很高，一周每个人需要支付20万欧，作为比较，这个隧道施工的总经费在204096万。为了配合，我们设计出了一个高压生活舱，平常高压作业的潜水员就直接生活在这个舱内，等到需要作业的时候，就将这个舱运到工作地点。回来的路上我们计算了一下成本，我们发现建隧道的成本其实很大，以盾构机来说吧，首先盾构机本身就分为了前面的刀片部分，后面用来铺设管片的部分，还有三道运输吊车。总长达到了133米，而且刀片一般都是采用的碳化钨制造，一般一片刀片价格就达到五位数甚至六位数，而这样的盾构机往往是不能重复利用的，即使遇到设计尺寸基本相符的工程，也需要花费额外的金钱和人力去更换适合的刀片，以及进行评估。相比之下桥梁的成本就低了很多了。而且一条隧道存在的安全隐患代价都应该远远高于一座过江大桥，所以为什么为什么我们还是要挖隧道而不是建桥呢，城市快速路使用隧道避了扰民，优化了城市的景观，可以理解，但是过江通道为什么不能考虑造桥呢？总结这次的实习，我们将书本上面的知识，在实际中得到了验证，同时，我们也感受到了岩土工程施工一线的环境和气氛，对我们的职业道路的规划起到了重要的指导与启迪作用。]]></content>
      <tags>
        <tag>土木工程</tag>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[POJ 1037 A Decorative Fence 动态规划解排序计数]]></title>
    <url>%2F2016%2F11%2F07%2FPOJ1037%2F</url>
    <content type="text"><![CDATA[这是在北京大学暑期课《ACM/ICPC竞赛训练》的一道DP的题目。 题意现在要排列长度为[1..N]的N个木棒，要求除了两端的木棒外，每一根木棒要不比左右的都长，要不比左右的都短。现在给定C，要求输出在所有符合上述条件的建法中按照字典序第C种排布方式。 思路这是课程pdf提供的源码（修改后）这是我的代码这道题分成两步，第一步是计算合法排列数量N，第二步是通过N来计算第C个合法排列。第一步，其实可以先写一个递归的方案，然后再改成dp就行了，我觉得比较巧妙的地方是把up方案和down方案区分开来了。第二步，依次对第[1..i]位枚举剩下来的第[1..k]长的木棒，因为已经求得up[i][k]和down[i][k]。这种思想可以用来实现C++里面的next_permutation函数，这里给出了一个实现。 需要注意 c需要用long long去读 在计算up[i][k]的时候，我原先是从k + 1开始算的，但是实际上应当从k开始算。因为up[i][k]指的是所有由i个木棒组成的方案中以这些木棒中第k短的木棒开头的up方案的个数。也就是需要取走第k短木棒kk后的i - 1木棒组成的是一个down方案。注意到取走kk后，应当从比kk长的第一个木棒开始计算，也就是从i根木棒的第k + 1短开始。但是原来i根木棒的第k + 1短变成了现在i - 1根木棒的第k短，因此还是要从k开始搜索。 在排序计数时退出条件应当是c == 1而不是c == 0。 然后注意是n - i + 1或者n - i（看下标上界是0还是1），不是i。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础工程复习]]></title>
    <url>%2F2016%2F11%2F06%2F%E5%9F%BA%E7%A1%80%E5%B7%A5%E7%A8%8B%E5%A4%8D%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[这是根据同济大学版的《基础工程设计原理》整理的复习提纲。 绪论 建筑物三要素：上部结构、基础、地基 地基 地基是承受建筑物荷载的地层 所以增加基础材料的强度并不能提高地基的极限承载力 地基可分为持力层和下卧层 第一章 地基模型 地基模型：描述地基土应力和应变关系的数学表达式 最常用的线性弹性地基模型：文克勒地基模型、弹性半空间地基模型、分层地基模型 文克勒地基模型： 假定地基有许多独立且互不影响的弹簧组成，因此地基任一点的压强p之和该点地基变形s成正比，即$ p = ks $，其中k是地基基床系数，表示产生单位变形所需要的压力强度（$ kN/m^3 $）。 这忽略了地基中的剪应力，是一个近似模型，地基越软，土的抗剪强度越低，越接近实际。 地基基床系数可由载荷板实验、室内三轴试验、固结试验获得。 弹性半空间模型： 将地基视作均匀的、各项同性的弹性半空间体。 由此可以使用Boussinesq解：$ s = \frac{Q(1 - v^2)}{\pi E r} $ 实际计算沉降偏大，一般认为是地基压缩层厚度是有限的且地基是分层的，即使同一种土，变形模量随深度增加。 分层地基模型： 我国地基基础规范。地基最终沉降等于压缩层范围内各计算分层在完全侧限条件下的压缩量之和。 地基模型的选择： 主要原则： 土的变形特征，外荷载在地基中引起的应力水平 荷载的种类和施加方式 土层的分布 基础和上部结构的刚度和形成过程 基础的埋置深度 施工过程 时效（考虑到土的固结） 常见形式 沙土、无粘性土、基础柔软、局部集中荷载：文克勒 基础埋深大、土质紧密：分层 粘性土：弹性空间地基模型、分层地基模型 文克勒模型的柔度矩阵： 将地基的面积分成m个$ a \times b $大小的矩形。，假设在j网格中点作用集中力Rj，那么当且仅当$ i = j $时，$ s_{ij} = \frac{R_i}{k_i \times a \times b} $。因而文克勒地基模型的柔度矩阵是个对角矩阵。 第二章 浅基础设计原理 地基基础设计需要考虑的因素： 基础所用材料和结构形式 基础埋深 地基土的承载力 基础的形状和布置，与相邻地下（基础、构筑物、管道）的关系 上部结构的类型、使用要求、对不均匀沉降的敏感性 施工期限、方法、设备 抗震要求 浅基础的类型： 按照所用基础材料的性能：无筋扩展基础、扩展基础、柱下钢筋混凝土条形基础 按照形状和大小：独立基础、条形/十字交叉条形基础、筏板基础、箱形基础、壳体基础 按照刚度：刚性基础（无筋扩展基础）、柔性（扩展基础） 无筋扩展基础 自重大、抗拉抗剪强度不高，一般相对高度较大，不会发生弯曲变形，因此被称为刚性基础 对于荷载大、沉降敏感建筑物，持力层土质差不适宜 钢筋混凝土扩展基础抗拉抗剪强度较高，因此在扩大基础底面积（为了满足地基承载力要求）不需要增加埋深；又称为柔性基础或有限刚度基础。可分为柱下钢筋混凝土独立基础和柱下钢筋混凝土条形基础和十字交叉条形基础。 筏板基础比十字交叉条形基础具有更大的整体刚度，有利于调整不均匀沉降。分为平板式和梁板式。 箱形基础在使用十字交叉基础不能满足承载力要求又不能采用桩基时。比筏板基础有更大的抗弯刚度，可视作绝对刚性基础。箱形基础是补偿基础。箱型基础材料消耗大，还会遇到深基坑开挖带来的困难。 基础埋深： 基础地面到天然地面的垂直距离 影响因素： 建筑物用途和荷载大小性质 对于地下室：承载力、变形、补偿基础的要求 对于高层：稳定性 对于承受水平荷载：满足抗滑要求 工程地质和水位地质 直接支撑基础的土层成为持力层，以下各土层成为下卧层。持力层必须强度足够稳定可靠。 当上层土承载力较低，应将基础埋置在下层较好的土层之中。如果需要深埋，需要和加固上层土或者短桩基础进行比较决定 例如上海某些地方，软土为不良持力层，但表面有2-3m硬壳层，六层以下民居可以利用 易于风化软岩，开挖后立即铺设垫层防止风化 地下水存在时，尽量在地下水位以上；否则要考虑基坑排水，坑壁支护等措施 若持力层下存在承压水，要控制基坑开挖深度，避免引起突涌或者流砂现象 相邻地下（基础、构筑物、管道）的关系 新建筑物埋深不宜深于旧的。否则要保证间距或者采用地连墙、分段施工、加固原有地基等措施。 地基土冻胀和融陷的影响冻结危害：地面不均匀隆起，土体膨胀，使墙体开裂，门窗不能开启化冻危害：土体松软，融陷，强度降低，沉降 补偿基础： 为了减小拟建建筑物的沉降量，除去地基处理或桩基础，还可以选用补偿基础。 箱形基础和筏板基础是补偿基础。由于地下室的存在基础具有大量空间，免去大量的回填土，可以用来补偿上部结构的全部或部分压力。基底附加应力p0公式为：$ p_0 = p - σ_c = \frac{N}{A} - γ_0 \times d $。其中N为作用在基地的荷载（$ kN $），A为基础底面积，d为基础埋深，$ γ_0 $为埋置深度内土重度的加权平均值。 定义当$ p_0 $时候的基础为全补偿基础，也就是建筑物的重力等于基坑挖去的总土量；否则是部分补偿基础。 无筋扩展基础和钢筋混凝土扩展地基的区别 无筋扩展基础是刚性基础，抗压高，拉剪弱 钢筋混凝土基础是柔性基础，抗拉、抗剪强度较高 减小不均匀沉降的措施 建筑措施 建筑物的体型力求简单 增强结构的整体刚度 设置沉降缝 相邻建筑物基础间要有合适净距 调整某些设计标高 结构措施 设计圈梁增强刚度 使用合适的结构形式 减轻建筑物和基础自重 减小调正基地附加压力 增强基础刚度 施工措施 先高后低 施工前使地基预先沉降 注意沉桩、降水对邻近建筑物的影响 基坑开挖保护坑底土 尽可能不扰动土的原状结构 确定地基承载力方法 地基承载力：地基土在同时满足强度和变形两个条件时，单位面积上所能承受的最大荷载的能力 承载力理论公式 现场载荷试验 浅层平板载荷和深层平板载荷实验。 经验方法 计算地基承载力 包含地基持力层承载力验算和软弱下卧层承载力验算。 天然地基上浅基础设计的内容 选择基础的材料、类型，进行基础平面布置 选择基础的埋置深度 确定地基承载力设计值 确定基础的底面尺寸 必要时进行地基变形与稳定性验算 进行基础结构设计（按基础布置进行内力分析、截面计算和满足构造要求） 绘制基础施工图，提出施工说明 第三章 浅基础结构设计 地基反力分布假设 墙下条形基础、柱下独立基础、筏板基础等（持力层土质均匀、上部结构刚度较好、各柱距相差不大、柱荷载分布均匀）：直线分布 弹性地基梁 基础结构设计主要内容 无限长和有限长梁的区分 文克勒模型上有限长和无限长梁内力求解 偏向受压独立基础、条形基础设计 第四章 桩基础桩基础由基桩和连接于桩顶的承台共同组成 桩的种类和优缺点 预制桩（挤土桩） 包含预制钢筋混凝土桩、预应力钢筋混凝土桩、钢桩 噪音大 灌注桩 钻孔灌注桩（非挤土桩） 人工挖孔灌注桩（非挤土桩） 沉管灌注桩（挤土桩） 噪音大 跳打：待混凝土强度足够时再在新桩的近旁施打相邻桩 轴向荷载沿桩身传递方式 开始加荷于桩顶，桩身压缩，桩侧受土的向上摩阻力 桩身荷载和压缩变形随深度递减 荷载增加，桩身压缩量增大，桩下部的摩阻力随之增加，产生桩端阻力 桩端土层压缩加大桩土相对位移，使桩身摩阻力进一步增大 桩身摩阻力达极限，继续加荷，荷载增量将全部由桩端阻力承担。桩端持力层大量压缩并塑性变形，直至桩端阻力达到极限，位移迅速增大至破坏。此时，桩达到其极限承载力。 影响桩侧桩端阻力的因素（荷载传递函数） 与土层性质、埋深、桩径等有关 桩侧桩端分担比还与桩土相对刚度、长径比l/d有关。桩土相对刚度越大，长径比l/d越小，桩端传递的荷载就越大 主特征参数：极限摩阻力$ q_su $ 和极限位移 $ s_u $ 单桩破坏形式 Q-s曲线（桩顶荷载/沉降曲线） 0-1阶段， 1-2阶段，桩侧土弹塑性阶段 当桩顶侧摩阻力达极限时（1点），桩侧进入塑性状态，随荷载增大，桩侧土塑性范围由浅到深发展，直至均达到塑性状态（2点） 2-3阶段，桩侧土完全塑性阶段 新增荷载全部由桩端承担，直至持力层破坏（$ k_s s_l \geq q_bu $），其中$ k_s, s_l, q_bu $ 分别是垂直方向地基反力系数、桩的沉降量和桩端承载力 摩擦型桩 2-3段近似直线，陡降，2点现明显拐点 端承型桩 端阻占比大，2点不现明显拐点，破坏需较大位移，曲线呈缓变型 深度效应 沉桩效应 单桩承载力确定方法 经验参数法 静载荷试验法 静力计算法 静力触探法 高应变动测法 负摩阻力及产生原因 当桩周土体发生下沉切沉降速率大于桩的下沉时，土对桩产生向下的摩阻力，称为负摩阻力。 负摩阻力产生原因有： 桩基附近地面大面堆载，引起地面沉降，产生负摩阻力。如大面积堆放重物的车间、仓库建筑桩基础。 因黄土湿陷、冻土融化产生地面下沉。 打桩，桩周土产生超空隙水压力，停止后桩周土的再固结作用引起下沉； 桩穿过欠固结土层（如填土）进入硬持力层，自重固结下沉； 土层中抽取地下水或其他原因，因自重固结下沉 群桩效应 群桩中任意一根基桩的工作性状都不同于孤立的单桩，群桩承载力不等于各单桩承载力之和，群桩沉降明显大于单桩。 定义群桩效率系数 $ \eta = \frac{P_u}{n Q_u} $。其中$ P_u, Q_u, n $ 分别为群桩竖向极限承载力、单桩竖向极限承载力和桩数。定义沉降比 $ \zeta = \frac{s_n}{s} $。$ n $和$ \zeta $主要取决于桩距和桩数，其次与土质和土层构造、桩径、桩的类型及排列方式等因素有关。 由端承桩组成的群桩，工作性状于独立单桩相近 由摩擦桩组成的群桩，桩顶荷载主要有桩侧摩阻力传到土层中，在桩端平面产生应力重叠。因此在粘性土中的群桩随着桩数增多，群桩效率系数η明显下降。 控制沉桩挤土效应方法：设置防振沟、挤土井、预钻孔、排水砂井、控制沉桩速度以及调整打桩流水 计算题：桩顶荷载和桩身最大弯矩计算 第五章 沉井基础 定义及特点 沉井是井筒状的结构物。它是以井内挖土，依靠自身重力克服井壁摩阻力后下沉到设计标高，然后经过混凝土封底并填塞井孔，使其成为结构物的基础。 沉井优点： 埋置深度大，整体性强、稳定性好 可作为挡土和挡土围堰结构物 施工工艺不复杂 施工时对邻近建筑物影响小 沉井的缺点： 施工周期长 易发生流砂现象，造成沉井倾斜（粉细砂） 大孤石、树干或井底岩层表面倾斜过大，给施工造成困难 沉井基础下沉困难的原因和解决措施 原因： 开挖面深度不够，正面阻力大 偏斜或刃脚下遇到障碍物、坚硬岩层和土层 井壁摩阻力大于沉井自重 井壁无减阻措施或泥浆套、空气幕等减阻构件遭到破坏 解决方案： 增加压重 提前接筑下节沉井 在井顶加压砂袋、钢轨等重物 不排水下沉时，可井内抽水 减小井壁摩阻力 井壁内埋设高压射水管组，射水辅助下沉 利用泥浆套或空气幕辅助下沉 增大开挖范围和深度 必要时还可采用0.1∼0.2kg炸药起爆助沉 沉井下沉突沉的原因和解决方案 原因： 井壁摩阻力较小，当刃脚下土被挖除时，沉井支承削弱 排水过多 挖土太深 出现塑流 解决方案： 控制均匀挖土，减小刃脚处挖土深度 在设计时可采用增大刃脚踏面宽度或增设底梁的措施提高刃脚阻力 流砂出现原因和解决方案 原因：土中动水压力的水头梯度大于临界值 解决方案： 排水下沉时发生流砂，可采取向井内灌水 不排水除土下沉时，减小水头梯度 采用井点，或深井和深井泵降水 沉井基础的施工工序（旱地） 整平场地 制造第一节沉井 制造沉井前，应先在刃脚处对称铺满垫木，以支承第一节沉井的重量 拆模及抽垫 挖土下沉 接高沉井 筑井顶围墙 地基检验和处理 封底、充填井孔及浇筑顶盖 水中沉井基础施工方法 筑岛法 浮运沉井施工 沉井下沉倾斜的原因和解决措施 原因： 土岛表面松软，河底土质软硬不匀 井壁与刃脚中线不重合 抽垫方法欠妥，回填不及时 除土不均匀对称 刃脚遇障碍物顶住而未及时发现 排土堆放不合理，或单侧受水流冲击淘空等导致沉井承受不对称外力作用 解决方案： 在沉井高的一侧集中挖土，在低的一侧回填砂石 在沉井高的一侧加重物或用高压射水冲松土层 在沉井顶面施加水平力扶正 沉井设计基本内容]]></content>
      <tags>
        <tag>土木工程</tag>
        <tag>基础工程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ACM/ICPC 2015 沈阳网络赛]]></title>
    <url>%2F2016%2F11%2F03%2FICPC2015%E6%B2%88%E9%98%B3%2F</url>
    <content type="text"><![CDATA[ACM/ICPC 2015 沈阳网络赛 1006 Fang Fang题意给你一个由小写字母组成的循环字符串S（循环字符串的意思是你可以从任意位置i开始，顺时针经过n回到i-1的位置），问至少需要序列F中的多少项才能组成字符串S。 思路水题，代码 1010 Jesus Is Here1012 Largest Point]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDU 5952 Counting Cliques]]></title>
    <url>%2F2016%2F11%2F02%2FHDU5952Counting-Cliques%2F</url>
    <content type="text"><![CDATA[ACM/ICPC 2016 沈阳站 Counting Cliques这道题蛮可惜的，其实就是暴力，不过在现场zyyyyy使用了set实现，实际上用vector就过了。 题意求一个N(N &le; 100)点M(N &le; 1000)边的无向图容量为S的团的个数。已知每个点的度不大于20。 思路如代码所示，进行dfs，dfs维护一个conn数组用来表示一个大小为sz的完全图的所有点。在每层的dfs中每次寻找并添加一个可能的点，这个点必须要满足和已有的完全图能够成一个新的大小为sz+1的完全图（也就是和完全图中的所有其他点的都要有边）。在实现过程中有以下优化： 为了避免重复，只从边号小到边号大建边 为了节约时间，筛掉度小于S-1的边 为了节约时间，第一层dfs完毕后将该点的从图中去掉。 去掉以上两个优化在hdu上还是能过。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Visual Studio使用技巧]]></title>
    <url>%2F2016%2F11%2F01%2FVS%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[记录Visual Studio的一些使用技巧，包括创建Snipplet、一些常见错误的解决方案和使用命令行编译的相关方法。 重定向源码路径 调试为了能够顺利进行调试，将 工程属性-调试-工作目录 设为新的目录 添加文件默认的右键工程目录添加文件并不好用，因为每次总是给定$(SolutionDir)$(ProjectName)下的一个地址，因此可以使用插件Add New File，只需要Shift+F2即可 出现符号未定义或者符号重定义的情况这是正常现象，重生成清理都没有用，正确方法是讲涉及的文件移出工程再重新添加即可，一般这种原因是某个函数所声明的h文件曾经被rename过。 使用MSBuild编译C++代码使用命令行编译可以使用MSBuild直接构建vcxproj文件，也可以使用VCVARS32.bat来运行传统的Makefile文件 命令行常见选项及意义目录OutDir这是输出目录，包含ilk、pdb文件的所在地。对应于VS中的常规-输出目录。建议和OutputFile的目录相同，否则会出一个warning。这应当在PropertyGroup选项中配置。默认值为$(SolutionDir)$(Platform)\$(Configuration)\，例12345&lt;PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'"&gt; &lt;LinkIncremental&gt;true&lt;/LinkIncremental&gt; &lt;OutDir&gt;../bin/&lt;/OutDir&gt; &lt;IntDir&gt;../bin/obj/&lt;/IntDir&gt;&lt;/PropertyGroup&gt; IntDir这是编译器生成的obj以及log文件的所在地。对应于VS中的常规-中间目录。这应当在和OutDir相同的地方配置。默认值为$(Platform)\$(Configuration)\，例同上 OutputFile这就是最终生成的exe文件名字。对应于VS中的链接器-常规-输出文件选项。这应当在ItemDefinitionGroup-Link选项中配置。默认值为$(OutDir)$(TargetName)$(TargetExt)，例12345678910111213141516&lt;ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'"&gt; &lt;ClCompile&gt; &lt;PrecompiledHeader&gt; &lt;/PrecompiledHeader&gt; &lt;WarningLevel&gt;Level3&lt;/WarningLevel&gt; &lt;Optimization&gt;Disabled&lt;/Optimization&gt; &lt;PreprocessorDefinitions&gt;_DEBUG;_CONSOLE;_CRT_SECURE_NO_WARNINGS;_SCL_SECURE_NO_WARNINGS;%(PreprocessorDefinitions)&lt;/PreprocessorDefinitions&gt; &lt;AdditionalIncludeDirectories&gt;%boost_dir%;%(AdditionalIncludeDirectories)&lt;/AdditionalIncludeDirectories&gt; &lt;/ClCompile&gt; &lt;Link&gt; &lt;SubSystem&gt;Console&lt;/SubSystem&gt; &lt;GenerateDebugInformation&gt;true&lt;/GenerateDebugInformation&gt; &lt;AdditionalLibraryDirectories&gt;%boost_dir%\stage\lib;%boost_dir%\libs;%(AdditionalLibraryDirectories)&lt;/AdditionalLibraryDirectories&gt; &lt;OutputFile&gt;../bin/$(TargetName)$(TargetExt)&lt;/OutputFile&gt; &lt;/Link&gt;&lt;/ItemDefinitionGroup&gt; LocalDebuggerCommandArguments为了能够让IDE兼容我们的编译结果，我们需要同时修改IDE的配置选项。这个是在IDE中用来调试的命令行，其默认值为$(TargetPath)，也就等于生成的exe的位置 LocalDebuggerWorkingDirectory]]></content>
      <tags>
        <tag>Visual Studio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCPC 2016 杭州站]]></title>
    <url>%2F2016%2F10%2F30%2FCCPC2016%E6%9D%AD%E5%B7%9E%2F</url>
    <content type="text"><![CDATA[CCPC2016杭州赛区推出了大中学生对抗赛，于是全场比赛主要看点一是clj封榜前能不能AK，另一个就是看清华学长PK清华学弟。 1001 ArcSoft’s Office Rearrangement题意给定a[1..N]，可以合并相邻两项或者将一项拆开成两项，问是否能够得到b[1..K]且b中每项都相等。 思路我的错误代码代码 1002 Bomb题意平面上给了n个炸弹，引爆其中的炸弹i需要代价ci，一个炸弹爆炸会使得它半径ri内的炸弹爆炸，以此类推。求使得所有炸弹爆炸需要的最小代价。 思路强连通缩点，然后找入度为0的所有的联通块，然后在联通块内找一个花费最小的即可。找联通快和寻找花费最小代价的点可以在tarjan的弹栈操作完成。特别地，寻找入度为0的所有连通块是通过遍历所有的边然后比较(u,v)是否属于同一联通块实现的实现的。此外注意引爆具有有向性。代码 1003 Car题意一辆车保持不减速运动（速度为实数），时间从0开始，在某些整数时刻记录下车的位置（整数递增），求最少需要多长时间达到最后一个记录点 思路这道题目的坑主要是卡精度，求ceil得时候要减去eps=1e-7。或者直接用分数类也能过。代码 1006 Four Operations题意在一个最多20位的整数里面按顺序插入+、-、*、/（整除）四个运算符，要求结果最大。 思路要注意整数有20位，使用long long。代码]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>CCPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hihoCoder 1392 War Chess 大模拟]]></title>
    <url>%2F2016%2F10%2F25%2Fhiho1392War-Chess%2F</url>
    <content type="text"><![CDATA[ACM/ICPC 2016 北京网络赛赛题 War Chess 题意HDU上有一道类似题目链接HDU以游戏曹操传为背景，给定地图N &times; M的矩阵。Gi j表示任人物穿过这个方格的行动值减小量。每个人物有以下属性： 生命值 HP 攻击力 AT 行动力 MV 攻击范围 [AD1, AD2] 起始坐标 (STx, STy) 所在阵营 GR 每个人物可以攻击攻击范围内的敌对玩家，一旦人物的HP小于等于0，将它的移出棋盘。人物可以从当前格子开始向四周移动，在人物移动过程中，当人物从格子(i,j)移到格子(x,y)时，他的行动力减少Gx y。当移动力小于0时移动是非法的。同时，当该人物四周有敌对人物时，该人物移动力变为0。现在给定游戏记录，要求模拟游戏，并判断合法性。 思路需要注意自己局中不能移动他人的棋子，死亡人物不能进行操作。我的不能使用的代码修改后的代码有几点做的不好： 可以开一个数组记录每个格子被谁占领，注意走和被Drive out后要及时更新 Attack前先要检测Attack之后HP是不是会小于等于0，如果是的就不能Attack 其实选择人物的时候并不需要检查Round 中间我还犯了一些错误，比如OC[dx][dy]写成了OC[x][y]，没有设vis[STx][STy]。此外的move时的bfs里面，不能更新Cha[cha].MV，这是一个固有的值，每次走完MV是不变的，所以应当记录走完之后MV用了多少。 比赛的时候用的dfs，这样太慢了，实际上是bfs，用一个优先队列维护mv最大的状态，每次都是贪心从mv最大的状态走。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[emacs学习笔记]]></title>
    <url>%2F2016%2F10%2F24%2Femacs%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[鉴于2015年icpc北京站没有cb等ide，来学习emacs。由于本人之前比较习惯使用vim，因此这里将部分地和vim进行对比。不过后来发现有尿壶geany（虽然我觉得很难用，关键是RE直接退出），和eclipse cdt（虽然eclipse我很讨厌但总比没有强吧），所以我决定不学了（VS大法好）。 基本操作在bash on windows下运行sudo apt-get emacs。安装完毕后运行emacs filename可以打开/创建一个新文件。使用Ctrl+X Ctrl+C可以退出emacs，类似vim的:q。 命令说明和vim不同，emacs比较依赖Ctrl，Meta键。Ctrl键是比较寻常的，Meta键有三种作用方式： Alt + X Esc X (先按Esc松开后按X) Ctrl+[ X 注意vim命令常可带数字前缀，例如3fa可以表示当前行第三个a，4yy表示复制四行。 光标跳转 操作 emacs(不使用光标控制键) vim(默认Normal模式) 光标控制键 备注 光标左移 Ctrl+B H ← 光标右移 Ctrl+F L → 光标上移 Ctrl+P K ↑ 光标下移 Ctrl+N J ↓ 上一词首 Alt+B b / vim不会忽略标点符号 上一词尾 ge / 下一词首 w / 下一词尾 Alt+F e / emacs实际移到插入位置，类似vim按a进入插入模式 光标到顶行 H 光标到中行 M 光标到底行 L 上半页 Ctrl+D 下半页 Ctrl+U 上一页 Alt+V Ctrl+B Page Up 下一页 Ctrl+V Ctrl+F Page Down 逐行下滚 Ctrl+E 逐行上滚 Ctrl+Y 行首 Ctrl+A 0 Home 行首(忽略前导空白) ^ 行末 Ctrl+E $ End 行末(忽略尾部空白) g_ 句首 Alt+A ( 句子以空行和句号分隔 句末 Alt+E ) 段首 Ctrl+{ { 段以空行分隔 段末 Ctrl+} } 首行 1G, gg 末行 G 置顶当前行 zt 置底当前行 zb 到本行下一个char字符处 f+char 到本行下一个char字符前 t+char 到本行前一个char字符处 F+char 到本行前一个char字符前 T+char 括号匹配 % 插改增删复制黏贴删除删除指令可以主要以d开头，可以在d后面指定重复次数，也可以在d前面指定重复次数。 操作 emacs vim vim(插入模式)或gedit 备注 删除当前字符 x, d+→ del 删除前一个字符 X, d+← backspace 删除当前单词 dw 删到行首 do 删到行尾 d$ 删到一行 dd 复制和粘贴 操作 emacs vim vim(插入模式)或gedit 备注 与下行合并 J 查找emacs概念]]></content>
      <tags>
        <tag>ICPC</tag>
        <tag>emacs</tag>
        <tag>vim</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ACM/ICPC 2016 沈阳站小记]]></title>
    <url>%2F2016%2F10%2F24%2FICPC2016%E6%B2%88%E9%98%B3%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[周六周日参加了icpc沈阳站的比赛。这次出题是doc老师，和去年的合肥一样，沈阳站撇去两条水题是1题铜两题银，我们过了C卡了E，最后以罚时打了铁。 正式赛赛题AB比较水，第一题选两个最大的数相加，第二题求分子质量。C是给出函数$ f(x) = 2 * f(x - 2) + f(x - 1) + x ^ 4 $给定$ f(1) $，$ f(2) $，求$ f(n) $。E是求含有S个点的完全图的数量。一开始我们分配是推C的公式（觉得不像是快速幂），我想的是dfs解决E，用在合肥的方法，但是不太好去重，后来zyyyyy试了一会儿C放弃了，写了另一个dfs试图过E，结果T了。后来我和Song打算搞C的快速矩阵幂，我快速幂记不得了，后来Song给我讲我也没听懂，因为她把矩阵右乘左乘搞反了，不过后来我想到了杨辉三角，构造了一个7阶矩阵：$$M\times\begin{bmatrix}f(n - 2) \\f(n - 1) \\1 \\i \\i^2 \\i^3 \\i^4 \\\end{bmatrix}=\begin{bmatrix}f(n - 1) \\f(n) \\1 \\i + 1 \\(i + 1)^2 \\(i + 1)^3 \\(i + 1)^4 \\\end{bmatrix}\tag{1}$$ 然后就过了。E题一直没过，后来看到旁边南航4题铜牌队过了，一问他们也是搜索，不过他们用了vector来判重的，但是我们是set。这道题的题解专门列了个blog 感受 第一次坐飞机，第一次去东北，表示非常兴奋。东北没有想象中那么冷，但是沈阳风很大，而且喜怒无常，穿上棉毛裤也不感觉暖和一点，不穿也不感觉冷，但是裤子要sa起来，不然确实串风。我们早上比赛的时候要求穿发的比赛服（还要把那个acm的sticker贴在胸前），可是我们到了比赛场馆外面等了好久门都不开，搞的我又把黑棉袄给穿上了。东北菜我觉得不太好吃，但是锅包肉确实特别好吃，我们吃了两次，第二次在饭店里面的还加了柠檬，几乎被我们五个人秒了。此外杀猪菜也很好吃，就是量少，酸菜有点酸，我吃不惯。玉米面烙饼也很好吃。 在东北大学见到了老同学，老同学非常热情，晚上请我们吃了顿饭（PS东北菜不太吃得惯，但是锅包肉真心好吃），第二天还买了特产小梨子送给我们，那个梨子真的挺好吃的，浑身上下传来一股热带水果的味道。乍一看品相也忒差了点了，坑坑洼洼的，但是吃起来很香。 比赛完了我们和老师五人一起玩了南湖公园，南湖公园还挺好玩的，里面有几座桥挺漂亮。晚上我们在南湖公园溜冰，具体就不说了，大家都比较惨，还玩了那个两个脚独立的滑板。溜完冰回来，我和老同学和队友互相普及各地方言。 周日晚上我们开始八卦之夜。大家分享对对方的看法，各种互黑，我也树立了毕业之后去说相声的远大志向。 热身赛是去年的题目，第一题居然是No Input猜一个数字，结果是东北大学的建校的年份。然后有一道题应该用SAM做的，然后我提出就暴力一下，顺便测测T，结果交了一发居然A了。 被质疑的大连海事大学金牌队就在我们对面，而且他们没有来，被我们缴获了他们的密码。 刚下车从机场打车到东北大学，司机东北人非常爱说话，说小萌是歌星（她来的时候带了个帽子），我们是小萌的保镖，又调侃小萌太男孩子（鉴于她最近搞了一个超级丑的头还不承认），过收费站的时候和收费员一个劲的美女的称呼。 这次比赛暴露出了一些问题，因为ACM是一个1+1+1&gt;3的比赛，和OI是不同的。队员实力导致必然每个人有擅长的方面，也有每个人不擅长的方面，但否能够扬长避短考验每个团队的能力。无论是去在有异议时理解和信任别人的想法，还是在别人质疑时有自信坚持和完善自己的想法都是非常考验一个人的。这次比赛我觉得在这些点上，大家都做得不够好，但是相比合肥站，我觉得其实是没有遗憾的，每个人都非常努力地发挥了，并且在互相理解和信任上也进步了很多。因此在我们每一次1Y的时候，我是非常骄傲能在这么一个队里面。这次题目偏难一点，我们之前也没有训练过这种一题铜的比赛，有点猝不及防，最后也是输在了罚时，但是我相信大家将来会越做越好。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>现场赛</tag>
        <tag>ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCPC2016合肥小记]]></title>
    <url>%2F2016%2F10%2F16%2FCCPC2016%E5%90%88%E8%82%A5%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[今天参加了CCPC2016合肥站的比赛。因为z+y的神脑洞，我们没有在规律题上怎么卡，而是死在了图论上，果然Cu到Ag还是算法不行。今天重现赛，我把我改掉那&amp;&amp;短路的代码交了一遍就1A了，考虑到我比赛最后30min一个人在队友怀疑中敲完了自己的思路，而且被短路虽然是低级失误，但我之前真的没遇到过（我平常if, for都是打大括号的，这次实在是赶时间）。我也问心无愧。我不遗憾，只是太可惜了。代码 正式赛赛题我们过了HIEC，卡了A（图论）。I题是位运算，对r先求补，mask掉highbit，然后不停lowbit修改l，比赛的时候zyyyyy写的，这是重现时我写的代码，在实际上写的时候将long long映射到int[64]会比直接的位操作要方便一点。H题要求给定序列a[i]，查询a[l..r]的xor的结果。一开始我样例搞错了，因为我把异或和非异或记反了。E题扫雷，要求是3行N列的矩阵的扫雷游戏，其中第二行的所有格子是已知的且都没有雷。求所有雷的安放的情况的总数。可以发现只要第一列确定了，后面每列的雷数（0, 1, 2）就确定了。这里贴一份网上扒的代码。C题是一道博弈的题目，给定一棵树，树的边权为0或1。对于每个查询，给定一个点作为树根，女生和男生交替选择一条权为1的边，并翻转从这条边到树根路径上的所有边。直到某一方不能找到权为1的边时，另一方就赢了。首先对于一条链来说如果根节点所在的边权为1，那么就可以翻转。一开始我没看懂，因为树的顶点是可以指定的，所以不一定就在最上面。A题，将一个竞赛图拆成两部分P和Q，判断P和Q是否同时都是传递的。当时我们的想法是首先不能有环，其次每条链上都必须是传递的，也就是每两点距离都是1。因此我当时敲的解法是dfs，使用to[u][v]表示能从u到v，假设现在对s进行dfs，首先对所有s连通的点i进行dfs，如果不满足性质则整个都不满足性质，然后检查i的所有能到达的点j，如果从s到j有直接边并且从j到s没有后向边，那么就是满足性质的。不过时间比较紧，我调试的时候遇到了sof（递归爆栈），当时比赛没发现是sof，因为控制台上没有出现任何错误提示，都以为时中途某个代码RE了。后来发现是有一句话把dfs短路掉了，导致最后一个单独的点无法被访问。对这条题目是比较遗憾的，因为当时队内一直希望找到更有效的解法，我自己也不自信，等到最后的半小时的时候我才开始敲我的思路，最后也非常紧张，没调试出来。我们对面的河南大学软件学院的同学是用了SPFA(O(kE), k&lt;=2)求了每两个点之间的最短路（dijkstra的O(V2)说会超时），然后检查是否存在有两点之间距离大于等于2。另有做法是分别添加Q的边和反向边插到P里面，然后拓扑排序判断是否有环。特别注意的是，我们使用PC^2评测的时候，PE是判成WA的，也就是没有PE，在做H还是I题的时候多输入了一个换行符，于是就WA了，浪费了一点罚时（不过也到不了银牌就是了）。PS补充一下CB有的时候是不能直接在Console黏贴的，这是正常的，可以将控制台换成gnome就好。 感受 合肥站的组织继承了ccpc组织优良的传统（虽然这才第二年）。热身赛的时候我们的键盘是大回车，导致backspace很容易按错，结果主办方第二天就换了键盘（虽然这次end键移到右上角，各种误触page up了）。 安徽大学好大啊，而且建筑特别漂亮，环境也好，第一天中午在操场上玩了半天器材，晚上走了半天才从最北边走到图书馆（中轴）。 第一次混进了教练餐（自助餐），感觉挺不错的，宾馆是安徽大学磬苑宾馆，感觉挺好的。安徽大学是发的自己学校的校园卡，80块钱，我们都买了一堆零食，SBzyyyyy给自己买个副耳机也是醉了。 正式赛早上恰逢合肥国际铁人三项，好多人堵在天宫酒店过不来，我们在坐在体育馆的看台上等了好长时间，中间还有志愿者给我们送来热水，期间我们看隔壁icpc大连场大佬们各种神过题（后来那一场4个AK，7题才铜）。最后十一点半比赛才开始，很多人最后都没赶上回去的车。 有幸遇到了初中同桌+6，本来晚上准备找她吃饭的，结果她晚上有个招聘，不过招聘完了晚上大家在宾馆玩杀人游戏，不过真是醉了，每次都是天亮了我死了，唯一一次我没死是因为我是杀手。 热身赛的时候没有比过石河子大学，正式赛报了“仇”。 学弟们都很强，希望他们能够再接再厉，为我校取得更好的成绩。 同沈阳最后一条感受。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>CCPC</tag>
        <tag>现场赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串算法学习]]></title>
    <url>%2F2016%2F10%2F14%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[相对于序列，字符串一定是连续的，字符串匹配和查找算法，如KMP、Trie、AC自动机等是比较基础的串算法。并使用摊还分析等方法分析了部分算法的复杂度 KMPKMP算法是一种前缀搜索方法，也就是说在搜索窗口内从前向后逐个读入文本字符，搜索窗口中文本和模式串的最长公共前缀。相对于前缀搜索，还有后缀搜索（Boyer-Moore、Horspool、Sunday）、子串搜索等方法。为了方便阅读，未特别注明情况下统一模式串为P，长m，以j为下标；文本串为S，长n，以i为下标，i和j下标从0开始。(i,j)表示匹配S[i]和P[j]。 KMP对朴素算法的优化 朴素的字符串匹配算法复杂度为O(n*m)，对于长n的文本串S，从位置[0..(n-m)]开始搜索匹配长m的模式串，对于每个位置至多需要m次比较。假设在(i,j)位置发生失配，那么接下来应当从(i-j+1,0)位置开始重新匹配。 容易发现其中有一些比较和回退操作是多余的。例如，假定模式串为P为&#39;ABCDABD&#39;，文本串为S=&#39;ABC ABCDAB&#39;，假设从(0,0)位置开始匹配，在(3,3)位置发现&#39; &#39;和&#39;D&#39;不等。此时朴素算法直接在(1,0)位置重新开始匹配，但实际上在刚才比较过程中可以得到(0..3,0)位置都是不行的，因为&#39;B&#39;、&#39;C&#39;、&#39; &#39;都不等于&#39;A&#39;，因此可以从(4,0)重新开始匹配。 另一个例子，考虑新的S=&#39;ABCDAB ABCDABCDABDE&#39;，在(6,6)处发现&#39; &#39;和&#39;D&#39;不等失配。同时发现P[0..1]和P[4..5]都能匹配S[4..5]（当然S[4..5]和S[0..1]都能匹配P[0..1]的&#39;AB&#39;，但目前我们考虑只移动模式串），由此可以尝试从(4,2)（注意j变成了2不是0）开始重新匹配，容易发现S并没有发生回退，而P右移了4位，用自己P[0..1]而不是P[4..5]的&#39;AB&#39;去匹配S[4..5]了。 因此可以得到KMP算法的思想：如果模式串P在(i,j)处失配文本串S，那么可以知道至少P[0..(j-1)]和S[i..(i+j-1)]是匹配的，既然如此，不妨可以利用已经匹配的这段长度，只回退（将串向右移动）模式串P，不回退文本串S（注意在KMP算法过程中对文本串S的操作只有递增一个）。因此通过KMP算法，假设在(i,j)位置发生失配，那么接下来应当右移符号串j-f(j)长度，从(i,f(j))位置开始重新匹配（注意此时失配前P[0..(j-1)]和S[i-(j-1)..i-1]已经匹配的部分会和P[f(j)-(j-1)..f(j)-1]重新匹配），其中f为next函数，将在下节中详细介绍；特别地，当j = 0时，我们应当从(i+1,0)开始匹配。可以得到这样算法的复杂度为O(n+m)。 KMP算法和next函数首先定义边界的概念，串v是串u的边界表示串v是串u的后缀，也是串u的前缀。我们考虑一下这样的u，它是一个奇妙的字符串，它的最前面一段和最后面一段是可以重叠的。有两类函数可以实现KMP，一种是fail函数fail(j)，对于失配的(i,j)，fail(j)是P[0..j]中最长边界对应的前缀的最后一个元素的下标。另一种是next函数next(i)，对于失配的(i,j)，next(j)是P[0,j-1]中最长边界后面那个元素的下标。这里的定义很奇怪，这是由于我们是从如何计算而不是如何应用的角度来说的。从作用上来讲，next(j)表示在(i,j)失配后rewind模式串（右移），从(i,next(j))重新匹配。fail实现的特点是计算的值会有很多-1，但是next实现只有next(0)是-1。在这里我们采用next函数进行描述。 next函数f(j)指出了查找下一个匹配时的模式串（这里可以理解为P[0..m-1]的子串P[0..j]）的回退距离（模式串P向右移动的距离），或者可以被称作最长边界。用形式方法来描述即，对于模式串P[0..j]来说，f(j) = max(k)，这里k满足P[(j-1)-(k-1)..(j-1)]即P[(j-k）..(j-1)] = P[0..(k-1)]（注意这里是j-1和k-1，在别的定义/实现方式中可能使用j和k）。这里要求是最大的k也就是最长边界，原因是考虑到可能存在多个k，为了不丢失匹配，回退距离应当尽可能小。 特别地，当j = 0时，即对于(i,0)位置的失配，指定f(0) = -1，这意味着我们应当递增文本串S的指针i，从下一位置匹配。 为了计算所有的f(1..m)，可以根据定义进行计算，朴素的方法需要O(m^2)的复杂度。但是可以采用dp实现线性复杂度的算法：令f(j) = k，即已知最大的k满足P[j-k...j-1] = P[0...k-1]，现在求f(j+1)： 如果P[k] = P[j]，则f(j+1) = k+1。 如果P[k]!=P[j]，于是显然P[0..k]显然不是P[0..j]的后缀（注意根据f定义下标分别是到j和k），所以只能在P[0..(k-1)]上寻找P[0..j]的后缀，但是P[0..(k-1)]也不一定就满足条件，当然可以对P[0..(k-1)]的所有前缀判O(k^2)次，但是也有简单办法，那就是利用失配前已经匹配了的结果。请在这里停顿并尝试自己推一下下面的过程，并体会其中的奇妙之处。令k= k2 = f(k)，继续寻找，如果此时P[k2]=P[j]，那就符合了，否则还要继续寻找。为什么说只要比较P[k2]=P[j]就行了呢？前面的k-1的长度不需要比较了么？因为k2是最大的满足P[k-k2..k-1] = P[0..k2-1]（也就是P[0..k2-1]的最长边界长度），而注意到我们发现P[k]!=P[j]，说明至少P[0..k-1]和P[j-k..j-1]是匹配的，因此P[0..k2-1] = P[k-k2..k-1] = P[j-k..j-1]，即我们新找到的P[0..k2-1]也和P[j-k..j-1]匹配。 下面对P=&#39;ABCDABD&#39;构造next函数。根据上文，首先有f(0)=-1。接下来计算f(1)，也就是在(i,j = 1)发生失配。我们需要找到此时P[0..(j-1)]=&#39;A&#39;的某个后缀同时也是P的前缀，显然并不存在。 简单的总结下，我们DP的过程是，假设已经求得P[j]，便尝试通过匹配的P[0..a] = P[b..j]来推导P[0..a+1]和P[b-1..j+1]是否匹配，如果P[a+1] != P[j+1]就可以立马使用前面的P。 为什么要从a推到a+1而不是从a-1推到a我们看到上面的递推过程是从next[a]推到next[a+1]，为什么不能从next[a-1]推到next[a]呢，这看起来更像常见的DP啊。我们不妨测试一下，设dp[j]为P[..j] == P[0..k]最大满足的k。123456789101112131415dp = [0 for i in xrange(n)]k = -1dp[0] = -1for j in xrange(1, n): k = dp[j] while k != -1 and t[j] != t[k]:# if k == 0:# break k = dp[k - 1] dp[j] = kprint dp# abcbad#dabcba# -000000000000# -0000100012345 我们发现不加上上面的注释的时候代码会死循环，这是因为当k == 0时dp[k - 1]越界了。而加上注释那么所有的dp都会变为0。仔细思考，这是因为我们不能区分0位置处是否能匹配的缘故。所以我们的next是失配指针，next[0]指的是0位置失配，而next[1]指的是1位置失配，此时0位置是匹配的。 求next函数和KMP算法比较KMP算法实际上是求模式串P[0..m]对文本串S[0..n]长度为m+1的边界（如果存在即找到）。next函数实际上是求模式串的某个前缀P[0..j]对P[0..j]长度最大的边界。回想KMP算法，在(i,j)位置发生失配，那么接下来应当从(i,f(j))位置开始重新匹配，因为f(j)是P[0..(j-1)]的最长边界。而在计算next函数f(j+1)时候，如果P[k]!=P[j]，那么可以理解为模式串P[0..k]在匹配文本串P[0..j]时在(j,k)发生失配，因此同样可以利用之前已经匹配了的结果，按照KMP应当从(j,f(k))开始寻找。 相关资料KMP算法有很多教程，每个教程都给出了自己的一套理解方法，没有一个我能够完全看懂。在学习过程中，我参照了Wikipedia的解释，其中适当后缀(proper suffix)，指的是不是自己本身的后缀，也就是“真后缀”。123456789101112131415161718192021222324252627282930313233343536373839// kuangbin模板// f大小至少为m+1void kmp_pre(const char P[],int m,int f[])&#123; // f[]：x[j-f[j]...j-1]=P[0...f[j]-1] // f[j]：为满足x[j-k...j-1]=P[0...k-1]的最大k值 // 对应于： // next[j]为满足x[j-z...j-1]=x[0...z-1]的最大z值 // next[j+1]为满足x[j-(z-1)...j]=x[0...z-1]的最大z值 int j,k; k=f[0]=-1; j=0; while(j&lt;m) &#123; while(k!=-1 &amp;&amp; P[j]!=P[k]) k=f[k]; f[++j]=++k; &#125;&#125;int KMP_Count(char P[],int m,char S[],int n)&#123; // P是模式串，S是主串 int i,j; int ans=0; kmp_pre(P,m,next); i=j=0; while(i&lt;n) &#123; while(-1!=j &amp;&amp; S[i]!=P[j]) j=next[j]; i++;j++; if(j&gt;=m) &#123; ans++; j=next[j]; &#125; &#125; return ans;&#125; 我也写了个实现 复杂度分析求next函数具有线性复杂度，考虑到内部有一层while，使用通常方法不易计算。实际的复杂度计算使用了摊还分析。 摊还分析对于一个操作序列，并不是所有操作的复杂度都相等的，例如对于std::vector，push_back()操作是O(1)的，但是当满了之后resize的操作却是O(n)的，仅通过push_back()便认为对std::vector增加一个元素需要常量时间是不恰当的（虽然却是是常量时间）。摊还分析(amortized analysis)是一种分析操作序列中所有操作的平均时间上界的方法。摊还分析主要有聚合法，核方法和势能法。 聚合法聚合法就是求出所有操作加起来最坏情况的总代价，然后除以总操作数。对于std::vector的添加元素操作来说，假设初始大小是1，倍增因子是m，要添加$n$个元素，需要重新分配内存$\lceil log_{m}{n} \rceil$次，第$i$次分配内存需要移动$m^{i-1}$个元素，总共需要$ \sum_{i=1}^{\lceil log_{m}{n} \rceil}{m^{i-1}} = O(n) $次移动操作，另需要push_back $n$次。因此复杂度为O(1) 核方法MIT的算法导论课公开课老师讲这个的时候在黑板上写了2 3 3 3…对这个记忆犹新核方法的原理就是把复杂度低的操作承担一部分复杂度高的操作的代价，从而证明算法复杂度的上界。定义$c_i$为第$i$个操作的真实代价，定义$\hat{c}_i$为摊还代价。在第$i$时刻，定义信用为$\sum_{i=1}^n{\hat{c}_i} - \sum_{i=1}^n{c_i}$，选取的摊还代价要保证信用始终非负，因为一旦信用是负数，那么这个操作实际上是在开销上界内不能完成的上图是一个倍增因子m为2的动态表std::vector，$size_i$表示添加第$i$项时的表达大小，真实代价$c_i$由两部分组成，一部分是添加进表的固定成本（$c_i$第一行），另一部分是把元素复制到新表中的成本（$c_i$第二行），$bank_i$就是信用。对于$m=2$的情况，可以发现$\hat{c}_i$取3即可，这包括自己的真实代价，移动表的前一半的代价，和移动表的后一半的代价。对于普遍的倍增因子m，后面m-1的元素要m个元素的移动代价，加上添加进表的1，摊还代价取$1 + \frac{m}{m - 1}$，特别地$i = 1$时只要支付自己的移动代价，故摊还代价为$1$，于是等式左边$\sum_{2}^{n}{(\frac{m}{m - 1})} + n = \frac{2nm - n - m}{m - 1} $，等式右边$n + \sum_{0}^{\lceil log_{m}{n} - 1 \rceil}{m^i} = n + \frac{n - 1}{m - 1} = \frac{nm - 1}{m - 1}$，发现左边恒大于右边。 势能法势能法和核方法基本上是相同的，区别在于核方法要先假设摊还代价，而势能法先考虑的信用和（也就是势）。对于有的题目势能法比核方法简单。对于上面的$m=2$的动态表，定义势函数$\phi(D_i) = 2i - 2^{\lceil log_{2}{i} \rceil}$，由于$i = 2^{log_{2}{i} }$，所以可以得到式子恒为正。因此满足势函数的基本要求$\phi(D_0) = 0$和$\phi(D_i) \ge 0$。下面计算摊还代价$\hat{c}_i = c_i + \phi(D_i) - \phi(D_{i - 1}) $，其中$c_i = \begin{cases} i \, , \, (i - 1) &amp; ((i - 1) - 1) == 0 \\1 \, , \, otherwise \end{cases}$。通过对$i$的讨论，可以发现每个操作的摊还代价是3，这和前面的核方法形成了印证。下面考虑倍增因子为m的情况，定义势函数为$\phi(D_i) = 2i - m^{\lceil log_{m}{i} \rceil}$，可以进行类似的计算，得到每个操作的摊还代价是$1 + \frac{m}{m - 1}$ 求next函数的复杂度下面使用摊还分析计算求next的kmp_pre函数的复杂度。首先跟踪变量k，因为k出现在了最内层的while中，但是j没有出现。发现对k有两次操作，第一个是k = f[k]，这个操作是当P[k] != P[j]时，利用先前的结果计算f(j+1)。第二个是++k，这个是当(j, k)匹配时，令f[j + 1] = k + 1，并继续外层的while循环循环计算f(j + 2)的值，直到j &gt;= m结束，m是模式串的长度。可以发现外层的j和k每次自增1，并且在等于m的时候跳出循环，这类似于对动态表添加元素的1的代价。特别地可以发现j和k的上界最高就是m。内层while循环是将k不断缩小，很难求出外循环的某次循环中内循环共循环了多少次，但是可以看出内循环体在整个函数中最多被执行m次，这是因为k最多只能加到m，所以最多只能变小m次。将外层循环视为操作序列，内层循环摊还的代价就是$O(1)$。因此这个函数的总代价是线性的。 TrieTrie（/ˈtraɪ/，字典树，前缀树）将多个字符串组成一棵有序树。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。在构造Trie树时，需要用flag数组标记每个节点是否可能是某个字符串的结尾，而不能仅靠“无路可走”来断定，例如对于单词表[b, bb]，b和bb都是合法的单词。 例题HDU 1247是Trie的简单应用，首先把每个字符串添加到Trie树上，然后对于每个字符串，搜索他的每个前缀，对于任意前缀，如果它产生的字符串属于这个单词表（碰到flag为true的节点），那么紧接着继续往下搜索看能不能搜到第二个字符串。这道题注意要搜索每个前缀，考虑下面的样例 ha hat word hatword 如果在实现时，对hatword第一次query到ha即返回，下面从tword开始就无法匹配了，由于第一次query已返回，所以也不会继续搜索前缀hat了。 AC自动机AC自动机（Aho-Corasick automation）能够匹配多个字符串，可以用来在线性时间内解答字符串S中出现了哪些字典D中的模式串的问题。从算法思想上来看，AC自动机结合了Trie和KMP的思路，虽然它的出现甚至要比KMP早。对我来说AC自动机的思想显得比KMP“自然”点，我们在Trie树上走，如果走不下去（失配）了，我们就回退到某个上层的节点。在这点上和KMP很相近，因为KMP也不回退文本串。于是现在我们要高效的求出在失配时是需要回退到的节点，也就是为所有节点生成失配指针。显然我们的高效算法能够利用先前节点的结论，所以我们以BFS的顺序来访问这个树上的所有节点。首先root的失配指针肯定是NULL，root都失配那就无路可走了。我们按照下面的规则生成失配指针，假设从状态S1通过读取字符x可以到达状态S2，我们现在计算状态S2上的失配指针。首先我们查看S1的失配指针指向的状态节点F1，注意F1不一定是S1的父节点，有可能在Trie的另一个分支上，所以我们需要BFS而不是DFS。接下来我们查看F1能不能通过x走到它的一个儿子节点F2，如果能，那么就更新S2的失配指针为F2，如果不能我们就沿着这个F1的失配指针继续网上找。容易看出现在root的前缀指针None显得不太合群了，因为root所有的子节点的失配指针都应当是root，而按照上面的规则会被计算成是自己。 后缀数组字符串S[0..n-1]后缀是指的形如S[i..n-1]的字符串。后缀数组P[0..n-1]给出了S的所有后缀S[i..n-1]经过字典排序后的起始下标i。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>字符串</tag>
        <tag>KMP</tag>
        <tag>AC自动机</tag>
        <tag>Trie</tag>
        <tag>摊还分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最大流]]></title>
    <url>%2F2016%2F10%2F14%2F%E6%9C%80%E5%A4%A7%E6%B5%81%2F</url>
    <content type="text"><![CDATA[总结一下最大流的各种算法 最大流问题设赋权有向图 $D(V,E,C)$，其中每一条边的权值$c \in C$表示这条边的容量。流$f: V * V \rightarrow R$是对于边$e \in E$的函数。我们定义唯一的开始节点$S$是源，只发出流量；唯一的结束节点$T$是汇，只接受流量。一个流网络具有以下的形式 流入流量取正号，流出流量取负号 每条边的流量$|f(u,v)|$不能超过容量 流经中间节点的流量无损耗 形式化的表述如下$$f(u, v) = -f(v,u) \\f(u, v) \le c(u,v) \\Σf(u, *) = 0, u \notin \{S, T\} \\$$ 特别注意对于条件1，可以得到只要有向边$(u,v)$上存在流$f(u,v)$，那有向边$(v,u)$上必然存在$f(v,u) = -f(u,v)$。特别地该边不存在的情况可以表示成$c(v,u)=0$，但是实际上我们只考虑流量为正的边，所以在一些教程上也只画出了这样的边。最大流问题就是求解通过流网络从源$S$能够流出的最大流量，也就是汇$T$能够得到的最大流量。 Ford Fulkerson方法最大流最小割定理对于网络流$G(V,E)$，以下命题等价： $f$是$G$的最大流 残余网络不存在增广路径 最大流=最小割 残量网络残量网络是一个双向图。定义剩余容量$cv(u,v)$$$c(u,v) - f(u,v) \qquad 若(u,v) \in E$$由cv为权的新有向图称为残量网络。并且当$f(u,v)$为负数时，$cv(u,v)$会大于$c(u,v)$。 增广路径Ford Fulkerson方法的Edmonds Karp实现与朴素Ford-Fulkerson算法不同的是Edmonds-Karp要求每次找长度最短的增广路径，即使用BFS查找增广路径。时间复杂度是$O(n m^2)$，空间复杂度是$O(n^2)$。 Dinic算法SAP算法]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDU 5889 Barricade 最大流最小割+BFS]]></title>
    <url>%2F2016%2F10%2F13%2FHDU5889Barricade%2F</url>
    <content type="text"><![CDATA[ACM/ICPC 2016 青岛网络赛赛题 Barricade 题意有图G(N, M)，每条边具有相同的长度和不同的权值。现在有敌人从点N沿最短长度路径到点1。现在要求在部分边上设置障碍，使敌人无论怎么走总能碰到障碍，求这些切断的边的最小权值之和。 思路分析因为敌人走最短路径，所以要建立新图，新图中只能保留死路和最短路径。因为每条路的长度都相等，所以可以采用bfs来寻找最短路径。在建立新图之后对新图用网络流即可。从点N开始使用dis记录到各点最短路。当bfs到点x，尝试使用点x松弛所有相连点i并在新图中添加路径(x,i)；但当bfs到点1并且点当前点x的长度大于dis[i]（广度优先搜索总是最短路的），则不使用该点更新dis。这样得到的图只含有死路（在得到dis[i]前bfs的部分）和最短路径。代码 需要注意的地方有几个地方需要注意： 第一个是使用bfs建立新图时 第二个是这道题源是N，汇是1，是反过来的 第三个因为最短路，所以只要添加单向边就好。 在bfs更新dis的时候我把u和v搞反了。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ACM/ICPC 2013 杭州邀请赛]]></title>
    <url>%2F2016%2F10%2F13%2FICPC2013%E6%9D%AD%E5%B7%9E%E9%82%80%E8%AF%B7%E8%B5%9B%2F</url>
    <content type="text"><![CDATA[ACM/ICPC 2013 杭州邀请赛复现 1010 Shaolin题意少林寺和尚上山需要比武，每个和尚具有id和武力值(k, g)。新和尚在比武时在已经上山的和尚中选择和自己武力值最接近的和尚比武（如果有两个就选择比自己弱的那个），现在给定和尚上山顺序，对于每个和尚计算应该和谁比武。 解答模拟，考虑到set是自动排序的，因此可以使用两个set分别存正序和逆序，然后分别lower_bound，注意处理只有一个武力值最大/最小的情况。代码 1009 Building bridges题意有一个m行n列的矩阵上有C岛H岛和O海洋。现在要在H和C之间建一个曼哈顿距离最短的桥。要求输出选择的H岛的坐标(x1,y1)和C岛坐标(x2,y2)，在曼哈顿距离相同的情况下依次按照x1, y1, x2, y2从小到大进行排序。 解答直接爆搜O(n^2*m^2)。代码 1001 Robot题意有一个1..n的环，从点1开始以均等概率逆时针或顺指针走w步，问进行m次操作后，停在[l,r]区间上的概率。 分析这道题目是概率dp，假设在旋转次m时，落在环上每一点的概率可以由旋转m-1次的概率求得。比较坑的地方是这题卡常数，我的一个算法用((((1 + x) % n) + n - 1) % n) + 1求wrap，多调用了几次mod就挂了。这也提醒我一般mod使用要注意，在我的笔记本电脑上测试1s能跑5.2e7次，乘法能跑1.6e8次。代码]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ACM/ICPC 2014 广东现场赛]]></title>
    <url>%2F2016%2F10%2F13%2FICPC2014%E5%B9%BF%E4%B8%9C%2F</url>
    <content type="text"><![CDATA[ACM/ICPC 2014 广东现场赛复现 1011 How Many Maos Does the Guanxi Worth题意有N个点，要求去掉一个点使得不连通（输出Inf），如果不能做到则使得最短路径路径最长（输出该值）。 思路裸的dijkstra，增加del[disable] = true，在判断vis[j]的地方加上判断!del[j]。由于删掉一个节点导致图可能不连通，因此注意红书模板mark==-1的时候要直接return，外循环不要N次。代码 1002 The E-Pang Palace题意有小于30个点，找出两个（必须是两个）不相邻、不相交的矩形。求面积并的最大值。 思路用vector&lt;int&gt; corx，cory记录出现过的坐标，并排序。用bool hit[x][y]表示点(x, y)是否出现过。在corx和cory中枚举出x1, x2, y1, y2（x1 != x2, y1 != y2）。如果点(x1, y1)和点(x2, y2)存在，那么将矩形添加到vector&lt;RECT&gt; vecrect中。接着分别检测相交（矩形1有一个点在矩形2里面）、相邻（横坐标相等，一个矩形纵坐标左边在另一个矩形的两个纵坐标中间）。这里如果实现保证struct RECT中x1 &lt; x2 &amp;&amp; y1 &lt; y2，会比较方便。但是还是WA，后来发现矩形1在矩形2内也算对的。我觉得这就比较坑了，因为题意是圈地分封，如果两个矩形成包含关系怎么分封呢？代码 1009 Little Zu Chongzhi’s Triangles题意有N个长度不等的线段，问能够组成的所有三角形最大面积和是多少，棒子不一定要全部用完。 思路贪心（当然这条数据较小也可以暴力，复杂度(12,3)(9,3)(6,3)）。每次取尽可能长的边。首先对数组a从小到大排序，如果a[i], a[i - 1], a[i - 2]能够组成三角形，那么加上这一组，如果不能，考虑a[i - 1], a[i - 2], a[i - 3]（舍弃a[i]是因为根据两边之和大于第三边，a[i - 3]相对于a[i - 2]肯定更不可以了）。证明：在HDU 5914上我们得到结论一个数列上任意三条边不构成当且仅当该序列是类斐波拉契数列的子数列。代码 1005 Song Jiang’s Rank List题意给水浒英雄排座次，按杀人多少，杀人数相同按照名字字典序排列。阅读理解，水题。代码 1004 Signal Interface题意思路]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[西瓜书笔记]]></title>
    <url>%2F2016%2F10%2F12%2F%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[开始写周志华教授的《机器学习》一书的学习笔记。也包含prml等书的学习笔记。 绪论假设空间]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最长上升子序列(LIS)和最长公共子序列(LCS)]]></title>
    <url>%2F2016%2F10%2F04%2FLISLCS%2F</url>
    <content type="text"><![CDATA[区别于字符串，序列并不一定是连续的。最长上升子序列(LIS)和最长公共子序列(LCS)算法是基础的序列算法。 最长公共子序列(LCS)这是一个经典的dp问题，使用dp[i][j]表示表示序列X的i位和序列Y的j位之前的最长公共子序列的长度。那么如果X[i] == Y[j]，dp[i][j] = dp[i+1][j+1] + 1；否则dp[i][j] = max{d[[i-1][j], dp[i][j-1], dp[i-1][j-1]}。 例题 POJ 1458 Common Subsequence第一次写成这样。应该是这样 最长上升子序列(LIS)$O(n^2)$方法运用动态规划的方法，记录$ l_i $为序列$a_{1..(i-1)}$中前$i - 1$个数中最长的上升序列长度。现在需求$l_i$，考虑将$a_i$插在以$i$前面的某个元素$a_j$的结尾的子序列的后面，那么就是要满足以下条件： $a_i &gt; a_j$ ，这是显然和必须的，否则这个序列就不是上升子序列 $l_j$最长 因此，对于$a_{i+1}$，需要找出最大的$l[m]$并且$a[m] &lt; a[i]$。可以发现复杂度为$O(n^2)$。容易发现，寻找最大的$l_j$可以使用二分法。因此可以得到下面的$O(NlogN)$方法。 区间段问题为了更好地理解下面的$O(NlogN)$方法，可以考虑有若干个任务具有不同的起止时间，在同一时间只能做同一任务，并且该任务完成后才能开始新的任务。现在要求找出能够完成的最多任务数。容易想到这是一个贪心问题。事实上每次选取结束时间最早的任务，这样保证了剩下的时间短尽可能地长，而一个较长的时间段肯定比它的较短的部分的可选工作数要多（至少不会变少）。 O(NlogN)方法这个方法与区间段问题的思想类似，要使得上升子序列最长，就要使得序列上升尽可能慢，因此我们希望每次在序列最后加上的数尽可能小，当然由于数列的长度是有限的，所以不一定这样能得到足够长的LIS序列，所以我们在确定新得到的LIS数列足够长的时候再更新长度。因此我们记录$dp[i]$为长度为$i$的LIS序列的末尾元素的值，使用动态规划依次计算$dp[1..n]$。我们使用$len$记录目前最长LIS的长度，显然$dp[i]$关于$i$是单调不减的。这是因为如果我们假设$dp[i] = 3$、$dp[i - 1] = 4$，那么$dp[i]$还多取一个数，所以也至少应该取到4。当使用$a[j]$更新$dp$时，我们顺着$dp[1]$开始找，一旦发现$dp[i-1] &lt; a[j] &lt; dp[i]$，那么可以用$a[j]$更新$dp[i]$，同时如果当前的$i$（从1开始）大于记录的$len$时，用$i$更新$len$。需要注意的是，虽然在原序列中$a[j]$出现在$dp[i]$对应的$a[j]’$之后，如果$a[j]$包含在序列中，那么比$a[j]$大的$a[j]’$显然不会包含在序列中，但是这不影响取得最大值，因为除非从$a[j]$开始的新序列能够去得更长的$len$，否则仍然取得的是当前的序列。此外，在找到$j$之后不要更新后面的$dp[i + 1..n]$，因为每取一个$a$，向后面递推一次$dp$。在寻找时，考虑到dp是一个不降序列，可以使用lower_bound函数（内部采用二分查找）。这个函数将会返回大于等于val的第一个值的指针，如果不存在就返回end指针，在使用时候注意区别upper_bound函数，upper_bound函数返回的是严格大于val的第一个值。注意指针的差值从0开始，但是序列长度从1开始，所以得到的差值转换成长度要加1。 例题 HDU 5532 Almost Sorted Array此题题意要求找出一个序列是否可以去掉最多一个元素形成一个sorted array。因此可以正反（考虑到可能是不升序列也可能是不降序列）求一次LIS（不降子序列），那求出的最长上升子序列的长度至少要大于等于n-1那么就是满足题意的。当然这道题目也可以用O(n)实现。O(n)算法需要注意不能只判断连续情况。 最长公共上升子序列(LCIS)]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>动态规划</tag>
        <tag>序列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDU 5914 Triangle]]></title>
    <url>%2F2016%2F10%2F04%2FHDU5914Triangle%2F</url>
    <content type="text"><![CDATA[这道题来自HDU 5914/ CCPC2016 长春现场赛 Triangle这道题目一开始想的是打表的解法，后来发现一直WA。后来找规律发现是斐波拉契数列。 题意有边长[1..n]（n不超过20）的边，问最少去掉几个边才能使得剩下的边不能组成三角形。 证明充分性：斐波拉契数列的任意项$l_i$，$l_j$，$l_k$均不构成三角形。由于任意三角形三边$a$、$b$、$c$，其中（$a &lt; b &lt; c$）均需要满足$a + b &lt; c$。而对于斐波拉契数列中任意的边$l_{k-2} + l_{k-1} = max(l_i + l_j) = l_k, i, j &lt; k$ ，因此不可能存在构成三角形。必要性：在斐波拉契数列中增加任意一项，则可以构成至少一个三角形。假设添加边长$m$在$l_i$和$l_{i+1}$之间，由于$l_i + l_{i+1} = l_{i+2}$ ，因此 $l_i + m &gt; l_{i+2}$，因此至少构成一个三角形。特别地，形如1, 3, 4, 7, 11…或者2, 5, 7, 12…等数列同样具有斐波拉契数列$f[i] = f[i - 1] + f[i - 2]$的性质，但是以$1, 1, …$开始的斐波拉契数列显然“利用率”最大。 打表方法之前有试过贪心打表方法，具体地，对于每个n，枚举出所有的三角形，统计出在三角形中出现最多次数的边（如果次数相等则进行dfs搜索），不断剔除边和，并移除该边对应的三角形，直到所有三角形都被移除。但事实上这种方法是不行的。例如对n=13，算法分别移除9（出现40次）、10（40）、8（39）、11（38）、6（34）、4（25）、12（35）、3（18），但却没有移除13（30）。其构成的1, 2, 5, 7, 13并不是最优的数列。]]></content>
      <tags>
        <tag>ACM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDU 5553 Advanced Calculator 表达式求值]]></title>
    <url>%2F2016%2F10%2F01%2FHDU5553Advanced-Calculator%2F</url>
    <content type="text"><![CDATA[这道题来自HDU 5553/ ICPC2015 合肥现场赛 Advanced Calculator，现场赛无人做（那场1题Cu，2题Ag，4题Au）。截至目前HDU上只有三人过这条。我现在还没有过这条，所以想贴出来我的想法、遇到的一些坑和代码http://paste.ubuntu.com/23275313/，也希望有大神能给我一点测试数据什么的。这道题就是表达式求值，运算符有+、-、*、/、(、)、=（可以连等）。操作数分为int和double。同时有唯一输出函数print。通常想到的办法就是逆波兰式。 逆波兰式基本的逆波兰式逆波兰式将中缀表达式转换为后缀形式。首先需要两个栈，表达式栈tok储存后缀表达式结果，栈ops用来暂时存放运算符。遇到变量的时候直接入tok栈。遇到运算符比较当前运算符op和ops.top()运算符的优先级。如果当前运算符op优先级大，则将op直接入栈ops；如果当前运算符优先级小于等于则依次弹出ops栈中运算符并入tok栈，直到栈空。特别地，当ops栈顶是左括号(时候，可以认为左括号优先级最小，因此当前运算符op可以直接入ops栈。在当前符号是右括号)的时候，弹出ops运算符中并入表达式栈，直到看到左括号(。 处理单目运算符有两个单目运算符正号+和负号-，同时他们也身兼二目运算符加法和减法的作用。为了区别这两个运算符，需要增加bool Arity2来记录是否在每个操作符前面出现了操作数，如果出现了，则是二目运算符。特别地，唯一的函数print可以作为一个单目运算符处理，实际上对于逆波兰表达式而言，函数本身就应当作为一个运算符，只是参数数目要以逗号数目确定。 不同数据类型的四则运算首先是数据的存储，对于运算数存储，一种方法是采用union来合并double和int，同时使用type来记录类型信息，不过这里考虑到可能存在的精度问题，以及将变量和常量统一起来，这里采用string val来记录数据，对于常量val为其字面值，对于变量，val为器变量名，对应值查表slots。对于运算符，直接采用char op存储。同时采用struct Item来把运算数和运算符统一，这样方便统一栈操作。 已知的坑不同数据类型的连等号考虑以下代码:1234int a;double b;b = a = 1 + 1.5;print(b); 结果应该a=2，b=2.000000而不是2.500000。 使用double2string转换丢失精度在进行计算的时候，采用sprintf和sscanf进行string和valuetype之间的转换。根据cppreference对sprintf的说明： Precision specifies the minimum number of digits to appear after the decimal point character. The default precision is 6.可以发现从string到double必须人为指定一个较长的数精度，这里指定了30位的小数。 It should be noticed that not all C— programs should contain variable statements变量是可以没有声明的直接引用的，这时候默认变量的值是0。 string::substr这个错误是经常犯的，substr的第二个参数是长度，而不是结束为止。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分图匹配]]></title>
    <url>%2F2016%2F08%2F21%2F%E4%BA%8C%E5%88%86%E5%9B%BE%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[总结一下二分图匹配的几种算法 定义把图的顶点分为不相交集合U和V，不存在连接U或V内部点的边，这样的图成为二分图（bipartite graph）。二分图有一些性质，如二分图中不存在奇数条边的环（奇圈），因为环必须首尾相接的，奇数条边必定会使首和尾分处于U和V中。如果我们对二分图进行DFS，那么每一次都是从U到V或者从V到U，这个性质可以被用来判断是否是二分图（DFS到vis[next]和自己的vis[cur]相等就说明不是）。匹配是对于边而言的，表示在所有的边中，任意两条边都没有公共顶点。如果一个图中的所有顶点都能够构成匹配，则称这个图存在完美匹配，否则这个图只存在最大匹配，含有尽可能多的匹配边数。一个点被当前匹配饱和指这个点在当前匹配的某个边上。 匈牙利算法算法介绍匈牙利算法试图优化当前的匹配，得到边数+1的匹配。构造的方式是从一个非饱和点（也称为非匹配点，saturated vertex）开始，依次通过非匹配边、匹配边、非匹配边…（这样非匹配边和匹配边交替形成的路径叫做交替路）。容易发现这样的路径总结束于一个到非饱和点的非匹配边，因为到达于一个匹配点，如果轮到走该点关联的那条匹配边，这样要么走完完美匹配，要么到达另一个匹配点。如果轮到走非匹配边，则可能到达一个匹配点（回到上个情况），也可能到达一个非饱和点，但是非饱和点肯定是不能继续走匹配边形成更长的交替路的，于是结束。可以发现，这样走下来非匹配边始终比匹配边多一条，并且除了一头一尾的两个节点，中间节点全部是匹配点，如果反向匹配边和非匹配边，就能够得到边数+1的匹配。因此把这条起点和终点未饱和的交替路称为增广路。可以发现这样的增广路中每个点至多出现一次，因此反向匹配边和非匹配边后不会出现一个点有两个匹配边连接的情况，并且增广路的长度总是奇数，并且总是起于二分图的一端，终于二分图的另一端。根据berge定理，如果图G中不存在对匹配M的增广路，那么该匹配M是最大匹配。 算法实现在实现匈牙利算法时，并不需要显式地去建立交替路，交替路的扩展和反转通过dfs（或者bfs）隐式地表现出来。这样的算法复杂度O(EV)，经过优化的Hopcroft-Karp算法复杂度可达到O(E*sqrt(V))。首先实现寻找增广路径的算法。从节点U（大写表示二分图左部）进行dfs寻找从U开始的增广路（因为从U开始，所以U必然要是非饱和点）。对于U的所有出边(U, v)，假如v是非饱和点，那么可以直接匹配U和v，显然匹配数会增加1。假如v已经和W匹配，但是能够为W在右部找到另一个匹配点x，那么就将U和v匹配。即对于这一种情况，匹配数同样是增加1的，假设原先(W, v)是匹配的，如果现在匹配U和v，则W失去匹配，匹配数并没有增加，但是如果能够找到另一个x能够和W匹配，那匹配数增加1，当然这个过程是递归的（因此匈牙利算法寻找增广路使用dfs实现），x和W匹配同样可能导致x的原配失配，因此这个算法的返回值是个表示是否存在增广路的布尔量，如果在递归的末端存在x的匹配Y不能找到新的匹配，也就是不存在从x开始的增广路，那么也不存在从v开始的增广路。对于其他情况就不存在从U开始的增广路。因此整个算法可以枚举二分图左边的点x，寻找是否存在增广路，从而得到匹配。在实现算法的时候需要注意对于有向图邻接矩阵不能设置m[dest][src]。下表给出了一个匈牙利算法的实例，其中红色点表示已经匹配了的点。增广路搜索始终从左端开始，因此从左侧到右侧是搜索的是不在当前匹配M中的边，从右侧到左侧是在当前匹配M中的边 初始情况 寻找增广路 新的匹配 例题 HDU2063代码 Hopcroft-Karp算法算法介绍匈牙利算法使用dfs寻找增广路，Hopcroft-Karp算法作为改进使用bfs寻找增广路，bfs相对dfs的优势是找到的增广路永远是最短的。因此Hopcroft-Karp每轮按层搜索多条无公共顶点的增广路并全部替换。算法流程如下： 将所有未饱和的左侧顶点作为第0层 对于偶数层顶点，通过不在当前匹配中的边寻找 对于奇数层顶点，通过在当前匹配中的边寻找 当发现未饱和右部顶点，或搜完全部顶点，bfs终止 如果搜到未饱和的右侧顶点，进行反向dfs，搜索回第一层的某个点，这样形成一条增广路。将这条增广路加入匹配，并临时删除这条路上的点和边。重复此步操作直到无法到达第0层。重新开始bfs。 算法实现Edmonds算法以上两种算法只可以在二分图上使用，这是因为二分图不会包含奇圈。 学习资料 Wikipedia 南京大学程龚讲义]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[沙盒跳出]]></title>
    <url>%2F2016%2F08%2F21%2F%E6%B2%99%E7%9B%92%E8%B7%B3%E5%87%BA%2F</url>
    <content type="text"><![CDATA[因为参加在上海举办的计算机设计大赛决赛，今天没事所以去了上海科技馆，我们观赏了多个展区之余尝试突破展览馆中计算机展览程序的沙盒，并玩一盘扫雷游戏。首先在物理展区，我们遇到一个运行着全屏课件程序的计算机，只提供了一个鼠标，系统是winxp。在查看多个界面后，我们发现在留言区有一个切换输入法的按钮，于是我们切换成微软全拼输入法，于是屏幕上出现输入法的浮动窗，右击菜单随便选择一个选项，桌面弹出一个窗口，同时出现了任务栏，切换输入法找出软键盘，运行winmine即可。在3d打印区，我们遇到了一个被ClipCursor的win7计算机，提供了一个全键盘，但是功能键（如win键，ctrl+alt键等）全部被锁了。同时展览程序的窗体被持续设置了焦点。对于这台计算机，我们采用了连按5次shift开启粘滞键的方法，对于win7系统，粘滞键启动会导致弹出一个提醒框，点击提醒框中提示即可打开新的窗口并显示任务栏。在体验区，我们遇到了一个全屏的chrome程序，只提供了一个鼠标，我们找到一个有滑动条的页面，右击滑动条选择另存为，再在框中右击选择属性，即可看到桌面。]]></content>
      <tags>
        <tag>沙盒</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tarjan算法]]></title>
    <url>%2F2016%2F08%2F21%2Ftarjan%2F</url>
    <content type="text"><![CDATA[有向图的强连通分量是一个极大强连通子图。一个强连通子图是一个节点集合，使得集合中的任意两个点互相可达。本文介绍有向图强连通分量的tarjan算法，并且提供了理解tarjan算法所需要的前置DFS知识。直观上来讲，tarjan算法对有向图建立搜索树，每一个连通分量都是该搜索树的一棵子树。在无向图中查找连通分量时，我们常借助于dfs，那么在有向图查找强连通分量时，我们也使用了借助于dfs的tarjan算法。tarjan算法由一个dfs构成，在dfs过程中，将访问过的节点压入一个栈中，栈顶到栈中的的某个元素构成一个极大强连通分量。 DFS相关知识补充相对于先前简单的vis数组，首先要介绍DFS的黑白灰染色法，我们规定当节点未被发现时为白色，被发现后为灰色，在它的所有邻接链表被扫描完毕后为黑色。使用黑白灰染色法能够方便我们进行下面的讨论。tarjan算法基于DFS，我们从任意一点$p$开始遍历，在DFS的过程中会形成一棵树（或者森林），称为DFS树。假如说我们从点$u$访问到一个尚未被访问的点$v$，那么边$(u, v)$是一条树边，体现在DFS上就是$v$是$u$的儿子。同理，紧接着从$v$继续DFS到另一个未发现的点$w$，那么边$(v, w)$也是一条树边。下面我们回到节点$u$，现在我们发现从$u$居然还有一条直接到$w$的边，这里的边$(u, w)$称为前向边，可惜在DFS时所有的前向边都不会体现在DFS树中，这是因为此时$vis[w]$必然为true，因此$w$是$u$的非儿子的后代。我们考虑刚才的前向边$(u, w)$，此时$u$为灰色，因为它访问的$w$节点还没有返回；$w$为黑色，$v$也是黑色，因为它的dfs已经返回了。下面我们考虑在此之前的一个情况，当$w$还是灰色的时候，它应该已经在$u$之前发现过$(u, w)$这条边了，但是这时候$u$和$w$都是灰色，这种情况就和上面之前看到的前向边不一样了，我们称他为后向边。后向边是一个非常有用的东西，它可以用来发现环和计算下面的强连通分量。我们还需要注意到后向边的一个性质，也就是$u.d &lt; w.d$，这是显然的。除此之外，还有一种横向边，不过所幸我们的DFS中只会出现树边和后向边。 tarjan算法原理我们容易发现可以把一个强连通分量看成搜索树中的一棵子树。我们在DFS的过程中不断将我们发现的节点加入一个堆栈，这个栈其实也对应这DFS的递归。算法需要$dfn[u]=1..vertex\_count$记录对节点$u$的访问次序， 对应着算法导论中的属性$u.d$，即该节点从白变灰的时间戳，记录这个次序主要是为了处理后向边。$low[u]$记录节点$u$的最早祖先，它表示$u$或$u$的子树能够追溯到的最早的还在栈中的节点的时间戳，我们在将一个节点由灰标黑时计算该节点对应的$low$值。显然，在遍历前我们要设置初始的$dfn[u]$和$low[u]$等于时间戳$index$。当遍历后仍然是$dfn[u]==low[u]$时，$u$不存在可到达的祖先了，得到极大强连通分量。此时$u$也作为这个子树的根（并查集也有类似的性质）。这时我们考察堆栈，根离栈顶最远，永远在最后被弹出。$low[u]$在三种情况下更新： 当存在树边$(u, v)$时，应当尝试用$low[v]$更新$low[u]$。这种情况发生在节点$u$发现一个白色节点$v$的时候，此时首先会递归地调用dfs来计算$v$节点，当$v$节点的遍历完成也就是变黑后，dfs返回到我们在$u$节点的调用处，这时候我们尝试用$low[v]$和$low[u]$之间的较小值更新$low[u]$。因此$low[v]$总是先于$low[u]$被更新，可以通过$dfn[v]$是否为0判断$v$是否被访问过 当存在后向边$(u, v)$时，当此时$v$还在栈中时，应当尝试用$dfn[v]$更新$low[u]$，这里自环也被认作后向边。注意我们必须要判断在$v$是否在栈中，因为$v$可能已经是个黑色节点了，这时$(u, v)$是一条横向边。因此可以得到$low[i]$的过程123456789def tarjan(u) for each (u ,v) in E if (!dfn[v]) // 注意一定要先进行dfs tarjan(v); low[u] = min(low[u], low[v]) else if(v exist in stack) low[u] = min(low[u], dfn[v]) // 否则v属于另一个连通分量已被弹出 下面是整个tarjan算法12345678910111213void tarjan(int u)&#123; dfn[u] = low[u] = ++index; stack.push(u); update low[u] if(dfn[u] == low[u]) // 注意不要把if写在update的for each循环里面 pop stack to u // 注意是u不是dfn[u]&#125;int main()&#123; zero(dfn); for each u in V if(!dfn(u)) tarjan(u)&#125; 可以看到算法对于每个点都访问一次，由dfn(u)!=0保证，同样，对每个边$(u, v)$都访问一次。 割点与桥求割点和桥是tarjan算法的一个经典应用。 LCA Tarjan这里的LCA Trajan是一种离线算法，它首先先要进行$O(n)$得到预处理。它的思路是第一次找到两个节点的时候，如果记录了他们的最低单亲节点，那么这个单亲节点就是LCA。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp malloc lab]]></title>
    <url>%2F2016%2F08%2F12%2Fcsapp-malloc%2F</url>
    <content type="text"><![CDATA[一个动态分配器的要求是： 处理任意请求序列 这意味着我们不能对请求的先后顺序以及释放操作发生的时间（甚至是否发生）做出任何假设。 立即响应 这里不是指要实现无阻塞的分配，而是说我们的请求要是在线的，我们不能进行缓冲或者重排 使用堆 对齐 不能移动已分配的块 一个动态分配器的目标包含下面两点，我们能看到的是这两个性质往往互为trade-off。 最大化吞吐率 最大化存储器利用率 【未完待续】 内存管理的通常方法位图(bitmap)查找位图中指定长度的连续为0的串是相对较为耗时的 隐式空闲链表隐式空闲链表由表头、有效载荷和填充组成。这里填充的作用体现了分配器的策略，例如我们需要它来对付外部碎片。目前我们还没有看到链表的next指针在哪里，其实这是因为我们可以通过头部的size字段来跳转到下一个块。下图中每一个正方格表示4个字节，我们看到我们可以仅通过遍历头部就能选取下一个空闲块。搜索空闲链表有首次匹配法、下次匹配法、最佳匹配法和分离匹配法，其中分离匹配法包括Linux的伙伴系统。当我们匹配到的空闲链表块过大时，我们可能会选择切分。当分配器释放一个已分配块时，如果这个块与其他空闲块相邻就会造成假碎片(fault fragmentation)现象，我们需要进行合并(coalescing)，合并可以是立即的，也可以是推迟的。立即合并具有常数开销，但可能会造成反复的合并-分隔这样的抖动，因此推迟合并是较为常用的一种方式。为了方便地进行合并我们需要一个类似prev指针的机制。Knuth提出一种边界标记(boundary tag)技术，为每个块后面加上一个脚部，现在可以向前跳跳转了。此外，我们发现只有前面块时空闲时，我们才想要去合并，才会有访问prev的需求，于是我们可以将前面块的状态维护在当前块低三位中的另一位上，这样我们就可以取消已分配块的脚部了。 显式空闲链表隐式空闲链表的实现比较优雅，但它对块的分配（首次适配的分配时间）与堆块的总数成线性关系，所以对于通用的分配器并不适合，只能作为一种baseline。显式链表增加了prev和next指针，现在我们可以将所有的空闲块单独串联起来。现在对于串联的顺序我们也可以进行设计了，首先我们有较为简单的LIFO原则，也就是将新释放的块放到链表的头部。为了提高地址利用率，我们可以按地址顺序组织链表（现在和隐式链表的顺序相同了，但不包含已分配项）。 简单分离存储分离存储是一个非常有用的思路，我们现在将所有的块按大小分成若干不同大小的类，称为大小类(size class)。简单分离存储实际上维护了一系列链表，每个链表链接了同一个大小的所有块。我们每一次申请不分割既有块，如果没有就直接向系统请求一个chunk，分割成指定大小添加至链表中；每一次释放也不合并相邻块。这样的方式会造成大量的内存碎片（由于不分割）和外部碎片（释放后不合并）。 伙伴系统Linux使用伙伴系统进行分离适配，在Linux中每一个大小类都是2的幂，在最初的阶段只有一个$2^m$的块。对于一个长度为x的请求，我们将它向上舍入到$2^k$的幂，这个过程我们可以用(x + mask) &amp; (~mask)来表示。如果我们找不到恰巧的，就只能找到第一个能容纳的$2^j$大小的块，下面我们要在这个块中裁出$2^k$的块供分配。裁剪的方法就是不停二分，直到得到两个$2^k$大小的块为止。每一次对半的切分得到的两个块互为伙伴，我们将多余的那一份放到对应的链表中存储，容易看出只要给定地址和块大小，我们能够轻松地得到伙伴的地址。例如某块的地址为0bxxxx1000，那么它伙伴的地址一定是0bxxxx0000]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++资源管理]]></title>
    <url>%2F2016%2F08%2F05%2FC%2B%2B-Resource-Manage%2F</url>
    <content type="text"><![CDATA[对Effective C++在资源管理部分的内容进行总结。 C++运行时内存C++运行时内存主要分为data、bss(Block Started by Symbol)、stack、heap和常量区（包含init、text和rodata段）。其中bss段存储程序中未被初始化的变量（全局变量和static local），它们在程序运行开始前会被初始化为0，对应到C++中就是做了zero initialization，详见我的博文。这么做的目的是为了优化可执行文件的大小，考虑到我们未给这些变量赋值，所以他们在可执行文件并不存在实体，所谓的bss段在可执行文件中只是一个placeholder。data段则相反，存储程序中已经被初始化的变量。stack中的变量由编译器自动分配和清除，所以称作自动变量。heap区由new调用构造函数初始化，由delete调用析构函数回收。在部分文章中还将heap进一步细化出一个自由存储区，指由C系函数malloc等分配并由free等释放的内存。12345678910int very_big[100000] = &#123;1, 2&#125;; // 在.data段会产生很大的编译结果int empty[100000]; // 在.bss段// Demo in https://stackoverflow.com/questions/30838144/what-all-local-variables-goto-data-bss-segmentvoid foo(void)&#123; static char array1[256] = ""; // Goes in BSS, probably static char array2[256] = "ABCDEFXYZ"; // Goes in Data static const char string[] = "Kleptomanic Hypochondriac"; // Goes in Text, probably ...&#125; RAII可以看出对于动态分配的内存（堆和自由存储）必须能够在适当时机调用delete/free进行释放，否则会造成泄露，也有可能某处代码在先前已经delete/free了，造成悬空指针undefined behaviour。当然可以建立一张表（称为对象池）登记这些指针，当满足一些条件的时候进行删除的手动管理。一个Best Practice是通过RAII借助栈来管理对象。 复制一般对象之间的复制行为分为4种： 浅复制：浅复制也是默认复制构造函数的实现，将源对象中的成员复制到新的对象中。因此如果源对象中存在指针，那么实际上源对象和新对象是共享指针指向的对象的，这并不是一个错误的逻辑，但是问题在于新老对象都没有意识到自己和别的对象共享着资源，如果存在析构函数（除非使用手动管理，否则必然要有析构函数用来释放指针指向对象），那么必然会造成悬空指针。 深复制：需要自定义复制构造函数，在复制行为发生时递归地建立对象成员以及指针指向对象的副本。 资源控制权转移：资源占用具有排他性，这种有点类似于Rust的语义，其实应当作为移动语义来看。常见的有std::unique_ptr来维护这种语义。 资源控制权共享：对应起来看就是std::shared_ptr，但这种方案解决了资源释放的问题，对于需要共享的资源设置引用计数，当引用计数变为0时销毁对象，而不再通过构造函数。 深复制在深复制中可能存在一个问题，假设有若干个派生类继承基类Derived_i : public Base，现在有一个Base * d，但是不知道具体类型，现在希望对这个基类进行深复制。直接调用基类的复制构造函数Base p = new Base(d)显然是行不通的，这是因为C++标准规定了复制构造函数，包括构造函数都不能是虚的。StackOverflow上详细地说明了原因，这是因为C++是静态类型的，所以多态地创建对象没有意义的。常用的办法是自己定义一个clone函数。同样地，对于其他的构造函数，也是不存在多态的，因此如果需要对于不同的参数返回不同的派生类的指针，可以通过定义一个工厂函数来解决。当然对于非继承的类型，当然可以定义三个函数（复制、赋值、析构）进行深复制，假设复制对象obj，可以认为复制了一棵树，树中任何节点（成员）的析构都会导致该节点为树根的子树被删除，所以对于这棵树只能修改树根或叶子，否则会造成内存泄露。 复制构造函数和赋值构造函数复制构造函数指的形如T(const T &amp;)的构造函数，涉及到C++的复制初始化。其中复制构造函数常被定义为explicit的，此时必须显式地使用该构造函数。在C++11标准之后扩大了范围，将非explicit构造函数都称为转换构造函数。这里要区分转换构造函数T::T(const U &amp;)和类型转换运算符operator T::U()，前者是从U构造T，后者是从自己T构造U。类型转换运算符有很多的作用，常见的是实现将函数返回值加入重载决议。赋值运算符指的形如T &amp; operator=(const T &amp;)的运算符，指的是赋值而不是初始化操作。 构造创建只能在栈上构造的类这个简单，将new和delete变成私有就行 创建只能在堆上构造的类私有构造函数是可以的。这个时候要在类里面写一个static工厂方法，用来产生一个对象。或者也可以私有析构函数。 析构delete this在MFC里面经常看到delete this。C++是允许这么用的，但需要注意，delete this是这个类的最后一个调用，并且这个对象是用new来分配的。]]></content>
      <tags>
        <tag>C++</tag>
        <tag>智能指针</tag>
        <tag>RAII</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flex和bison使用]]></title>
    <url>%2F2016%2F07%2F29%2Fflex%E5%92%8Cbison%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[flex/bison是对lex/yacc的开源实现，可以方便地进行编译器构造。MSVC下的flex和bison有着win_flex和win_bison这两个封装，用起来比较方便。本文就使用flex和bison进行编译器构造时出现的一些问题进行说明，并讨论一些进阶技巧，例如重定向输入流，处理大小写不敏感代码串，yymore，代码定位，错误信息及恢复，start condition，扩栈，push parser，glr-parser，%define指令，常见语法和错误处理方法以及flex/bison生成代码分析等。 在VS2015下配置在Sourceforge上下载 win flex-bison插件。下载后解压，将custom_build_rules文件夹按照右击项目-&gt;生成依赖项-&gt;生成自定义-&gt;查找现有的-&gt;选择custom_build_rules文件夹并添加确定。由此可以创建以.l结尾的flex文件和以.y结尾的bison文件。为了能够编译，还需要讲win_flex和win_bison复制到.l和.y所在目录下面。同时工具-&gt;选项-&gt;项目和解决方案-&gt;生成并运行可以选择输出的详细级别，改成普通之上可以得到flex和bison的编译输出信息。 flex使用说明如何重定向输入流yyin可以使用yy_scan_buffer函数重定向输入流，这个函数实际上调用了void yy_switch_to_buffer函数设置static YY_BUFFER_STATE * yy_buffer_stack的栈顶YY_CURRENT_BUFFER_LVALUE下面的语句是一个完整的重定向输入流的模板，也可以参考这里的不使用yacc的模板123456789101112// std::string in_str 被扫别识别的字符串// slen字符串长度YY_BUFFER_STATE buffer = yy_scan_buffer(buff, slen + 2);char * buff = (char *)malloc(slen + 2);// 要以两个'\0'结束memset(buff, 0, slen + 2);strcpy(buff, in_str.c_str());int token = yylex();yy_delete_buffer(buffer);free(buff); 需要注意一点的是，buffer必须以”\0\0”结尾，原因是在生成文件*.flex.cpp中，函数yy_scan_buffer的部分代码如下：123456789101112131415161718YY_BUFFER_STATE yy_scan_buffer (char * base, yy_size_t size )&#123; YY_BUFFER_STATE b; if ( size &lt; 2 || base[size-2] != YY_END_OF_BUFFER_CHAR || base[size-1] != YY_END_OF_BUFFER_CHAR ) /* They forgot to leave room for the EOB's. */ return 0; b = (YY_BUFFER_STATE) yyalloc(sizeof( struct yy_buffer_state ) ); if ( ! b ) YY_FATAL_ERROR( "out of dynamic memory in yy_scan_buffer()" ); b-&gt;yy_buf_size = size - 2; /* "- 2" to take care of EOB's */ /* 初始化b的其他字段 */ yy_switch_to_buffer(b); return b; 可以看出base[size-2]和base[size-1]是有用途的。顺便看一下yy_scan_buffer返回的typedef struct yy_buffer_state *YY_BUFFER_STATE类型12345678910111213141516171819202122232425262728293031323334353637383940414243444546struct yy_buffer_state&#123; FILE *yy_input_file; char *yy_ch_buf; /* input buffer */ char *yy_buf_pos; /* current position in input buffer */ /* Size of input buffer in bytes, not including room for EOB * characters. */ yy_size_t yy_buf_size; /* Number of characters read into yy_ch_buf, not including EOB * characters. */ yy_size_t yy_n_chars; /* Whether we "own" the buffer - i.e., we know we created it, * and can realloc() it to grow it, and should free() it to * delete it. */ int yy_is_our_buffer; /* Whether this is an "interactive" input source; if so, and * if we're using stdio for input, then we want to use getc() * instead of fread(), to make sure we stop fetching input after * each newline. */ int yy_is_interactive; /* Whether we're considered to be at the beginning of a line. * If so, '^' rules will be active on the next match, otherwise * not. */ int yy_at_bol; int yy_bs_lineno; /* The line count. */ int yy_bs_column; /* The column count. */ /* Whether to try to fill the input buffer when we reach the * end of it. */ int yy_fill_buffer; int yy_buffer_status;&#125;; 可以发现这个结构储存了flex解析上下文。 如何实现迭代读取不同于bison，flex中的yylex函数默认只返回int，用来表示识别出的终结符号的类型。但是我们有时需要返回更多东西，例如终结符号本身，终结符号的位置和长度等。我们不能直接改变yylex的定义，因此可以用next_token封装yylex。假设要实现函数int next_token(std::string in_str, int start)，能够识别非终结符[start, end]，它的长度是内置变量yyleng，所在行是内置变量yylineno。首先必须要能够记录当前读取后的位置。flex是不自带这个变量的，所以必须在每个规则的识别之后自动记录此时的读取位置，方法就是定义一个全局变量pos，并在每次识别后增加yyleng。事实上我们希望next_token能够返回一个结构FlexState，这个结构能够包含识别出的终结符号本身（如+、-、变量名var_name、整数或浮点数0.5之类的），识别出终结符号的类型（META_INTEGER、META_FLOAT等），长度，行号以及位置。我们定义一个FlexState结构来组织这些信息。调用层次如下： next_token调用yylex yylex进行词法分析，如果满足某一模式(pattern)（也就是正则表达式），那么调用规则对应的处理语句（也称为动作(action)，正则表达式对应的大括号内部的C代码） 使用函数int make_term_flex在规则对应的处理语句内构造FlexState并返回。 next_token返回上步构造好的FlexState类型的全局变量flex_state特别地，如果还使用bison，因为bison直接调用yylex而不是自己设计的next_token获得词法分析的结果，所以处理语句必须返回用%token定义的YY_前缀的非终结符记号，由yacc的yyparse来返回你需要的YYSTYLE类型的值。鉴于这种情况，需要额外开一个flex_state的全局单例，在模式的处理语句中定义一个update_flex函数来更新flex_state。 关于bison的说明：bison提供了符号在代码串的定位功能，详见本文的bison部分。 yymoreyymore是一个flag，表明保留当前的结果yytext，等到读入下一个字符串时进行连接。例如当前读到的yytext是a，下一个字符是b，调用yymore以后下一次的读取yytext就会变成ab。调用yymore函数只会设置一个flag，并不立即读取下面的字符并进行拼接。注意区分yymore和没有return的处理语句的关系。首先flex在编译时直接将处理语句大括号内的部分复制到yylex函数中的某个位置，所以return实际上是return的yylex函数。没有return只是yylex函数继续运行，进行下一轮的扫描；但是yymore是设置一个flag，表明不要清空yytext，依旧可以return返回，虽然这样做没有意义。事实上处理语句不return是个相当有用的特性，有了这个并不需要yymore，只需要在全局记录一下本次的yytext到字符串s，在下一次查看yytext是否为空串，如果不是，返回s + yytext即可。而由于不返回了，所以在写处理语句于并不能利用函数来复用代码，而必须使用宏，同一个处理语句既可能return，有可能不return。下面给出一段代码和运行结果以供参考：123456789101112131415161718%&#123;#include &lt;stdio.h&gt;#include &lt;string&gt;%&#125;%option yymore%%"1" &#123; yymore(); ECHO; putchar('\n'); printf("yytext %s\n", yytext); &#125;"2" &#123; ECHO; putchar('\n'); &#125;\n &#123; putchar('\n'); &#125;%%int yywrap() &#123; return(1); &#125;int main() &#123; yylex(); puts("");&#125; 运行结果 111 // 输入 1 yytext 1 11 yytext 11 111 yytext 111 222 // 输入 2 2 2 233 // 输入 2 33 常常希望在bison中使用yymore去处理区分else和else if的情况，然而往往每次的yytext并没有和上次叠加，原因主要有两点：1. 规则中出现了return。2. 空格没有yymore，导致打断。 使用flex处理非正则的文法有一些特殊的词法，例如匹配的括号属于2类文法，flex所依赖正则表达式并不能正确处理这样的文法。而无论是手撸词法分析，或是直接放到语法分析阶段（可能造成归约冲突）并不是一个好办法。对于简单的情况，可以给flex“打洞”，拿出这些特例进行处理。例如可以在识别出某些开始符号后，从当前位置调用某个外部函数进行处理并返回外部函数处理的结果。这样的限制是不能处理比flex单元更小的词法单元，如果flex中有一条匹配[0-9A-Za-z_]的规则，那么要使用这种方法处理[0-9A-Za-z]的规则是不行的，需要配合yyless(n)来回退yylen - n个字符。并且最重要的一点是外部函数处理过的那一段字符串仍然会被flex程序处理，这当然可以通过yyrestart来强行解决，但是有下面更好的办法。根据StackOverflow上的一篇回答，可以通过start conditions这个功能处理这个问题。要使用start condition，首先要使用%s或者%x来声明，其中%s表示使用这个start condition时还可以同时接受普通规则；而%x，x表示exclusive，表示使用这个start condition时忽略所有的普通规则。现在使用%x format定义了名字是format的start condition，可以在规则前加上&lt;format&gt;来说明这个规则属于format condition，那么这条规则只有在使用BEGIN(format)开启format condition之后才能被匹配到。使用BEGIN(0)可以退出当前的condition，回归普通模式。下面给出一个样例：123456789101112131415161718192021222324252627%&#123;#include &lt;stdio.h&gt;#include &lt;string&gt;void do_format();%&#125;%option yymore%x format%%"format(" &#123; BEGIN(format); &#125;&lt;format&gt;[0-9]+ &#123; printf("format: %s\n", yytext); &#125;&lt;format&gt;")" &#123;BEGIN(0); &#125;[0-9]+ &#123; printf("normal: %s\n", yytext); &#125;%%void do_format() &#123; &#125;int yywrap() &#123; return(1); &#125;int main() &#123; yylex(); puts(""); system("pause");&#125; 输出结果是 111format(222)333 // 输入 normal: 111 format: 222 normal: 333 在实际处理fortran的format语句过程中，还遇到了Syntax Error的错误，产生在将整个format语句作为一个YY_FORMAT_STMT终结符return，后来发现这是因为我在word_parse函数中处理format前缀时调用get_flex_external_context().begin_external_scanner(&quot;format&quot;);来开启start condition之后并没有return YY_IGNORE_THIS所致，因为这个format前缀仍然是作为普通规则而不是start condition处理的。加上C++本身的“不是所有路径都返回值”导致的UB错误。 bison的定位功能bison提供了获取终结符行号和光标位置的功能。可以使用@n访问第n个文法符号的first_line、first_column、last_line、last_column属性，所以如果只需要这四个属性，可以不定义自己的struct，而使用bison提供的YYLTYPE。1234567typedef struct YYLTYPE&#123; int first_line; int first_column; int last_line; int last_column;&#125; YYLTYPE; 但是我仍然建议自己处理定位信息，这样的好处是在词法分析阶段就可以对源语言中与目标语言关键字冲突的符号进行转义，而不影响语法分析阶段对代码的定位。例如如果fortran中声明int变量，那会和C++中的int类型声明产生冲突，这个问题宜在词法阶段直接替换解决，但是这会带来长度的变化，因此需要单独维护原来文本的长度。 重命名yylex我们知道bison会调用yylex来获得tokenizer返回的结果，而yylex是有flex直接生成的。有时候我们不希望直接把yylex函数产生的原始结果喂给bison，而是进行加工。这时候我们可以自己定义yylex函数，而给flex自动生成的函数进行重命名 #define YY_DECL int pure_yylex(void) 此时我们就可以自定义yylex函数了，bison会调用我们自定义的yylex函数，而我们的yylex函数可以通过pure_yylex去调用flex进行分析。 特殊情况的处理 读入字符不属于任意规则 如果不加处理，这个字符会被保留，例如,www如果定义了[A-Za-z]规则但没有定义,www规则会直接返回,www,但是匹配长度还是3。虽然可以再次截取出正确的字符，但是显然这是没有必要的。因此可以在最后为任意字符.加上规则。 到达读入字符串尾端 此时yylex函数返回0，这是为了配合bison端的yyparse函数设置的 用正则表达式表达字符串 \&quot;(\\.|[^&quot;])*\&quot; 在flex的正则表达式语法中，方括号内部引号自动转义 yymore_used_but_not_detected 需要在l文件第一部分使用%token yymore显式说明需要yymore函数。 根据manual，可使用一些语法来指定大小写不敏感的规则，但是要求flex的版本要高于2.5.3，配置时，在项目属性页选择Flex Files-&gt;FlexOptions-&gt;Case-insensitive mode 找不到入口点(main函数) 注意要将flex生成的cpp文件添加进MSVC项目中 多条适配规则 当有多条规则的模式被匹配到时，yylex会选择匹配长度最长的那条规则，如果长度相等，则选择排在最前面的规则。 bison使用说明可以参考Bison的帮助文档或者Lex and YACC primer或者YACC文档 部分元素的意义 %left、%right、%token、%nonassoc %token用来声明一个终结符号的类型（META_INTEGER、META_FLOAT等），这个函数将被放到.tab.h文件中供flex程序引用，上文提到的yylex返回的int值，实际上就是在这里定义的。 此外，%left和%right用来描述运算符的优先级和结合性。考虑二义性文法：E : E + E| E - E| E * E| E / E| i，考虑1 + 2 * 3，解析完2之后直接归约或者进行移进产生了冲突。当然我们可以写成以下的无二义性文法避免+-和*/之间的移进归约冲突，当然这样带来了比较多的归约步骤， E : E + T| E - T| T T : T * F| T / F| F F : i 因此我们规定每个操作符的优先级，方法是较上行的%left（%right，%nonassoc）定义比较下行的%left（%right，%nonassoc）定义优先级要低，这样解决了不同操作符的优先级问题，而且相对于引入TF终结符，我们可以少定义一些非终结符和产生式（参加下例）。 但是对于1-2+3，分析程序仍然是不知道按照(1-2)+3还是1-(2+3)归约。因此对于同优先级的符号，用%left和%right来规定结合性。 %nonassoc表示当前操作符op是没有结合性的，也就是说不可能出现x op y op z的这种情况。 yylval，%type，YYSTYLE，%union 前面说到yylex返回值是一个int，这对于语法分析是足够的，但是对于之后的语义分析是不够的。例如对于属性文法E.val-&gt;T1.val + T2.val，我们还需要语法分析时候顺便把属性也提取出来，相比扩充状态栈，yacc提供了一个YYSTYPE类型的全局变量yylval。这个YYSTYPE的类型是个宏，可以自定义，相比flex的yylex函数只能返回int显得方便了很多。 同时，对于不同的属性，bison可以直接给出parse之后的类型。例如对于浮点123.4，yacc能够解析出123.4。这是因为bison通过%union来列出yylval返回值类型，通过%type规定对于什么非终结符返回什么类型。例如， 12345678%union&#123; int intval; double floatval; char word[20];&#125;%type &lt;intval&gt; YY_INTEGER%type &lt;floatval&gt; YY_FLOAT%type &lt;identname&gt; YY_WORD 这里%union实现上就是C++中的联合union。union不同于struct，它的所有成员时分复用存储空间，因此一个union的大小等于所有成员大小的最大值。和reinterpret_cast一样，union可以用来规避C/C++中的类型检查，实现强制转换，使用union相对使用void*避免了较多的reinterpret_cast。 %start %start用来标注开始符号，这是可选的 &lt;&lt;EOF&gt;&gt; 顾名思义，用来匹配文件结尾 bison的二义性问题解决方法bison的默认parser是LR parser，虽然LR文法是不能出现移进归约冲突和归约归约冲突的，但这不意味着bison的LR parser不能处理部分二义性问题。 悬挂if-else问题 bison在处理移进归约冲突的解决办法是默认移进。处理归约归约冲突的办法是默认使用先出现的产生式。因此bison中使用 stat：YY_IF exp YY_THEN stmt | YY_IF exp YY_THEN stmt ELSE stmt 是默认没有问题的当然也可以使用运算符优先级来解决这个问题 %nonassoc IFX %nonassoc ELSE stmt: YY_IF exp stmt %prec IFX | YY_IF exp stmt YY_ELSE stmt else if问题 可以考虑将else if合并成一个YY_ELSEIF终结符 部分语法的翻译方法换行符和空规则bison中的空规则类似下面的形式 nonterminal : non_empty {} | /* empty */ {} 空规则的意义在于必须要在处理语句内{}处理更新$$，不然$$是不确定的，可能是上一次的结果。注意如果没有显式指定处理语句，bison默认情况下把$1的值拷贝给$$。 在许多语言中，换行符用来分开两个语句stmt，而一个语句不一定占用一行，因为一个语句可以是一个表达式exp，也可以是一个复合语句，如if_stmt，do_stmt等。如果不能正确处理换行符，可能会出现各种各样的Syntax Error。比较好的做法是，定义一个suite stmt : /* 在结尾不要带上换行符 */ | /* stmt可以是空语句 */ suite : stmt end_of_stmt suite | stmt 这实际上类似于处理参数表的方法。注意往往还有一种写法是 stmt : exp end_of_stmt suite : stmt suite | stmt program : suite 这样写的坏处是容易出现list : item list这样的语句，这样的语句会给语法带来很大的不确定性，例如上面的产生式中suite是和stmt归约到新的suite还是直接归约到program是不确定的，并且在出现连续的空行的时候往往不能正确匹配。 控制结构可以参照这里提供的例程 终结符对于ascii码表中的字符终结符，如+，*等运算符，这些字符会在yylex以自身ascii码的形式返回（如果定义了相应规则或者.规则）。而一些非字符形式的终结符，例如C++中的生存空间符号::，则需要通过%token(%left，%right)定义。这也是为什么%token(%left，%right)生成的终结符对应的index从258开始的原因（避开ascii表）。当然也可以自己来定义终结符号的类型所对应的值，好处是，我们可以用值的大小表示优先级关系（虽然bison中可以用%left等语句来规定），可以用正负表示一个操作符或者一个操作数或者关键字。出于此，可以直接在%token YY_INT META_INTEGER给YY_INT赋值，而不是由Bison决定。特别注意不要重定义0，这是yylex和yyparse的结束记号。 自定义类型的yylvalyylval的类型是YYSTYPE，可以用它来保存bison中的非终结符，统一起见，flex程序中的终结符也可以封装成YYSTYPE类型。考虑到在解析过程中，bison程序通过直接调用int yylex()方法来从flex程序中获得终结符号，所以flex中程序获得的一些额外信息可以通过yylval向bison程序传递。在自定义类型YYSTYPE为non-trivial类型后，会出现不能自动扩栈等问题，应当谨慎使用。tldp文档提供了两种方案 #define YYSTYPE structXXX 可能出现错误缺少类型说明符 - 假定为 int。注意: C++ 不支持默认 int。，经查看，源码中有： 123/* for90.tab.h */// YYSTYPE is not defined, YYSTYPE_IS_DECLARED is not defined #if ! defined YYSTYPE &amp;&amp; ! defined YYSTYPE_IS_DECLARED 解决方案是不在.y和.l文件中#define，而是在一个.y和.l文件共同#include的头文件中#define。 使用%union将struct包起来 使用这种方案不需要#define YYSTYPE，同样查看源码： 123456789/* for90.tab.h */#if ! defined YYSTYPE &amp;&amp; ! defined YYSTYPE_IS_DECLAREDtypedef union YYSTYPE&#123;/* Line 387 of yacc.c */#line 16 "for90.y" FlexState fs;/* Line 387 of yacc.c */#line 139 "for90.tab.cpp" 在以上步骤之后要确认这个union的定义是有的。 可能会出现如下问题：错误 C2280 “YYSTYPE::YYSTYPE(void)”: 尝试引用已删除的函数。对应代码为: 12345/* The semantic value of the lookahead symbol. */YYSTYPE yylval YY_INITIAL_VALUE(yyval_default);和 /* The semantic value stack. */YYSTYPE yyvsa[YYINITDEPTH]; 这两个函数/数组定义要求union实现构造函数和析构函数，但是这个是不行的。后来发现union中成员必须是trivial的，也就是包含构造函数/析构函数/拷贝构造函数/赋值运算符/虚函数的类成员，在union中都是不被允许的，所以改成union的成员改成对应的指针就可以了。 实现non-trivial的YYSTYPE根据Type-Generation，似乎可以通过%define api.value.type来解决这个问题，但是需要bison 3.0的版本，win_bison似乎并不支持如果使用的是win_bison的话，最好的方法是将YYSTYPE改成对应的指针形式。这可能会带来一些内存管理上的更改，之前的RAII似乎不能够使用了，此外shared_ptr和unique_ptr也不是trivial的（但是是standard layout） 左递归和右递归的选择对一些分析方法（如自上而下的不带回朔的递归下降法）来说，左递归不是省油的灯，例如LL1递归下降分析法直接要求消除左递归。例如LR(1)这样的移进-归约形式的分析方法允许左递归，左递归（产生式右部第一个符号时非终结符）是有弊有利的。右递归文法可能会占用比较大的栈空间，因为首先要将所有的项都压入堆栈里，然后再归约。大多数时候，左递归和右递归可以交换使用。例如处理else if的产生式可以写成：12elseif_stmt : YY_ELSE YY_IF exp YY_THEN stmt | YY_ELSE YY_IF exp YY_THEN stmt elseif_stmt 对于参数表更简单：1234567argtable : exp | argtable ',' exppure_paramtable : keyvalue | pure_paramtable ',' keyvalue | pure_paramtable ',' exp /* 注意这个规则不要丢掉 */ | argtable ',' keyvalue | 它的右递归形式1234567argtable : exp | exp ',' argtablepure_paramtable : keyvalue | keyvalue ',' pure_paramtable | exp ',' pure_paramtable | keyvalue ',' argtable | 这样的文法并不能处理11, a = 2 这样的文法，因为1不是keyvalue但是无论是左递归还是右递归，由于bison不支持EBNF，所以语法分析树总是往深度方向生长的，所以最好的做法是每一次处理item op list这样的规则时，将结果得到的树压平，注意压平操作要分左递归和右递归，否则顺序可能会有问题。不过拍平操作往往伴随着很大的性能损失，所以最好为自己的YYSTYPE写好复制构造函数。 bison常见错误及调试方法使用debug模式调试12#define YYDEBUG 1#define YYERROR_VERBOSE 注意yymsgp是const char*，所以如果重新定义yyerror参数要注意。12345678# define YYSYNTAX_ERROR yysyntax_error (&amp;yymsg_alloc, &amp;yymsg, \ yyssp, yytoken) &#123; /* 以上省略 */ yyerror (yymsgp); if (yysyntax_error_status == 2) goto yyexhaustedlab; &#125; 此外还可以在项目属性页选择Flex Files-&gt;FlexOption或对应的Bison标签页中开启DEBUG模式。 使用output文件分析语法冲突在bison生成的时候可以在输出中看到类似的语句：1231&gt; BisonTarget:1&gt; Process "for90.y" bison file1&gt; for90.y: conflicts: 132 shift/reduce, 33 reduce/reduce 这表明有132个移进归约冲突和33个归约归约冲突，这在二义性部分已经有相关的论述当出现冲突的时候可以使用bison -v xxx.y命令来查看具体的冲突。该命令会生成一个xxx.output文件在output文件中，所有因为冲突无用的产生式会被中括号[]括起，通过分析，可以解决一部分的冲突 m4sugar.m4win_bison: …\data/m4sugar/m4sugar.m4: cannot open: No such file or directory这个文件在和custom_build_rules文件夹同层的data文件夹中，所以注意是否将data文件夹加入路径 yylex identifier not found注意在y文件中第一部分extern yylex声明。 memory exhausted错误首先检查语法是否出现冲突，通常出现在语法嵌套比较深，从而出现间接的无限递归的情况。例如：123456789101112suite : stmt | stmt suite | program : YY_PROGRAM _optional_name crlf suite YY_END YY_PROGRAM _optional_name crlfwrapper : function_decl | program | suitefortran_program : wrapper | wrapper fortran_program 需要去掉wrapper的suite分支其次可以通过扩栈来解决，栈的大小可以通过#define YYMAXDEPTH来指定（默认10000），但是bison只有当确定对象是trivial的时候才会去扩栈： #ifndef YYSTACKEXPANDABLE # if (! defined __cplusplus \ || (defined YYSTYPE_IS_TRIVIAL &amp;&amp; YYSTYPE_IS_TRIVIAL)) # define YYSTACKEXPANDABLE 1 # else # define YYSTACKEXPANDABLE 0 # endif #endif 所以更好的方式是使用#define YYINITDEPTH来规定初始栈的大小（默认200） bison生成代码.tab.cpp分析有的时候会出现可能会导致Syntax Error，检查tab.cpp中的代码，发现123456789101112131415161718192021222324if (yychar &lt;= YYEOF) &#123; yychar = yytoken = YYEOF; YYDPRINTF ((stderr, "Now at end of input.\n")); &#125;else &#123; yytoken = YYTRANSLATE (yychar); YY_SYMBOL_PRINT ("Next token is", yytoken, &amp;yylval, &amp;yylloc); &#125;/* If the proper action on seeing token YYTOKEN is to reduce or to detect an error, take that action. */yyn += yytoken;if (yyn &lt; 0 || YYLAST &lt; yyn || yycheck[yyn] != yytoken) goto yydefault;yyn = yytable[yyn];if (yyn &lt;= 0) &#123; if (yytable_value_is_error (yyn)) goto yyerrlab; yyn = -yyn; goto yyreduce; &#125; 其中yycheck[yyn] != yytoken这个条件是不满足的。这个时候就需要查看bison对.y文件经过编译结果，也就是.tab.cpp文件。其中有一些数组对debug来说比较重要，要了解这些数组的用途，对于LALR(1)文法应当理解。 bison的GLR parser有的时候语法冲突是很难解决的，这时候与其去死扣语法，不如使用bison提供的GLR parser加上%define %glr-parser可以使用GLR parser。 flex/bison和antlr比较ANTLR(Another Tool for Language Recognition)顾名思义是另一个生成工具，相比bison是LALR/GLR，ANTLR是LL/ALL/SLL的，不过它对传统的LL文法解析做了优化。例如ALL算法能够在LL遇到多个可能分支的时候对每个分支启动一个DFA直到产生匹配，而这种DFA也是可以缓存的。此外，ANTLR能够解决一些直接左递归。ANTLR在解决冲突时和bison差不多，例如它规定了优先级按照规则的先后顺序而优先匹配，也可以指定符号的结合性。非常好的是ANTLR提供了在语义层面解决冲突的方法。ANTLR还支持Channel，也就是处理类似注释这种与上下文无关，但有可能出现在任何地方的非终结符，在flex+bison中，我是在词法分析阶段抽出来做的，而ANTLR可以发送给通道，并在目标代码生成时进行处理。ANTLR还可以解决上面需要借助flex中的start condition才能解决的同一代码文件中不同语言和不同语言版本（例如我遇到的Fortran77/90混杂）的问题，也就是借助于语义或者mode语句。]]></content>
      <tags>
        <tag>编译原理</tag>
        <tag>编译器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[语法分析实战]]></title>
    <url>%2F2016%2F07%2F22%2F%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1959年，Chomsky证明了文法和自动机的等价性，由此形式语言诞生了。目前，我们主要探讨4类文法，正则文法（确定有限自动机或非确定有限自动机）、上下文无关文法（下推自动机），上下文有关文法（线性有界自动机）、无限制文法（图灵机）。有限自动机具有有限种状态。上下文无关文法(CFG, Context Free Grammar)属于二类文法，其能力等价于下推自动机(PDA)。相对于三类文法即正则文法，上下文无关文法能够对非终结符做状态转移。图灵机的状态也是有限的。图灵机的“内存”不是栈，而是纸带，由此可以看做是有两个栈的PDA。自上而下和自下而上是两种常用的上下文无关文法分析方法。自上而下的方法的难点在于选择哪个产生式进行推导，自下而上的分析方法难点在于在不同的格局下选择移进或归约的矛盾。 本文定义和基础概念 文法G[S] 以S为开始符号的文法 拓广文法G&#39;[S&#39;] LR分析中用到的，相对原文法增加了S&#39; -&gt; S，从而保证开始符号始终在左部。 符号串 V 表示文法的符号表，包含终结符和非终结符。 V* 称为V的闭包。 表示V上所有有穷长串的集合。 大写英文字母，如A、B、C 表示非终结符 小写英文字母，如a、b、c 表示终结符 希腊字母，如α、β、γ 表示符号串，由若干（可以为0）个文法符号（终结符和非终结符）构成。 箭头-&gt; 表示产生式。产生式一般为α -&gt; β，其中α必须包含一个非终结符。 箭头=&gt; 表示推导。 其中=&gt;+表示经过大于等于1步的推导；=&gt;*表示经过大于等于0步推导。 =&gt;R表示最右推导，其实也就是规范推导。 =&gt;*R就是上面的结合了。 箭头&lt;= 表示归约 句型α：推导过程中生成的产生式 句型可以包含终结符或者非终结符，也可以是空串。例如在S-&gt;A-&gt;aB-&gt;ab中，A、aB、ab都是句型。 规范句型：即右句型，最右推导得到的句型 句子：不包含非终结符的句型 推导 从开始符号推导出和输入串相匹配的句子。 最右推导称为规范推导，指每次选择句型最右边的非终结符进行推导。 归约 用非终结符代替一段文法符号串，这是和推导的相反过程。通常需要解决两个问题，一是何时进行归约（可能导致移进-归约冲突），二是使用哪一个产生式进行归约（可能导致归约-归约冲突）。 最左归约称为规范归约，表示自左向右的归约过程。 下面的一些定义，被用在《自下而上的分析方法》这一章节中，但我们提上来讲一下。 短语 短语、直接短语和句柄，这三个概念的范围是依次缩小的。 短语指的是一个符号串，一个句型的语法树中任一子树叶节点所组成的符号串γ都是该句型的短语。我们称γ为这个句型相对于A的短语，其中A为该子树对应的非终结符。 形式化地，对于文法G的起始符号S，如果满足下面两个条件，则β是句型αβδ相对于非终结符A的短语。 12S =&gt;* αAδA =&gt;+ β 可以发现，这个条件简而言之就是说从开始符号S能够推到包含非终结符A的句型，并且这个句型中的A能够被推导到符号串β，那么符号串β就是相对于非终结符A的短语。 直接短语 直接短语更进一步，要求选择的子树不应该含有其他子树，即它的孩子全部都是叶子。 形式化地，如果满足A =&gt; β，则β是句型αβδ相对于规则A -&gt; β的直接短语。 值得注意的是这并不意味着这些叶子都是终结符。 句柄 句柄是最左直接短语。 句柄又被称为“可规约串”，不同于自上而下的分析，自下而上的分析方法总是等到句柄出现后进行归约。 语法分析器在读取输入串的每一个符号时要选择对这个符号是移进还是归约、按那个产生式规约（LR0，SLR1，LR1，LALR1文法的差别体现于此）。但无论如何先要找到句柄，因此引入活前缀的概念。 我们总结一下，考虑文法G[E]（可参考清华大学编译原理一书中的2.6.3），其中文法开始符号为E。123E -&gt; T| E + TT -&gt; F| T * FF -&gt; (E)| i 我们研究针对这个文法的下列句型，此处i1/i2/i3其实都是i，后缀是用来标识具体是哪一个i，方便讨论。1i1 * i2 + i3 容易看出 i1是这个句型相对于非终结符F的短语。 12E =&gt;* F * i2 + i3F =&gt; i 进一步地，因为F =&gt; i是一步，所以i1同时也是F -&gt; i规则的直接短语。 进一步地，i1是最左直接短语，也就是句柄 对于i2、i3，也能得到类似的结论，但它们不是句柄。 i1是这个句型相对于非终结符T的短语。 这是因为 12E =&gt;* E + i3 =&gt; T * F + i3 =&gt;* T * i2 + i3T =&gt; F =&gt; i 但是因为 1T =&gt;+ i 所以不是直接短语 i2 + i3不是这个句型的短语。 这是因为，虽然有 1E =&gt;+ i2 + i3 但是没有下面的推导 1E =&gt; i1 * E 文法介绍正则文法产生式具有下面格式的是正则文法：123A -&gt; aA -&gt; aBC -&gt; ε DFA和NFA可以通过子集法将NFA转化为DFA。方法分为2步： 找到ε-closure 从开始节点开始，对于NFA中的每一个节点，找到它能通过ε规则到达的所有节点。 这是一个递归的过程。 把这些closure作为新的DFA节点 可以参考Leetcode 10。 上下文无关文法C不是上下文无关语言，因为它们都要求标识符的声明先于引用，并且允许标识符任意长。由于这一点，描述这些语言语法的文法只是用id这样的记号来代表所有的标识符，而在这些语言的编译器中，由语义分析阶段检查标识符的声明必须先于引用。同样VB和Fortran也不是上下文无关语言，因为A(i)可能是数组或者函数，这同样需要语义分析程序进行处理。在我的CFortranTranslator中，在语法分析阶段把数组的slice和dimension部分看作一种特殊形式的参数表进行处理，从而实现和函数的同意。事实上，很多需要用更强的文法分析方法的问题可以在语义阶段较轻松地解决。 上下文无关文法和下推自动机的等价性 证明如果一个语言是上下文无关语言，那么我们能够构造一个NPDA对语言中的任何符号串产生一个最左推导。 上下文有关文法相比上下文无关文法，上下文有关文法允许产生式的左边同时有终结符和非终结符，例如1αAβ -&gt; αγβ 自上而下的分析方法自顶向下分析方法相对来说比较符合人的思维（我们交谈时一个句子听到一点中能估计到大概的意思，而不是要把一句话听完才能恍然大悟），编译器写起来也方便。自上而下的分析方法分为非确定的和确定的两种，确定指的是根据当前的输入符号，选择用来推导产生式是唯一确定的；对应的，非确定的自顶向下分析可以在关于一个非终结符有多个候选产生式的时候进行回溯，效率较低。确定的分析方法对文法要求较高，例如文法中就不能出现左递归和左公因子。 递归下降法LL(1)预测分析法LL分析（以下出现的LL分析指代LL(1)分析），是一种确定的自顶向下分析技术，确定体现在在推导过程中可以完全按照当前的输入符号（或者再向前看k-1个符号）决定哪个产生式向下推导。一般手写LL分析是很方便的，这是因为在语法分析的同时可以借助于语义分析来避免潜在的语法冲突。而常常借助于程序生成解析器的LR方法并不容易在里面嵌入语义分析模块。 FIRST集FIRST集是对于一个句型α来讲的，得到一个终结符集合。FIRST集表示一个句型所有可能的第一个非终结符。注意如果α可推导为ε，则ε也属于FIRST集。可以得到所有文法符号的FIRST(Xi)集的生成方法： 终结符的VT的FIRST集是自己，这是显然的 非终结符X的FIRST集包含以下内容： 包含ε 如果X有产生式X -&gt; ε。 或者X有全部由非终结符组成的产生式X-&gt;Y1Y2...Yn，并且这些非终结符Yx全部有ε产生式Yx -&gt; ε。 包含终结符a 如果X有以a开头的产生式。 包含所有非终结符的FIRST集，但是要除去所有的ε 如果X有全部由非终结符组成的产生式，并且存在一个非终结符没有ε产生式。 例如X-&gt;Y且Y =&gt; ε，则加入FIRST(Y) - ε。 又例如X-&gt;Y1Y2且其中Y1 =&gt; ε，但不能推出Y2 =&gt; ε，则加入(FIRST(Y1) - ε) ∪ FIRST(Y2)。这是显然的，因为X-&gt;Y1Y2不能推出ε，但如果写成FIRST(Y1) ∪ FIRST(Y2)，里面就包含了ε。 FOLLOW集FOLLOW集是对于一个非终结符A来讲的。表示所有可能在A后面的终结符。在计算时，{ # }和所有A-&gt;αBβ产生始终的FIRST(β)的非空元素都属于FOLLOW(B)。当然β可能推导为空，这样的情况下也将FOLLOW(A)加入FOLLOW(B)中。然后反复直到各个FOLLOW集合不再增大。容易看出FOLLOW集的计算需要依赖FIRST集。 SELECT集SELECT集是对于一个产生式A-&gt;α而言的，返回的是终结符的集合。当读取到终结符a时，对于A的所有产生式A-&gt;α，如果终结符在a在SELECT(A-&gt;α)集合中，那么就可以用这个产生式A-&gt;α推导。显然，当推导出错时没有这样的产生式，否则有且仅有一个这样的产生式。注意，SELECT(A-&gt;α)集合中可能有多个终结符。但是，同一个终结符a只会在非终结符A的一个SELECT集中，即通过键值对&lt;A, a&gt;可以唯一确定一个产生式。容易发现SELECT(A-&gt;α)有两部分组成，一部分是α不推导为ε时候，是FIRST(α)，一部分是α推导为ε时候，是FOLLOW(α)。 将非确定的文法转换成确定的LL(1)文法提取左公因子左公因子的存在会导致SELECT集相交，这是显然的。对于显式的左公因子，直接提出来即可，如1A -&gt; αβ|αγ 可以变为12A -&gt; αA'A'-&gt; β|γ 对于隐式的左公因子（即左边以非终结符开头的情况），可以使用关于该非终结符的所有右部以终结符开头的产生式展开，例如1234A -&gt; adA -&gt; BcB -&gt; aAB -&gt; bB 展开得到12345A -&gt; adA -&gt; aAc // B =&gt; aAA -&gt; bBc // B =&gt; bBB -&gt; aAB -&gt; bB 消除左递归考虑下面的文法12A -&gt; AbA -&gt; a 可以发现对于非终结符A，并不能确定用来推导的产生式，于是只能采用非确定的递归下降法，寻找最左非终结符，于是会陷入展开A的死循环A =&gt; Ab =&gt; Abb =&gt; Abbb通过改写文法消除左递归后，这就是一个确定的文法了123A -&gt; aBB -&gt; bB | ε 还要注意一点，有些人会将左递归和尾调用等同起来，但这是不同的两个概念： 左递归是针对文法而言的。不消除左递归，不能使用确定的自上向下分析。 尾调用是对于一个函数调用而言的。当一个函数的最后一个工作是调用自己的时候，这样的调用称为尾递归，例如计算阶乘的某些实现。当这个函数计算仅占用常量的栈空间的时候，特别是对于LISP这样的函数式语言，可以进行尾递归优化(Tail Call Optimization, TCO)，即可以不在调用栈上面添加一个新的栈帧，而是更新它，如同迭代一般。通过尾递归优化，可以将$O(n)$的栈帧使用变为$O(1)$，减少部分递归程序的开销。 自下而上的分析方法概念状态栈和符号栈ACTION表和GOTO表ACTION表和GOTO表可以被认为是两个二维数组，其中ACTION表的两个维度是终结符和状态，而GOTO表的两个维度是非终结符和状态。GOTO[Si, a/A]表示状态栈顶为Si时，遇到文法符号（终结符a或者非终结符A）时需要转移到的状态。ACTION[Si, a]表示状态栈顶为Si时，读入输入符号a时需要采取的Action，包含： 移进 如果有Sj = GOTO[Si, a]，则Si入状态栈，a入符号栈。 这里清华的教材有点让人看不懂，GOTO表里面不是没有终结符的项目么，如果是终结符怎么办呢？我觉得这里应该是对GOTO表的终结符部分进行了省略，直接整合进了ACTION表中。 既然如此，为什么我们不直接把非终结符也整合到ACTION表里面呢？ 归约 当符号栈顶出现句柄β时，将它归约成对应的非终结符A。 这个过程包含： 符号栈出栈，SP减去|β|长度，即弹出β。 压入A。 状态栈压栈，Sj = GOTO[Si, A]，表示归约后到达的状态。需要注意的是，这个过程是有顺序的，我们将在稍后的例子中看到。 接受acc 符号栈只剩开始符号S，且没有剩余的输入符号。 报错 LR分析器不需要扫描整个分析栈（状态栈和符号栈）就可以知道句柄是否出现在栈顶，因为栈顶的状态符号包含了确定句柄所需要的一切信息，在编译器实际处理过程中并不需要访问非栈顶元素。教科书中之所以画出了栈是为了方便理解。 给出文法1234(1) S -&gt; aAcBe(2) A -&gt; b(3) A -&gt; Ab(4) B -&gt; d 下图是该文法的一个示例。在ACTION表中，Si表示一个移进并转移到状态i；rj表示按照产生式j进行归约，对于每一个归约动作都会通过GOTO表来表示归约后到达的状态。 我们基于abbcde#分析。 第1-2步 我们进行移进操作，读入ab并入栈，状态从初始的0转移到了4。 第3步 此时状态为4，读入符号还是b，我们查看ACTION表，发现这一行全部是r2，因此我们按照产生式2进行归约操作。 然后，我们要移除移进被归约的状态号和符号，此时，符号栈变为#a，状态栈变为02。 归约后，得到非终结符A，现在栈顶不再是4，而是2了（也是我们之前提到为什么要有顺序的原因）。于是我们查看GOTO[2, a]，将状态从初始的4转移到了3。 第11步，我们按照产生式1进行归约操作 可归前缀和活前缀步骤3/5/8/10中符号栈中对应的符号串又被称为可归前缀。 我们考虑下面的文法G中的推导，这里w是终结符串，A是最右非终结符。我们对A进行推导，所以这是一个规范推导（最右推导）过程。1S'=&gt;* αAw =&gt;* αβw 插一句嘴，容易看到，规范推导的一般形式如下，这也印证了规范推导是最右推导。1文法符号串(α) 待推导的非终结符(A) 终结符串(w) 我们定义，如果符号串γ是αβ的前缀，那么γ是文法G的一个活前缀。同时，β是句型αβw相对于非终结符A的短语。γ是规范句型即右句型的前缀。活前缀的作用是什么呢？而一旦栈中出现αβ，也就是形成了A的句柄，那么就可以按照A-&gt;β归约，因此，只要输入串的已扫描部分可以归约成一个活前缀，那就意味着已经扫描的部分没有错误。LR分析栈中的文法符号总是构成活前缀。 容易发现，可归前缀和活前缀的关系是：规范句型（最右推导得到的句型）中形成可归前缀中的所有前缀都是活前缀，可归前缀也是活前缀。 构造ACTION表和GOTO表的方法主要有三种方法： 求出所有活前缀的正规表达式，构造NFA，转化为DFA 求出文法中所有的项目，按照特定的方法构造NFA，转化为DFA 通过CLOSURE和GO函数 项目和项目集在文法G的产生式的右部的适当位置加一个点·，得到一个项目。这个点可以在最左边或者最右边。点的左边表示打算用这个产生式归约时，已经被识别的句柄部分；右边表示期待的后缀部分。有点类似于光标一样。 项目有下列分类，其中 移进项目A -&gt; α·aβ 分析时将a入栈。 待约项目A -&gt; α·Bβ。 如果圆点后面是个非终结符，表示先要把一些串归约成B，才能继续分析β 归约项目A -&gt; α· 一个产生式的右部已经被分析完了。 接受项目S&#39; -&gt; α· 项目集I是一组项目的集合，对应着DFA中的一个状态。 基于有限自动机结果LR分析表的转移函数本质上等同于一个识别整个文法的活前缀和可归前缀的有限自动机，我们来尝试构造一个NFA。我们考虑文法，规定拓广文法的开始符号S&#39;的唯一产生式所对应的项目S&#39;-&gt;E为初始状态（也就是上图中的X）。1234S' -&gt; EE -&gt; aA | bBA -&gt; cA | dB -&gt; cB | d 我们列出所有的项目如下图所示 所有产生式的每个项目都对应于NFA的一个状态，于是我们得到状态机如下图所示。这里双圈表示识别句柄的状态，双圈加上星号表示识别句子的状态。 通过NFA，我们可以得到下面的DFA。其中I0表示0状态的项目集 过程我们需要有确定的办法来求出所有活前缀和可归前缀，才能构造出这个NFA。为此，我们有定义6.2，其中α是符号串，ω是终结符串、S&#39;是拓广文法的开始符号。1LC(A) = &#123;a | S' =&gt;*R αAω &#125; 那么，这里的LC(A)表示规范推导中非终结符A左边出现的符号串的集合。其实这个定义是显而易见的，我找到A出现的所有地方，然后我看看它前面可能出现哪些串就行了。容易发现，这个是可以用类似DP的方法来生成的。比如说如果我有β -&gt; γAδ，那么对于任意的α ∈ LC(B)，一定满足1αγ ∈ LC(A) 证明很简单，我们只需要观察到1S' =&gt;*R αBω =&gt;R αγAδω 下面还会提到一个实用的构造方法，即“LR(0)分析表的一般构造方法”。 LR(0)分析表的一般构造方法定义构成识别一个文法活前缀的DFA项目集的全体称为这个文法的项目集规范族。简单的讲，项目集规范族就是项目集的全体，它的范围和DFA是等同的（TODO？）。 构造NFA参考上面给出的文法和NFA图，考虑出自于同一个产生式的项目i和j，如果i项目是1X-&gt;X1X2...Xi-1·Xi...Xn j项目是1X-&gt;X1X2...Xi·Xi+1...Xn 那么就从i向j连一条线，它的标记是Xi。如果Xi是非终结符，那么也存在以它为左部的状态，例如Xi -&gt; ·β，它是状态k，那么我们从状态i向状态k连一条线，它的标记是ε。 基于CLOSURE得到DFA闭包、核心项目现在我们得到一个NFA了，接下来当然可以使用子集法把这个NFA确定化为一个DFA，但是这样计算量很大。对此，我们有下面的考量。 如果状态（项目集）中包含项目A，那么所有形如项目B也应该在这个状态内。12A -&gt; α·BβB -&gt; ·γ 还是上面的例子，我们考虑NFA图中的项目1，在确定化得到状态I0后，我们发现除了项目1之外，还多了两个项目E -&gt; ·aA和E -&gt; ·bB，这是因为我们刚好有下面的规则12S' -&gt; ·EE -&gt; aA | bB 这样的规则，实际上就对应了求闭包的过程。这里的闭包CLOSURE是针对一个项目集I而言的，CLOSURE(J)表示状态J的项目集。通过闭包，可以求出DFA一个状态的状态集。可是我们现在还不知道我们对什么样的J求闭包呢？事实上，我们对核心项目求闭包就行。 定义核心项目包含： 所有圆点不在产生式右部左端的项目 例如E -&gt; ·aA和E -&gt; ·bB 初始项目 例如S&#39; -&gt; E 每个所需要的项目集都可以由取核心项目集的闭包形成。通过对核心项目求闭包始终可以得到所有的非核心项目，因此在存储的时候，我们只需要存储核心项目就行了。 闭包的求法： I属于闭包 对于闭包中的所有项目: 如果是待约项目，将该非终结符的所有产生式加入闭包。这是一个递归的过程。 如果是移进项目，不属于当前状态对应的项目集，不需要加入闭包。 如果是归约项目，不需要加入闭包。 GO函数定义GO函数如下，其中I是包含某一项目集的状态，X为终结符或非终结符。对于I中任何型如A-&gt;α·Xβ的项目，我们右移小圆点，得到的A-&gt;αX·β称为该项目的后继项目。那么I所有后继项目的集合就是J。1GO(I, X)=CLOSURE(J) 直观地来说，如果状态I能够识别活前缀γ，那么状态J能识别活前缀γX。再意会一下，我认为，GO(I, X)表示将X的小圆点右移之后，从I“派生”出来的新的项目集。 求项目集规范族求项目集规范族的过程为： 对初态S&#39;求闭包，得到一个完整的项目集。 对于得到的项目集中的每个项目，读入一个文法符号X，向右移动圆点。读入不同的文法符号会通向不同的新状态/项目集 注意原项目集I中的两个项目在读取同一个文法符号X之后必然属于同一个状态/项目集，即使它们对应的产生式左部不相同，这是由于GO(I, X)是唯一确定的。 对于这些新状态，再求闭包，由此循环。 注意GO和GOTO表的意义是不一样的，GOTO的定义上文已经提过了，转换函数GO用来求出移动圆点之后的新的项目集。 构造GOTO和ACTION表对于LR(0)，分析表（GOTO和ACTION）可以按以下方式构造： 终结符移进：如果项目A-&gt;α·aβ属于项目集Ik，并且GOTO(Ik, a)=Ik，当a为终结符时置ACTION(k, a)为S。 终结符归约：如果项目A-&gt;α·属于项目集I，则对于所有的终结符a和#置ACTION(k, a)为rj，j是产生式A-&gt;α的符号。 特别地，下面的SLR(1)在这里改进，向前看a从而决定是否移进或如何归约。 非终结符移进：如果GO(Ik, A)=Ij，则GOTO(k, A)=j。 接收状态：如果项目S&#39;-&gt;S·属于项目集Ik，则置ACTION(k, #)为acc，即接受。 如果存在规范推导S =&gt; δAw =&gt; δα·βw那么项目[A-&gt;α·β, a]对活前缀δα是有效的。 SLR(1)分析对冲突的解决思想LR(0)文法相对于LL的预测分析法，将归约的时刻推迟到了读完句柄之后。这减少了冲突，但是因为在能归约的地方总是归约，所以仍存在冲突。考虑变量声明的问题吗，以C语言为例通常为t &lt;varname&gt; [,&lt;varname&gt;]，这里省略了赋初值，同时类型标识符作为一个终结符t出现，在上文中解释过这是因为受到上下文无关文法的限制。得到的文法为1234S'-&gt;SS-&gt;tDD-&gt;D,iD-&gt;i 构造文法的项目集族，容易发现会产生移进归约冲突：S-&gt;tD· D-&gt;D,·i,，也就是说当遇到int i,j这样的情况，编译器现在读到j，已经形成了S-&gt;tD的句柄，可以归约了，但是这样的归约是错误的，因为后面的,j就会被丢掉了。显然解决的办法就是再往前看一个字符，如果是,，就继续移进，如果不是就归约。当然也可以引进分号，修改文法为S-&gt;tD;避免冲突。所以得到以下方案：设12345I=&#123; X-&gt;α·bβ A-&gt;γ· B-&gt;δ·&#125; 则X和A、X和B有移进归约冲突，A和B有规约规约冲突。所以向前读一个输入符号a， 避免移进归约冲突：若a=b则按照产生式X移进 避免规约规约冲突：如果a=FOLLOW(A)则按A归约，如果a=FOLLOW(B)则按B归约。显然FOLLOW(A)和FOLLOW(B)必须不相交（当然不能和所有的移进终结符相交）。 可以发现其实这和LL(1)的预测分析法是类似的思路。只不过LL(1)向前读的是当前非终结符的第一个非终结符，但是SLR(1)读的是“下一个非终结符”的第一个非终结符。SLR(1)算法的分析表（ACTION和GOTO）的构造和LR(0)算法是相似的，不同之处在于读入终结符决定归约时，只对属于FOLLOW(A)的终结符添加ACTION表中记录。 LR(1)分析SLR(1)不能完全避免移进归约冲突。考虑以下的情况：123S -&gt; α·aβA -&gt; α·a ∈ FOLLOW(A) 显然按照S产生式面临输入符号a时应当移进，但是按照A产生式应当归约。这种情况的产生是因为a∈FOLLOW(A)说明存在有一种符号串Aa，但不是对于所有的符号串A后面都有a的。因为通常运气不会好到所有FOLLOW集都不会出现两个及以上数目的非终结符，于是我们惊讶前面的SLR(1)算法居然也能跑！其实并不是这样，SLR(1)要求表示移进的终结符不在表示归约的终结符集（也就是FOLLOW集）里面，对于上述文法，可以求得a∈FOLLOW(S)，但是根据S-&gt;α·aβ可以看到FOLLOW(S)和{ a }是有交集的，所以SLR(1)在前一步就以移进归约冲突报错了。还可以考虑以下C赋值语句文法的实际意义进一步加深理解： 123赋值表达式 S -&gt; V=E|E左值 V -&gt; *E|id右值 E -&gt; V 按照SLR分析算法，现在考虑I2项目集S-&gt;V·=E E-&gt;V·，可以计算出=∈FOLLOW(E)，所以句型V=E既可以按照E-&gt;V归约，也可以按照S-&gt;V=E移进，冲突发生了。但是仔细琢磨，其实文法中的信息没有被完全表达出来。一个左值V完全可以出现在等号的右边，但是一个右值是不能出现在等号的左边的，如果按照E-&gt;V归约，那必定会推出V=V形成错误。虽然SLR(1)在前一步就以移进归约冲突报错了。所以解决的方案就非常显然了，既然FOLLOW集太过笼统，那就对每个项目单独给出后继符号，即搜索符。首先给出搜索符的定义：对于项目集A-&gt;α·Bβ、B-&gt;·γ，如果使用生成式B-&gt;γ归约，则FIRST(β)即为搜索符。搜索符对β非空的项目[A-&gt;α·β, a]是不起作用的，但对形式为[A-&gt;α·, a]的项目，它表示只有在下一个输入符号是a时，才能要求按A-&gt;α·归约。因此可以看做是FOLLOW集的对每个项目的特化，LR(1)文法的1同时也意味着搜索符是长度是1的终结符。如果存在规范推导S =&gt; δAw =&gt; δα·βw其中γ=δα且a是w的第一个符号或者w是ε、a是$，那么项目[A-&gt;α·β, a]对活前缀γ是有效的。LR(1)和SLR(1)的流程大致是相同的，首先也要计算CLOSURE函数。因为LR(1)项目集多了搜索符，因此CLOSURE函数需要一些修改。假设项目A-&gt;α·Bβ, a属于CLOSURE(I)，那么对于产生式B-&gt;γ，当β∈FIRST(βa)时，B-&gt;·γ, b也在CLOSURE中。LR(1)算法的分析表（ACTION和GOTO）的构造和LR(0)、SLR(1)算法是相似的，不同之处在于读入终结符决定归约时，只对属于搜索符（是一个终结符）添加ACTION表中记录。 LALR(1)对LR(1)的简化如果两个项目集除了搜索符其他都一样，那么这两个项目集为同心集。合并同心集后不会产生移进归约冲突，但可能仍会产生规约规约冲突。 冲突的解决思想总结我们希望我们的文法分析过程是确定性的。这也就是说，对于LL分析，我们希望当推导时碰到某个非终结符的产生式有多个候选的时候，我们能够唯一确定一个候选进行推导；对于LR分析，我们希望能够唯一确定任何一时刻下的分析器的动作应该是移进还是归约（为了避免移进归约冲突，例如C语言的悬空else情况if(..)if(..)else中，在else位置是移进外层的if，还是归约内层的if，当然这个二义文法已经不算是LR文法了）、按照哪个产生式归约（为了避免规约规约冲突，例如前面所说的VB6语言A(i)可能是一个数组元素，也可能是一个函数调用，特别地，(1+2)和func_name(1+2)也可能导致规约规约冲突）。 因此可以发现事实上LR所能描述的文法是LL(1)预测分析法的真超集。回顾LL(1)预测分析法的流程，LL(1)预测分析法由一个栈S和一个预测分析表M组成。M[A,a]表示推导A时当遇到输入符a时，应当选择的A的产生式，这应当是唯一确定的。也就是说，对于任意的产生式A-&gt;α，如果a在SELECT(A-&gt;α)集合中，那就必须要选择产生式A-&gt;α，如果对于A的所有产生式，它们的SELECT集都不出现a，那就报错。因此，这就意味着选择A的哪一个产生式完全取决于a。例如考虑应用产生式A-&gt;lβ如下推导S=&gt;αAbw=&gt;rlβbw（其中α为符号串，A为最右非终结符，w为终结符串），LL(1)预测分析法需要在看到l时就作出决定选择产生式A-&gt;lβ，但是LR分析法可以在看到b之后再决定是否把lβ规约为A，因此LR实际上获得了更多的信息。同时LL(1)文法还是不能够出现左公因子和左递归的：对于前者可以发现同一个非终结符的所有SELECT集合是存在交集的；对于第二种情况，直接左递归A-&gt;Aβ或者间接左递归可以推出它们的SELECT集也是相交的。有的时候，虽然文法是二义性的，但是语言却可以不是二义性的，这可以通过语义分析解决。 通过重写文法解决二义性123stmt: if expr then stmt else stmt | if expr then stmt | other 可以提取公因子，重写为：1234stmt: if expr then stmt optional_else | otheroptional_else: else stmt | other 一般来说，对于文法12A -&gt; αηB -&gt; βη 提供一个将η归约为非终结符C的产生式123A -&gt; αCB -&gt; βCC -&gt; η 但是这样的坏处是会引入终结符C，并且这个C可能没有明确的语义作用。 通过设置终结符优先级解决二义性考虑通常的表达式文法：1E -&gt; E + E | E * E | (E) | id 对于1 + 2 * 3，能产生两种语法树，产生移进归约冲突，原因在于面临+的时候可以按照E-&gt;E + E归约，也可以按照E-&gt;E * E移进，于是规定*的优先级高于+，所以选择移进。对于1 + 2 + 3，同样能产生移进归约冲突，因此规定+是左结合的，因此对于项目id + id · + id，应当归约，而不是移进。此外，这个文法同样可以通过重写文法来消除二义性，例如下面这样的文法产生式的右边会出现单非终结符的产生式，增加了归约的次数。123E-&gt;E+T|TT-&gt;T*F|FF-&gt;(E)|id 这种方法常用来解决移进归约冲突 通过设置产生式优先级解决二义性考虑排版文法： 12345E -&gt; E ^ E _ EE -&gt; E ^ EE -&gt; E _ EE -&gt; &#123;E&#125;E -&gt; c 其中^表示上标，_表示下标。从定义形式语言的角度来讲，第一个产生式是多余规则，因为用2和3产生式能够得到1产生式可推导出的句子。但是从语义的角度来说它作为一个优先归约的特殊规则存在。例如我们考虑会产生的以下三个排版：ai2 a2i ai2它们的效果（语义）是不一样的，因此单独将第一个产生式列出来，优先级最高，当满足第一个产生式时，不使用后两个产生式进行归约。同样的方法可以用在处理A(args)和(exp)的冲突上面。这种方法常被用来解决归约归约冲突。 使用GLR文法解决二义性有时候冲突是无法避免的，这时候可以选择使用GLR文法分析器，相对于LALR分析，GLR会BFS所有可能的操作。GLR的最坏时间复杂度是O(n3)的，具体取决于冲突的数量 语义分析上的两种分析方法语法树语法树（推导树）的特点是非叶子节点都是非终结符，叶子节点都是终结符。因此从左到右遍历（也就是DFS）语法树即可生成代码。特别地，单趟编译器（one-pass compiler）不先建立语法树后编译。这样的编译器由语法分析带动整个编译流程，在语法分析的同时计算属性值，这样的做法称为语法指导翻译。TCC(Tiny C Compiler)就是这样的一个编译器。属性文法对遵循语法制导语义(syntax-directed semantic)原理的语言最有用，它表明程序的语义内容与它的语法密切相关。 综合属性和继承属性考虑一棵语法树，综合属性总是自下而上传递的，例如2.4+3*4，在语法树的根节点+，得到了结果14.4，注意到类型从int上升到double体现了自下而上的过程。继承属性是在语法树水平或者从上往下传递的，例如C语言中的变量初始化语句int i = 0, j = 0;，容易得到属性文法：123T -&gt; int| real T.type = int| realL -&gt; L1, id| id L1.in = L.in; do_symbol_table;D -&gt; TL L.in = T.type 可以发现，属性先从T横向向右传递给L，然后由L向下传给L1。在产生式上来看，综合属性属于产生式的左部非终结符，从产生式右部的文法符号的属性得到（自下而上），继承属性属于产生式右部的文法符号，从产生式左部（自上而下）或者产生式右部该文法符号之前的文法符号（横向）的属性得到。 L属性文法的自顶向下和自下而上分析自顶而下的L属性文法会导致翻译模式，也就是需要在产生式的右部文法符号中间嵌入语义计算动作（yacc中使用花括号{}括起来，里面可以写C++的代码，详情可以参考我的另一篇文章：flex和bison使用）。考虑常见的if..elseif..else..endif文法。12345678if_stmt : YY_IF exp YY_THEN stmt endif_stmt | YY_IF exp YY_THEN stmt else_stmt | YY_IF exp YY_THEN stmt elseif_stmtelseif_stmt : YY_ELSE YY_IF exp YY_THEN stmt | YY_ELSE YY_IF exp YY_THEN stmt elseif_stmt | YY_ELSE YY_IF exp YY_THEN stmt endif_stmtelse_stmt : YY_ELSE stmt endif_stmtendif_stmt : YY_END YY_IF 修订 表示所有可能在A后面的非终结符 错，应该是终结符 增加文法和自动机相关 以《形式语言与自动机导论》为主体 整理基本定义到单独一节 参考 清华大学 编译原理 龙书 编译原理 中科大]]></content>
      <tags>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线段树和树状数组]]></title>
    <url>%2F2016%2F07%2F13%2Fsegment-tree-and-binary-indexed-tree%2F</url>
    <content type="text"><![CDATA[线段树和树状数组是一系列神奇的数据结构的起源，但其本身却十分简洁优雅，是我非常喜欢的两种数据结构。 树状数组(binary indexed tree)考虑求和$A[n]=a[1..n]$，平凡的解法复杂度为$O(n)$，树状数组则是$O(log \, n)$的方法。理解树状数组，可以考虑任何一个自然数$x$可以表示成：$ x = a_0 2^0 + a_1 2^1 + … + a_n 2^n $，其中$a_i$可以取0或1。我们看到这样的以2为底的“科学计数法”能够将加法的计算量减少到$log_{2}n$。同样我们希望把对一个序列的求和计算也降为对数级的，容易想到可以缓存一些连续$2^n$个数的和作为子结构，例如我们可以算出下面的这张表，即T数组： 十进制 二进制 区域和T[i]即a[i..j]的和 1 1b $a[1]$ 2 10b $a[1..2]$ 3 11b $a[3]$ 4 100b $a[1..4]$ 5 101b $a[5]$ 6 110b $a[5..6]$ 7 111b $a[7]$ 8 1000b $a[1..8]$ 9 1001b $a[9]$ 10 1010b $a[9..10]$ 11 1011b $a[11]$ 12 1100b $a[9..12]$ 13 1101b $a[13]$ 14 1110b $a[13..14]$ 15 1111b $a[15]$ 16 10000b $a[1..16]$ 17 10001b $a[17]$ 18 10010b $a[17..18]$ 19 10011b $a[19]$ 下面我们尝试利用上面的表计算$A[13]$，首先把13分解成2的幂的代数和，即$13 = 8 + 4 + 1$。查表，我们发现$A[13] = T[8] + T[12] + T[13]$。而$T[8]$、$T[12]$、$T[13]$区间的长度分别对应了8、4、1。下面是个直观的图。 这张表是如何得出的呢？定义$T[i]$为区间$a[i-lowbit(i)+1 .. i]$共$lowbit(i) = 2^k$个元素的和，也就是说$i$最多能被2的几次幂整除，就从$i$开始往前数几个。下面用程序来描述查表的过程。我们要从“边长”小的方块往大的方块加，即$13 \rightarrow 9..12 \rightarrow 1..8$，即123for (int x = i; x &gt; 0; x -= lowbit(x))&#123; ...&#125; 树状数组不仅能快速查找，还能快速更新。更新位置$i$处的值时，我们按照以下规则更新： 只更新$i$位置后的节点，因为根据定义，$i$前的节点不可能包含$i$。 只更新“边长”为1（即自己）、2、…、$2^n$等2的幂次的节点，有些“边长”可能碰不到，其实这就取决于$i$在2进制表示中1出现的位置了。例如更新了$a[3]$，就要同时更新4、8、16这些位置；更新了$a[7]$就要同时更新8、16、32这些幂次；更新$a[11]$就要更新12、16这些节点1234for (int x = i; x &lt;= maxn; x += lowbit(x))&#123; // 注意是maxn不是a的实际个数n ...&#125; 最后推荐另外一个教程 二维树状数组二维树状数组中比较常见的题型是矩形区域最值/和问题。如刚遇到的hiho1336 线段树(segment tree)基础线段树一个基础的线段树支持单点修改和区间查询 PushDown和PushUp将线段树的各个操作提炼出得到一个模板，这样用户只需要PushUp这个操作和Update的一个终止条件。其中PushUp在Update和Build函数中使用，用来合并两个子区间的性质。 线段树数组的大小MAXN应当至少为4N假设对$[1..N]$建立线段树，其中$2^n &lt;= N &lt;= 2^{n+1}$。容易得到树的底层至少需要$2^{n+1}$个节点，因此整个树需要$2^{n+2}$个节点，也就是必须满足$MAXN \ge 2^{n+2}$ 。把$n$用$N$代替，得到$4N &gt;= 2^{n+2}$，显然对于任意$MAXN \ge 4N$，有$MAXN \ge 2^{n+2}$。 线段树查询 为什么需要$fr$，$to$，$l$，$r$四个变量？ 线段树的查询开销在$O(lgn)$。假设我们要求$[fr .. to]$之间的值，我们实际上是找寻若干长度为$2^i$的若干子树，它们的并集能够恰好覆盖$[fr .. to]$区间。由于线段树的结构是二分的，$[l .. r]$表示线段树中我们搜索到的当前节点所表示的区间。我们根据$l$、$r$与$fr$、$to$的关系可以判断出全取$[l, r]$结果，全不取$[l, r]$结果还是继续二分搜索。 开闭区间的问题 首先要注意优先级，&lt;&lt;的优先级低于+，所以应当写成(root &lt;&lt; 1) + 1这样。 Modify操作只需要更新（被影响的）一侧 线段树的区间更新可以对线段树进行区间更新，为了保证$log n$的复杂度，显然对每个叶子节点的更新是不可能的了，因此我们使用一个lazy[]辅助数组。当我们的update函数遍历到满足fr &lt;= l &amp;&amp; r &lt;= to时，我们就停止进行update，而设置lazy[root] = tree[root]，其中tree是我们维护的线段树。与此同时我们引入PushDown这个操作。PushDown在Update和Query函数中使用，负责将本层的lazy更新信息传递给下一层。12345678910111213141516void PushDown(int root, int ln, int rn)&#123; // 当具有lazy标记时 if(lazy[root] != -1) &#123; // 注意更新时仍然需要维护区间性质，而不能简单赋值为lazy[root] // 下面的代码维护了区间内最大值的性质 tree[root &lt;&lt; 1] = max(lazy[root], tree[root &lt;&lt; 1]); tree[root &lt;&lt; 1 | 1] = max(lazy[root], tree[root &lt;&lt; 1]); lazy[root &lt;&lt; 1] = max(lazy[root], lazy[root &lt;&lt; 1]); lazy[root &lt;&lt; 1 | 1] = max(lazy[root], lazy[root &lt;&lt; 1 | 1]); // 取消lazy标记 lazy[root] = -1; &#125; return;&#125; 二维线段树下面用二维线段树来解决刚才的问题。这道题目需要写三个update，原因是在使用update2更新完rx行以0为根的所有列构成的子树后，需要更新第i列中以rx行为根构成的子树。如果不更新，那么将来对于任意的第i列，当x为非叶子节点时，tree[x][i]的值都为0。如果暴力一波肯定会T。1234for (int i = 0; i &lt; 4 * n; i++)&#123; tree[rx][i] = tree[rx * 2 + 1][i] + tree[rx * 2 + 2][i];&#125; 所以需要用一个和update2类似的update3来更新代码 zkw线段树普通的递归版本的线段树的常数是比较大的，但有些题目可以考虑使用zkw线段树。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>线段树</tag>
        <tag>树状数组</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PAT解题报告]]></title>
    <url>%2F2016%2F07%2F06%2FPAT%2F</url>
    <content type="text"><![CDATA[浙江大学PAT(Programming Ability Test) A-level、top-level以及CCCC练习题的部分解题报告。源码在 https://github.com/CalvinNeo/PAT [YN\d]\t(\d+-)+\t([\w ]+)(\d+).* 1001 A+B Format注意判断-999,999的情况 1002 A+B for Polynomials1003 Emergency1004 Counting Leaves1005 Spell It Right比较简单，注意POSIX没有itoa，得用sprintf。特别地，对于二进制数字，可以借助于bitset来输出accumulate第三个size_t参数最好直接设为0，在函数外加上初值。 1006 Sign In and Sign Out1007 Maximum Subsequence Sum思路:1234567891011121314151617if(maxsumto[i-1]+n[i] &lt; n[i])&#123; // re-count maxsumto here maxsumto[i] = n[i]; start[i] = i; if (maxv &lt; maxsumto[i]) &#123; maxv = maxsumto[i]; maxid = start[i]; &#125;&#125;else&#123; maxsumto[i] += n[i]; start[i] = start[i - 1]; if (maxv &lt; maxsumto[i]) &#123; maxv = maxsumto[i]; maxid = start[i]; &#125;&#125; 有一个bug，为了方便计算，输入数据从n[1..k]，定义n[0] = start[0] = 0; 考虑1 -1 1 -1 1 -1 1 -1 1 -1这样的序列，得到结果为1 0 1，但是实际的结果应当是1 1 1。因此start[0] = 1。 HHU1 1003注意LL应当用printf(&quot;%lld&quot;)或者printf(&quot;%I64d&quot;)输出，但是double应当用printf(&quot;%f&quot;)输出。此外，要注意输入3 1 1 4的输出是4而不是1。 HHU2 1001二叉查找树的中序遍历非递归实现使用一个栈，栈中的节点都已经遍历过左子树。比较容易的做法是再开一个vis数组用来记录这N个节点是否全部被遍历过。 HHU2 1002(POJ2823)线段树的大小MAXN应当至少为4N HHU4(HDU5524)这一题问一个$N$节点的完全二叉树一共有多少个节点数不同的子树。这一题的关键在于完全二叉树的性质 二叉树始终有叶子，但是叶子节点只能出现在最下层或者次下层。最下层的叶子应当集中在左侧。 完全二叉树左右子树中至少有一个满二叉树，这个满二叉树的节点个数可以直接由其深度算得，另外一半的非满二叉树继续递归，最终一定能得到一个满二叉树 $N$节点的完全二叉树深度为$ \lfloor log(N) \rfloor +1 $，上$\lfloor log(N) \rfloor$层一定是满二叉树。对于满二叉树，第$i$层有$2_{i-1}$个节点，前$i$层有$2_{i} - 1$个节点。 完全二叉树的数组表示形式是连续的，当index从0开始时，$[0, len/2 - 1]$区间内的节点有孩子，其中$len/2 - 1$是最后一个元素的父节点 注意分清二叉查找树和二叉堆的区别。二叉查找树需要左孩子小于根小于右孩子。而二叉堆是一棵完全二叉树，要求满足递归的堆序性，即根小于等于或大于等于所有的孩子。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>PAT</tag>
        <tag>CCCC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSCPC总结]]></title>
    <url>%2F2016%2F05%2F09%2FJSCPC2016%2F</url>
    <content type="text"><![CDATA[五月八日在南京大学参加了第一届江苏省程序设计大赛。这次破天荒拿了7A。 首先是热身赛，第一条是最基本的dp，第二条是一个pq，第三条是带两个cost的dijkstra。进入正赛，一般这种比赛都是AJ水题。我先切的A，A是摩尔斯电码的翻译，是一条手速题，我看完的时候学弟已经看完B题了。B题是给出二叉树后序遍历的第k项。学弟用了二分，不过讲题的时候说因为数据故意改弱了，所以可以直接建树暴力做。B题WA了下，等到做完我断断续续把A题敲完了，1A过。后来发现I是个水题，就是dijkstra，另外建一个map把站点映射成index就行了，正好可以用刚才热身赛的dijkstra，我写了个框架给zqh填dijkstra，不过这道本以为1A的题目居然卡了很久，最后还是学弟调出来的。中间看了J题，之前学弟第一个切了J，觉得J没见过难，我一看是个人肉pattern recognition：给一段话，要你分析出是English还是Spanish还是Chinese Pingyin。这个主要思路一个是特征词，比如西班牙语特有el，y，e，o，por这种词，另外就是长度判别，中文一定是长度小于6的，因为句子都是选自维基百科等的实际文献，而且长度都大于100个词，所以不要担心会产生误判。不过在写代码的时候WA了两次，有个坑，std::string的find会默认对pattern做trim，而trim之后，“y”也会同样匹配“sky”这样的英文单词了，所以得手写一个find，这里直接对find之后的index首尾直接验证有没有空格。J是倒数第二个A的，之前学弟有A了C和F。这时候zqh在推G题，G题是个类似博弈的题目，但实际上是推一个公式。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>CCPC</tag>
        <tag>现场赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[winsock/boost::asio笔记]]></title>
    <url>%2F2016%2F04%2F15%2Fwinsock%2F</url>
    <content type="text"><![CDATA[WinSock/boost::asio 编程遇到的一些问题 未归类的配置问题 fatal error C1189: #error: WinSock.h has already been included这个是windows SDK + boost的一个历史问题，解决方案是在最前面#include &lt;WinSock2.h&gt; error LNK2019: 无法解析的外部符号 “void __cdecl func_name(void)” (?func_name@@YAXXZ)，该符号在函数 _wmain 中被引用这种错误一般是因为在头文件里面声明了某个函数，但是却没有实现它。但是仔细检查发现并不是这个问题。使用#pragma messagelog一下发现也不是头文件包含上面出现了问题。后来发现这个函数所声明的h文件曾经被rename过，于是重新添加该文件到工程中，问题就被解决了。事实上很多时候经常出现类似某个符号无法找到或者重复声明的错误，clean build都没有用，这时候常常可以重新添加代码文件即可。]]></content>
      <tags>
        <tag>网络</tag>
        <tag>boost</tag>
        <tag>winsock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的重要科学计算库numpy]]></title>
    <url>%2F2016%2F03%2F06%2Fnumpy%2F</url>
    <content type="text"><![CDATA[本文主要包括numpy用法上的一些套路和坑。 ndarray的性质axis执行以下代码1234import numpy as npa = np.array([[1,2],[3,4]])np.sum(a, axis=0)np.sum(a, axis=1) 输出12345678&gt;&gt;&gt; aarray([[1, 2], [3, 4]])&gt;&gt;&gt; np.sum(a, axis=0)array([4, 6])&gt;&gt;&gt; np.sum(a, axis=1)array([3, 7])&gt;&gt;&gt; 实际上表示在哪个轴上连接。比如当axis=0的时候，最外面一层数组的长度就改变了。可以看出，axis=0对每个纵轴Y，求和a[:, Y]，压扁X轴。同理，axis=1对每个横轴求和a[X, :]，压扁Y轴。 交换axis轴在处理CNN相关数据的时候常常遇到类似的需求比如说NHWC和NCHW之间的交换。方法是通过swapaxes函数。 OrderFortran Order和C order在打印的结果是一致的1234aforder = np.array([[1,2,3],[4,5,6]], order="F")print(aforder, aforder.flags)acorder = np.array([[1,2,3],[4,5,6]], order="C")print(acorder, acorder.flags) 上面的代码输出12345678910111213141516(array([[1, 2, 3], [4, 5, 6]]), C_CONTIGUOUS : False F_CONTIGUOUS : True OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False)(array([[1, 2, 3], [4, 5, 6]]), C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False) 并且轴也是对应的12print(np.sum(aforder, axis=0), np.sum(acorder, axis=0))print(np.sum(aforder, axis=1), np.sum(acorder, axis=1)) 上面的代码输出12(array([5, 7, 9]), array([5, 7, 9]))(array([ 6, 15]), array([ 6, 15])) Fortran和C式存储的读写性能据说有差异，但实际看下来感觉差异不大123456789101112131415# 计算列和R = 1000C = 1000carray = np.array([i * 0.001 for i in range(1000000)], order="C").reshape((R, C))farray = np.array([i * 0.001 for i in range(1000000)], order="F").reshape((R, C))sw.mark()s = 0for t in range(1000): s += np.sum(carray[:, 22])print("C &#123;&#125; elapsed &#123;&#125;".format(s, sw.elapsed()))sw.mark()s = 0for t in range(1000): s += np.sum(farray[:, 22])print("F &#123;&#125; elapsed &#123;&#125;".format(s, sw.elapsed())) 得到1234C 22499500.0 elapsed 0.00500011444092F 22499500.0 elapsed 0.00400018692017C 499522000.0 elapsed 0.00600004196167F 499522000.0 elapsed 0.00699996948242 dtype介绍元素类型dtype作为诸如np.array的参数时，用来表示数组中元素的类型。Numpy中的数组是homogeneous的，都具有用dtype对象表示的类型1234&gt;&gt;&gt; type(np.int8)&lt;type 'type'&gt;&gt;&gt;&gt; type(np.dtype(np.int32))&lt;type 'numpy.dtype'&gt; 但与此同时np.dtype还是一个函数。诸如np.int8等都是这个类的实例。1np.dtype(object, align, copy) 如果align为True，那么就进行对齐（似乎我们不能指定对齐到多少字节）。如果copy为False，则是对内置数据类型对象的引用。下面来看必选参数object，它非常灵活。 可以是类型 1np.dtype(np.int32) 可以是字符串 这里i4表示int32，&lt;表示使用小端存储。 1np.dtype('&lt;i4') 此外，dtype还可以被直接用来描述数组，或者嵌套结构。 表示struct 含有一个字段f1，这个字段是一个struct，里面包含一个f1 123d = np.dtype([('f1', [('f1', np.int16)])])&gt;&gt;&gt; d.fieldsdict_proxy(&#123;'f1': (dtype([('f1', '&lt;i2')]), 0)&#125;) 表示多维数组 1np.dtype("i4, (2,3)f8") 比较有趣的是去np.dtype到np.void上。有的时候，astype(int)会依旧输出numpy.int64，此时参考SoF，选用.item() ndarray的方法创建/复制数组复制np.array(arr)和np.copy(arr)都可以复制numpy数组，感谢来自评论区的指正。1234arr = np.array([1,2,3,4,5])arr2 = np.array(arr)arr[2] = 999print arr2 以上代码输出1[ 1 2 3 4 5] 可以通过fromfunction函数，通过index来创建一个数组。 创建随机01数组这个通常用来生成随机的mask数组。考虑场景，我们需要把数组arr中的随机transform_count位进行变换f，剩下的不变。我们可以借助下面的办法，首先对所有元素应用f，得到transformed数组。然后生成一个01的mask，并调用shuffle打乱，接着将所有mask为1的位置设置为transformed，其余的使用原来的arr。12345678910111213from functools import reducedef perform(f, arr, transform_count): transformed = f(arr) length = reduce(lambda x,y: x * y, arr.shape) mask = [1] * transform_count + [0] * (length - transform_count) mask = np.array(mask) np.random.shuffle(mask) mask = mask.reshape(*arr.shape) combine = transformed*mask + arr*(1-mask) return combinearr = np.array([1,2,3,4,5,6,7,8])print(perform(lambda x: x*2, arr, 5)) fromfunction这个函数非常古怪，乍一看，我们是传入一个函数P，这个函数接受一个坐标作为参数，输出这个坐标上的值。但结果是这样的么？我们首先来执行一下12345def P(*X): import random return random.random()np.fromfunction(P, (2, 3, 4), dtype=int) 结果输出了一个随机数1234567def P(*X): for x in X: print(x) print("====") return 1np.fromfunction(P, (2, 3, 4), dtype=int) 结果输出123456789101112131415161718192021222324[[[0 0 0 0] [0 0 0 0] [0 0 0 0]] [[1 1 1 1] [1 1 1 1] [1 1 1 1]]]====[[[0 0 0 0] [1 1 1 1] [2 2 2 2]] [[0 0 0 0] [1 1 1 1] [2 2 2 2]]]====[[[0 1 2 3] [0 1 2 3] [0 1 2 3]] [[0 1 2 3] [0 1 2 3] [0 1 2 3]]]==== 那么有什么办法可以做到呢？答案是用np.vectorize包裹一下1234def P(*X): return X[0] + X[1] + X[2]np.fromfunction(np.vectorize(P), (2, 3, 4), dtype=int) 增删相关方法连接在本节中，使用下面的定义1234a = np.array([[1, 2], [3, 4]])b = np.array([[5, 6]])c = np.array([[5], [6]]) concatenateconcatenate表示按照axis进行连接，连接之后，axis参数对应的轴的长度会变化。如果axis是None，则拍平再连接。123456print np.concatenate((a, b), axis=0)print np.concatenate((a, b), axis=None)print len(a), len(np.concatenate((a, b), axis=0))print np.concatenate((a, c), axis=1)print np.concatenate((a, c), axis=None)print len(a), len(np.concatenate((a, c), axis=1)) tiletile是concatenate的语法糖。第二个参数表示沿着哪个轴进行复制，下面两个是等价的。12print np.concatenate((a, a), axis=0)print np.tile(a, (2, 1)) 都返回1234[[1 2] [3 4] [1 2] [3 4]] 下面的会连接到右边12print np.concatenate((a, a), axis=1)print np.tile(a, (1, 2)) stackstack会升维1print np.stack([a, a], axis=0) 会返回12345array([[[1, 2], [3, 4]], [[1, 2], [3, 4]]]) 查看一下shape1print a.shape, np.stack([a, a], axis=0).shape 结果是1(2L, 2L) (2L, 2L, 2L) appendappend类似于vector的push_back操作同理，如果不指定axis，那么永远是得到一个一维数组。12print np.append([1, 2, 3], [[[4, 5, 6], [7, 8, 9]]], axis=None)print np.append([[1, 2, 3]], [[4, 5, 6], [7, 8, 9]], axis=0) View相关方法View相比np.array和ndarray.copy，numpy还提供了view的机制以方便在相同的数据上面建立view。dtype表示元素的type，会进行reinterpret cast，而type表示外面封装的type，比如np.array或者np.matrix啥的，但必须是ndarray的子类型 1234mat_x = np.array([(1, 2), (3, 4)], dtype=[('a', np.int8), ('b', np.int8)])mat_y = mat_x.view(dtype=np.int16, type=np.matrix)mat_y_int8 = mat_x.view(dtype=np.int8, type=np.matrix)print(mat_y_int8) 可以发现type变成了matrix，而当dtype不等于原来时，数组的含义也发生了改变。输出如下1234&gt;&gt;&gt; print(mat_y)matrix([[ 513, 1027]], dtype=int16)&gt;&gt;&gt; print(mat_y)matrix([[1, 2, 3, 4]], dtype=int8) 可以看出，我们对得到的数组进行了reshape，结果是跟随变化的123mat_ravel = mat_x.view(dtype=np.int8).reshape(-1)mat_ravel[0] = 100print(mat_x) 输出1[(100, 2) ( 3, 4)] 但是flatten基于view创建了副本，所以不会随之改变123mat_flatten = mat_x.view(dtype=np.int8).flatten()mat_flatten[0] = 200print(mat_x) 输出1[(100, 2) ( 3, 4)] 除了matrix，还有np.recarray这种东西，可以实现类似namedtuple或者pandas里面的类似效果12named_mat_x = mat_x.view(type = np.recarray)print(named_mat_x.a) 输出1[100 3] mask机制ascontiguousarrayndarray默认都是C Order的，也就是按行存储，那么同行之间的元素是连续的。容易想到，通过slice操作，可以得到一个既不是C连续，又不是Fortran连续的数组。123a_cont = np.array([[1,2,3],[4,5,6],[7,8,9]])a_non_cont = a_cont[:, 1:3]print(a_non_cont.flags) 打印一下可以发现a_non_cont是不连续的。1234567C_CONTIGUOUS : FalseF_CONTIGUOUS : FalseOWNDATA : FalseWRITEABLE : TrueALIGNED : TrueWRITEBACKIFCOPY : FalseUPDATEIFCOPY : False 通过ascontiguousarray，能够得到一个底层存储不连续的数组的一个副本（有可能不是副本，但不能保证），这个新ndarray的底层存储是连续的。12a_non_cont_as_cont = np.ascontiguousarray(a_non_cont)print(a_non_cont_as_cont.flags) 打印发现是C连续的1234567C_CONTIGUOUS : TrueF_CONTIGUOUS : FalseOWNDATA : TrueWRITEABLE : TrueALIGNED : TrueWRITEBACKIFCOPY : FalseUPDATEIFCOPY : False 此外，我们还能发现np.ascontiguousarray默认以C模式（而不是Fortran）模式输出数组。下面展示了相关代码实现，ndmin=1是为了保证C模式不出错（数组至少有一维）。12345ref: numpy\core\numeric.pydef asarray(a): return array(a, dtype, copy=False, order=order)def ascontiguousarray(a): return array(a, dtype, copy=False, order='C', ndmin=1) 不过新产生的数组就是一个副本了123a_non_cont_as_cont[0][1] = 100print(a_non_cont_as_cont)print(a_non_cont) 上面的代码输出123456[[ 2 100] [ 5 6] [ 8 9]][[2 3] [5 6] [8 9]] Reshape相关方法通过arr.shape可以输出其形状。一般一维数组的shape是(n, )，二维数组是(n, m)这样。对于一维数组也可以输入一个Scalar，而不是一元tuple。通过resize函数或者resize方法可以变更ndarray的大小，但是使用resize方法可能出现ValueError: cannot resize an array references or is referenced by another array in this way. Use the resize function这个错误。 reshape12a = np.arange(0, 10)print(a) 输出1[0 1 2 3 4 5 6 7 8 9] reshape之后的array的形状要能够和之前的match，例如总长度都不等，是会报错的。1a2d = a.reshape((7, 7)) 这个会报错1ValueError: cannot reshape array of size 9 into shape (7,7) 可以指定一个-1，让numpy自己推导剩下一维的大小12a2d = a.reshape((2, -1))print(a2d) 输出12[[0 1 2 3 4] [5 6 7 8 9]] 但是不可以指定两个及以上的-11a3d = a.reshape((2, -1, -1)) 这样的代码会报错1ValueError: can only specify one unknown dimension Flatten下面的函数都可以把数组拍平12345print(a2d.reshape(-1))print(a2d.ravel())print(a2d.flatten())# 需要显式指定dtype，否则 https://github.com/numpy/numpy/issues/6616print(np.ndarray(shape=(5, 2), buffer=a2d.data, dtype=np.int32)) 上面都是输出都是相同的1[0 1 2 3 4 5 6 7 8 9] flatten、ravel和reshape都可以将一个多维数组压平，那么区别是什么呢？从下面的代码可以看出flatten返回的是副本。下面的代码输出100，可见reshape不会生成副本12a2d.reshape(-1)[1] = 100print(a2d[0][1]) 下面的代码输出200，可见ravel也不会生成副本12a2d.ravel()[1] = 200print(a2d[0][1]) 下面的代码输出200，可见flattern会生成副本12a2d.flatten()[1] = 300print(a2d[0][1]) Filter相关方法去重可以通过unique去重123all_points = np.array([1,1,2,2,3,3,4,4])non_repeated = np.unique(all_points)print(non_repeated) 打印输出1[1, 2, 3, 4] 指定return_index，会返回不重复的index而不是值12_, idx = np.unique(all_points, return_index=True)print(idx) 结果如下1[0 2 4 6] 二维去重需要注意的是，对于二维数组，也是逐元素进行去重的123all_points = np.array([[1,1],[2,2],[2,2],[3,3],[3,3],[4,5]])non_repeated = np.unique(all_points)print(non_repeated) 实际输出是1[1, 2, 3, 4, 5] 那么，如果我们是想把某一维作为整体进行去重，该如何做呢？下面展示一个骚操作，all_points是一个点集类型的数据，我们希望把这个点集进行去重。主要思路是首先把它按第二维转成二进制形式12b = np.ascontiguousarray(all_points.copy()) # 先复制一份出来，并将它变成连续的内存布局 .view(np.dtype((np.void, a.dtype.itemsize * a.shape[1]))) 这样我们得到的b实际是一个一维数组，每一维表示编码后的一个点。1234567array([[b'\x01\x00\x00\x00\x01\x00\x00\x00'], # [1,1] [b'\x02\x00\x00\x00\x02\x00\x00\x00'], # [2,2] [b'\x02\x00\x00\x00\x02\x00\x00\x00'], # [2,2] [b'\x03\x00\x00\x00\x03\x00\x00\x00'], # [3,3] [b'\x03\x00\x00\x00\x03\x00\x00\x00'], # [3,3] [b'\x04\x00\x00\x00\x05\x00\x00\x00']], # [4,5] dtype='|V8') 然后对这个二进制编码进行去重，再反推回来。12_, idx = np.unique(b, return_index=True)all_points = a[idx] 这样的输出是1234array([[1, 1], [2, 2], [3, 3], [4, 5]]) 压缩我们可以借助于unique提供的return_inverse参数实现压缩。在指定该参数后，unique还会返回一个数组，表示原数组中的每个元素对应到unique数组中的哪一项。1u, idx = np.unique(all_points, return_inverse=True) 在获得压缩之后，通过下面的代码会返回和all_points一样的数组1print u[idx] 过滤可以通过mask机制12np.array([1,2,3])[np.array([False,True,False])]np.array([1,2,3])[np.array([0,1,0]).astype(np.bool)] 注意这里用int的结果是不同的1np.array([1,2,3])[np.array([0,1,0])] Transform相关方法vectorize向量化是函数式编程中的一个默认的特性，向量化风格的写法天生直观，并且便于优化以及实现并行计算。numpy提供vectorize函数，用来将一个非numpy-aware的函数向量化，并运用到ndarray上。1class numpy.vectorize(pyfunc, otypes=None, doc=None, excluded=None, cache=False, signature=None) 向量化后的fminus，等于对数列中的每个元素都进行了减100的操作123a = np.arange(0, 10)fminus = lambda x: x - 100print(np.vectorize(fminus)(a)) 输出1[-100 -99 -98 -97 -96 -95 -94 -93 -92 -91] 升维在很多时候，我们会遇到升维的需求，例如我们要对一个一维数组做onehot得到一个二维数组，像下面这样写会报错1np.vectorize(lambda x: [0,0,0,1,0])(arr_1d) 对此，可以借助于下面的代码来实现，其中nb_classes指的是onehot的depth，也就是说onehot维的长度。12targets = np.array(arr_1d).reshape(-1)return np.eye(nb_classes)[targets] 那么有没有更通用的办法呢？爆栈网上就有人问能不能one-to-n这样映射，vectorize主要是为了将非numpy-aware的函数提升到numpy上，而如果说要进行升维的操作，那么必然是numpy-aware的（因为相当于是ndarray套ndarray了），但其实也是有办法的，就是借助于signature。12fminus2order = np.vectorize(lambda x: np.array([x - 100]), signature='()-&gt;(n)')print(fminus2order(a)) 输出12345678910[[-100] [ -99] [ -98] [ -97] [ -96] [ -95] [ -94] [ -93] [ -92] [ -91]] 降维vectorize对于二维数组，也是逐元素应用的123456789a2d = a.reshape((5,2))print(np.vectorize(fminus)(a2d))'''[[-100 -99] [ -98 -97] [ -96 -95] [ -94 -93] [ -92 -91]]''' 但有的时候，我们需要用到对12fsum1order = np.vectorize(lambda x: x.sum(), signature='(n)-&gt;()')print(fsum1order(a2d)) 输出就是对每一行求和1[ 1, 5, 9, 13, 17] 那么如果要对列求和怎么办呢？请往下看 vectorize的性能问题vectorize性能没有经过优化，所以第二行要比第一行性能好。12arr = np.vectorize(lambda x: 1 if x &gt; 0 else 0)(arr)arr[arr &gt; 0] = 1 apply_over_axesapply_over_axes函数可以指定对哪一个轴应用函数12345678&gt;&gt;&gt; np.apply_over_axes(np.sum, a2d, [1])array([[ 1], [ 5], [ 9], [13], [17]])&gt;&gt;&gt; np.apply_over_axes(np.sum, a2d, [0])array([[20, 25]]) 我们也可以通过指定所有轴的方式让函数应用到所有的轴上面123456&gt;&gt;&gt; np.apply_over_axes(lambda x,axis: x+1, a2d, [0,1])array([[ 2, 3], [ 4, 5], [ 6, 7], [ 8, 9], [10, 11]]) Reduce相关方法countnumpy中没有类似np.count(value)这样的方法，要知道这是连Python里面的原生list都有的。但是爆栈网上给出了下面的思路123a = numpy.array([0, 3, 0, 1, 0, 1, 2, 1, 0, 0, 0, 0, 1, 3, 4])unique, counts = numpy.unique(a, return_counts=True)dict(zip(unique, counts)) 可以看出，unique函数还是十分强大的。此外，如果只是统计0的数量，可以用下面的函数1np.count_nonzero(y) 再结合一下mask方法1np.count_nonzero(y == value) 此外，如果限定是大数据量，但是值域很小并且是整数的场景，还可以用bincount来解决。 all和anyall指定axis会降维。如果不带参数，会返回scalar。1234a = np.array([[True, True], [True, True]])print a.all()print a.all(axis=0) 如果指定keepdims，那么返回的数组保持和原数组一样的维度。12print a.all(keepdims=True)print a.all(axis=0, keepdims=True) 我们考虑sum方法，下面的两个语句都是按行相加，但一个返回二维数组，一个返回一维数组。12print(np.sum(a, axis=1, keepdims=True))print(np.sum(a, axis=1)) 广播123print np.array([3]) * 2print np.array([3]) * np.array([2,4,6])print np.array([3]) * np.array([[2,4,6]]) 但是下面的代码会报错1print np.array([3,7]) * np.array([2,4,6]) 显示1ValueError: operands could not be broadcast together with shapes (2,) (3,) ndarray对Python函数的亲和性原生函数 len 一般返回ndarray的行数 zip zip作用到两个一维ndarray，会得到一个原生的list。 12345z1 = np.array([1,2,3,4,5])z2 = np.array([6,7,8,9,10])z = zip(z1, z2)print(z)print(type(z)) 输出 12[(1, 6), (2, 7), (3, 8), (4, 9), (5, 10)]&lt;type 'list'&gt; 如果说zip两个不同维度的呢？ 1list(zip(np.array([[1,2],[3,4]]), np.array([5,6]))) 输出 1[(array([1, 2]), 5), (array([3, 4]), 6)] any和all 注意，numpy中也有any和all，例如(A==B).all()返回A和B中是否所有的数都对应相等。 itertools 12import itertoolsprint(list(itertools.imap(lambda x, y: x * y, z1, z2))) 原生类型转换ndarray和原生数组/常量的互转 pandas类型转换详见pandas相关 matplotlib一个程序中，所有的plot默认会画到一个figure上。包括使用importlib的调用。所以应当使用plt.figure(x)来选择绘制的图，并使用close(x)进行关闭。 Reference https://github.com/numpy/numpy/blob/0703f55f4db7a87c5a9e02d5165309994b9b13fd/numpy/core/src/multiarray/shape.c https://www.runoob.com/numpy/numpy-dtype.html https://numpy.org/doc/stable/reference/ufuncs.html]]></content>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GCC和MSVC在pow函数实现和类型转换比较]]></title>
    <url>%2F2016%2F01%2F16%2FC-GCC-VS-pow%2F</url>
    <content type="text"><![CDATA[ACM中常常遇到卡精度的问题，卡精度可能因为取整、比较相等、高精度等多种原因。这里通过一个例子试图探讨两个编译器的浮点数运算实现机制以及类型转换的机制，以及使用不同编译器和使用不同指令集在取整上的卡精度的问题。 问题描述江科大的nomasp同学在刷Leetcode(171:Excel Colmun Number)的时候发现了一个问题。他的代码（简化后）如下：123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;cmath&gt;using namespace std;int solve(string s) &#123; int n = 0, len = s.length(); for(int i = 0; i &lt; len; ++ i) &#123; int c = s[i] - 'A' + 1; n += c * pow(26, len - 1 - i); cout&lt;&lt;"c = " &lt;&lt; c &lt;&lt; endl; cout&lt;&lt;"pow = " &lt;&lt; pow(26, len - 1 - i) &lt;&lt; endl; cout&lt;&lt;"n = " &lt;&lt; n &lt;&lt; endl; cout&lt;&lt;endl; &#125; return n;&#125;int main() &#123; cout&lt;&lt;solve("AAB"); return 0;&#125; 使用Mingw32 GCC/G++(4.7.2)编译(g++.exe cpp_path -o exepath -std=c++11 -g3 -static-libstdc++ -static-libgcc -g3)后，输出如下：使用MSVC140(VS2015)编译后，输出如下：稍有常识的人都会看出，GCC的结果是错误的。 问题分析有同学认为pow函数是个浮点函数，因此应当转成int之后再相加减，但实际试验之后发现这个问题仍然存在，结果是：经过分析，如果手动实现pow函数则GCC的结果是对的。因此定位到调用pow函数这边出了问题。因此取一下测试代码分析。12345678910#include &lt;cstdio&gt; #include &lt;cmath&gt;using namespace std;int main() &#123; float f = pow(26, 2); int i = f; int i2 = pow(26, 2); printf("%f %d %d\n", f, i, i2); //似乎这个版本的GCC不支持%lf return 0;&#125; 在GCC下编译运行得：在VS2015下编译运行得：可以发现对GCC，当使用float变量直接初始化int时发生窄化，不过不影响结果。但是将这个float变量换成pow函数后就会影响结果。谦谦同学指出在GCC520版本下源代码也能正常运行。他进而提出pow函数返回的是double，在转成int的时候需要先转成float再转成int。根据这个意见，我测试了下面的代码，如果说会先转换成float，那么yy的值应当为55，因为从double到float的过程中精度丢失了。12345678910int main()&#123; float x = 54.999999999999993; int y = (int) x; double xx = 54.999999999999993; int yy = (int) xx; long double xxx = 54.999999999999993; int yyy = (int) xxx; printf("%d %d %d\n", y, yy, yyy); return 0;&#125; 不过结果是55 54 54，看来从double到int并不会经过float。不过在他的提示下，我把pow函数改成powf函数，发现返回值正常了。既然如此，我又测试了下面的代码123456789#include &lt;cstdio&gt; #include &lt;cmath&gt;using namespace std;int main() &#123; double f = pow(26, 2); int i = f; printf("%f %d\n", f, i); return 0;&#125; 按照上面的理论，这里应该输出675，但结果却是正确的676。因此现在的差别实际上就来自pow函数，我倾向于是一个RVO问题。为了进一步研究原因，需要比较对pow函数的实现以及类型转换机制。 MSVC对pow的实现MSVC中我们实际上使用的是double pow&lt;int, int&gt;(int _Left, int _Right); 这个重载版本。首先定位到头文件xtgmath.h：123456789101112//xtgmath.h_C_STD_BEGIN// #define _STD ::std::// #define _CSTD ::template&lt;class _Ty1, class _Ty2&gt; inline typename _STD enable_if&lt; _STD is_arithmetic&lt;_Ty1&gt;::value &amp;&amp; _STD is_arithmetic&lt;_Ty2&gt;::value ,typename _STD _Common_float_type&lt;_Ty1, _Ty2&gt;::type&gt;::type pow(const _Ty1 _Left, const _Ty2 _Right) &#123; // bring mixed types to a common type typedef typename _STD _Common_float_type&lt;_Ty1, _Ty2&gt;::type type; return (_CSTD pow(type(_Left), type(_Right))); &#125; 可以看到最后调用一个参数是_Common_float_type的pow函数，那这个函数在哪里呢，我们首先来看一下_Common_float_type这个类型。123456789101112131415161718192021//xtr1common.h typedef integral_constant&lt;bool, false&gt; false_type;// integral_constant is convenient template for integral constant types//xtgmath.h template&lt;class _Ty&gt; struct _Promote_to_float &#123; // promote integral to double typedef typename conditional&lt;is_integral&lt;_Ty&gt;::value, double, _Ty&gt;::type type; &#125;; template&lt;class _Ty1, class _Ty2&gt; struct _Common_float_type &#123; // find type for two-argument math function typedef typename _Promote_to_float&lt;_Ty1&gt;::type _Ty1f; typedef typename _Promote_to_float&lt;_Ty2&gt;::type _Ty2f; typedef typename conditional&lt;is_same&lt;_Ty1f, long double&gt;::value || is_same&lt;_Ty2f, long double&gt;::value, long double, typename conditional&lt;is_same&lt;_Ty1f, double&gt;::value || is_same&lt;_Ty2f, double&gt;::value, double, float&gt;::type&gt;::type type; &#125;; 这边说明一下这段代码：std::is_integral用来判断一个类型是否是整数std::conditional有三个参数，其作用相当于_Test? _Ty1: _Ty2，其中_Ty1和_Ty2都是类型，而std::enable_if相对std::conditional省略了假的情况。std::is_same用来判断_Ty1和_Ty2是否相同类型。这个是模板编程里面常用到的元函数。_Promote_to_float用来将integral（整数）类型扩成double类型，如果是浮点数则不变。说到扩展，也挺有意思的，例如char在被爆之后是直接变成int，还有符号扩展和0扩展啥的，可以查看CSAPP P49页。_Common_float_type意思就是123456if (_Ty1 is long double || _Ty2 is long double) typedef type long doubleelse if(_Ty1 is double || _Ty2 is double) typedef type doubleelse typedef type float 用来给浮点数之间运算结果选择适合的精度 下面我们开启调试，跟踪pow函数执行。在调试中，在断点_CSTD pow(type(_Left), type(_Right))处发现type(_Left)和type(_Right)都已经通过_Common_float_type变成了double，继续跟踪发现直接调用了math.h中的pow。特别地，对于c mode，pow实际直接调用了pow(double, double)。此外还注意到&lt;cmath&gt;中有一个的_Check_return_ inline double pow(_In_ double _Xx, _In_ int _Yx)函数，而这个函数实际上调用了&lt;cmath&gt;中的_Pow_int函数，该函数如下： 1234567891011121314151617template&lt;class _Ty&gt; _Check_return_ inline _Ty _Pow_int(_Ty _Xx, int _Yx) _NOEXCEPT &#123; unsigned int _Nx; if (_Yx &gt;= 0) _Nx = static_cast&lt;unsigned int&gt;(_Yx); else _Nx = static_cast&lt;unsigned int&gt;(-_Yx); for (_Ty _Zx = static_cast&lt;_Ty&gt;(1); ; _Xx *= _Xx) &#123; if ((_Nx &amp; 1) != 0) _Zx *= _Xx; if ((_Nx &gt;&gt;= 1) == 0) return (_Yx &lt; 0 ? static_cast&lt;_Ty&gt;(1) / _Zx : _Zx); &#125; &#125; 这段代码主要就是处理指数为int的情况，其使用的是类似于快速幂的方法得到的结果。不过经过测试，这段代码始终没有被调用的情况，为什么标准库不使用这个重载版本，我想附录里面的一段答案应该能够给我们启发。对于以上代码，我想最重要的就是_Common_float_type，它避免了GCC472版本的类型二次转换的错误，直接调用对应类型的重载版本。 MSVC对类型转换的实现为了分析_pow函数，需要先了解一下MSVC对于类型转换的实现方案 double -&gt; int123456789101112131415161718192021222324; int i = pow(26, 2);00E7277E push 2 00E72780 push 1Ah 00E72782 call pow&lt;int,int&gt; (0E71064h) 00E72787 add esp,8 00E7278A call __ftol2_sse (0E71195h) 00E7278F mov dword ptr [i],eax ; int i = pow(26.0, 2.0);00FE277E sub esp,8 00FE2781 movsd xmm0,mmword ptr ds:[0FEAB98h] 00FE2789 movsd mmword ptr [esp],xmm0 00FE278E sub esp,8 00FE2791 movsd xmm0,mmword ptr ds:[0FEABD0h] 00FE2799 movsd mmword ptr [esp],xmm0 00FE279E call _pow (0FE11FEh) 00FE27A3 add esp,10h 00FE27A6 call __ftol2_sse (0FE1195h) 00FE27AB mov dword ptr [i],eax ; double s = 26.0;00D8277E movsd xmm0,mmword ptr ds:[0D8AB98h] 00D82786 movsd mmword ptr [s],xmm0 ; int i = s;00D8278B cvttsd2si eax,mmword ptr [s] 00D82790 mov dword ptr [i],eax 这里我们发现如果pow参数都为int则是调用pow&lt;int, int&gt;，而这个pow&lt;int, int&gt;是通过xtgmath.h中的pow函数实现的：12345678910111213141516171819202122_C_STD_BEGIN;template&lt;class _Ty1,; class _Ty2&gt; inline; typename _STD enable_if&lt; _STD is_arithmetic&lt;_Ty1&gt;::value; &amp;&amp; _STD is_arithmetic&lt;_Ty2&gt;::value,; typename _STD _Common_float_type&lt;_Ty1, _Ty2&gt;::type&gt;::type; pow(const _Ty1 _Left, const _Ty2 _Right); &#123; // bring mixed types to a common type00FE2B12 mov ecx,30h 00FE2B17 mov eax,0CCCCCCCCh 00FE2B1C rep stos dword ptr es:[edi] ; typedef typename _STD _Common_float_type&lt;_Ty1, _Ty2&gt;::type type;; return (_CSTD pow(type(_Left), type(_Right)));00FE2B1E cvtsi2sd xmm0,dword ptr [_Right] 00FE2B23 sub esp,8 00FE2B26 movsd mmword ptr [esp],xmm0 00FE2B2B cvtsi2sd xmm0,dword ptr [_Left] 00FE2B30 sub esp,8 00FE2B33 movsd mmword ptr [esp],xmm0 00FE2B38 call _pow (0FE11FEh) 00FE2B3D add esp,10h ; &#125; cvtsi2sd来自SSE2，负责取出最低位的64位整型，并将其转换为一个浮点值，存放到xmm0浮点寄存器中。mmword负责将xmm0内的浮点移到[esp]所以pow&lt;int, int&gt;实现也是先转换成浮点再调用_pow对于__ftol2_sse函数底层是调用cvtsi2sd函数的，相比之下由于double是有符号而且表示范围要大于int，因此需要额外加一些处理。所以实际上通过调用cvttsd2si函数进行了类型转换。 float -&gt; int1234567891011121314151617; int i = powf(26, 2);00C5277E push ecx 00C5277F movss xmm0,dword ptr ds:[0C5AB48h] 00C52787 movss dword ptr [esp],xmm0 00C5278C push ecx 00C5278D movss xmm0,dword ptr ds:[0C5AB4Ch] 00C52795 movss dword ptr [esp],xmm0 00C5279A call _powf (0C51523h) 00C5279F add esp,8 00C527A2 call __ftol2_sse (0C51195h) 00C527A7 mov dword ptr [i],eax ; float s = 26.0;00D5277E movss xmm0,dword ptr ds:[0D5AB48h] 00D52786 movss dword ptr [s],xmm0 ; int i = s;00D5278B cvttss2si eax,dword ptr [s] 00D52790 mov dword ptr [i],eax MSVC对_pow函数的实现下面分析_pow函数首先win7并没有装MSVC 140的库，编译成静态IDA导入不了PDB，都是天书。于是再在win10下面使用ollydbg来调试，然而并找不到_main，只看到_cinit函数包含的_initterm，只好靠调用关系和参数传递硬找。 过程 图片 解释 进入main函数 main函数 pow函数 pow函数 跳转使用SSE指令集计算pow pow函数返回 pow函数返回后准备调用类型转换函数 使用cvttsd2si的类型转换函数 第一行的cmp指令由于不等于0，所以使用cvttsd2si而不是fistp，注意和后面gcc使用fistp进行比较 类型转换的结果 od_win10_vs_after_main_exit 退出main函数 可以看到exit和_cexit函数 GCC对pow的实现GCC版本之间差别比较大，我们这里还以GCC 472(Mingw32)分析。并简化了函数12345678#include &lt;cstdio&gt; #include &lt;cmath&gt;using namespace std;int main() &#123; int i2 = pow(26, 2); printf("%d\n", i2); return 0;&#125; 跟踪pow函数，发现实际调用了/MinGW32/lib/gcc/mingw32/5.7.2/include/c++/cmath中的函数12345678template&lt;typename _Tp, typename _Up&gt; inline _GLIBCXX_CONSTEXPR typename __gnu_cxx::__promote_2&lt;_Tp, _Up&gt;::__type pow(_Tp __x, _Up __y) &#123; typedef typename __gnu_cxx::__promote_2&lt;_Tp, _Up&gt;::__type __type; return pow(__type(__x), __type(__y)); &#125; 的重载std::pow&lt;int, int&gt;(__x = 26, __y = 2)汇编代码如下1234567891011 0x00401d20 &lt;+0&gt;: push %ebp 0x00401d21 &lt;+1&gt;: mov %esp,%ebp 0x00401d23 &lt;+3&gt;: sub $0x18,%esp 0x00401d26 &lt;+6&gt;: fildl 0xc(%ebp) 0x00401d29 &lt;+9&gt;: fildl 0x8(%ebp) 0x00401d2c &lt;+12&gt;: fxch %st(1) 0x00401d2e &lt;+14&gt;: fstpl 0x8(%esp) 0x00401d32 &lt;+18&gt;: fstpl (%esp)=&gt; 0x00401d35 &lt;+21&gt;: call 0x401c88 &lt;pow&gt; 0x00401d3a &lt;+26&gt;: leave 0x00401d3b &lt;+27&gt;: ret 其中fildl表示往st（浮点数操作堆栈）栈顶放入一个长整数，fstpl是取出一个长整型数然后调用了crt中的pow函数的汇编代码 12345678910111213141516 0x74cd34b0 &lt;+0&gt;: cmpl $0x0,0x74cf6d84=&gt; 0x74cd34b7 &lt;+7&gt;: je 0x74cd3544 &lt;msvcrt!_CrtDbgReportWV+84&gt; 0x74cd34bd &lt;+13&gt;: sub $0x8,%esp 0x74cd34c0 &lt;+16&gt;: stmxcsr 0x4(%esp) 0x74cd34c5 &lt;+21&gt;: mov 0x4(%esp),%eax 0x74cd34c9 &lt;+25&gt;: and $0x1f80,%eax 0x74cd34ce &lt;+30&gt;: cmp $0x1f80,%eax 0x74cd34d3 &lt;+35&gt;: jne 0x74cd34e4 &lt;pow+52&gt; 0x74cd34d5 &lt;+37&gt;: fnstcw (%esp) 0x74cd34d8 &lt;+40&gt;: mov (%esp),%ax 0x74cd34dc &lt;+44&gt;: and $0x7f,%ax 0x74cd34e0 &lt;+48&gt;: cmp $0x7f,%ax 0x74cd34e4 &lt;+52&gt;: lea 0x8(%esp),%esp 0x74cd34e8 &lt;+56&gt;: jne 0x74cd3544 &lt;msvcrt!_CrtDbgReportWV+84&gt; 0x74cd34ea &lt;+58&gt;: jmp 0x74ce0249 &lt;msvcrt!modf+9193&gt; 0x74cd34ef &lt;+63&gt;: nop 其中stmxcsr将MXCSR存储到32位寄存器，modf将数分解为整数部分和小数部分。在0x74cd34b7 &lt;+7&gt;处程序进入msvcrt!_CrtDbgReportWV+84。然后在其中某一个modf方法中卡死。于是很奇怪为什么要用到msvcrt!_CrtDbgReportWV这个函数后来我试图用IDA来调试，不过win10 把我的安装程序杀掉了，所以我试图在win7里面用IDA调试，首先装完DevCPP之后进行调试，发现了不一样的光景。crt中pow函数的代码变成了这样！ 1234567891011121314=&gt; 0x7613608f &lt;+0&gt;: cmpl $0x0,0x761b50c0 0x76136096 &lt;+7&gt;: je 0x7613609d &lt;pow+14&gt; 0x76136098 &lt;+9&gt;: jmp 0x76140eb8 &lt;msvcrt!_CIpow+271&gt; 0x7613609d &lt;+14&gt;: lea 0xc(%esp),%edx 0x761360a1 &lt;+18&gt;: call 0x76120c6f &lt;msvcrt!_clearfp+230&gt; 0x761360a6 &lt;+23&gt;: jmp 0x76120c85 &lt;msvcrt!_clearfp+252&gt; 0x761360ab &lt;+28&gt;: movl $0x8,-0x218(%ebp) 0x761360b5 &lt;+38&gt;: jmp 0x7611cf67 &lt;wtoi+1860&gt; 0x761360ba &lt;+43&gt;: cmp %edi,%esi 0x761360bc &lt;+45&gt;: jne 0x7611c269 &lt;wcsncpy_s+30&gt; 0x761360c2 &lt;+51&gt;: jmp 0x7615dbb3 &lt;msvcrt!_ftol2_sse_excpt+114168&gt; 0x761360c7 &lt;+56&gt;: xor %eax,%eax 0x761360c9 &lt;+58&gt;: mov %ax,(%esi) 0x761360cc &lt;+61&gt;: jmp 0x7611c2b8 &lt;wcsncpy_s+109&gt; 反汇编居然不一样了！那到底哪个结果是对的呢？用IDA调试发现GCC编译结果连main函数都不知道在哪里，到处都是sub_xxxx的无名函数，于是使用OD进行调试，至少能看清楚先后调用关系 下面是调试过程 过程 图片 解释 进入main函数 前面要先经过两个jmp 进入pow&lt;int, int&gt;函数 进入CRT中的pow函数的跳转 这里是一个jmp跳转 进入CRT中真正的pow函数 可以和WIN10和WIN7下的DEVCPP的反汇编进行对比 CRT中pow函数返回 注意右边寄存器表中的ST0的值是正确的26**2==676.00 printf前的结果 注意到eax实际上存放着printf的参数int i2，但是变成了整数0x02A3==675而不是676 所以应该是在浮点数变成整数这块出了问题先解释几个汇编指令 汇编 解释 fstcw 存储FPU控制字到一个内存区域 fldcw 逆运算 fistp 存储ST(0)到整数并弹出寄存器堆栈 下面来看main函数中是如何将FPU中的运算结果拿到eax中并提供给printf输出的 过程 图片 解释 从pow&lt;int, int&gt;函数跳出 发现此时运算结果还在ST(0)中，并且fstcw指令从[esp+1e]处存取浮点控制字，fisttp指令将ST(0)存放到[esp+1c]==0x0028ff1c处 运行完fistp检查内存块0x0028ff1c 发现此时结果变为2a3==675，于是应该是fistp指令出现了问题 总结MSVC 140和GCC472(MinGW)使用了不同的汇编指令进行类型转换，导致出现问题。GCC使用了x87 FPU指令而MSVC 140使用了SSE指令集。如果改成这样的方式123456789#include &lt;cstdio&gt; #include &lt;cmath&gt;using namespace std;const double eps = 1e-6; int main() &#123; int i2 = pow(26, 2) + eps; printf("%d\n", i2); //似乎这个版本的GCC不支持%lf return 0;&#125; 输出结果在GCC472版本上也是正确的了 Postscript本文参考了在 cplusplus.com 上guestgulkan给出的这样的解答： This is actually quite interesting and works differently on Microsoft Visual Studio 2008 and Dev C++(using mingw); Microsoft Visual Studio 2008 cmath is basically a wrapper that calls math.h.In math.h if running in C mode you only get one power function pow(double, double).In C++ mode (which we are using) you get the c++ overloaded functions:long double pow(long double,int), float pow(float,int), double pow(double,int) and a few others.So calling pow(int, int) for example pow(3,2) will always fail due to ambiguity whether you include cmath or math.h DEV C++ with MINGWWith this set up, math.h just contains the the usual C functionpow(double, double) - so all the functions work because with pow(int, int) both ints get promoted to double by compiler and all is OKcmath in more than a wrapper for math.h. First it includes math.h and then undefines a whole lot of stuff that math.h defined, and substitutes the c++ versions.This includes the pow function declaration.As the c++ overloaded functions (same as any other c++ compiler), you will get the ambiguity problem - when using pow(int, int).P.S The ambiguity occurs with pow(int, int) because integers can be promoted to floats or doubles, which means that pow(int, int) can fit any of the 6 or so overloaded c++ pow function - so the compiler gets confused. 对于标准库对pow函数的处理，stackoverflow上的enigmaticPhysicist给出了这样的回答： A specialisation of pow(x, n) to where n is a natural number is often useful for time performance. But the standard library’s generic pow() still works pretty (surprisingly!) well for this purpose and it is absolutely critical to include as little as possible in the standard C library so it can be made as portable and as easy to implement as possible. On the other hand, that doesn’t stop it at all from being in the C++ standard library or the STL, which I’m pretty sure nobody is planning on using in some kind of embedded platform.]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>C++</tag>
        <tag>MSVC</tag>
        <tag>GCC</tag>
        <tag>卡精度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[brainfuck]]></title>
    <url>%2F2015%2F12%2F26%2Fbrainfuck%2F</url>
    <content type="text"><![CDATA[brainfuck是一个图灵完备的语言，仅有8个操作，晦涩难懂，但能够像图灵机一样完成任何计算。本文主要讨论一下brainfuck的一些编程技巧。 brainfuck由8个操作，输入输出流，一块初始化为0的内存，以及一个全局指针ptr（默认指向内存块的开始）构成。八个操作分别为（这里采用c描述）：12345678&gt; ptr++&lt; ptr--+ *ptr++- *ptr--, *ptr = getchar(). putchar(*ptr)[ while(*ptr)&#123;] &#125; // of while 马上就是新年了，下面这段程序可以输出HappyNewYear1++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++.+++++++++++++++++++++++++.+++++++++++++++..+++++++++.&gt;++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++.+++++++++++++++++++++++.&lt;--.++.&gt;.----.+++++++++++++++++. brainfuck由于语法简单，所以解释器也非常好实现，这里也实现了一个：Calvin’s brainfuck interpreter。由于写bf会导致+-&lt;&gt;比较多，解释器也提供了+(48)表示连续48个加号的糖，同时也可使用%作注释，使用#stk访问变量表。程序可以开启debug模式，可以使用#dbg和#cdb代码块局部开启或关闭debug模式。同时这边也附了一个贪心算法的实现，用比较短的bf代码打印字符串。等我考完试再优化一下ლ(╹◡╹ლ)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# https://github.com/CalvinNeo/brainfuck/blob/master/print_gen.py#coding:utf8import sysdef naive_gen(ascii): code = '' for x in ascii: code += '&gt;' + '+' * ord(x) + '.' return codedef greedy_gen(ascii): current = [] code = '' ptr = -1 for x in ascii: if len(current) == 0: code += '+' * ord(x) + '.' ptr += 1 current.append(x) else: min_dist = 256 min_index = 0 for (index, y) in zip(range(len(current)), current): if abs(ord(y)-ord(x)) &lt; min_dist: min_dist, min_index = abs(ord(y)-ord(x)), index if min_dist &lt; ord('A'): if ord(current[min_index]) &gt;= ord(x): ptr_delta = '-' * ( ord(current[min_index]) - ord(x) ) else: ptr_delta = '+' * ( ord(x) - ord(current[min_index]) ) if min_index &gt;= ptr: ptr_move = '&gt;' * ( min_index - ptr ) else: ptr_move = '&lt;' * ( ptr - min_index ) code += ptr_move + ptr_delta + '.' ptr = min_index current[min_index] = x else: code += '&gt;' * (len(current) - ptr) + '+' * ord(x) + '.' current.append(x) ptr = len(current) - 1 return codeif __name__ == '__main__': ascii = raw_input() print greedy_gen(ascii) 下面介绍一下brainfuck的常用技巧。 数学运算 乘法以下代码实现了两个一位数乘法：123456789101112131415161718,-(48)&gt;,-(48) % read 2 integers[- % while $2-- &lt; % set ptr to $1 [ - % while $1-- &gt;&gt;+ % $3++ &gt;+ % $4++ &lt;&lt;&lt; % set ptr back to $1 ] &gt;&gt;&gt; % set ptr to $4 [ % copy $4 to $1 - % while $4-- &lt;&lt;&lt;+ % $1++ &gt;&gt;&gt; % set ptr back to $4 ] &lt;&lt; % move ptr to $2 and continue]&gt;+(48). % print answer in $3 内存操作 清空存储区这里需要特别强调一下，brainfuck里面没有生存空间这样的概念，也就是它的ptr是全局的单例的，在使用[]嵌套循环的时候，要特别注意这一点。12 语言结构 if语句 switch语句 嵌套循环]]></content>
      <tags>
        <tag>brainfuck</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中for循环的一个用法]]></title>
    <url>%2F2015%2F12%2F22%2FC-for%2F</url>
    <content type="text"><![CDATA[今天发现了C/C++里面for的一个不常见到的用法，来水一篇文章。 今天看到一个技术交流群上面分享了下面这一段代码；12345678910111213#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; string s; cin &gt;&gt; s; for(int i = s.size(); i--;)&#123; cout &lt;&lt; s[i]; &#125; cout &lt;&lt; endl; return 0;&#125; 请注意这一行for(int i = s.size(); i--;){ 乍一看循环根本不能跳出，使用g++编译，发现得到了正确的反向字符串。我们使用char[]代替string，并跟踪i，发现i实现了递减，并且当(i--)等于0时，循环跳出。12345678910111213#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; char s[] = &#123;'a','b','c','d','e'&#125;; for(int i = 5; i--;)&#123; cout &lt;&lt; i; cout &lt;&lt; s[i]; &#125; cout &lt;&lt; endl; return 0;&#125; 于是得出初步结论，for(A;B;C)语句中，当C为空时，B在更新循环标记的同时起返回值作为循环结束的条件。其作用相当于下面代码中的judge_end函数。12345678910111213141516#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;bool judge_end(int &amp; i)&#123; return i-- &lt;= 0 ? false : true;&#125; int main()&#123; char s[] = &#123;'a','b','c','d','e'&#125;; for(int i = 5; judge_end(i);)&#123; cout &lt;&lt; i; &#125; cout &lt;&lt; endl; return 0;&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ACM/ICPC EC-FINAL小结]]></title>
    <url>%2F2015%2F12%2F14%2FICPC-EC-FINAL%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[EC-FINAL是2015年度最后一次ACM区域赛了，这次总共有288个队参加比赛。命题还是Google。 正式赛赛题这次出生点在强队中间，右后方就是本次冠军，唯一的9A，陈立杰的华莱士队，左边是北航的7A，正后方是浙大，右边是广大。热身赛题目是Google一次网试的笔试题。A题Dynamic Grid，直接暴力模拟。B题IP Summarization，要求是给出若干个IP以及他们的掩码，要求输出合并的Normalize之后的所有IP，Google给的思路就是建一颗二叉树。实际做的时候发现这道题要注意一点就是你要先排序，考虑子网和合并的情况。C题Virtual Rabbit，讲的是一个人只能在[W,H)和[B,G)时间段内喂兔子，兔子在X秒内不被喂食就会死去，问喂食的最少次数。正式赛还是比较有难度的。水题是ADLM。A题Boxes and Balls，据说是一个初中数学题，找最大的m，使得m(m+1)/2 &lt; N，解方程的时候用double可能会出精度问题，没清WA了一次，其实也可以用二分去做。M题November 11th，电影院里面Singles不能坐在相邻的座位，且有B个坏椅子的坐标，求最多最少可以坐多少个单身狗。这里要注意只要两个人中间隔两个就不能坐人了，一开始想成了一个。结果是模3有规律，直接硬算找规律。然后就是坑爹的D题，题目的意思是你有A块钱，不过是整的，你现在要买一个自动售货机换得零钱然后去付另外的B块钱，问你最少需要在自动售货机上面卖多少钱东西，其中A,B∈{0.01,0.02,0.05,0.1,0.2,0.5,1,2,5,10,20,50,100}。又看到样例T&lt;=78的时候笑了，这个不就是打表嘛，总共78个样例，于是我们在纸上手算了半天，但是到最后还是没有A出来，出来之后才知道，可以在自动售货机上面买若干次。至于L题，讲的是有一个无限大的乘法表，现在给定一个由数字和问号（相当于未知）矩阵，问这个矩阵有没有可能是这个大的乘法表的一部分。这道题目思路就是只要矩阵中知道两个数，那么我们就可以把整个矩阵的所有值解出来，这样我们就可以一一确定剩下来的值是否符合我们已经确定了的矩阵了。但是我们忽略了一种情况，就是如果只有一个数的话，这个矩阵不一定存在，比如1这个数，他只能出现在第一行的第一列，如果有这样的一个矩阵：123? ? ?? 1 ?? ? ? 那它肯定不是乘法表的一部分，因此我们少一步分解因数，检查每一个数字是否能够出现在这个乘法表中的过程。 感受 上海大学宝山校区好荒啊，我们住在蓝波万酒店感觉名字好屌啊，走到学校好远啊。然而宾馆只有一张大床一张小床，我和良哥阿洁哥一起睡的，纪存哥阿涛和清恒拼在一起睡得，结果他们晚上被阿涛各种挤。 晚上吃了羊蝎子火锅超级逗，一盆饭6块钱，一盘豆芽菜1块钱，阿涛点了六盘豆芽菜，然后大家最后实际上就是在吃豆芽菜 宾馆里面有电脑！于是热身赛晚上张老师让我们写一写热身赛的题目，于是我们只好装做在电脑上写，但是阿涛一直给女票盈盈买衣服，张老师来了也不停，超级逗笔。]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>现场赛</tag>
        <tag>ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LaTeX学习笔记]]></title>
    <url>%2F2015%2F12%2F02%2FLaTeX%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[目录 Step 0. 配置LaTeX Step 1. 使用LaTeX做Routine Work Hello, World 带格式的文本 加入数学公式的文本 特殊字符的输入 Step 2. 支持中文 Step 3. 论文编辑的常用元素 一些额外需要注意的配置 数学符号 矩阵 表格 有序列表和无序列表 代码 Step 4. 段落，段落格式和目录 分段 目录和标题 交叉引用 Step 5. 图片 Step 6. 页面设置 Step 7. 模板 Step inf. 额外说明 TeX是由高德纳开发的一款排版引擎，由于纯TeX过于底层，所以很多人选择使用LaTeX，LaTeX是TeX的一个常用宏包。一般来说在使用LaTeX时写论文时，官方都会给一套现成的模板，我们按照上面的说明用就行。但有些先验知识我们还是要先学习的。 Step 0. 配置LaTeXWindows下常用的LaTeX命令行工具是MikTeX，不过我们一般直接使用CTEX整合包。特别需要注意的是CTEX的安装过程会重置Windows的环境变量，所以一定要注意先行保存！另外需要提及的就是各种LateX的IDE了，常用的有TexStudio、TeXMaker等，其实差别不大。下面以TeXStuido为主介绍。 TeXStudioTeXStudio是一个的界面还是比较简单容易操作的。其中配置常出现以下问题： Make sure that you have installed a (La)TeX distribution这是因为没有没有安装LaTeX发行版的缘故，TeXStudio是一个可配置的LaTeX编辑器，我们需要单独安装对应的编译器。有很多LaTeX的发行版，我们这里可以安装使用MikTeX。可前往MikTeX官网 http://miktex.org/ 上下载对应的版本。安装完后应当进入Options-&gt;Configure TeXStudio-&gt;Commands来检查MikTeX路径是否正确 没有错误，但是无法生成文档。这个可能是因为安装了其他LaTeX发行版，比如CTEX整合包的缘故，卸载该整合包，重新安装MikTeX即可。 Step 1. 使用LaTeX做Routine Work Hello, World 新建文档，并输入 1234\documentclass&#123;article&#125; % meta info of the document\begin&#123;document&#125; Hello, World\end&#123;document&#125; 生成文档，预览 带格式的文本 新建文档，并输入 123456789101112131415161718\documentclass&#123;article&#125;\begin&#123;document&#125; \noindent % no indent at the head of this paragraph \textbf&#123;Bold&#125; \newline % use this command to start a new line \textit&#123;Italic&#125; \\ % another way to start a new line \underline&#123;Underline&#125; \begin&#123;flushleft&#125; Left \end&#123;flushleft&#125; \begin&#123;center&#125; Middle \end&#123;center&#125; \begin&#123;flushright&#125; Right \end&#123;flushright&#125;\end&#123;document&#125; 生成文档，预览 其中： \noindent 取消段首缩进 \textbf{your_text} 加粗your_text \textit{your_text} 斜体的your_text \underline{your_text} 带有下划线的your_text \newline 和 \\ 是换行指令 \begin{command} 和 \end{command} 之间是command的scope，其中flushleft, center, flushright表示靠左、居中和靠右对齐 加入数学公式的文本 数学公式和普通文本的格式是不同的，应当使用$和$，\(和\)，\begin{math}和\end{math}将数学公式包起来，如 12345678910\documentclass&#123;article&#125;\begin&#123;document&#125; $a_&#123;1&#125;+b_&#123;1&#125; = c_&#123;1&#125;$ \\ \( a^&#123;2&#125; + b^&#123;2&#125; = c^&#123;2&#125; \) \\ \begin&#123;math&#125; \frac&#123;1&#125;&#123;2&#125; + \sqrt&#123;3&#125; = 0 \end&#123;math&#125;\end&#123;document&#125; 特别地，使用\[和\]或者\begin{displaymath} 和\end{displaymath}能够另起一行显示公式，试比较 123456789101112\documentclass&#123;article&#125;\begin&#123;document&#125; \noindent the equlation \[ 1+2+3+4 = 7 \] is not established the equlation \( 1+2+3+4 = 7 \) is true\end&#123;document&#125; 对于多个方程我们可以使用\begin{equation}和\end{equation}来标记,并且使用\label{name}来标记,使用\ref{name}来引用。 1234567891011121314\documentclass&#123;article&#125;\begin&#123;document&#125; \noindent \begin&#123;equation&#125; \label&#123;eq:eps&#125; \epsilon &gt; 0 % our formula \end&#123;equation&#125; \begin&#123;equation&#125; \label&#123;eq2:eps&#125; \delta &lt; 0 \end&#123;equation&#125; From (\ref&#123;eq2:eps&#125;), we can ... \end&#123;document&#125; 使用\textrm{xxx}插入普通格式的文本 特殊字符的输入 LaTeX中有一些字符是不能“正常”输入的。 除反斜杠之外的特殊字符，#、$、%、^、&amp;、_、{、}、~，可在前面直接加反斜杠，如\#便可显示# 反斜杠（stroke）：可使用$\backslash$生成。 空格：使用\,强行插入多个空格，注意一般英文文本需要两个\,才能达到理想的单词间距。其他插入空格的方式还有~、\;等 日期：可使用\today生成。 引号：用 产生左双引号，用`&#39;&#39;`产生右双引号。用 `产生左单引号，用&#39;产生右单引号。当单引号与双引号相邻时，在两者中间插入空格\,。 取反号和波浪号：用\~{}生成取反号（位置靠上），用$\sim$生成波浪号（位置竖直居中） 角度°：角度是一个上标的圆圈，圆圈用\circ生成，于是10度角就是$10^{\circ}$ 比较符号：大于等于号可以使用\geq、\textgreater等符号来表示。这里注意，不能以为等号是\eq，这样会报Undefined control sequence错误，等号就是=。 Step 2. 支持中文缺少ctex库的情况： 运行 C:\Program Files (x86)\MiKTeX 2.9\miktex\bin\mpm.exe 设置Repository，这里建议选择第一个中科大的资源站，如果不幸40X或者50X的话可以选择翻墙去比如华盛顿大学的（翻墙的话需要配置Connection Settings）镜像站。 选择安装ctex安装过程是这样的（注意进度条结束之后可能还有一个解压过程，不要点Cancel，等安装完毕，Cancel会变成Close） 按照以上方法安装 l3kernel, l3packages, ms, ulem, zhnumber, （cjk, cjkpunct）（PS 亦可通过ftp://mirrors.ustc.edu.cn/CTAN/systems/win32/miktex/tm/packages/ 直接下载lmza文件安装） 测试1234567\documentclass&#123;article&#125;\usepackage&#123;ctex&#125;\begin&#123;document&#125;\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gkai&#125; 蛤蛤蛤蛤蛤蛤\end&#123;CJK&#125;\end&#123;document&#125; Step 3. 论文编辑的常用元素 0. 一些额外需要注意的配置 需要补充安装 amsmath，listings，mptopdf几个包。这几个包的安装方法都可以参照Step2中中文支持包一样安装。 1. 数学符号 希腊字母 123\alpha α; \beta β; \gamma γ; \delta δ; \epsilon ε; \zeta ζ; \eta η; \theta θ; \iota t; \kappa κ; \lambda λ; \mu μ; \xi ξ：\nu ν; \o o; \pi π; \rho ρ; \sigma σ; \tau τ; \upsilon υ; \phi Φ; \chi Χ; \psi Ψ; \omega ω 将首字母大写可以得到大写的希腊字母 空格 在这里提过，可以用\,来生成一个小空格，此外数学公式中还可以用\quad和\qquad生成大小不等的空格。 一般来说，可以使用\来得到一个空格，这个空格比较小，用于词语词之间的分隔；用\@得到一个较大的句子之间的空格，用~得到一个不会在此处换行的空格。 此外，用来在一行中并列排放两个数学变量，用\quad也是一个不错的选择。其实对于空格，有以下的一些比例：\quad 即\hspace{1em}，一个英文字符**M**的宽度 \qquad 即\hspace{2em}，两个英文字符**M**的宽度 \; 5/18个英文字符的宽度 \: 4/18个英文字符的宽度 \, 3/18个英文字符的宽度 \! -3/18个英文字符的宽度 \hspace{长度} 产生指定宽度 \phantom{文本} 产生指定文本的宽度 插入普通文本 在这里 数学符号 对于任意的：\forall 存在：\exists 根号：\sqrt[n]表示n次方根，其中平方根可以省略[n] 括号：使用\big( \Big( bigg( Bigg( 生成不同大小的左（括号 省略号：ldots（位置靠下）和cdots（位置居中） 上标和下标 上标使用^来，下标采用_。特别地，当要将一个式子（而不是字母）作为上标，需要将这个式子整体括起来，如a^{x+y} 可以同时指定上标和下标，如a^{2}_{i} 特殊的上标，如导数符号，使用&#39;获得。例如对f求导，应当输入f&#39;而不是f^{&#39;} 此外，在平均数和估计中常用的hat和bar，可以写作\hat{x}，\bar{x} 修饰符 向量：\vec a，\overrightarrow{AB} 大的数学符号 如sigma，limit之类的数学符号在LaTeX中是相对容易输入的，选择对应的命令，按照上下标的输入方式输入即可。 1234567891011121314\documentclass&#123;article&#125;\begin&#123;document&#125; \noindent \begin&#123;equation&#125; \label&#123;eq:eps&#125; \epsilon \textrm&#123; simple text&#125; &gt; 0 % our formula \end&#123;equation&#125; \begin&#123;equation&#125; \label&#123;eq1:eps&#125; \lim_&#123;n \to \infty&#125; \sum_&#123;k=1&#125;^n k = \infty \end&#123;equation&#125;\end&#123;document&#125; 数学公式 使用双斜杠换行 123456789\documentclass&#123;article&#125;\begin&#123;document&#125; \noindent \begin&#123;equation&#125; \alpha_1 f_c b x = f_y A_s \\ M_u = f_y A_s (h_0 - \frac&#123;x&#125;&#123;2&#125;) \\ M_u = \alpha_1 f_c b x (h_0 - \frac&#123;x&#125;&#123;2&#125;) \\ \end&#123;equation&#125;\end&#123;document&#125; 方程组的情况： 2. 矩阵 12345678910111213141516\documentclass&#123;article&#125;\usepackage&#123;CJKutf8&#125;\usepackage&#123;amsmath&#125;\usepackage&#123;listings&#125; \usepackage&#123;graphicx&#125;\begin&#123;document&#125; \noindent \begin&#123;equation&#125; \begin&#123;bmatrix&#125; -1&amp; 1&amp; 1&amp; 1&amp; -1&amp; \ldots &amp; -1 \\ -1&amp;1&amp;1&amp;-1&amp;-1&amp; \ddots &amp; -1 \\ \vdots&amp; \vdots&amp; \vdots&amp; \vdots&amp; \vdots&amp; \vdots&amp; \vdots&amp; \\ 1&amp; 1&amp; 1&amp;-1&amp;-1&amp; \ldots &amp; 1 \\ \end&#123;bmatrix&#125; \end&#123;equation&#125;\end&#123;document&#125; 这里要注意几点：\begin{bmatrix}标记的，不过需要在数学编辑的环境下哦。 第一，\usepackage{amsmath}这个包是必备的，如果没有是无法生成文档的。 第二，&amp;区分矩阵中每一行的元素，\\区分矩阵中的每一行。 第三，&amp;后面的空格不是必须的，但是有了这个空格，源码会显得比较明朗，也易于修改。 第四，\ldots，\ddots，\vdots分别表示横过来的，斜过来的，竖过来的省略号。 3. 表格 首先先生成一个最简单的表格 123456789101112\documentclass&#123;article&#125;\usepackage&#123;multirow&#125;\begin&#123;document&#125; \noindent \begin&#123;tabular&#125;&#123;|l|c|r|&#125; \hline 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \\ \hline \end&#123;tabular&#125; \end&#123;document&#125; 可以看出表格和矩阵时差不多的，&amp;区分矩阵中每一行的元素，\\区分矩阵中的每一行。额外有几点的区别，补充说明如下： 我们使用\begin{tabular}和\end{tabular}来标记一个表格（注意，是tabular不是table哦）。 后面的{|l|c|r|}抽象地表示了一个表格的一行。其中|表示竖向的表格线，从而形成一行表格，当然也可以用||，这样表格线就是双层的啦。里面的l、c、r分别表示在这个格子里面中的文字是靠左，居中还是靠右对齐。特别地，当表格有很多行的时候写起来会比较麻烦，这时候可以采用重复指令*{n}{repeat}，其中*{n}{repeat}表示重复repeat n次，模板如下：*{3}{|c}| 表示一个三列的表格且都是居中。 \hline表示横向的表格线。 下面给表格加上一个标题： 12345678910111213141516\documentclass&#123;article&#125;\usepackage&#123;multirow&#125;\begin&#123;document&#125; \noindent \begin&#123;table&#125; \caption&#123;My first table&#125; \centering \begin&#123;tabular&#125;&#123;|l|c|r|&#125; \hline 1 &amp; 2 &amp; 3\\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \\ \hline \end&#123;tabular&#125; \end&#123;table&#125;\end&#123;document&#125; 可以看到，在\begin{tabular}外面又套了一层\begin{table}，这两层是不相同的，我们需要在\begin{table}里面，\begin{tabular}外面用\caption{My first table}指定标题为“My first table”，而下面的\centering指令是让表格居中。 其实我们可以发现\begin{tabular}表示一个表格实体的开始，而\begin{table}表示一个表格连同标题至脚注的开始。 在Word中常常用到“合并单元格”和拆分单元格指令，在LaTeX中可以通过\multirow和\multicolumn来实现。这里\usepackage{multirow}是必备的。 先看一个例子：现有一个4x4的表： 1234567891011121314151617\documentclass&#123;article&#125;\usepackage&#123;multirow&#125;\usepackage&#123;ctex&#125;\begin&#123;document&#125;\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gkai&#125; \noindent \renewcommand&#123;\multirowsetup&#125;&#123;\centering&#125; \begin&#123;tabular&#125;&#123;|l|l|l|l|&#125; \hline 1行1列 &amp; 1行2列 &amp; 1行3列 &amp; 1行4列 \\ 2行1列 &amp; 2行2列 &amp; 2行3列 &amp; 2行4列 \\ 3行1列 &amp; 3行2列 &amp; 3行3列 &amp; 3行4列 \\ 4行1列 &amp; 4行2列 &amp; 4行3列 &amp; 4行4列 \\ \hline \end&#123;tabular&#125;\end&#123;CJK&#125;\end&#123;document&#125; 下面我们合并第一列和第三列。 1234567891011121314151617\documentclass&#123;article&#125;\usepackage&#123;multirow&#125;\usepackage&#123;ctex&#125;\begin&#123;document&#125;\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gkai&#125; \noindent \renewcommand&#123;\multirowsetup&#125;&#123;\centering&#125; \begin&#123;tabular&#125;&#123;|l|l|l|l|&#125; \hline \multirow&#123;4&#125;&#123;2cm&#125;&#123;第1列&#125; &amp; 1行2列 &amp; \multirow&#123;4&#125;&#123;2cm&#125;&#123;第3列&#125; &amp; 1行4列 \\ &amp; 2行2列 &amp; &amp; 2行4列 \\ &amp; 3行2列 &amp; &amp; 3行4列 \\ &amp; 4行2列 &amp; &amp; 4行4列 \\ \hline \end&#123;tabular&#125;\end&#123;CJK&#125;\end&#123;document&#125; 对比代码发现，合并行单元格，我们只要在被合并的单元格的起始单元格调用\multirow命令，然后在被这个大单元格占据的其他地方使用空格代替原来的字符就行了。 这里说明一下\multirow命令的参数，第一个参数，这里是4表示向下合并多少行的单元格，第二个参数，这里是2cm一般取2cm或者*就可以，第三个参数，就是这个大单元格里面的内容了，你可以在里面嵌入其他指令，如textbf用来加粗等。 此外对于合并列，有同样的\multicolumn指令，注意这里第二个参数变成了{c|}这样，用来说明这个大单元格内文本的对齐方式。不过这里需要特别注意的一点就是，在同一行中，我们不需要给被\multicolumn吃掉的单元格占位置了。 1234567891011121314151617\documentclass&#123;article&#125;\usepackage&#123;multirow&#125;\usepackage&#123;ctex&#125;\begin&#123;document&#125; \begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gkai&#125; \noindent \renewcommand&#123;\multirowsetup&#125;&#123;\centering&#125; \begin&#123;tabular&#125;&#123;|l|l|l|l|&#125; \hline 1行1列 &amp; 1行2列 &amp; \multicolumn&#123;2&#125;&#123;|c|&#125;&#123;1行34列&#125; \\ \cline&#123;1-4&#125; 2行1列 &amp; 2行2列 &amp; 2行3列 &amp; 2行4列 \\ 3行1列 &amp; 3行2列 &amp; 3行3列 &amp; 3行4列 \\ 4行1列 &amp; 4行2列 &amp; 4行3列 &amp; 4行4列 \\ \hline \end&#123;tabular&#125; \end&#123;CJK&#125;\end&#123;document&#125; 注意这里第10行的\cline{1-4}，试着将它去掉，我们可以发现\multicolumn部分失去了下面的表格构造线。这里\cline{1-4}表示在第1列到第4列画上表格构造线。 如果要实现合并多行多列的单元格可以嵌套使用指令\multirow，\multicolumn。 1234567891011121314% 此例修改自知乎专栏，作者李阿玲。% http://zhuanlan.zhihu.com/LaTeX/19749566\documentclass&#123;article&#125;\usepackage&#123;multirow&#125;\begin&#123;document&#125; \noindent \begin&#123;tabular&#125;&#123;|ccc|&#125; \hline 1 &amp; 2 &amp; 3 \\ 4 &amp; \multicolumn&#123;2&#125;&#123;c|&#125; &#123; \multirow&#123;2&#125;&#123;*&#125;&#123;&#123;?&#125;&#125; &#125; \\ 7 &amp; &amp; \\ \hline \end&#123;tabular&#125;\end&#123;document&#125; 特别地，\renewcommand用来重定义一个指令，对于\renewcommand{\multirowsetup}{\centering}来说，就是把系统中已有的\multirowsetup重新定义成了使用\centering命令，从而达到强制multirow中内容居中居中的效果。当然还有newcommand用来定义一个之前不存在的命令，如同C++里面的#define一样。 斜线表头。为了能够使用斜线表头，需要\usepackage{diagbox}，\usepackage{pict2e}，\usepackage{fp}包。 1234567891011121314151617% 此例修改自知乎专栏，作者李阿玲。% http://zhuanlan.zhihu.com/LaTeX/19749566\documentclass&#123;article&#125;\usepackage&#123;multirow&#125;\usepackage&#123;booktabs&#125;\usepackage&#123;diagbox&#125;\begin&#123;document&#125; \noindent \begin&#123;tabular&#125;&#123;|l|ccc|&#125; \hline \diagbox&#123;Time&#125;&#123;Room&#125;&#123;Day&#125; &amp; Mon &amp; Tue &amp; Wed \\ \hline Morning &amp; used &amp; used &amp; \\ Afternoon &amp; &amp; used &amp; used \\ \hline \end&#123;tabular&#125;\end&#123;document&#125; 注意第11行\diagbox{Time}{Room}{Day}表示顺时针的三个Time，Room，Day。 三线表。对于英文论文来说，表格尽量 使用三线表格式。需要 12345678910111213141516% 此例修改自知乎专栏，作者李阿玲。% http://zhuanlan.zhihu.com/LaTeX/19749566\documentclass&#123;article&#125;\usepackage&#123;multirow&#125;\usepackage&#123;booktabs&#125;\begin&#123;document&#125; \noindent \begin&#123;tabular&#125;&#123;ccc&#125; \toprule 2&amp;9&amp;4\\ \midrule 7&amp;5&amp;3\\ 6&amp;1&amp;8\\ \bottomrule \end&#123;tabular&#125;\end&#123;document&#125; 4. 有序列表和无序列表 有序列表enumerate： 123456789\documentclass&#123;article&#125;\begin&#123;document&#125; \noindent \begin&#123;enumerate&#125; \item C \item Python \item Haskell \end&#123;enumerate&#125;\end&#123;document&#125; 无序列表enumerate： 123456789\documentclass&#123;article&#125;\begin&#123;document&#125; \noindent \begin&#123;itemize&#125; \item CSharp \item Javascript \item Rust \end&#123;itemize&#125;\end&#123;document&#125; 带小标题的列表description： 123456789\documentclass&#123;article&#125;\begin&#123;document&#125; \noindent \begin&#123;description&#125; \item[C++] Leaking basin \item[PHP] Best language in the world \item[Perl] WTF \end&#123;description&#125;\end&#123;document&#125; 5. 代码 1234567891011\documentclass&#123;article&#125;\usepackage&#123;CJKutf8&#125;\usepackage&#123;amsmath&#125;\usepackage&#123;listings&#125; \begin&#123;document&#125; \noindent \begin&#123;lstlisting&#125;[language=python] #coding:utf8 import numpy as np \end&#123;lstlisting&#125;\end&#123;document&#125; 这里同样注意\usepackage{listings}包不能丢掉，其中language表示里面显示的是什么语言。 Step 4. 段落，段落格式和目录 分段 LaTeX对分段有着以下几个明确的指令 1234567\section&#123;...&#125;\subsection&#123;...&#125;\subsubsection&#123;...&#125;\paragraph&#123;...&#125;\subparagraph&#123;...&#125;\part&#123;...&#125;\chapter&#123;...&#125; 注意：chapter仅限于report和book类（点击查看详细说明） 前五个命令表示从大到小的5个五级标题，其中含paragraph的一般为段落，前面没有标号，而且需要有实际的内容，不然这个paragraph就不会被显示（试着将含有remove me的行注释掉，注意观察编译结果），编译： 123456789101112131415\documentclass&#123;article&#125;\usepackage&#123;ctex&#125;\begin&#123;document&#125;\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gkai&#125; \section&#123;section&#125; \subsection&#123;subsection&#125; \subsubsection&#123;subsubsection&#125; \paragraph&#123;paragraph1&#125; there's some subparagraph \subparagraph&#123;subparagraph1&#125; \subparagraph&#123;subparagraph2&#125; \paragraph&#123;paragraph2&#125; % remove me there's no more subparagraph % remove me\end&#123;CJK&#125;\end&#123;document&#125; 此外，还有一种\section{short_title}{long_title}的写法，在中间的short_title我们指定一个简短的标题名，用来后面生成目录。 下面是part指令，类似于section，不过相比section，part是不带编号的，而且\part{}自动生成类似Part I这样的标题，不需要写成\part{Part I}，所以一般part指令都是用在比较独立的地方，比如用在chapter和section中间。 这边注意一点：请不要用section或者paragraph指令去做有序列表或者无序列表，点此查看专门的方案 1234567891011\documentclass&#123;article&#125;\usepackage&#123;ctex&#125;\begin&#123;document&#125;\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gkai&#125; \section&#123;section1&#125; \part&#123;&#125; \part&#123;&#125; \part&#123;&#125; \section&#123;section2&#125; \end&#123;CJK&#125;\end&#123;document&#125; 通过之前的几个例子，我们发现section系是不带编号的，paragraph和part是带编号的。事实上section也可以不带编号，paragraph也可以带编号。事实上这个是可以调整的。 运行一下代码，将\setcounter的最后一个参数从1一直调到5，逐次编译，比较每次的不同。 12345678910111213\documentclass&#123;article&#125;\usepackage&#123;ctex&#125;\begin&#123;document&#125;\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gkai&#125; \setcounter&#123;secnumdepth&#125;&#123;5&#125; % change this from 1 to 5 %控制显示4层编号 \section&#123;A&#125; \subsection&#123;B&#125; \subsubsection&#123;C&#125; \paragraph&#123;D&#125; D \subparagraph&#123;E&#125; E\end&#123;CJK&#125;\end&#123;document&#125; 对于article文档类来说，\setcounter默认的是3，也就是默认section系的有编号，parag系的没有编号。 事实上，如果我们仅仅只是想去掉一级section的编号的话，可以使用\section*{...}在\section和实际内容之间加上一个*就可以实现了。 目录和标题 先使用\title{}，\author{}和可选的\data{}为文章设置标题。 再使用\maketitle显示标题。 交叉引用 Step 5. 图片Step 6. 页面设置Step 7. 模板Step inf. 额外说明 文档类 文档类一般包括以下几个 12345article 最常用的minimal 最基本的文档类，一般仅用来查错report 较长的报告和论文book 书籍slides 幻灯片 使用\documentclass{...}定义。本文中大多数都是article类型]]></content>
      <tags>
        <tag>LaTeX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django配置与使用]]></title>
    <url>%2F2015%2F10%2F21%2Fdjango%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在配置Django的时候常常会出现一些问题，比如migrate无效，表单提交valid验证不过等问题，本文给出了一些解决方案 同步数据库的问题根据不同版本有对应以下两种方法同步数据库：1python manage.py syncdb (用于旧版本)12python manage.py makemigrationpython manage.py migrate (用于新版本)其中migrate方法一般要提前建一个空的数据库，但是数据表是自动同步的 自定义数据表一般地，django在数据库中存储的表名为model name，但是可以通过以下方式自定义表名123class MyModel(models.Model): class Meta: db_table = 'xxx' 上传文件问题 上传空文件会导致is_valid不过 不能在如view.py, model.py中正常地import 这些文件的sys.path中的当前目录是manage.py所在目录，一般比这些文件本身所在的目录高一级。所以sys.path.append中的路径应当比实际高一层。 同样因为这个原因，保存文件时路径不能以’/upload/‘开头，而应该直接以’upload/‘开头。在外部程序访问时，应当做一个路径转化。 Migrate问题 RuntimeError: Error creating new content types. Please make sure contenttypes is migrated before trying to migrate apps individually.检查Model.pyContentType 模型对应数据库中django_content_type表，主要用户维护django project中所安装的所有用户模型出现这个问题一定是模型问题，我后来发现我的原因是因为 models.XXXField 里面多了一些参数比如required什么的删掉就好，此外form也要注意之后一定要先drop database再migrate就可以了 file clean之后变成None摘自C:\Program Files (x86)\Python27\Lib\site-packages\Django-1.9-py2.7.egg\django\forms\forms.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def full_clean(self): """ Cleans all of self.data and populates self._errors and self.cleaned_data. """ self._errors = ErrorDict() if not self.is_bound: # Stop further processing. return self.cleaned_data = &#123;&#125; # If the form is permitted to be empty, and none of the form data has # changed from the initial data, short circuit any validation. if self.empty_permitted and not self.has_changed(): return self._clean_fields() self._clean_form() self._post_clean()def _clean_fields(self): for name, field in self.fields.items(): # value_from_datadict() gets the data from the data dictionaries. # Each widget type knows how to retrieve its own data, because some # widgets split data over several HTML fields. if field.disabled: value = self.initial.get(name, field.initial) else: value = field.widget.value_from_datadict(self.data, self.files, self.add_prefix(name)) try: if isinstance(field, FileField): initial = self.initial.get(name, field.initial) value = field.clean(value, initial) else: value = field.clean(value) self.cleaned_data[name] = value if hasattr(self, 'clean_%s' % name): value = getattr(self, 'clean_%s' % name)() self.cleaned_data[name] = value except ValidationError as e: self.add_error(name, e)def _clean_form(self): try: cleaned_data = self.clean() except ValidationError as e: self.add_error(None, e) else: if cleaned_data is not None: self.cleaned_data = cleaned_data 看了半天源码发现，里面的name要和Form里面的name相同 python的小坑python是没有select/switch语句的，为了避免很麻烦的if-elif-else，可以采用{condition:value}[statement]近似替代select/switch语句，这个小坑在于，所有的condition:value都会被求值，所以一方面会降低性能，一方面要考虑副作用的问题了。 字符集的小坑request.GET.get得到的参数是unicode，必须先转换类型才能使用哦 HttpResponse的小坑HttpResponse不能正确处理array object的情况，例如下面的代码是不能得到正确的结果的哦：123456789return HttpResponse([ &#123;'name':'TP', 'value':assessmodel.TP&#125; ,&#123;'name':'TN', 'value':assessmodel.TN&#125; ,&#123;'name':'FP', 'value':assessmodel.FP&#125; ,&#123;'name':'FN', 'value':assessmodel.FN&#125; ,&#123;'name':'P', 'value':assessmodel.P&#125; ,&#123;'name':'R', 'value':assessmodel.R&#125; ,&#123;'name':'F1', 'value':assessmodel.F1&#125; ]) 运行发现前端得到的是这样的数据：解决方案是当遇到对象数组的时候使用json.dump()函数将它转化为json，然后返回application/json格式的HttpResponse，如return HttpResponse(json_stuff, content_type =&quot;application/json&quot;)，当然千万注意前端ajax拿到data之后就不要eval了。 转义Django和Angular等框架合用需要注意转义：openblock { %closeblock % }templatetag openvariable { {templatetag closevariable } }openbrace {closebrace }opencomment { #closecomment # } Angular的问题这边顺便说一下Angular和jQuery混合使用常犯的一个错误：12345678910$.ajax(&#123; url : '' ,data : &#123; &#125; ,async : true ,success : function (data, textStatus) &#123; $scope.data = data &#125;&#125;) 如上代码$scope是不能更新的，因为success函数不在angular的名字空间里面了。 Python urllib2的问题使用以下代码抓取网页123456def getHtml(url): req = urllib2.Request(url) req.add_header('User-Agent','Mozilla/5.0 (Windows NT 6.2; rv:16.0) Gecko/20100101 Firefox/16.0') page = urllib2.urlopen(req) html = page.read() return html 发现报502错，这时候检查一下自己的翻墙软件是不是全局代理，这边我的Shadowsocks开启了全局代理，urllib2就不能抓https://127.0.0.1:8091了，502报错1urllib2.HTTPError: HTTP Error 502: Server dropped connection Django + Nginx + Https这里有一个非常大的坑，如果使用本机调试的话，千万不要选择localhost，而应该选择127.0.0.1.因为localhost可以是[::1]也可以是127.0.0.1，详见 这里 和 这里如果使用了localhost，那么会造成1min左右的加载问题，最初我以为是static files的问题，后来查看了error发现是 *24 upstream timed out (10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond) while connecting to upstream, client: 127.0.0.1, server: localhost ，这种问题一般都是写了localhost。–推荐以下blog http://www.ziqiangxuetang.com/django/django-models.html]]></content>
      <tags>
        <tag>python</tag>
        <tag>前端</tag>
        <tag>web</tag>
        <tag>django</tag>
        <tag>angular.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[钢筋混凝土学习]]></title>
    <url>%2F2015%2F10%2F20%2F%E9%92%A2%E7%AD%8B%E6%B7%B7%E5%87%9D%E5%9C%9F%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[土木工程这个学科啊，excited。特别是钢混这门课，总是学的有点迷糊（虽然我最后考试满绩）。我觉得钢混这门课学好大概有三件事，第一是理解清楚钢筋与砼这两种关键材料的性质，这些性质决定了我们设计的原则；第二是掌握承载能力的计算方法，对于梁的抗弯、抗剪，柱的抗压等构件的计算方法；第三是理解建筑设计的一般原则，将构件组成结构之后需要注意哪些方面。如果说还有一点就是实际设计截面时要注意一些构造要求，比如说弯起钢筋的排布，或者对钢筋排数和直径的限制。但这些都是次要的，主要的就是三件事情，因为这些原则它们的目的都是统一的，就是为了发挥钢筋混凝土这种材料的最大性能。 材料性质首先是钢筋与砼的性质，有一大串的指标：理解这些很重要。 混凝土部分混凝土的强度混凝土立方体强度等级fcu,k其中下标cu表示立方体，k表示标准值。立方体抗压强度没有设计值，在标准条件测得。标准条件：温度20℃±2℃，相对湿度为95%以上养护20d。这里有一个标准值和设计值的区别要看清楚。 荷载标准值k就是设计时要比它大。荷载设计值就是标准值乘以分项系数γ。一般地，恒荷载γg=1.2，活荷载γQ=1.4。同理，材料强度设计值等于标准值除以分项系数。例如混凝土轴心抗拉强度设计值ft=ftk/γc，其中γc=1.4。 标准试验方法需要注意： 加载速度越快越高 试验方法涂抹润滑剂会导致横向变形更容易，因此更容易破坏 尺寸效应小尺寸测得抗压强度要搞 其他强度fck 轴心抗压强度，和立方体抗压强度fcu,k之间存在公式转换。能更好的反应实际抗压能力。ftk 轴心抗拉强度，通过劈裂实验测量 混凝土的变形变形模量 原点模量（弹性模量）$ E_r $：应力应变曲线上过原点的切线。 割线模量$ E’_c $：应力应变曲线任一点和原点的连线。 切线模量$ E’’_c $：应力应变曲线任一点和原点的切线。 徐变徐变具有两面性： 优点：有利于结构内力重分布，减少外界因素对超静定结构的不利影响，降低附加应力 缺点：引起结构变形增大，导致预应力损失、结构破坏、徐变特点：加载越早、水泥越多、水灰比越大，徐变越大。骨料越坚硬弹性模量越高（对水泥徐变约束大）、养护时温湿度越高（水化充分），徐变越小。受到荷载作用后温度越高湿度越低，构件尺寸越大（失水受限），徐变越小。 混凝土本构关系可参考教材 混凝土的破坏一般混凝土的破坏指达到极限压应变 钢筋部分钢筋破坏有明显流幅（屈服台阶）的钢筋计算时以屈服点作为强度限值，没有明显流幅或屈服点的，取残余应变的0.2%对应的应力作为条件屈服强度标准值。同时对钢筋极限拉应变也有要求 钢筋本构关系钢筋与混凝土协同工作光面钢筋粘结力的形成因素：胶结力（水泥浆体对钢筋表面氧化层的渗透）和摩阻力（混凝土收缩）变形钢筋粘结力形成因素：机械咬合作用 混凝土保护层的作用 防止纵筋锈蚀 火灾情况下减缓钢筋温度上升 钢筋和混凝土更好粘结 梁的正截面承载力设计适筋梁破坏三阶段这个将来会做实验看到 I阶段：混凝土未裂阶段 Ia阶段：可作为受弯构件抗裂度计算依据 II阶段：混凝土带裂缝工作阶段 可作为正常使用阶段盐酸变形和开展宽度的依据 III阶段：破坏阶段 梁的正截面破坏形式此处可以对比柱的五种破坏形式 适筋梁适筋梁的破坏是塑性破坏，始于受拉区钢筋屈服，这时候受压区混凝土还未达到极限压应变。 超筋梁超筋梁的破坏是脆性破坏，始于受压区混凝土的压碎（达到极限压应变），此时钢筋还未屈服。 少筋梁少筋梁的破坏是脆性破坏，始于受拉区钢筋迅速屈服并进入强化阶段。对于这种破坏裂缝往往集中出现一条，宽度和高度都比较大。 梁的抗弯设计梁的抗弯设计相对比较简单。主要是考虑钢筋拉力T，受压区混凝土的均布力C（拉区混凝土相对于钢筋可以忽略不计）和弯矩M的平衡。此外还要避免超筋和少筋破坏。 梁的抗弯设计所做的简化的假定 五个基本假定 平截面假定 不考虑混凝土抗拉 混凝土受压应力应变曲线 注意和前面的本构关系比较，发现两者并不相同 钢筋极限拉应变取0.01 等效矩形应力图 受压区混凝土理论应力图形较难计算，这里等效成矩形，可以方便地得到C的大小和作用位置，同时引入了系数$ \alpha_1 $和$\beta_1$。 常用符号以及解释 符号定义 意义 $ A_s $ 纵向钢筋总截面面积 $ a_s $ 下部受拉钢筋合力点到截面受拉区边缘的距离 $ h_0 = h - a_s $ 下部受拉钢筋合力点到截面受压区边缘的距离 $ \rho = \frac{A_s}{b h_0} $ 配筋率 $ x$ 混凝土受压区高度 $ x_c $ 中和轴高度/受压区理论高度 $ \xi = \frac{x}{h_0} = \rho \frac{f_y}{\alpha_1 f_c} $ 相对受压区高度/配筋系数 $ \xi_b = \frac{x_b}{h_0} $ 界限受压区高度 $ \alpha_1, \beta_1 $ 受压区等效矩形应力图系数 $ f_y $ 钢筋抗拉强度设计值 $ f_c $ 混凝土抗压强度设计值 $ M_u $ 截面受弯承载力设计值 基本方程$$\alpha_1 f_c b x = f_y A_s \\M_u = f_y A_s (h_0 - \frac{x}{2}) \\M_u = \alpha_1 f_c b x (h_0 - \frac{x}{2}) \\$$以上方程可以暴力解 快速计算]]></content>
      <tags>
        <tag>土木工程</tag>
        <tag>钢筋混凝土</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo常出现的配置问题]]></title>
    <url>%2F2015%2F10%2F19%2FHexo%E5%B8%B8%E5%87%BA%E7%8E%B0%E7%9A%84%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在配置Hexo的时候常常会出现一些问题，比如hexo d无法部署，tags不自动生成，评论不正常显示等问题，本文给出了一些解决方案 HexoHexo（Hail EXO，好吧这个我瞎编的）是基于nodejs的静态博客构建工具。由于Ruby的蜜汁信仰问题（而且windows下Ruby有点坑），我弃Jekyll投Hexo。配置方法烂大街，这里不提了，可以去https://blog.lmintlcx.com/post/blog-with-hexo.html 这里看看。这次主要说一些可能遇到的问题。 常见错误git问题 常见错误1event.js:72 throw er;// Unhandled &apos;error&apos; event 常见错误2Error: fatal : Not a git repository (or any of the parent directories): .git 解决方法：检查自己的.git文件夹是否在.deploy_git下，否则重新git init tags问题&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;http://www.calvinneo.com/tags/ 不能正常显示tag 检查是否安装了必须的包 我们可以使用npm ls --depth 0来查看依赖。 1234npm install hexo-generate-index --savenpm install hexo-generate-tags --savenpm install hexo-generate-category --savenpm install hexo-generate-archive --save 检查是否配置了tags页面 检查/.deploy_git/tags下是否有index.html，这个是不会自动生成的，在命令行输入： 1hexo new page tags 该命令/source/tags/目录下新建了index.md。打开文件，键入或修改： 1type: "tags" npm故障 可能会出现如下故障: TypeError: Cannot read property ‘latest’ of undefined hexo 这可能是因为已经安装了以上npm包，所以不需要重复安装了。建议在hexo init后直接npm install即可。 NexT主题问题使用多说由于某些NexT主题使用多说插件有一些小注意点，比如说有些文章“喜欢”之后的分享转进来的链接是yoursite.com这个域下面的。打开duoshuo_shortname.duoshuo.com发现这些文章的地址也是yoursite.com。这个有三点原因： 检查site和theme的两个_config.yml中，是否url字段配置成自己的域名。 一旦同名文章添加进多说，其地址不会再次更改，因此要将多说中的文章先手动删除一下。 还有一种原因是文章的标题变动了，对于这种情况可以先hexo clean，再重新生成并部署。注意这时多说后台会生成一个新的文章，旧的文章并没有被替换。 设置网站的favicon值得一提的是有一个方便的设置favicon的方法： 将所需图片如favicon.jpg复制到source下 在网站的_config.yml下输入1avatar: /favicon.jpg sitemap网站地图12npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 可能产生错误： duplicated mapping key at … path: baidusitemap.xml这是yaml的语法问题，比较简单的方法是直接去掉两个path中间的一个，每次只生成google或baidu的sitemap。当然你也可以把path缩进一下，这样就可以了。 Hexo s 命令不能在本地调试首先检查是否安装了hexo-server。其次不要在config里面显式用plugins指定插件。 vendors文件夹无法访问vendors里面主要是脚本等东西，缺少之后网页无法显示。f12看到整个vendors里面的东西都404了。然后我在一个新建文件夹新建了文件/test/1.txt并deploy，发现以下错误：既然确定了是github抽风了，就将网站搞一份到coding.net，可以使用下面配置：12345deploy: type: git repository: coding: git@git.coding.net:calvinneo/calvinneo.git,coding-pages github: https://github.com/CalvinNeo/calvinneo.github.io.git,master 这边特别注意，里面一定要用空格而不是tab缩进。然后更新dns，之前因为github不稳定，我常常使用ss代理访问，但是代理的dns不一定立即更新，鉴于目前在国内网站coding.net重新部署了，可以直接访问www.calvinneo.com2016年11月10日更新：部署到coding之后vendors又被禁了。真是醉了，后来想起来蒲神给我看了这个issue，从github下了最新版本的next，这个问题解决了，FYI，我原来的版本是5.0.0。值得注意的是蒲神也是next，一次没坏过（无敌了）。然后在配置新版本的_config.yml的时候发现现在next可以支持MathJax和busuanzi了，之前我还一直手动的。 管理git文件夹hexo cleanhexo clean语句相当于重新init下git文件夹（这里应该是之前说错了，hexo init是这样的，但是clean只清空缓存，是安全的），所以所有的历史会全部消失，因此需要慎重。如果仅仅是为了清理，可以选择对.git进行rebase等操作 压缩图片如果git中跟踪大体积的图片会导致git文件夹变得很大，而有的托管网站的容量实际上是有限制的，所以应当将图片压缩，软件Antelope是一个简洁易用的压缩图片工具 icon和avataricon和avatar是不一样的，icon是favicon.ico决定的，显示在浏览器标签页的最左边（chrome），avatar是在_config.yml里面指定的，显示在侧边栏。 给Hexo(NexT)加上搜索功能swiftype是大家都推荐的工具，我用了之后各种资源加载不了，而且他还是一个收费的工具，于是我换成了Local Search根据https://github.com/iissnan/hexo-theme-next/pull/694上的介绍可以添加配置，还是非常简单的但是配置完成之后发现并没有弹出搜索窗口，显示的是javascript:;，然而根目录下的search.xml是存在的。后来f12发现是我在站点的配置文件中的swifttype_key字段没有注释掉，于是相当于现在还是使用的swifttype搜索，于是注释掉之后重新hexo g，再hexo s就出现搜索框了 MarkDownMarkDown表格写法12345678&lt;!-- 上面一定要空一行 --&gt;| 表头1 | 表头2 | 表头3|&lt;!-- 下面冒号表示对齐方式 --&gt;|:-|:-:|-:|&lt;!-- 下面开始内容 --&gt;|a|b|c||d|e|f| 效果是这样的: 表头1 表头2 表头3 aaaa bbb cc d ee fff Hexo中md文件转义的问题这可能是某篇文章有字符未转义，出现解析错误 MarkDown存在的Bug有些MD格式会出现Bug，例如在列表项里面的表格因为必须没有缩进，所以会破坏列表项的连续性，表格后的列表项会从1开始重新标号。有的时候一段列表之后的新段会具有和列表项同样的缩进，即使中间插入了若干空行。 Error spawn git ENOENT问题这个问题发生在我迁移整个hexo到另一台电脑上时。 MarkDown编译问题很多时候hexo s造成的错误是markdown编译产生的，比如下面这个乱七八糟的错误，就是我在md里面写了一个用代码括号括起来的go数组造成的123456789101112131415161718192021Template render error: (unknown path) [Line 305, Column 300] expected variable end at Object._prettifyError (F:\Codes\web\node_modules\nunjucks\src\lib.js:36:11) at Template.render (F:\Codes\web\node_modules\nunjucks\src\environment.js:524:21) at Environment.renderString (F:\Codes\web\node_modules\nunjucks\src\environment.js:362:17) at F:\Codes\web\node_modules\hexo\lib\extend\tag.js:66:9 at Promise._execute (F:\Codes\web\node_modules\bluebird\js\release\debuggability.js:303:9) at Promise._resolveFromExecutor (F:\Codes\web\node_modules\bluebird\js\release\promise.js:483:18) at new Promise (F:\Codes\web\node_modules\bluebird\js\release\promise.js:79:10) at Tag.render (F:\Codes\web\node_modules\hexo\lib\extend\tag.js:64:10) at Object.tagFilter [as onRenderEnd] (F:\Codes\web\node_modules\hexo\lib\hexo\post.js:230:16) at F:\Codes\web\node_modules\hexo\lib\hexo\render.js:65:19 at tryCatcher (F:\Codes\web\node_modules\bluebird\js\release\util.js:16:23) at Promise._settlePromiseFromHandler (F:\Codes\web\node_modules\bluebird\js\release\promise.js:512:31) at Promise._settlePromise (F:\Codes\web\node_modules\bluebird\js\release\promise.js:569:18) at Promise._settlePromise0 (F:\Codes\web\node_modules\bluebird\js\release\promise.js:614:10) at Promise._settlePromises (F:\Codes\web\node_modules\bluebird\js\release\promise.js:693:18) at Async._drainQueue (F:\Codes\web\node_modules\bluebird\js\release\async.js:133:16) at Async._drainQueues (F:\Codes\web\node_modules\bluebird\js\release\async.js:143:10) at Immediate.Async.drainQueues (F:\Codes\web\node_modules\bluebird\js\release\async.js:17:14) at processImmediate (internal/timers.js:439:21) MathJax使用MathJax首先要将hexo的_config.yml和next的_config.yml都设置为true。然后next的_config.yml是默认给出了一个cdn去加载，但是我希望能够从本地加载（家里断网了），并且希望能够在用到的时候（流量有限）再加载这个模块。 配置本地的MathJax根据这篇博文，解压下来居然有50M，真是吐血！后来听从博客，放到theme的source目录下面的js里面了。 配置可选的MathJax加载方式根据这篇博文和这篇博文，在/themes/next/layout/_scripts/third-party下面找到了mathjax.swig。swig表示这里是使用的swig模板语言（有的是使用的ejs模板语言）。然后改成这样 123456789101112&#123;% if theme.mathjax.enable &amp;&amp; page.mathjax %&#125; &lt;script type="text/x-mathjax-config"&gt; MathJax.Hub.Config(&#123; tex2jax: &#123; inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true, skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] &#125; &#125;); &lt;/script&gt; ...&#123;% endif %&#125; 注意swig模板语言不能在\{\% if \%\}块里面嵌入\{\% inlcude \%\} hexo部署本地MathJaxnode内存溢出在配置的时候我一开始是把它放在/source/cdn/mathjax/目录下面的，我以为是这个原因，后来完全去掉这个模块还是不行，生成的db.json有150M炸了。后来发现还真是因为那个文件＋太大了的原因，导致第一次出现了Template render error: (unknown path)错误，然后因为db.json生成太大了，下面再读取这个db.json的时候内存就直接爆炸了。而我移除模块之后，还要再clean一下，把那个超大的json去掉才行。后来发现得放在theme/source/js里面。然后最好还要设置一下hexo的_config.yml里面的skip_render，这个使用来跳过渲染的，否则hexo回自动帮你渲染页面。下面方法来自这里 单个文件夹下全部文件：skip_render: test/*单个文件夹下指定类型文件：skip_render: test/*.html单个文件夹下全部文件以及子目录: skip_render: test/**多个文件夹以及各种复杂情况： 123skip_render: - test1/*.html - test2/** 静态文件过多在把MathJax放在theme/source/js里面以后在windows下hexo s发现：1Error: EMFILE, too many open files 出现以上的错误信息，目前还没有找到解决方法。 Hexo Mathjax转义部分LaTeX符号需要进行转义输入 LaTeX Hexo+LaTeX \ \\ \\ \\\\ _ \_ {, } \{, \} * \* SEO从这里看到可以在百度/谷歌“认领”自己的站点注意在验证时需要将一个html文件放到网站根目录下面，但无论是填写skip_render还是12layout:false--- 都做不到这点，后来发现对于next主题，放到主题的source文件夹下面就可以了。当然也可以走DNS验证，或者修改主题，在上面加上meta标签。]]></content>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCPC2015小记]]></title>
    <url>%2F2015%2F10%2F19%2FCCPC2015%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[这周末(Oct 17-18 2015)，第一次参加了ACM类的比赛，感触颇深，小记一番。 这次比赛是第一届的ACM国赛，充满着对目前ICPC区域赛的怨念（开幕式上各种高级黑）不过也造福了长春赛区的ACMer们（榜惨不忍睹，好可惜我们没有拿到长春的名额啊），和我土力学实验、校庆志愿者、毛概实践课、计算机等级考试都重起来了，一天之内怒请五个假。晚上和张老师去火车站和阿洁哥良哥他们汇合，然后就是不出意料的火车晚点，不出意料的CCPC专列（上海到南阳的K1106），不出意料的上铺很冷，不出意料地发现自己身高不咋地。早上的Face++神牛们的会被我们睡过了，下午开幕式之后直接热身赛，三条题目。A题Googol String（这次比赛Google命题）意思是要找一个特定生成的二进制字符串序列的第Googol项。这条我一开始的思路是把它的每一项理解成一个序列，然后求出他的通项公式。后来良哥找到了循环节 (001 0) (110 0) 顺着这个思路想下去将每组中的第四项提出发现依然具有相同的循环节(001 0) (110 0)。这条AC。B题New Years Eve给出了如下的酒杯排布123456789第1层 1第2层 1 2 3第3层 1 2 34 5 6 这条最后硬上模拟做了出来。第二天是正式赛。12条。签到题两条L和A。L的意思是一串瓶子都相同，里面的东西不同，问如何用最少的瓶子去区分。答案显而易见，就是把瓶子摆成一个对称的形状，这样无论拿正拿反都一样了。如 D-C-B-A-B-C-D 答案就是2n+1。不过因为我们当时题目意思没理解对，导致一直不敢交，白浪费了20min。A题就是两个2x2矩阵 a b e f c d g h 叫你判断旋转之后是否相同，其实只要硬写四个if就好了。当时搞了两个数组，反而复杂了，WA了两次。不过因为这条我体验了一把主敲和现场A题的滋味。爽。下面是H，二阶数独，阿洁哥A了。我和良哥讨论CDG三条。C题是在一个1000长度的串N中找出所有的上升子列，问有多少种方法，这一条现场把case由10个增到了100个，按照朴素的N3算法，达到了1011的计算量，后来良哥又想了个N2LogN的算法，不过还是有109的量，良哥觉得并不能在1s内解决（不过仔细优化下应该还是可以的，我记得当时对面的陕西师范大学的人说这条题目卡常数，应该他们也是这个复杂度类的），不过题解说是N2复杂度就可以了，这具体怎么做，还不是太明白的。D题是一个扩展的背包问题。意思就是把一些线段（golden stick）去覆盖另一条线段（container segment），不过多了一个限制条件，也就是这些golden stick可以有一部分超出container segment的外面，只要整个的重心在里面。如图所示： 这条良哥先提出一个想法，G是这次比赛最蛋疼的一条，因为它真的很简单，我们的思路很清晰，然后中坑的也是这一条，WA了7次。先说题目就是围棋，问走一步能不能吧对方的棋子吃掉。这一条的思路就是BFS/DFS找出所有的连通分量，然后逐个棋子检测有多少个“气”。我们错在后来的优化上面，忽略了多个棋子可能公用一个“气”的情况，直接把每个棋子的“气”加起来看大于不大于1。赛题说完了，谈一下比赛的一些感受。首先是学习到了一些经验，比如说弱队看着榜选题A，比如说ACM的一些专用的调试工具，比如说切题的一些技巧。其次是失败的原因。首先我们学校这方面不是很强，对，不过这次也不至于输的这个憋屈吧？南大女队都比我们高到不知道哪里去了。究其原因我觉得我们还是在简单题上，没有做好，难题，我们确实不会，不过别人也不会，6A就可以上银牌区，4A就可以上铜牌区，而AGHL都属于签到题，CDK也是属于有时间可以想出来的题目，有难题，像BIJ，但是全场AK也就SJTU一个。所以我们差在哪里。签到题L，别人2min过，我们20min才过，为什么呢？只是一个对称的构造，原理很简单，但是我们一直在怀疑自己的判断 。接下来签到题A，WA了三次？为什么呢？代码写错了。为什么代码写错了呢？一个简单问题，用了一个比较复杂的方法来做（用了数组，WA的话可能是wrap上问题）,换成简单的实现就可以了。其实题目没这么难。 最后给出zhihu上面的评价 http://www.zhihu.com/question/36617747?rf=36617203–未完待续–PS 其实我只是先先看看这个模板效果23332016-12-04 我决定不续了，马上都退役了]]></content>
      <tags>
        <tag>ACM</tag>
        <tag>CCPC</tag>
        <tag>现场赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[厦门游记]]></title>
    <url>%2F2015%2F10%2F08%2F%E5%8E%A6%E9%97%A8%E6%B8%B8%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[这篇游记是在写完敦煌游记之后补写的，原因是和菡姐聊天时她觉得每个人的旅游心态都不一样，她比较喜欢安静闲适地坐着吃吃喝喝，但是我好奇心重精力旺盛喜欢到处跑。我觉得她说的挺对的，每到一个地方我都恨不得长出十双眼睛二十副耳朵去看去听，恨不得一天有三十六个小时让我玩。继而我又发现把自己的见闻记录下来是非常重要的。 这次旅行是在国庆期间，也就注定了其劳民伤财的特性，不过最后算了一算居然只用了3000多块钱。特别幸运的是我们出发前几天天气预报说有台风要经过厦门，可我们玩的几天除了云比较多一直没有风雨，还是特别幸运的。 Oct.1 长三角一日游去的时候是乘坐的动车，车次我现在都记得D3135，在这趟车上足不出户就完成了一次江浙沪闽一日游，因为它从南京经上海到杭州再到宁波，在一路南下到厦门北站，几乎经过长江南岸所有的长三角城市和东部沿海城市。过了宁波之后山开始逐渐变多，用手机上网体验也越来越差，经常忽的列车进了一列隧道。然后蜂窝网和GPS统统没用了，幸亏我在三星手机上下了一些电影，可以看着玩。快经过温州的时候看到下面居然有人建了一个缩小版的天安门广场，非常有意思。不知什么时候上来的一个无座的大叔开始课前面的回家的妹子们聊了起来，大叔是jiangjiu（漳州）人。当列车穿过一条极长的隧道后，前面的妹子们欢呼起来，胡建省到了。福建省感觉比浙江的地形更为“奔放”，而且水变多了。到了厦门北站，茫茫多的人，排了一会队才买到BRT的票。我们坐BRT到第一码头的终点站（中间还被骗在前面一站下车），然后转乘公交前往科技中学站，最后到达位于曾厝垵（后来知道是个景区，卧槽我们居然住在景区里面）的旅馆。厦门的BRT以高架为主，双向两车道专供BRT行驶，感觉很吊。一路上厦门的空气中弥漫着一股热带水果的味道，一个叫鹭江道的地方特别明显，这让我影响十分深刻。我们的旅馆叫三个厦大人客栈。住三晚，共600块钱，从后门出去就是曾厝垵夜市一条街（第二天晚上我们发现其实是夜市一条迷宫）。我们靠着夜市出门吃了厦门著名的沙茶面，沙茶面感觉就和海鲜杂烩一样，里面会有不同的牡蛎、虾、豆腐干子，酸甜酸甜非常好吃。 Oct.2 厦门大学早晨在旅馆门口的饭店吃了顿简易的早餐，和饭店老板租了辆自行车，真他妈贵啊。到了厦大好家伙，进门先要排队，排到途中有人说交多少钱帮我们插队，加上我们有自行车，所以也顺便请他给我们看一下车。交了钱于是他把我们带到一个人稍微少一点的队尾，然后我们继续排队。不过总算是进去了。伴随着逛校园的当然是敲章啦，来厦门玩的年轻人不会错过在各个景点小店敲章的机会，无论在厦门岛上还是鼓浪屿上，无论是商店、景点、KFC、旅馆、邮局、新华书店，只要你能想到的，甚至鼓浪屿上的派出所都有章可以敲。在厦大我们买了一个抓们用来敲章的本子，上面记载了一些明确提供敲章服务的地点，不过还有一些例如派出所是要自己去开发的哦。厦门大学与集美大学同为陈嘉庚先生所创，其建筑风格以中西合璧为特色，也就是俗称的“穿西装戴斗笠”。最为明显的特点就是大量的白色黄冈眼、红砖、橙色大瓦片和海蛎砂浆等具有厦门特色的建筑材料。厦门大学的学生也住在这样精美瑰丽的房屋里面，我们在路上就经过了一栋公主楼，厦门大学的一个女生宿舍。厦门大学最有名的应该就是芙蓉隧道了。有点类似上海交通大学的隧道，隧道两面墙壁上是学生们的各种图鸦，天文地理无所不有，我们看到了大白、雷锋、习总、大圣归来的壁画，还有大一时让我们很蛋疼的工程制图。甚至在墙上还看到一个“禹”字，果断在下面拍了张合照。有意思的是，我发现隧道中有个地下室的大门上写着厦门大学“飞思卡尔智能车”工作室。在芙蓉隧道靠近终点的地方有一个1015咖啡厅，我们可以在店里敲一个芙蓉隧道的专属印章。出了芙蓉隧道居然就是厦大校门了！好意想不到啊，我们只得折返，走一边回头路。中午我们在厦大食堂吃了一餐，厦门大学食堂是对游客开放的，但是我们买会特别特别贵。接着我们去了厦大著名的操场。逛完厦大，我们去了对面超市买了些零食，考虑到在马上要去海边，我额外买了毛巾和拖鞋。从厦大出来已经是三点多了，傍晚我们出发沿着环岛路逆时针骑行。一路上上坡下坡真是累死了，关键是人特别多，有的时候得抱着车上台阶从栈桥上过，栈桥上的一些关卡一次只能通一个人，所幸过了曾厝垵之后人变得少了很多，并且骑行带变宽阔了好多，而且刷上了鲜明的红色。每骑一段路都会遇到服务区（没错，自行车的服务区），可以在这里休息上厕所感受沙滩。我们一直骑行到一个叫椰风寨的地方，然后往回骑行。回到曾厝垵，我们去了昨天看到的一家叫“高烤”的烧烤店，居然客满了，老板把我们带到一个很阴森巷子里面的另一块店面，在等了一会儿之后，我们终于盼来了一张桌子，这里的菜单叫烤卷，点菜叫开始高考。这里的菜也很是别致，他们没有酱，所有的食材都是预先经过腌制，放在纸盘子里面，老板说烤熟了就能直接吃了。我们尝了尝确实非常好吃，可惜量太少了，价格比较贵，人均要47块。吃完高烤，继续逛曾厝垵的夜市，大家突发奇想，进了一家酒吧。一进去妈的这酒吧真特么吵啊，里面的驻唱歌手和伴奏和声一个比一个响！坐在吧台的凳子上点了一些闹着玩的酒，菡姐点了一杯星空，感觉名字特别美，可是喝起来感觉一口一个小珍珠，非常难喝。接着大家开始玩真心话大冒险，问了菡姐一些感情方面的事情。吃完饭喝完酒后回到旅馆仍然不过瘾，商量着去演武大桥骑行。由于曹经文躲在旅馆不愿意去，所以只能我们三人出发，我们顺着环岛路往厦门大学方向走，这时候白天拥堵的人群少了很多，很快我们便到达了厦门大学。演武大桥是一座建在海面上的大桥，位于厦门大学的外侧。我们顺着大学路走顺着匝道上了演武大桥，不去不知道一去吓一跳，妈的演武大桥是个双向四车道的快速路，旁边没有自行车道的！我们只能沿着白实线外慢慢蹭，排队型拍照时，我们看着旁边车嗖嗖地飞驰而过不禁瑟瑟发抖，最难的是穿过有匝道的路口时，我们得不停给身后的车辆让路。在演武大桥上往右看就是厦门大学的白城海滩，虽然已经是晚上十一点了但沙滩上还三三两两地坐着情侣。查了查地图，眼看前面是和成功大道的一个立交，赶快从最近的匝道下来到演武路上。下了演武大桥，我们接着骑往明天要去的中山路。晚上的厦门还是比较安静的，我们从演武路顺着导航走，经过民族路到鹭江道上沿着海边骑往中山路。半路上在民族路附近，一条铁轨横穿马路，这是一个叫铁路文化公园的地方，感觉挺有意思的。后来知道这也是一个比较著名的景点，是用一条废弃的老铁路改造而成的。其实厦门岛上的主要景区（厦大、曾厝垵、中山路）等都离得非常近，很适合骑行。我们不一会儿就到了中山路。晚上的中山路显得特别安静，没啥好逛的。加上时间已是凌晨十二点，加上我们来时的的路比较寂静，有的小巷虽然有灯，但一个人都没有，让人感到挺害怕的，于是我们从中山路的东面走思明南路回宾馆。在思明南路我们又发现了铁路文化公园，原来这个公园是沿着老铁路的一条长4.5千米，宽十数米的公园，保存了厦门悠久浓厚的历史文化气息。回程又路过厦大西门，惊讶地发现厦门路边有像公交站台一样的24自动借书柜台，民众可以从任意借书点借书，并在其他的借书点归还，同时借书点还提供了预约功能。 Oct.3 中山路折腾了一个晚上，今天醒的有点迟。今天的行程是去中山路。厦门的建筑比较有特色，会在人行道上盖骑楼。中午我们在中山路吃了美团上有名的一家大块排骨锅。这个排骨锅很有意思，首先上来一个焖锅，里面是熬好的排骨，啃完排骨（大家都饱了）还可以往汤底里面当火锅加上不同的东西。中山路离第一码头不远，我们去第一码头查看了一下明天的船票，结果似乎第一码头只有厦门本市居民才能从那里乘船，我们还是得走我们套票上的东渡出发去鼓浪屿。来了厦门对一些店名会非常的有印象，例如张三疯奶茶店和赵小姐的店。我们下午对这些店进行了具体的考察。张三疯奶茶只有两种口味卖20块，其实相比它网红奶茶的身份，这价格并不贵，口感其实不错，不是特别甜腻，但也不是很突出。倒是里面的料大大的良心。我记得我的一杯奶茶至少三分之一的都是固体物质，特别是葡萄干，真的炒鸡炒鸡多！赵小姐的店主要是卖茶。还有一家叫黄远堂的凤梨酥，其招牌是祖传的手艺，绝对不加冬瓜。我之前从来没吃过凤梨酥，尝了尝感觉打开了新世界的大门，看一看价格，好贵好贵，一盒五枚要三十块，想想这家一直说不加冬瓜好像很不容易的样子，于是买了一盒。在中山路附近有一家大清一等邮局，它是一座类似外滩上的洋楼的建筑。邮局里面像个小商店，会卖各种小纪念品。既然来了邮局必须得盖一张邮戳，我们买了一张邮票，就可以贴在自己的小本本上盖邮戳了。我们在中山路一家阁楼店里面逛时，曹经文说有同学找他玩，于是他先走了，我们乘了一辆假的士回宾馆，路上又经过演武大桥。下午的演武大桥就没晚上那么恐怖了，实际上是堵得一塌糊涂，我们可以在桥上欣赏大海风光。晚上得知数学建模的成绩出来了，只拿了省二，很是伤心。我们在夜幕笼罩的海滩上开始准备觅食。晚上深入地逛了曾厝垵夜市，厦门的吃食是非常有特色的，除了之前吃的沙茶面，我们看到一种特别大的叫青芒的芒果，我之前都没有见过，于是我们买了好几个打算寄回去，老板说最少买六个才能寄，于是我合计了一下我打算买六个寄回家，后来回家称了称，妈的给我缺斤短两，折算下来只相当于淘宝上最贵的那种。海蛎煎给我的印象也特别深刻，它实际上就是将海蛎混入蛋饼中，再淋上特制的酱料制作而成的，吃起来非常地鲜美。还有一种非常常见的食物叫土笋冻，不过吃之前一定要做好心理准备，因为它并不是竹笋之类的东西，而是用一种叫沙虫（回来之后查了查应该是星虫，沙虫是以讹传讹）的虫子做成的。除了拼命逛街当然还要拼命盖章啦，鼓浪屿有些章也特别有意思，相同名字的连锁店，不同的店面的章也是不尽相同的，有一家叫一杯茶堂的店，它的章是一个狗头的雕塑，还有一家店它的章是用石头做的，像一座宝塔一样，特别特别沉。我们一直盖到十一点半，最后还剩一个叫芒果西番莲的店面，我们到达时那边已经关门了，于是非常遗憾地只能拍照留念。 Oct.4 鼓浪屿厦门岛上有个叫第一码头的地方，但是我们在美团上买的套票（175元包含往返船票、鼓浪屿景点联票以及两个额外景点选一）是要从海沧区的一个地方乘船去鼓浪屿。我们乘着公交车一路坐（堵）到海沧换成公交到达嵩屿码头，到了码头取票时发现鼓浪屿的门票得在厦门岛上取！大家当时都绝望了，打电话给美团那边的人，说到那边人安慰我们说到了鼓浪屿也是可以用自助取票机取的。乘坐轮渡真是痛苦的经历，我们背着全部家当和茫茫多的人挤在凉棚下苦等，站也站不得，坐也坐不了，非常蛋疼。等船靠了岸时间已经将近十一点了。因为鼓浪屿上住宿实在是太贵了，所以我们在鼓浪屿定了帐篷（这样还一个人50），到了内厝澳码头，我们直接奔赴租帐篷的人家寄存行李，房主是个女的，相当于是将自己家里拿出来做宾馆，但床位是一张一张的卖，而且特别贵，我们来的时候客厅里面已经挤满了人和行李。出了寄存行李的地方，这时候肚子里已经是饿得要死，我们决定先吃点东西再说，就在路边，山路旁边的一个小平台上，摆放了几副石桌石凳，于是我们就到哪里吃了个中饭。虽然环境简陋，可是那里的饭菜可是贵的一批啊。吃完饭就开始全岛晃荡着找取票的地方，我们一边找，曹经文一边逛沿途的各种店铺，最后终于找到了取票机。路上还经过菽庄花园，发现我们买的联票还不如直接用学生证单买。在鼓浪屿上我们吸食了一个叫百香果的水果，说是吸食一点不假，拿到手是一个石榴大小的果子，里面插着一根吸管，老板教我们来回搅动，然后用吸管吸出来的汁液，据说十分酸甜解渴，不过实际体验下来还是算了，水分真的很少……在琴园的时候我还15块买了个椰子吃了吃，感觉和家里面的也差不多，可惜不能砸开来吃椰肉。我和田韵决定先去玩近一点的日光岩。日光岩在晃岩路（路名感觉很巧妙啊）上，晃岩路非常好找，它旁边就是马约翰体育场的。如果你从那里出发一定不要错过派出所，是可以敲章的哦。日光岩又称晃岩、龙头山，是鼓浪屿的制高点，有着“不到日光岩就不算来过厦门”的俗称。日光岩的得名源自其顶部的一块巨石，据说这块巨石直径达到40米。我们从山脚下往上爬，经过日光岩寺、古避暑洞等景点。日光岩寺就是个山脚下的寺庙，我们都没怎么高兴去看。古避暑洞其实并不是一个山洞，而是两块岩石和地面相抵，形成的一个尚可通人的洞。过了避暑洞，继续往上走，到达一块岩石形成的较大平台，也就是日光岩的顶部。在日光岩的顶部建造有一个仅能容纳数人的观景台，称为“光复台”，通往观景平台的石阶又高又陡，只能容纳一人通过，但是我们还是勉强挤上了平台。从日光岩上往下看，鼓浪屿尽收眼底，对面的厦门岛也一览无余，鼓浪屿全岛的建筑风格和厦门大学有点类似，都是橙色的屋顶。据说在天气好的时候登上日光岩能够见到对岸的台湾岛。参观完了日光岩，从出口出来对面便是琴园的入口，进去之后有个百鸟园，我们正好碰上三点场的驯鸟表演。两只鹦鹉为我们带来了独轮走钢丝、跳舞、滚筒、套圈等演出。比较有意思的是最后演出人员会让我们拿出人民币，鹦鹉会飞到你拿里把钱叼走。有意思的是有人拿了一个皱巴巴的一元纸币，那鹦鹉飞了几次就是不飞过去，原来这鸟也是嫌贫爱富的呀！从百鸟园出来还可以往上走，当时只有我能爬的动，我便一个人爬了上去，上面英雄岩和听涛崖，还有一个关于殷承宗的博物馆，里面很少人。其中听涛崖是在海边的一块悬崖，据说是观看落日最佳的地方，不过我去的时候还是四点，太阳照的我眼睛有点睁不开，没看到晚霞。此外这里位于鼓浪屿最西南，也是登高望远的好地方，据说这里天气比较好的时候甚至可以看到对岸的漳州。地图上这里还有个景点叫鼓声洞，开始以为是一个和听涛崖一起的山洞，但事实上这是一个穿山的隧道！我们今天早些时候就是从这里来到了靠南的海滩上。菡姐下午因为一些原因身体不舒服，所以就先回旅馆了，没有和我们一起去日光岩玩。她和曹经文从菽庄花园出来，说里面有个关于十二生肖的景点可以捉迷藏，非常有意思。四点多的时候我们逛完琴园便去了菽庄花园。菽庄花园和日光岩比较相似，里面包含了钢琴博物馆、听涛亭、补山园、四十四桥等多个不同风格景点。从大门进去，绕过一道高墙，便是一个观海平台，一道石围栏将地势较高的菽庄花园观海平台和外面的地势较低海滨浴场隔开，既起到了分割作用，又不至于阻碍观赏美景，这是古代园林常有的开门见山的效果。再往南走不远就是四十四桥景点，四十四桥和二十四桥有点像，不过是环抱海边的一道桥或者栈道。走在桥上，蜿蜒曲折更有多个亭台点缀。朝西远望，落日下的日光岩尽收眼底，上面蚂蚁一样的人群还在往观景平台上奋力攀登，近看是一块巨大礁石上刻有“海阔天空”的书法，据说是明代大书法家所作，脚下海浪拍打着海岸，宛若在低语欢笑。在四十四桥上就看到了在山上的鼓浪屿钢琴博物馆，于是我们飞奔上去。钢琴博物馆分为两层，陈列有各式各样不同造型和年代的钢琴。鼓浪屿上的钢琴文化非常浓郁，据说每家每户都有一架钢琴。在钢琴博物馆我们看到了新老不一的钢琴，有的钢琴非常有意思，是成一个直角弯折过来的。还有很多自动演奏的钢琴，据说是先前贵族人家的主人如果热爱音乐又不会演奏钢琴，就可以在钢琴上装上打孔的纸带，用脚踩动，钢琴就能够自动地演奏出音乐。著名的音乐家殷承宗也是出生在鼓浪屿。在最后，讲解员为我们演奏了一曲《鼓浪屿之波》：“鼓浪屿对这台湾岛，台湾是我家乡。登上日光岩眺望，只见云海苍茫。我渴望，我渴望，快快见到你，美丽的基隆港”，这首歌表达了台湾人民对海峡两岸统一的愿望。菡姐提到的十二洞天的景点其实在补山园里面，它是一个非常大的假山，假山上有十二个山洞，错综复杂的明道与暗洞将上下左右的这些洞口相连，形成一道巨大的迷魂阵。十二生肖代表的动物雕塑就潜伏在洞口附近的石头中，需要耐心仔细地寻找才行。十二洞天是我见到过的规模最大的假山了，非常有意思。晚上住帐篷，洗澡变成了一件麻烦事，租帐篷的人很多，但是她家只有一个浴室，澡得排队洗。幸亏菡姐帮我们排了个队，我们只等了大概一小时左右吧。我排在四个人中的最后一个，其实我洗澡很快的，但是前面曹经文洗的比较慢，我才洗了三分钟，外面一个女声就开始碎碎念了，心里窝火，看把你猴急的样子，我说你要是急得话进来和我一起洗吧，于是她闭嘴了。经历了这次事件我们决定明天选择在中午或者下午洗澡，避开晚上的高峰时段。当然这里还是建议如果能够避免重大节假日还是尽量避免，这样能够获得更舒适的体验，否则你真的能够体会到什么叫人声鼎沸，水泄不通的！晚上曹经文和菡姐都很虚脱了，但是我和田韵还是很吊。于是继续在鼓浪屿上开始了漫漫的敲章（和帮菡姐曹经文敲章）之路。鼓浪屿的路非常有意思，有一些路走着走着就变成了一条巷子，有些路走着走着就进了一条隧道，有的路上静的怕人，但是侧面开了个两人宽的小道，从小道穿过霎时到了人声鼎沸的龙头路，更有走一段变个路名，原路要拐个弯才能到的情况。除了之前看到的晃岩路，还有一条龙头路，龙头路应该是鼓浪屿上最长的一条路了，一直通到海边的钢琴码头，在地图上看这条路并不是一条笔直的路，而像一棵树一样，这一片区域的所有路或者巷子都叫龙头路。值得庆幸的是，因为这里靠近海边，有KFC和一个蜡像馆，所以沿着主干道走倒也好找，并且这里也是鼓浪屿商铺（和美食）最为集中的地方，即使迷路了，随便逛逛也是挺有意思的。路上我们还看到一家店叫“联邦调查局”，进去一看原来是卖茶叶的。我们第一天在鼓浪屿从日光岩开始基本就是分头行动的！鼓浪屿偏西偏北的地势起伏比较大，有的时候也不能光看导航走，路线选不对就容易走山路，爬上爬下特别麻烦。这里推荐几个比较好的地标，第一个是马约翰体育场，因为它就挨着中华路边上，并且离菽庄花园也不远；第二个就是钢琴码头了，它靠着海边和龙头路，可以顺着导航从龙头路逛回来到这里集合。我们的帐篷在鼓浪屿的最北面海边的草地上，这里地势起伏比较大，景点相对来说也比较少，比较惨的是上厕所，这里离最近的厕所要走十分钟，关键是去了那儿那里居然不开放，我又得额外绕个几分钟，到了曾厝垵一个阴森的小巷里面上的厕所！我们在过去的路上意外看到有条路叫兴化路，这里的兴化不是我家，而是莆田的旧称啦。 Oct.5 鼓浪屿为了看日出，今天早上五点半就从帐篷里面爬出来了，顺着走到海边想看日出，谁知天公不作美，天上一朵接着一朵的云。今天早上的计划是去一个叫4D魔觉馆的地方，这是在美团上买门票送的一个景点。由于起的特别早，我们也无处可等。中途我们看到一家教堂三一堂。三一堂也是厦门最富名气的教堂，是情侣们在厦门举办婚礼的首选地点。走到这里时我们实在太困，就靠着旁边的一家锻炼器材的地方睡着了。去魔觉馆的路上我们经过了一些非常漂亮的小巷子，有些巷子后来从照片上看到才发现它的美。魔觉馆是由一对夫妇开的，老板人特别和善，我们去的时候还没开门，他们亲切地招呼我们坐下，当知道我们从南京过来时，他们说年轻的时候去过南京，那里是个好地方，特别热闹，不过路程太远了。魔觉馆类似于蜡像馆，也是一个拍照片的地方。逛完魔觉馆，我们在一家叫做闽南疯古早小吃的地方吃了午饭，古早是闽南语，意思就是怀旧。这家店很有特色，不仅是贵，而且是先用人民币充值，换取刀币，然后在一楼的自助平台用刀币兑换食物。临走时我们又领了一份免费的海蛎煎。吃完便沿着龙头路瞎逛。一直逛到了海边，我们拍了些合照，快三点多跟了一个导游逛了逛毓园。从台阶上下到皓月后的一片海滨浴场和大海来了次亲密的接触。这里的风景和菽庄花园旁边的浴场应该是最好的了。从这里能够看到对岸厦门岛的世茂海峡大厦和演武大桥的地标。世茂海峡大厦是一座双子塔，其形状像两柄刀，也像两片竹叶，无论是在厦大还是环岛路，亦或是在鼓浪屿，它的出镜率总是特别高。最刺激的是乘着快艇冲浪了，快艇在琴园附近的海滩上乘坐，我们大概五点多到那儿，可是一艘要满六个人才能坐，我们真担心要四cover六时，正巧来了一对情侣凑成一艘。快艇要开了，司机师傅嘱咐我们把手机啥的收好，弄丢不负责，后来发现真是明智。快艇加速时感觉我们要从船尾滑出，转弯时船舷靠着水面，我感觉感觉船要翻掉一样，遇到波浪时快艇会陡然的一阵顿挫，特别爽。开到一半师傅说加点钱就带我们环岛一圈，果断答应（后来有点后悔后悔当时应该假装不答应，叫那个男朋友出钱，不过实在是太爽了）。冲完浪大家就准备回宾馆了，路上大家算了算开销，大概三千多，其实并不高。我们在一个类似于露天的花园式咖啡厅的地方，点了一些晚餐。九点多的时候由出来沿着海边晃悠了一圈 Oct.6 回程回厦门岛是从三丘田码头出发到东渡。到了岛上，我们乘坐火车站快线到达火车站，一下火车站司机便堵住我们问我们要去哪里，我没好气地说去南京你带不带。大家肚子都饿得咕咕直叫，大家都盘算着还来得及来不及吃还没吃过的海鲜了。最后大家还是跑很远的地方买了KFC。开始一天的长途高铁之旅。]]></content>
      <tags>
        <tag>游记</tag>
        <tag>厦门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSE4和字符串函数]]></title>
    <url>%2F2015%2F08%2F26%2Fsse4_str_func%2F</url>
    <content type="text"><![CDATA[简而言之，SSE4.2加入了7个指令，CRC32、PCMPESTRI、PCMPESTRM、PCMPISTRI、PCMPISTRM、PCMPGTQ和POPCNT。【未完待续】 SSE4指令集的字符串计算库 __m128i _mm_load_si128 (__m128i *p) = MOVDQA和int _mm_cvtsi128_si32 (__m128i a) = MOVD 这两个函数是相对的，第一个负责将p位置的值加载到一个寄存器中（用返回的__m128i标记）。p必须是16bytes对齐的，否则应当使用_mm_loadu_si128。根据Milo的博文，_mm_loadu_si128能可能造成一定概率的崩溃。 第二个负责将将低32位移到int中。 __m128i _mm_cmpistrm (__m128i a, __m128i b, const int mode)和__m128i _mm_cmpestrm (__m128i a, int la, __m128i b, int lb, const int mode) 这两个函数封装了PCMPISTRM这个指令，这里最后的M表示Mask。按照mode对两组字符进行比较。后面的函数可以指定长度la和lb。 mode参数包含a/b类型（byte或者word）、比较方式、返回方式 SIDD_UBYTE_OPS a是pattern，对b中每个字符x，查看a中是否存在。结果r的r[i]表示b[i]的结果（所以打印出来看起来是倒过来的）。 _SIDD_CMP_EQUAL_EACH a和b逐比特比较。 _SIDD_CMP_RANGES a是pattern，如azAZ表示从a到z和从A到Z的字符，对b中每个字符，查看是否在a的范围中。 _SIDD_CMP_EQUAL_ORDERED 在b中搜索a，1标记第一个位置。 _SIDD_NEGATIVE_POLARITY 这个按比特会翻转一下结果。 _SIDD_UNIT_MASK和_SIDD_BIT_MASK 一般用_SIDD_BIT_MASK就行了，根据stackoverflow，_SIDD_UNIT_MASK返回16个bytes，而不是bits。。。所以没必要用这个是吧。。。 int _mm_cmpistri(__m128i a, __m128i b, const int mode)和int _mm_cmpestri(__m128i a, int la, __m128i b, int lb, const int mode) 这两个函数封装了`PCMPISTRI`这个[指令](https://www.felixcloutier.com/x86/PCMPISTRI.html)，这里最后的`I`表示Index，用来返回最高位或者最低位的1的index。`_SIDD_LEAST_SIGNIFICANT`参数表示从最右起，`_SIDD_MOST_SIGNIFICANT`表示从最左起，要是没有就返回MaxSize。 以下面的代码为例，对于_SIDD_LEAST_SIGNIFICANT返回1，对于_SIDD_MOST_SIGNIFICANT返回3。倘若将pat_str改为&quot;c&quot;，那么返回值都是16，也就是MaxSize。 123456static const char pat_str[] = "a";static const char test_str[] = "badab"; const int i = _mm_cmpistri(pat_w, test_w, _SIDD_UBYTE_OPS | _SIDD_CMP_EQUAL_ANY | _SIDD_LEAST_SIGNIFICANT);printf("%d\n", i); 注意我们现在使用的是_SIDD_CMP_EQUAL_ANY，如果换成_SIDD_CMP_EQUAL_EACH的话就是逐位比较，其mask结果是111111111111100000，那么我们返回值分别是5和15。 ACOSZ 有没有很熟悉呢？这五个辅助函数被用来读取EFLAGS寄存器的值。这些指令一般在_mm_cmpistrm等四个函数之后调用，这样其功能相当于直接获取寄存器的值。有的编译器可能会在调用_mm_cmpistrm后再调用一次pcmpistri，这个看起来是冗余的。具体案例可以查看SoF。 以int _mm_cmpistrz(__m128i a, __m128i b, const int mode)为例，这个指令用来检测b中是否存在\0。 利用SSE4优化基础字符串函数为什么cstring不使用SSE4.2优化我们发现在一些c库中cstring并没有实现SSE优化，其原因可以参照stackoverflow。但是SSE4.2指令集不强制要求字符串对齐，并且可以在内部处理C或Pascal形式的字符串结尾问题。 实现strlen1234567891011121314151617181920212223242526int last_1_off(unsigned int r) &#123; int ans = -1; unsigned x = r &amp; ((~r) + 1); while (x) &#123; x &gt;&gt;= 1; ans++; &#125; return ans;&#125;inline int sse4_strlen(const char * s) &#123; int l = 0; static const char pat_str[16] = "\0"; const __m128i pat_w = _mm_load_si128((const __m128i *)&amp;pat_str[0]); while (1) &#123; const __m128i test_w = _mm_load_si128((const __m128i *)&amp;s[l]); unsigned r = _mm_cvtsi128_si32(_mm_cmpistrm(pat_w, test_w, _SIDD_UBYTE_OPS | _SIDD_CMP_EQUAL_EACH | _SIDD_BIT_MASK )); if (r == 0) &#123; l += 16; &#125; else &#123; return l + last_1_off(r); &#125; &#125;&#125; 上面的代码在G++下编译可能出现段错误，这是由于对齐所致，此时应当使用_mm_loadu_si128来代替。 实现strcmp12345678910111213141516171819202122inline int sse4_strcmp(const char * a, const char * b) &#123; int l = 0; while (1) &#123; const __m128i a_w = _mm_load_si128((const __m128i *)&amp;a[l]); const __m128i b_w = _mm_load_si128((const __m128i *)&amp;b[l]); unsigned r = _mm_cvtsi128_si32(_mm_cmpistrm(a_w, b_w, _SIDD_UBYTE_OPS | _SIDD_CMP_EQUAL_EACH | _SIDD_BIT_MASK | _SIDD_NEGATIVE_POLARITY )); if (r == 0) &#123; // 两个字符串相同 if (a[l] == 0) &#123; // 两个字符串都结束，注意如果只有一个字符串结束，那么r不可能为0 return 0; &#125; l += 16; &#125; else &#123; l += last_1_off(r); return a[l] - b[l] &lt; 0 ? -1: 1; &#125; &#125;&#125; 实现strchr]]></content>
      <tags>
        <tag>C++</tag>
        <tag>CPU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arthurluk攻略]]></title>
    <url>%2F2011%2F05%2F22%2Farthurluk%E6%94%BB%E7%95%A5%2F</url>
    <content type="text"><![CDATA[arthurluk是高中（大概2010年暑假）matrix67介绍的一个智力游戏，当时是大神arrowrowe引进的，我们做到46关。后面是收集的一些攻略。新版html -&gt; php 1http://riddle.arthurluk.net/stageone.htmldon’t install 2http://riddle.arthurluk.net/snowflakes.htmlCtrl+A点右下角链接 3http://riddle.arthurluk.net/fruit.html观察图片中水果种类strawberry 4http://riddle.arthurluk.net/strawberry.html查看源代码, 最后一行cleverest 5http://riddle.arthurluk.net/cleverest.html查看源代码，发现16是p，于是明白数字n代表第n个英文字母。（这技巧以后会经常用）{16, 15, 3, 11, 5, 20}→pocketpocket 6http://riddle.arthurluk.net/pocket.html谷歌搜索”弹珠台秘技 无限弹珠”bmax 7http://riddle.arthurluk.net/snowman/windows.html那是哪个操作系统的标志？linux 8http://riddle.arthurluk.net/snowman/linux.htmlCtrl+A看到”有聽過甚麼是元素週期表嗎？”于是查询：Phosphorus是第15号磷，Lithium是第3号锂，Boron是第5号硼，Hydrogen是第1号氢，Silicon是第14号硅。得到{15, 3, 5, 1, 14}。查看源代码，发现提示用第五关方法。{15, 3, 5, 1, 14}→oceanocean 9http://riddle.arthurluk.net/snowman/ocean.html在图中发现五个字母：左上角s，中下方阴影里o，右下角礼盒上l，圣诞树中上方偏右的外部v，左下角esolve 10http://riddle.arthurluk.net/snowman/eraser.html标题栏”diagonal”，于是连对角线发现”continue”continue 11http://riddle.arthurluk.net/search/unsinkable.html宣称永不沉没之船沉没了——再看图片风格——立刻想到泰坦尼克。查询得知泰坦尼克沉没于1912年1912 12http://riddle.arthurluk.net/search/1912.html标题栏”What’s the song?”，于是查歌词，发现是陈奕迅的《1874》1874 13http://riddle.arthurluk.net/search/carol.html标题栏”I wish I can see Pets Not Giants”，发现首字母故意大写标出PNG图片网址”http://riddle.arthurluk.net/search/tiger.jpg&quot;，换jpg为png，打开&quot;http://riddle.arthurluk.net/search/tiger.png&quot;发现图片上的答案wingdingswingdings 14http://riddle.arthurluk.net/search/wingdings.html计算。3^12+659+8+2483=534202534202 15http://riddle.arthurluk.net/search/534202.html计算。4562*3+65536/256=1394213942 16http://riddle.arthurluk.net/search/13942.html查看源代码，发现提示”数字人生”（香港有个电台节目叫”数字人生”）查询”数字人生”（http://baike.baidu.com/view/1234166.htm）发现歌词中”534202 13942”测试下一行”13424”，错误然后发现下面还有一行”534202 13942”，测试它的下一行”43140624”43140624 17http://riddle.arthurluk.net/search/running.html熟悉网页应立即意识到”&nbsp;”是空格，空格的英文”space”恰为5个字母space 18http://riddle.arthurluk.net/search/excuse.html查询”71828, 18284, 59045, 23536, 02874”，发现它是自然对数的前5个5位截断（http://baike.baidu.com/view/11033.htm）于是用第6个5位截断71352 19http://riddle.arthurluk.net/number/morse.html地址中”morse”提示莫尔斯，查看源代码发现提示”if “”l”” represents “”-“””用”-“替换”l”得到”-i-i i-i i i- - i”据莫尔斯编码（http://baike.baidu.com/view/20024.htm）对照替换得到&quot;create&quot;create 20http://riddle.arthurluk.net/number/copycat.html地址”copycat”提示把图片另存为，用记事本打开后发现含明文字符串”The password is supply.”supply 21http://riddle.arthurluk.net/number/battery.html超链接（”Hyper Text Markup”意为”超链接”）中划去Lhttp://riddle.arthurluk.net/number/battery.htm 22http://riddle.arthurluk.net/number/battery.htm图片左下角发现”run! escape!”，去掉非英文runescape Oops!http://riddle.arthurluk.net/number/runescape.htm需要L回来http://riddle.arthurluk.net/number/runescape.html 23http://riddle.arthurluk.net/number/runescape.html“QWERTY”指键盘排序转字母序，例：O是第9个，对应第9个字母i{9, 19, 12, 1, 14, 4}→islandisland 24http://riddle.arthurluk.net/number/heartbreak.html查看源代码，发现提示”別說你沒有這個遊戲 :P”，联想地址”heartbreak”、说明”偷走你們的心”、图片纸牌，得到结论红心大战查询红心大战计分法（http://wenwen.soso.com/z/q89592561.htm）得到&quot;每张红桃1分，黑桃Q 13分”结合标题”addition”（加和），于是计算13+1*5=18，测试18，错误，测试eighteeneighteen 25http://riddle.arthurluk.net/number/pascal.html地址和标题都提示”pascal”，于是用pascal运行此代码得到44244424 26http://riddle.arthurluk.net/flash/tutorial.html查看源代码，发现”答案在下面”，到最下面一行发现”你好像誤解了我的意思”，领悟到指的是Flash的下面打开Flash（http://riddle.arthurluk.net/flash/flash.swf），调节比例（纵向拉长），发现&quot;The password is :champion”champion 27http://riddle.arthurluk.net/flash/stillflash.html要等3600s，足足1h，当然要跃过时间。发现无法跳帧，于是动用VB（因为VB最方便嘛 = =。）代码：（添加Flash播放器控件，命名S） S.Movie = “http://riddle.arthurluk.net/flash/wait.swf&quot; S.Play S.SetVariable “time”, 0发现”well… well…\nthe password is ATTIC”attic 28http://riddle.arthurluk.net/ballgames/snooker.html查看源代码，发现”Again, a=1”，于是寻找数字组地址和标题都提示”snooker”，于是查询斯诺克计分法（http://baike.baidu.com/view/5025.htm，相关术语&gt;&gt;彩色球）得到红1、白2、绿3、棕4、蓝5、粉6、黑7转换球得到{1, 3, 3, 5, 4, 5}→accedeaccede 29http://riddle.arthurluk.net/ballgames/accede.html查询”eagle par”（http://www.google.com.hk/search?hl=zh-CN&amp;source=hp&amp;q=eagle+par&amp;btnG=Google+%E6%90%9C%E7%B4%A2&amp;aq=f&amp;aqi=&amp;aql=&amp;oq=&amp;gs_rfai=）立刻明白是birdiebirdie 30http://riddle.arthurluk.net/moon/essential.html第一个来月球的当然是阿姆斯特朗了armstrong 31http://riddle.arthurluk.net/moon/armstrong.html查看源代码，发现提示”Not mathematics but coordinates”（不是数学而是坐标）在图片中建立标准计算机坐标系（左上角原点，X正方向水平向右，Y正方向竖直向下）在底下那串数字里得到坐标（+为坐标间的分隔，-为X、Y间的分隔）检查每一组坐标对应的点所指向的字母，得到horoscopehoroscope 32http://riddle.arthurluk.net/moon/horoscope.html标题栏”A cartoon character”，查看源代码，图片对应”Who’s my owner?”联想到多来A梦的任意门doraemon 33http://riddle.arthurluk.net/checked/normal.html图片上一闪而过”REMEMBER THE PASSWORD: 69368549465021468008”（用截屏软件或者干脆(Alt+)PrintScreen再粘贴）69368549465021468008 34http://riddle.arthurluk.net/checked/advancedsearch.html标题提示”In Depth Battlepedia”、源码提示”NQII InSaNe Mode”、说明提示”no space, no capital”（无空格，无大写）搜索过程是枯燥的，就省略了。最终找到了此游戏的资源库（http://items.jellyneo.net/?go=show_items&amp;name=bow&amp;name_type=partial&amp;desc=&amp;cat=0&amp;specialcat=0&amp;status=0&amp;rarity=0&amp;sortby=name&amp;numitems=20）第二页的左下角就是这把弓，图片完全一致。名称是”Bow of Destiny”（去空格，去大写）bowofdestiny 35http://riddle.arthurluk.net/checked/bowofdestiny.html查看源代码，图片的Aim属性”Find the composer”（找到作曲者）查询”Sonata in E minor, Op.90”，发现作曲者是Beethovenbeethoven 36http://riddle.arthurluk.net/checked/hogwarts.html地址提示霍格沃茨，图片提示火车，源码提示”有 hogwartsone 即是有…”查询之（http://www.google.com.hk/search?hl=zh-CN&amp;safe=strict&amp;q=%E6%9C%89+hogwartsone+%E5%8D%B3%E6%98%AF%E6%9C%89...&amp;aq=f&amp;aqi=&amp;aql=&amp;oq=&amp;gs_rfai=）找到（”http://zhidao.baidu.com/question/165484021.html&quot;）gillywater 37http://riddle.arthurluk.net/checked/gillywater.html标题”The soup of Sung”（宋家汤？）、输入框answerlength属性”6 or 7”、查看源码”Guess a food”查询”The soup of Sung”（http://www.google.com.hk/search?hl=zh-CN&amp;source=hp&amp;q=The+soup+of+Sung&amp;btnG=Google+%E6%90%9C%E7%B4%A2&amp;aq=f&amp;aqi=&amp;aql=&amp;oq=&amp;gs_rfai=）果然是罗宋汤。borsch 38http://riddle.arthurluk.net/express/love.html输入Romeo、Juliet不解释……计算得到24.5%24.5 39http://riddle.arthurluk.net/express/24.5.html谷歌地球发挥作用。查看25°2’1”N 121°33’52”E处，是台北taipei 40http://riddle.arthurluk.net/express/taipei.html标题”Vowel”，动用Notepad++复制文本进去，用正则”[AEIOU]”高亮全部结果，发现隐藏着的EXTRAextra 41http://riddle.arthurluk.net/express/extra.html标题”Keyboard caesar”，于是用CaesarCode加解密dyrq，均错误恺撒密码 后推三位联系Keyboard和第23关经验，于是用键盘顺序来作密表，加密dyrq得到hour 键盘后推三位hour 42http://riddle.arthurluk.net/express/hour.html标题意为帝国时代2，Ctrl+A看到”這建築物的英文名稱？”翻译铁匠铺得到BlackSmithblacksmith 43http://riddle.arthurluk.net/factory/mix.html地址提示”混合”，联想”巧克力、咖啡”得到摩卡咖啡（http://baike.baidu.com/view/8123.htm）mocha 44http://riddle.arthurluk.net/biologycity/entrance.html查看源代码，进入”http://riddle.arthurluk.net/biologycity/plant.html&quot;那个蘑菇（http://riddle.arthurluk.net/biologycity/mushroom.jpg）哪里错了呢？（它不是蘑菇，好像是树。。。）于是进入http://riddle.arthurluk.net/biologycity/tree.jpg，可是这里是草于是进入http://riddle.arthurluk.net/biologycity/grass.jpg，可是这里是蜗牛于是进入http://riddle.arthurluk.net/biologycity/snail.jpg，可是这里是鳄鱼于是进入http://riddle.arthurluk.net/biologycity/crocodile.jpg，可是这里是熊猫于是进入http://riddle.arthurluk.net/biologycity/panda.jpg大写字母要敏感的。。http://riddle.arthurluk.net/biologycity/troy.html 45http://riddle.arthurluk.net/biologycity/troy.html需要翻墙。。不解释。请跳到下一关 46http://riddle.arthurluk.net/highway/quest.html德沃夏克键盘… 47http://riddle.arthurluk.net/factory/fix.htmlorienteering43关是mix…不要说,查吧… 48http://riddle.arthurluk.net/factory/charlie/chocolate.html查理的巧克力工厂 49http://riddle.arthurluk.net/highway/calculator.html卡西欧 FX3650P 计算器 Mem clear : ? → A : ? → B : Lbl 1 :B ÷ A – .5 : Fix 0 : Rnd : Norm 1 : Ans → C :B – AC : Ans 10x D M+ : C → B :D + 1 → D : C =&gt; Goto 1 : M Find the output if A=5 and B=2007 也是很好算的 31012 50.1http://riddle.arthurluk.net/highway/fifty.html关键是“THIS TIME”直接在dvorak键盘上平移而不是转到普通键盘 发现和果然和上次41关一样，右移动3位，得到答案：truth 50.2http://riddle.arthurluk.net/highway/truth.htmlsilver.jpg 改为 gold.jpg 50.3http://riddle.arthurluk.net/highway/choice.html图的左上角 51http://riddle.arthurluk.net/highway/park.html数独，填出来是1942，中途岛海战,二战119 97 14 = war 52http://riddle.arthurluk.net/highway/secondworldwar.html保龄球 积分规则得到以下分数:7 9+10 10+10 10+8 8 10+10 10+10 10+10 10+10 10+8答案 187 53.1：http://riddle.arthurluk.net/samuelriddle/shadow.html看到那个括号了吗？仔细看，那个单词中有一个字母是错误的，改正它放入地址栏进入riddle 53.2：http://riddle.arthurluk.net/samuelriddle/riddle.htmlc c r a n e 能组成什么新单词呢？cancer(我弄了半小时!!!) 53.3：http://riddle.arthurluk.net/samuelriddle/cancer.htmlmspaint_a.png，把-a换成b.d.e.f.g…？一个一个的跳,直到h后把源码中所有mspaint_h.html全替换成空白 然后你看到一个网页，在右下角。。。mspeint_h.html 53.4：http://riddle.arthurluk.net/samuelriddle/mspeint_h.html这关就不为难你们了，需要专门的查看器，所以答案是muffin54关：http://riddle.arthurluk.net/samuelriddle/muffin.html察看图片吧 55关：http://riddle.arthurluk.net/chem_is_try/muffin.html原来这四个都是 欧盟的 危险品标识corrosive有害的harmful易爆的Explosive易燃的flammable首字母 55.2：http://riddle.arthurluk.net/chem_is_try/chef.html！！擦，同上一关类似~http://s2.hubimg.com/u/80145_f496.jpg 这是资料 55.3http://riddle.arthurluk.net/chem_is_try/beef.html希望你们还活着。。把XXXX改成txt，得到提示然后，1，听歌，2 谷歌它（元素周期表） 56关：http://riddle.arthurluk.net/chem_is_try/rubidium.html255汉诺塔。。。 57关： 微软雅黑所属的字体类型的名字Segoe Ui~~微软在Windows Vista和Office 12中放弃Windows XP中的Tahoma字体，转而启用新的Segoe UI字体，意在提高字体的可读性，使之更加人性化看图片名称，找出这个字体~是特有的哦~ 58关：http://riddle.arthurluk.net/escalator/segoeui.html1293，卡通人物 tiyilon=doraemon 59关：http://riddle.arthurluk.net/poker/chinese_horoscope.html罗马数字，生肖，首字母，我相信你知道的~ 60.http://riddle.arthurluk.net/poker/drop.html德国61.http://riddle.arthurluk.net/poker/germany.html一个日期(希特勒的生日)62.http://riddle.arthurluk.net/poker/hitler.htmlpiano(36个白,52个黑)63.http://riddle.arthurluk.net/goldengatebridge/obstacle.php看提示“此地不宜久留，請到圖所示的地方。”~~这是金门大桥呀~~再看网址http://riddle.arthurluk.net/goldengatebridge/obstacle.html ，其实的文件夹名就是金门大桥的意思，那剩下的obstacle是什么意思呢？百度之，原来是障碍~~那么，我们去掉障碍不就能到金门大桥了嘛~~于是输入http://riddle.arthurluk.net/goldengatebridge ，发现它跳了几次后跑到网站首页去了~~怎么回事？~~再看提示，“此地不宜久留”，哦，就是说要在它跳转的时候看代码~~于是多试几次呗，在跳转中不停地打开代码，直到你看到“你最後還是停了下來！”为止 64.http://riddle.arthurluk.net/goldengatebridge/flashgame.html这一关提示为“辛苦了這麼久，來玩個射擊遊戲吧！(Arthur：這關算是大放送XD)本關目標就是要找出 Final Boss 的名稱 (** Zombie)”，嗯，那就玩游戏吧~~只有几个要注意的，一是密码门那儿的密码就是门框上的不过要从右往左输；二是中毒后大左边的箱子，注意看会有个黑色的小东西出现，，打它得红卡，然后打右上按钮左边的黑线，即刷卡，然后依次打按钮即可~~最后要注意的是最终boss名字出现时间较短，要用心记~~嗯，最后出现的是“Limbless Zombie”意为无足的僵尸~~然后再注意一点，提示中已经给出Zombie了 65.http://riddle.arthurluk.net/goldengatebridge/limbless.html这一关咋一看我还以为是多少进制的呢，再一看代码，有个“ADFGVX cipher”，谷歌维基之，得ADFGVX密码~~是一战时候用的哦~~简单的说就是一个6*6的表格，行和列的表头都是ADFGVX，然后把26个字母和10个数字以一定顺序填入方框中，这样每个字母或数字都可以用如AD这样的坐标来代替(AD代表t)，读坐标时先读行再读列~~这样，题目“ADDDXF FXXFGXAD FGADAFGAXF AGFG GFAFAXADGGXDXF.DDADXAAG”就被翻译成了the next stage ls capture.html~~神奇吧~~不过里面有一处应该是is作者弄成了ls，应该是他错了~~ 66.http://riddle.arthurluk.net/goldengatebridge/capture.html 67.http://riddle.arthurluk.net/fortress/atmosphere.php看代码，里面有句“What is ISP in full name?”和一句“size=”20” maxlength=”20” answerlength=”23””~~意为答案是23为长度的ISP的全称~~百度，得Internet Service Provider~~输入internetserviceprovider，发现答案栏不够输，因为刚才代码中写了，最长范围为20答案有23~~于是输到网址中~~它说“答案就對了，不過你應把答案放到該放的位置。”~~看来还是要放到答案栏中~~怎么办呢？~~把源码保存下来，在本地自己用此源码新建个网页，改动action=”../check3.php”&gt;变为action=”http://riddle.arthurluk.net/check3.php&quot;&gt;，size=&quot;20&quot; maxlength=”20” 变为size=”23” maxlength=”23” ~~保存，打开，输入~~成功啦~~ 68.http://riddle.arthurluk.net/fortress/umbrella.html 69.http://riddle.arthurluk.net/fortress/vincentvangogh.html这一关其实就是个数学推理题，不过有点难度~~它问：ICQ+IQC+CIQ+CQI+QIC+QCI=WHAT，提示“WHAT is the answer”，于是计算呗~首先我们设2I+2C+2Q=XT，于是题目变成XT+10XT+100XT=WHAT~~我们用穷举法假设XT的所有可能，最后得出XTAHW=28013、83019、37014、73018、38124、83129、46015、64017、47125、74128、48235、84239、65127、57236、75238、58346、85349、76348、68457、86459、87569~~那么接下来就一个一个试呗~~我运气好，试第一个就对啦~~3108~~嗯，下一关 70. 72.http://riddle.arthurluk.net/fortress/bend.html盐…http://riddle.arthurluk.net/fortress/salt.html 73.http://riddle.arthurluk.net/fortress/sodiumchloride.phpNonogram游戏填充,是heart 74.http://riddle.arthurluk.net/marble/maze.phpbasketballhttp://riddle.arthurluk.net/marble/basketball.htmlJerry Alan Westhttp://riddle.arthurluk.net/marble/jerry.php这条是ascii和16进制解码 75.http://riddle.arthurluk.net/marble/chat.htm:題目為ひらえ うわ てを おそまけけふまそめ，由提示的伊呂波歌得下面歌詞：いろはにほへとちりぬるをわかよたれそつねならむういのおくやまけふこえてあさきゆめみしえひもせす並且由原始檔中寫的pic16.gif圖中看出A~Z&amp;a~z順序（Wedding字形），為縱行排序。將伊呂波歌依序填入1~47的空格，就可拼出”The pw is crossworD”（pw為password縮寫），故密碼為crossword 76.http://riddle.arthurluk.net/marble/exifforh人名 Aragorn Eowyn Gollum Théoden答案gate 77.http://riddle.arthurluk.net/sweater/english帝国时代答案 isolation 78.http://riddle.arthurluk.net/sweater/colour.php 79.http://riddle.arthurluk.net/sweater/royalblue.phpfind the director电影是mission impossible的海报导演brian de palma 80.http://riddle.arthurluk.net/sweater/briandepalma.php是纽约的夜景(联合国总部)答案 unitednations 81.http://riddle.arthurluk.net/sweater/unitednations.php香港童子军 答案 voyageraward 82.http://riddle.arthurluk.net/keroro/floppy.phpatbash密码 解码出来是notepad 记事本图片的名字为treasuremap.jpg,改成treasuremap.txt得到关于隐藏关卡的信息(aboutthehiddenstage.html),然后读到好几句话,每句话的字数:20,18,9,1,14,7,12,5;得到triangle 83.http://riddle.arthurluk.net/keroro/triangle.html图片名是tan.jpg,打开sin.jpg和cos.jpg得到fire love就是恋爱三要素和燃烧三要素 首字母来的答案honest 84. 一开始毫无头绪~~我查了标题triangle，是三角形的意思，还有一部电影也叫这个名字，恰巧我看过~于是输入导演名，不对~~然后看图片~我把图片后缀改成bmp、png、txt都不对~~又百度了图片中的Toblerone，是卡夫的三角形巧克力~~依然无头绪~~后来在卡了好久之后，我突然发现图片名tan不就是三角函数嘛~于是我试了sin和cos~出现心和火之类的~~我输入heart、fire这些都不对~~后来我突然想到会不会这回是要改前面的网址呢~于是我改成heart.php之类的，还是不对~~再后来我在打heart时突然想到会不会是heat温度呢？输入heat.php~显示“Partly correct.”部分正确~~然后我就无能为力了~~于是各种谷歌百度~网上有人提示“oxygen”氧气~~于是输入oxygen.php~~显示“Partly correct.”~~这时就有点眉目了~火燃烧的三个条件就是温度、氧气、可燃物~~于是看sin那张图~~试了好几次，最后发现是fuel~输入fuel.php~~显示“Partly correct.”~~对了，这时候注意到每个源文件中都有“That’s 1/6 of the answer”，也就是说我们还少三个单词~~好吧，继续百度，有大大说是passion激情~输入passion.php~~显示“Partly correct.”~~还有，这回出现的图片是船，前面分别是礼物盒子、急救车、问号~完全不知道是什么~~继续找大大~~有人说是“intimacy”亲密，出现一个圆~~又有人说是“commitment”委托，出现火车~~好啦现在6个全齐了~输入“heatoxygenfuelpassionintimacycommitment.php”~~竟然不对！~~我彻底疯了~~八成是要拆字~~好吧，我承认我拆不出来~~于是再去找大大~~得到提示“honest”~~输入，通过~~下一关http://riddle.arthurluk.net/keroro/honest.php ~~好吧，其实这一关我真的没干啥，全是在大大们的各种指引下才过的~真悲催~~唔！刚才洗澡的时候我突然地悟啦！~那个三角形中间套个火的图案其实在我们的化学书上见到过的，讲的就是火的三元素，所以才是温度heat、氧气oxygen、可燃物fuel~~那么那个三角形中间套个love的图案，讲的就是爱的三要素了~我百度“爱情三要素”，得到“爱情三角形理论”：美国心理学家斯腾伯格提出的爱情理论，认为爱情由三个基本成分组成：亲密（Intimacy）、激情（passion）、及承诺(commitment) ~~所以啦，那6个答案就都出来啦~~至于怎么把这6个答案合成honest~我现在还不知道~~http://riddle.arthurluk.net/keroro/honest.phphttp://riddle.arthurluk.net/keroro/angol.php 85.http://riddle.arthurluk.net/keroro/100000000000000.php在数字键盘上写字1478963456填上发现是A，9874123是C，852是I，74178621是D，9874123456是E，1475369是N，789852是T，合起来就是ACCIDENT哈~这一关一开始还真以为是什么找规律呢，结果看了好久也没看出个所以然来~~后来百度这些数字~~竟然被我找到了专门讲键盘加密方法的一个网页http://bbs.moyu8.com/home.php?mod=space&amp;uid=85626&amp;do=blog&amp;id=10751 ~~这个里面的数字键盘加密法，说白了就是在数字键盘上写字，怎么像怎么来~~于是我在数字键盘上把1478963456填上发现是A，9874123是C，852是I，74178621是D，9874123456是E，1475369是N，789852是T，合起来就是ACCIDENT意外事故~于是输入accident，通过~~下一关http://riddle.arthurluk.net/regular/recycle.php ~~86.http://riddle.arthurluk.net/regular/recycle.php这一关我的浏览器没发出声音，不知道你们的是不是~~不过我在源文件中发现了音乐的地址http://riddle.arthurluk.net/regular/stage86.mid ~~ 呃~但是我听不出来这是什么哎~~这就是从小没学音乐的后果~呜~~然后我用了一个在线录歌搜音乐的网站http://www.midomi.com/ ~~可惜还是没搜出来，这个网站主要是搜有人唱的歌的~~呃~于是我就只好在百度上搜“世界名曲钢琴曲”~然后一首一首的听~~终于被我听到啦~~是《土耳其进行曲》~~然后百度“土耳其进行曲”~得到是奥地利音乐家莫扎特Mozart于1781年至1783年间在慕尼黑或维也纳所作的~~于是输入mozart~~呃，竟然不对？幸亏我有没事就查看源文件的习惯~只见源文件中赫然写着“The next stage is in problem.php” 87.1http://riddle.arthurluk.net/regular/problem.php先看源代码，发现图片名为stage87pic1，于是好奇的输入stage87pic2，又出来一个图片~一共有5幅~~然后挨个儿看吧~~第一幅图片一开始我以为是什么游戏，后来猛然想到应该是元素，中间是质子，周围是一圈圈电子层~第二幅图片是一排数列？呃，这个彻底不知道，先放着~~第三幅图片是一个雪屋，大概是爱斯基摩人的吧~用百度翻译翻译雪屋，得igloo~这个有点小把握~~第四幅是一堆橘子，orange~~第五幅是扫雷游戏，可惜我家的这台电脑是中文版的，要是宿舍的那台英文版的就好了~所以只好百度，好像扫雷游戏的英文名是mine sweeping~~其实我一开始也愣了好久，后来才想到可能是用各个图片的首字母~~现在可能是是z?iom（？为一个任意字母，*为任意个任意字母）~~我用必应词典，输入z?iom~竟然没有！~~于是去掉最不肯定的z~~输入??iom~得axiom（公理）和idiom（习语）~~挨个试~~试到idiom时，终于对了，进入第二小关 87.2The grass is always greener on the other side，这山望着那山高http://riddle.arthurluk.net/regular/thegrassisalwaysgreener.php 88.http://riddle.arthurluk.net/regular/idiom.php点白色一团纸 89.http://riddle.arthurluk.net/eightynine.php 116.http://arthurluk.net/riddle/horror/quaver.php 117.http://riddle.arthurluk.net/revolution/mountain.php不要输密码框118.http://arthurluk.net/riddle/revolution/emptyfortstrategy.php 参考了以下的文章http://www.zhangshengdong.com/post/2012-03-17/15426274http://www.douban.com/group/topic/27282526/http://jilu.zhangshengdong.com/post/2012-05-30/40028636785http://www.sudokufans.org.cn/forums/topic/732/http://jilu.zhangshengdong.com/post/2012-05-30/40028636785和这个攻略 1:点击Don’t install. 2:Ctrl+A ，你看见了什么？ 3：查看图片的地址然后打开，知道是？ 4:打开源文件。 5:这个是字母表密码。 6:goole一下无限弹珠的游戏秘籍 7:与Windows齐名的另一款系统软件 企鹅系统？ 8:（元素周期表）先翻译成数字，再翻译成字母。 9:看见图上的字母了吗？我一直以为是loves 10:源文件老规矩看title “Diagonal” 11:泰坦尼克号：不沉的船还是沉了 12:百度一下你就知道（1874） 13:看见源文件中有一个Pets Not Giant.取首字母得PNG,拷贝老虎图片地址，将后缀名改成png便知秘密 14:直接算出来吧（534202） 15:直接算出来吧（13942） 16:数字人生（43140624） 17:空格？ 18:百度一下 自然对数？（71352） 19: 如果l是-那么i就是….【摩斯电码】 20:另存为——用记事本打开 或者查看图片注释。 21:去掉超文本标记html后边的l 22:仔细看图片？左下角？还有上一关？ 23:键盘移位密码： qwert键盘上对应的数字？ 24:红心大战记分规则？，答案用英文表示。 25:sqr()函数：平方 ; trunc()函数：去小数保整数。 26:打开FLASH源地址 冠军的身上- - (champion) 27:等吧。或者把FLASH下下来跳帧（好吧 不浪费大家时间了 答案是attic） 28:计分，并替换成英文字母。 29:Google之 30:…度娘一下吧 31:下载图片，进入画图，每个坐标对应一个字母。 32:这个门是叮当猫的。。。（很冷） 33:截屏。 34:在Jellyneo的Data base中搜索。 35:贝多芬的曲子。。 36:由hogwartsone推想hogwartszero然后google之 37:观察源文件得到提示，然后Google之 38:随便试试 39:Google Earth之 40:所有的元音调一下。 41:键盘凯撒。 42:帝国时代2建筑 43:Google之 44:不停地修改错误 45:其实就是作者的Xanga. 46:sign my questbook然后翻到最后一页，期间可以欣赏Simon大神的留言。。 47:Google之 48:观看标题，《查理的巧克力工厂》 49:老老实实算吧。 50:1)凯撒 2)观看源文件知道如何加密 3)看到silver想到gold 4)Jellyneo的Data base 5)看图的左上角 51:先解数独，然后猜事件 52:保龄球 187 53:1)改正riddle.. 2)cancer. 3)图片右下角，carrot. 4)破解QR码，muffin 54:修改中间,查看图片 55:1)首字母缩写 chef 2)同上 beef 3)观察标题。 56:汉诺伊塔 57:Segoe UI 58:1293..Google之 59:MCMLXXXVIII=1988=D MCMLXII=1963=R MCMLXII=1997=O MMVII=2007=P 60:帝国三主城 Germany的Berlin 61:加起来，然后看源文件，得到答案。 62:钢琴。 63:停止。先remove obstacle,然后停止 64:完成游戏。 65:查询得结果，棋盘密码。 66:语法 67:修改源文件 68:Google，然后多试几次 69:当成小学奥数题算，然后多试几次 70:这个。。看源文件。。观察日期的规律。 71:1)重复第21关 2)找出4种货币和他们对应的名称，连起来即可 72:考验你的时候到了。嘿嘿 73:填充，然后我发现这个简直是表白利器啊！！ 74:拼图，然后组词，这个词我想了很久。。 75:1)Google之 2)Hex+Ascll嘿嘿！别想太复杂 3)直接Google找答案！！ 76:看过《魔戒》没,认出你能认出的所有的，然后枚举吧！ 77:这个铁匠铺和外面的世界____？eyesolation是什么？ 78:http://ken.frwonline.com/color.htm自己研究吧 79:Wiki之 80:真的很简单 81:这个组织我好喜欢啊。为什么大陆没有呢？ 82:很烦人的一关，先观源文件，然后转换，然后翻译，然后再观汉字，然后再转字母 83:这个。。找吧。 84:1)太变态了！！Arthur 恶趣味！！！ 2)不断加0!!Arthur 恶趣味！！！ 85:感谢密码吧 86:看源文件就应该清楚它问的是什么。。然后相信自己。。 87:1)认出你会的所有的，然后枚举吧！ 2) 西方谚语 88:1)压力。。。 2)猜猜看呀。。。首页是？ 89:1)四边形推理 2)Do it! 看起来是什么幂诶。。。 90:1)单键吗？ 2)偶尔来一个水关反而会死很多人。。 3)What is missing? 4)呃。。 91:什么东西？一片空白？ 92:话说他少鸣谢了一个。。见66关 93:移去8个字母 94:去源文件看看吧。。嘿嘿。。相信你自己 95:找到赛道吧。 96:首页的图片 97:文字游戏 98:缩写 99:把图片绘出，然后识别一下 100:手机上写写，然后枚举！！ 101:排列组合 102:哇！这纸应该会很大！！ 103:100关后还有如此水关。。 104:搜索这个星舰 105:用圆周率来跳读，然后回答问题。 106:什么平均数来着？ 107:我。。。我以为是圣经。。原来是本儿童读物。 108:有一个原来的技巧在里面。 109:brick ignore the k 然后就行了 110:这个。。先变黑白，然后再flip然后就行了 111:保存下来，各种拉伸 112:这是某样东西的分布图 113:下载程序，然后找吧 114:旋转呀！ 115:哇哈哈，这些音符我太熟了 116:等效代换，有问题的可以问我。。 117:有密码框就一定要输吗？]]></content>
      <tags>
        <tag>arthurluk</tag>
        <tag>游戏</tag>
      </tags>
  </entry>
</search>
