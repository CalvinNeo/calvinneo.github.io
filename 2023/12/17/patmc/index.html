<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="性能," />





  <link rel="alternate" href="/atom.xml" title="Calvin's Marbles" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="According to 老板，according to yifan，这本书很好，所以我就来学习一下了。">
<meta name="keywords" content="性能">
<meta property="og:type" content="article">
<meta property="og:title" content="Performance analysis and tuning on modern CPUs 学习笔记">
<meta property="og:url" content="http://www.calvinneo.com/2023/12/17/patmc/index.html">
<meta property="og:site_name" content="Calvin&#39;s Marbles">
<meta property="og:description" content="According to 老板，according to yifan，这本书很好，所以我就来学习一下了。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/3.8.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/3.9.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/3.10.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/t2.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/3.12.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/3.13.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/3.14.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/3.16.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/cpiipc.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/5.19.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/5.25.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/5.24.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/l8.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/5.25.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/5.25.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/6.28.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/7.41.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/7.42.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/7.43.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/7.44.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/t6.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/8.45.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/ext1.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/l32.png">
<meta property="og:image" content="http://www.calvinneo.com/img/patmc/l34.png">
<meta property="og:updated_time" content="2024-01-29T15:25:44.930Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Performance analysis and tuning on modern CPUs 学习笔记">
<meta name="twitter:description" content="According to 老板，according to yifan，这本书很好，所以我就来学习一下了。">
<meta name="twitter:image" content="http://www.calvinneo.com/img/patmc/3.8.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.calvinneo.com/2023/12/17/patmc/"/>





  <title>Performance analysis and tuning on modern CPUs 学习笔记 | Calvin's Marbles</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Calvin's Marbles</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.calvinneo.com/2023/12/17/patmc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Calvin Neo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Calvin's Marbles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Performance analysis and tuning on modern CPUs 学习笔记
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-12-17T10:57:32+08:00">
                2023-12-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>According to 老板，according to yifan，这本书很好，所以我就来学习一下了。</p>
<a id="more"></a>

<h1 id="Part-1-的说明"><a href="#Part-1-的说明" class="headerlink" title="Part 1 的说明"></a>Part 1 的说明</h1><h1 id="Measuring-Performance"><a href="#Measuring-Performance" class="headerlink" title="Measuring Performance"></a>Measuring Performance</h1><p>Changing a seemingly unrelated part of the source code can surprise us with a significant impact on program performance. This phenomenon is called measurement bias. … Instead, we will just focus on high-level ideas and directions to follow.</p>
<p>This chapter will give a brief introduction to why modern systems yield noisy performance measurements and what you can do about it.</p>
<h2 id="Noise-In-Modern-Systems"><a href="#Noise-In-Modern-Systems" class="headerlink" title="Noise In Modern Systems"></a>Noise In Modern Systems</h2><p>一种叫 Dynamic Frequency Scaling 的技术可以短时间内提升 CPU 的频率，但它是基于核心温度的，所以不确定。在散热不太好的笔记本上经常发生第一个 run 会 turbo，但第二个 run 回归到 base frequency 的情况。</p>
<p>软件层面的因素，包括 file cache 是否 warm。有论文说，env var 的大小，以及 link 的顺序都能影响性能。影响内存布局也可以影响性能，有研究说 efficiently and repeatedly randomizing the placement of code, stack, and heap objects at runtime 可以解决处理内存布局带来的问题。</p>
<p>如果 benchmark 一个云处理器环境，上述的 noise 和 variation 基本难以被消除。</p>
<p>temci 这个工具能够设置环境，从而确保一个 low variance。</p>
<h2 id="Measuring-Performance-In-Production"><a href="#Measuring-Performance-In-Production" class="headerlink" title="Measuring Performance In Production"></a>Measuring Performance In Production</h2><h1 id="CPU-Microarchitecture"><a href="#CPU-Microarchitecture" class="headerlink" title="CPU Microarchitecture"></a>CPU Microarchitecture</h1><h2 id="Instruction-Set-Architecture"><a href="#Instruction-Set-Architecture" class="headerlink" title="Instruction Set Architecture"></a>Instruction Set Architecture</h2><p>the critical CPU architecture and microarchitecture features that impact performance</p>
<p>In addition to providing the basic functions in the ISA such as<br>load, store, control, scalar arithmetic operations using integers and floating-point, the widely deployed architectures continue to enhance their ISA to support new computing paradigms. These include enhanced vector processing instructions (e.g., Intel AVX2, AVX512, ARM SVE) and matrix/tensor instructions (Intel AMX). Software mapped to use these advanced instructions typically provide orders of magnitude improvement in performance.</p>
<p>深度学习中，即使使用较少的 bits 效果也挺好，所以一些处理器倾向于引入 8bit integer 等来节约计算和内存带宽。</p>
<h2 id="Pipelining"><a href="#Pipelining" class="headerlink" title="Pipelining"></a>Pipelining</h2><p>The processing of instructions is divided into stages. The stages operate in parallel, working on different parts of different instructions.</p>
<p>在 CSAPP 里面已经学习了取指、解码、执行、访存、写回的流水线。</p>
<p>The throughput of a pipelined CPU is defined as the number of instructions that complete and exit the pipeline per unit of time.</p>
<p>The latency for any given instruction is the total time through all the stages of the pipeline.</p>
<p>The time required to move an instruction from one stage to the other defines the basic machine cycle or clock for the CPU. The value chosen for the clock for a given pipeline is defined by the <strong>slowest stage</strong> of the pipeline. 因此这里的优化点是均衡或者重新设计 pipeline，消除最慢的 stage 的 bottleneck。</p>
<p>假定所有的 stage 都是完美 balanced，没有任何 stall，那么通过 pipeline，可以让一个指令的处理时间减少到原来的 n_stage 分之一。</p>
<p>下面提到三种冒险，其中 Structural hazard 指的是对硬件资源的争抢，通常通过复制硬件解决。剩下两种在 CSAPP 中详细介绍过了，本教程做了归纳。<br>数据冒险是程序中的数据依赖，分三类：</p>
<ol>
<li><p>Read after write<br> x 的写结束前，x + 1 就需要读到 x 的写的内容，不然 x + 1 会读到更旧的数据。通常使用 bypassing 的办法，将数据从流水线的后面(指令 x + 1 的阶段) forward 到前面(指令 x 的阶段)。</p>
</li>
<li><p>Write after read<br> x 在读完之后，x + 1 才能写，不然 x 会读到更新的数据。译码阶段总是在写回阶段前面，为什么会有 WAR 场景？原因是需要考虑处理器乱序执行。如下所示，R0 上存在 WAR 场景。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">R1 = R0 ADD 1</span><br><span class="line">R0 = R2 ADD 2</span><br></pre></td></tr></table></figure>

<p> WAR 可以被 register renaming 解决。 Logical (architectural) registers, the ones that are defined by the ISA, are just aliases over a wider register file。因此，只需要将第二个 R0，以及之后的所有的 R0 重命名到另一个寄存器文件上即可解决问题。因此这两个指令之间就可以被乱序执行了。<br> 【Q】这些 physical register file 如何被 gc 呢？旧的 R0 alias 不知道新的 R0 alias 的存在啊。看 CPU backend 的介绍时发现，这个是 ROB 做的。</p>
</li>
<li><p>Write after write<br> 同样可以通过 register renaming 解决。</p>
</li>
</ol>
<p>控制冒险主要指分支预测之类的东西，影响取指阶段。诸如动态分支预测、 speculative execution 能优化。</p>
<h2 id="Exploiting-Instruction-Level-Parallelism-ILP"><a href="#Exploiting-Instruction-Level-Parallelism-ILP" class="headerlink" title="Exploiting Instruction Level Parallelism (ILP)"></a>Exploiting Instruction Level Parallelism (ILP)</h2><p>大多数的指令可以被并行执行，因为它们是不相关的。</p>
<h3 id="OOO-Execution"><a href="#OOO-Execution" class="headerlink" title="OOO Execution"></a>OOO Execution</h3><p>An instruction is called retired when it is finally executed, and its results are correct and visible in the <a href="https://en.wikipedia.org/wiki/Architectural_state" target="_blank" rel="noopener">architectural state</a>. To ensure correctness, CPUs must retire all instructions in the program order. 这里 architectural state 主要区分于 microarchitectural state，后者是隐藏的 state，例如 pipeline registers、cache tag、branch predictor 等。</p>
<p>OOO is primarily used to avoid underutilization of CPU resources due to stalls caused by dependencies, especially in superscalar engines described in the next section.</p>
<p>scoreboard 被用来 schedule the in-order retirement and all machine state updates。它需要记录每一条指令的数据依赖 and where in the pipe the data is available。scoreboard 的大小决定了 CPU 能够超前多少调度彼此无关的指令。</p>
<p>下图中，x + 1 因为一些冲突，插入了一些气泡。而 OOO 的执行可以使 x + 2 这个 independent 的指令先进入执行(EXE)阶段。但是所有的指令还是要 按照 program order 来 retire，也就是最后的写回阶段是要按顺序的。<br><img src="/img/patmc/3.8.png"></p>
<h3 id="Superscalar-Engines-and-VLIW"><a href="#Superscalar-Engines-and-VLIW" class="headerlink" title="Superscalar Engines and VLIW"></a>Superscalar Engines and VLIW</h3><p>Most modern CPUs are superscalar i.e., they can issue more than one instruction in a given cycle. Issue-width is the maximum number of instructions that can be issued during the same cycle.</p>
<p>目前处理器的 issue width 在 2 到 6 之间。为了处理这些 instruction，目前 CPU 也会支持 more than one execution unit and/or pipelined execution units。Superscalar 也可以和之前提到的 pipeline 和 OOO 结合起来用。</p>
<p>下图展示了 issue width = 2 的情况。 Superscalar CPU 中支持多个 independent execution units 能够执行指令，而避免冲突。<br><img src="/img/patmc/3.9.png"></p>
<p>Intel 使用 VLIW，即 Very Long Instruction Word 技术将调度 Superscalar 和 multi execution unit 的负担转移给编译器。这是因为 software pipelining, loop unrolling 这些编译器优化相比硬件能看到的更多。</p>
<h3 id="Speculative-Execution"><a href="#Speculative-Execution" class="headerlink" title="Speculative Execution"></a>Speculative Execution</h3><p>下面介绍了 Speculative Execution 是什么，不翻译了。</p>
<blockquote>
<p>As noted in the previous section, control hazards can cause significant performance loss in a pipeline if instructions are stalled until the branch condition is resolved. One technique to avoid this performance loss is hardware branch prediction logic to predict the likely direction of branches and allow executing instructions from the predicted path (speculative execution).</p>
</blockquote>
<p>如下所示，Speculative Execution 不会等 branch 预测结果，而是直接执行 foo，如打星号所示，但是实际的状态变化直到 condition 被 resolve 之后才会被 commit，这样才能保证 architecture state 不会被 speculative executing 影响。</p>
<p><img src="/img/patmc/3.10.png"></p>
<p>在现实中，branch 命令可能依赖从内存中加载上来的某个值，这可能需要花费上百个 cycle。如果分支预测的是不正确的，也就是实际应该调用 bar 了，那么 speculative 执行的结果需要被扔掉，称为 branch misprediction penalty。</p>
<p>为了记录 speculation 的进度，CPU 支持一个叫 ReOrder Buffer 即 ROB 的结构。ROB 中依照顺序了所有指令，包括已经 retire 的指令的状态。如果 speculation 是正确的华，speculative execution 的结果按照 program order 会写到 ROB 里面，然后被 commit 到 architecture register 中。</p>
<p>CPUs can also combine speculative execution with out-of-order execution and use the ROB to track both speculation and out-of-order execution.</p>
<h2 id="Exploiting-Thread-Level-Parallelism"><a href="#Exploiting-Thread-Level-Parallelism" class="headerlink" title="Exploiting Thread Level Parallelism"></a>Exploiting Thread Level Parallelism</h2><p>A hardware multi-threaded CPU supports dedicated hardware resources to track the state (aka context) of each thread independently.<br>The main motivation for such a multi-threaded CPU is to switch from one context to another with the smallest latency (without incurring the cost of saving and restoring thread context) when a thread is blocked due to a long latency activity such as memory references</p>
<h3 id="Simultaneous-Multithreading"><a href="#Simultaneous-Multithreading" class="headerlink" title="Simultaneous Multithreading"></a>Simultaneous Multithreading</h3><p>ILP techniques and multi-threading 被结合使用。不同线程中的指令在同一个 cycle 中被并发地执行。同时从多个线程中 dispatch 指令可以充分利用 superscalar 资源，提高 CPU 总体性能。为了支持 SMT，CPU 需要复制硬件去存储 thread state，例如 PC 和寄存器等。追踪 OOO 和 speculative execution 的资源可以复制，也可以共享。一些 Cache 被 hardware 线程共享。</p>
<h2 id="Memory-Hierarchy"><a href="#Memory-Hierarchy" class="headerlink" title="Memory Hierarchy"></a>Memory Hierarchy</h2><p>Memory Hierarchy 从下面两种性质构造：</p>
<ol>
<li>Temporal locality</li>
<li>Spatial locality</li>
</ol>
<p>CSAPP 中进行了更为详细的讨论。</p>
<h3 id="Cache-Hierarchy"><a href="#Cache-Hierarchy" class="headerlink" title="Cache Hierarchy"></a>Cache Hierarchy</h3><p>A particular level of the cache hierarchy can be used exclusively for code (instruction cache, i-cache) or for data (data cache, d-cache), or shared between code and data (unified cache).</p>
<h4 id="Placement-of-data-within-the-cache"><a href="#Placement-of-data-within-the-cache" class="headerlink" title="Placement of data within the cache"></a>Placement of data within the cache</h4><h4 id="Finding-data-in-the-cache"><a href="#Finding-data-in-the-cache" class="headerlink" title="Finding data in the cache"></a>Finding data in the cache</h4><h4 id="Managing-misses"><a href="#Managing-misses" class="headerlink" title="Managing misses"></a>Managing misses</h4><p>对 direct-mapped 来讲，它会 evict 掉之前的 block。<br>对 set-associative 来讲，需要一个例如 LRU cache 的算法。</p>
<h4 id="Managing-writes"><a href="#Managing-writes" class="headerlink" title="Managing writes"></a>Managing writes</h4><p>CPU designs use two basic mechanisms to handle writes that hit in the cache:</p>
<ol>
<li>In a write-through cache<br> hit data is written to both the block in the cache and to the next lower level of the hierarchy</li>
<li>In a write-back cache<br> hit data is only written to the cache.<br> Subsequently, lower levels of the hierarchy contain stale data.<br> The state of the modified line is tracked through a dirty bit in the tag. When a modified cache line is eventually evicted from the cache, a write-back operation forces the data to be written back to the next lower level.</li>
</ol>
<p>Cache misses on write operations can be handled using two different options:</p>
<ol>
<li>write-allocate or fetch on write miss cache<br> 数据会被从下一级缓存中被加载上来，并且当前 write operation 会被视作一次 write hit。</li>
<li>no-write-allocate policy<br> cache miss 会直接被发送到下一级缓存，并且该缓存不会被加载到当前缓存。</li>
</ol>
<p>Out of these options, most designs typically choose to implement a write-back cache with a write-allocate policy as both of these techniques try to convert subsequent write transactions into cache-hits, without additional traffic to the lower levels of the hierarchy.</p>
<p>Write through caches typically use the no-write-allocate policy.</p>
<h4 id="Other-cache-optimization-techniques"><a href="#Other-cache-optimization-techniques" class="headerlink" title="Other cache optimization techniques"></a>Other cache optimization techniques</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Average Access Latency = Hit Time + Miss Rate × Miss Penalty</span><br></pre></td></tr></table></figure>

<p>硬件工程师们努力减少 Hit Time，以及 Miss Penalty。而 Miss Rate 取决于 block size 和 associativity，以及软件。</p>
<h4 id="HW-and-SW-Prefetching"><a href="#HW-and-SW-Prefetching" class="headerlink" title="HW and SW Prefetching"></a>HW and SW Prefetching</h4><p>Prefetch 指令和数据可以减少 cache miss 和后续的 stall 的发生。</p>
<p>Hardware prefetchers observe the behavior of a running application and initiate prefetching on repetitive patterns of cache misses. Hardware prefetching can automatically adapt to the dynamic behavior of the application, such as varying data sets, and does not require support from an optimizing compiler or profiling support. Also, the hardware prefetching works without the overhead of additional address-generation and prefetch instructions. 当然，hardware prefetching 只限于某几种 cache miss pattern。</p>
<p>Software memory prefetching 中，开发者可制定一些内存位置，或者让编译器自行添加一些 prefetch 指令。</p>
<h3 id="Main-memory"><a href="#Main-memory" class="headerlink" title="Main memory"></a>Main memory</h3><p>Main memory uses DRAM (dynamic RAM) technology that supports large capacities at reasonable cost points.</p>
<p>主存被三个属性描述，latency、bandwidth 和 capacity。</p>
<p>Latency 主要是两个指标，Memory access time 是从请求，到数据 available 的时间。Memory cycle time 是两个连续的访存操作之间最小的时间间隔。</p>
<p>DDR (double data rate) DRAM 是主要的 DRAM 技术。历史上，DRAM bandwidth 每一代都会被提高，但是 DRAM 的 latency 原地踏步，甚至会更高。下面的表中展示了最近三代的 DDR 技术的相关数据。MT/s 指的是 a million transfers per sec。</p>
<p><img src="/img/patmc/t2.png"></p>
<h2 id="Virtual-Memory"><a href="#Virtual-Memory" class="headerlink" title="Virtual Memory"></a>Virtual Memory</h2><p>Virtual Memory 实现多个程序共享一个内存。具有特性：</p>
<ol>
<li>protection<br> 也就是不能访问其他进程的内存</li>
<li>relocation<br> 也就是不改变逻辑地址，但是将程序加载到任意的物理地址</li>
</ol>
<p>vitual 地址和物理地址通过 page table 进行转换。vitual 地址分为两部分。virtual page number 用来索引具体的 page table，这个 page table 可能是一层，也有可能嵌套了很多层。page offset 用来 access the physical memory location at the same offset in the mapped physical page。<br>如果需要的 page 不在主存里面，就会发生 page fault。操作系统负责告诉硬件去处理 page fault，这样一个 LRU 的 page 会被 evict 掉，腾出空间给新 page。</p>
<p>CPUs typically use a hierarchical page table format to map virtual address bits efficiently to<br>the available physical memory. CPU 会使用一个有层级的 page table 去维护 virtual address 和 physical memory 的关系。但 page fault 的惩罚是很大的，需要从 hierarchy 中 traverse 查找。所以 CPU 支持一个硬件结构 translation lookaside buffer (TLB) 来保存最近的地址翻译结果。</p>
<p><img src="/img/patmc/3.12.png"></p>
<h2 id="SIMD-Multiprocessors"><a href="#SIMD-Multiprocessors" class="headerlink" title="SIMD Multiprocessors"></a>SIMD Multiprocessors</h2><p>SIMD (Single Instruction, Multiple Data) multiprocessors 是相对于之前的 MIMD 来说的。SIMD 会在一个 cycle 中将一条指令运用于多个数据上，从而利用多个 functional units。</p>
<p>下图是 SISD 和 SIMD 的对比。<br><img src="/img/patmc/3.13.png"></p>
<h2 id="Modern-CPU-design"><a href="#Modern-CPU-design" class="headerlink" title="Modern CPU design"></a>Modern CPU design</h2><p>下图是 Skylake(2015) 的架构。 The Skylake core is split into an in-order front-end that fetches and decodes x86 instructions into u-ops and an 8-way superscalar, out-of-order backend.</p>
<p>The core supports 2-way SMT. It has a 32KB, 8-way first-level instruction cache (L1 I-cache), and a 32KB, 8-way first-level data cache (L1 D-cache). The L1 caches are backed up by a unified 1MB second-level cache, the L2 cache. The L1 and L2 caches are private to each core.</p>
<p><img src="/img/patmc/3.14.png"></p>
<h3 id="CPU-Front-End"><a href="#CPU-Front-End" class="headerlink" title="CPU Front-End"></a>CPU Front-End</h3><p>前端负责 fetch and decode instructions from memory，将准备好的指令喂给后端执行。</p>
<p>每一个 cycle，前端从 L1 I-cache 中取 16 bytes 的指令。它们被两个线程分享，所以实际上是第一个周期线程 A 取，第二个周期线程 B 取，然后又是线程 A 这样。这些指令是复杂的可变长度的指令，pipeline 的 pre-decode 和 decode 阶段将它们分成 micro Ops(UOPs)，并且把它们排在 Allocation Queue (IDQ) 队列中。</p>
<p>pre-decode 主要标记指令的边界。指令的长度从 1 到 15 bytes 不等。这个阶段还 identifies branch instructions。这个阶段移动最多 6 条指令，或者称为 Macro Instructions 到 instruction queue 中。instruction queue is split between the two threads. instruction queue 中有个 macro-op fusion unit，可以检测两个 macroinstructions 是否可以 fuse 为一个指令、</p>
<p>一个周期中，最多5个被 pre-decode 完毕的指令会被发送到 instruction queue，同样是两个线程轮流分享这个接口。Decoder 将复杂的 macro-Op 转化为固定长度的 UOP，也就是上文提到的 micro Op。Decoder 是 5-way 的。</p>
<p>前端主要的性能提升组件是 Decoded Stream Buffer (DSB)，或者称为 UOP Cache。它的目的是将 macro Op 到 UOP 的转换保存在单独的 DSB 结构中。在取指阶段，会先在 DSB 查询。频繁执行的 macro op 会命中 DSB，pipeline 就能够避免昂贵的 pre-decode 和 decode 环节。</p>
<p>DSB 提供 6 个 UOP，这个和前端到后端的接口匹配。DSB 和 BPU 也就是 branch prediction unit 协同工作。</p>
<p>一些非常复杂的指令需要超过 decoder 能够处理的 UOP，它们就会被送给 Microcode Sequencer (MSROM) 处理。这些命令包含字符串处理、加密、同步等指令。另外，MSROM 也会保存 microcode operation，以便处理分支预测出错（需要刷新 pipeline），或者 floating-point 等异常情况。 </p>
<p>Instruction Decode Queue (IDQ) 是在 inorder 的前端和 OOO 的后端之间的桥梁。每个 hardware thread 上 IDQ 大小 64 个 UOP，总计大小 128 UOP。</p>
<h3 id="CPU-Back-End"><a href="#CPU-Back-End" class="headerlink" title="CPU Back-End"></a>CPU Back-End</h3><p>后端是一些 OOO engine，执行指令并且存储结果。<br>后端的心脏是一个 ReOrder Buffer，即 ROB，它有 224 条 entry。它的功能：</p>
<ol>
<li>维护 architecture-visible registers 到 physical registers 的映射。这个映射被 Reservation Station/Scheduler (RS) 使用。</li>
<li>支持 register renaming。</li>
<li>记录 speculative execution。</li>
</ol>
<p>ROB entry 按照 program order retire。</p>
<p>Reservation Station/Scheduler (RS) 结构记录一个 UOP 所使用的所有资源的 availablility。一旦这些资源满足了，就会将这个 UOP dispatch 到某一个 port。因为 the core（不知道指的是什么）是 8-way superscalar，所以 RS 在一个 cycle 中可以 dispatch 最多 8 个 UOP。如上面图 14 所示，这些 Port 分别支持不同的操作：</p>
<ul>
<li>Ports 0, 1, 5, and 6 provide all the integer, FP, and vector ALU. UOPs dispatched to those ports do not require memory operations.</li>
<li>Ports 2 and 3 are used for address generation and for load operations.</li>
<li>Port 4 is used for store operations.</li>
<li>Port 7 is used for address generation.</li>
</ul>
<h3 id="Performance-Monitoring-Unit"><a href="#Performance-Monitoring-Unit" class="headerlink" title="Performance Monitoring Unit"></a>Performance Monitoring Unit</h3><h4 id="Performance-Monitoring-Counters"><a href="#Performance-Monitoring-Counters" class="headerlink" title="Performance Monitoring Counters"></a>Performance Monitoring Counters</h4><p>这也就是后面在 Sampling 中提到的 PMC。PMC 会收集 CPU 中各个组件的统计信息。<br><img src="/img/patmc/3.16.png"></p>
<p>一般来说，PMC 有 48bit 宽，这样可以允许分析工具能够跑更长时间，而不至于被中断触发。这是因为当 PMC overflow 的时候，程序执行会被中断，SW 需要存储 overflow 的情况。在 Sampling 章节也会进一步看到分析工具是如何利用这个特性的。</p>
<p>PMC 是 HW register，被实现为 Model Specific Register(MSR)。也就是具体有哪些，每种 CPU 是不一样的，并且 width 也不一定是 48bit。</p>
<h1 id="Terminology-and-metrics-in-performance-analysis"><a href="#Terminology-and-metrics-in-performance-analysis" class="headerlink" title="Terminology and metrics in performance analysis"></a>Terminology and metrics in performance analysis</h1><p>perf 命令或者 Intel VTune Profiler 里面的术语很难懂，本章进行介绍。</p>
<h2 id="Retired-vs-Executed-Instruction"><a href="#Retired-vs-Executed-Instruction" class="headerlink" title="Retired vs. Executed Instruction"></a>Retired vs. Executed Instruction</h2><ol>
<li>正常情况，the CPU commits results once they are available, and all precedinginstructions are already retired.</li>
<li>Speculative 执行，the CPU keeps their results without immediately committing their results. When the speculation turns out to be correct, the CPU unblocks such instructions and proceeds as normal. 如果预测失败，则会丢弃所有的结果，并且不 retire 它们。</li>
</ol>
<h2 id="CPU-Utilization"><a href="#CPU-Utilization" class="headerlink" title="CPU Utilization"></a>CPU Utilization</h2><p>CPU 不在跑 idle 线程的时候，即被认为是 utilize 的。</p>
<h2 id="CPI-amp-IPC"><a href="#CPI-amp-IPC" class="headerlink" title="CPI &amp; IPC"></a>CPI &amp; IPC</h2><p><img src="/img/patmc/cpiipc.png"></p>
<h2 id="UOPs-micro-ops"><a href="#UOPs-micro-ops" class="headerlink" title="UOPs (micro-ops)"></a>UOPs (micro-ops)</h2><p>Microprocessors with the x86 architecture translate complex CISC-like instructions into simple RISC-like59 microoperations - abbreviated µops or uops. 这里 CISC 指的是 Complex Instruction Set Computer。RISC 指的是 Reduced Instruction Set Computer。</p>
<p>这个转换的好处在于，UOP 可以被 OOO 地执行。一个简单的加法指令，例如 ADD EXA,EBX 只会产生一个 UOP。而一个复杂的指令，例如 ADD EAX,[MEM1] 可能生成两个 UOP，一个用来读内存到一个临时的，没有名字的寄存器中，另一个指令将这个临时寄存器中的数字加到 EAX 中。同理，ADD [MEM1],EAX 会产生三个 UOP，一个读内存，一个加，一个写内存。不同的 CPU 处理这些指令，比如如何将它们划分为不同的 UOP 的方式，是不一样的。</p>
<p>除了将复杂的 CISC-like 的指令分解为 RISC-lick 的 UOP 或者说 microoperations 之外，还有一种策略是融合一些指令。有两种融合的类型：</p>
<ol>
<li><p>Microfusion<br> 对同一个指令中的多个 UOP 进行 fuse。如下所示，访存操作和加法在 decode 阶段被 fuse 了。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Read the memory location [ESI] and add it to EAX</span><br><span class="line"># Two uops are fused into one at the decoding step.</span><br><span class="line">add eax, [esi]</span><br></pre></td></tr></table></figure></li>
<li><p>Macrofusion<br> 如下所示，一个代数计算和一个条件跳转指令被 fuse 为一个 compute-and-branch UOP 了。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Two uops from DEC and JNZ instructions are fused into one</span><br><span class="line">.loop:</span><br><span class="line">dec rdi</span><br><span class="line">jnz .loop</span><br></pre></td></tr></table></figure></li>
</ol>
<p>Both Micro- and Macrofusion save bandwidth in all stages of the pipeline from decoding to retirement. The fused operations share a single entry in the reorder buffer (ROB). The capacity of the ROB is increased when a fused uop uses only one entry。我想这就是为什么要 fuse 指令的原因，因为它们节约了 ROB 的空间。在执行的时候，这个表示两个操作的 ROB entry 会被两个 execution units 处理，被发送到两个不同的 execution ports，但最后作为一个 unit 被 retire。</p>
<p>Linux perf users can collect the number of issued, executed, and retired uops for their workload by running the following command:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ perf stat -e uops_issued.any,uops_executed.thread,uops_retired.all -- a.exe</span><br><span class="line">2856278 uops_issued.any</span><br><span class="line">2720241 uops_executed.thread</span><br><span class="line">2557884 uops_retired.all</span><br></pre></td></tr></table></figure>

<h2 id="Pipeline-Slot"><a href="#Pipeline-Slot" class="headerlink" title="Pipeline Slot"></a>Pipeline Slot</h2><p>A pipeline slot represents hardware resources needed to process one uop.</p>
<h2 id="Core-vs-Reference-Cycles"><a href="#Core-vs-Reference-Cycles" class="headerlink" title="Core vs. Reference Cycles"></a>Core vs. Reference Cycles</h2><p>Reference Cycles 是 CPU 计算 cycle 数量，仿佛没有 frequency scaling 一般。相当于不 tuebo，base frequency 下运行的 cycles。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ perf stat -e cycles,ref-cycles ./a.exe</span><br><span class="line">    43340884632 cycles # 3.97 GHz</span><br><span class="line">    37028245322 ref-cycles # 3.39 GHz</span><br><span class="line">    10,899462364 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p>The core clock cycle counter is very useful when testing which version of a piece of code is fastest because you can avoid the problem that the clock frequency goes up and down.</p>
<h2 id="Cache-miss"><a href="#Cache-miss" class="headerlink" title="Cache miss"></a>Cache miss</h2><h2 id="Mispredicted-branch"><a href="#Mispredicted-branch" class="headerlink" title="Mispredicted branch"></a>Mispredicted branch</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ perf stat -e branches,branch-misses -- a.exe</span><br><span class="line">358209 branches</span><br><span class="line">14026 branch-misses</span><br></pre></td></tr></table></figure>

<h1 id="Performance-Analysis-Approaches"><a href="#Performance-Analysis-Approaches" class="headerlink" title="Performance Analysis Approaches"></a>Performance Analysis Approaches</h1><h2 id="Code-Instrumentation"><a href="#Code-Instrumentation" class="headerlink" title="Code Instrumentation"></a>Code Instrumentation</h2><p>比如用 printf 调试，打印一个函数执行了多少次这样。这是 macro level 的，而不是 mirco level 的。<br>这个技术的主要用处是，能够快速定位到具体问题的模块。因为性能问题不仅和代码有关，也和数据有关。例如一个场景渲染比较慢，有可能是数据压缩问题，也有可能是场景元素过多。<br>当然，缺点就是只在 app 层级，到不了内核以及更下层。另外，调试代码需要重新编译，会降低性能，甚至改变现场。</p>
<p>Binary instrumentation 技术的特点：</p>
<ol>
<li>对二进制分析</li>
<li>提供 static 和 dynamic 两种模式<br> dynamic 模式可以动态开启，可以限制只对某些函数调试</li>
</ol>
<p>诸如 Intel Pin 的工具可以拦截某个事件，并且在之后插入代码。</p>
<ol>
<li>instruction count and function call counts.</li>
<li>intercepting function calls and execution of any instruction in an application.</li>
<li>allows “record and replay” the program region by capturing the memory and HW registers state at the beginning of the region.</li>
</ol>
<h2 id="Tracing"><a href="#Tracing" class="headerlink" title="Tracing"></a>Tracing</h2><p>strace 工具跟踪系统调用，可以被视作对内核的测量。Intel Processor Traces 工具跟踪 CPU 指令，可以被视作对 CPU 的测量。<br>Tracing is often used as the black-box approach, where a user cannot modify the code of the application, yet they want insight on what the program is doing behind the scenes。</p>
<p>Tracing 用来检查异常。例如一个系统十秒都不响应了，这个时候，Code Instrumentation 可能就不管用，但 tracing 可以去了解到底发生了什么。</p>
<h2 id="Workload-Characterization"><a href="#Workload-Characterization" class="headerlink" title="Workload Characterization"></a>Workload Characterization</h2><p>Workload characterization is a process of describing a workload by means of quantitative parameters and functions。</p>
<h3 id="Counting-Performance-Events"><a href="#Counting-Performance-Events" class="headerlink" title="Counting Performance Events"></a>Counting Performance Events</h3><p>用一个 Counter 记录在跑一个 workload 时，某个事件在一段时间内发生的次数。</p>
<h3 id="Manual-performance-counters-collection"><a href="#Manual-performance-counters-collection" class="headerlink" title="Manual performance counters collection"></a>Manual performance counters collection</h3><p>一般来说，不建议直接观察 PMC，而是使用 Intel Vtune Profiler 去看一个处理后的结果。</p>
<p>可以通过 perf list 查看可以访问的 PMC。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ perf list</span><br><span class="line">branches [Hardware event]</span><br><span class="line">branch-misses [Hardware event]</span><br><span class="line">bus-cycles [Hardware event]</span><br><span class="line">cache-misses [Hardware event]</span><br><span class="line">cycles [Hardware event]</span><br><span class="line">instructions [Hardware event]</span><br><span class="line">ref-cycles [Hardware event]</span><br></pre></td></tr></table></figure>

<p>对于没列出的，可以使用下面的来检查</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">perf stat -e cpu/event=0xc4,umask=0x0,name=BR_INST_RETIRED.ALL_BRANCHES/</span><br><span class="line">-- ./a.exe</span><br></pre></td></tr></table></figure>

<h3 id="Multiplexing-and-scaling-events"><a href="#Multiplexing-and-scaling-events" class="headerlink" title="Multiplexing and scaling events"></a>Multiplexing and scaling events</h3><p>考虑到有时候需要同时记录多个事件，但只有一个 counter。所以 PMU 会为每个 HW 线程提供四个 counter。但可能还是不够。<br>Top-Down Analysis Methodology (TMA) 需要一次执行过程中收集最多 100 个不同的 performance event。<br>这个时候，就引入了 multiplexing 技术，如下图所示。<br><img src="/img/patmc/5.19.png"></p>
<h2 id="Sampling"><a href="#Sampling" class="headerlink" title="Sampling"></a>Sampling</h2><p>人们常常用 profiling 这个词去指代 sampling，但其实 profiling 这个词包含的范围更广。</p>
<h3 id="User-Mode-And-Hardware-Event-based-Sampling"><a href="#User-Mode-And-Hardware-Event-based-Sampling" class="headerlink" title="User-Mode And Hardware Event-based Sampling"></a>User-Mode And Hardware Event-based Sampling</h3><p>User-mode sampling 是个 SW 方案，也就是在用户程序中 embed 一个库。这个库会为每个线程设置 OS timer，在 timer 超时的时候，程序会收到 SIGPROF 信号。<br>EBS 是一个 HW 方案，它使用 PMC 去触发中断。</p>
<p>SW 方案只能被用来发现热点。而 HW 方案还可以被用来采样 cache miss，TMA(section 6.1) 等。</p>
<p>SW 方案的 overhead 更大。HW 方案更准确，因为允许采样更多的数据。</p>
<h3 id="Finding-Hotspots"><a href="#Finding-Hotspots" class="headerlink" title="Finding Hotspots"></a>Finding Hotspots</h3><p>下面的一个技术使用了 counter overflow 技术。也就是当 counter 溢出的时候，触发 performance monitoring interrupt(PMI)。<br><img src="/img/patmc/5.25.png"></p>
<p>我们不一定要 sample CPU cycle，例如如果要检查程序中哪里出现了最多的 L3 cache miss，就可以 sample <code>MEM_LOAD_RETIRED.L3_MISS</code> 这个事件。</p>
<p>流程如下：</p>
<ol>
<li>配置 PMC 去计算某项指标，例如 cycle 数</li>
<li>在执行过程中，PMC 会递增</li>
<li>PMC 最终会 overflow，HW 会触发 PMI</li>
<li>Profile 工具会抓住中断，并使用配置了的 Interrupt Service Routine(ISR) 去处理这个事件<ul>
<li>禁止掉 counting</li>
<li>reset counter 到 N</li>
<li>继续 benchmark 过程</li>
</ul>
</li>
</ol>
<p>通过 N 的不同取值，可以决定采样的频率。</p>
<h3 id="Collecting-Call-Stacks"><a href="#Collecting-Call-Stacks" class="headerlink" title="Collecting Call Stacks"></a>Collecting Call Stacks</h3><p>常见情况是，最热点的函数是被多个 caller 调用的。这个时候就需要知道是 Control Flow Graph (CFG) 里面的哪一条路径导致的。想要去追踪 foo 的所有 caller 是很耗时的，但我们只是想最终那些导致 foo 变成 hotspot 的，或者说是想找到 CFG 中经过 foo 的最热的路径。</p>
<p>下面三种方法：</p>
<ol>
<li>Frame pointer<br> perf record –call-graph fp<br> 这需要二进制被以 -fnoomit-frame-pointer 形式编译。历史上，Frame pointer 也就是 BP 寄存器被用来 debug，是因为它允许 get the call stack without popping all the arguments from the stack(stack unwinding)。Frame pointer 可以直接告诉我们 return address。</li>
<li>DWARF debug info<br> perf record –call-graph dwarf<br> 这需要程序被按照 -g (-gline-tables-only) 形式编译。</li>
<li>Intel Last Branch Record (LBR)<br> perf record –call-graph lbr<br> 这种方式得到的 call graph 的深度不如前面两者。</li>
</ol>
<h3 id="Flame-graph"><a href="#Flame-graph" class="headerlink" title="Flame graph"></a>Flame graph</h3><p>相比上面提到的，一个更流行的办法是火焰图。</p>
<h2 id="Roofline-Performance-Model"><a href="#Roofline-Performance-Model" class="headerlink" title="Roofline Performance Model"></a>Roofline Performance Model</h2><p>这里的 roofline 指的是应用程序的性能不会超过机器本身的容量。每个函数或者每个循环都会被机器本身的计算或者内存容量所限制。</p>
<p>HW 有两方面限制：</p>
<ol>
<li>它可以算多快<br> FLOPS</li>
<li>它可以多快传输数据<br> GB/s</li>
</ol>
<p>一个程序的不同部分，会有不同的 performance characteristics。<br><img src="/img/patmc/5.24.png"></p>
<p>Arithmetic Intensity (AI) is a ratio between FLOPS and bytes and can be extracted for every loop in a program。不妨对下面的代码来算一下。在最内层循环有一个加法和一个乘法，所以是 2FLOPS。另外，还有三个读操作和一个写操作，所以传输了 <code>4 * 4 = 16</code> 字节。所以 AI 是 <code>2 / 16 = 0.125</code>。这作为图表的横轴。</p>
<p><img src="/img/patmc/l8.png"></p>
<p>一般来说，提高程序性能可以分为 vectorization、memory、threading 三个方面。Roofline methodology 可以帮助评估应用的特征。如下所示，在 roofline 图表上，我们可以画出单核、SIMD 单核和 SIMD 多核的性能。因此可以借助于图表来判断优化方向。AI 越高，说明越是 CPU bound 的，就越要考虑 CPU 方面的优化。Vectorization 和 threading 的操作一般能够让图表中的点上移，而 optimize memory access 的操作一般能够将点右移，也可能能将点上移。</p>
<p><img src="/img/patmc/5.25.png"></p>
<p>Roffline 分析可以进行前后的对比，如下所示，在执行完交换内外循环，以及 vectorize 后，性能发生了提高。<br><img src="/img/patmc/5.25.png"></p>
<h2 id="Static-Performance-Analysis"><a href="#Static-Performance-Analysis" class="headerlink" title="Static Performance Analysis"></a>Static Performance Analysis</h2><h2 id="Compiler-Optimization-Reports"><a href="#Compiler-Optimization-Reports" class="headerlink" title="Compiler Optimization Reports"></a>Compiler Optimization Reports</h2><h1 id="CPU-Features-For-Performance-Analysis"><a href="#CPU-Features-For-Performance-Analysis" class="headerlink" title="CPU Features For Performance Analysis"></a>CPU Features For Performance Analysis</h1><p>通常来说，profiling 能够快速发现应用程序的 hotspots。例如考虑 profile 一个函数，你觉得它应该是 cold 的，但你发现它实际花了很长时间并且被调用了很多次。所以你可以使用 cache 等技术来减少调用的次数，从而提高性能。</p>
<p>当主要的性能优化点都被处理后，就需要 CPU的支持来发现新的性能瓶颈了。所以在了解本章之前，需要先确保程序没有主要的性能问题。</p>
<p>现代 CPU 提供新的特性来辅助性能分析，这些特性可以用来发现 cache miss 或者 branch misprediction。这些措施包括：</p>
<ol>
<li>Top-Down Microarchitecture Analysis Methodology (TMA)<br> 特征化出 workload 的瓶颈，并且能够在源码中进行定位。</li>
<li>Last Branch Record (LBR)<br> 持续地记录最近的 branch outcomes。被用来记录 call stacks，识别 hot branch，计算 misprediction rates of individual branches。</li>
<li>Processor Event-Based Sampling (PEBS)</li>
<li>Intel Processor Traces (PT)<br> 能够回放程序的执行。</li>
</ol>
<h2 id="Top-Down-Microarchitecture-Analysis"><a href="#Top-Down-Microarchitecture-Analysis" class="headerlink" title="Top-Down Microarchitecture Analysis"></a>Top-Down Microarchitecture Analysis</h2><p><img src="/img/patmc/6.28.png"></p>
<h1 id="Part-2-的说明"><a href="#Part-2-的说明" class="headerlink" title="Part 2 的说明"></a>Part 2 的说明</h1><p>In part 2, we will take a look at how to use CPU monitoring features (see section 6) to find the places in the code which can be tuned for execution on a CPU. For performance-critical applications like large distributed cloud services, scientific HPC software, ‘AAA’ games, etc. it is very important to know how underlying HW works.</p>
<p>面对 performance-critical 负载时，一些经典算法未必有效。例如链表并不适合用来处理 flat 的数据。原因是需要逐节点动态分配，并且每个元素是零散分布在内存中的。</p>
<p>Some data structures, like binary trees, have natural linked-list-like representation, so it might be tempting to implement them in a pointer chasing manner. However, more efficient “flat” versions of those data structures exist, see boost::flat_map, boost::flat_set.</p>
<p>另一方面，即使算法是最好的，但它未必对某些特定的 case 是最好的。例如对有序数组使用二分查找是最优的，但他的 branch miss 很高，因为是 50-50 的失败率。因此对于短数组，常常是线性查找。</p>
<p>在讲解 CPU 微架构的优化前，先列出一些更高层级的优化方案：</p>
<ol>
<li>If a program is written using interpreted languages (python, javascript, etc.), rewrite its performance-critical portion in a language with less overhead.</li>
<li>Analyze the algorithms and data structures used in the program, see if you can find better ones.</li>
<li>Tune compiler options. Check that you use at least these three compiler flags: -O3 (enables machine-independent optimizations), -march (enables optimizations for particular CPU generation), -flto (enables inter-procedural optimizations).</li>
<li>If a problem is a highly parallelizable computation, make it threaded, or consider running<br>it on a GPU.</li>
<li>Use async IO to avoid blocking while waiting for IO operations.</li>
<li>Leverage using more RAM to reduce the amount of CPU and IO you have to use (memoization, look-up tables, caching of data, compression, etc.)</li>
</ol>
<p>此外，并不是所有的优化方式都对每个平台有效。例如 <a href="https://en.wikipedia.org/wiki/Loop_nest_optimization" target="_blank" rel="noopener">loop blocking</a> 对 memory hierarchy 很敏感，特别是 L2 和 L3 的大小。loop blocking 优化就是如果两层循环都比较大，那么可能内层循环中的元素会在一轮中被 evict 掉，从而导致外层循环在下轮中重新加载。通过重排循环，可以减少重新加载的次数。可以详细看 <a href="https://zhuanlan.zhihu.com/p/292539074" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/292539074</a> 的解读。</p>
<h2 id="Data-Driven-Optimizations"><a href="#Data-Driven-Optimizations" class="headerlink" title="Data-Driven Optimizations"></a>Data-Driven Optimizations</h2><p>Data-Driven 优化的一个经典案例是 Structure-Of-Array to Array-Of-Structures (SOA-to-AOS)。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line"><span class="keyword">int</span> a[N];</span><br><span class="line"><span class="keyword">int</span> b[N];</span><br><span class="line"><span class="keyword">int</span> c[N];</span><br><span class="line"><span class="comment">// many other fields</span></span><br><span class="line">&#125;;</span><br><span class="line">&lt;=&gt;</span><br><span class="line">struct S &#123;</span><br><span class="line"><span class="keyword">int</span> a;</span><br><span class="line"><span class="keyword">int</span> b;</span><br><span class="line"><span class="keyword">int</span> c;</span><br><span class="line"><span class="comment">// many other fields</span></span><br><span class="line">&#125;;</span><br><span class="line">S s[N];</span><br></pre></td></tr></table></figure>

<p>如何选择取决于数据的读取模式，我理解类似于行存和列存的区别：</p>
<ol>
<li>If the program iterates over the data structure and only accesses field b, then SOA is better because all memory accesses will be sequential (spatial locality). </li>
<li>If the program iterates over the data structure and does excessive operations on all the fields of the object (i.e. a, b, c), then AOS is better because it’s likely that all the members of the structure will reside in the same cache line. It will additionally better utilize the memory bandwidth since fewer cache line reads will be required.</li>
</ol>
<p>Data-Driven 优化的另一个案例是 Small Size optimization。也就是提前分配一些内存，用来减少后续的动态内存分配开销。</p>
<h1 id="CPU-Front-End-Optimizations"><a href="#CPU-Front-End-Optimizations" class="headerlink" title="CPU Front-End Optimizations"></a>CPU Front-End Optimizations</h1><p>CPU Front-End (FE) component is discussed in section 3.8.1. Most of the time, inefficiencies in CPU FE can be described as a situation when Back-End is waiting for instructions to execute, but FE is not able to provide them. As a result, CPU cycles are wasted without doing any actual useful work. Because modern processors are 4-wide (i.e., they can provide four uops every cycle), there can be a situation when not all four available slots are filled. This can be a source of inefficient execution as well. In fact, IDQ_UOPS_NOT_DELIVERED performance event is counting how many available slots were not utilized due to a front-end stall. TMA uses this performance counter value to calculate its “Front-End Bound” metric.</p>
<h2 id="Machine-code-layout"><a href="#Machine-code-layout" class="headerlink" title="Machine code layout"></a>Machine code layout</h2><p>Assembly instructions will be encoded and laid out in memory consequently. This is what is called machine code layout.</p>
<h2 id="Basic-Block"><a href="#Basic-Block" class="headerlink" title="Basic Block"></a>Basic Block</h2><p>A basic block is a sequence of instructions with a single entry and single exit.<br>一个 basic block 中的代码会并且只会被执行一次，所以可以减少 control flow graph analysis and transformations。</p>
<h2 id="Basic-block-placement"><a href="#Basic-block-placement" class="headerlink" title="Basic block placement"></a>Basic block placement</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// hot path</span></span><br><span class="line"><span class="keyword">if</span> (cond)</span><br><span class="line">    coldFunc();</span><br><span class="line"><span class="comment">// hot path again</span></span><br></pre></td></tr></table></figure>

<p><img src="/img/patmc/7.41.png"></p>
<p>原因：</p>
<ol>
<li>Not taken branches are fundamentally cheaper than taken.<br> In the general case, modern Intel CPUs can execute two untaken branches per cycle but only one taken branch every two cycles.</li>
<li>右边这幅图能够更好地利用 instruction cache 和 uop cache（之前提到的 DSB）。这是因为如果把所有的 hot code 连起来，就没有 cache line fragmentation。L1I Cache 中的所有的 Cache line 都被 hot code 使用。这点对 uop cache 也是一样的，因为它的 cache 也是基于下层的 code layout。</li>
<li>如果 taken branch 了，CPU 的 fetch 部分也会受影响。因为它也是 fetch 连续的 16 bytes 指令的。</li>
</ol>
<p>通过指定 likely 和 unlikely 可以帮助编译器优化。如果一个分支是 unlikely 的，编译器可能选择不 inline，从而减少大小。likely 还可以在 switch 中使用。</p>
<h2 id="Basic-block-alignment"><a href="#Basic-block-alignment" class="headerlink" title="Basic block alignment"></a>Basic block alignment</h2><p>Skylake 的 instruction cache line 的大小是 64 bytes，下面的代码可能被编译得跨越两个 cache line。这对 CPU 前端的性能会有影响，特别是像这种小循环。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">benchmark_func</span><span class="params">(<span class="keyword">int</span>* a)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; ++i)</span><br><span class="line">        a[i] += <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>下面的优化通过添加 nop 指令让整个循环都在一个缓存行里面。为什么这能提高性能比较复杂，因此就不解释了。<br><img src="/img/patmc/7.42.png"></p>
<p>By default, the LLVM compiler recognizes loops and aligns them at 16B boundaries，就和上面图中未优化的情况一样。通过指定 <code>-mllvm -align-all-blocks</code> 可以变成优化后的样子。但是要慎重做这样的处理，因为增加 NOP 指令会影响执行时间。尽管 NOP 不执行，但是他同样需要被 fetch、解码、retire。所以需要额外地耗费在 FE 中的空间。</p>
<h2 id="Function-splitting"><a href="#Function-splitting" class="headerlink" title="Function splitting"></a>Function splitting</h2><p>目的是将 hot 部分和 cold 部分分离出来。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">bool</span> cond1, <span class="keyword">bool</span> cond2)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// hot path</span></span><br><span class="line">    <span class="keyword">if</span> (cond1) &#123;</span><br><span class="line">        <span class="comment">// large amount of cold code (1)</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// hot path</span></span><br><span class="line">    <span class="keyword">if</span> (cond2) &#123;</span><br><span class="line">        <span class="comment">// large amount of cold code (2)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>分离后</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">bool</span> cond1, <span class="keyword">bool</span> cond2)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// hot path</span></span><br><span class="line">    <span class="keyword">if</span> (cond1)</span><br><span class="line">        cold1();</span><br><span class="line">    <span class="comment">// hot path</span></span><br><span class="line">    <span class="keyword">if</span> (cond2)</span><br><span class="line">        cold2();</span><br><span class="line">&#125;</span><br><span class="line">void cold1() __attribute__((noinline)) &#123; // cold code (1) &#125;</span><br><span class="line">void cold2() __attribute__((noinline)) &#123; // cold code (2) &#125;</span><br></pre></td></tr></table></figure>

<p>如下图所示，因为在 hot path 中只保留了 CALL，所以下一条指令很有可能在同一个 cache line 里面。这也说明了，对冷代码而言，应该避免它被 inline。<br><img src="/img/patmc/7.43.png"></p>
<p>特别地，冷函数可以被放在 .text.old 中，从而避免在运行时加载。</p>
<h2 id="Function-grouping"><a href="#Function-grouping" class="headerlink" title="Function grouping"></a>Function grouping</h2><p>Figure 44 gives a graphical representation of grouping foo, bar, and zoo. The default layout (see fig. 44a) requires four cache line reads, while in the improved version (see fig. 44b), code of foo, bar and zoo fits in only three cache lines. Additionally, when we call zoo from foo, the beginning of zoo is already in the I-cache since we fetched that cache line already.</p>
<p><img src="/img/patmc/7.44.png"></p>
<p>和之前一样，function grouping 能提高 I-Cache 和 DSB-cache 的效率。</p>
<p>使用 ld.gold 链接器来指定顺序：</p>
<ol>
<li><code>-ffunction-sections</code> flag, which will put each function into a separate section.</li>
<li><code>--section-ordering-file=order.txt</code> option should be used to provide a file with a sorted list of function names that reflects the desired final layout.</li>
</ol>
<p>一个叫 HFSort 的工具可以帮助 group function。</p>
<h2 id="Profile-Guided-Optimizations"><a href="#Profile-Guided-Optimizations" class="headerlink" title="Profile Guided Optimizations"></a>Profile Guided Optimizations</h2><h2 id="Optimizing-for-ITLB"><a href="#Optimizing-for-ITLB" class="headerlink" title="Optimizing for ITLB"></a>Optimizing for ITLB</h2><p>Virtual-to-physical address translation of memory address 也影响了 CPU FE 的效率。通常，这是被 TLB 来处理，TLB 会缓存最近的地址。When TLB cannot serve translation request, a time-consuming page walk of the kernel page table takes place to calculate the correct physical address for each referenced virtual address.</p>
<p>如果 TMA 指示了 high ITLB overhead，那么下面的内容就很重要：</p>
<ol>
<li>将一些 performance-critical code 中的部分映射到较大的 page 中。</li>
<li>使用一些标准的 I-cache performance 优化办法，例如 reorder 函数让 hot 函数更为 collocated。或者通过 LTO 或者 IPO 技术减少 hot region 的大小。或者使用 profile guided optimization。或者使用激进的 inline 技术。</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="/img/patmc/t6.png"></p>
<h1 id="CPU-Back-End-Optimizations"><a href="#CPU-Back-End-Optimizations" class="headerlink" title="CPU Back-End Optimizations"></a>CPU Back-End Optimizations</h1><p>Most of the time, inefficiencies in CPU BE can be described as a situation when FE has fetched and decoded instructions, but BE is overloaded and can’t handle new instructions. Technically speaking, it is a situation when FE cannot deliver uops due to a lack of required resources for accepting new uops in the Backend. An example of it may be a stall due to data-cache miss or a stall due to the divider unit being overloaded.<br>I want to emphasize to the reader that it’s recommended to start looking into optimizing code for CPU BE only when TMA points to a high “Back-End Bound” metric. TMA further divides the Backend Bound metric into two main categories: Memory Bound and Core Bound, which we will discuss next.</p>
<h2 id="Memory-Bound"><a href="#Memory-Bound" class="headerlink" title="Memory Bound"></a>Memory Bound</h2><p>如下图所示，截止 2010 年，CPU 的提升比内存的提升要快很多。【Q】最近还是这样么？<br><img src="/img/patmc/8.45.png"></p>
<p>通过 TMA，Memory Bound estimates a fraction of slots where the CPU pipeline is likely stalled due to demand load or store instructions。</p>
<h3 id="Cache-Friendly-Data-Structures"><a href="#Cache-Friendly-Data-Structures" class="headerlink" title="Cache-Friendly Data Structures"></a>Cache-Friendly Data Structures</h3><p>A variable can be fetched from the cache in just a few clock cycles, but it can take more than a hundred clock cycles to fetch the variable from RAM memory if it is not in the cache.<br>下面一张图展示了各个 CPU 操作的耗时。<br><img src="/img/patmc/ext1.png"></p>
<p>Cache-friendly code 的关键是 temporal 和 spatial locality。</p>
<h4 id="Access-data-sequentially"><a href="#Access-data-sequentially" class="headerlink" title="Access data sequentially"></a>Access data sequentially</h4><p>让 HW Prefetcher 感知到我们在顺序访问，从而提前取出下一个 chunk 的数据。<br>下面代码之所以是 cache friendly 的，是因为它的访问模式和它存储的 layout 是一致的。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (row = <span class="number">0</span>; row &lt; NUMROWS; row++)</span><br><span class="line">    <span class="keyword">for</span> (column = <span class="number">0</span>; column &lt; NUMCOLUMNS; column++)</span><br><span class="line">        matrix[row][column] = row + column;</span><br></pre></td></tr></table></figure>

<p>又比如，传统的二分查找算法并没有很好的空间局部性，因为它会测试彼此之间相距很远的元素，这些元素可能在不同的 cache line 上。一个解决方案是使用 <a href="https://en.algorithmica.org/hpc/data-structures/binary-search/" target="_blank" rel="noopener">Eytzinger layout</a>。我理解就是存在一个类似二叉堆的结构中。</p>
<h4 id="Use-appropriate-containers"><a href="#Use-appropriate-containers" class="headerlink" title="Use appropriate containers"></a>Use appropriate containers</h4><p>或者说是在 array 中直接存对象，还是存指针。如果排序，适合存指针。如果仅仅是线性遍历，适合存对象。</p>
<h4 id="Packing-the-data"><a href="#Packing-the-data" class="headerlink" title="Packing the data"></a>Packing the data</h4><ol>
<li>位域</li>
<li>重新排列 field 以减少 padding 和 aligning 带来的内存浪费 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S1</span> &#123;</span></span><br><span class="line">    <span class="keyword">bool</span> b;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">short</span> s;</span><br><span class="line">&#125;; <span class="comment">// S1 is sizeof(int) * 3</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S2</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">short</span> s;</span><br><span class="line">    <span class="keyword">bool</span> b;</span><br><span class="line">&#125;; <span class="comment">// S2 is sizeof(int) * 2</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="Aligning-and-padding"><a href="#Aligning-and-padding" class="headerlink" title="Aligning and padding"></a>Aligning and padding</h4><p>比如，一个 16 bytes 的对象可能占用两个 cache line。读取这样的对象需要读两次 cache line。</p>
<p>A variable is accessed most efficiently if it is stored at a memory address, which is divisible by the size of the variable.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Make an aligned array</span></span><br><span class="line">alignas(<span class="number">16</span>) <span class="keyword">int16_t</span> a[N];</span><br><span class="line"><span class="comment">// Objects of struct S are aligned at cache line boundaries</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CACHELINE_ALIGN alignas(64)</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">CACHELINE_ALIGN</span> <span class="title">S</span> &#123;</span></span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>Padding 技术还可以备用来解决 cache contention 和 false sharing 问题。</p>
<p>For example, false sharing issues might occur in multithreaded applications when two threads, A and B, access different fields of the same structure. An example of code when such a situation might happen is shown on Listing 24. Because a and b members of struct S could potentially occupy the same cache line, cache coherency issues might significantly slow down the program.</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> a; <span class="comment">// written by thread A</span></span><br><span class="line">    <span class="keyword">int</span> b; <span class="comment">// written by thread B</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>通过 padding 来解决伪共享</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CACHELINE_ALIGN alignas(64)</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> a; <span class="comment">// written by thread A</span></span><br><span class="line">    CACHELINE_ALIGN <span class="keyword">int</span> b; <span class="comment">// written by thread B</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>When it comes to dynamic allocations via malloc, it is guaranteed that the returned memory address satisfies the target platform’s minimum alignment requirements. Some applications might benefit from a stricter alignment. For example, dynamically allocating 16 bytes with a 64 bytes alignment instead of the default 16 bytes alignment. In order to leverage this, users of POSIX systems can use memalign API.</p>
<h4 id="Dynamic-memory-allocation"><a href="#Dynamic-memory-allocation" class="headerlink" title="Dynamic memory allocation"></a>Dynamic memory allocation</h4><ol>
<li>使用诸如 jemalloc 或者 tcmalloc 的实现</li>
<li>使用 custom allocator<br> 例如 arena allocator。这样 allocator 不需要在每次分配的时候都 sys call。<br> 另外，也更灵活，支持不同的策略。比如冷数据一个 arena，热数据一个 arena。将热数据放一起可以有机会共享 cache line。从而提高内存贷款和 spatial locality。同时还可以提高 TLB 利用率，因为 hot data 会占用更少的 page。<br> 此外，还是 thread-aware 的，可以实现 thread local 的分配策略，从而避免线程间的同步。</li>
</ol>
<h4 id="Tune-the-code-for-memory-hierarchy"><a href="#Tune-the-code-for-memory-hierarchy" class="headerlink" title="Tune the code for memory hierarchy"></a>Tune the code for memory hierarchy</h4><p>这里还是 loop blocking 的例子。也就是将 matrix 切成多个小块，让每一块能够被装在 L2 cache 里面。</p>
<h3 id="Explicit-Memory-Prefetching"><a href="#Explicit-Memory-Prefetching" class="headerlink" title="Explicit Memory Prefetching"></a>Explicit Memory Prefetching</h3><p>如下代码所示，如果 calcNextIndex 返回的是很随机的数字，那么 arr[j] 会频繁 cache miss。如果 arr 很大，那么 HW prefetcher 就不能去识别 pattern，然后 prefetch。<br>因为在计算 j 和访问 arr[j] 之间有不少操作，所以可以借助 <code>__builtin_prefetch</code> 来 prefetch。这也是要点，一定要提前足够的时间。但也不能提前太多，从而污染 cache。在后面的 6.2.5 节中会介绍如何选择。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">    <span class="keyword">int</span> j = calcNextIndex();</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    doSomeExtensiveComputation();</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    x = arr[j]; <span class="comment">// this load misses in L3 cache a lot</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>一般比较通用的是提前获取下一个 iter 的数据</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">    <span class="keyword">int</span> j = calcNextIndex();</span><br><span class="line">    __builtin_prefetch(a + j, <span class="number">0</span>, <span class="number">1</span>); <span class="comment">// well before the load</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    doSomeExtensiveComputation();</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    x = arr[j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>需要注意，Explicit Memory Prefetching 不是 portable 的。可能在别的平台上反而会让性能变差。Consider a situation when we want to insert a prefetch instruction into the piece of code that has average IPC=2, and every DRAM access takes 100 cycles. To have the best effect, we would need to insert prefetching instruction 200 instructions before the load. It is not always possible, especially if the load address is computed right before the load itself. The pointer chasing problem can be a good example when explicit prefetching is helpless.</p>
<p>另外，prefetch 指令会加重 CPU 前端的开销。</p>
<h3 id="Optimizing-For-DTLB"><a href="#Optimizing-For-DTLB" class="headerlink" title="Optimizing For DTLB"></a>Optimizing For DTLB</h3><p>如前介绍，TLB is a fast but finite per-core cache for virtual-to-physical address translations of memory addresses. 没有它，每次内存访问都需要去遍历内核的 page table，然后计算出正确的 physical address。</p>
<p>TLB 由 L1 ITLB(instructions)、L1 DTLB(data) 和 L2 STLB(shared by data and instructions) 组成。L1 ITLB 的 cache miss 的惩罚很小，通常能够被 OOO 执行掩盖掉。L2 STLB 的 cache miss 就会导致遍历内核的 page table 了。这个 penalty 是可被观测的，因为这段时间 CPU 是 stall 的。假设 Linux 的默认 page size 是 4KB，L1 TLB 只能够存几百个 entry，覆盖大约 1MB 的地址空间。L2 STLB 覆盖大概一千多个。</p>
<p>一种减少 ITLB cache miss 的方案是使用更大的 page size。TLB 也支持使用 2MB 和 1GB 的 page。</p>
<p>Large memory applications such as relational database systems (e.g., MySQL, PostgreSQL, Oracle, etc.) and Java applications configured with large heap regions frequently benefit from using large pages.</p>
<p>On Linux OS, there are two ways of using large pages in an application: Explicit and Transparent Huge Pages.</p>
<h4 id="Explicit-Hugepages"><a href="#Explicit-Hugepages" class="headerlink" title="Explicit Hugepages"></a>Explicit Hugepages</h4><p>用户可以通过 mmap 等指令去访问。可以通过 <code>cat /proc/meminfo</code> 并检查 <code>HugePages_Total</code> 来检查相关配置。</p>
<p>Huge page 可以在系统启动，或者运行的时候被保留。在启动期间保留的成功率更高，因为此时系统的内存空间没有被显著碎片化(fragmented)。</p>
<p>可以通过 libhugetlbfs 来 override 掉 malloc 调用。只需要调整环境变量酒席了。</p>
<ol>
<li>mmap using the MAP_HUGETLB flag<br> <a href="https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/map_hugetlb.c" target="_blank" rel="noopener">https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/map_hugetlb.c</a></li>
<li>mmap using a file from a mounted hugetlbfs filesystem<br> <a href="https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/hugepage-mmap.c" target="_blank" rel="noopener">https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/hugepage-mmap.c</a></li>
<li>shmget using the SHM_HUGETLB flag<br> <a href="https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/hugepage-shm.c" target="_blank" rel="noopener">https://elixir.bootlin.com/linux/latest/source/tools/testing/selftests/vm/hugepage-shm.c</a></li>
</ol>
<h4 id="Transparent-Hugepages"><a href="#Transparent-Hugepages" class="headerlink" title="Transparent Hugepages"></a>Transparent Hugepages</h4><p>Linux also offers Transparent Hugepage Support(THP)。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">always [madvise] never</span><br></pre></td></tr></table></figure>

<p>always 表示 system wide，madvise 表示 per process。</p>
<h4 id="Explicit-vs-Transparent-Hugepages"><a href="#Explicit-vs-Transparent-Hugepages" class="headerlink" title="Explicit vs. Transparent Hugepages"></a>Explicit vs. Transparent Hugepages</h4><ol>
<li>Background maintenance of transparent huge pages incurs non-deterministic latency overhead from the kernel as it manages the inevitable fragmentation and swapping issues. EHP is not subject to memory fragmentation and cannot be swapped to the disk.</li>
<li>EHP is available for use on all segments of an application, including text segments (i.e., benefits both DTLB and ITLB), while THP is only available for dynamically allocated memory regions.</li>
</ol>
<h2 id="Core-Bound"><a href="#Core-Bound" class="headerlink" title="Core Bound"></a>Core Bound</h2><p>也就是在 OOO 执行过程中所有不是因为内存原因造成的 stall。包含：</p>
<ol>
<li>Shortage in hardware compute resources<br> 比如除法和平方根计算被 Divider Unit 处理，耗时比较长。如果这方面的操作比较多，那么就会造成 stall。</li>
<li>Dependencies between software’s instructions</li>
</ol>
<h3 id="Inlining-Functions"><a href="#Inlining-Functions" class="headerlink" title="Inlining Functions"></a>Inlining Functions</h3><p>它不仅能够去掉调用函数的开销，同时也让其他优化变为可能。因为此时编译期能看到更多的代码。<br>对 LLVM 编译期而言，基于 computing cost 和 a threshold for each function call(callsite) 来计算。如果 cost 比 threshold 更低，就会 inline。</p>
<p>threshold 的选取通常是固定的，一般来说有一些启发式的方法：</p>
<ol>
<li>小函数基本总是会被 inline</li>
<li>只有一个 callsite 的函数会被倾向于 inline</li>
<li>大函数通常不会 inline，因为它们让 caller 变大</li>
</ol>
<p>有些不能 inline 的情况：</p>
<ol>
<li>递归函数不能 inline</li>
<li>Function that is referred to through a pointer can be inlined in place of a direct call but has to stay in the binary, i.e., cannot be fully inlined and eliminated. The same is true for functions with external linkage.</li>
</ol>
<p>One way to find potential candidates for inlining in a program is by looking at the profiling data, and in particular, how hot is the prologue and the epilogue of the function. 下面的 demo 中，这个函数的 profile 中体现了 prologue 和 epilogue 花费了大概 50% 的时间。这<strong>可能</strong>说明了如果我们 inline 这个函数，就能减少 prologue 和 epilogue 的开销。但这不是绝对的，因为 inline 会导致一系列变化，所以很难预测结果。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Overhead | Source code &amp; Disassembly</span><br><span class="line">(%) | of function `foo`</span><br><span class="line">--------------------------------------------</span><br><span class="line">3.77 : 418be0: push r15 # prologue</span><br><span class="line">4.62 : 418be2: mov r15d,0x64</span><br><span class="line">2.14 : 418be8: push r14</span><br><span class="line">1.34 : 418bea: mov r14,rsi</span><br><span class="line">3.43 : 418bed: push r13</span><br><span class="line">3.08 : 418bef: mov r13,rdi</span><br><span class="line">1.24 : 418bf2: push r12</span><br><span class="line">1.14 : 418bf4: mov r12,rcx</span><br><span class="line">3.08 : 418bf7: push rbp</span><br><span class="line">3.43 : 418bf8: mov rbp,rdx</span><br><span class="line">1.94 : 418bfb: push rbx</span><br><span class="line">0.50 : 418bfc: sub rsp,0x8</span><br><span class="line">...</span><br><span class="line"># # function body</span><br><span class="line">...</span><br><span class="line">4.17 : 418d43: add rsp,0x8 # epilogue</span><br><span class="line">3.67 : 418d47: pop rbx</span><br><span class="line">0.35 : 418d48: pop rbp</span><br><span class="line">0.94 : 418d49: pop r12</span><br><span class="line">4.72 : 418d4b: pop r13</span><br><span class="line">4.12 : 418d4d: pop r14</span><br><span class="line">0.00 : 418d4f: pop r15</span><br><span class="line">1.59 : 418d51: ret</span><br></pre></td></tr></table></figure>

<h3 id="Loop-Optimizations"><a href="#Loop-Optimizations" class="headerlink" title="Loop Optimizations"></a>Loop Optimizations</h3><p>通常，循环的性能被下面几点限制：</p>
<ol>
<li>memory lantency</li>
<li>memory bandwidth</li>
<li>机器的 compute capability</li>
</ol>
<p>Roofline Perfoemance Model 是评估 HW 理论最大值和不同的 loop 实际之间的方法。Top-Down Microarchitecture Analusis 是另外一个瓶颈相关的信息来源。</p>
<p>这一节中，首先讨论 low-level 的优化，也就是将代码在一个 loop 中移动。这样的优化方式让循环内的计算更有效率。然后是 high-level 的优化，会 restructure loops，通常会影响多个 loop。第二种优化的目的主要是提高 memory access。eliminating memory bandwidth 和 memory lantency 问题。</p>
<h4 id="Low-level-optimizations"><a href="#Low-level-optimizations" class="headerlink" title="Low-level optimizations"></a>Low-level optimizations</h4><p>下面这些优化通常能够提高具有 high arithmetic intensity 的 loop 的性能，比如循环是 CPU-compute-bound 的。大部分情况下，编译器能够自己做相关优化，少部分情况下，需要人工帮助。</p>
<h5 id="Loop-Invariant-Code-Motion-LICM"><a href="#Loop-Invariant-Code-Motion-LICM" class="headerlink" title="Loop Invariant Code Motion (LICM)"></a>Loop Invariant Code Motion (LICM)</h5><p>将循环中的不变量移出循环。<br>什么是循环中的不变量呢？ Expressions evaluated in a loop that never change are called loop invariants.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0; i &lt; N; ++i)</span><br><span class="line">    for (int j = 0; j &lt; N; ++j)</span><br><span class="line">        a[j] = b[j] * c[i]; </span><br><span class="line"></span><br><span class="line">==&gt;</span><br><span class="line"></span><br><span class="line">for (int i = 0; i &lt; N; ++i) &#123;</span><br><span class="line">    auto temp = c[i];</span><br><span class="line">    for (int j = 0; j &lt; N; ++j)</span><br><span class="line">        a[j] = b[j] * temp;</span><br></pre></td></tr></table></figure>

<h5 id="Loop-Unrolling"><a href="#Loop-Unrolling" class="headerlink" title="Loop Unrolling"></a>Loop Unrolling</h5><p>循环的 induction variable，也就是 for i 的那个 i，每个 iteration 去修改它的代价是比较大的。所以可以选择 unroll 一个循环。</p>
<p>下面的例子中，unroll the loop by a factor of 2. 从而减少了 compare 和 branch 指令的开销到原来的一半。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0; i &lt; N; ++i)</span><br><span class="line">    a[i] = b[i] * c[i];</span><br><span class="line"></span><br><span class="line">==&gt;</span><br><span class="line"></span><br><span class="line">for (int i = 0; i &lt; N; i+=2) &#123;</span><br><span class="line">    a[i] = b[i] * c[i];</span><br><span class="line">    a[i+1] = b[i+1] * c[i+1];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>作者建议不要手工展开循环：</p>
<ol>
<li>编译器很擅长做这个，并且做得很好</li>
<li>处理器有一个 “embedded unroller”，thanks to their OOO speculative execution engine<br> 当处理器正等待第一个 iteration 的负载完成时，它可能预先开始执行第二个 iteration 的负载了。This spans to multiple iterations ahead, effectively unrolling the loop in the instruction Reorder Buffer (ROB).</li>
</ol>
<h5 id="Loop-Strength-Reduction-LSR"><a href="#Loop-Strength-Reduction-LSR" class="headerlink" title="Loop Strength Reduction (LSR)"></a>Loop Strength Reduction (LSR)</h5><p>将开销比较大的操作换为开销更小的操作。通常和 induction variable 上的计算有关。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0; i &lt; N; ++i)</span><br><span class="line">    a[i] = b[i * 10] * c[i];</span><br><span class="line"></span><br><span class="line">==&gt;</span><br><span class="line"></span><br><span class="line">int j = 0;</span><br><span class="line">for (int i = 0; i &lt; N; ++i) &#123;</span><br><span class="line">    a[i] = b[j] * c[i];</span><br><span class="line">    j += 10;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="Loop-Unswitching"><a href="#Loop-Unswitching" class="headerlink" title="Loop Unswitching"></a>Loop Unswitching</h5><p>这个很简单，尝试能不能把 loop 中的 branch 提出来，分成两个 loop</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">for (i = 0; i &lt; N; i++) &#123;</span><br><span class="line">    a[i] += b[i];</span><br><span class="line">    if (c)</span><br><span class="line">        b[i] = 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if (c)</span><br><span class="line">    for (i = 0; i &lt; N; i++) &#123;</span><br><span class="line">        a[i] += b[i];</span><br><span class="line">        b[i] = 0;</span><br><span class="line">    &#125;</span><br><span class="line">else</span><br><span class="line">    for (i = 0; i &lt; N; i++) &#123;</span><br><span class="line">        a[i] += b[i];</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h4 id="High-level-optimizations"><a href="#High-level-optimizations" class="headerlink" title="High-level optimizations"></a>High-level optimizations</h4><p>下面的一些变换，从编译器的角度比较难合法地或者自动地进行。所以很多时候可能需要手动做。</p>
<h5 id="Loop-Interchange"><a href="#Loop-Interchange" class="headerlink" title="Loop Interchange"></a>Loop Interchange</h5><p>交换多层循环的 order。<br>目的是 perform sequential memory accesses to the elements of a multi-dimensional array。<br>如下所示，在一个按行存储的数组中，让 i 到内层循环的空间局部性更好。</p>
<p><img src="/img/patmc/l32.png"></p>
<h5 id="Loop-Blocking-Tiling"><a href="#Loop-Blocking-Tiling" class="headerlink" title="Loop Blocking (Tiling)"></a>Loop Blocking (Tiling)</h5><h5 id="Loop-Fusion-and-Distribution-Fission"><a href="#Loop-Fusion-and-Distribution-Fission" class="headerlink" title="Loop Fusion and Distribution (Fission)"></a>Loop Fusion and Distribution (Fission)</h5><p>Loop fusion 可以用来：</p>
<ol>
<li>减少 loop overhead，因为它会复用相同的 induction variable</li>
<li>可以提高 memory access 的 temporal locality<br> 如下代码中，如果 x 和 y 都位于同一个缓存行上面，那么将两个 loop fuse 在一起能够避免加载同一个缓存行两次。<br> 这样就能减少 cache footprint，并且提高 memory bandwidth utilization。</li>
</ol>
<p><img src="/img/patmc/l34.png"></p>
<p>相反地有 Loop Distribution 即 Loop Fission。其目的是：</p>
<ol>
<li>可以先在一个循环中 pre-filter、sort、reorg 数据</li>
<li>减少一个 iteration 中需要访问的数据，从而提高 memory access 的 temporal locality。这对具有较高 cache contention 的场景，也就是大 loop 中会比较有用</li>
<li>减少对寄存器的压力，同样是因为一个 iteration 中会执行更少的操作了</li>
<li>通常还可能提升 CPU FE 的性能，因为 cache utilization 会更好</li>
<li>编译期能够更好地优化小循环</li>
</ol>
<h4 id="Discovering-loop-optimization-opportunities"><a href="#Discovering-loop-optimization-opportunities" class="headerlink" title="Discovering loop optimization opportunities"></a>Discovering loop optimization opportunities</h4><p>如下所示，编译器不能把 strlen 移出循环体。这是因为 a 和 b 两个数组可能是 overlap 的。所以，需要通过 restrict 关键词来显式声明这两段内存不会 overlap。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">char</span>* a, <span class="keyword">char</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="built_in">strlen</span>(a); ++i)</span><br><span class="line">        b[i] = (a[i] == <span class="string">'x'</span>) ? <span class="string">'y'</span> : <span class="string">'n'</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在一些时候，编译期可以通过 compiler optimization remarks (sec 5.7) 告诉我们失败了的优化。但对于上面的情况，Clang 10 和 GCC 10 目前还都不行。目前只能通过反编译出来的代码才能看出来。</p>
<p>有一些指令可以配置编译器的优化行为，例如 <code>#pragma unroll(8)</code>。</p>
<h4 id="Use-Loop-Optimization-Frameworks"><a href="#Use-Loop-Optimization-Frameworks" class="headerlink" title="Use Loop Optimization Frameworks"></a>Use Loop Optimization Frameworks</h4><p>目前有一些框架可以检测 loop transformation 的合法性了。例如 polyhedral 框架，polyhedral 的意思是多面体。LLVM 系列也有自己的 polyheral 框架，即 Polly。LLVM 默认不启用。对于 GEMM 内核，Polly 能提供 20 倍左右的提速。</p>
<h3 id="Vectorization"><a href="#Vectorization" class="headerlink" title="Vectorization"></a>Vectorization</h3><p>大部分情况下，Vectorization 能够被编译器发现，然后自动发生。<br>一般来说，在编译器中完成三种 Vectorization：</p>
<ol>
<li>inner loop vectorization</li>
<li>outer loop vectorization</li>
<li>SLP (Superword-Level Parallelism) vectorization</li>
</ol>
<p>第一种最常见。</p>
<h4 id="Compiler-Autovectorization"><a href="#Compiler-Autovectorization" class="headerlink" title="Compiler Autovectorization"></a>Compiler Autovectorization</h4><p>阻止 Autovectorization 的情况：</p>
<ol>
<li>unsigned loop-indices 溢出</li>
<li>两个指针可能指向重叠的内存区间</li>
<li>处理器本身不支持比如 predicated (bitmask-controlled) load and store operation</li>
<li>vector-wide format conversion between signed integers to doubles because the result operates on vector registers of different sizes</li>
</ol>
<p>所以一般分为三步：</p>
<ol>
<li>Legality-check<br> 检查 the loop progresses linearly。<br> 确保 the memory and arithmetic operations in the loop can be widened into consecutive operations。<br> That the control flow of the loop is uniform across all lanes and that the memory access patterns are uniform。没看懂是在说什么。<br> 确保不会访问和修改不应该的内存。<br> analyze the possible range of pointers, and if it has some missing information, it has to assume that the transformation is illegal。看不懂。</li>
<li>Profitability-check<br> It needs to take into account the added instructions that shuffle data into registers, predict register pressure, and estimate the cost of the loop guards that ensure that preconditions that allow vectorizations are met. 我觉得作者这样说就是在让人看不懂。</li>
<li>Transformation</li>
</ol>
<h4 id="Discovering-vectorization-opportunities"><a href="#Discovering-vectorization-opportunities" class="headerlink" title="Discovering vectorization opportunities"></a>Discovering vectorization opportunities</h4><p>检查 compiler vectorization remarks 可以发现编译期进行了什么优化，包含是否 vectorized 了，vectorization factor(VF) 是多少。</p>
<h4 id="Vectorization-is-illegal"><a href="#Vectorization-is-illegal" class="headerlink" title="Vectorization is illegal"></a>Vectorization is illegal</h4><p>下面的函数不是 vectorizable 的。因为是 read-after-write dependence.</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">vectorDependence</span><span class="params">(<span class="keyword">int</span> *A, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; i++)</span><br><span class="line">        A[i] = A[i<span class="number">-1</span>] * <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>下面的函数不是 vectorizable 的。因为是 floating-point arithmetic。一般来说，浮点数加法是可交换的，但浮点数加法不是可结合的。如果向量化，则会导致不同的 round decision，和一个不同的结果。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">calcSum</span><span class="params">(<span class="keyword">float</span>* a, <span class="keyword">unsigned</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> sum = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">unsigned</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">        sum += a[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如下所示的代码，GCC 会为其创建两个不同的版本。如果发现 a 和 b 和 c 有 overlap，则运行普通版本，否则运行 simd 版本。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">float</span>* a, <span class="keyword">float</span>* b, <span class="keyword">float</span>* c, <span class="keyword">unsigned</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">unsigned</span> i = <span class="number">1</span>; i &lt; N; i++) &#123;</span><br><span class="line">        c[i] = b[i];</span><br><span class="line">        a[i] = c[i<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -O3 -march=core-avx2 -fopt-info</span><br><span class="line">a.cpp:2:26: optimized: loop vectorized using 32 byte vectors</span><br><span class="line">a.cpp:2:26: optimized: loop versioned for vectorization because of possible</span><br><span class="line">aliasing</span><br></pre></td></tr></table></figure>

<h4 id="Vectorization-is-not-beneficial"><a href="#Vectorization-is-not-beneficial" class="headerlink" title="Vectorization is not beneficial"></a>Vectorization is not beneficial</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">stridedLoads</span><span class="params">(<span class="keyword">int</span> *A, <span class="keyword">int</span> *B, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">        A[i] += B[i * <span class="number">3</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="Loop-vectorized-but-scalar-version-used"><a href="#Loop-vectorized-but-scalar-version-used" class="headerlink" title="Loop vectorized but scalar version used"></a>Loop vectorized but scalar version used</h4><p>一般是因为 loop trip 比较小。比如以 AVX2 来说，如果同时加上 unroll 循环的技术，假设 unroll 4-5 倍，那么一个 loop iteration 需要处理 40 个元素。所以这种情况下，会直接 fallback 到处理剩余尾数的普通循环中。<br>此时，可以强制使用更小的 vectorization factor 或者 unroll count。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> clang loop vectorize_width(N)</span></span><br></pre></td></tr></table></figure>

<h4 id="Loop-vectorized-in-a-suboptimal-way"><a href="#Loop-vectorized-in-a-suboptimal-way" class="headerlink" title="Loop vectorized in a suboptimal way"></a>Loop vectorized in a suboptimal way</h4><p>最优的 vectorization factor 是难以通过直觉判断的，因为存在以下因素：</p>
<ol>
<li>很难在大脑中模拟 CPU 的运行模式<br> Vector shuffles that touch multiple vector lanes could be more or less expensive than expected, depending on many factors.<br> 什么是 vector shuffle？</li>
<li>运行时，程序可能以非预期的方式运行，取决于 port pressure 或者其他因素<br> 人类可以通过 Vectorization pragmas 来尝试各种  vectorization factor。也可以尝试各种 unroll factor 来选出最优的。但编译器做不到。</li>
<li>非 vec 的版本可能更好<br> 因为 gather/scatter loads, masking, shuffle 这些向量操作更昂贵。<br> 所以也需要尝试禁用向量化比较性能。如使用 <code>-fno-vectorize</code> 和 <code>-fno-slp-vectorize</code>，或者 <code>#pragma clang loop vectorize(enable)</code>。</li>
</ol>
<h4 id="Use-languages-with-explicit-vectorization"><a href="#Use-languages-with-explicit-vectorization" class="headerlink" title="Use languages with explicit vectorization"></a>Use languages with explicit vectorization</h4><h4 id="“Close-to-the-metal”-programming-model"><a href="#“Close-to-the-metal”-programming-model" class="headerlink" title="“Close to the metal” programming model"></a>“Close to the metal” programming model</h4><p>这里说的是传统的 C 和 C++ 中没有向量化的概念，所以总是需要通过 compiler intrinsics 来做这个工作。而像 ISPC 这样的语言中 <code>+=</code> 这样的操作符会被隐式地认为是 SIMD 操作，并会并行的执行多个加法。</p>
<h1 id="Optimizing-Bad-Speculation"><a href="#Optimizing-Bad-Speculation" class="headerlink" title="Optimizing Bad Speculation"></a>Optimizing Bad Speculation</h1><p>Mispredicting a branch can add a significant speed penalty when it happens regularly. When such an event happens, a CPU is required to clear all the speculative work that was done ahead of time and later was proven to be wrong. It also needs to flush the whole pipeline and start filling it with instructions from the correct path. Typically, modern CPUs experience a 15-20 cycles penalty as a result of a branch misprediction.</p>
<p>现在的处理器能够进行分支预测，不仅仅是静态的规则，甚至可以发现动态的模式。</p>
<p>我们可以通过 TMA Bad Speculation 指标来查看一个程序在多大程度上收到分支预测的影响。对此，作者推荐只有当分支预测失败率在 10% 以上的时候，再进行关注。</p>
<p>从前，可以在分治命令前加上前缀 0x2E 或者 0x3E 来分别表示是否选择这个分支。但随着后面分支预测机制的完善，这个功能被去掉了。所以目前唯一能够避免分支预测失败的<strong>直接</strong>办法是不使用分支。下面介绍两种避免分支的办法。</p>
<p>注：likely 和 unlikely 是通过放置可能性较大的指令到靠近分支跳转指令<a href="https://zhuanlan.zhihu.com/p/357434227" target="_blank" rel="noopener">来实现优化</a>的。</p>
<h2 id="Replace-branches-with-lookup"><a href="#Replace-branches-with-lookup" class="headerlink" title="Replace branches with lookup"></a>Replace branches with lookup</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">mapToBucket</span><span class="params">(<span class="keyword">unsigned</span> v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (v &gt;= <span class="number">0</span> &amp;&amp; v &lt; <span class="number">10</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (v &gt;= <span class="number">10</span> &amp;&amp; v &lt; <span class="number">20</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (v &gt;= <span class="number">20</span> &amp;&amp; v &lt; <span class="number">30</span>) <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> (v &gt;= <span class="number">30</span> &amp;&amp; v &lt; <span class="number">40</span>) <span class="keyword">return</span> <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">if</span> (v &gt;= <span class="number">40</span> &amp;&amp; v &lt; <span class="number">50</span>) <span class="keyword">return</span> <span class="number">4</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">==&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> buckets[<span class="number">256</span>] = &#123;</span><br><span class="line">    <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">    <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">    <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>,</span><br><span class="line">    <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>,</span><br><span class="line">    <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>,</span><br><span class="line">    <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>,</span><br><span class="line">    <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>,</span><br><span class="line">... &#125;;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">mapToBucket</span><span class="params">(<span class="keyword">unsigned</span> v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (v &lt; (<span class="keyword">sizeof</span> (buckets) / <span class="keyword">sizeof</span> (<span class="keyword">int</span>)))</span><br><span class="line">    <span class="keyword">return</span> buckets[v];</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Replace-branches-with-predication"><a href="#Replace-branches-with-predication" class="headerlink" title="Replace branches with predication"></a>Replace branches with predication</h2><h1 id="额外说明"><a href="#额外说明" class="headerlink" title="额外说明"></a>额外说明</h1><h2 id="superscalar-和-SMT"><a href="#superscalar-和-SMT" class="headerlink" title="superscalar 和 SMT"></a>superscalar 和 SMT</h2><p>在“Superscalar Engines and VLIW”中介绍了 superscalar 技术。superscalar 指的是在一条流水线中，有多个执行单元，所以在一个 cycle 中可以 issue 多条指令。所以这就导致原先串行的命令中，不冲突的命令不再构成全序关系，这也就是所谓的 OOO 乱序执行。BTW，将全序关系拆解成多个不冲突的偏序关系也是一种并行或者分布式领域的常用技术。</p>
<p>SMT 也就是 Simultaneous Multithreading，也被称为 hyperthreading。指一个核心同时拥有两套寄存器、缓存，保存两个线程工作的现场。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div></div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/img/fkm/wxfk.jpg" alt="Calvin Neo WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/img/fkm/zfbfk.jpg" alt="Calvin Neo Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/性能/" rel="tag"># 性能</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2023/09/11/grafana-issue-floating/" rel="next" title="Grafana 使用 histogram_quantile 和 rate 的精度问题">
                <i class="fa fa-chevron-left"></i> Grafana 使用 histogram_quantile 和 rate 的精度问题
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/favicon.jpg"
               alt="Calvin Neo" />
          <p class="site-author-name" itemprop="name">Calvin Neo</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">203</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">146</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/CalvinNeo" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/CalvinNeo0" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/1568200035" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://xqq.im/" title="xqq" target="_blank">xqq</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.lovelywen.com/" title="wenwen" target="_blank">wenwen</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://smlight.github.io/blog/" title="zyyyyy" target="_blank">zyyyyy</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Part-1-的说明"><span class="nav-number">1.</span> <span class="nav-text">Part 1 的说明</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Measuring-Performance"><span class="nav-number">2.</span> <span class="nav-text">Measuring Performance</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Noise-In-Modern-Systems"><span class="nav-number">2.1.</span> <span class="nav-text">Noise In Modern Systems</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Measuring-Performance-In-Production"><span class="nav-number">2.2.</span> <span class="nav-text">Measuring Performance In Production</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CPU-Microarchitecture"><span class="nav-number">3.</span> <span class="nav-text">CPU Microarchitecture</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Instruction-Set-Architecture"><span class="nav-number">3.1.</span> <span class="nav-text">Instruction Set Architecture</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pipelining"><span class="nav-number">3.2.</span> <span class="nav-text">Pipelining</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Exploiting-Instruction-Level-Parallelism-ILP"><span class="nav-number">3.3.</span> <span class="nav-text">Exploiting Instruction Level Parallelism (ILP)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#OOO-Execution"><span class="nav-number">3.3.1.</span> <span class="nav-text">OOO Execution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Superscalar-Engines-and-VLIW"><span class="nav-number">3.3.2.</span> <span class="nav-text">Superscalar Engines and VLIW</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Speculative-Execution"><span class="nav-number">3.3.3.</span> <span class="nav-text">Speculative Execution</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Exploiting-Thread-Level-Parallelism"><span class="nav-number">3.4.</span> <span class="nav-text">Exploiting Thread Level Parallelism</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Simultaneous-Multithreading"><span class="nav-number">3.4.1.</span> <span class="nav-text">Simultaneous Multithreading</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Memory-Hierarchy"><span class="nav-number">3.5.</span> <span class="nav-text">Memory Hierarchy</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Cache-Hierarchy"><span class="nav-number">3.5.1.</span> <span class="nav-text">Cache Hierarchy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Placement-of-data-within-the-cache"><span class="nav-number">3.5.1.1.</span> <span class="nav-text">Placement of data within the cache</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Finding-data-in-the-cache"><span class="nav-number">3.5.1.2.</span> <span class="nav-text">Finding data in the cache</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Managing-misses"><span class="nav-number">3.5.1.3.</span> <span class="nav-text">Managing misses</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Managing-writes"><span class="nav-number">3.5.1.4.</span> <span class="nav-text">Managing writes</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Other-cache-optimization-techniques"><span class="nav-number">3.5.1.5.</span> <span class="nav-text">Other cache optimization techniques</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HW-and-SW-Prefetching"><span class="nav-number">3.5.1.6.</span> <span class="nav-text">HW and SW Prefetching</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Main-memory"><span class="nav-number">3.5.2.</span> <span class="nav-text">Main memory</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Virtual-Memory"><span class="nav-number">3.6.</span> <span class="nav-text">Virtual Memory</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SIMD-Multiprocessors"><span class="nav-number">3.7.</span> <span class="nav-text">SIMD Multiprocessors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Modern-CPU-design"><span class="nav-number">3.8.</span> <span class="nav-text">Modern CPU design</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU-Front-End"><span class="nav-number">3.8.1.</span> <span class="nav-text">CPU Front-End</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU-Back-End"><span class="nav-number">3.8.2.</span> <span class="nav-text">CPU Back-End</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Performance-Monitoring-Unit"><span class="nav-number">3.8.3.</span> <span class="nav-text">Performance Monitoring Unit</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Performance-Monitoring-Counters"><span class="nav-number">3.8.3.1.</span> <span class="nav-text">Performance Monitoring Counters</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Terminology-and-metrics-in-performance-analysis"><span class="nav-number">4.</span> <span class="nav-text">Terminology and metrics in performance analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Retired-vs-Executed-Instruction"><span class="nav-number">4.1.</span> <span class="nav-text">Retired vs. Executed Instruction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CPU-Utilization"><span class="nav-number">4.2.</span> <span class="nav-text">CPU Utilization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CPI-amp-IPC"><span class="nav-number">4.3.</span> <span class="nav-text">CPI &amp; IPC</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#UOPs-micro-ops"><span class="nav-number">4.4.</span> <span class="nav-text">UOPs (micro-ops)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pipeline-Slot"><span class="nav-number">4.5.</span> <span class="nav-text">Pipeline Slot</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Core-vs-Reference-Cycles"><span class="nav-number">4.6.</span> <span class="nav-text">Core vs. Reference Cycles</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cache-miss"><span class="nav-number">4.7.</span> <span class="nav-text">Cache miss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mispredicted-branch"><span class="nav-number">4.8.</span> <span class="nav-text">Mispredicted branch</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Performance-Analysis-Approaches"><span class="nav-number">5.</span> <span class="nav-text">Performance Analysis Approaches</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Code-Instrumentation"><span class="nav-number">5.1.</span> <span class="nav-text">Code Instrumentation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tracing"><span class="nav-number">5.2.</span> <span class="nav-text">Tracing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Workload-Characterization"><span class="nav-number">5.3.</span> <span class="nav-text">Workload Characterization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Counting-Performance-Events"><span class="nav-number">5.3.1.</span> <span class="nav-text">Counting Performance Events</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Manual-performance-counters-collection"><span class="nav-number">5.3.2.</span> <span class="nav-text">Manual performance counters collection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multiplexing-and-scaling-events"><span class="nav-number">5.3.3.</span> <span class="nav-text">Multiplexing and scaling events</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sampling"><span class="nav-number">5.4.</span> <span class="nav-text">Sampling</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#User-Mode-And-Hardware-Event-based-Sampling"><span class="nav-number">5.4.1.</span> <span class="nav-text">User-Mode And Hardware Event-based Sampling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Finding-Hotspots"><span class="nav-number">5.4.2.</span> <span class="nav-text">Finding Hotspots</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Collecting-Call-Stacks"><span class="nav-number">5.4.3.</span> <span class="nav-text">Collecting Call Stacks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flame-graph"><span class="nav-number">5.4.4.</span> <span class="nav-text">Flame graph</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Roofline-Performance-Model"><span class="nav-number">5.5.</span> <span class="nav-text">Roofline Performance Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Static-Performance-Analysis"><span class="nav-number">5.6.</span> <span class="nav-text">Static Performance Analysis</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Compiler-Optimization-Reports"><span class="nav-number">5.7.</span> <span class="nav-text">Compiler Optimization Reports</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CPU-Features-For-Performance-Analysis"><span class="nav-number">6.</span> <span class="nav-text">CPU Features For Performance Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Top-Down-Microarchitecture-Analysis"><span class="nav-number">6.1.</span> <span class="nav-text">Top-Down Microarchitecture Analysis</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Part-2-的说明"><span class="nav-number">7.</span> <span class="nav-text">Part 2 的说明</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Driven-Optimizations"><span class="nav-number">7.1.</span> <span class="nav-text">Data-Driven Optimizations</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CPU-Front-End-Optimizations"><span class="nav-number">8.</span> <span class="nav-text">CPU Front-End Optimizations</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Machine-code-layout"><span class="nav-number">8.1.</span> <span class="nav-text">Machine code layout</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic-Block"><span class="nav-number">8.2.</span> <span class="nav-text">Basic Block</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic-block-placement"><span class="nav-number">8.3.</span> <span class="nav-text">Basic block placement</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic-block-alignment"><span class="nav-number">8.4.</span> <span class="nav-text">Basic block alignment</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Function-splitting"><span class="nav-number">8.5.</span> <span class="nav-text">Function splitting</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Function-grouping"><span class="nav-number">8.6.</span> <span class="nav-text">Function grouping</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Profile-Guided-Optimizations"><span class="nav-number">8.7.</span> <span class="nav-text">Profile Guided Optimizations</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Optimizing-for-ITLB"><span class="nav-number">8.8.</span> <span class="nav-text">Optimizing for ITLB</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">8.9.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CPU-Back-End-Optimizations"><span class="nav-number">9.</span> <span class="nav-text">CPU Back-End Optimizations</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Memory-Bound"><span class="nav-number">9.1.</span> <span class="nav-text">Memory Bound</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Cache-Friendly-Data-Structures"><span class="nav-number">9.1.1.</span> <span class="nav-text">Cache-Friendly Data Structures</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Access-data-sequentially"><span class="nav-number">9.1.1.1.</span> <span class="nav-text">Access data sequentially</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Use-appropriate-containers"><span class="nav-number">9.1.1.2.</span> <span class="nav-text">Use appropriate containers</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Packing-the-data"><span class="nav-number">9.1.1.3.</span> <span class="nav-text">Packing the data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Aligning-and-padding"><span class="nav-number">9.1.1.4.</span> <span class="nav-text">Aligning and padding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dynamic-memory-allocation"><span class="nav-number">9.1.1.5.</span> <span class="nav-text">Dynamic memory allocation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tune-the-code-for-memory-hierarchy"><span class="nav-number">9.1.1.6.</span> <span class="nav-text">Tune the code for memory hierarchy</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Explicit-Memory-Prefetching"><span class="nav-number">9.1.2.</span> <span class="nav-text">Explicit Memory Prefetching</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Optimizing-For-DTLB"><span class="nav-number">9.1.3.</span> <span class="nav-text">Optimizing For DTLB</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Explicit-Hugepages"><span class="nav-number">9.1.3.1.</span> <span class="nav-text">Explicit Hugepages</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Transparent-Hugepages"><span class="nav-number">9.1.3.2.</span> <span class="nav-text">Transparent Hugepages</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Explicit-vs-Transparent-Hugepages"><span class="nav-number">9.1.3.3.</span> <span class="nav-text">Explicit vs. Transparent Hugepages</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Core-Bound"><span class="nav-number">9.2.</span> <span class="nav-text">Core Bound</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Inlining-Functions"><span class="nav-number">9.2.1.</span> <span class="nav-text">Inlining Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Loop-Optimizations"><span class="nav-number">9.2.2.</span> <span class="nav-text">Loop Optimizations</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Low-level-optimizations"><span class="nav-number">9.2.2.1.</span> <span class="nav-text">Low-level optimizations</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Loop-Invariant-Code-Motion-LICM"><span class="nav-number">9.2.2.1.1.</span> <span class="nav-text">Loop Invariant Code Motion (LICM)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Loop-Unrolling"><span class="nav-number">9.2.2.1.2.</span> <span class="nav-text">Loop Unrolling</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Loop-Strength-Reduction-LSR"><span class="nav-number">9.2.2.1.3.</span> <span class="nav-text">Loop Strength Reduction (LSR)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Loop-Unswitching"><span class="nav-number">9.2.2.1.4.</span> <span class="nav-text">Loop Unswitching</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#High-level-optimizations"><span class="nav-number">9.2.2.2.</span> <span class="nav-text">High-level optimizations</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Loop-Interchange"><span class="nav-number">9.2.2.2.1.</span> <span class="nav-text">Loop Interchange</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Loop-Blocking-Tiling"><span class="nav-number">9.2.2.2.2.</span> <span class="nav-text">Loop Blocking (Tiling)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Loop-Fusion-and-Distribution-Fission"><span class="nav-number">9.2.2.2.3.</span> <span class="nav-text">Loop Fusion and Distribution (Fission)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Discovering-loop-optimization-opportunities"><span class="nav-number">9.2.2.3.</span> <span class="nav-text">Discovering loop optimization opportunities</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Use-Loop-Optimization-Frameworks"><span class="nav-number">9.2.2.4.</span> <span class="nav-text">Use Loop Optimization Frameworks</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Vectorization"><span class="nav-number">9.2.3.</span> <span class="nav-text">Vectorization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Compiler-Autovectorization"><span class="nav-number">9.2.3.1.</span> <span class="nav-text">Compiler Autovectorization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Discovering-vectorization-opportunities"><span class="nav-number">9.2.3.2.</span> <span class="nav-text">Discovering vectorization opportunities</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Vectorization-is-illegal"><span class="nav-number">9.2.3.3.</span> <span class="nav-text">Vectorization is illegal</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Vectorization-is-not-beneficial"><span class="nav-number">9.2.3.4.</span> <span class="nav-text">Vectorization is not beneficial</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Loop-vectorized-but-scalar-version-used"><span class="nav-number">9.2.3.5.</span> <span class="nav-text">Loop vectorized but scalar version used</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Loop-vectorized-in-a-suboptimal-way"><span class="nav-number">9.2.3.6.</span> <span class="nav-text">Loop vectorized in a suboptimal way</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Use-languages-with-explicit-vectorization"><span class="nav-number">9.2.3.7.</span> <span class="nav-text">Use languages with explicit vectorization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#“Close-to-the-metal”-programming-model"><span class="nav-number">9.2.3.8.</span> <span class="nav-text">“Close to the metal” programming model</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Optimizing-Bad-Speculation"><span class="nav-number">10.</span> <span class="nav-text">Optimizing Bad Speculation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Replace-branches-with-lookup"><span class="nav-number">10.1.</span> <span class="nav-text">Replace branches with lookup</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Replace-branches-with-predication"><span class="nav-number">10.2.</span> <span class="nav-text">Replace branches with predication</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#额外说明"><span class="nav-number">11.</span> <span class="nav-text">额外说明</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#superscalar-和-SMT"><span class="nav-number">11.1.</span> <span class="nav-text">superscalar 和 SMT</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Calvin Neo</span>
  <span> &nbsp; Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a></span>
</div>
<div>
  <span><a href="/about/yytl/">版权声明</a></span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse 
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://www.calvinneo.com/2023/12/17/patmc/';
          this.page.identifier = '2023/12/17/patmc/';
          this.page.title = 'Performance analysis and tuning on modern CPUs 学习笔记';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://calvinneo.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  








  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      $('#local-search-input').focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

</body>
</html>
